quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,filename,wiki,url,total_similar,target_keywords,target_matched_words
Deployability,"tructor initializers before the colon and after the commas. .. code-block:: c++. Constructor(); : initializer1(),; initializer2(). * ``BCIS_BeforeComma`` (in configuration: ``BeforeComma``); Break constructor initializers before the colon and commas, and align; the commas with the colon. .. code-block:: c++. Constructor(); : initializer1(); , initializer2(). * ``BCIS_AfterColon`` (in configuration: ``AfterColon``); Break constructor initializers after the colon and commas. .. code-block:: c++. Constructor() :; initializer1(),; initializer2(). .. _BreakInheritanceList:. **BreakInheritanceList** (``BreakInheritanceListStyle``) :versionbadge:`clang-format 7` :ref:`¶ <BreakInheritanceList>`; The inheritance list style to use. Possible values:. * ``BILS_BeforeColon`` (in configuration: ``BeforeColon``); Break inheritance list before the colon and after the commas. .. code-block:: c++. class Foo; : Base1,; Base2; {};. * ``BILS_BeforeComma`` (in configuration: ``BeforeComma``); Break inheritance list before the colon and commas, and align; the commas with the colon. .. code-block:: c++. class Foo; : Base1; , Base2; {};. * ``BILS_AfterColon`` (in configuration: ``AfterColon``); Break inheritance list after the colon and commas. .. code-block:: c++. class Foo :; Base1,; Base2; {};. * ``BILS_AfterComma`` (in configuration: ``AfterComma``); Break inheritance list only after the commas. .. code-block:: c++. class Foo : Base1,; Base2; {};. .. _BreakStringLiterals:. **BreakStringLiterals** (``Boolean``) :versionbadge:`clang-format 3.9` :ref:`¶ <BreakStringLiterals>`; Allow breaking string literals when formatting. In C, C++, and Objective-C:. .. code-block:: c++. true:; const char* x = ""veryVeryVeryVeryVeryVe""; ""ryVeryVeryVeryVeryVery""; ""VeryLongString"";. false:; const char* x =; ""veryVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryLongString"";. In C# and Java:. .. code-block:: c++. true:; string x = ""veryVeryVeryVeryVeryVe"" +; ""ryVeryVeryVeryVeryVery"" +; ""VeryLongString"";. false:; s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:55345,configurat,configuration,55345,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"true is a required pass. For example:. .. code-block:: c++. class HelloWorldPass : public PassInfoMixin<HelloWorldPass> {; public:; PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);. static bool isRequired() { return true; }; };. A required pass is a pass that may not be skipped. An example of a required; pass is ``AlwaysInlinerPass``, which must always be run to preserve; ``alwaysinline`` semantics. Pass managers are required since they may contain; other required passes. An example of how a pass can be skipped is the ``optnone`` function; attribute, which specifies that optimizations should not be run on the; function. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:7519,pipeline,pipelines,7519,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,1,['pipeline'],['pipelines']
Deployability,"try``, the static; destructor *unregisters*. Thus a pass that is statically linked in the tool; will be registered at start up. A dynamically loaded pass will register on; load and unregister at unload. Using existing registries; -------------------------. There are predefined registries to track instruction scheduling; (``RegisterScheduler``) and register allocation (``RegisterRegAlloc``) machine; passes. Here we will describe how to *register* a register allocator machine; pass. Implement your register allocator machine pass. In your register allocator; ``.cpp`` file add the following include:. .. code-block:: c++. #include ""llvm/CodeGen/RegAllocRegistry.h"". Also in your register allocator ``.cpp`` file, define a creator function in the; form:. .. code-block:: c++. FunctionPass *createMyRegisterAllocator() {; return new MyRegisterAllocator();; }. Note that the signature of this function should match the type of; ``RegisterRegAlloc::FunctionPassCtor``. In the same file add the ""installing""; declaration, in the form:. .. code-block:: c++. static RegisterRegAlloc myRegAlloc(""myregalloc"",; ""my register allocator help string"",; createMyRegisterAllocator);. Note the two spaces prior to the help string produces a tidy result on the; :option:`-help` query. .. code-block:: console. $ llc -help; ...; -regalloc - Register allocator to use (default=linearscan); =linearscan - linear scan register allocator; =local - local register allocator; =simple - simple register allocator; =myregalloc - my register allocator help string; ... And that's it. The user is now free to use ``-regalloc=myregalloc`` as an; option. Registering instruction schedulers is similar except use the; ``RegisterScheduler`` class. Note that the; ``RegisterScheduler::FunctionPassCtor`` is significantly different from; ``RegisterRegAlloc::FunctionPassCtor``. To force the load/linking of your register allocator into the; :program:`llc`/:program:`lli` tools, add your creator function's global; declaration to ``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:50052,install,installing,50052,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['install'],['installing']
Deployability,"ts are verified. It is the; responsibility of the programmer to ensure that this verification was indeed; correct. Please note that `csa_mark_sanitized` function is only declared and; used during Clang Static Analysis and skipped in (production) builds. Further examples of injection vulnerabilities this checker can find. .. code-block:: c. void test() {; char x = getchar(); // 'x' marked as tainted; system(&x); // warn: untrusted data is passed to a system call; }. // note: compiler internally checks if the second param to; // sprintf is a string literal or not.; // Use -Wno-format-security to suppress compiler warning.; void test() {; char s[10], buf[10];; fscanf(stdin, ""%s"", s); // 's' marked as tainted. sprintf(buf, s); // warn: untrusted data used as a format string; }. void test() {; size_t ts;; scanf(""%zd"", &ts); // 'ts' marked as tainted; int *p = (int *)malloc(ts * sizeof(int));; // warn: untrusted data used as buffer size; }. There are built-in sources, propagations and sinks even if no external taint; configuration is provided. Default sources:; ``_IO_getc``, ``fdopen``, ``fopen``, ``freopen``, ``get_current_dir_name``,; ``getch``, ``getchar``, ``getchar_unlocked``, ``getwd``, ``getcwd``,; ``getgroups``, ``gethostname``, ``getlogin``, ``getlogin_r``, ``getnameinfo``,; ``gets``, ``gets_s``, ``getseuserbyname``, ``readlink``, ``readlinkat``,; ``scanf``, ``scanf_s``, ``socket``, ``wgetch``. Default propagations rules:; ``atoi``, ``atol``, ``atoll``, ``basename``, ``dirname``, ``fgetc``,; ``fgetln``, ``fgets``, ``fnmatch``, ``fread``, ``fscanf``, ``fscanf_s``,; ``index``, ``inflate``, ``isalnum``, ``isalpha``, ``isascii``, ``isblank``,; ``iscntrl``, ``isdigit``, ``isgraph``, ``islower``, ``isprint``, ``ispunct``,; ``isspace``, ``isupper``, ``isxdigit``, ``memchr``, ``memrchr``, ``sscanf``,; ``getc``, ``getc_unlocked``, ``getdelim``, ``getline``, ``getw``, ``memcmp``,; ``memcpy``, ``memmem``, ``memmove``, ``mbtowc``, ``pread``, ``qsort``,; ``qsort_r``, ``rawmemc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:70978,configurat,configuration,70978,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['configurat'],['configuration']
Deployability,"ts are; given in \ref tprocessid, \ref tref, and \ref trefarray respectively.; Of these three objects, only TProcessID objects necessarily comprise; a complete data record (a ""TProcessID"" record). TRef and TRefArray; objects typically are data members of larger objects, and therefore are; only a part of the data portion of a record. In addition, objects that; are referenced by such a pointer have an additional field in the base TObject.; See \ref tobject. A description of how these pointers work is given under; the \ref ptpo ""Pointers to persistent objects"" heading below. ### ""application"" layer record types. These are either user defined record types, or record types supplied; by ROOT that are not needed by ROOTIO. The format of such an object that; uses the default streamer is shown in \ref dobject. ## Data compression. The user can set the data compression level for new or modified data records; when creating or opening a file. When an existing file is opened for update,; the compression level selected need not match that used previously. The; compression level of existing records is not modified unless the record itself; is modified. There are ten compression levels, 0-9, ranging from 0 (no compression) to 9; (maximum compression), with level 1 being the default. The level chosen is; a tradeoff between disk space and compression performance. The decompression; speed is independent of level. Currently, in release 3.2.6, level 2 is not used.; If level 2 is selected, level 1 is used with no notification to the user. The chosen compression level is not applied to the entire file. The following; portions of the file are not compressed, regardless of the compression level; selected:. 1. the file header; 2. the KeysList data record; 3. the FreeSegments data record; 4. any data record (outside of a TTree) where the uncompressed size of; the data portion is 256 bytes or less.; 5. the key portion of any data record. Furthermore, the data portion of the StreamerInfo data re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:4681,update,update,4681,io/doc/TFile/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md,1,['update'],['update']
Deployability,"ts compiling and linking in a single step:. .. code-block:: shell. clang++ --offload-arch=gfx906 -xhip sample.cpp -o sample. In the above commands, ``gfx906`` is the GPU architecture that the code is being compiled for. The supported GPU; architectures can be found in the `AMDGPU Processor Table <https://llvm.org/docs/AMDGPUUsage.html#processors>`_.; Alternatively, you can use the ``amdgpu-arch`` tool that comes with Clang to list the GPU architecture on your system:. .. code-block:: shell. amdgpu-arch. You can use ``--offload-arch=native`` to automatically detect the GPU architectures on your system:. .. code-block:: shell. clang++ --offload-arch=native -xhip sample.cpp -o sample. Path Setting for Dependencies; =============================. Compiling a HIP program depends on the HIP runtime and device library. The paths to the HIP runtime and device libraries; can be specified either using compiler options or environment variables. The paths can also be set through the ROCm path; if they follow the ROCm installation directory structure. Order of Precedence for HIP Path; --------------------------------. 1. ``--hip-path`` compiler option; 2. ``HIP_PATH`` environment variable *(use with caution)*; 3. ``--rocm-path`` compiler option; 4. ``ROCM_PATH`` environment variable *(use with caution)*; 5. Default automatic detection (relative to Clang or at the default ROCm installation location). Order of Precedence for Device Library Path; -------------------------------------------. 1. ``--hip-device-lib-path`` compiler option; 2. ``HIP_DEVICE_LIB_PATH`` environment variable *(use with caution)*; 3. ``--rocm-path`` compiler option; 4. ``ROCM_PATH`` environment variable *(use with caution)*; 5. Default automatic detection (relative to Clang or at the default ROCm installation location). .. list-table::; :header-rows: 1. * - Compiler Option; - Environment Variable; - Description; - Default Value; * - ``--rocm-path=<path>``; - ``ROCM_PATH``; - Specifies the ROCm installation pa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HIPSupport.rst:3904,install,installation,3904,interpreter/llvm-project/clang/docs/HIPSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HIPSupport.rst,1,['install'],['installation']
Deployability,"ts for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can break them.; The two typical solutions are to either restrict the choice of Python; interpreter and version that are supported (common in HPC) or to provide; binaries (wheels) for a large range of different interpreters and versions; (as e.g. done for conda). In the case of cppyy, only CPython/CPyCppyy and PyPy/_cppyy (an internal; module) depend on the Python interpreter (see:; :ref:`Package Structure <package-structure>`).; The user-facing ``cppyy`` module is pure Python and the backend (Cling) is; Python-independent.; Most importantly, since all bindings are generated at run-time, there are no; extension modules to regenerate and/or recompile. Thus, the end-user only needs to rebuild/reinstall CPyCppyy for each relevant; version of Python (and nothing extra is needed for PyPy) to switch Python; versions and/or interpreter.; The rest of the software stack remains completely unchanged.; Only if Cling in cppyy's backend is updated, which happens infrequently, and; non-standard precompiled headers or modules are used, do these need to be; rebuild in full. .. _`SWIG`: http://swig.org/; .. _`pybind11`: https://pybind11.readthedocs.io/en/stable/; .. _`PyPy`: https://www.pypy.org/; .. _`CINT`: https://en.wikipedia.org/wiki/CINT; .. _`LLVM`: https://llvm.org/; .. _`Numba`: http://numba.pydata.org/; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:11714,update,updated,11714,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,1,['update'],['updated']
Deployability,"ts the heap; used is the garbage collected one and no further action is required. Otherwise; the compiler must issue a call to potentially release any heap storage for; ``__block`` variables at all escapes or terminations of their scope. The call; should be:. .. code-block:: c. _Block_object_dispose(&_block_byref_foo, BLOCK_FIELD_IS_BYREF);. Nesting; ^^^^^^^. ``Blocks`` may contain ``Block`` literal expressions. Any variables used within; inner blocks are imported into all enclosing ``Block`` scopes even if the; variables are not used. This includes ``const`` imports as well as ``__block``; variables. Objective C Extensions to ``Blocks``; ====================================. Importing Objects; -----------------. Objects should be treated as ``__attribute__((NSObject))`` variables; all; ``copy_helper``, ``dispose_helper``, ``byref_keep``, and ``byref_dispose``; helper functions should use ``_Block_object_assign`` and; ``_Block_object_dispose``. There should be no code generated that uses; ``*-retain`` or ``*-release`` methods. ``Blocks`` as Objects; ---------------------. The compiler will treat ``Blocks`` as objects when synthesizing property setters; and getters, will characterize them as objects when generating garbage; collection strong and weak layout information in the same manner as objects, and; will issue strong and weak write-barrier assignments in the same manner as; objects. ``__weak __block`` Support; --------------------------. Objective-C (and Objective-C++) support the ``__weak`` attribute on ``__block``; variables. Under normal circumstances the compiler uses the Objective-C runtime; helper support functions ``objc_assign_weak`` and ``objc_read_weak``. Both; should continue to be used for all reads and writes of ``__weak __block``; variables:. .. code-block:: c. objc_read_weak(&block->byref_i->forwarding->i). The ``__weak`` variable is stored in a ``_block_byref_foo`` structure and the; ``Block`` has copy and dispose helpers for this structure that ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst:18989,release,release,18989,interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,1,['release'],['release']
Deployability,"ts, then the plot behind; will be visible. ### TH2Poly. - Implement a simple version of ""Scale"". ### TF1. - Change `TF1::Integral(double a, double b, double * params = 0, double eps = 1.E-12)` to; `TF1::Integral(doubnle a, double b, double epsrel=1.E-12)`. One should use `TF1::SetParameters` to; set the function parameters before computing the integral. - Add a new function `TF1::IntegralOneDim(Double_t a, Double_t b, Double_t epsrel, Double_t epsabs, Double_t &err)`; that returns as last argument the error in the integration. `TF1::Integral` is implemented using `Tf1::IntegralOneDim`. - The one-dim and multi-dim integral functions are now implemented using the `ROOT::Math::IntegratorOneDim` and `ROOT::Math::IntegratorMultiDim`; classes. This allows to change the integration algorithm used in `TF1` using the static methods of the classes; `ROOT::Math::IntegratorOneDimOptions` and `ROOT::Math::IntegratorMultiDimOptions`. The default algorithm used are; `ROOT::Math::IntegratorOneDimOptions::DefaultIntegratorType()` and `ROOT::Math::IntegratorMultiDimOptions::DefaultIntegratorType()`.; For example, if ROOT has been built with mathmore the default one-dim integration type is the GSL AdaptiveSingular integration algorithm. - Implement the possibility to save a `TF1` as C code indenpant from; ROOT. It is enough to save the function as a "".cc"" file. \; Example:. ``` {.cpp}; root [0] TF1 *f1 = new TF1(""f1"",""x*x"",-10,10); root [1] f1->SaveAs(""f1.cc"");; Info in <TF1::SaveAs>: cc file: f1.cc has been generated; root [2] .x f1.cc(9.); (double)8.10019368181367980e+01; ```. ### TF2, TF3. - Implement `TF2::GetMinimumXY` and `TF3::GetMinimumXYZ` using the `ROOT::Math::Minimizer` class instead of `TFitter`. The methods return now the function value at the minimum. - Implement also a `TF2::GetMaximumXY` and `TF3::GetMaximumXYZ`. - Remove some ambigous `Integral` functions. ### TFractionFitter, TBinomialFitter. - Change to use the `ROOT::Math::Fitter` instead of the `TFitter` class.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:13423,integrat,integration,13423,hist/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md,2,['integrat'],['integration']
Deployability,"ts. 2021-02-15: 1.9.3; -----------------. * Wheels for Linux now follow manylinux2014; * Enable direct calls of base class' methods in Python cross-overrides; * cppyy.bind_object can now re-cast types, incl. Python cross-derived ones; * Python cross-derived objects send to (and owned by) C++ retain Python state; * Ignore, for symbol lookups, libraries that can not be reloaded; * Use PathCanonicalize when resolving paths on Windows; * Add more ways of finding the backend library; * Improve error reporting when failed to find the backend library; * Workaround for mixing std::endl in JIT-ed and compiled code on Windows 32b; * Fixed a subtle crash that arises when an invalid ``using`` is the last method; * Filter -fno-plt (coming from anaconda builds; not understood by Cling); * Fixed memory leak in generic base ``__str__``. 2021-01-05: 1.9.2; -----------------. * Added ``cppyy.types`` module for exposing cppyy builtin types; * Improve numpy integration with custom ``__array__`` methods; * Allow operator overload resolution mixing class and global methods; * Installation fixes for PyPy when using pip. 2020-11-23: 1.9.1; -----------------. * Fix custom installer in pip sdist. 2020-11-22: 1.9.0; -----------------. * In-tree build resolving build/install order for PyPy with pyproject.toml; * ``std::string`` not converterd to ``str`` on function returns; * Cover more use cases where C string memory can be managed; * Automatic memory management of converted python functions; * Added pyinstaller hooks (https://stackoverflow.com/questions/64406727); * Support for enums in pseudo-constructors of aggregates; * Fixes for overloaded/split-access protected members in cross-inheritance; * Support for deep, mixed, hierarchies for multi-cross-inheritance; * Added tp_iter method to low level views. 2020-11-06: 1.8.6; -----------------. * Fix preprocessor macro of CPyCppyy header for Windows/MSVC. 2020-10-31: 1.8.5; -----------------. * Fix leaks when using vector iterators on Py3/Linux.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:8598,integrat,integration,8598,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,1,['integrat'],['integration']
Deployability,"ts.llvm.org/mailman/listinfo/cfe-commits>`_, or `lldb-commits; <http://lists.llvm.org/mailman/listinfo/lldb-commits>`_. Missing features and bugs are tracked through our `GitHub issue tracker <https://github.com/llvm/llvm-project/issues>`_; and assigned labels. We recommend that active developers monitor incoming issues.; You can subscribe for notification for specific components by joining; one of the `issue-subscribers-* <https://github.com/orgs/llvm/teams?query=issue-subscribers>`_; teams.; You may also subscribe to the `llvm-bugs; <http://lists.llvm.org/mailman/listinfo/llvm-bugs>`_ email list to keep track; of bugs and enhancements occurring in the entire project. We really appreciate people; who are proactive at catching incoming bugs in their components and dealing with them; promptly. Please be aware that all public LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and the time it is applied. #. Once you have created your patch, create a; :ref:`GitHub Pull Request <github-reviews>` for; it (or commit it directly if applicable). When submitting patches, please do not add confidentiality or non-disclosure; notices to the patches themselves. These notices conflict with the LLVM; licensing terms and may result in your contribution being excluded. .",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:3718,patch,patches,3718,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['patch'],['patches']
Deployability,"tted as separate patches as this makes reviewing easier.; * have a single commit (unless stacked on another Differential), up-to-date with the upstream ``origin/main`` branch, and don't have merges. .. _format patches:. Before sending a patch for review, please also try to ensure it is; formatted properly. We use ``clang-format`` for this, which has git integration; through the ``git-clang-format`` script. On some systems, it may already be; installed (or be installable via your package manager). If so, you can simply; run it -- the following command will format only the code changed in the most; recent commit:. .. code-block:: console. % git clang-format HEAD~1. Note that this modifies the files, but doesn't commit them -- you'll likely want; to run. .. code-block:: console. % git commit --amend -a. in order to update the last commit with all pending changes. .. note::; If you don't already have ``clang-format`` or ``git clang-format`` installed; on your system, the ``clang-format`` binary will be built alongside clang, and; the git integration can be run from; ``clang/tools/clang-format/git-clang-format``. The LLVM project has migrated to GitHub Pull Requests as its review process.; We still have an active :ref:`Phabricator <phabricator-reviews>`; instance for the duration of the migration. If you want to contribute to LLVM; now, please use GitHub. For more information about the workflow of using GitHub; Pull Requests see our :ref:`GitHub <github-reviews>` documentation. To make sure the right people see your patch, please select suitable reviewers; and add them to your patch when requesting a review. Suitable reviewers are the; code owner (see CODE_OWNERS.txt) and other people doing work in the area your; patch touches. Github will normally suggest some reviewers based on rules or; people that have worked on the code before. If you are a new contributor, you; will not be able to select reviewers in such a way, in which case you can still; get the attention of pot",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst:3261,install,installed,3261,interpreter/llvm-project/llvm/docs/Contributing.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Contributing.rst,2,"['install', 'integrat']","['installed', 'integration']"
Deployability,"tutions are not defined in the proper order, some will remain in the; ``RUN:`` line unexpanded. For example, the following directives refer to; ``%{inner}`` within ``%{outer}`` but do not define ``%{inner}`` until after; ``%{outer}``:. .. code-block:: llvm. ; By default, this definition order does not enable full expansion. ; DEFINE: %{outer} = %{inner}; ; DEFINE: %{inner} = expanded. ; RUN: echo '%{outer}'. ``DEFINE:`` inserts substitutions at the start of the substitution list, so; ``%{inner}`` expands first but has no effect because the original ``RUN:`` line; does not contain ``%{inner}``. Next, ``%{outer}`` expands, and the output of; the ``echo`` command becomes:. .. code-block:: shell. %{inner}. Of course, one way to fix this simple case is to reverse the definitions of; ``%{outer}`` and ``%{inner}``. However, if a test has a complex set of; substitutions that can all reference each other, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:36839,configurat,configuration,36839,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['configurat'],['configuration']
Deployability,"tyExcessCharacter>`; The penalty for each character outside of the column limit. .. _PenaltyIndentedWhitespace:. **PenaltyIndentedWhitespace** (``Unsigned``) :versionbadge:`clang-format 12` :ref:`¶ <PenaltyIndentedWhitespace>`; Penalty for each character of whitespace indentation; (counted relative to leading non-whitespace column). .. _PenaltyReturnTypeOnItsOwnLine:. **PenaltyReturnTypeOnItsOwnLine** (``Unsigned``) :versionbadge:`clang-format 3.7` :ref:`¶ <PenaltyReturnTypeOnItsOwnLine>`; Penalty for putting the return type of a function onto its own line. .. _PointerAlignment:. **PointerAlignment** (``PointerAlignmentStyle``) :versionbadge:`clang-format 3.7` :ref:`¶ <PointerAlignment>`; Pointer and reference alignment style. Possible values:. * ``PAS_Left`` (in configuration: ``Left``); Align pointer to the left. .. code-block:: c++. int* a;. * ``PAS_Right`` (in configuration: ``Right``); Align pointer to the right. .. code-block:: c++. int *a;. * ``PAS_Middle`` (in configuration: ``Middle``); Align pointer in the middle. .. code-block:: c++. int * a;. .. _QualifierAlignment:. **QualifierAlignment** (``QualifierAlignmentStyle``) :versionbadge:`clang-format 14` :ref:`¶ <QualifierAlignment>`; Different ways to arrange specifiers and qualifiers (e.g. const/volatile). .. warning::. Setting ``QualifierAlignment`` to something other than ``Leave``, COULD; lead to incorrect code formatting due to incorrect decisions made due to; clang-formats lack of complete semantic information.; As such extra care should be taken to review code changes made by the use; of this option. Possible values:. * ``QAS_Leave`` (in configuration: ``Leave``); Don't change specifiers/qualifiers to either Left or Right alignment; (default). .. code-block:: c++. int const a;; const int *a;. * ``QAS_Left`` (in configuration: ``Left``); Change specifiers/qualifiers to be left-aligned. .. code-block:: c++. const int a;; const int *a;. * ``QAS_Right`` (in configuration: ``Right``); Change specifiers/qu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:96351,configurat,configuration,96351,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"tyle.py script to update this file. .. raw:: html. <style type=""text/css"">; .versionbadge { background-color: #1c913d; height: 20px; display: inline-block; min-width: 120px; text-align: center; border-radius: 5px; color: #FFFFFF; font-family: ""Verdana,Geneva,DejaVu Sans,sans-serif""; }; </style>. .. role:: versionbadge. ==========================; Clang-Format Style Options; ==========================. :doc:`ClangFormatStyleOptions` describes configurable formatting style options; supported by :doc:`LibFormat` and :doc:`ClangFormat`. When using :program:`clang-format` command line utility or; ``clang::format::reformat(...)`` functions from code, one can either use one of; the predefined styles (LLVM, Google, Chromium, Mozilla, WebKit, Microsoft) or; create a custom style by configuring specific style options. Configuring Style with clang-format; ===================================. :program:`clang-format` supports two ways to provide custom style options:; directly specify style configuration in the ``-style=`` command line option or; use ``-style=file`` and put style configuration in the ``.clang-format`` or; ``_clang-format`` file in the project directory. When using ``-style=file``, :program:`clang-format` for each input file will; try to find the ``.clang-format`` file located in the closest parent directory; of the input file. When the standard input is used, the search is started from; the current directory. When using ``-style=file:<format_file_path>``, :program:`clang-format` for; each input file will use the format file located at `<format_file_path>`.; The path may be absolute or relative to the working directory. The ``.clang-format`` file uses YAML format:. .. code-block:: yaml. key1: value1; key2: value2; # A comment.; ... The configuration file can consist of several sections each having different; ``Language:`` parameter denoting the programming language this section of the; configuration is targeted at. See the description of the **Language** option; b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:1203,configurat,configuration,1203,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,2,['configurat'],['configuration']
Deployability,"t}); string(REPLACE ""complex"" ""root_std_complex.h"" header ${header}); string(REPLACE ""multi"" """" header ${header}); ROOT_STANDARD_LIBRARY_PACKAGE(${dict}Dict; NO_SOURCES NO_INSTALL_HEADERS NO_CXXMODULE; STAGE1; NODEPHEADERS ${header}; LINKDEF src/${dict}Linkdef.h; DICTIONARY_OPTIONS --noIncludePaths; DEPENDENCIES Core); target_include_directories(${dict}Dict PRIVATE ${CMAKE_SOURCE_DIR}/interpreter/cling/include/cling/cint); endforeach(). set(CLANG_RESOURCE_DIR_STEM); if (builtin_clang); set(CLANG_RESOURCE_DIR_STEM ${CMAKE_BINARY_DIR}/interpreter/llvm-project/llvm/${CMAKE_CFG_INTDIR}/lib/clang); set(CLANG_RESOURCE_DIR_VERSION ${LLVM_VERSION_MAJOR}); else (); set(CLANG_RESOURCE_DIR_STEM ${LLVM_LIBRARY_DIR}/clang); # A user can define a clang version to use, otherwise find it (but will error if more than one version is present); if (NOT DEFINED CLANG_RESOURCE_DIR_VERSION); if (NOT EXISTS ${CLANG_RESOURCE_DIR_STEM}); message(FATAL_ERROR ""${CLANG_RESOURCE_DIR_STEM} does not exist. Please install clang.""); endif(); # There is no reasonable way to get the version of clang under which is its resource directory.; # For example, lib/clang/5.0.0/include. Deduce it.; file(GLOB CHILDREN RELATIVE ${CLANG_RESOURCE_DIR_STEM} ${CLANG_RESOURCE_DIR_STEM}/*); list(LENGTH CHILDREN CHILDREN_LENGTH); if (${CHILDREN_LENGTH} GREATER 1); message(FATAL_ERROR ""Found more than one version of clang. CLANG_RESOURCE_DIR_VERSION contains: '${CHILDREN}'."" ); endif(). list(GET CHILDREN 0 CLANG_RESOURCE_DIR_VERSION); endif(); endif(). set(CLANG_RESOURCE_DIR ${CLANG_RESOURCE_DIR_STEM}/${CLANG_RESOURCE_DIR_VERSION}/include). #---Deal with clang resource here----------------------------------------------; install(DIRECTORY ${CMAKE_BINARY_DIR}/etc/cling/lib/clang/${CLANG_RESOURCE_DIR_VERSION}/include/; DESTINATION ${CMAKE_INSTALL_SYSCONFDIR}/cling/lib/clang/${CLANG_RESOURCE_DIR_VERSION}/include USE_SOURCE_PERMISSIONS). #---Install a bunch of files to /etc/cling------------------------------------; set(clin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/clingutils/CMakeLists.txt:3028,install,install,3028,core/clingutils/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/clingutils/CMakeLists.txt,1,['install'],['install']
Deployability,"u will also need the `CMake <http://www.cmake.org/>`_ build system since it; generates the project files you will use to build with. CMake is bundled with; Visual Studio 2019 so separate installation is not required. If you do install; CMake separately, Visual Studio 2022 will require CMake Version 3.21 or later. If you would like to run the LLVM tests you will need `Python; <http://www.python.org/>`_. Version 3.6 and newer are known to work. You can; install Python with Visual Studio 2019, from the Microsoft store or from; the `Python web site <http://www.python.org/>`_. We recommend the latter since it; allows you to adjust installation options. You will need `Git for Windows <https://git-scm.com/>`_ with bash tools, too.; Git for Windows is also bundled with Visual Studio 2019. Getting Started; ===============; Here's the short story for getting up and running quickly with LLVM.; These instruction were tested with Visual Studio 2019 and Python 3.9.6:. 1. Download and install `Visual Studio <https://visualstudio.microsoft.com/>`_.; 2. In the Visual Studio installer, Workloads tab, select the; **Desktop development with C++** workload. Under Individual components tab,; select **Git for Windows**.; 3. Complete the Visual Studio installation.; 4. Download and install the latest `Python 3 release <http://www.python.org/>`_.; 5. In the first install screen, select both **Install launcher for all users**; and **Add Python to the PATH**. This will allow installing psutil for all; users for the regression tests and make Python available from the command; line.; 6. In the second install screen, select (again) **Install for all users** and; if you want to develop `lldb <https://lldb.llvm.org/>`_, selecting; **Download debug binaries** is useful.; 7. Complete the Python installation.; 8. Run a ""Developer Command Prompt for VS 2019"" **as administrator**. This command; prompt provides correct path and environment variables to Visual Studio and; the installed tools.; 9. In the t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst:2907,install,install,2907,interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,1,['install'],['install']
Deployability,"ubproject_branches[@]}. for p in ${my_projects[@]}; do; subproject_branch=${p}/local/monorepo/${my_local_branch}; git -C my-monorepo branch -d ${subproject_branch}; done. # Create local branches for upstream monorepo branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/upstream/monorepo); do; upstream_branch=${ref#refs/remotes/upstream/monorepo/}; git -C my-monorepo branch upstream/${upstream_branch} ${ref}; done. The above gets you to a state like the following::. U1 - U2 - U3 <- upstream/main; \ \ \; \ \ - Llld1 - Llld2 -; \ \ \; \ - Lclang1 - Lclang2-- Lmerge <- local/octopus/main; \ /; - Lllvm1 - Lllvm2-----. Each branched component has its branch rewritten on top of the; monorepo and all components are unified by a giant octopus merge. If additional active local branches need to be preserved, the above; operations following the assignment to ``my_local_branch`` should be; done for each branch. Ref paths will need to be updated to map the; local branch to the corresponding upstream branch. If local branches; have no corresponding upstream branch, then the creation of; ``local/octopus/<local branch>`` need not use ``git-merge-base`` to; pinpoint its root commit; it may simply be branched from the; appropriate component branch (say, ``llvm/local_release_X``). Zipping local history; ---------------------. The octopus merge is suboptimal for many cases, because walking back; through the history of one component leaves the other components fixed; at a history that likely makes things unbuildable. Some downstream users track the order commits were made to subprojects; with some kind of ""umbrella"" project that imports the project git; mirrors as submodules, similar to the multirepo umbrella proposed; above. Such an umbrella repository looks something like this::. UM1 ---- UM2 -- UM3 -- UM4 ---- UM5 ---- UM6 ---- UM7 ---- UM8 <- main; | | | | | | |; Lllvm1 Llld1 Lclang1 Lclang2 Lllvm2 Llld2 Lmyproj1. The vertical bars represent su",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:23544,update,updated,23544,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['update'],['updated']
Deployability,"uction; ------------. Thanks to CernVM and PROOF on Demand, it is possible to deploy a ready; to use Virtual Analysis Facility on your cloud (either public, private; or even your desktop computer). On the server side, ""configuring"" the Virtual Analysis Facility is; simply a matter of starting a certain number of CernVM virtual machines; that will become part of your PROOF cluster. CernVM uses; contextualization to specialize each virtual machine to be either a head; node or a worker node. The Virtual Analysis Facility comes with many preconfigured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Anal",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:1122,deploy,deployment,1122,proof/doc/confman/DeployVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md,1,['deploy'],['deployment']
Deployability,"uctions for adding new builder to LLVM buildbot master. :doc:`Packaging`; Advice on packaging LLVM into a distribution. :doc:`Release notes for the current release <ReleaseNotes>`; This describes new features, known bugs, and other limitations. .. _lists-forums:. Forums & Mailing Lists; ----------------------. If you can't find what you need in these docs, try consulting the; Discourse forums. There are also commit mailing lists for all commits to the LLVM Project.; The :doc:`CodeOfConduct` applies to all these forums and mailing lists. `LLVM Discourse`__; The forums for all things LLVM and related sub-projects. There are categories and subcategories for a wide variety of areas within LLVM. You can also view tags or search for a specific topic. .. __: https://discourse.llvm.org/. `Commits Archive (llvm-commits)`__; This list contains all commit messages that are made when LLVM developers; commit code changes to the repository. It also serves as a forum for; patch review (i.e. send patches here). It is useful for those who want to; stay on the bleeding edge of LLVM development. This list is very high; volume. .. __: http://lists.llvm.org/pipermail/llvm-commits/. `Bugs & Patches Archive (llvm-bugs)`__; This list gets emailed every time a bug is opened and closed. It is; higher volume than the LLVM-dev list. .. __: http://lists.llvm.org/pipermail/llvm-bugs/. `LLVM Announcements`__; If you just want project wide announcements such as releases, developers meetings, or blog posts, then you should check out the Announcement category on LLVM Discourse. .. __: https://discourse.llvm.org/c/announce/46. .. _online-sync-ups:. Online Sync-Ups; ---------------. A number of regular calls are organized on specific topics. It should be; expected that the range of topics will change over time. At the time of; writing, the following sync-ups are organized.; The :doc:`CodeOfConduct` applies to all online sync-ups. If you'd like to organize a new sync-up, please add the info in the tabl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingInvolved.rst:3115,patch,patches,3115,interpreter/llvm-project/llvm/docs/GettingInvolved.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingInvolved.rst,1,['patch'],['patches']
Deployability,"uda-resource-headers; COMPONENT cuda-resource-headers); add_llvm_install_targets(install-hexagon-resource-headers; DEPENDS hexagon-resource-headers; COMPONENT hexagon-resource-headers); add_llvm_install_targets(install-hip-resource-headers; DEPENDS hip-resource-headers; COMPONENT hip-resource-headers); add_llvm_install_targets(install-mips-resource-headers; DEPENDS mips-resource-headers; COMPONENT mips-resource-headers); add_llvm_install_targets(install-ppc-resource-headers; DEPENDS ppc-resource-headers; COMPONENT ppc-resource-headers); add_llvm_install_targets(install-ppc-htm-resource-headers; DEPENDS ppc-htm-resource-headers; COMPONENT ppc-htm-resource-headers); add_llvm_install_targets(install-riscv-resource-headers; DEPENDS riscv-resource-headers; COMPONENT riscv-resource-headers); add_llvm_install_targets(install-systemz-resource-headers; DEPENDS systemz-resource-headers; COMPONENT systemz-resource-headers); add_llvm_install_targets(install-ve-resource-headers; DEPENDS ve-resource-headers; COMPONENT ve-resource-headers); add_llvm_install_targets(install-x86-resource-headers; DEPENDS x86-resource-headers; COMPONENT x86-resource-headers); add_llvm_install_targets(install-webassembly-resource-headers; DEPENDS webassembly-resource-headers; COMPONENT webassembly-resource-headers). add_llvm_install_targets(install-hlsl-resource-headers; DEPENDS hlsl-resource-headers; COMPONENT hlsl-resource-headers); add_llvm_install_targets(install-opencl-resource-headers; DEPENDS opencl-resource-headers; COMPONENT opencl-resource-headers); add_llvm_install_targets(install-openmp-resource-headers; DEPENDS openmp-resource-headers; COMPONENT openmp-resource-headers); add_llvm_install_targets(install-windows-resource-headers; DEPENDS windows-resource-headers; COMPONENT windows-resource-headers); add_llvm_install_targets(install-utility-resource-headers; DEPENDS utility-resource-headers; COMPONENT utility-resource-headers); endif(). source_group(""Clang Runtime Headers"" FILES ${files}); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt:18648,install,install-hlsl-resource-headers,18648,interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/Headers/CMakeLists.txt,5,['install'],"['install-hlsl-resource-headers', 'install-opencl-resource-headers', 'install-openmp-resource-headers', 'install-utility-resource-headers', 'install-windows-resource-headers']"
Deployability,"ue, point the ``TMP`` and ``TEMP`` envars to an existing; directory with a short name before the build:; For example::. > set TMP=C:\TMP; > set TEMP=C:\TMP. The first package to build is ``cppyy-cling``.; It may take a long time, especially on a laptop (Mac ARM being a notable; exception), since Cling comes with a builtin version of LLVM/Clang.; Consider therefore for a moment your reasons for building from source: there; being no pre-built wheel for the platform that you're interested in or simply; needing the latest version from the repository; or perhaps you are planning; to develop/modify the sources. If the former, clone the repository, check out a specific tagged release as; needed, then run the following steps to add Cling and build a wheel.; Once built, install the wheel as appropriate::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ python setup.py bdist_wheel; $ python -m pip install dist/cppyy_cling-* --upgrade. .. note::; ``cppyy-cling`` wheels do not depend on the Python interpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:3065,install,install,3065,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,2,"['install', 'upgrade']","['install', 'upgrade']"
Deployability,"uential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:231045,release,release,231045,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,4,['release'],['release']
Deployability,"uests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The idea behind such server is to provide direct access to the data from a running ROOT application. Any object can be streamed when requested and delivered to the browser. ##### Starting HTTP server. To start http server, at any time create instance; of the **`THttpServer`** class like:. ``` {.cpp}; serv = new THttpServer(""http:8080"");; ```. This will start civetweb-based http server on port 8080.; Then, one should be able to open address ""http://localhost:8080""; in any modern browser and browse objects created in application. By default, the server can access files, canvases and histograms via gROOT. All such objects can be displayed with JSRootIO graphics. At any time one could register other objects with the command:. ``` {.cpp}; TGraph* gr = new TGraph(10);; gr->SetName(""gr1"");; serv->Register(""graphs/subfolder"", gr);; ```. If the object content is changing in the application, like for example histograms being continuously filled, one could enable the monitoring flag in the browser, then the object view will be regularly updated. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:3515,continuous,continuously,3515,net/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md,2,"['continuous', 'update']","['continuously', 'updated']"
Deployability,"uild LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6352,install,installed,6352,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['install'],['installed']
Deployability,"uilding, representing and drawing geometrical objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities. Binaries for all supported platforms are available at:. http://root.cern.ch/root/Version521.html; Versions for AFS have also been updated. See the list of supported; platforms:; http://root.cern.ch/Welcome.html. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Kevin Belasco, N/A, Princeton University for MCMC, ; Bertrand Bellenot, CERN/SFT,; Rene Brun, CERN/SFT,; Philippe Canal, FNAL,; Or Cohen, CERN & Weizmann, TMVA; Olivier Couet, CERN/SFT,; Kyle Cranmer, NYU/Atlas, RooStats; Dominik Dannheim, MPI-Munich/Atlas, TMVA ; Valeri Fine, BNL/STAR,; Gerri Ganis, CERN/SFT,; Andrei Gheata, CERN/Alice,; Mihaela Gheata, CERN/Alice,; David Gonzalez Maline, CERN/SFT, ; Roberto Gracia Del Ba�o, Universidad de Valencia, recorder, ; Andreas Hoecker, CERN/Atlas, TMVA ; Jan Iwaszkiewicz, CERN, ; Lukasz Janyst, CERN/IT, ; Anna Kreshuk, GSI, ; Wim Lavrijsen, LBNL, PyRoot; Alfio Lazzaro, Milano/AtlasMinuit; George Lewis, New York University/Atlas for SPlot, ; Josef Leydold, TU Vienna, Unuran; Sergei Linev, GSI,; Johan Lundberg, CERN/Atlas, class TRolke; Anar ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v524/index.html:1469,update,updated,1469,doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v524/index.html,1,['update'],['updated']
Deployability,"uirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:23833,deploy,deploying,23833,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['deploy'],['deploying']
Deployability,"uitable for plotting with; a graphics routine or by hand (using MnPlot, see [api:plot]). The points; are given in counter-clockwise order around the contour. Only one; contour is calculated per command, and the level is; $\displaystyle F_{\mathrm{min}} + \mbox{up}$. where $\mbox{up}$; is the return value of FCNBase::up() specified by the user (usually 1.0; by default). The number of points to be calculated is chosen by the user; (default is 20). As a by-product, $\mbox{CONTOURS}$ provides the; $\mbox{MINOS}$ errors of the two parameters in question, since these; are just the extreme points of the contour (use the; MnContours::contour(...) method in order to get the points of the; contour and the ones of the $\mbox{MINOS}$ errors).; MnContours::operator() returns a; std::vector$<$std::pair$<$double,double$> >$ of (x,y) points. Using; MnPlot::operator() will generate a text graphics plot in the terminal. # M installation #. ## M releases ##. To follow the current release process the user is referred to the M; homepage @bib-C++MINUIT. M was re–implemented in from 2002–2004, but the functionality is largely; compatible with the one of the version. The usage is different in the; sense that the re–write from to was done by its signification and not; literally (with minor exceptions). Applications such as; $\mbox{MIGRAD}$ have a corresponding class MnMigrad, M ""commands""; became classes or methods of classes according to their purpose. Users; familiar with the version of M , who have not yet used releases from the; version, should however read this manual, in order to adapt to the; changes as well as to discover the new features and easier ways of using; old features. ## Install M using autoconf/make ##. For each release of M a tar.gz file is provided for downloading from the; M homepage @bib-C++MINUIT. For non-UNIX platforms please refer to the M; homepage. The necessary steps to follow are:. 1. download the tar.gz by clicking on it from the release page. 2. unzip it:. $ ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:21385,release,release,21385,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['release'],['release']
Deployability,"uld be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independent review. Reviewers may also accept a patch; conditioned on the author providing a follow-up patch addressing some; particular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicable, it is polite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in a timely fashion, please communicate that fact in; the review. Who Can/Should Review Code?; ===========================. Non-Experts Should Review Code; ------------------------------. You do not need to be an expert in some area of the code base to review patches;; it's fine to ask questions about what some piece of code is doing. If it's not; clear to you what is going on, you're unlikely to be the only one. Please; remember that it is not in the long-term best interest of the community to have; components that are only understood well by a small number of people. Extra; comments and/or test cases can often help (and asking for comments in the test; cases is fine as well). Moreover, authors are encouraged to interpret questions as a reason to reexamine; the readability of the code in question. Structural changes, or further; comments, may be appropriate. If you're new to the LLVM community, you might also find this presentation helpful:; .. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:9615,patch,patch,9615,interpreter/llvm-project/llvm/docs/CodeReview.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst,2,['patch'],['patch']
Deployability,"ule will not be compiled until they are first; called. LLLazyJIT aims to provide a replacement of LLVM's original (pre-MCJIT); JIT API. LLJIT and LLLazyJIT instances can be created using their respective builder; classes: LLJITBuilder and LLazyJITBuilder. For example, assuming you have a; module ``M`` loaded on a ThreadSafeContext ``Ctx``:. .. code-block:: c++. // Try to detect the host arch and construct an LLJIT instance.; auto JIT = LLJITBuilder().create();. // If we could not construct an instance, return an error.; if (!JIT); return JIT.takeError();. // Add the module.; if (auto Err = JIT->addIRModule(TheadSafeModule(std::move(M), Ctx))); return Err;. // Look up the JIT'd code entry point.; auto EntrySym = JIT->lookup(""entry"");; if (!EntrySym); return EntrySym.takeError();. // Cast the entry point address to a function pointer.; auto *Entry = EntrySym.getAddress().toPtr<void(*)()>();. // Call into JIT'd code.; Entry();. The builder classes provide a number of configuration options that can be; specified before the JIT instance is constructed. For example:. .. code-block:: c++. // Build an LLLazyJIT instance that uses four worker threads for compilation,; // and jumps to a specific error handler (rather than null) on lazy compile; // failures. void handleLazyCompileFailure() {; // JIT'd code will jump here if lazy compilation fails, giving us an; // opportunity to exit or throw an exception into JIT'd code.; throw JITFailed();; }. auto JIT = LLLazyJITBuilder(); .setNumCompileThreads(4); .setLazyCompileFailureAddr(; ExecutorAddr::fromPtr(&handleLazyCompileFailure)); .create();. // ... For users wanting to get started with LLJIT a minimal example program can be; found at ``llvm/examples/HowToUseLLJIT``. Design Overview; ===============. ORC's JIT program model aims to emulate the linking and symbol resolution; rules used by the static and dynamic linkers. This allows ORC to JIT; arbitrary LLVM IR, including IR produced by an ordinary static compiler (e.g.; clang) t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:5393,configurat,configuration,5393,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['configurat'],['configuration']
Deployability,"ule.h <https://github.com/llvm/llvm-project/blob/main/clang/include/clang/Tooling/Transformer/RewriteRule.h>`_. Using a RewriteRule as a clang-tidy check; -----------------------------------------. Transformer supports executing a rewrite rule as a; `clang-tidy <https://clang.llvm.org/extra/clang-tidy/>`_ check, with the class; ``clang::tidy::utils::TransformerClangTidyCheck``. It is designed to require; minimal code in the definition. For example, given a rule; ``MyCheckAsRewriteRule``, one can define a tidy check as follows:. .. code-block:: c++. class MyCheck : public TransformerClangTidyCheck {; public:; MyCheck(StringRef Name, ClangTidyContext *Context); 	 : TransformerClangTidyCheck(MyCheckAsRewriteRule, Name, Context) {}; };. ``TransformerClangTidyCheck`` implements the virtual ``registerMatchers`` and; ``check`` methods based on your rule specification, so you don't need to implement; them yourself. If the rule needs to be configured based on the language options; and/or the clang-tidy configuration, it can be expressed as a function taking; these as parameters and (optionally) returning a ``RewriteRule``. This would be; useful, for example, for our method-renaming rule, which is parameterized by the; original name and the target. For details, see; `clang-tools-extra/clang-tidy/utils/TransformerClangTidyCheck.h <https://github.com/llvm/llvm-project/blob/main/clang-tools-extra/clang-tidy/utils/TransformerClangTidyCheck.h>`_. Related Reading; ---------------. A good place to start understanding the clang AST and its matchers is with the; introductions on clang's site:. * :doc:`Introduction to the Clang AST <IntroductionToTheClangAST>`; * :doc:`Matching the Clang AST <LibASTMatchers>`; * `AST Matcher Reference <https://clang.llvm.org/docs/LibASTMatchersReference.html>`_. .. rubric:: Footnotes. .. [#f1] Technically, it binds it to the string ""str"", to which our; variable ``s`` is bound. But, the choice of that id string is; irrelevant, so elide the difference.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangTransformerTutorial.rst:17196,configurat,configuration,17196,interpreter/llvm-project/clang/docs/ClangTransformerTutorial.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangTransformerTutorial.rst,1,['configurat'],['configuration']
Deployability,"ules. Now the calls to initialize; functions from imported module units can be omitted if the initialize; function is known to be empty.; (`#56794 <https://github.com/llvm/llvm-project/issues/56794>`_). - Clang now allow to export declarations within linkage-specification.; (`#71347 <https://github.com/llvm/llvm-project/issues/71347>`_). Moved checkers; ^^^^^^^^^^^^^^. - Move checker ``alpha.unix.Errno`` out of the ``alpha`` package; to ``unix.Errno``.; `Documentation <https://clang.llvm.org/docs/analyzer/checkers.html#unix-errno-c>`__. - Move checker ``alpha.unix.StdCLibraryFunctions`` out of the ``alpha`` package; to ``unix.StdCLibraryFunctions``.; `Documentation <https://clang.llvm.org/docs/analyzer/checkers.html#unix-stdclibraryfunctions-c>`__. - Move checker ``alpha.security.cert.env.InvalidPtr`` out of the ``alpha``; package to ``security.cert.env.InvalidPtr``.; `Documentation <https://clang.llvm.org/docs/analyzer/checkers.html#security-cert-env-invalidptr>`__. - Move checker ``alpha.cplusplus.EnumCastOutOfRange`` out of the ``alpha``; package to ``optin.core.EnumCastOutOfRange``.; `Documentation <https://clang.llvm.org/docs/analyzer/checkers.html#optin-core-enumcastoutofrange-c-c>`__. .. _release-notes-sanitizers:. Sanitizers; ----------. - ``-fsanitize=signed-integer-overflow`` now instruments ``__builtin_abs`` and; ``abs`` builtins. Python Binding Changes; ----------------------. Additional Information; ======================. A wide variety of additional information is available on the `Clang web; page <https://clang.llvm.org/>`_. The web page contains versions of the; API documentation which are up-to-date with the Git version of; the source code. You can access versions of these documents specific to; this release by going into the ""``clang/docs/``"" directory in the Clang; tree. If you have any questions or comments about Clang, please feel free to; contact us on the `Discourse forums (Clang Frontend category); <https://discourse.llvm.org/c/clang/6>`_.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:77940,release,release,77940,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['release'],['release']
Deployability,"umber of shadow bytes following the; intrinsic. The variable number of operands that follow are the ``live; values`` for which locations will be recorded in the stack map. To use this intrinsic as a bare-bones stack map, with no code patching; support, the number of shadow bytes can be set to zero. Semantics:; """""""""""""""""""". The stack map intrinsic generates no code in place, unless nops are; needed to cover its shadow (see below). However, its offset from; function entry is stored in the stack map. This is the relative; instruction address immediately following the instructions that; precede the stack map. The stack map ID allows a runtime to locate the desired stack map; record. LLVM passes this ID through directly to the stack map; record without checking uniqueness. LLVM guarantees a shadow of instructions following the stack map's; instruction offset during which neither the end of the basic block nor; another call to ``llvm.experimental.stackmap`` or; ``llvm.experimental.patchpoint`` may occur. This allows the runtime to; patch the code at this point in response to an event triggered from; outside the code. The code for instructions following the stack map; may be emitted in the stack map's shadow, and these instructions may; be overwritten by destructive patching. Without shadow bytes, this; destructive patching could overwrite program text or data outside the; current function. We disallow overlapping stack map shadows so that; the runtime does not need to consider this corner case. For example, a stack map with 8 byte shadow:. .. code-block:: llvm. call void @runtime(); call void (i64, i32, ...) @llvm.experimental.stackmap(i64 77, i32 8,; ptr %ptr); %val = load i64, ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:5879,patch,patchpoint,5879,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['patch'],['patchpoint']
Deployability,"uments.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is 0 then the kernarg; memory size is; unspecified.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is not 0 then the value; specifies the kernarg; memory size in bytes. It; is recommended to provide; a value as it may be used; by CP to optimize making; the kernarg memory; visible to the kernel; code. 127:96 4 bytes Reserved, must be 0.; 191:128 8 bytes KERNEL_CODE_ENTRY_BYTE_OFFSET Byte offset (possibly; negative) from base; address of kernel; descriptor to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC1``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`.; 447:416 4 bytes COMPUTE_PGM_RSRC2 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC2``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table`.; 458:448 7 bits *See separate bits below.* Enable the setup of the; SGPR user data registers; (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). The total number of SGPR; user data registers; requested must not exceed; 16 and match value in; ``compute_pgm_rsrc2.user_sgpr.user_sgp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:160514,configurat,configuration,160514,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['configurat'],['configuration']
Deployability,"unctionally equivalent to the one shown below.; Placing on Objective-C methods: With respect to Objective-C methods.,; this attribute is identical in its behavior and usage to 'ns_returns_retained'; except for the distinction of returning a Core Foundation object instead of a; Cocoa object. This distinction is important for the following reason:; as Core Foundation is a C API,; the analyzer cannot always tell that a pointer return value refers to a; Core Foundation object.; In contrast, it is; trivial for the analyzer to recognize if a pointer refers to a Cocoa object; (given the Objective-C type system). Placing on C functions: When placing the attribute; 'cf_returns_retained' on the declarations of C functions, the analyzer; interprets the function as:. Returning a Core Foundation Object; Treating the function as if it its name; contained the keywords ""create"" or ""copy"". This means the; returned object as a +1 retain count that must be released by the caller, either; by sending a release message (via toll-free bridging to an Objective-C; object pointer), or calling CFRelease or a similar function. Example. $ cat test.m; $ cat test.m; #import <Cocoa/Cocoa.h>. #ifndef __has_feature // Optional.; #define __has_feature(x) 0 // Compatibility with non-clang compilers.; #endif. #ifndef CF_RETURNS_RETAINED; #if __has_feature(attribute_cf_returns_retained); #define CF_RETURNS_RETAINED __attribute__((cf_returns_retained)); #else; #define CF_RETURNS_RETAINED; #endif; #endif. @interface MyClass : NSObject {}; - (NSDate*) returnsCFRetained CF_RETURNS_RETAINED;; - (NSDate*) alsoReturnsRetained;; - (NSDate*) returnsNSRetained NS_RETURNS_RETAINED;; @end. CF_RETURNS_RETAINED; CFDateRef returnsRetainedCFDate() {; return CFDateCreate(0, CFAbsoluteTimeGetCurrent());; }. @implementation MyClass; - (NSDate*) returnsCFRetained {; return (NSDate*) returnsRetainedCFDate(); // No leak.; }. - (NSDate*) alsoReturnsRetained {; return (NSDate*) returnsRetainedCFDate(); // Always report a leak.;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html:7338,release,released,7338,interpreter/llvm-project/clang/www/analyzer/annotations.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html,2,['release'],"['release', 'released']"
Deployability,"under which you'll find object files for each source. For example:. .. code-block:: console. % cd llvm_build_dir; % find lib/Support/ -name APFloat*; lib/Support/CMakeFiles/LLVMSupport.dir/APFloat.cpp.o. Optional Configuration Items; ----------------------------. If you're running on a Linux system that supports the `binfmt_misc; <http://en.wikipedia.org/wiki/binfmt_misc>`_; module, and you have root access on the system, you can set your system up to; execute LLVM bitcode files directly. To do this, use commands like this (the; first command may not be required if you are already using the module):. .. code-block:: console. % mount -t binfmt_misc none /proc/sys/fs/binfmt_misc; % echo ':llvm:M::BC::/path/to/lli:' > /proc/sys/fs/binfmt_misc/register; % chmod u+x hello.bc (if needed); % ./hello.bc. This allows you to execute LLVM bitcode files directly. On Debian, you can also; use this command instead of the 'echo' command above:. .. code-block:: console. % sudo update-binfmts --install llvm /path/to/lli --magic 'BC'. .. _Program Layout:; .. _general layout:. Directory Layout; ================. One useful source of information about the LLVM source base is the LLVM `doxygen; <http://www.doxygen.org/>`_ documentation available at; `<https://llvm.org/doxygen/>`_. The following is a brief introduction to code; layout:. ``llvm/cmake``; --------------; Generates system build files. ``llvm/cmake/modules``; Build configuration for llvm user defined options. Checks compiler version and; linker flags. ``llvm/cmake/platforms``; Toolchain configuration for Android NDK, iOS systems and non-Windows hosts to; target MSVC. ``llvm/examples``; -----------------. - Some simple examples showing how to use LLVM as a compiler for a custom; language - including lowering, optimization, and code generation. - Kaleidoscope Tutorial: Kaleidoscope language tutorial run through the; implementation of a nice little compiler for a non-trivial language; including a hand-written lexer, parser, AST,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:33757,update,update-binfmts,33757,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,2,"['install', 'update']","['install', 'update-binfmts']"
Deployability,"unk is in decent shape by; examining nightly tester and buildbot results. #. Bump the version in trunk to N.0.0git and tag the commit with llvmorg-N-init.; If ``X`` is the version to be released, then ``N`` is ``X + 1``. ::. $ git tag -sa llvmorg-N-init. #. Clear the release notes in trunk. #. Create the release branch from the last known good revision from before the; version bump. The branch's name is release/X.x where ``X`` is the major version; number and ``x`` is just the letter ``x``. #. On the newly-created release branch, immediately bump the version; to X.1.0git (where ``X`` is the major version of the branch.). #. All tags and branches need to be created in both the llvm/llvm-project and; llvm/llvm-test-suite repos. Update LLVM Version; ^^^^^^^^^^^^^^^^^^^. After creating the LLVM release branch, update the release branches'; version with the script in ``llvm/utils/release/bump-version.py``. Tagging the LLVM Release Candidates; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Tag release candidates:. ::. $ git tag -sa llvmorg-X.Y.Z-rcN. The Release Manager must supply pre-packaged source tarballs for users. This can; be done with the export.sh script in utils/release. Tarballs, release binaries, or any other release artifacts must be uploaded to; GitHub. This can be done using the github-upload-release.py script in utils/release. ::. $ github-upload-release.py upload --token <github-token> --release X.Y.Z-rcN --files <release_files>. ::. $ ./export.sh -release X.Y.Z -rc $RC. This will generate source tarballs for each LLVM project being validated, which; can be uploaded to github for further testing. Build The Binary Distribution; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Creating the binary distribution requires following the instructions; :doc:`here <ReleaseProcess>`. That process will perform both Release+Asserts and Release builds but only; pack the Release build for upload. You should use the Release+Asserts sysroot,; normally under ``final/Phase3/Release+Asserts/llvmCore-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:4849,release,release,4849,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['release']
Deployability,"unsafe_unretained``, an externally-retained variable still; behaves as a strong variable outside of initialization and destruction. For; instance, when an externally-retained variable is captured in a block the value; of the variable is retained and released on block capture and destruction. It; also affects C++ features such as lambda capture, ``decltype``, and template; argument deduction. Implicitly, the implementation assumes that the :ref:`self parameter in a; non-init method <arc.misc.self>` and the :ref:`variable in a for-in loop; <arc.misc.enumeration>` are externally-retained. Externally-retained semantics can also be opted into with the; ``objc_externally_retained`` attribute. This attribute can apply to strong local; variables, functions, methods, or blocks:. .. code-block:: objc. @class WobbleAmount;. @interface Widget : NSObject; -(void)wobble:(WobbleAmount *)amount;; @end. @implementation Widget. -(void)wobble:(WobbleAmount *)amount; __attribute__((objc_externally_retained)) {; // 'amount' and 'alias' aren't retained on entry, nor released on exit.; __attribute__((objc_externally_retained)) WobbleAmount *alias = amount;; }; @end. Annotating a function with this attribute makes every parameter with strong; retainable object pointer type externally-retained, unless the variable was; explicitly qualified with ``__strong``. For instance, ``first_param`` is; externally-retained (and therefore ``const``) below, but not ``second_param``:. .. code-block:: objc. __attribute__((objc_externally_retained)); void f(NSArray *first_param, __strong NSArray *second_param) {; // ...; }. You can test if your compiler has support for ``objc_externally_retained`` with; ``__has_attribute``:. .. code-block:: objc. #if __has_attribute(objc_externally_retained); // Use externally retained...; #endif. .. _arc.misc.self:. ``self``; --------. The ``self`` parameter variable of an non-init Objective-C method is considered; :ref:`externally-retained <arc.misc.externally_retained>` b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:93390,release,released,93390,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['released']
Deployability,"unt"" integer Number of VGPRs used by the shader.; "".sgpr_count"" integer Number of SGPRs used by the shader.; "".stack_frame_size_in_bytes"" integer Amount of stack size used by the shader.; "".shader_subtype"" string Shader subtype/kind. Values include:. - ""Unknown"". ============================= ============== =================================================================. .. .. table:: AMDPAL Code Object Register Map; :name: amdgpu-amdpal-code-object-register-map-table. ========================== ============== ====================================================================; 32-bit Integer Key Value Type Description; ========================== ============== ====================================================================; ``reg offset`` 32-bit integer ``reg offset`` is the dword offset into the GFXIP register space of; a GRBM register (i.e., driver accessible GPU register number, not; shader GPR register number). The driver is required to program each; specified register to the corresponding specified value when; executing this pipeline. Typically, the ``reg offsets`` are the; ``uint16_t`` offsets to each register as defined by the hardware; chip headers. The register is set to the provided value. However, a; ``reg offset`` that specifies a user data register (e.g.,; COMPUTE_USER_DATA_0) needs special treatment. See; :ref:`amdgpu-amdpal-code-object-user-data-section` section for more; information.; ========================== ============== ====================================================================. .. _amdgpu-amdpal-code-object-user-data-section:. User Data; +++++++++. Each hardware stage has a set of 32-bit physical SPI *user data registers*; (either 16 or 32 based on graphics IP and the stage) which can be; written from a command buffer and then loaded into SGPRs when waves are; launched via a subsequent dispatch or draw operation. This is the way; most arguments are passed from the application/runtime to a hardware; shader. PAL abstracts this ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:412804,pipeline,pipeline,412804,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['pipeline'],['pipeline']
Deployability,"uplicate`` doesn't; have the same safe semantics of CFG as ``convergent`` and can cause changes in; CFG that modify semantics of the original program. ``noduplicate`` is kept for backwards compatibility only and it considered to be; deprecated for future uses. .. _cxx_for_opencl:. C++ for OpenCL; --------------. Starting from clang 9 kernel code can contain C++17 features: classes, templates,; function overloading, type deduction, etc. Please note that this is not an; implementation of `OpenCL C++; <https://www.khronos.org/registry/OpenCL/specs/2.2/pdf/OpenCL_Cxx.pdf>`_ and; there is no plan to support it in clang in any new releases in the near future. Clang currently supports C++ for OpenCL 1.0 and 2021.; For detailed information about this language refer to the C++ for OpenCL; Programming Language Documentation available; in `the latest build; <https://www.khronos.org/opencl/assets/CXX_for_OpenCL.html>`_; or in `the official release; <https://github.com/KhronosGroup/OpenCL-Docs/releases/tag/cxxforopencl-docrev2021.12>`_. To enable the C++ for OpenCL mode, pass one of following command line options when; compiling ``.clcpp`` file:. - C++ for OpenCL 1.0: ``-cl-std=clc++``, ``-cl-std=CLC++``, ``-cl-std=clc++1.0``,; ``-cl-std=CLC++1.0``, ``-std=clc++``, ``-std=CLC++``, ``-std=clc++1.0`` or; ``-std=CLC++1.0``. - C++ for OpenCL 2021: ``-cl-std=clc++2021``, ``-cl-std=CLC++2021``,; ``-std=clc++2021``, ``-std=CLC++2021``. Example of use:; .. code-block:: c++. template<class T> T add( T x, T y ); {; return x + y;; }. __kernel void test( __global float* a, __global float* b); {; auto index = get_global_id(0);; a[index] = add(b[index], b[index+1]);; }. .. code-block:: console. clang -cl-std=clc++1.0 test.clcpp; clang -cl-std=clc++ -c --target=spirv64 test.cl. By default, files with ``.clcpp`` extension are compiled with the C++ for; OpenCL 1.0 mode. .. code-block:: console. clang test.clcpp. For backward compatibility files with ``.cl`` extensions can also be compiled; in C+",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:152919,release,releases,152919,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['release'],['releases']
Deployability,"upply a positive whole number that; selects the instance of the given name, with ""1"" indicating the first; instance. If :option:`N` is not specified the first member of that name will; be selected. If *count* is not supplied, the operation fails.*count* cannot be. .. option:: o. When extracting files, use the modification times of any *files* as they; appear in the ``archive``. By default *files* extracted from the archive; use the time of extraction. .. option:: O. Display member offsets inside the archive. .. option:: T. Alias for ``--thin``. In many ar implementations ``T`` has a different; meaning, as specified by X/Open System interface. .. option:: v. When printing *files* or the ``archive`` table of contents, this modifier; instructs :program:`llvm-ar` to include additional information in the output. Modifiers (generic); ~~~~~~~~~~~~~~~~~~~. The modifiers below may be applied to any operation. .. option:: c. For the :option:`r` (replace)and :option:`q` (quick update) operations,; :program:`llvm-ar` will always create the archive if it doesn't exist.; Normally, :program:`llvm-ar` will print a warning message indicating that the; ``archive`` is being created. Using this modifier turns off; that warning. .. option:: D. Use zero for timestamps and UIDs/GIDs. This is set by default. .. option:: P. Use full paths when matching member names rather than just the file name.; This can be useful when manipulating an ``archive`` generated by another; archiver, as some allow paths as member names. This is the default behavior; for thin archives. .. option:: s. This modifier requests that an archive index (or symbol table) be added to the; ``archive``, as if using ranlib. The symbol table will contain all the; externally visible functions and global variables defined by all the bitcode; files in the archive. By default :program:`llvm-ar` generates symbol tables in; archives. This can also be used as an operation. .. option:: S. This modifier is the opposite of the :option:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-ar.rst:8309,update,update,8309,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-ar.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-ar.rst,1,['update'],['update']
Deployability,"upport C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STDCXX`` to control the C++ standard version; ``MAKE`` to; change the ``make`` command, ``MAKE_NPROCS`` to control the maximum number of; parallel jobs allowed, and ``VERBOSE=1`` to see full build/compile commands.; Example (using ``--verbose`` to see ``pip`` progress)::. $ STDCXX=17 MAKE_NPROCS=32 pip install --verbose cppyy --no-binary=cppyy-cling. Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled).; Once built, however, the wheel of ``cppyy-cling`` is reused by pip for all; versions of CPython and for PyPy, thus the long compilation is needed only; once for all different versions of Python on the same machine. See the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:5415,release,release,5415,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,1,['release'],['release']
Deployability,"ur behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to require a moderator to approve the email, so do not be concerned if a; commit does not immediately appear in the archives. If you have recently been granted commit access, these policies apply:. #. You are granted *commit-after-approval* to all parts of LLVM. For; information on how to get approval for a patch, please see :doc:`CodeReview`.; When approved, you may commit it yourself. #. You are allowed to commit patches without approval which you think are; obvious. This is clearly a subjective decision --- we simply expect you to; use good judgement. Examples include: fixing build breakage, reverting; obviously broken patches, documentation/comment changes, any other minor; changes. Avoid committing formatting- or whitespace-only changes outside of; code you plan to make subsequent changes to. Also, try to separate; formatting or whitespace changes from functional changes, either by; correcting the format first (ideally) or afterward. Such changes should be; highly localized and the commit message should clearly state that the commit; is not intended to change functionality, usually by stating it is; :ref:`NFC <nfc>`. #. You are allowed to commit patches without approval to those portions of LLVM; that you have contributed or maintain (i.e., have been assigned; responsibility for), with the proviso that such commits must not break the; build. This is a ""trust but verify"" policy, and commits of this nature are; reviewed after they are committed. #. Multiple violations of these policies or a single egregious violation may; cause commit access to be revoked. In any case, your changes are still subjec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:24654,patch,patches,24654,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['patch'],['patches']
Deployability,"ur new worker to connect to the staging buildmaster; which is silent by default. Try this once then check the log file; ``<buildbot-worker-root-directory>/worker/twistd.log``. If your settings; are correct you will see a refused connection. This is good and expected,; as the credentials have not been established on both ends. Now stop the; worker and proceed to the next steps. #. Fill the buildbot-worker description and admin name/e-mail. Here is an; example of the buildbot-worker description::. Windows 7 x64; Core i7 (2.66GHz), 16GB of RAM. g++.exe (TDM-1 mingw32) 4.4.0; GNU Binutils 2.19.1; cmake version 2.8.4; Microsoft(R) 32-bit C/C++ Optimizing Compiler Version 16.00.40219.01 for 80x86. See `here <http://docs.buildbot.net/current/manual/installation/worker.html>`_; for which files to edit. #. Send a patch which adds your build worker and your builder to; `zorg <https://github.com/llvm/llvm-zorg>`_. Use the typical LLVM; `workflow <https://llvm.org/docs/Contributing.html#how-to-submit-a-patch>`_. * workers are added to ``buildbot/osuosl/master/config/workers.py``; * builders are added to ``buildbot/osuosl/master/config/builders.py``. Please make sure your builder name and its builddir are unique through the; file. All new builders should default to using the ""'collapseRequests': False""; configuration. This causes the builder to build each commit individually; and not merge build requests. To maximize quality of feedback to developers,; we *strongly prefer* builders to be configured not to collapse requests.; This flag should be removed only after all reasonable efforts have been; exhausted to improve build times such that the builder can keep up with; commit flow. It is possible to allow email addresses to unconditionally receive; notifications on build failure; for this you'll need to add an; ``InformativeMailNotifier`` to ``buildbot/osuosl/master/config/status.py``.; This is particularly useful for the staging buildmaster which is silent; otherwise. #. Send th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:5276,patch,patch,5276,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['patch'],['patch']
Deployability,"uration options, please see the; :doc:`user-docs/TaintAnalysisConfiguration`. For an example see; :ref:`clangsa-taint-configuration-example`. **Configuration**. * `Config` Specifies the name of the YAML configuration file. The user can; define their own taint sources and sinks. **Related Guidelines**. * `CWE Data Neutralization Issues; <https://cwe.mitre.org/data/definitions/137.html>`_; * `SEI Cert STR02-C. Sanitize data passed to complex subsystems; <https://wiki.sei.cmu.edu/confluence/display/c/STR02-C.+Sanitize+data+passed+to+complex+subsystems>`_; * `SEI Cert ENV33-C. Do not call system(); <https://wiki.sei.cmu.edu/confluence/pages/viewpage.action?pageId=87152177>`_; * `ENV03-C. Sanitize the environment when invoking external programs; <https://wiki.sei.cmu.edu/confluence/display/c/ENV03-C.+Sanitize+the+environment+when+invoking+external+programs>`_. **Limitations**. * The taintedness property is not propagated through function calls which are; unknown (or too complex) to the analyzer, unless there is a specific; propagation rule built-in to the checker or given in the YAML configuration; file. This causes potential true positive findings to be lost. alpha.unix; ^^^^^^^^^^. .. _alpha-unix-BlockInCriticalSection:. alpha.unix.BlockInCriticalSection (C); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for calls to blocking functions inside a critical section.; Applies to: ``lock, unlock, sleep, getc, fgets, read, recv, pthread_mutex_lock,``; `` pthread_mutex_unlock, mtx_lock, mtx_timedlock, mtx_trylock, mtx_unlock, lock_guard, unique_lock``. .. code-block:: c. void test() {; std::mutex m;; m.lock();; sleep(3); // warn: a blocking function sleep is called inside a critical; // section; m.unlock();; }. .. _alpha-unix-Chroot:. alpha.unix.Chroot (C); """"""""""""""""""""""""""""""""""""""""""; Check improper use of chroot. .. code-block:: c. void f();. void test() {; chroot(""/usr/local"");; f(); // warn: no call of chdir(""/"") immediately after chroot; }. .. _alpha-unix-PthreadLock:. alpha.uni",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:74368,configurat,configuration,74368,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['configurat'],['configuration']
Deployability,urceforge.net/projects/civetweb/](https://sourceforge.net/projects/civetweb/). Developers can contribute to CivetWeb via GitHub; [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb). Due to a [bug in Git for Windows V2.24](https://github.com/git-for-windows/git/issues/2435); CivetWeb must be used with an earlier or later version (see also [here](https://github.com/civetweb/civetweb/issues/812)). Trouble tickets should be filed on GitHub; [https://github.com/civetweb/civetweb/issues](https://github.com/civetweb/civetweb/issues). New releases are announced at Google Groups; [https://groups.google.com/d/forum/civetweb](https://groups.google.com/d/forum/civetweb). Formerly some support question and discussion threads have been at [Google groups](https://groups.google.com/d/forum/civetweb).; Recent questions and discussions use [GitHub issues](https://github.com/civetweb/civetweb/issues). Source releases can be found on GitHub; [https://github.com/civetweb/civetweb/releases](https://github.com/civetweb/civetweb/releases). A very brief overview can be found on GitHub Pages; [http://civetweb.github.io/civetweb/](http://civetweb.github.io/civetweb/). Getting The Source; ------------------; Download the source code by running the following code in your command prompt:. $ git clone https://github.com/civetweb/civetweb.git; or simply grab a copy of the source code as a ZIP or TGZ file. Quick start documentation; --------------------------. - [docs/Installing.md](https://github.com/civetweb/civetweb/blob/master/docs/Installing.md) - Install Guide (for end users using pre-built binaries); - [docs/UserManual.md](https://github.com/civetweb/civetweb/blob/master/docs/UserManual.md) - End User Guide; - [docs/Building.md](https://github.com/civetweb/civetweb/blob/master/docs/Building.md) - Building the Server (quick start guide); - [docs/Embedding.md](https://github.com/civetweb/civetweb/blob/master/docs/Embedding.md) - Embedding (how to add HTTP support to an ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:3445,release,releases,3445,net/http/civetweb/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md,1,['release'],['releases']
Deployability,"urces and debug info to relative ones. The; source prefix can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_RELATIVE_PATHS_IN_DEBUG_INFO**:BOOL; Rewrite absolute source paths in debug info to relative ones. The source prefix; can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_SANITIZER**:STRING; Define the sanitizer used to build LLVM binaries and tests. Possible values; are ``Address``, ``Memory``, ``MemoryWithOrigins``, ``Undefined``, ``Thread``,; ``DataFlow``, and ``Address;Undefined``. Defaults to empty string. **LLVM_USE_SPLIT_DWARF**:BOOL; If enabled CMake will pass ``-gsplit-dwarf`` to the compiler. This option; reduces link-time memory usage by reducing the amount of debug information that; the linker needs to resolve. It is recommended for platforms using the ELF object; format, like Linux systems when linker memory usage is too high. **SPHINX_EXECUTABLE**:STRING; The path to the ``sphinx-build`` executable detected by CMake.; For installation instructions, see; https://www.sphinx-doc.org/en/master/usage/installation.html. **SPHINX_OUTPUT_HTML**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) then the targets for; building the documentation as html are added (but not built by default unless; ``LLVM_BUILD_DOCS`` is enabled). There is a target for each project in the; source tree that uses sphinx (e.g. ``docs-llvm-html``, ``docs-clang-html``; and ``docs-lld-html``). Defaults to ON. **SPHINX_OUTPUT_MAN**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) the targets for building; the man pages are added (but not built by default unless ``LLVM_BUILD_DOCS``; is enabled). Currently the only target added is ``docs-llvm-man``. Defaults; to ON. **SPHINX_WARNINGS_AS_ERRORS**:BOOL; If enabled then sphinx documentation warnings will be treated as; errors. Defaults to ON. Advanced variables; ~~~~~~~~~~~~~~~~~~. These are niche, and changing them from their defaults is more likely to cause; things to go wrong. They are also unsta",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:36930,install,installation,36930,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['install'],['installation']
Deployability,"ure after we adjust the .gitattribute settings correctly, but; is required for Windows users at the time of this writing. Simply run:. .. code-block:: console. % git clone https://github.com/llvm/llvm-project.git. or on Windows,. .. code-block:: console. % git clone --config core.autocrlf=false https://github.com/llvm/llvm-project.git. This will create an '``llvm-project``' directory in the current directory and; fully populate it with all of the source code, test directories, and local; copies of documentation files for LLVM and all the related subprojects. Note; that unlike the tarballs, which contain each subproject in a separate file, the; git repository contains all of the projects together. If you want to get a specific release (as opposed to the most recent revision),; you can check out a tag after cloning the repository. E.g., `git checkout; llvmorg-6.0.1` inside the ``llvm-project`` directory created by the above; command. Use `git tag -l` to list all of them. Sending patches; ^^^^^^^^^^^^^^^. See :ref:`Contributing <submit_patch>`. Bisecting commits; ^^^^^^^^^^^^^^^^^. See `Bisecting LLVM code <GitBisecting.html>`_ for how to use ``git bisect``; on LLVM. Reverting a change; ^^^^^^^^^^^^^^^^^^. When reverting changes using git, the default message will say ""This reverts; commit XYZ"". Leave this at the end of the commit message, but add some details; before it as to why the commit is being reverted. A brief explanation and/or; links to bots that demonstrate the problem are sufficient. Local LLVM Configuration; ------------------------. Once checked out repository, the LLVM suite source code must be configured; before being built. This process uses CMake. Unlinke the normal ``configure``; script, CMake generates the build files in whatever format you request as well; as various ``*.inc`` files, and ``llvm/include/llvm/Config/config.h.cmake``. Variables are passed to ``cmake`` on the command line using the format; ``-D<variable name>=<value>``. The following v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:22943,patch,patches,22943,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['patch'],['patches']
Deployability,"ures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:219517,release,release,219517,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability,"urity protocols in the list of protocols returned by the serverMake the readahead strategy more conservativeFix a rare race condition happening when destroying instances with outstanding open requestsEnforce cache coherency in the case of reads+writes in the same fileCorrectly guess the filesize of a file opened for writing in sync modeMake server host name check more flexible for GSI authenticationFix some relevant issues with cache handling on the client, including a rare but fatal bug in; determining the cache holes list and the end of a cache lookupMore complete detection of async read errorsGeneralFix problem in handling the return code; of X509_REQ_verify; in XrdCryptosslX509Req.ccAvoid SEGV when doing an lsd admin command with; authenticated xrootd clientsClose race conditions that allowed a supervisor/manager; to subscribe without declaring a data port. Initialize nostage state in; XrdCmsState to prevent erroneous state declaration during; initialization.Fix a problem with the subject name of proxies of level; > 1; this was creating a failure when a Globus application was; trying to use the proxy certificateFix a problem with cache refreshing in XrdSutCache; affecting automatic reloading of password filesFor now, turn off IPV6 processing as it seems to create; several problems.Fix a few issues with the available releases of gcc 4.4Fix a few issues with the 'icc' compilerFix several issues in GSI and PWD authentication modulesNew featuresNew File Residency Manager (frm), replacement for the MPS scriptsScripts are now provided toautomatically donwload a CRL certificate; (utils/getCRLcert)install the recommended verion of OpenSSL and build it; with the options optimal for usage in XROOTD/SCALLA; (utils/installOpenSSL.sh)install the recommended verion of OpenAFS and build it; with the options optimal for usage in; XROOTD/SCALLA (utils/installOpenAFS.sh)MiscellaneaTokenAuthz and CS2 modules are no longer part of the main; built; they have to be built externally. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v524/index.html:3387,release,releases,3387,net/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v524/index.html,5,"['install', 'release']","['install', 'installOpenAFS', 'installOpenSSL', 'releases']"
Deployability,"urn memory(none). Arguments:; """""""""""""""""""". The first argument is a pointer, which refers to a thread local global. Semantics:; """""""""""""""""""". The address of a thread local global is not a constant, since it depends on; the calling thread. The `llvm.threadlocal.address` intrinsic returns the; address of the given thread local global in the calling thread. .. _int_vscale:. '``llvm.vscale``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 llvm.vscale.i32(); declare i64 llvm.vscale.i64(). Overview:; """""""""""""""""". The ``llvm.vscale`` intrinsic returns the value for ``vscale`` in scalable; vectors such as ``<vscale x 16 x i8>``. Semantics:; """""""""""""""""""". ``vscale`` is a positive value that is constant throughout program; execution, but is unknown at compile time.; If the result value does not fit in the result type, then the result is; a :ref:`poison value <poisonvalues>`. Stack Map Intrinsics; --------------------. LLVM provides experimental intrinsics to support runtime patching; mechanisms commonly desired in dynamic language JITs. These intrinsics; are described in :doc:`StackMaps`. Element Wise Atomic Memory Intrinsics; -------------------------------------. These intrinsics are similar to the standard library memory intrinsics except; that they perform memory transfer as a sequence of atomic memory accesses. .. _int_memcpy_element_unordered_atomic:. '``llvm.memcpy.element.unordered.atomic``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.memcpy.element.unordered.atomic`` on; any integer bit width and for different address spaces. Not all targets; support all bit widths however. ::. declare void @llvm.memcpy.element.unordered.atomic.p0.p0.i32(ptr <dest>,; ptr <src>,; i32 <len>,; i32 <element_size>); declare void @llvm.memcpy.element.unordered.atomic.p0.p0.i64(ptr <dest>,; ptr <src>,; i64 <len>,; i32 <element_size>). Overview:; """""""""""""""""". The '``llvm.memcpy.element.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:956647,patch,patching,956647,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['patch'],['patching']
Deployability,"urned value; is again compared to the maximum allowed step (the proposed one) and in; case the distance is safe no other action is performed and the proposed; step is approved. In case the boundary is closer, the computed distance; is taken as maximum allowed step. For optimization purposed, for; particles starting very close to the current volume boundary (less than; 0.01 microns) and exiting the algorithm stops here. After computing the distance to exit the current node, the distance to; the daughter of the current volume which is crossed next is computed by; TGeoManager::FindNextDaughterBoundary(). This computes the; distance to all daughter candidates that can be possibly crossed by; using volume voxelization. The algorithm is efficient in average only in; case the number of daughters is greater than 4. For fewer nodes, a; simple loop is performed and the minimum distance (from a point outside; each shape) is taken and compared to the maximum allowed step. The step; value is again updated if `step<stepmax` . A special case is when the current node is declared as possibly; overlapping with something else. If this is the case, the distance is; computed for all possibly overlapping candidates, taking into account; the overlapping priorities (see also: "" Overlapping volumes ""). The global matrix describing the next crossed physical node is; systematically computed in case the value of the proposed step is; negative. In this case, one can subsequently call; TGeoManager::ComputeNormalFast() to get the normal vector to the; crossed surface, after propagating the current point with the; TGeoManager::GetStep() value. This propagation can be done like:. ~~~{.cpp}; Double_t *current_point = gGeoManager->GetCurrentPoint();; Double_t *current_dir = gGeoManager->GetCurrentDirection();; for (Int_t i=0; i<3; i++); current_point[i] += step * current_dir[I];; ~~~. Note: The method TGeoManager::FindNextBoundary() does not modify the; current point/direction nor the current volume/s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:124204,update,updated,124204,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['update'],['updated']
Deployability,"uron.cxx; src/TNeuronInputAbs.cxx; src/TNeuronInputChooser.cxx; src/TNeuronInput.cxx; src/TNeuronInputSqSum.cxx; src/TNeuronInputSum.cxx; src/Tools.cxx; src/TrainingHistory.cxx; src/TransformationHandler.cxx; src/TSpline1.cxx; src/TSpline2.cxx; src/TSynapse.cxx; src/Types.cxx; src/VariableDecorrTransform.cxx; src/VariableGaussTransform.cxx; src/VariableIdentityTransform.cxx; src/VariableImportance.cxx; src/VariableInfo.cxx; src/VariableNormalizeTransform.cxx; src/VariablePCATransform.cxx; src/VariableRearrangeTransform.cxx; src/VariableTransformBase.cxx; src/VariableTransform.cxx; src/VarTransformHandler.cxx; src/Volume.cxx; src/DNN/Architectures/Reference.cxx; src/DNN/Architectures/Reference/DataLoader.cxx; src/DNN/Architectures/Reference/TensorDataLoader.cxx; src/DNN/Architectures/Cpu.cxx; src/DNN/Architectures/Cpu/CpuBuffer.cxx; src/DNN/Architectures/Cpu/CpuMatrix.cxx; ${TMVA_EXTRA_SOURCES}; DEPENDENCIES; TreePlayer; Tree; Hist; Matrix; Minuit; MLP; MathCore; Core; RIO; XMLIO; ${TMVA_EXTRA_DEPENDENCIES}; DICTIONARY_OPTIONS; -writeEmptyRootPCM; INSTALL_OPTIONS; ${installoptions}; ${EXTRA_DICT_OPTS}; ). if(MSVC); target_compile_definitions(TMVA PRIVATE _USE_MATH_DEFINES); endif(). if(vdt OR builtin_vdt); target_link_libraries(TMVA PRIVATE VDT::VDT); endif(); if(builtin_vdt); add_dependencies(TMVA VDT); endif(). if(tmva-cpu); target_include_directories(TMVA PRIVATE ${TBB_INCLUDE_DIRS}); target_link_libraries(TMVA PRIVATE ${TBB_LIBRARIES}); set_target_properties(TMVA PROPERTIES COMPILE_FLAGS ""${TBB_CXXFLAGS}""). if(BLAS_FOUND); target_link_libraries(TMVA PRIVATE ${BLAS_LINKER_FLAGS} ${BLAS_LIBRARIES}); elseif(GSL_FOUND); target_compile_definitions(TMVA PRIVATE -DDNN_USE_CBLAS); target_include_directories(TMVA SYSTEM PRIVATE ${GSL_INCLUDE_DIR}); target_link_libraries(TMVA PRIVATE ${GSL_CBLAS_LIBRARY}); if(builtin_gsl); add_dependencies(TMVA GSL); endif(); else(); message(FATAL_ERROR ""tmva-cpu enabled but neither BLAS nor GSL BLAS were found""); endif(); endif(). if(tmva-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/CMakeLists.txt:9325,install,installoptions,9325,tmva/tmva/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/CMakeLists.txt,1,['install'],['installoptions']
Deployability,"urpose of these; groups is to give vendors early notice that potentially disruptive changes; are being considered but have not yet been accepted. Vendors can give early; testing feedback on the changes to alert us to unacceptable breakages. The; current list of vendor groups is:. * `Clang vendors <https://reviews.llvm.org/project/members/113/>`_; * `libc++ vendors <https://reviews.llvm.org/project/members/109/>`_. People interested in joining the vendors group can do so by clicking the; ""Join Project"" link on the vendor's ""Members"" page in Phabricator. * When committing the change to the repository, add appropriate information; about the potentially breaking changes to the ``Potentially Breaking Changes``; section of the project's release notes. The release note should have; information about what the change is, what is potentially disruptive about; it, as well as any code examples, links, and motivation that is appropriate; to share with users. This helps users to learn about potential issues with; upgrading to that release. * After the change has been committed to the repository, the potentially; disruptive changes described in the release notes should be posted to the; `Announcements <https://discourse.llvm.org/c/announce/>`_ channel on; Discourse. The post should be tagged with the ``potentially-breaking`` label; and a label specific to the project (such as ``clang``, ``llvm``, etc). This; is another mechanism by which we can give pre-release notice to users about; potentially disruptive changes. It is a lower-traffic alternative to the; joining ""vendors"" group. To automatically be notified of new announcements; with the ``potentially-breaking`` label, go to your user preferences page in; Discourse, and add the label to one of the watch categories under; ``Notifications->Tags``. .. _code owners:. Code Owners; -----------. The LLVM Project relies on two features of its process to maintain rapid; development in addition to the high quality of its source base: the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:6890,release,release,6890,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['release'],['release']
Deployability,"urrounding context. .. code-block:: c++. namespace N {; enum E {; E1,; E2,; };. class C {; public:; C();; };. bool baz(int i) {; try {; do {; switch (i) {; case 1: {; foobar();; break;; }; default: {; break;; }; }; } while (--i);; return true;; } catch (...) {; handleError();; return false;; }; }. void foo(bool b) {; if (b) {; baz(2);; } else {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_Linux`` (in configuration: ``Linux``); Like ``Attach``, but break before braces on function, namespace and; class definitions. .. code-block:: c++. namespace N; {; enum E {; E1,; E2,; };. class C; {; public:; C();; };. bool baz(int i); {; try {; do {; switch (i) {; case 1: {; foobar();; break;; }; default: {; break;; }; }; } while (--i);; return true;; } catch (...) {; handleError();; return false;; }; }. void foo(bool b); {; if (b) {; baz(2);; } else {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_Mozilla`` (in configuration: ``Mozilla``); Like ``Attach``, but break before braces on enum, function, and record; definitions. .. code-block:: c++. namespace N {; enum E; {; E1,; E2,; };. class C; {; public:; C();; };. bool baz(int i); {; try {; do {; switch (i) {; case 1: {; foobar();; break;; }; default: {; break;; }; }; } while (--i);; return true;; } catch (...) {; handleError();; return false;; }; }. void foo(bool b); {; if (b) {; baz(2);; } else {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_Stroustrup`` (in configuration: ``Stroustrup``); Like ``Attach``, but break before function definitions, ``catch``, and; ``else``. .. code-block:: c++. namespace N {; enum E {; E1,; E2,; };. class C {; public:; C();; };. bool baz(int i); {; try {; do {; switch (i) {; case 1: {; foobar();; break;; }; default: {; break;; }; }; } while (--i);; return true;; }; catch (...) {; handleError();; return false;; }; }. void foo(bool b); {; if (b) {; baz(2);; }; else {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_All",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:48741,configurat,configuration,48741,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"us of implementation, level of support; available, who the sub-community is and, if applicable, roadmap for inclusion; into the core tier.; * Be restricted to a specific directory or have a consistent pattern (ex.; unique file suffix), making it easy to remove when necessary. Inclusion Policy; ================. To add a new peripheral component, send an RFC to the appropriate dev list; proposing its addition and explaining how it will meet the support requirements; listed above. Different types of components could require different levels of; detail. when in doubt, ask the community what's the best approach. Inclusion must reach consensus in the RFC by the community and the approval of; the corresponding review (by multiple members of the community) is the official; note of acceptance. After merge, there often is a period of transition, where teething issues on; existing buildbots are discovered and fixed. If those cannot be fixed straight; away, the sub-community is responsible for tracking and reverting all the; pertinent patches and retrying the inclusion review. Once the component is stable in tree, it must follow this policy and the; deprecation rules below apply. Due to the uncertain nature of inclusion, it's advisable that new components; are not added too close to a release branch. The time will depend on the size; and complexity of the component, so adding release and testing managers on the; RFC and review is strongly advisable. Deprecation Policy; ==================. The LLVM code base has a number of files that aren't being actively maintained.; But not all of those files are obstructing the development of the project and; so it remains in the repository with the assumption that it could still be; useful for downstream users. For code to remain in the repository, its presence must not impose an undue; burden on maintaining other components (core or peripheral). Warnings; --------. There are multiple types of issues that might trigger a request for depreca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:7431,patch,patches,7431,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst,1,['patch'],['patches']
Deployability,"use in the replacement of a ``s@@@`` command in sed; %{/T:regex_replacement} %/T but escaped for use in the replacement of a ``s@@@`` command in sed; %:s On Windows, %/s but a ``:`` is removed if its the second character.; Otherwise, %s but with a single leading ``/`` removed.; %:S On Windows, %/S but a ``:`` is removed if its the second character.; Otherwise, %S but with a single leading ``/`` removed.; %:p On Windows, %/p but a ``:`` is removed if its the second character.; Otherwise, %p but with a single leading ``/`` removed.; %:t On Windows, %/t but a ``:`` is removed if its the second character.; Otherwise, %t but with a single leading ``/`` removed.; %:T On Windows, %/T but a ``:`` is removed if its the second character.; Otherwise, %T but with a single leading ``/`` removed.; ======================= ==============. Other substitutions are provided that are variations on this base set and; further substitution patterns can be defined by each test module. See the; modules :ref:`local-configuration-files`. More detailed information on substitutions can be found in the; :doc:`../TestingGuide`. TEST RUN OUTPUT FORMAT; ~~~~~~~~~~~~~~~~~~~~~~. The :program:`lit` output for a test run conforms to the following schema, in; both short and verbose modes (although in short mode no PASS lines will be; shown). This schema has been chosen to be relatively easy to reliably parse by; a machine (for example in buildbot log scraping), and for other tools to; generate. Each test result is expected to appear on a line that matches:. .. code-block:: none. <result code>: <test name> (<progress info>). where ``<result-code>`` is a standard test result such as PASS, FAIL, XFAIL,; XPASS, UNRESOLVED, or UNSUPPORTED. The performance result codes of IMPROVED and; REGRESSED are also allowed. The ``<test name>`` field can consist of an arbitrary string containing no; newline. The ``<progress info>`` field can be used to report progress information such; as (1/300) or can be empty, but even",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:22047,configurat,configuration-files,22047,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['configurat'],['configuration-files']
Deployability,"use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argument and; return value:. .. code-block:: none. Stack Map: ID=78, Loc0=%r9 Loc1=%r8. The patch code sequence m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:10515,patch,patch,10515,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['patch'],['patch']
Deployability,"used by long data dependencies and; sub-optimal usage of hardware resources. An instruction in the timeline view is identified by a pair of indices, where; the first index identifies an iteration, and the second index is the; instruction index (i.e., where it appears in the code sequence). Since this; example was generated using 3 iterations: ``-iterations=3``, the iteration; indices range from 0-2 inclusively. Excluding the first and last column, the remaining columns are in cycles.; Cycles are numbered sequentially starting from 0. From the example output above, we know the following:. * Instruction [1,0] was dispatched at cycle 1.; * Instruction [1,0] started executing at cycle 2.; * Instruction [1,0] reached the write back stage at cycle 4.; * Instruction [1,0] was retired at cycle 10. Instruction [1,0] (i.e., vmulps from iteration #1) does not have to wait in the; scheduler's queue for the operands to become available. By the time vmulps is; dispatched, operands are already available, and pipeline JFPU1 is ready to; serve another instruction. So the instruction can be immediately issued on the; JFPU1 pipeline. That is demonstrated by the fact that the instruction only; spent 1cy in the scheduler's queue. There is a gap of 5 cycles between the write-back stage and the retire event.; That is because instructions must retire in program order, so [1,0] has to wait; for [0,2] to be retired first (i.e., it has to wait until cycle 10). In the example, all instructions are in a RAW (Read After Write) dependency; chain. Register %xmm2 written by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:24395,pipeline,pipeline,24395,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['pipeline'],['pipeline']
Deployability,"used by; navigation algorithms to optimize tracking. These must geometrically; contain their belongings (positioned volumes) so that these do not; extrude its shape boundaries. Not respecting this rule generally leads; to unpredictable results. Therefore `A` and `B` together must fit into; `C` that has to fit also into `D,E,` and `F`. This is not always; straightforward to accomplish, especially when instead of `A` and `B` we; have many more volumes. In order to avoid these problems, one can use for the difficult cases; the class **`TGeoVolumeAssembly`**, representing an assembly of volumes.; This behaves like a normal container volume supporting other volumes; positioned inside, but it has neither shape nor medium. It cannot be; used directly as a piece of the geometry, but just as a temporary; structure helping temporary assembling and positioning volumes. If we define now `C` as an assembly containing `A` and `B`, positioning; the assembly into `D,E` and `F` will actually position only `A` and; `B `directly into these volumes, taking into account their combined; transformations `A/B` to `C` and `C` to `D/E/F`. This looks much nicer,; is it? In fact, it is and it is not. Of course, we managed to get rid of; the ‘unnecessary' volume `C` in our geometry, but we end-up with a more; flat structure for `D,E` and `F` (more daughters inside). This can get; much worse when extensively used, as in the case: assemblies of; assemblies. For deciding what to choose between using virtual containers or; assemblies for a specific case, one can use for both cases, after the; geometry was closed:. ``` {.cpp}; gGeoManager->SetTopVolume(ptr_D);; gGeoManager->Test();; gGeoManager->RestoreMasterVolume();; ```. The `ptr_D` is a pointer to volume `D` containing the interesting; structure. The test will provide the timing for classifying 1 million; random points inside `D`. #### Examples of Volume Positioning. Now let us make a simple volume representing a copper wire. We suppose; that a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:72138,A/B,A/B,72138,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['A/B'],['A/B']
Deployability,"used with -offset and -length.; Can only be used with one input file.; -n - Alias for --dry-run; --offset=<uint> - Format a range starting at this byte offset.; Multiple ranges can be formatted by specifying; several -offset and -length pairs.; Can only be used with one input file.; --output-replacements-xml - Output replacements as XML.; --qualifier-alignment=<string> - If set, overrides the qualifier alignment style; determined by the QualifierAlignment style flag; --sort-includes - If set, overrides the include sorting behavior; determined by the SortIncludes style flag; --style=<string> - Set coding style. <string> can be:; 1. A preset: LLVM, GNU, Google, Chromium, Microsoft,; Mozilla, WebKit.; 2. 'file' to load style configuration from a; .clang-format file in one of the parent directories; of the source file (for stdin, see --assume-filename).; If no .clang-format file is found, falls back to; --fallback-style.; --style=file is the default.; 3. 'file:<format_file_path>' to explicitly specify; the configuration file.; 4. ""{key: value, ...}"" to set specific parameters, e.g.:; --style=""{BasedOnStyle: llvm, IndentWidth: 8}""; --verbose - If set, shows the list of processed files. Generic Options:. --help - Display available options (--help-hidden for more); --help-list - Display list of available options (--help-list-hidden for more); --version - Display the version of this program. .. END_FORMAT_HELP. When the desired code formatting style is different from the available options,; the style can be customized using the ``-style=""{key: value, ...}""`` option or; by putting your style configuration in the ``.clang-format`` or ``_clang-format``; file in your project's directory and using ``clang-format -style=file``. An easy way to create the ``.clang-format`` file is:. .. code-block:: console. clang-format -style=llvm -dump-config > .clang-format. Available style options are described in :doc:`ClangFormatStyleOptions`. .clang-format-ignore; ====================. You ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst:4156,configurat,configuration,4156,interpreter/llvm-project/clang/docs/ClangFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst,1,['configurat'],['configuration']
Deployability,"useful.; 7. Complete the Python installation.; 8. Run a ""Developer Command Prompt for VS 2019"" **as administrator**. This command; prompt provides correct path and environment variables to Visual Studio and; the installed tools.; 9. In the terminal window, type the commands:. .. code-block:: bat. c:; cd \. You may install the llvm sources in other location than ``c:\llvm`` but do not; install into a path containing spaces (e.g. ``c:\Documents and Settings\...``); as it will fail. 10. Register the Microsoft Debug Interface Access (DIA) DLLs. .. code-block:: bat. regsvr32 ""%VSINSTALLDIR%\DIA SDK\bin\msdia140.dll""; regsvr32 ""%VSINSTALLDIR%\DIA SDK\bin\amd64\msdia140.dll"". The DIA library is required for LLVM PDB tests and; `LLDB development <https://lldb.llvm.org/resources/build.html>`_. 11. Install psutil and obtain LLVM source code:. .. code-block:: bat. pip install psutil; git clone https://github.com/llvm/llvm-project.git llvm. Instead of ``git clone`` you may download a compressed source distribution; from the `releases page <https://github.com/llvm/llvm-project/releases>`_.; Select the last link: ``Source code (zip)`` and unpack the downloaded file using; Windows Explorer built-in zip support or any other unzip tool. 12. Finally, configure LLVM using CMake:. .. code-block:: bat. cmake -S llvm\llvm -B build -DLLVM_ENABLE_PROJECTS=clang -DLLVM_TARGETS_TO_BUILD=X86 -Thost=x64; exit. ``LLVM_ENABLE_PROJECTS`` specifies any additional LLVM projects you want to; build while ``LLVM_TARGETS_TO_BUILD`` selects the compiler targets. If; ``LLVM_TARGETS_TO_BUILD`` is omitted by default all targets are built; slowing compilation and using more disk space.; See the :doc:`LLVM CMake guide <CMake>` for detailed information about; how to configure the LLVM build. The ``cmake`` command line tool is bundled with Visual Studio but its GUI is; not. You may install `CMake <http://www.cmake.org/>`_ to use its GUI to change; CMake variables or modify the above command line. * Once CMake i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst:4711,release,releases,4711,interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,1,['release'],['releases']
Deployability,"users** and; if you want to develop `lldb <https://lldb.llvm.org/>`_, selecting; **Download debug binaries** is useful.; 7. Complete the Python installation.; 8. Run a ""Developer Command Prompt for VS 2019"" **as administrator**. This command; prompt provides correct path and environment variables to Visual Studio and; the installed tools.; 9. In the terminal window, type the commands:. .. code-block:: bat. c:; cd \. You may install the llvm sources in other location than ``c:\llvm`` but do not; install into a path containing spaces (e.g. ``c:\Documents and Settings\...``); as it will fail. 10. Register the Microsoft Debug Interface Access (DIA) DLLs. .. code-block:: bat. regsvr32 ""%VSINSTALLDIR%\DIA SDK\bin\msdia140.dll""; regsvr32 ""%VSINSTALLDIR%\DIA SDK\bin\amd64\msdia140.dll"". The DIA library is required for LLVM PDB tests and; `LLDB development <https://lldb.llvm.org/resources/build.html>`_. 11. Install psutil and obtain LLVM source code:. .. code-block:: bat. pip install psutil; git clone https://github.com/llvm/llvm-project.git llvm. Instead of ``git clone`` you may download a compressed source distribution; from the `releases page <https://github.com/llvm/llvm-project/releases>`_.; Select the last link: ``Source code (zip)`` and unpack the downloaded file using; Windows Explorer built-in zip support or any other unzip tool. 12. Finally, configure LLVM using CMake:. .. code-block:: bat. cmake -S llvm\llvm -B build -DLLVM_ENABLE_PROJECTS=clang -DLLVM_TARGETS_TO_BUILD=X86 -Thost=x64; exit. ``LLVM_ENABLE_PROJECTS`` specifies any additional LLVM projects you want to; build while ``LLVM_TARGETS_TO_BUILD`` selects the compiler targets. If; ``LLVM_TARGETS_TO_BUILD`` is omitted by default all targets are built; slowing compilation and using more disk space.; See the :doc:`LLVM CMake guide <CMake>` for detailed information about; how to configure the LLVM build. The ``cmake`` command line tool is bundled with Visual Studio but its GUI is; not. You may install `CMake <ht",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst:4552,install,install,4552,interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,1,['install'],['install']
Deployability,"ushes the updated L. It is an evaluation error if the updated bit offset of any SL is less than 0; or greater than or equal to the size of the location storage specified by; SL. 2. ``DW_OP_LLVM_offset_uconst`` *New*. ``DW_OP_LLVM_offset_uconst`` has a single unsigned LEB128 integer operand; that represents a byte displacement B. The operation is equivalent to performing ``DW_OP_constu B;; DW_OP_LLVM_offset``. *This operation is supplied specifically to be able to encode more field; displacements in two bytes than can be done with* ``DW_OP_lit*;; DW_OP_LLVM_offset``\ *.*. .. note::. Should this be named ``DW_OP_LLVM_offset_uconst`` to match; ``DW_OP_plus_uconst``, or ``DW_OP_LLVM_offset_constu`` to match; ``DW_OP_constu``?. 3. ``DW_OP_LLVM_bit_offset`` *New*. ``DW_OP_LLVM_bit_offset`` pops two stack entries. The first must be an; integral type value that represents a bit displacement B. The second must be; a location description L. It adds the value of B to the bit offset of each single location description; SL of L, and pushes the updated L. It is an evaluation error if the updated bit offset of any SL is less than 0; or greater than or equal to the size of the location storage specified by; SL. 4. ``DW_OP_push_object_address``. ``DW_OP_push_object_address`` pushes the location description L of the; current object. *This object may correspond to an independent variable that is part of a; user presented expression that is being evaluated. The object location; description may be determined from the variable's own debugging information; entry or it may be a component of an array, structure, or class whose; address has been dynamically determined by an earlier step during user; expression evaluation.*. *This operation provides explicit functionality (especially for arrays; involving descriptors) that is analogous to the implicit push of the base; location description of a structure prior to evaluation of a*; ``DW_AT_data_member_location`` *to access a data member of a st",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:99676,update,updated,99676,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['update'],['updated']
Deployability,"ust happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. flat_atomic sc1=1; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:324363,release,released,324363,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['released']
Deployability,"ustom modules; list(INSERT CMAKE_MODULE_PATH 0; ""${CMAKE_CURRENT_SOURCE_DIR}/cmake""; ""${CMAKE_CURRENT_SOURCE_DIR}/cmake/modules""; ""${LLVM_COMMON_CMAKE_UTILS}/Modules""; ). # Generate a CompilationDatabase (compile_commands.json file) for our build,; # for use by clang_complete, YouCompleteMe, etc.; set(CMAKE_EXPORT_COMPILE_COMMANDS 1). option(LLVM_INSTALL_BINUTILS_SYMLINKS; ""Install symlinks from the binutils tool names to the corresponding LLVM tools."" OFF). option(LLVM_INSTALL_CCTOOLS_SYMLINKS; ""Install symlinks from the cctools tool names to the corresponding LLVM tools."" OFF). # By default we use symlinks on Unix platforms and copy binaries on Windows; # If you have the correct setup on Windows you can use this option to enable; # symlinks and save a lot of diskspace.; option(LLVM_USE_SYMLINKS ""Use symlinks instead of copying binaries"" ${CMAKE_HOST_UNIX}). option(LLVM_INSTALL_UTILS ""Include utility binaries in the 'install' target."" OFF). option(LLVM_INSTALL_TOOLCHAIN_ONLY ""Only include toolchain files in the 'install' target."" OFF). # Unfortunatly Clang is too eager to search directories for module maps, which can cause the; # installed version of the maps to be found when building LLVM from source. Therefore we turn off; # the installation by default. See llvm.org/PR31905.; option(LLVM_INSTALL_MODULEMAPS ""Install the modulemap files in the 'install' target."" OFF). option(LLVM_USE_FOLDERS ""Enable solution folders in Visual Studio. Disable for Express versions."" ON); if ( LLVM_USE_FOLDERS ); set_property(GLOBAL PROPERTY USE_FOLDERS ON); endif(). include(VersionFromVCS). option(LLVM_APPEND_VC_REV; ""Embed the version control system revision in LLVM"" ON). set(LLVM_FORCE_VC_REVISION; """" CACHE STRING ""Force custom VC revision for LLVM_APPEND_VC_REV""). set(LLVM_FORCE_VC_REPOSITORY; """" CACHE STRING ""Force custom VC repository for LLVM_APPEND_VC_REV""). option(LLVM_TOOL_LLVM_DRIVER_BUILD ""Enables building the llvm multicall tool"" OFF). set(PACKAGE_NAME LLVM); set(PACKAGE_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:14076,install,install,14076,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['install'],['install']
Deployability,"ut of scope on the C++ side, the Python object will change type; into an object that largely behaves like None. The strict policy differs in that it will never relinquish ownership; when passing an object as a parameter to a function. It is then up to; the developer to prevent double deletes. Choosing one or the other; policy is done by:. ``` {.cpp}; ROOT.SetMemoryPolicy( ROOT.kMemoryStrict ); ```. for the strict policy, or for the heuristic policy:. ``` {.cpp}; ROOT.SetMemoryPolicy( ROOT.kMemoryHeuristics ); ```. Care must be taken in the case of graphic objects: when drawn on the; current pad, a reference to the graphics is kept that `PyROOT` isn't; currently aware of, and it is up to the developer to keep at lease one; Python reference alive. See `$ROOTSYS/tutorials/pyroot/zdemo.py`; (available in the latest release) for an example. Alternatively, one can; tell python to give up ownership for individual instances:. ``` {.cpp}; o = ROOT.TObject(); ROOT.SetOwnership( o, False ) # True to own, False to release; ```. #### Memory Management by Hand. If needed, you can explicitly destroy a ROOT object that you own through; its associated **`TClass`**:. ``` {.cpp}; myobject.IsA().Destructor(myobject); ```. which will send out the deletion notification to the system (thus you do; not need to care anymore at this point about Python reference counting,; the object will go, even if it's reference count it non-zero), and free; the memory. ### Performance. The performance of `PyROOT` when programming with ROOT in Python is; similar to that of Cling. Differences occur mainly because of differences; in the respective languages: C++ is much harder to parse, but once; parsed, it is much easier to optimize. Consequently, individual calls to; ROOT are typically faster from `PyROOT`, whereas loops are typically; slower. When programming in Python, the modus operandi is to consider; performance generally ""good enough"" on the outset, and when it turns out; that, it is not good enough;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:21874,release,release,21874,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['release'],['release']
Deployability,"ut(StringRef Scalar, void *Ctxt,; MyStringType &Value) {; Value.Str = Scalar.str();; return StringRef();; }; };. Mappings; ========. To be translated to or from a YAML mapping for your type T you must specialize; llvm::yaml::MappingTraits on T and implement the ""void mapping(IO &io, T&)""; method. If your native data structures use pointers to a class everywhere,; you can specialize on the class pointer. Examples:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. // Example of struct Foo which is used by value; template <>; struct MappingTraits<Foo> {; static void mapping(IO &io, Foo &foo) {; io.mapOptional(""size"", foo.size);; ...; }; };. // Example of struct Bar which is natively always a pointer; template <>; struct MappingTraits<Bar*> {; static void mapping(IO &io, Bar *&bar) {; io.mapOptional(""size"", bar->size);; ...; }; };. There are circumstances where we want to allow the entire mapping to be; read as an enumeration. For example, say some configuration option; started as an enumeration. Then it got more complex so it is now a; mapping. But it is necessary to support the old configuration files.; In that case, add a function ``enumInput`` like for; ``ScalarEnumerationTraits::enumeration``. Examples:. .. code-block:: c++. struct FooBarEnum {; int Foo;; int Bar;; bool operator==(const FooBarEnum &R) const {; return Foo == R.Foo && Bar == R.Bar;; }; };. template <> struct MappingTraits<FooBarEnum> {; static void enumInput(IO &io, FooBarEnum &Val) {; io.enumCase(Val, ""OnlyFoo"", FooBarEnum({1, 0}));; io.enumCase(Val, ""OnlyBar"", FooBarEnum({0, 1}));; }; static void mapping(IO &io, FooBarEnum &Val) {; io.mapOptional(""Foo"", Val.Foo);; io.mapOptional(""Bar"", Val.Bar);; }; };. No Normalization; ----------------. The ``mapping()`` method is responsible, if needed, for normalizing and; denormalizing. In a simple case where the native data structure requires no; normalization, the mapping method just uses mapOptional() or mapRequired() to; bind th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:15763,configurat,configuration,15763,interpreter/llvm-project/llvm/docs/YamlIO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst,1,['configurat'],['configuration']
Deployability,"ution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. buffer_wbl2 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgk",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:313860,release,release,313860,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability,"ution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory order",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:263521,release,release,263521,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability,"utocol"" options - standard ""plc"" should be used instead; 8. Provide drawing of artificial ""$legend"" item - it creates TLegend for all primitives in pad; Can be used when several histograms or several graphs superimposed; 9. Let configure ""&toolbar=vert"" in URL to change orientation of tool buttons; 10. Improve markers and error bars drawing for TH1/TProfile. ## Changes in 5.4.3; 1. Fix - draw functions also when histogram ""same"" option used (#159); 2. Fix - when draw histogram as markers improve optimization algorithm; 3. Fix - correct histogram Y-axis range selection in logarithmic scale; 4. Fix - for TH2 draw options allow combination ""colztext"" (#162); 5. Fix - PNG file generation with 3D drawings inside. ## Changes in 5.4.2; 1. Fix - take into account extra quotes in multipart http reply (#157); 2. Fix - display of labels on X axis with TProfile; 3. Fix - support time display in TMultiGraph; 4. Fix - correctly parse ""optstat"" and ""optfit"" in URL; 5. Fix - correctly update TGraph drawing when X range is changing; 6. Fix - return only TF1/TF2 object when searching function (#158). ## Changes in 5.4.1; 1. Fix - monitoring mode in draw.htm page; 2. Fix - zooming in colz palette; 3. Fix - support both 9.x and 10.x jsdom version in Node.js (#149); 4. Fix - draw axis main line with appropriate attributes (#150); 5. Fix - use axis color when drawing grids lines (#150); 6. Fix - when set pad logx/logy, reset existing user ranges in pad; 7. Fix - avoid too deep calling stack when drawing many graphs or histos (#154); 8. Fix - correctly (re)draw tooltips on canvas with many subpads. ## Changes in 5.4.0; 1. New supported classes:; - TDiamond; - TArc; - TCurlyLine; - TCurlyArc; - TCrown; 2. New draw options:; - ""RX"" and ""RY"" for TGraph to reverse axis; - ""noopt"" for TGraph to disable drawing optimization; - ""CPN"" for TCanvas to create color palette from N last colors; - ""line"" for TGraph2D; 3. New features:; - support LZ4 compression; - tooltips and zooming in TGraphPolar dra",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:35000,update,update,35000,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['update'],['update']
Deployability,"uttonGroup(p,""Coordinate system"",kVerticalFrame);; fR[0] = new TGRadioButton(bg,new TGHotString(""&Pixel""));; fR[1] = new TGRadioButton(bg,new TGHotString(""&NDC ""));; fR[2] = new TGRadioButton(bg,new TGHotString(""&User ""));; fR[1]->SetState(kButtonDown);; br->Show();; ```. It is enough to change `kVerticalFrame` to `kHorizontalFrame` in; **`TGButtonGroup`** constructor and you will have radio buttons aligned; horizontally:. ![](pictures/03000211.png). The class **`TGButtonGroup`** will help you to organize button widgets; in a group. There is no need to call `AddFrame()` since the buttons are; added automatically with a default layout hint to their parent by; **`TGButtonGroup`**`::Show()` as shown in the previous example. The; buttons in the group have assigned identifiers. Any button in a group; emits a `Clicked()` signal with this identifier when it is clicked. This; giving an ideal solution to connect several `Clicked()` signals to one; slot. An exclusive button group switches off all toggle buttons except the; selected one. The group is by default non-exclusive but its entire radio; buttons will be mutually exclusive. **`TGHButtonGroup`** and **`TGVButtonGroup`** are convenience classes; that offer you a thin layer on top of **`TGButtonGroup`**.; **`TGHButtonGroup`** organize button widgets in a group of one; horizontal row, **`TGVButtonGroup`** in a group of one column. You can; also organize buttons in rows and columns using the provided constructor; and **`TGMatrixLayout`**. Do not use a radio button to indicate the presence or absence of a state; - use a check box instead. ![](pictures/03000212.png). To have the check button ""Event Status"" and to set it as selected we; need to write:. ``` {.cpp}; TGCheckButton *estat = new TGCheckButton(p, ""Event Status"",1);; estat->SetState(kButtonDown);; ```. Check boxes show the selected choices and any number of them can be; selected, including none. Their proper usage is for setting attributes,; properties or values; als",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md:61138,toggle,toggle,61138,documentation/users-guide/WritingGUI.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md,1,['toggle'],['toggle']
Deployability,"uture version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorator. Numba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-resolution to a minimum.; On use in a JITed trace, each C++ type or function call is refined to the; actual, concrete types and type-specific overloads, with templates; instantiated as-needed.; Where possible, lowering is kept generic to reduce the number of callbacks; in Numba's compilation chain. Examples; --------. The following, non-exhaustive, set of examples gives an idea of the; current lev",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:2158,integrat,integration,2158,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,1,['integrat'],['integration']
Deployability,"validating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:219571,release,release,219571,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability,"value for storing into ``x``. Dependency does not propagate through stores of dependent pointer; values because doing so would allow dependency to outlive the; full-expression which produced the original value. For example, the; address of an instance variable could be written to some global; location and then freely accessed during the lifetime of the local,; or a function could return an inner pointer of an object and store; it to a local. These cases would be potentially impossible to; reason about and so would basically prevent any optimizations based; on imprecise lifetime. There are also uncommon enough to make it; reasonable to require the precise-lifetime annotation if someone; really wants to rely on them. Dependency does propagate through return values of pointer type.; The compelling source of need for this rule is a property accessor; which returns an un-autoreleased result; the calling function must; have the chance to operate on the value, e.g. to retain it, before; ARC releases the original pointer. Note again, however, that; dependence does not survive a store, so ARC does not guarantee the; continued validity of the return value past the end of the; full-expression. .. _arc.optimization.object_lifetime:. No object lifetime extension; ----------------------------. If, in the formal computation history of the program, an object ``X``; has been deallocated by the time of an observable side-effect, then; ARC must cause ``X`` to be deallocated by no later than the occurrence; of that side-effect, except as influenced by the re-ordering of the; destruction of objects. .. admonition:: Rationale. This rule is intended to prohibit ARC from observably extending the; lifetime of a retainable object, other than as specified in this; document. Together with the rule limiting the transformation of; releases, this rule requires ARC to eliminate retains and release; only in pairs. ARC's power to reorder the destruction of objects is critical to its; ability to do an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:82186,release,releases,82186,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['releases']
Deployability,"value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisancePdf, which given a model configuration (or the global pdf and the; observables), factorizes from the model pdf the constraint probability density functions for the nuisance parameters; and builds a global nuisance pdf. This function can then be used in the HybridCalculator or in the BayesianCalculator; with the option ""TOYMC"".; . HypotestInverter and HypoTestInverterResult. Several improvements and bug fixes in merging results and in computing the observed and expected limits.; Provide support now for using the AsympoticCalculator. MCMCCalculator. Add now possibility to store in the chain only the parameter of interested via the method MCMCCalculator::SetChainParameters. This saves memory in case of models with a; large number of nuisance parameters. . Test Statistics classes. Make a more robust evaluation of the ProfileLikelihoodTestStat. Use RooMinimizer and give possibility to use; different minimizer, via ProfileLikelihoodTestStat::SetMinimizer. The print level of minimization can also be; controlled via ProfileLikelihoodTestStat::SetPrintLevel. Activate also the RooFit ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:8171,configurat,configuration,8171,roofit/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html,1,['configurat'],['configuration']
Deployability,"var will not be automatically released during; deallocation. .. _arc.ownership.semantics:. Semantics; ---------. There are five :arc-term:`managed operations` which may be performed on an; object of retainable object pointer type. Each qualifier specifies different; semantics for each of these operations. It is still undefined behavior to; access an object outside of its lifetime. A load or store with ""primitive semantics"" has the same semantics as the; respective operation would have on an ``void*`` lvalue with the same alignment; and non-ownership qualification. :arc-term:`Reading` occurs when performing a lvalue-to-rvalue conversion on an; object lvalue. * For ``__weak`` objects, the current pointee is retained and then released at; the end of the current full-expression. In particular, messaging a ``__weak``; object keeps the object retained until the end of the full expression. .. code-block:: objc. __weak MyObject *weakObj;. void foo() {; // weakObj is retained before the message send and released at the end of; // the full expression.; [weakObj m];; }. This must execute atomically with respect to assignments and to the final; release of the pointee.; * For all other objects, the lvalue is loaded with primitive semantics. :arc-term:`Assignment` occurs when evaluating an assignment operator. The; semantics vary based on the qualification:. * For ``__strong`` objects, the new pointee is first retained; second, the; lvalue is loaded with primitive semantics; third, the new pointee is stored; into the lvalue with primitive semantics; and finally, the old pointee is; released. This is not performed atomically; external synchronization must be; used to make this safe in the face of concurrent loads and stores.; * For ``__weak`` objects, the lvalue is updated to point to the new pointee,; unless the new pointee is an object currently undergoing deallocation, in; which case the lvalue is updated to a null pointer. This must execute; atomically with respect to other ass",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:38294,release,released,38294,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['released']
Deployability,"variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the build directory:. .. code-block:: console. $ cmake --build . The ``--build`` option tells ``cmake`` to invoke the underlying build; tool (``make``, ``ninja``, ``xcodebuild``, ``msbuild``, etc.). The underlying build tool can be invoked directly, of course, but; the ``--build`` option is portable. #. After LLVM has finished building, install it from the build directory:. .. code-block:: console. $ cmake --build . --target install. The ``--target`` option with ``install`` parameter in addition to; the ``--build`` option tells ``cmake`` to build the ``install`` target. It is possible to set a different install prefix at installation time; by invoking the ``cmake_install.cmake`` script generated in the; build directory:. .. code-block:: console. $ cmake -DCMAKE_INSTALL_PREFIX=/tmp/llvm -P cmake_install.cmake. .. _Basic CMake usage:; .. _Usage:. Basic CMake usage; =================. This section explains basic aspects of CMake; which you may need in your day-to-day usage. CMake comes with extensive documentation, in the form of html files, and as; online help accessible via the ``cmake`` executable itself. Execute ``cmake; --help`` for further help options. CMake allows you to specify a build tool (e.g., GNU make, Visual Studio,; or Xcode). If not specified on the command line, CMake tries to guess which; build tool to use, based on your environment. Once it has identified your; build tool, CMake uses the corresponding *Generator* to create files for your; build tool (e.g., Makefiles or Visual Studio or Xcode project files). You can; explicitly specify the generator with the command line option ``-G ""N",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:3533,install,install,3533,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,2,['install'],"['install', 'installation']"
Deployability,"variables, installing them one at a; time. For each variable we put into the symbol table, we remember the; previous value that we replace in OldBindings. .. code-block:: c++. // Emit the initializer before adding the variable to scope, this prevents; // the initializer from referencing the variable itself, and permits stuff; // like this:; // var a = 1 in; // var a = a in ... # refers to outer 'a'.; Value *InitVal;; if (Init) {; InitVal = Init->codegen();; if (!InitVal); return nullptr;; } else { // If not specified, use 0.0.; InitVal = ConstantFP::get(*TheContext, APFloat(0.0));; }. AllocaInst *Alloca = CreateEntryBlockAlloca(TheFunction, VarName);; Builder->CreateStore(InitVal, Alloca);. // Remember the old variable binding so that we can restore the binding when; // we unrecurse.; OldBindings.push_back(NamedValues[VarName]);. // Remember this binding.; NamedValues[VarName] = Alloca;; }. There are more comments here than code. The basic idea is that we emit; the initializer, create the alloca, then update the symbol table to; point to it. Once all the variables are installed in the symbol table,; we evaluate the body of the var/in expression:. .. code-block:: c++. // Codegen the body, now that all vars are in scope.; Value *BodyVal = Body->codegen();; if (!BodyVal); return nullptr;. Finally, before returning, we restore the previous variable bindings:. .. code-block:: c++. // Pop all our variables from scope.; for (unsigned i = 0, e = VarNames.size(); i != e; ++i); NamedValues[VarNames[i].first] = OldBindings[i];. // Return the body computation.; return BodyVal;; }. The end result of all of this is that we get properly scoped variable; definitions, and we even (trivially) allow mutation of them :). With this, we completed what we set out to do. Our nice iterative fib; example from the intro compiles and runs just fine. The mem2reg pass; optimizes all of our stack variables into SSA registers, inserting PHI; nodes where needed, and our front-end remains simple: no",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:27983,update,update,27983,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['update'],['update']
Deployability,"vate:; protected:; };. * ``ELAAMS_Leave`` (in configuration: ``Leave``); Keep existing empty lines after access modifiers.; MaxEmptyLinesToKeep is applied instead. * ``ELAAMS_Always`` (in configuration: ``Always``); Always add empty line after access modifiers if there are none.; MaxEmptyLinesToKeep is applied also. .. code-block:: c++. struct foo {; private:. int i;; protected:. int j;; /* comment */; public:. foo() {}; private:. protected:. };. .. _EmptyLineBeforeAccessModifier:. **EmptyLineBeforeAccessModifier** (``EmptyLineBeforeAccessModifierStyle``) :versionbadge:`clang-format 12` :ref:`¶ <EmptyLineBeforeAccessModifier>`; Defines in which cases to put empty line before access modifiers. Possible values:. * ``ELBAMS_Never`` (in configuration: ``Never``); Remove all empty lines before access modifiers. .. code-block:: c++. struct foo {; private:; int i;; protected:; int j;; /* comment */; public:; foo() {}; private:; protected:; };. * ``ELBAMS_Leave`` (in configuration: ``Leave``); Keep existing empty lines before access modifiers. * ``ELBAMS_LogicalBlock`` (in configuration: ``LogicalBlock``); Add empty line only when access modifier starts a new logical block.; Logical block is a group of one or more member fields or functions. .. code-block:: c++. struct foo {; private:; int i;. protected:; int j;; /* comment */; public:; foo() {}. private:; protected:; };. * ``ELBAMS_Always`` (in configuration: ``Always``); Always add empty line before access modifiers unless access modifier; is at the start of struct or class definition. .. code-block:: c++. struct foo {; private:; int i;. protected:; int j;; /* comment */. public:; foo() {}. private:. protected:; };. .. _ExperimentalAutoDetectBinPacking:. **ExperimentalAutoDetectBinPacking** (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <ExperimentalAutoDetectBinPacking>`; If ``true``, clang-format detects whether function calls and; definitions are formatted with one parameter per line. Each call can be bin-packed",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:62106,configurat,configuration,62106,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"ve a sufficiently modern Xcode, or you will likely need to upgrade until you; do. Windows does not have a ""system compiler"", so you must install either Visual; Studio 2019 (or later), or a recent version of mingw64. FreeBSD 10.0 and newer; have a modern Clang as the system compiler. However, some Linux distributions and some other or older BSDs sometimes have; extremely old versions of GCC. These steps attempt to help you upgrade you; compiler even on such a system. However, if at all possible, we encourage you; to use a recent version of a distribution with a modern system compiler that; meets these requirements. Note that it is tempting to install a prior; version of Clang and libc++ to be the host compiler, however libc++ was not; well tested or set up to build on Linux until relatively recently. As; a consequence, this guide suggests just using libstdc++ and a modern GCC as the; initial host in a bootstrap, and then using Clang (and potentially libc++). The first step is to get a recent GCC toolchain installed. The most common; distribution on which users have struggled with the version requirements is; Ubuntu Precise, 12.04 LTS. For this distribution, one easy option is to install; the `toolchain testing PPA`_ and use it to install a modern GCC. There is; a really nice discussions of this on the `ask ubuntu stack exchange`_ and a; `github gist`_ with updated commands. However, not all users can use PPAs and; there are many other distributions, so it may be necessary (or just useful, if; you're here you *are* doing compiler development after all) to build and install; GCC from source. It is also quite easy to do these days. .. _toolchain testing PPA:; https://launchpad.net/~ubuntu-toolchain-r/+archive/test; .. _ask ubuntu stack exchange:; https://askubuntu.com/questions/466651/how-do-i-use-the-latest-gcc-on-ubuntu/581497#58149; .. _github gist:; https://gist.github.com/application2000/73fd6f4bf1be6600a2cf9f56315a2d91. Easy steps for installing a specific version ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:16022,install,installed,16022,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['install'],['installed']
Deployability,"ve already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-trap-handler-abi:. Trap Handler ABI; ~~~~~~~~~~~~~~~~. For code objects generated by the AMDGPU backend for HSA [HSA]_ compatible; runtimes (see :ref:`amdgpu-os`), the runtime installs a trap handler that; supports the ``s_trap`` instruction. For usage see:. - :ref:`amdgpu-trap-handler-for-amdhsa-os-v2-table`; - :ref:`amdgpu-trap-handler-for-amdhsa-os-v3-table`; - :ref:`amdgpu-trap-handler-for-amdhsa-os-v4-onwards-table`. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V2; :name: amdgpu-trap-handler-for-amdhsa-os-v2-table. =================== =============== =============== =======================================; Usage Code Sequence Trap Handler Description; Inputs; =================== =============== =============== =======================================; reserved ``s_trap 0x00`` Reserved by hardware.; ``debugtrap(arg)`` ``s_trap 0x01`` ``SGPR0-1``: Reserved for Finalizer HSA ``debugtrap``; ``queue_ptr`` intrinsic (not implemented).; ``VGPR0``:; ``arg``; ``llvm.trap`` ``s_trap 0x02`` ``SGPR0-1``: Causes wave to be halted with the PC at; ``queue_ptr`` the trap instruction. The associated; queue is signalled to put it in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:380385,install,installs,380385,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['install'],['installs']
Deployability,"ve relocation, computed as ``pc - entry``. To decode, a user has to; compute ``entry + *entry``. The size of each entry depends on the code model. With large and medium sized; code models, the entry size matches pointer size. For any smaller code model; the entry size is just 32 bits. Encoding Options; ----------------. Optional encoding options can be passed in the first ``MDString`` operator:; ``<section>!<options>``. The following options are available:. * ``C`` -- Compress constant integers of size 2-8 bytes as ULEB128; this; includes the function size (but excludes the PC entry). For example, ``foo!C`` will emit into section ``foo`` with all constants; encoded as ULEB128. Guarantees on Code Generation; =============================. Attaching ``!pcsections`` metadata to LLVM IR instructions *shall not* affect; optimizations or code generation outside the requested PC sections. While relying on LLVM IR metadata to request PC sections makes the above; guarantee relatively trivial, propagation of metadata through the optimization; and code generation pipeline has the following guarantees. Metadata Propagation; --------------------. In general, LLVM *does not make any guarantees* about preserving IR metadata; (attached to an ``Instruction``) through IR transformations. When using PC; sections metadata, this guarantee is unchanged, and ``!pcsections`` metadata is; remains *optional* until lowering to machine IR (MIR). Note for Code Generation; ------------------------. As with other LLVM IR metadata, there are no requirements for LLVM IR; transformation passes to preserve ``!pcsections`` metadata, with the following; exceptions:. * The ``AtomicExpandPass`` shall preserve ``!pcsections`` metadata; according to the below rules 1-4. When translating LLVM IR to MIR, the ``!pcsections`` metadata shall be copied; from the source ``Instruction`` to the target ``MachineInstr`` (set with; ``MachineInstr::setPCSections()``). The instruction selectors and MIR; optimization pass",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PCSectionsMetadata.rst:2958,pipeline,pipeline,2958,interpreter/llvm-project/llvm/docs/PCSectionsMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PCSectionsMetadata.rst,1,['pipeline'],['pipeline']
Deployability,"ved by using; ``SpacesInParens`` with ``Custom`` and by setting all; ``SpacesInParensOptions`` to ``true`` except for ``InCStyleCasts`` and; ``InEmptyParentheses``. .. _SpacesInSquareBrackets:. **SpacesInSquareBrackets** (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <SpacesInSquareBrackets>`; If ``true``, spaces will be inserted after ``[`` and before ``]``.; Lambdas without arguments or unspecified size array declarations will not; be affected. .. code-block:: c++. true: false:; int a[ 5 ]; vs. int a[5];; std::unique_ptr<int[]> foo() {} // Won't be affected. .. _Standard:. **Standard** (``LanguageStandard``) :versionbadge:`clang-format 3.7` :ref:`¶ <Standard>`; Parse and format C++ constructs compatible with this standard. .. code-block:: c++. c++03: latest:; vector<set<int> > x; vs. vector<set<int>> x;. Possible values:. * ``LS_Cpp03`` (in configuration: ``c++03``); Parse and format as C++03.; ``Cpp03`` is a deprecated alias for ``c++03``. * ``LS_Cpp11`` (in configuration: ``c++11``); Parse and format as C++11. * ``LS_Cpp14`` (in configuration: ``c++14``); Parse and format as C++14. * ``LS_Cpp17`` (in configuration: ``c++17``); Parse and format as C++17. * ``LS_Cpp20`` (in configuration: ``c++20``); Parse and format as C++20. * ``LS_Latest`` (in configuration: ``Latest``); Parse and format using the latest supported language version.; ``Cpp11`` is a deprecated alias for ``Latest``. * ``LS_Auto`` (in configuration: ``Auto``); Automatic detection based on the input. .. _StatementAttributeLikeMacros:. **StatementAttributeLikeMacros** (``List of Strings``) :versionbadge:`clang-format 12` :ref:`¶ <StatementAttributeLikeMacros>`; Macros which are ignored in front of a statement, as if they were an; attribute. So that they are not parsed as identifier, for example for Qts; emit. .. code-block:: c++. AlignConsecutiveDeclarations: true; StatementAttributeLikeMacros: []; unsigned char data = 'x';; emit signal(data); // This is parsed as variable declaration. AlignCo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:129268,configurat,configuration,129268,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"vely, you can use the ``amdgpu-arch`` tool that comes with Clang to list the GPU architecture on your system:. .. code-block:: shell. amdgpu-arch. You can use ``--offload-arch=native`` to automatically detect the GPU architectures on your system:. .. code-block:: shell. clang++ --offload-arch=native -xhip sample.cpp -o sample. Path Setting for Dependencies; =============================. Compiling a HIP program depends on the HIP runtime and device library. The paths to the HIP runtime and device libraries; can be specified either using compiler options or environment variables. The paths can also be set through the ROCm path; if they follow the ROCm installation directory structure. Order of Precedence for HIP Path; --------------------------------. 1. ``--hip-path`` compiler option; 2. ``HIP_PATH`` environment variable *(use with caution)*; 3. ``--rocm-path`` compiler option; 4. ``ROCM_PATH`` environment variable *(use with caution)*; 5. Default automatic detection (relative to Clang or at the default ROCm installation location). Order of Precedence for Device Library Path; -------------------------------------------. 1. ``--hip-device-lib-path`` compiler option; 2. ``HIP_DEVICE_LIB_PATH`` environment variable *(use with caution)*; 3. ``--rocm-path`` compiler option; 4. ``ROCM_PATH`` environment variable *(use with caution)*; 5. Default automatic detection (relative to Clang or at the default ROCm installation location). .. list-table::; :header-rows: 1. * - Compiler Option; - Environment Variable; - Description; - Default Value; * - ``--rocm-path=<path>``; - ``ROCM_PATH``; - Specifies the ROCm installation path.; - Automatic detection; * - ``--hip-path=<path>``; - ``HIP_PATH``; - Specifies the HIP runtime installation path.; - Determined by ROCm directory structure; * - ``--hip-device-lib-path=<path>``; - ``HIP_DEVICE_LIB_PATH``; - Specifies the HIP device library installation path.; - Determined by ROCm directory structure. .. note::. We recommend using the comp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HIPSupport.rst:4269,install,installation,4269,interpreter/llvm-project/clang/docs/HIPSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HIPSupport.rst,1,['install'],['installation']
Deployability,"ven time. We can conclude; that the floating point PRF was the only register file used for the example, and; that it was never resource constrained. The register file statistics are; displayed by using the command option ``-all-stats`` or; ``-register-file-stats``. In this example, we can conclude that the IPC is mostly limited by data; dependencies, and not by resource pressure. Instruction Flow; ^^^^^^^^^^^^^^^^; This section describes the instruction flow through the default pipeline of; :program:`llvm-mca`, as well as the functional units involved in the process. The default pipeline implements the following sequence of stages used to; process instructions. * Dispatch (Instruction is dispatched to the schedulers).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:34370,pipeline,pipeline,34370,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['pipeline'],"['pipeline', 'pipelines']"
Deployability,"ver(""fastcgi:9000"");; ```. In fact, the FastCGI interface can run in parallel to http server. One can just call:. ```cpp; serv = new THttpServer(""http:8080"");; serv->CreateEngine(""fastcgi:9000"");; ```. One could specify a debug parameter to be able to adjust the FastCGI configuration on the web server:. ```cpp; serv->CreateEngine(""fastcgi:9000?debug=1"");; ```. By default 10 threads are used to process FastCGI requests. This number can be changed with ""thrds"" url parameter:. ```cpp; serv->CreateEngine(""fastcgi:9000?thrds=20"");; ```. If `thrds=0` parameter specified, the only thread will be use to received and process all requests. All user access will be ruled by the main web server. Authorized account names could be used to configure access restriction in THttpServer. ### Configure fastcgi with Apache2. Since Apache version 2.4 FastCGI is directly supported - there is no need to compile and install external modules any more.; One only need to enable `mod_proxy` and `mod_proxy_fcgi` modules and add following line to **Apache2** configuration file:. ```; ProxyPass ""/root.app/"" ""fcgi://localhost:9000/"" enablereuse=on; ```. More information can be found in [FastCGI proxy docu](https://httpd.apache.org/docs/2.4/mod/mod_proxy_fcgi.html).; After restarting apache server one should be able to open address: `http://apache_host_name/root.app/`.; There are many ways to configure user authentication in Apache. Example of digest auth for FastCGI server:. ```; <Location ""/root.app/"">; AuthType Digest; AuthName ""root""; AuthDigestDomain ""/root.app/"" ""root""; AuthDigestProvider file; AuthUserFile ""/srv/auth/auth.txt""; Require valid-user; </Location>; ```. ### Configure fastcgi with lighttpd. An example of configuration file for **lighttpd** server is:. ```; server.modules += ( ""mod_fastcgi"" ); fastcgi.server = (; ""/root.app"" =>; (( ""host"" => ""192.168.1.11"",; ""port"" => 9000,; ""check-local"" => ""disable"",; ""docroot"" => ""/""; )); ); ```. Be aware, that with *lighttpd* one should specify IP",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:11293,configurat,configuration,11293,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['configurat'],['configuration']
Deployability,"ver; - ``clang-dxc`` for the ``dxc`` driver. For example, when calling ``x86_64-pc-linux-gnu-clang-g++``,; the driver will first attempt to use the configuration file named::. x86_64-pc-linux-gnu-clang++.cfg. If this file is not found, it will attempt to use the name found; in the executable instead::. x86_64-pc-linux-gnu-clang-g++.cfg. Note that options such as ``--driver-mode=``, ``--target=``, ``-m32`` affect; the search algorithm. For example, the aforementioned executable called with; ``-m32`` argument will instead search for::. i386-pc-linux-gnu-clang++.cfg. If none of the aforementioned files are found, the driver will instead search; for separate driver and target configuration files and attempt to load both.; The former is named ``<driver>.cfg`` while the latter is named; ``<triple>.cfg``. Similarly to the previous variants, the canonical driver name; will be preferred, and the compiler will fall back to the actual name. For example, ``x86_64-pc-linux-gnu-clang-g++`` will attempt to load two; configuration files named respectively::. clang++.cfg; x86_64-pc-linux-gnu.cfg. with fallback to trying::. clang-g++.cfg; x86_64-pc-linux-gnu.cfg. It is not an error if either of these files is not found. The configuration file consists of command-line options specified on one or; more lines. Lines composed of whitespace characters only are ignored as well as; lines in which the first non-blank character is ``#``. Long options may be split; between several lines by a trailing backslash. Here is example of a; configuration file:. ::. # Several options on line; -c --target=x86_64-unknown-linux-gnu. # Long option split between lines; -I/usr/lib/gcc/x86_64-linux-gnu/5.4.0/../../../../\; include/c++/5.4.0. # other config files may be included; @linux.options. Files included by ``@file`` directives in configuration files are resolved; relative to the including file. For example, if a configuration file; ``~/.llvm/target.cfg`` contains the directive ``@os/linux.opts``, the fil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:33850,configurat,configuration,33850,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['configurat'],['configuration']
Deployability,"verts automatically to an integer, which represents the status code of the fit. If the Fit method is used as before, there is a no visible change for the user.; When using the fit option ""S"", the TFitResultPtr will now contain a pointer to the new TFitResult class. It will behave as a smart pointer to TFitResult,; by using the -> operator the user can call the TFitResult methods or access directly the TFitResult object, by using the de-reference operator * or; TFitResultPtr::Get().; The TFitResult class derives from the ROOT::Math::FitResult, which contains all the result information from a fit and from TNamed. It provides then I/O capabilities for the FitResult object and convenience methods like Print(), Write(), GetCovarianceMatrix() and GetCorrelationMatrix() which return a TMatrixDSym object.; Example of usage:; ; TFitResult r = h->Fit(""myFunc"",""S"");; TMatrixDSym cov = r->GetCovarianceMatrix(); // to access the covariance matrix; Double_t chi2 = r->Chi2(); // to retrieve the fit chi2; Double_t par0 = r->Value(0); // retrieve the value for the parameter 0; Double_t err0 = r->Error(0); // retrieve the error for the parameter 0; r->Print(""V""); // print full information of fit including covariance matrix; r->Write(); // store the result in a file. FitPanel. Added predefined 2D Functions.; Addition of new minimization algorithms from the GSL library and foreseen the addition of; genetic minimizers when will be released.; Fixed up to three bugs from the previous release; Added the Update Button. This way the user can update the content of the fitpanel with all the new objects and functions created in the current ROOT session.; Changed the way the TF1s were being copied internally. Instead of using TObject::Clone, now it's using the TF1 copy constructor. new tutorial rebin.C; This tutorial illustrates how to:. create a variable binwidth histogram with a binning such; that the population per bin is about the same.; rebin a variable binwidth histogram into another one. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v526/index.html:5981,release,released,5981,hist/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v526/index.html,3,"['release', 'update']","['release', 'released', 'update']"
Deployability,"very task; on a worker will now run only in the worker processes. Previously, it was also run eagerly at the point of calling, that; is in the main user process. This is done to better separate the user driver environment and the worker environments. If; necessary, the function passed to `initialize` can be called directly by the user in the main application to reproduce; the same effect as before.; * Some internal details of the `RDataFrame` implementation were reworked to decrease memory usage and runtime of programs; with very deep computation graphs (more than O(10K) nodes in the same branch). Preliminary tests indicate between 30%; and a factor 2.5 in memory decrease. This improvement is transparent for `RDataFrame` users. ## Graphics backends; The ROOT release 6.32 brings a lot of impressive enhancements to the Web Graphics package, greatly surpassing the features and capabilities of version 6.30. ; This update provides users with a more robust Web Graphics. * The JSROOT version has been updated to v7.7. ## 2D Graphics Libraries. - TMultiGraph: Add the objects from the list of functions in legend produce by TLegend.; - Implement the IsInside method for TEllipse, TCrown and TDiamond. Also, a new graphics example `inside.C` has been added.; - Two new methods in TColor: `ListColors()` and `GetColorByname()`.; - Make sure the option `L` draws closed polygon for `TH2Poly`.; - Use Tex Gyre fonts for sans serif (similar to Helvetica) .; - The new method `TPad::ModifiedUpdate` is short cut to call `Modified()` and `Update()` in a single call. On Mac with Cocoa, it performs an additional ProcessEvents().; - Improve `SetTextSize` error: show code and values.; - Very long text string generated a wrong SVG file.; - Fix the option `SAME` works for `TGraph2D`.; - Implement the title for the palette of a `TH3`.; - Fix typo in `TLegend::PaintPrimitives()` and improve the exclusion graphs legend.; - `SetParameters(…)` or `SetParameter(…)` on a TF1 reset the properties of the ax",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:16553,update,updated,16553,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['update'],['updated']
Deployability,"ves `RVec` elements at the specified indices.; - handy aliases `ROOT::RVecI`, `ROOT::RVecD`, `ROOT::RVecF`, ..., have been introduced as short-hands for `RVec<int>`, `RVec<double>`, `RVec<float>`, ...; - Add `VecOps::StableArgsort` and `VecOps::StableSort` operations. ## RooFit Libraries. ### Experimental CUDA support for RooFit's `BatchMode`. RooFit's [`BatchMode`](https://root.cern/doc/master/classRooAbsPdf.html#a8f802a3a93467d5b7b089e3ccaec0fa8) has been around; [since ROOT 6.20](https://root.cern/doc/v620/release-notes.html#fast-function-evaluation-and-vectorisation).; It was further [improved in ROOT 6.24](https://root.cern/doc/v624/release-notes.html#massive-speed-up-of-roofits-batchmode-on-cpus-with-vector-extensions) to use vector extensions of modern CPUs without recompiling ROOT, introducing the new `RooBatchCompute` library as a backend that is compiled multiple times for different instruction sets.; With this release, `RooBatchCompute` is also compiled with the Nvidia CUDA compiler to support the computation on GPUs if supported by the RooFit object.; You can use the CUDA mode by passing `""cuda""` to the `BatchMode()` command argument:; ```C++; model.fitTo(data); // not using the batch mode; model.fitTo(data, RooFit::BatchMode(true)); // using the BatchMode on CPU (RooFit::BatchMode(""cpu"") is equivalent); model.fitTo(data, RooFit::BatchMode(""cuda"")); // using the new CUDA backend; ```. The `RooBatchCompute` backend now also supports ROOT's implicit multithreading (similar to RDataFrame), which can be enabled as follows:; ```C++; ROOT::EnableImplicitMT(nThreads);; ```. For more information, please have a look at this [contribution to the ACAT 2021 conference](https://indico.cern.ch/event/855454/contributions/4596763/) or consult the [RooBatchComupte README](https://github.com/root-project/root/tree/v6-26-00-patches/roofit/batchcompute).; The README also describes how to enable BatchMode support for your own PDFs. ### Parallel calculation of likelihood gradi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:15414,release,release,15414,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['release'],['release']
Deployability,"ves the; email format unchanged besides the commit URL. Straw Man Migration Plan; ========================. Step #1 : Before The Move; -------------------------. 1. Update docs to mention the move, so people are aware of what is going on.; 2. Set up a read-only version of the GitHub project, mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up commits from the GitHub repository.; 6. LNT and llvmlab have to be updated: they rely on unique monotonically; increasing integer across branch [MatthewsRevNum]_.; 7. Instruct downstream integrators to pick up commits from the GitHub; repository.; 8. Review and prepare an update for the LLVM documentation. Until this point nothing has changed for developers, it will just; boil down to a lot of work for buildbot and other infrastructure; owners. The migration will pause here until all dependencies have cleared, and all; problems have been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account information, and add them to the project.; 10. Switch the SVN repository to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Step #4 : Post Move; -------------------. 13. Archive the SVN repository.; 14. Update links on the LLVM website pointing to viewvc/klaus/phab etc. to; point to GitHub instead. GitHub Repository Description; =============================. Monorepo; ----------------. The LLVM git repository hosted at https://github.com/llvm/llvm-project contains all; sub-projects in a single ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:7519,integrat,integrators,7519,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['integrat'],['integrators']
Deployability,"vesAll();; }. Now when we run our pass, we get this output:. .. code-block:: console. $ opt -load lib/LLVMHello.so -gvn -hello -licm --debug-pass=Structure < hello.bc > /dev/null; Pass Arguments: -gvn -hello -licm; ModulePass Manager; FunctionPass Manager; Dominator Tree Construction; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Memory Dependence Analysis; Global Value Numbering; Hello World Pass; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Which shows that we don't accidentally invalidate dominator information; anymore, and therefore do not have to compute it twice. .. _writing-an-llvm-pass-releaseMemory:. The ``releaseMemory`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void releaseMemory();. The ``PassManager`` automatically determines when to compute analysis results,; and how long to keep them around for. Because the lifetime of the pass object; itself is effectively the entire duration of the compilation process, we need; some way to free analysis results when they are no longer useful. The; ``releaseMemory`` virtual method is the way to do this. If you are writing an analysis or any other pass that retains a significant; amount of state (for use by another pass which ""requires"" your pass and uses; the :ref:`getAnalysis <writing-an-llvm-pass-getAnalysis>` method) you should; implement ``releaseMemory`` to, well, release the memory allocated to maintain; this internal state. This method is called after the ``run*`` method for the; class, before the next call of ``run*`` in your pass. Registering dynamically loaded passes; =====================================. *Size matters* when constructing production quality tools using LLVM, both for; the purposes of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:46971,release,releaseMemory,46971,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['release'],['releaseMemory']
Deployability,"vide a filename prefix to collect the GlobalISel rule coverage""); endif(). # Add path for custom modules; list(INSERT CMAKE_MODULE_PATH 0; ""${CMAKE_CURRENT_SOURCE_DIR}/cmake""; ""${CMAKE_CURRENT_SOURCE_DIR}/cmake/modules""; ""${LLVM_COMMON_CMAKE_UTILS}/Modules""; ). # Generate a CompilationDatabase (compile_commands.json file) for our build,; # for use by clang_complete, YouCompleteMe, etc.; set(CMAKE_EXPORT_COMPILE_COMMANDS 1). option(LLVM_INSTALL_BINUTILS_SYMLINKS; ""Install symlinks from the binutils tool names to the corresponding LLVM tools."" OFF). option(LLVM_INSTALL_CCTOOLS_SYMLINKS; ""Install symlinks from the cctools tool names to the corresponding LLVM tools."" OFF). # By default we use symlinks on Unix platforms and copy binaries on Windows; # If you have the correct setup on Windows you can use this option to enable; # symlinks and save a lot of diskspace.; option(LLVM_USE_SYMLINKS ""Use symlinks instead of copying binaries"" ${CMAKE_HOST_UNIX}). option(LLVM_INSTALL_UTILS ""Include utility binaries in the 'install' target."" OFF). option(LLVM_INSTALL_TOOLCHAIN_ONLY ""Only include toolchain files in the 'install' target."" OFF). # Unfortunatly Clang is too eager to search directories for module maps, which can cause the; # installed version of the maps to be found when building LLVM from source. Therefore we turn off; # the installation by default. See llvm.org/PR31905.; option(LLVM_INSTALL_MODULEMAPS ""Install the modulemap files in the 'install' target."" OFF). option(LLVM_USE_FOLDERS ""Enable solution folders in Visual Studio. Disable for Express versions."" ON); if ( LLVM_USE_FOLDERS ); set_property(GLOBAL PROPERTY USE_FOLDERS ON); endif(). include(VersionFromVCS). option(LLVM_APPEND_VC_REV; ""Embed the version control system revision in LLVM"" ON). set(LLVM_FORCE_VC_REVISION; """" CACHE STRING ""Force custom VC revision for LLVM_APPEND_VC_REV""). set(LLVM_FORCE_VC_REPOSITORY; """" CACHE STRING ""Force custom VC repository for LLVM_APPEND_VC_REV""). option(LLVM_TOOL_LLVM_DRIVER_B",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:13979,install,install,13979,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['install'],['install']
Deployability,"view:. Overview; ________. Taint analysis works by checking for the occurrence of special operations during the symbolic execution of the program.; Taint analysis defines sources, sinks, and propagation rules. It identifies errors by detecting a flow of information that originates from a taint source, reaches a taint sink, and propagates through the program paths via propagation rules.; A source, sink, or an operation that propagates taint is mainly domain-specific knowledge, but there are some built-in defaults provided by :ref:`alpha-security-taint-TaintPropagation`.; It is possible to express that a statement sanitizes tainted values by providing a ``Filters`` section in the external configuration (see :ref:`clangsa-taint-configuration-example` and :ref:`clangsa-taint-filter-details`).; There are no default filters defined in the built-in settings.; The checker's documentation also specifies how to provide a custom taint configuration with command-line options. .. _clangsa-taint-configuration-example:. Example configuration file; __________________________. .. code-block:: yaml. # The entries that specify arguments use 0-based indexing when specifying; # input arguments, and -1 is used to denote the return value. Filters:; # Filter functions; # Taint is sanitized when tainted variables are pass arguments to filters. # Filter function; # void cleanse_first_arg(int* arg); #; # Result example:; # int x; // x is tainted; # cleanse_first_arg(&x); // x is not tainted after the call; - Name: cleanse_first_arg; Args: [0]. Propagations:; # Source functions; # The omission of SrcArgs key indicates unconditional taint propagation,; # which is conceptually what a source does. # Source function; # size_t fread(void *ptr, size_t size, size_t nmemb, FILE * stream); #; # Result example:; # FILE* f = fopen(""file.txt"");; # char buf[1024];; # size_t read = fread(buf, sizeof(buf[0]), sizeof(buf)/sizeof(buf[0]), f);; # // both read and buf are tainted; - Name: fread; DstArgs: [0, -1].",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst:1939,configurat,configuration-example,1939,interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst,1,['configurat'],['configuration-example']
Deployability,"vironment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so` module. Finally, the top-level package ``cppyy``::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy; $ python -m pip install . --upgrade --no-deps. Please see the `pip documentation`_ for more options, such as developer mode. .. _`setuptools`: https://setuptools.readthedocs.io/; .. _`upstream`: https://root.cern.ch/download/; .. _`cmake documentation`: https://cmake.org/; .. _`pip documentation`: https://pip.pypa.io/; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:6150,install,install,6150,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,4,"['install', 'upgrade']","['install', 'upgrade']"
Deployability,"vironment!. You should not see any unexpected failures, but will see many unsupported; tests and expected failures:. ::. 114>Testing Time: 1124.66s; 114> Skipped : 39; 114> Unsupported : 21649; 114> Passed : 51615; 114> Expectedly Failed: 93; ========== Build: 114 succeeded, 0 failed, 321 up-to-date, 0 skipped ==========``. Alternatives to manual installation; ===================================; Instead of the steps above, to simplify the installation procedure you can use; `Chocolatey <https://chocolatey.org/>`_ as package manager.; After the `installation <https://chocolatey.org/install>`_ of Chocolatey,; run these commands in an admin shell to install the required tools:. .. code-block:: bat. choco install -y git cmake python3; pip3 install psutil. There is also a Windows; `Dockerfile <https://github.com/llvm/llvm-zorg/blob/main/buildbot/google/docker/windows-base-vscode2019/Dockerfile>`_; with the entire build tool chain. This can be used to test the build with a; tool chain different from your host installation or to create build servers. Next steps; ==========; 1. Read the documentation.; 2. Seriously, read the documentation.; 3. Remember that you were warned twice about reading the documentation. Test LLVM on the command line:; ------------------------------; The LLVM tests can be run by changing directory to the llvm source; directory and running:. .. code-block:: bat. c:\llvm> python ..\build\Release\bin\llvm-lit.py llvm\test. This example assumes that Python is in your PATH variable, which would be; after **Add Python to the PATH** was selected during Python installation.; If you had opened a command window prior to Python installation, you would; have to close and reopen it to get the updated PATH. A specific test or test directory can be run with:. .. code-block:: bat. c:\llvm> python ..\build\Release\bin\llvm-lit.py llvm\test\Transforms\Util. Build the LLVM Suite:; ---------------------; * The projects may still be built individually, but to build them",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst:8677,install,installation,8677,interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,1,['install'],['installation']
Deployability,"virtually; unwound. The* ``DW_OP_LLVM_call_frame_entry_reg`` *operation provides access; to registers in the virtually unwound calling frame.*. .. note::. GDB only implements ``DW_OP_entry_value`` when E is exactly; ``DW_OP_reg*`` or ``DW_OP_breg*; DW_OP_deref*``. .. _amdgpu-dwarf-location-description-operations:. A.2.5.4.4 Location Description Operations; #########################################. This section describes the operations that push location descriptions on the; stack. .. _amdgpu-dwarf-general-location-description-operations:. A.2.5.4.4.1 General Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces part of DWARF Version 5 section 2.5.1.3. 1. ``DW_OP_LLVM_offset`` *New*. ``DW_OP_LLVM_offset`` pops two stack entries. The first must be an integral; type value that represents a byte displacement B. The second must be a; location description L. It adds the value of B scaled by 8 (the byte size) to the bit offset of each; single location description SL of L, and pushes the updated L. It is an evaluation error if the updated bit offset of any SL is less than 0; or greater than or equal to the size of the location storage specified by; SL. 2. ``DW_OP_LLVM_offset_uconst`` *New*. ``DW_OP_LLVM_offset_uconst`` has a single unsigned LEB128 integer operand; that represents a byte displacement B. The operation is equivalent to performing ``DW_OP_constu B;; DW_OP_LLVM_offset``. *This operation is supplied specifically to be able to encode more field; displacements in two bytes than can be done with* ``DW_OP_lit*;; DW_OP_LLVM_offset``\ *.*. .. note::. Should this be named ``DW_OP_LLVM_offset_uconst`` to match; ``DW_OP_plus_uconst``, or ``DW_OP_LLVM_offset_constu`` to match; ``DW_OP_constu``?. 3. ``DW_OP_LLVM_bit_offset`` *New*. ``DW_OP_LLVM_bit_offset`` pops two stack entries. The first must be an; integral type value that represents a bit displacement B. The second must be; a location description L. It ad",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:98639,update,updated,98639,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['update'],['updated']
Deployability,"vl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. flat_atomic; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - Howe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:273582,release,released,273582,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['released']
Deployability,"vm-install-name-tool` [*options*] *input*. DESCRIPTION; -----------. :program:`llvm-install-name-tool` is a tool to manipulate dynamic shared library; install names and rpaths listed in a Mach-O binary. For most scenarios, it works as a drop-in replacement for Apple's; :program:`install_name_tool`. OPTIONS; --------; At least one of the following options are required, and some options can be; combined with other options. Options :option:`-add_rpath`, :option:`-delete_rpath`,; and :option:`-rpath` can be combined in an invocation only if they do not share; the same `<rpath>` value. .. option:: -add_rpath <rpath>. Add an rpath named ``<rpath>`` to the specified binary. Can be specified multiple; times to add multiple rpaths. Throws an error if ``<rpath>`` is already listed in; the binary. .. option:: -change <old_install_name> <new_install_name>. Change an install name ``<old_install_name>`` to ``<new_install_name>`` in the; specified binary. Can be specified multiple times to change multiple dependent shared; library install names. Option is ignored if ``<old_install_name>`` is not listed; in the specified binary. .. option:: -delete_rpath <rpath>. Delete an rpath named ``<rpath>`` from the specified binary. Can be specified multiple; times to delete multiple rpaths. Throws an error if ``<rpath>`` is not listed in; the binary. .. option:: -delete_all_rpaths. Deletes all rpaths from the binary. .. option:: --help, -h. Print a summary of command line options. .. option:: -id <name>. Change shared library's identification name under LC_ID_DYLIB to ``<name>`` in the; specified binary. If specified multiple times, only the last :option:`-id` option is; selected. Option is ignored if the specified Mach-O binary is not a dynamic shared library. .. option:: -rpath <old_rpath> <new_rpath>. Change an rpath named ``<old_rpath>`` to ``<new_rpath>`` in the specified binary. Can be specified; multiple times to change multiple rpaths. Throws an error if ``<old_rpath>`` is not liste",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-install-name-tool.rst:1257,install,install,1257,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-install-name-tool.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-install-name-tool.rst,1,['install'],['install']
Deployability,"vm/invitation>`_ directly. Once; accept the invitation, you'll get commit access. Prior to obtaining commit access, it is common practice to request that; someone with commit access commits on your behalf. When doing so, please; provide the name and email address you would like to use in the Author; property of the commit. For external tracking purposes, committed changes are automatically reflected; on a commits mailing list soon after the commit lands (e.g. llvm-commits_).; Note that these mailing lists are moderated, and it is not unusual for a large; commit to require a moderator to approve the email, so do not be concerned if a; commit does not immediately appear in the archives. If you have recently been granted commit access, these policies apply:. #. You are granted *commit-after-approval* to all parts of LLVM. For; information on how to get approval for a patch, please see :doc:`CodeReview`.; When approved, you may commit it yourself. #. You are allowed to commit patches without approval which you think are; obvious. This is clearly a subjective decision --- we simply expect you to; use good judgement. Examples include: fixing build breakage, reverting; obviously broken patches, documentation/comment changes, any other minor; changes. Avoid committing formatting- or whitespace-only changes outside of; code you plan to make subsequent changes to. Also, try to separate; formatting or whitespace changes from functional changes, either by; correcting the format first (ideally) or afterward. Such changes should be; highly localized and the commit message should clearly state that the commit; is not intended to change functionality, usually by stating it is; :ref:`NFC <nfc>`. #. You are allowed to commit patches without approval to those portions of LLVM; that you have contributed or maintain (i.e., have been assigned; responsibility for), with the proviso that such commits must not break the; build. This is a ""trust but verify"" policy, and commits of this nature ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:24443,patch,patches,24443,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['patch'],['patches']
Deployability,"volves tagging the ""final"" release; branch, updating documentation that refers to the release, and updating the; demo page. Update Documentation; ^^^^^^^^^^^^^^^^^^^^. Review the documentation in the release branch and ensure that it is up; to date. The ""Release Notes"" must be updated to reflect new features, bug; fixes, new known issues, and changes in the list of supported platforms.; The ""Getting Started Guide"" should be updated to reflect the new release; version number tag available from Subversion and changes in basic system; requirements. .. _tag:. Tag the LLVM Final Release; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Tag the final release sources:. ::. $ git tag -sa llvmorg-X.Y.Z; $ git push https://github.com/llvm/llvm-project.git llvmorg-X.Y.Z. Update the LLVM Website; ^^^^^^^^^^^^^^^^^^^^^^^. The website must be updated before the release announcement is sent out. Here; is what to do:. #. Check out the ``www-releases`` module from GitHub. #. Create a new sub-directory ``X.Y.Z`` in the releases directory. #. Copy and commit the ``llvm/docs`` and ``LICENSE.txt`` files into this new; directory. #. Update the ``releases/download.html`` file with links to the release; binaries on GitHub. #. Update the ``releases/index.html`` with the new release and link to release; documentation. #. After you push the changes to the www-releases repo, someone with admin; access must login to prereleases-origin.llvm.org and manually pull the new; changes into /data/www-releases/. This is where the website is served from. #. Finally checkout the llvm-www repo and update the main page; (``index.html`` and sidebar) to point to the new release and release; announcement. Announce the Release; ^^^^^^^^^^^^^^^^^^^^. Create a new post in the `Announce Category <https://discourse.llvm.org/c/announce>`_; once all the release tasks are complete. For X.1.0 releases, make sure to include a; link to the release notes in the post. For X.1.1+ releases, generate a changelog; using this command and add it to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:14773,release,releases,14773,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['release'],['releases']
Deployability,"w of data between environments, we will see more of that later.; With this tool you ca use any library or R package wich allows you to access a big amount of benefits to make statistical analysis.; ROOTR also has a R events processing system, which allows to use the R graphical system from `C++`. ## INSTALLATION; To install ROOTR please read first. - [https://root.cern.ch/building-root](https://root.cern.ch/building-root); - [https://root.cern.ch/build-prerequisites](https://root.cern.ch/build-prerequisites). ### COMPILING ROOTR ON MAC WITH CMAKE:; **NOTE:** Mac OSX Yosemite last xcode and without macports. **Prerequisites**. - xcode; - [xquartz](http://xquartz.macosforge.org/); - [R last version](https://www.r-project.org); - [cmake](https://cmake.org/download/). To compile with cmake added into ~/.profile. ~~~{.sh}; export PATH=$PATH:/Applications/CMake.app/Contents/bin/; ~~~; and. ~~~{.sh}; source ~/.profile; ~~~. Install needed R packages, open R and in the prompt type. ~~~{.sh}; install.packages(c('Rcpp','RInside')); ~~~; select a mirror and install. Install the next additional packages for R TMVA interface. ~~~{.sh}; install.packages(c('C50','RSNNS','e1071','xgboost')); ~~~. Download code from git repo. ~~~{.sh}; git clone http://root.cern.ch/git/root.git; ~~~. To compile ROOTR lets to create a compilation directory and to activate it use cmake -Dr=ON .. ~~~{.sh}; mkdir compile; cd compile; cmake -Dr=ON ..; make -j 5; ~~~. ### Compiling ROOTR on Gnu/Linux with CMake:; **NOTE:** Tested on Gnu/Linux Debian Jessie with gcc 4.9. **Prerequisities**; install; (For debian-based distros). ~~~{.sh}; apt-get install r-base r-base-dev; ~~~; Install needed R packages, open R and in the prompt type. ~~~{.sh}; install.packages(c('Rcpp','RInside')); ~~~; select a mirror and install. Install the next additional packages for R TMVA interface. ~~~{.sh}; install.packages(c('C50','RSNNS','e1071','xgboost')); ~~~. Download code from git repo. ~~~{.sh}; git clone http://root.cern.ch",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:1897,install,install,1897,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['install'],['install']
Deployability,"w option, *ValidationSize* has been added to the global options for `MethodDL`.; The same option is also available in the `PyKeras` method of `PyMVA`; - The fast tanh implementation from VDT is now used as activation function when training the network on CPU.; - Using `Cblas` from the GSL library is supported for CPU training when no other Blas libraries are found. However, it is strongly recommended, to use an optimized Blas implementation such as `libopenblas`, that is; available in cvmfs.; - Add several performance optimizations for both CPU and GPU versions of `MethodDL`. . ### Other New TMVA Features. - Add a new option to the `DataLoader` to switch off computation of correlation matrix. The new option is called *CalcCorrelations* and it should be used when a large number of input variables are; provided, otherwise TMVA will spend a long time in setting up the data set before training. ; ; - Build configuration:; - Add new cmake flags, `tmva-cpu` and `tmva-gpu`, which can be used to swicth on/off the CPU and GPU (based on CUDA) implementations of the TMVA Deep Learning module. `tmva-cpu` is enabled by; default if a Blas or CBlas library is found in the system. `tmva-gpu` is enabled when the cmake flag `cuda` is enabled and a compatible Cuda library is found. ; enabled if the corre; - Add possibility to independently configure building of optional pymva part of tmva with flag `-Dpymva=ON|OFF`. - New Cross Validation features:; - Add stratified splitting for cross validation.; - New plotting option in cross validation, average ROC curve. - Bugfixes:; - Fix bug in BDT training with imt=on; - Improved handling of large event numbers in cross validation using deterministic splitting. - Documentation:; - Update TMVA Users' guide. ## 2D Graphics Libraries. - Highlight mode is implemented for `TH1` and for `TGraph` classes. When; highlight mode is on, mouse movement over the bin will be represented; graphically. Histograms bins or graph points will be highlighted. Moreo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md:15448,configurat,configuration,15448,README/ReleaseNotes/v616/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md,1,['configurat'],['configuration']
Deployability,"w release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic sc0=1; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 3. buffer/global/flat_atomic sc1=1; atomicrmw release - system - global 1. buffer_wbl2 sc0=1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:310787,release,release,310787,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability,"w that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory oper",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:226865,release,released,226865,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['released']
Deployability,"w worker is stable, and; approval from Galina has been received (see last step) should it; be pointed at the main buildmaster. Now start the worker:. .. code-block:: bash. $ buildbot-worker start <buildbot-worker-root-directory>. This will cause your new worker to connect to the staging buildmaster; which is silent by default. Try this once then check the log file; ``<buildbot-worker-root-directory>/worker/twistd.log``. If your settings; are correct you will see a refused connection. This is good and expected,; as the credentials have not been established on both ends. Now stop the; worker and proceed to the next steps. #. Fill the buildbot-worker description and admin name/e-mail. Here is an; example of the buildbot-worker description::. Windows 7 x64; Core i7 (2.66GHz), 16GB of RAM. g++.exe (TDM-1 mingw32) 4.4.0; GNU Binutils 2.19.1; cmake version 2.8.4; Microsoft(R) 32-bit C/C++ Optimizing Compiler Version 16.00.40219.01 for 80x86. See `here <http://docs.buildbot.net/current/manual/installation/worker.html>`_; for which files to edit. #. Send a patch which adds your build worker and your builder to; `zorg <https://github.com/llvm/llvm-zorg>`_. Use the typical LLVM; `workflow <https://llvm.org/docs/Contributing.html#how-to-submit-a-patch>`_. * workers are added to ``buildbot/osuosl/master/config/workers.py``; * builders are added to ``buildbot/osuosl/master/config/builders.py``. Please make sure your builder name and its builddir are unique through the; file. All new builders should default to using the ""'collapseRequests': False""; configuration. This causes the builder to build each commit individually; and not merge build requests. To maximize quality of feedback to developers,; we *strongly prefer* builders to be configured not to collapse requests.; This flag should be removed only after all reasonable efforts have been; exhausted to improve build times such that the builder can keep up with; commit flow. It is possible to allow email addresses to unconditional",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:5022,install,installation,5022,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['install'],['installation']
Deployability,"w-tests. List all of the discovered tests and exit. EXIT STATUS; -----------. :program:`lit` will exit with an exit code of 1 if there are any FAIL or XPASS; results. Otherwise, it will exit with the status 0. Other exit codes are used; for non-test related failures (for example a user error or an internal program; error). .. _test-discovery:. TEST DISCOVERY; --------------. The inputs passed to :program:`lit` can be either individual tests, or entire; directories or hierarchies of tests to run. When :program:`lit` starts up, the; first thing it does is convert the inputs into a complete list of tests to run; as part of *test discovery*. In the :program:`lit` model, every test must exist inside some *test suite*.; :program:`lit` resolves the inputs specified on the command line to test suites; by searching upwards from the input path until it finds a :file:`lit.cfg` or; :file:`lit.site.cfg` file. These files serve as both a marker of test suites; and as configuration files which :program:`lit` loads in order to understand; how to find and run the tests inside the test suite. Once :program:`lit` has mapped the inputs into test suites it traverses the; list of inputs adding tests for individual files and recursively searching for; tests in directories. This behavior makes it easy to specify a subset of tests to run, while still; allowing the test suite configuration to control exactly how tests are; interpreted. In addition, :program:`lit` always identifies tests by the test; suite they are in, and their relative path inside the test suite. For; appropriately configured projects, this allows :program:`lit` to provide; convenient and flexible support for out-of-tree builds. .. _test-status-results:. TEST STATUS RESULTS; -------------------. Each test ultimately produces one of the following eight results:. **PASS**. The test succeeded. **FLAKYPASS**. The test succeeded after being re-run more than once. This only applies to; tests containing an ``ALLOW_RETRIES:`` annot",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:11582,configurat,configuration,11582,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['configurat'],['configuration']
Deployability,"w_mask:0xa bank_mask:0x1 bound_ctrl:0. VOP3_DPP examples (Available on GFX11+):. .. code-block:: nasm. v_add_f32_e64_dpp v0, v1, v2 dpp8:[0,1,2,3,4,5,6,7]; v_sqrt_f32_e64_dpp v0, v1 row_shl:1 row_mask:0xa bank_mask:0x1 bound_ctrl:0; v_ldexp_f32 v0, v1, v2 dpp8:[0,1,2,3,4,5,6,7]. VOP_SDWA examples:. .. code-block:: nasm. v_mov_b32 v1, v2 dst_sel:BYTE_0 dst_unused:UNUSED_PRESERVE src0_sel:DWORD; v_min_u32 v200, v200, v1 dst_sel:WORD_1 dst_unused:UNUSED_PAD src0_sel:BYTE_1 src1_sel:DWORD; v_sin_f32 v0, v0 dst_unused:UNUSED_PAD src0_sel:WORD_1; v_fract_f32 v0, |v0| dst_sel:DWORD dst_unused:UNUSED_PAD src0_sel:WORD_1; v_cmpx_le_u32 vcc, v1, v2 src0_sel:BYTE_2 src1_sel:WORD_0. For full list of supported instructions, refer to ""Vector ALU instructions"". .. _amdgpu-amdhsa-assembler-predefined-symbols-v2:. Code Object V2 Predefined Symbols; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .. warning::; Code object V2 generation is no longer supported by this version of LLVM. The AMDGPU assembler defines and updates some symbols automatically. These; symbols do not affect code generation. .option.machine_version_major; +++++++++++++++++++++++++++++. Set to the GFX major generation number of the target being assembled for. For; example, when assembling for a ""GFX9"" target this will be set to the integer; value ""9"". The possible GFX major generation numbers are presented in; :ref:`amdgpu-processors`. .option.machine_version_minor; +++++++++++++++++++++++++++++. Set to the GFX minor generation number of the target being assembled for. For; example, when assembling for a ""GFX810"" target this will be set to the integer; value ""1"". The possible GFX minor generation numbers are presented in; :ref:`amdgpu-processors`. .option.machine_version_stepping; ++++++++++++++++++++++++++++++++. Set to the GFX stepping generation number of the target being assembled for.; For example, when assembling for a ""GFX704"" target this will be set to the; integer value ""4"". The possible GFX stepping generation numbers",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:430391,update,updates,430391,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['update'],['updates']
Deployability,"walking the immediate and transitive uses of; the store. .. code-block:: c++. checkUses(MemoryAccess *Def) { // Def can be a MemoryDef or a MemoryPhi.; for (auto& U : Def->uses()) {; MemoryAccess *MA = cast<MemoryAccess>(Use.getUser());; if (auto *MU = cast_of_null<MemoryUse>MA) {; // Process MemoryUse as needed.; }; else {; // Process MemoryDef or MemoryPhi as needed. // As a user can come up twice, as an optimized access and defining; // access, keep a visited list. // Check transitive uses as needed; checkUses (MA); // use a worklist for an iterative algorithm; }; }; }. An example of similar traversals can be found in the DeadStoreElimination pass. Invalidation and updating; -------------------------. Because ``MemorySSA`` keeps track of LLVM IR, it needs to be updated whenever; the IR is updated. ""Update"", in this case, includes the addition, deletion, and; motion of ``Instructions``. The update API is being made on an as-needed basis.; If you'd like examples, ``GVNHoist`` and ``LICM`` are users of ``MemorySSA``\ s; update API.; Note that adding new ``MemoryDef``\ s (by calling ``insertDef``) can be a; time-consuming update, if the new access triggers many ``MemoryPhi`` insertions and; renaming (optimization invalidation) of many ``MemoryAccesses``\ es. Phi placement; ^^^^^^^^^^^^^. ``MemorySSA`` only places ``MemoryPhi``\ s where they're actually; needed. That is, it is a pruned SSA form, like LLVM's SSA form. For; example, consider:. .. code-block:: llvm. define void @foo() {; entry:; %p1 = alloca i8; %p2 = alloca i8; %p3 = alloca i8; ; 1 = MemoryDef(liveOnEntry); store i8 0, ptr %p3; br label %while.cond. while.cond:; ; 3 = MemoryPhi({%0,1},{if.end,2}); br i1 undef, label %if.then, label %if.else. if.then:; br label %if.end. if.else:; br label %if.end. if.end:; ; MemoryUse(1); %1 = load i8, ptr %p1; ; 2 = MemoryDef(3); store i8 2, ptr %p2; ; MemoryUse(1); %2 = load i8, ptr %p3; br label %while.cond; }. Because we removed the stores from ``if.then`` and ``if.e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:14430,update,update,14430,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['update'],['update']
Deployability,"warf-control-flow-operations:. A.2.5.4.2 Control Flow Operations; #################################. .. note::. This section replaces DWARF Version 5 section 2.5.1.5. The following operations provide simple control of the flow of a DWARF operation; expression. 1. ``DW_OP_nop``. ``DW_OP_nop`` is a place holder. It has no effect on the DWARF stack; entries. 2. ``DW_OP_le``, ``DW_OP_ge``, ``DW_OP_eq``, ``DW_OP_lt``, ``DW_OP_gt``,; ``DW_OP_ne``. .. note::. The same as in DWARF Version 5 section 2.5.1.5. 3. ``DW_OP_skip``. ``DW_OP_skip`` is an unconditional branch. Its single operand is a 2-byte; signed integer constant. The 2-byte constant is the number of bytes of the; DWARF expression to skip forward or backward from the current operation,; beginning after the 2-byte constant. If the updated position is at one past the end of the last operation, then; the operation expression evaluation is complete. Otherwise, the DWARF expression is ill-formed if the updated operation; position is not in the range of the first to last operation inclusive, or; not at the start of an operation. 4. ``DW_OP_bra``. ``DW_OP_bra`` is a conditional branch. Its single operand is a 2-byte signed; integer constant. This operation pops the top of stack. If the value popped; is not the constant 0, the 2-byte constant operand is the number of bytes of; the DWARF operation expression to skip forward or backward from the current; operation, beginning after the 2-byte constant. If the updated position is at one past the end of the last operation, then; the operation expression evaluation is complete. Otherwise, the DWARF expression is ill-formed if the updated operation; position is not in the range of the first to last operation inclusive, or; not at the start of an operation. 5. ``DW_OP_call2, DW_OP_call4, DW_OP_call_ref``. ``DW_OP_call2``, ``DW_OP_call4``, and ``DW_OP_call_ref`` perform DWARF; procedure calls during evaluation of a DWARF operation expression. ``DW_OP_call2`` and ``DW_OP_call4``, ha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:71403,update,updated,71403,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['update'],['updated']
Deployability,"was created TDirectory::fDatimeC; | (year-1995)<<26|month<<22|day<<17|hour<<12|minute<<6|second; 6->9 DatimeM = Date and time when directory was last modified TDirectory::fDatimeM; | (year-1995)<<26|month<<22|day<<17|hour<<12|minute<<6|second; 10->13 NbytesKeys= Number of bytes in the associated KeysList record TDirectory::fNbyteskeys; 14->17 NbytesName= Number of bytes in TKey+TNamed at creation TDirectory::fNbytesName; 18->21 [18->25] SeekDir = Byte offset of directory record in file TDirectory::fSeekDir; 22->25 [26->33] SeekParent= Byte offset of parent directory record in file TDirectory::fSeekParent; 26->29 [34->41] SeekKeys = Byte offset of associated KeysList record in file TDirectory::fSeekKeys; 30->31 [42->43] UUID vers = TUUID class version identifier TUUID::Class_Version(); 32->47 [44->59] UUID = Universally Unique Identifier TUUID::fTimeLow through fNode[6]; 48->59 Extra space to allow SeekKeys to become 64 bit without moving this header; </pre></div>. Format of a TDirectory record in release 3.02.06. It is never compressed. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; ----------TKey--------------; byte 0->3 Nbytes = Number of bytes in compressed record (Tkey+data) TKey::fNbytes; 4->5 Version = TKey class version identifier TKey::fVersion; 6->9 ObjLen = Number of bytes of uncompressed data TKey::fObjLen; 10->13 Datime = Date and time when record was written to file TKey::fDatime; | (year-1995)<<26|month<<22|day<<17|hour<<12|minute<<6|second; 14->15 KeyLen = Number of bytes in key structure (TKey) TKey::fKeyLen; 16->17 Cycle = Cycle of key TKey::fCycle; 18->21 SeekKey = Byte offset of record itself (consistency check) TKey::fSeekKey; 22->25 SeekPdir = Byte offset of parent directory record TKey::fSeekPdir; 26->26 lname = Number of bytes in the class name (10) TKey::fClassName; 27->.. ClassName = Object Class Name (""TDirectory"") TKey::fClassName; 0->0 lname = Number of bytes in the object name TNamed::fName; 1->.. Name = lName bytes w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tdirectory.md:2862,release,release,2862,io/doc/TFile/tdirectory.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tdirectory.md,1,['release'],['release']
Deployability,"watch?v=K2KqEV866Ro>`_; - *V Vasilev*, CERN PH-SFT, 2013; - Vassil Vasilev (Princeton University) explains how Cling enables interactivity in C++, and illustrates the type introspection mechanism provided by the interpreter.; * - `Introducing Cling, a C++ Interpreter Based on Clang/LLVM <https://www.youtube.com/watch?v=f9Xfh8pv3Fs>`_; - *Axel Naumann* 2012 Googletechtalks; - Axel Naumann (CERN) discusses Cling’s most relevant features: abstract syntax tree (AST) production, wrapped functions, global initialization of a function, delay expression evaluation at runtime, and dynamic scopes.; * - `Creating Cling, an interactive interpreter interface <https://www.youtube.com/watch?v=BjmGOMJWeAo>`_; - *Axel Naumann* 2010 LLVM Developers’ meeting; - This presentation introduces Cling, an ahead-of-time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_; - 2022.2 Version; - CLion uses Cling to integrate the `Quick Documentation <https://www.jetbrains.com/help/clion/2022.2/viewing-inline-documentation.html>`_ popup by allowing you to view the value of the expressions evaluated at compile time.; * - `Interactive C++ for Data Science <https://www.youtube.com/watch?v=23E0S3miWB0&t=2716s>`_; - *Vassil Vassilev* 2021 CppCon (The C++ Conference); - In this video, the author discusses how Cling enables interactive C++ for Data Science projects. ; * - `Cling -- Beyond Just Interpreting C++ <https://blog.llvm.org/posts/2021-03-25-cling-beyond-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/ti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:1966,integrat,integration,1966,interpreter/cling/docs/chapters/references.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst,1,['integrat'],['integration']
Deployability,"which will be pointed at; the function's implementation once the function has been compiled) and an; indirect jump through the pointer. By fixing the address of the indirect jump; for the lifetime of the program we can give the function a permanent ""effective; address"", one that can be safely used for indirection and function pointer; comparison even if the function's implementation is never compiled, or if it is; compiled more than once (due to, for example, recompiling the function at a; higher optimization level) and changes address. The second utility, the compile; callback, represents a re-entry point from the program into the compiler that; will trigger compilation and then execution of a function. By initializing the; function's stub to point at the function's compile callback, we enable lazy; compilation: The first attempted call to the function will follow the function; pointer and trigger the compile callback instead. The compile callback will; compile the function, update the function pointer for the stub, then execute; the function. On all subsequent calls to the function, the function pointer; will point at the already-compiled function, so there is no further overhead; from the compiler. We will look at this process in more detail in the next; chapter of this tutorial, but for now we'll trust the CompileOnDemandLayer to; set all the stubs and callbacks up for us. All we need to do is to add the; CompileOnDemandLayer to the top of our stack and we'll get the benefits of; lazy compilation. We just need a few changes to the source:. .. code-block:: c++. ...; #include ""llvm/ExecutionEngine/SectionMemoryManager.h""; #include ""llvm/ExecutionEngine/Orc/CompileOnDemandLayer.h""; #include ""llvm/ExecutionEngine/Orc/CompileUtils.h""; ... ...; class KaleidoscopeJIT {; private:; std::unique_ptr<TargetMachine> TM;; const DataLayout DL;; RTDyldObjectLinkingLayer ObjectLayer;; IRCompileLayer<decltype(ObjectLayer), SimpleCompiler> CompileLayer;. using OptimizeFunction =; s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst:3232,update,update,3232,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst,1,['update'],['update']
Deployability,"while `TRandom3` generates only 32 bit random numbers.; * `TRandomRanlux48` - 48 bit Ranlux generator. Note that `TRandom1` is a 24 bit generator. ; * Improve thread safety of `TMinuit` constructor [ROOT-8217]; * Vc has ben removed from the ROOT sources. If the option 'vc' is enabled, the package will be searched (by default),; alternatively the source tarfile can be downloded and build with the option 'builtin_vc'. ## TMVA Libraries. * New `DataLoader` class that allows flexibility in variable and dataset selection. ; * New Deep Neural Network. Three different versions are available, which can be selected with the 'Architecture' option. See also the tutorial`tmva/TMVAClassification.C` for using the new DNN.; * `Architecture=STANDARD` to select the earlier version.; * `Architecture=CPU` to select the newer version for CPU, but designed also for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:13062,configurat,configuration,13062,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['configurat'],['configuration']
Deployability,"whole flag string.; # Flags in the ""Flags"" list will be added if any flag generated from command; # line options matches the regular expression.; Mappings:. # Set a ""--target=thumbv7m-none-eabi"" flag if the regular expression matches; # any of the flags generated from the command line options.; # Match is a POSIX extended regular expression string.; - Match: --target=thumbv([7-9]|[1-9][0-9]+).*; # Flags is a list of one or more strings.; Flags: [--target=thumbv7m-none-eabi]. Design principles; =================. Stable interface; ----------------. ``multilib.yaml`` and ``-print-multi-flags-experimental`` are new; interfaces to Clang. In order for them to be usable over time and across LLVM; versions their interfaces should be stable.; The new multilib system will be considered experimental in LLVM 17, but in; LLVM 18 it will be stable. In particular this is important to which multilib; selection flags Clang generates from command line options. Once a flag is; generated by a released version of Clang it may be used in ``multilib.yaml``; files that exist independently of the LLVM release cycle, and therefore; ceasing to generate the flag would be a breaking change and should be; avoided. However, an exception is the normalization of ``-march``.; ``-march`` for Arm architectures contains a list of enabled and disabled; extensions and this list is likely to grow. Therefore ``-march`` flags are; unstable. Incomplete interface; --------------------. The new multilib system does multilib selection based on only a limited set of; command line options, and limits which flags can be used for multilib; selection. This is in order to avoid committing to too large an interface.; Later LLVM versions can add support for multilib selection from more command; line options as needed. Extensible; ----------. It is likely that the configuration format will need to evolve in future to; adapt to new requirements.; Using a format like YAML that supports key-value pairs helps here as it's; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst:9740,release,released,9740,interpreter/llvm-project/clang/docs/Multilib.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst,1,['release'],['released']
Deployability,"will be fixed. Any bugs introduced by; merged patches will be fixed. If so a third round of testing is needed. * The release notes are updated. * Finally, release!. * Announce bug fix release schedule to the LLVM community and update the website. * Do bug-fix releases every two weeks until X.1.5 or X.1.6 (if necessary). Release Process; ===============. .. contents::; :local:. Release Administrative Tasks; ----------------------------. This section describes a few administrative tasks that need to be done for the; release process to begin. Specifically, it involves:. * Updating version numbers,. * Creating the release branch, and. * Tagging release candidates for the release team to begin testing. Create Release Branch; ^^^^^^^^^^^^^^^^^^^^^. Branch the Git trunk using the following procedure:. #. Remind developers that the release branching is imminent and to refrain from; committing patches that might break the build. E.g., new features, large; patches for works in progress, an overhaul of the type system, an exciting; new TableGen feature, etc. #. Verify that the current git trunk is in decent shape by; examining nightly tester and buildbot results. #. Bump the version in trunk to N.0.0git and tag the commit with llvmorg-N-init.; If ``X`` is the version to be released, then ``N`` is ``X + 1``. ::. $ git tag -sa llvmorg-N-init. #. Clear the release notes in trunk. #. Create the release branch from the last known good revision from before the; version bump. The branch's name is release/X.x where ``X`` is the major version; number and ``x`` is just the letter ``x``. #. On the newly-created release branch, immediately bump the version; to X.1.0git (where ``X`` is the major version of the branch.). #. All tags and branches need to be created in both the llvm/llvm-project and; llvm/llvm-test-suite repos. Update LLVM Version; ^^^^^^^^^^^^^^^^^^^. After creating the LLVM release branch, update the release branches'; version with the script in ``llvm/utils/release/bump-ver",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:3720,patch,patches,3720,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['patch'],['patches']
Deployability,"will cause the caller to gain the attribute. This is intended; to provide a maximally conservative model where the code in a function; annotated with this attribute will always (even after inlining) end up; hardened.; ``speculatable``; This function attribute indicates that the function does not have any; effects besides calculating its result and does not have undefined behavior.; Note that ``speculatable`` is not enough to conclude that along any; particular execution path the number of calls to this function will not be; externally observable. This attribute is only valid on functions; and declarations, not on individual call sites. If a function is; incorrectly marked as speculatable and really does exhibit; undefined behavior, the undefined behavior may be observed even; if the call site is dead code. ``ssp``; This attribute indicates that the function should emit a stack; smashing protector. It is in the form of a ""canary"" --- a random value; placed on the stack before the local variables that's checked upon; return from the function to see if it has been overwritten. A; heuristic is used to determine if a function needs stack protectors; or not. The heuristic used will enable protectors for functions with:. - Character arrays larger than ``ssp-buffer-size`` (default 8).; - Aggregates containing character arrays larger than ``ssp-buffer-size``.; - Calls to alloca() with variable sizes or constant sizes greater than; ``ssp-buffer-size``. Variables that are identified as requiring a protector will be arranged; on the stack such that they are adjacent to the stack protector guard. If a function with an ``ssp`` attribute is inlined into a calling function,; the attribute is not carried over to the calling function. ``sspstrong``; This attribute indicates that the function should emit a stack smashing; protector. This attribute causes a strong heuristic to be used when; determining if a function needs stack protectors. The strong heuristic; will enable protectors f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:102766,canary,canary,102766,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['canary'],['canary']
Deployability,"wing ExplodedGraph is your most powerful tool for understanding; the analyzer's false positives, because it gives comprehensive information; on every decision made by the analyzer across all analysis paths.; There are more debug checkers available. To see all available debug checkers:. $ clang -cc1 -analyzer-checker-help | grep ""debug"". Debug Prints and Tricks; To view ""half-baked"" ExplodedGraph while debugging, jump to a frame; that has clang::ento::ExprEngine object and execute:. (gdb) p ViewGraph(0). To see the ProgramState while debugging use the following command. (gdb) p State->dump(). To see clang::Expr while debugging use the following command. If you; pass in a SourceManager object, it will also dump the corresponding line in the; source code. (gdb) p E->dump(). To dump AST of a method that the current ExplodedNode belongs; to:. (gdb) p C.getPredecessor()->getCodeDecl().getBody()->dump(). Making Your Checker Better. User facing documentation is important for adoption! Make sure the checker list is updated; at the homepage of the analyzer. Also ensure the description is clear to; non-analyzer-developers in Checkers.td.; Warning and note messages should be clear and easy to understand, even if a bit long. Messages should start with a capital letter (unlike Clang warnings!) and should not; end with ..; Articles are usually omitted, eg. Dereference of a null pointer ->; Dereference of null pointer.; Introduce BugReporterVisitors to emit additional notes that explain the warning; to the user better. There are some existing visitors that might be useful for your check,; e.g. trackNullOrUndefValue. For example, SimpleStreamChecker should highlight; the event of opening the file when reporting a file descriptor leak. If the check tracks anything in the program state, it needs to implement the; checkDeadSymbolscallback to clean the state up.; The check should conservatively assume that the program is correct when a tracked symbol; is passed to a function that is unkn",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html:22993,update,updated,22993,interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,1,['update'],['updated']
Deployability,"with `TH2` lego plots; - Many adjustment with new `TWebCanvas` - interactivity, attributes/position updates, context menus; - Upgrade three.js 86 -> 102, use `SoftwareRenderer` instead of `CanvasRenderer`; - Upgrade d3.js 4.4.4 -> 5.7.0; - Fix - support clipping for tracks and points in geo painter; - Fix - drawing of TGeoNode with finder; - Fix - key press events processed only in active pad (ROOT-9128); - Fix - use X0/Y0 in xtru shape, thanks to @altavir. ### New files location. JSROOT sources were moved from `etc/http/` into `js/` subfolder in ROOT sources tree.; OpenUI5 files were moved to `ui5/` subfolder. After ROOT compilation they can be found in; `$ROOTSYS/js/` and `$ROOTSYS/ui5/` subfolders respectively. ## Tutorials; - Add `RSqliteDS` examples.; - Make RCsvDS and RLazyDS tutorials standalone, i.e. downloading input csv directly using `TFile::Cp` rather than relying on CMake. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. ### CMake build system requirements and updates. The minimum required version of CMake has been updated to 3.9 or newer to be; able to take advantage of new features such as native support for the CUDA; language, among other things. Please refer to CMake's release notes for further; information. The method to select the C++ standard has changed. Now the recommended way; to select the C++ standard is via the option `-DCMAKE_CXX_STANDARD=XX`, which; is the idiomatic way to do it in CMake. The old options still work, but have; been deprecated and will be removed in a future release. Build option descriptions have been updated to indicate which builtins require; an active network connection during the build. You can inspect the list of; options and their descriptions by running `cmake -LH $PWD` in the build; directory. The build system has been updated to remove most file globbing to improve; the reliability of incremental builds when source files are added or removed. A new check has been added to make ROOT fail",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:22008,update,updates,22008,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['update'],['updates']
Deployability,"with the option ""Z"" the option ""CJUST"" allows to draw the color palette; with axis labels justified on the color boundaries (implemented by Otto Schaile).; * The `TCanvas` Event Status Bar now displays the date and time when the mouse cursor; is moved over a time axis (implemented by Otto Schaile).; * Negative values were not painted with option ""TEXT"" for TH2Poly. ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ### Jupyter Notebook Integration; - When starting Jupyter server with `root --notebook arg1 arg2 ...`, extra arguments can be provided.; All these arguments delivered as is to jupyter executable and can be used for configuration.; Like server binding to specific host `root --notebook --ip=hostname`; - Remove `c.NotebookApp.ip = '*'` from default jupyter config. One has to provide ip address for server; binding using `root --notebook --ip=<hostaddr>` arguments; - Now Jupyter Notebooks will use JSROOT provided with ROOT installation. This allows to use notebooks; without internet connection (offline). ## JavaScript ROOT; - Provide monitoring capabilities for TGeoManager object. Now geomtry with some tracks can be displayed and; updated in web browser, using THttpServer monitoring capability like histogram objects. ## Tutorials; - Add the ""Legacy"" category collecting the old tutorials which do not represent any more best practices. ## Class Reference Guide; - Images in tutorials can now be displayed à JavaScript thanks to the (js) option; added next to the directive `\macro_image`; - As the tutorial `palettes.C` is often hit when searching the keyword `palette`; in the reference guide, a direct link from this example to the full list of; predefined palettes given in `TColor` has been added.; - Revisited the TSpectrum2 documentation. All the static images have been replaced; by macros generating images at reference guide build tim",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md:6422,install,installation,6422,README/ReleaseNotes/v620/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md,1,['install'],['installation']
Deployability,"with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libraries,; tools, etc. It is the responsibility of **every** LLVM developer to care for the core tier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc).; * Build infrastructure that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reverted, as per review policy.; * Bit-rot of a component in the core tier will result in that component being; downgraded to the peripheral tier or being removed. Sub-communities can; avoid this by fixing all raised issues in a timely manner. Peripheral Tier; ===============. The peripheral tier encompass the parts of LLVM that cater to a specific; sub-community and which don't usually affect the core components directly. This includes experimental back-ends, disabled-by-default options and; alternative paths (work-in-progress replacements) in the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:2446,release,releases,2446,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst,1,['release'],['releases']
Deployability,"with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4903,integrat,integrator,4903,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,1,['integrat'],['integrator']
Deployability,wn. 1162; NAD; Dependent elaborated-type-specifiers in non-deduced contexts; Unknown. 1163; NAD; extern template prevents inlining functions not marked inline; Unknown. 1164; C++11; Partial ordering of f(T&) and f(T&&); Unknown. 1165; C++11; Exceptions when destroying array elements; Unknown. 1166; C++11; exception-declarations that do not declare objects; Unknown. 1167; C++11; function-try-blocks for destructors; Unknown. 1168; C++11; Additional reasons to call std::terminate; Unknown. 1169; C++11; Missing feature macro for strict pointer safety; Unknown. 1170; C++11; Access checking during template argument deduction; Unknown. 1171; C++11; Partial stack unwinding with noexcept violation; Unknown. 1172; drafting; “instantiation-dependent” constructs; Not resolved. 1173; C++11; Unclear specification of effects of signal handling; Unknown. 1174; C++11; When is a pure virtual function “used?”; Unknown. 1175; C++11; Disambiguating user-defined literals; Unknown. 1176; C++11; Definition of release sequence; Unknown. 1177; C++11; Intra-thread dependency-ordered-before; Unknown. 1178; C++11; Deduction failure matching placement new; Unknown. 1179; NAD; Cv-qualification of non-type template parameters; Unknown. 1180; C++11; Over-aligned class types; Unknown. 1181; C++11; What is a “built-in type?”; Unknown. 1182; C++11; Incorrect description of pack expansion syntax; Unknown. 1183; C++11; Expansion of parameter packs in declarators; Unknown. 1184; C++11; Argument conversions to nondeduced parameter types; Unknown. 1185; C++11; Misleading description of language linkage and member function types; Unknown. 1186; C++11; Non-dependent constexpr violations in function templates; Unknown. 1187; C++11; Problems in initialization example; Unknown. 1188; C++11; Type punning in constant expressions; Unknown. 1189; C++11; Address of distinct base class subobjects; Unknown. 1190; C++11; Operations on non-safely-derived pointers; Unknown. 1191; C++11; Deleted subobject destructors and ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:78270,release,release,78270,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,1,['release'],['release']
Deployability,"work and currently have no maintainers. Invoking clang; --------------. Invoking clang for CUDA compilation works similarly to compiling regular C++.; You just need to be aware of a few additional flags. You can use `this <https://gist.github.com/855e277884eb6b388cd2f00d956c2fd4>`_; program as a toy example. Save it as ``axpy.cu``. (Clang detects that you're; compiling CUDA code by noticing that your filename ends with ``.cu``.; Alternatively, you can pass ``-x cuda``.). To build and run, run the following commands, filling in the parts in angle; brackets as described below:. .. code-block:: console. $ clang++ axpy.cu -o axpy --cuda-gpu-arch=<GPU arch> \; -L<CUDA install path>/<lib64 or lib> \; -lcudart_static -ldl -lrt -pthread; $ ./axpy; y[0] = 2; y[1] = 4; y[2] = 6; y[3] = 8. On MacOS, replace `-lcudart_static` with `-lcudart`; otherwise, you may get; ""CUDA driver version is insufficient for CUDA runtime version"" errors when you; run your program. * ``<CUDA install path>`` -- the directory where you installed CUDA SDK.; Typically, ``/usr/local/cuda``. Pass e.g. ``-L/usr/local/cuda/lib64`` if compiling in 64-bit mode; otherwise,; pass e.g. ``-L/usr/local/cuda/lib``. (In CUDA, the device code and host code; always have the same pointer widths, so if you're compiling 64-bit code for; the host, you're also compiling 64-bit code for the device.) Note that as of; v10.0 CUDA SDK `no longer supports compilation of 32-bit; applications <https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#deprecated-features>`_. * ``<GPU arch>`` -- the `compute capability; <https://developer.nvidia.com/cuda-gpus>`_ of your GPU. For example, if you; want to run your program on a GPU with compute capability of 3.5, specify; ``--cuda-gpu-arch=sm_35``. Note: You cannot pass ``compute_XX`` as an argument to ``--cuda-gpu-arch``;; only ``sm_XX`` is currently supported. However, clang always includes PTX in; its binaries, so e.g. a binary compiled with ``--cuda-gpu-arch=sm_30`` would",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:2461,install,install,2461,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,2,['install'],"['install', 'installed']"
Deployability,"work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:209118,release,release,209118,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['release'],['release']
Deployability,"write clang tools, and their pros and cons. LibClang; --------. `LibClang <https://clang.llvm.org/doxygen/group__CINDEX.html>`_ is a stable high; level C interface to clang. When in doubt LibClang is probably the interface; you want to use. Consider the other interfaces only when you have a good; reason not to use LibClang. Canonical examples of when to use LibClang:. * Xcode; * Clang Python Bindings. Use LibClang when you...:. * want to interface with clang from other languages than C++; * need a stable interface that takes care to be backwards compatible; * want powerful high-level abstractions, like iterating through an AST with a; cursor, and don't want to learn all the nitty gritty details of Clang's AST. Do not use LibClang when you...:. * want full control over the Clang AST. Clang Plugins; -------------. :doc:`Clang Plugins <ClangPlugins>` allow you to run additional actions on the; AST as part of a compilation. Plugins are dynamic libraries that are loaded at; runtime by the compiler, and they're easy to integrate into your build; environment. Canonical examples of when to use Clang Plugins:. * special lint-style warnings or errors for your project; * creating additional build artifacts from a single compile step. Use Clang Plugins when you...:. * need your tool to rerun if any of the dependencies change; * want your tool to make or break a build; * need full control over the Clang AST. Do not use Clang Plugins when you...:. * want to run tools outside of your build environment; * want full control on how Clang is set up, including mapping of in-memory; virtual files; * need to run over a specific subset of files in your project which is not; necessarily related to any changes which would trigger rebuilds. LibTooling; ----------. :doc:`LibTooling <LibTooling>` is a C++ interface aimed at writing standalone; tools, as well as integrating into services that run clang tools. Canonical; examples of when to use LibTooling:. * a simple syntax checker; * refactorin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Tooling.rst:1361,integrat,integrate,1361,interpreter/llvm-project/clang/docs/Tooling.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Tooling.rst,1,['integrat'],['integrate']
Deployability,"written separately. ## Schema Evolution. Schema evolution is a problem faced by long-lived data. When a schema; changes, existing persistent data can become inaccessible unless the; system provides a mechanism to access data created with previous; versions of the schema. In the lifetime of collaboration, the class; definitions (i.e. the schema) are likely to change frequently. Not only; can the class itself change, but any of its parent classes or data; member classes can change also. This makes the support for schema; evolution necessary. ROOT fully supports schema evolution. The next figure below illustrates; some of the scenarios. ![The ROOT schema evolution](pictures/020000ED.jpg). The top half represents different versions of the shared library with; the class definitions. These are the in-memory class versions. The; bottom half represents data files that contain different versions of the; classes. - An old version of a shared library and a file with new class; definitions - this can be the case when someone has not updated the; library and is reading a new file. - Reading a file with a shared library that is missing a class; definition (i.e. missing class D). - Reading a file without any class definitions. This can be the case; where the class definition is lost, or unavailable. - The current version of a shared library and an old file with old; class versions (backward compatibility). This is often the case when; reading old data. - Reading a file with a shared library built with `MakeProject`. This; is the case when someone has already read the data without a shared; library and has used ROOT `MakeProject` feature to reconstruct the; class definitions and shared library (`MakeProject` is explained in; detail later on). In case of a mismatch between the in-memory version and the persistent; version of a class, ROOT maps the persistent one to the one in memory.; This allows you to change the class definition at will, for example:. - Change the order of data me",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:68471,update,updated,68471,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['update'],['updated']
Deployability,"ws. Using Ninja alongside Visual Studio; We recommend that developers who want the fastest incremental builds use the; Ninja build system. You can use the; generated Visual Studio project files to edit Clang source code and generate a; second build directory next to it for running the tests with these steps:. Check out clang and LLVM as described above; Open a developer command prompt with the appropriate environment.; ; If you open the start menu and search for ""Command Prompt"", you should; see shortcuts created by Visual Studio to do this. To use native x64; tools, choose the one titled ""x64 Native Tools Command Prompt for VS; 2017"".; Alternatively, launch a regular cmd prompt and run the; appropriate vcvarsall.bat incantation. To get the 2017 x64 tools, this; would be:; ""C:\Program Files (x86)\Microsoft Visual; Studio\2017\Community\VC\Auxiliary\Build\vcvarsall.bat"" x64. mkdir build_ninja (or build, or use your own; organization); cd build_ninja; set CC=cl (necessary to force CMake to choose MSVC over mingw GCC; if you have it installed); set CXX=cl; cmake -GNinja -DLLVM_ENABLE_PROJECTS=clang ..\llvm; ninja clang This will build just clang.; ninja check-clang This will run the clang tests. Clang Compiler Driver (Drop-in Substitute for GCC); The clang tool is the compiler driver and front-end, which is; designed to be a drop-in replacement for the gcc command. Here are; some examples of how to use the high-level driver:. $ cat t.c; #include <stdio.h>; int main(int argc, char **argv) { printf(""hello world\n""); }; $ clang t.c; $ ./a.out; hello world. The 'clang' driver is designed to work as closely to GCC as possible to; maximize portability. The only major difference between the two is that; Clang defaults to gnu99 mode while GCC defaults to gnu89 mode. If you see; weird link-time errors relating to inline functions, try passing -std=gnu89; to clang.; Examples of using Clang. $ cat ~/t.c; typedef float V __attribute__((vector_size(16)));; V foo(V a, V b) { return ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/get_started.html:6578,install,installed,6578,interpreter/llvm-project/clang/www/get_started.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/get_started.html,1,['install'],['installed']
Deployability,"ws; may require more extensive changes: please get involved if you are interested; in porting this feature. .. code-block:: console. # Step 2: Run the program.; % LLVM_PROFILE_FILE=""foo.profraw"" ./foo. Note that continuous mode is also used on Fuchsia where it's the only supported; mode, but the implementation is different. The Darwin and Linux implementation; relies on padding and the ability to map a file over the existing memory; mapping which is generally only available on POSIX systems and isn't suitable; for other platforms. On Fuchsia, we rely on the ability to relocate counters at runtime using a; level of indirection. On every counter access, we add a bias to the counter; address. This bias is stored in ``__llvm_profile_counter_bias`` symbol that's; provided by the profile runtime and is initially set to zero, meaning no; relocation. The runtime can map the profile into memory at arbitrary locations,; and set bias to the offset between the original and the new counter location,; at which point every subsequent counter access will be to the new location,; which allows updating profile directly akin to the continuous mode. The advantage of this approach is that doesn't require any special OS support.; The disadvantage is the extra overhead due to additional instructions required; for each counter access (overhead both in terms of binary size and performance); plus duplication of counters (i.e. one copy in the binary itself and another; copy that's mapped into memory). This implementation can be also enabled for; other platforms by passing the ``-runtime-counter-relocation`` option to the; backend during compilation. For a program such as the `Lit <https://llvm.org/docs/CommandGuide/lit.html>`_; testing tool which invokes other programs, it may be necessary to set; ``LLVM_PROFILE_FILE`` for each invocation. The pattern strings ""%p"" or ""%Nm""; may help to avoid corruption due to concurrency. Note that ""%p"" is also a Lit; token and needs to be escaped as ""%%p"". ..",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst:4850,continuous,continuous,4850,interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,1,['continuous'],['continuous']
Deployability,"wser is reloaded; - load of widgets code only when really required (shorter startup time for RBrowser). ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ## JavaScript ROOT. ### Major JSROOT update to version 6. - update all used libraries `d3.js`, `three.js`, `MathJax.js`, openui5; - change to Promise based interface for all async methods, remove call-back arguments; - change scripts names, core scripts name now `JSRoot.core.js`; - unify function/methods naming conventions, many changes in method names; - provide central code loader via `JSROOT.require`, supporting 4 different loading engines; - many nice features and many bug fixes; see JSROOT v6 release notes. ## Tutorials. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. - a new cmake variable, `CMAKE_INSTALL_PYTHONDIR`, has been added: it allows customization of the installation directory of ROOT's python modules; - the developer build option `asserts` is introduced to enable/disable asserts via the `NDEBUG` C/CXX flag. Asserts are always enabled for `CMAKE_BUILD_TYPE=Debug` and `dev=ON`. The previous behavior of the builds set via the `CMAKE_BUILD_TYPE` variable has not changed.; - `CMAKE_CXX_STANDARD`, i.e. the C++ standard ROOT is built with, now defaults to the compiler default (or C++11 if the compiler default is older than that) rather than always defaulting to C++11. In turn this means that v6.24 is the first ROOT release for which ROOT's pre-compiled binaries are not compiled with C++11 but with the default standard in use by the default system compiler. On Ubuntu 20.04, for example, the v6.24 pre-compiled binaries are now compiled with C++14 rather than C++11 as it happened for previous ROOT versions. Also see [ROOT-10692](https://sft.its.cern.ch/jira/browse/ROOT-10692). The following builtins have been updated:. - VecCore 0.7.0. ## PyROOT. - Deprecate `TTree.AsMatrix` in this release and mark for removal in v6.26. Please use instead `RDataFrame.AsNumpy`.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:28607,release,release,28607,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,3,"['release', 'update']","['release', 'updated']"
Deployability,"x reliably working in node.js, does not depend from availability of canvas component; 3. Many optimizations to produce smaller (and faster) SVG output; 4. Provide x3dscNNN and y3dscNNN draw option for histogram to resize x/y axis in 3D plots; 5. Provide ""Find label"" command in TAxis context menu to zoom into bin region; 6. Allows to use JSROOT.define() in external scripts; 7. Provide JSROOT.Painter.setDefaultDrawOpt() to change class default draw option; 8. Provide example of custom entries in histogram context menu; 9. Provide alternative external location for zstd-codec, let use zstd even when not found locally; 10. Let skip HEAD requests when reading files, adding ""^"" symbol to file name (#223); 11. Show long histogram names in stats box when possible; 12. Fix logic how ""ndiv"" parameter of TAxis is handled, showing really the configured number of ticks; 13. Fix problem with curved TGraph drawings (#218); 14. Fix problems with TGraph drawing updates; 15. Base version for ROOT 6.26 release. ## Changes in 6.2.2; 1. Fix - proper fill TH1 which drawn with line option; 2. Fix - object drawing from inspector; 3. Fix - error with filling data of TGeoTrack in ""extract tracks"" example; 4. Fix - error in pad items context menu; 5. Fix - assigned dropped item name only when new painter created. ## Changes in 6.2.1; 1. Fix logy and logz handling on lego plots; 2. Fix error in statistic calculations for projections; 3. Fix zstd-codec loading with minified jsroot scripts. ## Changes in 6.2.0; 1. Support fully interactive second X/Y axis for histograms, graphs, functions and spline; 2. Support X+, Y+, RX, RY draw options for TF1; 3. Remove deprecated JSRootCore.js script, one have to use JSRoot.core.js; 4. Upgrade three.js to r127; 5. Upgrade d3.js to 6.7.0; 6. Implement ""nozoomx"" and ""nozoomy"" draw options for TPad; 7. Implement ""frame"" draw option for TGaxis - fix position of axis relative to the frame; 8. Preserve position of TPaletteAxis, if provided with histogram; make defa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:22092,release,release,22092,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['release'],['release']
Deployability,"x was updated from 0.6.4 to 0.6.7 (support for OpenSSL 1.1, [ROOT-9353](https://sft.its.cern.ch/jira/browse/ROOT-9353)); - Vdt has been updated from 0.3.9 to 0.4.1 (includes new atan function); - XRootd has been updated from 4.6.1 to 4.8.2 (for GCC 8.x support); - Builtin TBB can now be used on Windows; - xxHash and LZ4 have been separated so that a system version of LZ4 can be used even if it does not include xxHash headers ([ROOT-9099](https://sft.its.cern.ch/jira/browse/ROOT-9099)); - In addition, several updates have been made to fix minor build system issues, such as not checking for external packages if their builtin is turned off, or checking for packages even when the respective option is disabled ([ROOT-8806](https://sft.its.cern.ch/jira/browse/ROOT-8806), [ROOT-9190](https://sft.its.cern.ch/jira/browse/ROOT-9190), [ROOT-9315](https://sft.its.cern.ch/jira/browse/ROOT-9315), [ROOT-9385](https://sft.its.cern.ch/jira/browse/ROOT-9385)).; - The `python3` option to CMake has been removed ([ROOT-9033](https://sft.its.cern.ch/jira/browse/ROOT-9033), [ROOT-9143](https://sft.its.cern.ch/jira/browse/ROOT-9143)). Python support is enabled by default. To configure ROOT to use specific Python versions, there is a new option called `python_version`. This is how to configure ROOT and Python for the common use cases:. * Use the default Python interpreter:; - `-Dpython=ON` (default); * Search only for Python 2.x or only 3.x:; - `-Dpython_version=2` or `-Dpython_version=3`; * Use a specific version of Python from `$PATH`:; - `-Dpython_version=2.7` or `-Dpython_version=3.5`; * Use a specific Python interpreter, whatever the version:; - `-DPYTHON_EXECUTABLE=/usr/local/bin/python`. Note: The use of `PYTHON_EXECUTABLE` requires the full path to the interpreter. ## Infrastructure and Testing. - Reduce time taken by tests which takes too long to run ({One,Two}SidedFrequentistUpperLimitWithBands.C); - Disable PyROOT SQL tutorials (the C++ counterparts are since several releases).; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:20407,release,releases,20407,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['release'],['releases']
Deployability,"x) algorithms that can generate random; numbers from large classes of continuous (in one or multi-dimensions),; discrete distributions, empirical distributions (like histograms) and; also from practically all standard distributions. An extensive online; documentation is available at the UNU.RAN Web Site; <http://statmath.wu-wien.ac.at/unuran/>. The ROOT class **`TUnuran`** is used to interface the UNURAN package. It; can be used as following:. - With the UNU.RAN native, string API for pre-defined distributions; (see UNU.RAN documentation for the allowed string values at; <http://statistik.wu-wien.ac.at/unuran/doc/unuran.html> ):. ``` {.cpp}; TUnuran unr;; // initialize unuran to generate normal random numbers using; // a ""arou"" method; unr.Init(""normal()"",""method=arou"");; ...; // sample distributions N times (generate N random numbers); for (int i = 0; i<N; ++i); double x = unr.Sample();; ```. - For continuous 1D distribution object via the class; **`TUnuranContDist`** that can be created for example from a; **`TF1`** function providing the pdf (probability density function); . The user can optionally provide additional information via; `TUnuranContDist::SetDomain(min,max)` like the `domain()` for; generating numbers in a restricted region. ``` {.cpp}; // 1D case: create a distribution from two TF1 object; // pointers pdfFunc; TUnuranContDist dist( pdfFunc);; // initialize unuran passing the distribution and a string; // defining the method; unr.Init(dist, ""method=hinv"");; // sample distribution N times (generate N random numbers); for (int i = 0; i < N; ++i); double x = unr.Sample();; ```. - For multi-dimensional distribution via the class; **`TUnuranMultiContDist`**, which can be created from a the; multi-dimensional pdf. ``` {.cpp}; // Multi- dimensional case from a TF1 (TF2 or TF3) objects; TUnuranMultiContDist dist( pdfFuncMulti);; // the recommended method for multi-dimensional function is ""hitro""; unr.Init(dist,""method=hitro"");; // sample distribution N times",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:19469,continuous,continuous,19469,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['continuous'],['continuous']
Deployability,"x; LaSumOfElements.cxx; LaVtMVSimilarity.cxx; MPIProcess.cxx; MinimumBuilder.cxx; Minuit2Minimizer.cxx; MnApplication.cxx; MnContours.cxx; MnCovarianceSqueeze.cxx; MnEigen.cxx; MnFcn.cxx; MnFumiliMinimize.cxx; MnFunctionCross.cxx; MnGlobalCorrelationCoeff.cxx; MnHesse.cxx; MnLineSearch.cxx; MnMachinePrecision.cxx; MnMinos.cxx; MnParabolaFactory.cxx; MnParameterScan.cxx; MnPlot.cxx; MnPosDef.cxx; MnPrint.cxx; MnPrintImpl.cxx; MnScan.cxx; MnSeedGenerator.cxx; MnStrategy.cxx; MnTiny.cxx; MnTraceObject.cxx; MnUserFcn.cxx; MnUserParameterState.cxx; MnUserParameters.cxx; MnUserTransformation.cxx; ModularFunctionMinimizer.cxx; NegativeG2LineSearch.cxx; Numerical2PGradientCalculator.cxx; ParametricFunction.cxx; ScanBuilder.cxx; SimplexBuilder.cxx; SimplexParameters.cxx; SimplexSeedGenerator.cxx; SinParameterTransformation.cxx; SqrtLowParameterTransformation.cxx; SqrtUpParameterTransformation.cxx; VariableMetricBuilder.cxx; VariableMetricEDMEstimator.cxx; mnbins.cxx; mndasum.cxx; mndaxpy.cxx; mnddot.cxx; mndscal.cxx; mndspmv.cxx; mndspr.cxx; mnlsame.cxx; mnteigen.cxx; mntplot.cxx; mnvert.cxx; mnxerbla.cxx; ). prepend_path(MINUIT2_HEADERS ""${Minuit2_SOURCE_DIR}/inc/Minuit2"" ${MINUIT2_HEADERS}); prepend_path(MINUIT2_SOURCES ""${CMAKE_CURRENT_SOURCE_DIR}"" ${MINUIT2_SOURCES}). add_library(Minuit2; ${MINUIT2_SOURCES}; ${MINUIT2_HEADERS}; ). # Add alias for direct inclusion with add_subdirectory; add_library(Minuit2::Minuit2 ALIAS Minuit2). target_include_directories(; Minuit2; PUBLIC; $<BUILD_INTERFACE:${Minuit2_SOURCE_DIR}/inc>; $<INSTALL_INTERFACE:include/Minuit2>; ). target_compile_features(Minuit2 PUBLIC cxx_nullptr cxx_nonstatic_member_init); set_target_properties(Minuit2 PROPERTIES CXX_EXTENSIONS OFF). target_link_libraries(Minuit2 PUBLIC Minuit2Math Minuit2Common). install(TARGETS Minuit2; EXPORT Minuit2Targets; LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}; ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR}; ). install(FILES ${MINUIT2_HEADERS} DESTINATION include/Minuit2/Minuit2); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/CMakeLists.txt:4488,install,install,4488,math/minuit2/src/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/src/CMakeLists.txt,2,['install'],['install']
Deployability,"xpects to take; ownership of a +1 retain count. This is done by adding the; ``ns_returns_retained`` attribute to the function or method declaration, like; so:. .. code-block:: objc. id foo(void) __attribute((ns_returns_retained));; - (id) foo __attribute((ns_returns_retained));. This attribute is part of the type of the function or method. When returning from such a function or method, ARC retains the value at the; point of evaluation of the return statement, before leaving all local scopes. When receiving a return result from such a function or method, ARC releases the; value at the end of the full-expression it is contained within, subject to the; usual optimizations for local values. .. admonition:: Rationale. This formalizes direct transfers of ownership from a callee to a caller. The; most common scenario this models is the retained return from ``init``,; ``alloc``, ``new``, and ``copy`` methods, but there are other cases in the; frameworks. After optimization there are typically no extra retains and; releases required. Methods in the ``alloc``, ``copy``, ``init``, ``mutableCopy``, and ``new``; :ref:`families <arc.method-families>` are implicitly marked; ``__attribute__((ns_returns_retained))``. This may be suppressed by explicitly; marking the method ``__attribute__((ns_returns_not_retained))``. It is undefined behavior if the method to which an Objective-C message send; statically resolves has different retain semantics on its result from the; method it dynamically resolves to. It is undefined behavior if a block or; function call is made through a static type with different retain semantics on; its result from the implementation of the called block or function. .. admonition:: Rationale. Mismatches with returned results will cause over-retains or over-releases,; depending on the direction. Again, the rule about function calls is really; just an application of the existing C/C++ rule about calling functions; through an incompatible function type. .. _arc.obje",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:20275,release,releases,20275,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['release'],['releases']
Deployability,"xpression to skip forward or backward from the current operation,; beginning after the 2-byte constant. If the updated position is at one past the end of the last operation, then; the operation expression evaluation is complete. Otherwise, the DWARF expression is ill-formed if the updated operation; position is not in the range of the first to last operation inclusive, or; not at the start of an operation. 4. ``DW_OP_bra``. ``DW_OP_bra`` is a conditional branch. Its single operand is a 2-byte signed; integer constant. This operation pops the top of stack. If the value popped; is not the constant 0, the 2-byte constant operand is the number of bytes of; the DWARF operation expression to skip forward or backward from the current; operation, beginning after the 2-byte constant. If the updated position is at one past the end of the last operation, then; the operation expression evaluation is complete. Otherwise, the DWARF expression is ill-formed if the updated operation; position is not in the range of the first to last operation inclusive, or; not at the start of an operation. 5. ``DW_OP_call2, DW_OP_call4, DW_OP_call_ref``. ``DW_OP_call2``, ``DW_OP_call4``, and ``DW_OP_call_ref`` perform DWARF; procedure calls during evaluation of a DWARF operation expression. ``DW_OP_call2`` and ``DW_OP_call4``, have one operand that is, respectively,; a 2-byte or 4-byte unsigned offset DR that represents the byte offset of a; debugging information entry D relative to the beginning of the current; compilation unit. ``DW_OP_call_ref`` has one operand that is a 4-byte unsigned value in the; 32-bit DWARF format, or an 8-byte unsigned value in the 64-bit DWARF format,; that represents the byte offset DR of a debugging information entry D; relative to the beginning of the ``.debug_info`` section that contains the; current compilation unit. D may not be in the current compilation unit. .. note::. DWARF Version 5 states that DR can be an offset in a ``.debug_info``; section other than the o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:72085,update,updated,72085,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['update'],['updated']
Deployability,"xtended fit by default if the pdf is extendible. This makes; the behavior consistent with `RooAbsPdf::fitTo()`. Same applies to; `RooAbsPdf::createChi2()`. ## TMVA; ### SOFIE : Code generation for fast inference of Deep Learning models; TMVA SOFIE now supports parsing and further inference of Graph Neural Networks based on DeepMind's [graph_nets](https://github.com/google-deepmind/graph_nets). The list of all operators supported in the `RModel` class is the one provided below for the ONNX parser. #### SOFIE-GNN; 1. The SOFIE-GNN implementation brought a major change in SOFIE's architecture. Instead of having only the RModel class to store model information, now SOFIE has RModel, RModel_GNN and RModel_GraphIndependent classes which are inherited from RModel_Base.; 2. **RModel_GNN** is used to store a GNN model having nodes, edges, and globals with functions for their update and aggregate(for inter-relationships).; 3. **RModel_GraphIndependent** is used to store an independent Graph model with nodes, edges and globals with their individual update functions.; 4. **RFunctions** are used to declare update/aggregate operations over graph components. Currently supported RFunctions include:; - **Update Functions**; - RFunction_MLP; - **Aggregate Functions**; - RFunction_Mean; - RFunction_Sum; 5. Pythonized functions for parsing a Graphnets' model can be used to generate inference code; ```; import graph_nets as gn; from graph_nets import utils_tf. GraphModule = gn.modules.GraphNetwork(; edge_model_fn=lambda: snt.nets.MLP([2,2], activate_final=True),; node_model_fn=lambda: snt.nets.MLP([2,2], activate_final=True),; global_model_fn=lambda: snt.nets.MLP([2,2], activate_final=True)). GraphData = get_graph_data_dict(2,1,2,2,2). model = ROOT.TMVA.Experimental.SOFIE.RModel_GNN.ParseFromMemory(GraphModule, GraphData); model.Generate(); model.OutputGenerated(). ```; A complete tutorial for the SOFIE-GNN implementation can be found [here](https://github.com/root-project/root/blob/mas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:17638,update,update,17638,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,1,['update'],['update']
Deployability,"xtra_args ""-D${new_name}=${new_value}""); endif(); endif(); endforeach(). llvm_ExternalProject_Add(builtins-${name}; ${compiler_rt_path}/lib/builtins; DEPENDS ${ARG_DEPENDS}; CMAKE_ARGS -DLLVM_LIBRARY_OUTPUT_INTDIR=${LLVM_LIBRARY_DIR}; -DLLVM_RUNTIME_OUTPUT_INTDIR=${LLVM_TOOLS_BINARY_DIR}; -DLLVM_ENABLE_PER_TARGET_RUNTIME_DIR=ON; -DCMAKE_C_COMPILER_WORKS=ON; -DCMAKE_ASM_COMPILER_WORKS=ON; -DCOMPILER_RT_DEFAULT_TARGET_ONLY=ON; ${COMMON_CMAKE_ARGS}; ${${name}_extra_args}; USE_TOOLCHAIN; ${EXTRA_ARGS} ${ARG_EXTRA_ARGS}); endfunction(). # If compiler-rt is present we need to build the builtin libraries first. This; # is required because the other runtimes need the builtin libraries present; # before the just-built compiler can pass the configuration tests.; get_compiler_rt_path(compiler_rt_path); if(compiler_rt_path); if(NOT LLVM_BUILTIN_TARGETS); builtin_default_target(${compiler_rt_path}; DEPENDS clang-resource-headers); else(); if(""default"" IN_LIST LLVM_BUILTIN_TARGETS); builtin_default_target(${compiler_rt_path}; DEPENDS clang-resource-headers); list(REMOVE_ITEM LLVM_BUILTIN_TARGETS ""default""); else(); add_custom_target(builtins); add_custom_target(install-builtins); add_custom_target(install-builtins-stripped); endif(). foreach(target ${LLVM_BUILTIN_TARGETS}); check_apple_target(${target} builtin). builtin_register_target(${compiler_rt_path} ${target}; DEPENDS clang-resource-headers; CMAKE_ARGS -DLLVM_DEFAULT_TARGET_TRIPLE=${target}; EXTRA_ARGS TARGET_TRIPLE ${target}). add_dependencies(builtins builtins-${target}); add_dependencies(install-builtins install-builtins-${target}); add_dependencies(install-builtins-stripped install-builtins-${target}-stripped); endforeach(); endif(); set(builtins_dep builtins); # We don't need to depend on the builtins if we're building instrumented; # because the next stage will use the same compiler used to build this stage.; if(NOT LLVM_BUILD_INSTRUMENTED AND CLANG_ENABLE_BOOTSTRAP); add_dependencies(clang-bootstrap-deps builtins); e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt:5252,install,install-builtins,5252,interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,2,['install'],"['install-builtins', 'install-builtins-stripped']"
Deployability,"xtract) # now empty (or invalid); 0; >>> extract = boost.any_cast[std.vector[int]](val); >>> list(extract); [0, 1, 2, 3, 4, 5, 6, ..., 97, 98, 99]; >>>. Of course, there is no reason to use Boost from Python (in fact, this example; calls out for :doc:`pythonizations <pythonizations>`), but it shows that; cppyy seamlessly supports many advanced C++ features. cppyy is available for both `CPython`_ (v2 and v3) and `PyPy`_, reaching; C++-like performance with the latter.; It makes judicious use of precompiled headers, dynamic loading, and lazy; instantiation, to support C++ programs consisting of millions of lines of; code and many thousands of classes.; cppyy minimizes dependencies to allow its use in distributed, heterogeneous,; development environments. .. _Cling: https://github.com/vgvassilev/cling; .. _tutorial: https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb; .. _`PyHPC'16 paper`: http://wlav.web.cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf; .. _`CAAS presentation`: https://www.youtube.com/watch?v=stMD7VDWlVU; .. _`Jason Turner's`: https://www.youtube.com/watch?v=TL83P77vZ1k; .. _`Boost`: http://www.boost.org/; .. _`CPython`: http://python.org; .. _`PyPy`: http://pypy.org. .. only: not latex. Contents:. .. toctree::; :maxdepth: 1. changelog; license. .. toctree::; :caption: Getting Started; :maxdepth: 1. installation; starting; examples; bugs. .. toctree::; :caption: Features; :maxdepth: 1. toplevel; basic_types; strings; classes; functions; type_conversions; stl; exceptions; python; numba; cuda; lowlevel; misc; debugging. .. toctree::; :caption: Redistribution; :maxdepth: 1. pythonizations; utilities; cmake_interface. .. toctree::; :caption: Developers; :maxdepth: 1. packages; repositories; testing. .. toctree::; :caption: Background; :maxdepth: 1. history; philosophy. Bugs and feedback; -----------------. Please report bugs or requests for improvement on the `issue tracker`_. .. _`issue tracker`: https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:5244,install,installation,5244,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst,1,['install'],['installation']
Deployability,"y across; the project. Specifically, our code review process aims to:. * Improve readability and maintainability.; * Improve robustness and prevent the introduction of defects.; * Best leverage the experience of other contributors for each proposed change.; * Help grow and develop new contributors, through mentorship by community leaders. It is important for all contributors to understand our code-review; practices and participate in the code-review process. General Policies; ================. What Code Should Be Reviewed?; -----------------------------. All developers are required to have significant changes reviewed before they; are committed to the repository. Must Code Be Reviewed Prior to Being Committed?; -----------------------------------------------. Code can be reviewed either before it is committed or after. We expect; significant patches to be reviewed before being committed. Smaller patches; (or patches where the developer owns the component) that meet; likely-community-consensus requirements (as apply to all patch approvals) can; be committed prior to an explicit review. In situations where there is any; uncertainty, a patch should be reviewed prior to being committed. Please note that the developer responsible for a patch is also; responsible for making all necessary review-related changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:1096,patch,patches,1096,interpreter/llvm-project/llvm/docs/CodeReview.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst,3,['patch'],"['patch', 'patches']"
Deployability,"y and gFile are now all accessed via a static function of their respective class. The access is made transparent via a CPP macro. Note: Whenever a thread has an associated TThread object, the value of gDirectory is now thread local, i.e. all modifications direct or indirect of gDirectory will not be seen by the other thread. In particular this means that several I/O operations (including TDirectory::Write) are thread safe (as long as all the required TClass and TStreamerInfo has been previously setup).; Note: This model does not support sharing TFile amongst threads (i.e. a TFile must be accessed from exactly one thread). This means that whenever a TFile's control is passed from a thread to another, the code must explicitly reset gDirectory to another value or there is a risk for this gDirectory to point to a stale pointer if the other thread deletes the TFile object. A TFile deletion will only affect the value of the local gDirectory and gFile. TMemFile; Introduce TMemFile and update TFileMerger to support incremental merges. Add new tutorials (net/treeClient.C + net/fastMergeServer.C); demonstrating how a TMemFile can be used to do parallel merge; from many clients. (TMemFile still needs to be better integrated; with TMessage and TSocket). The new TMemFile class support the TFile interface but only store; the information in memory. This version is limited to 32MB. TMessage mess;; ...; mess->ReadFastArray(scratch,length);; transient = new TMemFile(""hsimple.memroot"",scratch,length);. will copy the content of 'scratch' into the in-memory buffer; created by/for the TMemFile. TMemFile *file = new TMemFile(""hsimple.memroot"",""RECREATE"");. Will create an empty in-memory of (currently fixed) size 32MB. file->ResetAfterMerge(0);. Will reset the objects in the TDirectory list of objects; so that they are ready for more data accumulations (i.e.; returns the data to 0 but keep the customizations). TFile::MakeProject. New option 'par' in to pack in a PAR file the generated; code",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html:3974,update,update,3974,io/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html,1,['update'],['update']
Deployability,"y as a backend that is compiled multiple times for different instruction sets.; With this release, `RooBatchCompute` is also compiled with the Nvidia CUDA compiler to support the computation on GPUs if supported by the RooFit object.; You can use the CUDA mode by passing `""cuda""` to the `BatchMode()` command argument:; ```C++; model.fitTo(data); // not using the batch mode; model.fitTo(data, RooFit::BatchMode(true)); // using the BatchMode on CPU (RooFit::BatchMode(""cpu"") is equivalent); model.fitTo(data, RooFit::BatchMode(""cuda"")); // using the new CUDA backend; ```. The `RooBatchCompute` backend now also supports ROOT's implicit multithreading (similar to RDataFrame), which can be enabled as follows:; ```C++; ROOT::EnableImplicitMT(nThreads);; ```. For more information, please have a look at this [contribution to the ACAT 2021 conference](https://indico.cern.ch/event/855454/contributions/4596763/) or consult the [RooBatchComupte README](https://github.com/root-project/root/tree/v6-26-00-patches/roofit/batchcompute).; The README also describes how to enable BatchMode support for your own PDFs. ### Parallel calculation of likelihood gradients during fitting; This release features two new optional RooFit libraries: `RooFit::MultiProcess` and `RooFit::TestStatistics`.; To activate both, build with `-Droofit_multiprocess=ON`. The `RooFit::TestStatistics` namespace contains a major refactoring of the `RooAbsTestStatistic`-`RooAbsOptTestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;; 2. calculation/evaluation/optimization based classes on the other hand. The main selling point of using `RooFit::TestStatistics` from a performance point of view is the implementation of the `RooFit::MultiProcess` based `LikelihoodGradientJob` calculator class.; To use it to perform a ""migrad"" fit (using Minuit2), one should create a `RooMinimizer` using a new constructor with a `RooAbsL` likelihood parameter as follows:. ```c++; using RooFit::Test",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:16328,patch,patches,16328,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['patch'],['patches']
Deployability,"y common collector designs and easy; extension points. If you don't already have a specific binary interface; you need to support, we recommend trying to use one of these built in collector; strategies. .. _gc_intrinsics:. LLVM IR Features; ================. This section describes the garbage collection facilities provided by the; :doc:`LLVM intermediate representation <LangRef>`. The exact behavior of these; IR features is specified by the selected :ref:`GC strategy description; <plugin>`. Specifying GC code generation: ``gc ""...""``; -------------------------------------------. .. code-block:: text. define <returntype> @name(...) gc ""name"" { ... }. The ``gc`` function attribute is used to specify the desired GC strategy to the; compiler. Its programmatic equivalent is the ``setGC`` method of ``Function``. Setting ``gc ""name""`` on a function triggers a search for a matching subclass; of GCStrategy. Some collector strategies are built in. You can add others; using either the loadable plugin mechanism, or by patching your copy of LLVM.; It is the selected GC strategy which defines the exact nature of the code; generated to support GC. If none is found, the compiler will raise an error. Specifying the GC style on a per-function basis allows LLVM to link together; programs that use different garbage collection algorithms (or none at all). .. _gcroot:. Identifying GC roots on the stack; ----------------------------------. LLVM currently supports two different mechanisms for describing references in; compiled code at safepoints. ``llvm.gcroot`` is the older mechanism;; ``gc.statepoint`` has been added more recently. At the moment, you can choose; either implementation (on a per :ref:`GC strategy <plugin>` basis). Longer; term, we will probably either migrate away from ``llvm.gcroot`` entirely, or; substantially merge their implementations. Note that most new development; work is focused on ``gc.statepoint``. Using ``gc.statepoint``; ^^^^^^^^^^^^^^^^^^^^^^^^; :doc:`This pa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:8975,patch,patching,8975,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['patch'],['patching']
Deployability,"y contains all header files. It is especially; important because the header files contain the class definitions. ### \$ROOTSYS/\<library\>. The directories we explored above are available when downloading the; binaries. When downloading the source you also get a directory for; each library with the corresponding header and source files, located; in the `inc` and `src` subdirectories. To see what classes are in a; library, you can check the `<library>/inc` directory for the list of; class definitions. For example, the physics library `libPhysics.so`; contains these class definitions:. ``` {.cpp}; > ls -m $ROOTSYS/math/physics/inc/; LinkDef.h, TFeldmanCousins.h, TGenPhaseSpace.h, TLorentzRotation.h,; TLorentzVector.h, TQuaternion.h, TRobustEstimator.h, TRolke.h,; TRotation.h, TVector2.h, TVector3.h; ```. ## How to Find More Information. website The ROOT web site has up to date documentation. The ROOT; source code automatically generates this documentation, so each class; is explicitly documented on its own web page, which is always up to; date with the latest official release of ROOT. The ROOT Reference Guide web pages can be found at class index; reference guide <https://root.cern/doc/master/classes.html>. Each; page contains a class description, and an explanation of each method.; It shows the class inheritance tree and lets you jump to the parent; class page by clicking on the class name. If you want more details,; you can even see the source. There is a help page available in the; little box on the upper right hand side of each class documentation; page. You can see on the next page what a typical class documentation; web page looks like. The ROOT web site also contains in addition to; this Reference Guide, ""How To's"", a list of publications and example; applications. ### Class Reference Guide. The top of any class reference page lets you jump to different parts; of the documentation. The first line links to the class index and the; index for the current module (a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:24396,release,release,24396,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['release'],['release']
Deployability,"y default unless; ``LLVM_BUILD_DOCS`` is enabled). There is a target for each project in the; source tree that uses sphinx (e.g. ``docs-llvm-html``, ``docs-clang-html``; and ``docs-lld-html``). Defaults to ON. **SPHINX_OUTPUT_MAN**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) the targets for building; the man pages are added (but not built by default unless ``LLVM_BUILD_DOCS``; is enabled). Currently the only target added is ``docs-llvm-man``. Defaults; to ON. **SPHINX_WARNINGS_AS_ERRORS**:BOOL; If enabled then sphinx documentation warnings will be treated as; errors. Defaults to ON. Advanced variables; ~~~~~~~~~~~~~~~~~~. These are niche, and changing them from their defaults is more likely to cause; things to go wrong. They are also unstable across LLVM versions. **LLVM_TOOLS_INSTALL_DIR**:STRING; The path to install the main LLVM tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORC",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:38175,install,install,38175,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['install'],['install']
Deployability,"y operand support. - ``D``: Print the second register of a two-register operand, or prints the; second word of a double-word memory operand. (On a big-endian system, ``D`` is; equivalent to ``L``, and on little-endian system, ``D`` is equivalent to; ``M``.); - ``w``: No effect. Provided for compatibility with GCC which requires this; modifier in order to print MSA registers (``W0-W31``) with the ``f``; constraint. NVPTX:. - ``r``: No effect. PowerPC:. - ``L``: Print the second register of a two-register operand. Requires that it; has been allocated consecutively to the first. .. FIXME: why is it restricted to consecutive ones? And there's; nothing that ensures that happens, is there?. - ``I``: Print the letter 'i' if the operand is an integer constant, otherwise; nothing. Used to print 'addi' vs 'add' instructions.; - ``y``: For a memory operand, prints formatter for a two-register X-form; instruction. (Currently always prints ``r0,OPERAND``).; - ``U``: Prints 'u' if the memory operand is an update form, and nothing; otherwise. (NOTE: LLVM does not support update form, so this will currently; always print nothing); - ``X``: Prints 'x' if the memory operand is an indexed form. (NOTE: LLVM does; not support indexed form, so this will currently always print nothing). RISC-V:. - ``i``: Print the letter 'i' if the operand is not a register, otherwise print; nothing. Used to print 'addi' vs 'add' instructions, etc.; - ``z``: Print the register ``zero`` if an immediate zero, otherwise print; normally. Sparc:. - ``L``: Print the low-order register of a two-register operand.; - ``H``: Print the high-order register of a two-register operand.; - ``r``: No effect. SystemZ:. SystemZ implements only ``n``, and does *not* support any of the other; target-independent modifiers. X86:. - ``c``: Print an unadorned integer or symbol name. (The latter is; target-specific behavior for this typically target-independent modifier).; - ``A``: Print a register name with a '``*``' before it.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:239430,update,update,239430,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['update'],['update']
Deployability,"y out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of; intrinsic calls known collectively as a ""statepoint relocation sequence"". Let's consider a simple call in LLVM IR:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call void ()* @foo(); ret i8 addrspace(1)* %obj; }. Depending on our language we may need to allow a safepoint during the execution; of ``foo``. If so, we need to let the collector update local values in the; current frame. If we don't, we'll be accessing a potential invalid reference; once we eventually return from the call. In this example, we need to relocate the SSA value ``%obj``. Since we can't; actually change the value in the SSA value ``%obj``, we need to introduce a new; SSA value ``%obj.relocated`` which represents the potentially changed value of; ``%obj`` after the safepoint and update any following uses appropriately. The; resulting relocation sequence is:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; %0 = call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj); %obj.relocated = call coldcc i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %0, i32 7, i32 7); ret i8 addrspace(1)* %obj.relocated; }. Ideally, this sequence would have been represented as a M argument, N; return value function (where M is the number of values being; relocated + the original call arguments and N is the original return; value + each relocated value), but LLVM does not easily support such a; representation. Instead, the statepoint intrinsic marks the actual site of the; safepoint or statepoint. The statepoint returns a token value (which; exists only at compile time). To get",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:8711,update,update,8711,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['update'],['update']
Deployability,"y the preprocessed content of; ""system"" headers to the output; instead, preserve the #include directive.; This can greatly reduce the volume of text produced by :option:`-E` which; can be helpful when trying to produce a ""small"" reproduceable test case. This option does not guarantee reproduceability, however. If the including; source defines preprocessor symbols that influence the behavior of system; headers (for example, ``_XOPEN_SOURCE``) the operation of :option:`-E` will; remove that definition and thus can change the semantics of the included; header. Also, using a different version of the system headers (especially a; different version of the STL) may result in different behavior. Always verify; the preprocessed file by compiling it separately. ENVIRONMENT; -----------. .. envvar:: TMPDIR, TEMP, TMP. These environment variables are checked, in order, for the location to write; temporary files used during the compilation process. .. envvar:: CPATH. If this environment variable is present, it is treated as a delimited list of; paths to be added to the default system include path list. The delimiter is; the platform dependent delimiter, as used in the PATH environment variable. Empty components in the environment variable are ignored. .. envvar:: C_INCLUDE_PATH, OBJC_INCLUDE_PATH, CPLUS_INCLUDE_PATH, OBJCPLUS_INCLUDE_PATH. These environment variables specify additional paths, as for :envvar:`CPATH`, which are; only used when processing the appropriate language. .. envvar:: MACOSX_DEPLOYMENT_TARGET. If :option:`-mmacosx-version-min` is unspecified, the default deployment; target is read from this environment variable. This option only affects; Darwin targets. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/issues/>. Most bug reports should; include preprocessed source files (use the :option:`-E` option) and the full; output of the compiler, along with information to reproduce. SEE ALSO; --------. :manpage:`as(1)`, :manpage:`ld(1)`; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:21553,deploy,deployment,21553,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['deploy'],['deployment']
Deployability,"y the program, so we preserve all analyses; void getAnalysisUsage(AnalysisUsage &AU) const override {; AU.setPreservesAll();; }. Now when we run our pass, we get this output:. .. code-block:: console. $ opt -load lib/LLVMHello.so -gvn -hello -licm --debug-pass=Structure < hello.bc > /dev/null; Pass Arguments: -gvn -hello -licm; ModulePass Manager; FunctionPass Manager; Dominator Tree Construction; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Memory Dependence Analysis; Global Value Numbering; Hello World Pass; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Which shows that we don't accidentally invalidate dominator information; anymore, and therefore do not have to compute it twice. .. _writing-an-llvm-pass-releaseMemory:. The ``releaseMemory`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void releaseMemory();. The ``PassManager`` automatically determines when to compute analysis results,; and how long to keep them around for. Because the lifetime of the pass object; itself is effectively the entire duration of the compilation process, we need; some way to free analysis results when they are no longer useful. The; ``releaseMemory`` virtual method is the way to do this. If you are writing an analysis or any other pass that retains a significant; amount of state (for use by another pass which ""requires"" your pass and uses; the :ref:`getAnalysis <writing-an-llvm-pass-getAnalysis>` method) you should; implement ``releaseMemory`` to, well, release the memory allocated to maintain; this internal state. This method is called after the ``run*`` method for the; class, before the next call of ``run*`` in your pass. Registering dynamically loaded passes; ===================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:46861,release,releaseMemory,46861,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['release'],['releaseMemory']
Deployability,"y the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These conditional move instructions are known to not be predicted on any x86; processors, making them immune to misprediction that could reintroduce the; vulnerability. When we insert the conditional moves, the code ends up looking; like the following:; ```; # %bb.0: # %entry; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; testl %edi, %edi; jne .LBB0_1; # %bb.2: # %then1; cmovneq %r8, %rax # Conditionally update predicate state.; testl %esi, %esi; jne .LBB0_1; # %bb.3: # %then2; cmovneq %r8, %rax # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; ...; ```. Here we create the ""empty"" or ""correct execution"" predicate state by zeroing; `%rax`, and we create a constant ""incorrect execution"" predicate value by; putting `-1` into `%r8`. Then, along each edge coming out of a conditional; branch we do a conditional move that in a correct execution will be a no-op,; but if misspeculated, will replace the `%rax` with the value of `%r8`.; Misspeculating any one of the three predicates will cause `%rax` to hold the; ""incorrect execution"" value from `%r8` as we preserve incoming values when; execution is correct rather than overwriting it. We now have a value in `%rax` in each basic block that indicates if at some; point previously a predicate was mispredicted. And we have arranged for that; value to be particularly effective when used below to harden loads. ##### Indirect Call, Branch, and Return Predicates. The",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:16875,update,update,16875,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['update'],['update']
Deployability,"y to reduce the; number of entries in the TOC.; * Added a number of missing Power10 extended mnemonics.; * Added the SCV instruction.; * Fixed register class for the paddi instruction.; * Optimize VPERM and fix code order for swapping vector operands on LE.; * Added various bug fixes and code gen improvements. AIX Support/improvements:. * Support for a non-TOC-based access sequence for the local-exec TLS model (called small local-exec).; * XCOFF toc-data peephole optimization and bug fixes.; * Move less often used __ehinfo TOC entries to the end of the TOC section.; * Fixed problems when the AIX libunwind unwinds starting from a signal handler; and the function that raised the signal happens to be a leaf function that; shares the stack frame with its caller or a leaf function that does not store; the stack frame backchain. Changes to the RISC-V Backend; -----------------------------. * The Zfa extension version was upgraded to 1.0 and is no longer experimental.; * Zihintntl extension version was upgraded to 1.0 and is no longer experimental.; * Intrinsics were added for Zk*, Zbb, and Zbc. See https://github.com/riscv-non-isa/riscv-c-api-doc/blob/master/riscv-c-api.md#scalar-bit-manipulation-extension-intrinsics; * Default ABI with F but without D was changed to ilp32f for RV32 and to lp64f for RV64.; * The Zvbb, Zvbc, Zvkb, Zvkg, Zvkn, Zvknc, Zvkned, Zvkng, Zvknha, Zvknhb, Zvks,; Zvksc, Zvksed, Zvksg, Zvksh, and Zvkt extension version was upgraded to 1.0; and is no longer experimental. However, the C intrinsics for these extensions; are still experimental. To use the C intrinsics for these extensions,; ``-menable-experimental-extensions`` needs to be passed to Clang.; * XSfcie extension and SiFive CSRs and instructions that were associated with; it have been removed. None of these CSRs and instructions were part of; ""SiFive Custom Instruction Extension"" as SiFive defines it. The LLVM project; needs to work with SiFive to define and document real extension names for;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst:6932,upgrade,upgraded,6932,interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,1,['upgrade'],['upgraded']
Deployability,"y to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ###",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2157,configurat,configuration,2157,proof/doc/confman/UsingVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md,3,"['configurat', 'install']","['configuration', 'installed']"
Deployability,"y, the last; (boolean) argument determines whether your new importer should be; added at the top of the priority list (`true`) or at the bottom; (`false`). If the import fails, other importers are attempted. The implementation of an exporter works in a very similar fashion:. ``` {.cpp}; class MyClassStreamer : public RooFit::JSONIO::Exporter {; public:; std::string const &key() const override; {; const static std::string keystring = ""<json key>"";; return keystring;; }; bool exportObject(RooJSONFactoryWSTool *, const RooAbsArg *func, JSONNode &elem) const override; {; const MyClass *theObj = static_cast<const MyClass *>(func);; elem[""type""] << key();. auto &member1 = elem[""<class member key #1>""];; member1 << theObj->getMember1();. auto &member2 = elem[""<class member key #2>""];; member2 << theObj->getMember2();. return true;; }; };; ```. Also this needs to be registered with the tool. ``` {.cpp}; RooFit::JSONIO::registerExporter(MyClass::Class(), new MyClassStreamer(), true);; ```. For more complicated cases where members are lists of elements, the; methods `is_seq()`, `set_seq()`, `is_map()`, `set_map()` and; ranged-based for-loops via `children()` might come in handy. ### Contributing. If you encounter a missing importer or exporter, please consider; filing a feature request via the; [issue tracker](https://github.com/root-project/root/issues/new?assignees=&labels=new+feature&template=feature_request.md). If you don't want to wait for one of the dev's to pick up your request; an process it, you can use the above instructions to write your own.; If you wrote an importer or exporter for a `RooFit` class that is part; of `ROOT`, either via `export keys` and `factory expressions`, or via; native `C++` classes, please consider contributing your implementation; to `ROOT` such that it can help other users also missing this importer; or exporter. You can fork `ROOT`, commit your changes, and file a pull; request to `ROOT` for your work to be included in the next release!. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_hs3.md:8507,release,release,8507,roofit/doc/developers/roofit_hs3.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_hs3.md,1,['release'],['release']
Deployability,"y. If any tests did fail, the; Failing Tests (count): message will be followed by a list; of the test source file paths that failed. For example:. Failing Tests (3):; /home/john/llvm/tools/clang/test/SemaCXX/member-name-lookup.cpp; /home/john/llvm/tools/clang/test/SemaCXX/namespace-alias.cpp; /home/john/llvm/tools/clang/test/SemaCXX/using-directive.cpp. If you used the make VERBOSE=1 option, the terminal; output will reflect the error messages from the compiler and; test runner.; The regression suite can also be run with Valgrind by running; make test VG=1 in the top-level clang directory.; For more intensive changes, running; the LLVM; Test Suite with clang is recommended. Currently the best way to; override LLVMGCC, as in: make LLVMGCC=""clang -std=gnu89""; TEST=nightly report (make sure clang is in your PATH or use the; full path). Testing using Visual Studio on Windows. The Clang test suite can be run from either Visual Studio or; the command line.; Note that the test runner is based on; Python, which must be installed. Find Python at:; https://www.python.org/downloads/.; Download the latest stable version.; The GnuWin32 tools are also necessary for running the tests.; Get them from ; http://getgnuwin32.sourceforge.net/.; If the environment variable %PATH% does not have GnuWin32,; or if other grep(s) supercedes GnuWin32 on %PATH%,; you should specify LLVM_LIT_TOOLS_DIR; to CMake explicitly.; The cmake build tool is set up to create Visual Studio project files; for running the tests, ""check-clang"" being the root. Therefore, to; run the test from Visual Studio, right-click the check-clang project; and select ""Build"". Please see also; Getting Started; with the LLVM System using Microsoft Visual Studio and; Building LLVM with CMake.; . Testing on the Command Line. If you want more control over how the tests are run, it may; be convenient to run the test harness on the command-line directly. Before; running tests from the command line, you will need to ensure that; lit.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/hacking.html:4784,install,installed,4784,interpreter/llvm-project/clang/www/hacking.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/hacking.html,1,['install'],['installed']
Deployability,"y; clang-format is turned off or back on. .. code-block:: c++. int formatted_code;; // clang-format off; void unformatted_code ;; // clang-format on; void formatted_code_again;. Configuring Style in Code; =========================. When using ``clang::format::reformat(...)`` functions, the format is specified; by supplying the `clang::format::FormatStyle; <https://clang.llvm.org/doxygen/structclang_1_1format_1_1FormatStyle.html>`_; structure. Configurable Format Style Options; =================================. This section lists the supported style options. Value type is specified for; each option. For enumeration types possible values are specified both as a C++; enumeration member (with a prefix, e.g. ``LS_Auto``), and as a value usable in; the configuration (without a prefix: ``Auto``). .. _BasedOnStyle:. **BasedOnStyle** (``String``) :ref:`¶ <BasedOnStyle>`; The style used for all options not specifically set in the configuration. This option is supported only in the :program:`clang-format` configuration; (both within ``-style='{...}'`` and the ``.clang-format`` file). Possible values:. * ``LLVM``; A style complying with the `LLVM coding standards; <https://llvm.org/docs/CodingStandards.html>`_; * ``Google``; A style complying with `Google's C++ style guide; <https://google.github.io/styleguide/cppguide.html>`_; * ``Chromium``; A style complying with `Chromium's style guide; <https://chromium.googlesource.com/chromium/src/+/refs/heads/main/styleguide/styleguide.md>`_; * ``Mozilla``; A style complying with `Mozilla's style guide; <https://firefox-source-docs.mozilla.org/code-quality/coding-style/index.html>`_; * ``WebKit``; A style complying with `WebKit's style guide; <https://www.webkit.org/coding/coding-style.html>`_; * ``Microsoft``; A style complying with `Microsoft's style guide; <https://docs.microsoft.com/en-us/visualstudio/ide/editorconfig-code-style-settings-reference>`_; * ``GNU``; A style complying with the `GNU coding standards; <https://www.gnu.org",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:5266,configurat,configuration,5266,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"you must export ``MACOSX_DEPLOYMENT_TARGET=10.9`` before running; the script. This script builds three phases of Clang+LLVM twice each (Release and; Release+Asserts), so use screen or nohup to avoid headaches, since it'll take; a long time. Use the ``--help`` option to see all the options and chose it according to; your needs. findRegressions-nightly.py; --------------------------. TODO. .. _test-suite:. Test Suite; ==========. .. contents::; :local:. Follow the `LNT Quick Start Guide; <https://llvm.org/docs/lnt/quickstart.html>`__ link on how to set-up the; test-suite. The binary location you'll have to use for testing is inside the; ``rcN/Phase3/Release+Asserts/llvmCore-REL-RC.install``.; Link that directory to an easier location and run the test-suite. An example on the run command line, assuming you created a link from the correct; install directory to ``~/devel/llvm/install``::. ./sandbox/bin/python sandbox/bin/lnt runtest \; nt \; -j4 \; --sandbox sandbox \; --test-suite ~/devel/llvm/test/test-suite \; --cc ~/devel/llvm/install/bin/clang \; --cxx ~/devel/llvm/install/bin/clang++. It should have no new regressions, compared to the previous release or release; candidate. You don't need to fix all the bugs in the test-suite, since they're; not necessarily meant to pass on all architectures all the time. This is; due to the nature of the result checking, which relies on direct comparison,; and most of the time, the failures are related to bad output checking, rather; than bad code generation. If the errors are in LLVM itself, please report every single regression found; as blocker, and all the other bugs as important, but not necessarily blocking; the release to proceed. They can be set as ""known failures"" and to be; fix on a future date. .. _pre-release-process:. Pre-Release Process; ===================. .. contents::; :local:. When the release process is announced on the mailing list, you should prepare; for the testing, by applying the same testing you'll do on",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst:4016,install,install,4016,interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,2,['install'],['install']
Deployability,"you're using Clang as the cross-compiler, there is a problem in; the LLVM ARM back-end that is producing absolute relocations on; position-independent code (``R_ARM_THM_MOVW_ABS_NC``), so for now, you; should disable PIC:. .. code-block:: bash. -DLLVM_ENABLE_PIC=False. This is not a problem, since Clang/LLVM libraries are statically; linked anyway, it shouldn't affect much. #. The ARM libraries won't be installed in your system.; But the CMake prepare step, which checks for; dependencies, will check the *host* libraries, not the *target*; ones. Below there's a list of some dependencies, but your project could; have more, or this document could be outdated. You'll see the errors; while linking as an indication of that. Debian based distros have a way to add ``multiarch``, which adds; a new architecture and allows you to install packages for those; systems. See https://wiki.debian.org/Multiarch/HOWTO for more info. But not all distros will have that, and possibly not an easy way to; install them in any anyway, so you'll have to build/download; them separately. A quick way of getting the libraries is to download them from; a distribution repository, like Debian (http://packages.debian.org/jessie/),; and download the missing libraries. Note that the ``libXXX``; will have the shared objects (``.so``) and the ``libXXX-dev`` will; give you the headers and the static (``.a``) library. Just in; case, download both. The ones you need for ARM are: ``libtinfo``, ``zlib1g``,; ``libxml2`` and ``liblzma``. In the Debian repository you'll; find downloads for all architectures. After you download and unpack all ``.deb`` packages, copy all; ``.so`` and ``.a`` to a directory, make the appropriate; symbolic links (if necessary), and add the relevant ``-L``; and ``-I`` paths to ``-DCMAKE_CXX_FLAGS`` above. Running CMake and Building; --------------------------. Finally, if you're using your platform compiler, run:. .. code-block:: bash. $ cmake -G Ninja <source-dir> -DCMAKE_BUILD_TYPE=<",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToCrossCompileLLVM.rst:5289,install,install,5289,interpreter/llvm-project/llvm/docs/HowToCrossCompileLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToCrossCompileLLVM.rst,1,['install'],['install']
Deployability,"your GnuPG key, use the following command:; ```sh; gpg --fingerprint; ```; Again, all these checks are performed by default when you launch CPT with ```-c``` option.; [Ubuntu Packaging Guide]:http://packaging.ubuntu.com/html/getting-set-up.html#create-your-gpg-key. #### Windows; CPT is meant to be executed on cmd.exe prompt. Make sure you have set the; environment properly before continuing.; Below is a list of required packages for Windows (Win32-x86):. [MSYS Git] for Windows. [Python] for Windows. Microsoft Visual Studio 11 (2012), with Microsoft Visual C++ 2012. [MSYS Git]:http://msysgit.github.io/; [Python]:https://www.python.org/. ###### Setting Up:; Unlike other UNIX-like platforms, Windows requires you to follow some rules.; Do not ignore this section unless you want CPT to fail mid-way with wierd; errors. You should require these instructions only once. * While installing the packages make sure the executable is in a path that; doesn't contain spaces. For example, you should install Python in a path like. ```sh; C:\Python27; ```; rather than. ```sh; C:\Program Files (x86)\Python 2.7; ```; * Path to all the required executables should be present in the Windows; **PATH** environment variable.; * In case of MSYS Git, choose the option ""Run Git from Windows; Command Prompt"" during installation. A good way to check if everything is detected properly by the script is to; run the following command:; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```. #### Red Hat Linux (Fedora/Scientific Linux CERN); This section applies to all distros based on Red Hat Linux like Fedora, and; Scientific Linux CERN (SLC). Apparently, you can build RPM packages in any; distro regardless of the package manager it uses. This has been tested on; Fedora, SLC, Ubuntu, and CrunchBang. If you are interested, you can test it; on your favourite platform and email me the results. Depending on the package manager of your distro, you can install the; packages required by CPT to build ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:4285,install,install,4285,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,1,['install'],['install']
Deployability,"your comments, scroll to the bottom of the page and; click the Submit button. You can add overall comments in the text box at the bottom of the page.; When you're done, click the Submit button. Phabricator has many useful features, for example allowing you to select; diffs between different versions of the patch as it was reviewed in the; *Revision Update History*. Most features are self descriptive - explore, and; if you have a question, drop by on #llvm in IRC to get help. Note that as e-mail is the system of reference for code reviews, and some; people prefer it over a web interface, we do not generate automated mail; when a review changes state, for example by clicking ""Accept Revision"" in; the web interface. Thus, please type LGTM into the comment box to accept; a change from Phabricator. .. _pre-merge-testing:. Pre-merge testing; -----------------. The pre-merge tests are a continuous integration (CI) workflow. The workflow; checks the patches uploaded to Phabricator before a user merges them to the main; branch - thus the term *pre-merge testing*. When a user uploads a patch to Phabricator, Phabricator triggers the checks and; then displays the results. This way bugs in a patch are contained during the; code review stage and do not pollute the main branch. Our goal with pre-merge testing is to report most true problems while strongly; minimizing the number of false positive reports. Our goal is that problems; reported are always actionable. If you notice a false positive, please report; it so that we can identify the cause. If you notice issues or have an idea on how to improve pre-merge checks, please; `create a new issue <https://github.com/google/llvm-premerge-checks/issues/new>`_; or give a ❤️ to an existing one. Requirements; ^^^^^^^^^^^^. To get a patch on Phabricator tested, the build server must be able to apply the; patch to the checked out git repository. Please make sure that either:. * You set a git hash as ``sourceControlBaseRevision`` in Phabric",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst:10485,patch,patches,10485,interpreter/llvm-project/llvm/docs/Phabricator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst,1,['patch'],['patches']
Deployability,"ype' will be; placed to the right of the type and aligned in the order supplied. .. code-block:: yaml. QualifierOrder: ['inline', 'static', 'type', 'const', 'volatile' ]. .. _RawStringFormats:. **RawStringFormats** (``List of RawStringFormats``) :versionbadge:`clang-format 6` :ref:`¶ <RawStringFormats>`; Defines hints for detecting supported languages code blocks in raw; strings. A raw string with a matching delimiter or a matching enclosing function; name will be reformatted assuming the specified language based on the; style for that language defined in the .clang-format file. If no style has; been defined in the .clang-format file for the specific language, a; predefined style given by 'BasedOnStyle' is used. If 'BasedOnStyle' is not; found, the formatting is based on llvm style. A matching delimiter takes; precedence over a matching enclosing function name for determining the; language of the raw string contents. If a canonical delimiter is specified, occurrences of other delimiters for; the same language will be updated to the canonical if possible. There should be at most one specification per language and each delimiter; and enclosing function should not occur in multiple specifications. To configure this in the .clang-format file, use:. .. code-block:: yaml. RawStringFormats:; - Language: TextProto; Delimiters:; - 'pb'; - 'proto'; EnclosingFunctions:; - 'PARSE_TEXT_PROTO'; BasedOnStyle: google; - Language: Cpp; Delimiters:; - 'cc'; - 'cpp'; BasedOnStyle: llvm; CanonicalDelimiter: 'cc'. .. _ReferenceAlignment:. **ReferenceAlignment** (``ReferenceAlignmentStyle``) :versionbadge:`clang-format 13` :ref:`¶ <ReferenceAlignment>`; Reference alignment style (overrides ``PointerAlignment`` for; references). Possible values:. * ``RAS_Pointer`` (in configuration: ``Pointer``); Align reference like ``PointerAlignment``. * ``RAS_Left`` (in configuration: ``Left``); Align reference to the left. .. code-block:: c++. int& a;. * ``RAS_Right`` (in configuration: ``Right``); A",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:99205,update,updated,99205,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['update'],['updated']
Deployability,"yter lab. - Let use created notebooks with viewers like https://nbviewer.jupyter.org/; - Fix problem with using of local JSROOT version. ## Tutorials. - The tutorial games.C was not working properly. - Improve tutorial ErrorIntegral.C. - Schrödinger's Hydrogen Atom example. - Tutorial demonstrating how the changing of the range can zoom into the histogram. - Tutorial demonstrating how a Histogram can be read from a ROOT File. - histMax.C: a tutorial demoing how the hist->GetMaximumBin() can be used. ## Class Reference Guide. - Images for ROOT7 tutorials can be generated, in json format, using the directive using; `\macro_image (json)` in the macro header. - Clarify THStack drawing options. - Add missing documentation to TH1 functions. - Restructure the math reference guide. - Make the web gui documentation visible in the reference guide. - Make clear THtml is legacy code. Add deprecated flag on PROOF and TGeoTrack. - Improve many classes documentation: TContext, TTreePlayer, THistPainter, TGraph, TSelector,; integrator, GUI, TH1, TH2, TH3, TColor classes ... - Make the TFile layout doc visible in Reference Guide. - Update the external links of the reference guide main page. - Reformat TMVA mathcore Unuran Roostats documentation . ## Build, Configuration and Testing Infrastructure. - For users building from source the `latest-stable` branch and passing `-Droottest=ON` to the CMake command line, the corresponding revision of roottest pointed to by `latest-stable` will be downloaded as required. ## PyROOT. - The `ROOT` Python module is now properly serializable so that it is automatically available in the Python environment if a function or ROOT object needs to be serialized. See issue [#6764](https://github.com/root-project/root/issues/6764) for a concrete usecase.; - Improve overload resolution of functions that accept classes with long inheritance trees. Now prefer to call the function overload of the most derived class type (PR [#9092](https://github.com/root-proje",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:39159,integrat,integrator,39159,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['integrat'],['integrator']
Deployability,"ython access can be used, an example Python; module is needed, as follows:. ``` {.cpp}; print('creating class MyPyClass ... '); class MyPyClass:; def __init__(self):; print('in MyPyClass.__init__'); self._browser = None; def gime(self, what):; return what; ```. This module can now be loaded into a Cling session, the class used to; instantiate objects, and their member functions called for showing how; different types can cross:. ``` {.cpp}; root[] TPython::LoadMacro(""MyPyClass.py"");; creating class MyPyClass ...; root[] MyPyClass m;; in MyPyClass.__init__; root[] char* s = m.gime(""aap"");; root[] s; (char* 0x41ee7754)""aap""; ```. Note that the `LoadMacro()` call makes the class automatically; available, such that it can be used directly. Otherwise, a; `gROOT->GetClass()` call is required first. #### Callbacks. The simplest way of setting a callback to Python from Cling, e.g. for a; button, is by providing the execution string. See for example; `tutorials/pyroot/demo.py` that comes with the ROOT installation:. ``` {.cpp}; # [..]; bar = ROOT.TControlBar('vertical','Demos'); bar.AddButton('Help on Demos',r'TPython::Exec(""execfile('demoshelp.py')"");','Click Here For Help on Running the Demos'); bar.AddButton('browser',r'TPython::Exec(""b = Tbrowser()"");','Start the ROOT browser'); # [..]; ```. Here, the callback is a string that will be interpreted by Cling to call; `TPython::Exec()`, which will, in turn, interpret and execute the string; given to it. Note the use of raw strings (the '`r`' in front of the; second argument string), in order to remove the need of escaping the; backslashes. #### Cling Commands. In interactive mode, the Python exception hook is used to mimic some of; the Cling commands available. These are: `.q`, **`.!`**, **`.x`**,; **`.L`**, **`.cd`**, **`.ls`**, **`.pwd`**, **`.?`** and **`.help`**.; Note that **`.x`** translates to Python '`execfile()`' and thus accepts; only Python files, not Cling macros. ### Memory Handling. The Python interpreter handle",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:18548,install,installation,18548,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['install'],['installation']
Deployability,"ython-side always deals with true Python objects; or; adjust the C++ interfaces to be the same as their Python equivalents.; Neither is very satisfactory: the former is not because of the existence of; global/static variables and return-by-reference.; If only a copy is available, then expected modifications do not propagate.; Copying is also either slow (when copying every time) or memory intensive (if; the results are cached).; Filling out the interfaces may look more appealing, but all operations then; involve C++ function calls, which can be slower than the Python equivalents,; and C++-style error handling. Given that neither choice will satisfy all cases, ``cppyy`` aims to maximize; functionality and minimum surprises based on common use.; Thus, for example, ``std::vector`` grows a pythonistic ``__len__`` method,; but does not lose its C++ ``size`` method.; Passing a Python container through a const reference to a ``std::vector``; will trigger automatic conversion, but such an attempt through a non-const; reference will fail since a non-temporary C++ object is required [#f1]_ to; return any updates/changes. ``std::string`` is almost always converted to Python's ``str`` on function; returns (the exception is return-by-reference when assigning), but not when; its direct use is more likely such as in the case of (global) variables or; when iterating over a ``std::vector<std::string>``. The rest of this section shows examples of how STL containers can be used in; a natural, pythonistic, way. `std::vector`; -------------. A ``std::vector`` is the most commonly used C++ container type because it is; more efficient and performant than specialized types such as ``list`` and; ``map``, unless the number of elements gets very large.; Python has several similar types, from the builtin ``tuple`` and ``list``,; the ``array`` from builtin module ``array``, to ""as-good-as-builtin""; ``numpy.ndarray``.; A vector is more like the latter two in that it can contain only one type,; b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:1587,update,updates,1587,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,1,['update'],['updates']
Deployability,"yy package, but the built-in module takes; precedence.; To use cppyy, first import a compatibility module::. $ pypy; [PyPy 5.8.0 with GCC 5.4.0] on linux2; >>>> import cppyy_compat, cppyy; >>>>. You may have to set ``LD_LIBRARY_PATH`` appropriately if you get an; ``EnvironmentError`` (it will indicate the needed directory). Note that your python interpreter (whether CPython or ``pypy-c``) may not have; been linked by the C++ compiler.; This can lead to problems during loading of C++ libraries and program shutdown.; In that case, re-linking is highly recommended. Very old versions of PyPy (5.6.0 and earlier) have a built-in ``cppyy`` based; on `Reflex`_, which is less feature-rich and no longer supported.; However, both the :doc:`distribution utilities <utilities>` and user-facing; Python codes are very backwards compatible, making migration straightforward. Precompiled header; ------------------. For performance reasons (reduced memory and CPU usage), a precompiled header; (PCH) of the system and compiler header files will be installed or, failing; that, generated on startup.; Obviously, this PCH is not portable and should not be part of any wheel. Some compiler features, such as AVX, OpenMP, fast math, etc. need to be; active during compilation of the PCH, as they depend both on compiler flags; and system headers (for intrinsics, or API calls).; You can control compiler flags through the ``EXTRA_CLING_ARGS`` envar and thus; what is active in the PCH.; In principle, you can also change the C++ language standard by setting the; appropriate flag on ``EXTRA_CLING_ARGS`` and rebuilding the PCH.; However, if done at this stage, that disables some automatic conversion for; C++ types that were introduced after C++11 (such as ``string_view`` and; ``optional``). If you want multiple PCHs living side-by-side, you can generate them; yourself (note that the given path must be absolute)::. >>> import cppyy_backend.loader as l; >>> l.set_cling_compile_options(True) # adds defaults",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:7648,install,installed,7648,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,1,['install'],['installed']
Deployability,"ze`.; Higher values lead to more accurate measurements but lengthen the benchmark. .. option:: --loop-body-size=<Preferred loop body size>. Only effective for `-repetition-mode=[loop|min]`.; Instead of looping over the snippet directly, first duplicate it so that the; loop body contains at least this many instructions. This potentially results; in loop body being cached in the CPU Op Cache / Loop Cache, which allows to; which may have higher throughput than the CPU decoders. .. option:: --max-configs-per-opcode=<value>. Specify the maximum configurations that can be generated for each opcode.; By default this is `1`, meaning that we assume that a single measurement is; enough to characterize an opcode. This might not be true of all instructions:; for example, the performance characteristics of the LEA instruction on X86; depends on the value of assigned registers and immediates. Setting a value of; `-max-configs-per-opcode` larger than `1` allows `llvm-exegesis` to explore; more configurations to discover if some register or immediate assignments; lead to different performance characteristics. .. option:: --benchmarks-file=</path/to/file>. File to read (`analysis` mode) or write (`latency`/`uops`/`inverse_throughput`; modes) benchmark results. ""-"" uses stdin/stdout. .. option:: --analysis-clusters-output-file=</path/to/file>. If provided, write the analysis clusters as CSV to this file. ""-"" prints to; stdout. By default, this analysis is not run. .. option:: --analysis-inconsistencies-output-file=</path/to/file>. If non-empty, write inconsistencies found during analysis to this file. `-`; prints to stdout. By default, this analysis is not run. .. option:: --analysis-filter=[all|reg-only|mem-only]. By default, all benchmark results are analysed, but sometimes it may be useful; to only look at those that to not involve memory, or vice versa. This option; allows to either keep all benchmarks, or filter out (ignore) either all the; ones that do involve memory (involve in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:14353,configurat,configurations,14353,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['configurat'],['configurations']
Deployability,"zer, University of Florida, CMS\; Christopher Jones, Fermilab, CMS,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Abhinav Moudgil, GSoC, \; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh, GSoC, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/IT,\; Paul Russo, Fermilab,\; Enric Tejedor Saavedra, CERN/SFT,\; George Troska, Dortmund Univ.,\; Liza Sakellari, CERN/SFT,\; Alex Saperstein, ANL,\; Manuel Tobias Schiller, CERN/LHCb,\; David Smith, CERN/IT,\; Peter Speckmayer,\; Tom Stevenson, Queen Mary University of London, ATLAS\; Matevz Tadel, UCSD/CMS, Eve,\; Peter van Gemmeren, ANL, ATLAS,\; Xavier Valls, CERN/SFT, \; Vassil Vassilev, Fermilab/CMS,\; Stefan Wunsch, KIT, CMS\; Omar Zapata, University of Antioquia, CERN/SFT.; . <a name=""core-libs""></a>. ## General. * Remove many instances of new warnings issued by gcc 6.1; * Significant update of the valgrind suppression file to hide intentional lack; of delete of some entities at the end of the process.; * Resolved several memory leaks.; * Added deprecation system: when compiling against interfaces marked R__DEPRECATED, the compiler will issue a warning showing the ROOT version when the interface will be removed.; * From this version on, building ROOT with CMake requires CMake &gt;= 3.4.3. ## Core Libraries. ROOT prepares for [cxx modules](http://clang.llvm.org/docs/Modules.html). One of; the first requirements is its header files to be self-contained (section ""Missing; Includes""). ROOT header files were cleaned up from extra includes and the missing; includes were added. This could be considered as backward incompatibility (for good however). User; code may need to add extra includes, which were previously resolved indirectly; by including a ROOT header. For example:. * TBuffer.h - TObject.h doesn't include TBuffer.h anymore. Third party code,; replying on the definition of TBufer will need to include TBuffer.h, alo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:1647,update,update,1647,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['update'],['update']
Deployability,"zers:. Configuring LLVM to Build Fuzzers; ---------------------------------. Fuzzers will be built and linked to libFuzzer by default as long as you build; LLVM with sanitizer coverage enabled. You would typically also enable at least; one sanitizer to find bugs faster. The most common way to build the fuzzers is; by adding the following two flags to your CMake invocation:; ``-DLLVM_USE_SANITIZER=Address -DLLVM_USE_SANITIZE_COVERAGE=On``. .. note:: If you have ``compiler-rt`` checked out in an LLVM tree when building; with sanitizers, you'll want to specify ``-DLLVM_BUILD_RUNTIME=Off``; to avoid building the sanitizers themselves with sanitizers enabled. .. note:: You may run into issues if you build with BFD ld, which is the; default linker on many unix systems. These issues are being tracked; in https://llvm.org/PR34636. Continuously Running and Finding Bugs; -------------------------------------. There used to be a public buildbot running LLVM fuzzers continuously, and while; this did find issues, it didn't have a very good way to report problems in an; actionable way. Because of this, we're moving towards using `OSS Fuzz`_ more; instead. You can browse the `LLVM project issue list`_ for the bugs found by; `LLVM on OSS Fuzz`_. These are also mailed to the `llvm-bugs mailing; list`_. .. _OSS Fuzz: https://github.com/google/oss-fuzz; .. _LLVM project issue list:; https://bugs.chromium.org/p/oss-fuzz/issues/list?q=Proj-llvm; .. _LLVM on OSS Fuzz:; https://github.com/google/oss-fuzz/blob/master/projects/llvm; .. _llvm-bugs mailing list:; http://lists.llvm.org/cgi-bin/mailman/listinfo/llvm-bugs. Utilities for Writing Fuzzers; =============================. There are some utilities available for writing fuzzers in LLVM. Some helpers for handling the command line interface are available in; ``include/llvm/FuzzMutate/FuzzerCLI.h``, including functions to parse command; line options in a consistent way and to implement standalone main functions so; your fuzzer can be buil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst:8918,continuous,continuously,8918,interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FuzzingLLVM.rst,1,['continuous'],['continuously']
Deployability,"{CMAKE_BINARY_DIR}/include/module.modulemap.extra""; COPYONLY). # From now on we handled all exposed module and want to make all new modulemaps private to ROOT.; set(ROOT_CXXMODULES_WRITE_TO_CURRENT_DIR ON). set (CMAKE_CXX_FLAGS_SEPARATE ""${CMAKE_CXX_FLAGS}""). string(REGEX REPLACE ""[ ]-"" "";-"" CMAKE_CXX_FLAGS_SEPARATE ""${CMAKE_CXX_FLAGS_SEPARATE}""); if(MSVC); string(REPLACE ""-Zc:__cplusplus"" """" CMAKE_CXX_FLAGS_SEPARATE ""${CMAKE_CXX_FLAGS_SEPARATE}""); string(REPLACE ""-nologo"" """" CMAKE_CXX_FLAGS_SEPARATE ""${CMAKE_CXX_FLAGS_SEPARATE}""); string(REPLACE ""-EHsc-"" """" CMAKE_CXX_FLAGS_SEPARATE ""${CMAKE_CXX_FLAGS_SEPARATE}""); string(REPLACE ""-GR"" """" CMAKE_CXX_FLAGS_SEPARATE ""${CMAKE_CXX_FLAGS_SEPARATE}""); string(REPLACE ""-MDd"" """" CMAKE_CXX_FLAGS_SEPARATE ""${CMAKE_CXX_FLAGS_SEPARATE}""); endif(). if(runtime_cxxmodules); # Dummy target that does nothing, we don't need a PCH for modules.; # Onepcm target has all dependencies needed for allDict.cxx.pch, which allow; # to test hsimple.C after all C++ modules are updated.; add_custom_target(onepcm); foreach(target_dependency ${ROOT_LIBRARY_TARGETS}); add_dependencies(onepcm ${target_dependency}); endforeach(); unset(ROOT_LIBRARY_TARGETS CACHE); else(); get_property(incdirs DIRECTORY PROPERTY INCLUDE_DIRECTORIES). if(WIN32); list(APPEND incdirs; ${CMAKE_SOURCE_DIR}/graf2d/win32gdk/gdk/src; ${CMAKE_SOURCE_DIR}/graf2d/win32gdk/gdk/src/gdk; ${CMAKE_SOURCE_DIR}/graf2d/win32gdk/gdk/src/glib; ); endif(). foreach(d ${incdirs}); if(NOT ""${d}"" MATCHES ""AFTER|BEFORE|INTERFACE|PRIVATE|PUBLIC|SYSTEM""); set(__allIncludes ${__allIncludes} -I${d}); endif(); endforeach(). get_property(__cling_pch GLOBAL PROPERTY CLINGETCPCH); get_property(__pch_dependencies GLOBAL PROPERTY ROOT_PCH_DEPENDENCIES); get_property(__pch_dictionaries GLOBAL PROPERTY ROOT_PCH_DICTIONARIES). add_custom_command(OUTPUT etc/allDict.cxx.pch; BYPRODUCTS; etc/dictpch/allCppflags.txt; etc/dictpch/allHeaders.h; etc/dictpch/allLinkDefs.h; COMMAND; ${Python3_EXECUTABLE} ${CMAKE_SOURCE_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt:19509,update,updated,19509,CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/CMakeLists.txt,1,['update'],['updated']
Deployability,"| Libraries to link against. |; +----------------------+---------------------------------------------------------------------------------------------+; |H_DIRS directory | Base directories for H_FILES. |; +----------------------+---------------------------------------------------------------------------------------------+; |H_FILES h_file | Header files for which to generate bindings in pkg. |; | | Absolute filenames, or filenames relative to H_DIRS. All |; | | definitions found directly in these files will contribute |; | | to the bindings. (NOTE: This means that if ""forwarding |; | | headers"" are present, the real ""legacy"" headers must be |; | | specified as H_FILES). |; | | All header files which contribute to a given C++ namespace |; | | should be grouped into a single pkg to ensure a 1-to-1 |; | | mapping with the implementing Python class. |; +----------------------+---------------------------------------------------------------------------------------------+. Returns via PARENT_SCOPE variables::. target The CMake target used to build.; setup_py The setup.py script used to build or install pkg. Examples::. find_package(Qt5Core NO_MODULE); find_package(KF5KDcraw NO_MODULE); get_target_property(_H_DIRS KF5::KDcraw INTERFACE_INCLUDE_DIRECTORIES); get_target_property(_LINK_LIBRARIES KF5::KDcraw INTERFACE_LINK_LIBRARIES); set(_LINK_LIBRARIES KF5::KDcraw ${_LINK_LIBRARIES}); include(${KF5KDcraw_DIR}/KF5KDcrawConfigVersion.cmake). cppyy_add_bindings(; ""KDCRAW"" ""${PACKAGE_VERSION}"" ""Shaheed"" ""srhaque@theiet.org""; LANGUAGE_STANDARD ""14""; LINKDEFS ""../linkdef_overrides.h""; GENERATE_OPTIONS ""-D__PIC__;-Wno-macro-redefined""; INCLUDE_DIRS ${Qt5Core_INCLUDE_DIRS}; LINK_LIBRARIES ${_LINK_LIBRARIES}; H_DIRS ${_H_DIRS}; H_FILES ""dcrawinfocontainer.h;kdcraw.h;rawdecodingsettings.h;rawfiles.h""). cppyy_find_pips; ^^^^^^^^^^^^^^^. Return a list of available pip programs. .. _`support for exporting all`: https://cmake.org/cmake/help/latest/prop_tgt/WINDOWS_EXPORT_ALL_SYMBOLS.html; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:10503,install,install,10503,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,1,['install'],['install']
Deployability,"| | deallocation stack traces for MTE fault |; | | | reports. The larger the buffer, the more |; | | | unrelated allocations can happen between |; | | | (de)allocation and the fault. |; | | | If your sync-mode MTE faults do not have |; | | | (de)allocation stack traces, try increasing the |; | | | buffer size. |; | | | |; | | | Stack trace collection can be requested using |; | | | the scudo_malloc_set_track_allocation_stacks |; | | | function. |; +---------------------------------+----------------+-------------------------------------------------+. Additional flags can be specified, for example if Scudo if compiled with; `GWP-ASan <https://llvm.org/docs/GwpAsan.html>`_ support. The following ""mallopt"" options are available (options are defined in; ``include/scudo/interface.h``):. +---------------------------+-------------------------------------------------------+; | Option | Description |; +---------------------------+-------------------------------------------------------+; | M_DECAY_TIME | Sets the release interval option to the specified |; | | value (Android only allows 0 or 1 to respectively set |; | | the interval to the minimum and maximum value as |; | | specified at compile time). |; +---------------------------+-------------------------------------------------------+; | M_PURGE | Forces immediate memory reclaiming but does not |; | | reclaim everything. For smaller size classes, there |; | | is still some memory that is not reclaimed due to the |; | | extra time it takes and the small amount of memory |; | | that can be reclaimed. |; | | The value is ignored. |; +---------------------------+-------------------------------------------------------+; | M_PURGE_ALL | Same as M_PURGE but will force release all possible |; | | memory regardless of how long it takes. |; | | The value is ignored. |; +---------------------------+-------------------------------------------------------+; | M_MEMTAG_TUNING | Tunes the allocator's choice of memory tags to make |; | | ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:12428,release,release,12428,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['release'],['release']
Deployability,"| | some architectures. |; +----------------------------+---------+--------------------------------------------------------------------------------+; | MaxSimultaneousAllocations | 16 | Number of simultaneously-guarded allocations available in the pool. |; +----------------------------+---------+--------------------------------------------------------------------------------+; | SampleRate | 5000 | The probability (1 / SampleRate) that a page is selected for GWP-ASan |; | | | sampling. Sample rates up to (2^31 - 1) are supported. |; +----------------------------+---------+--------------------------------------------------------------------------------+; | InstallSignalHandlers | true | Install GWP-ASan signal handlers for SIGSEGV during dynamic loading. This |; | | | allows better error reports by providing stack traces for allocation and |; | | | deallocation when reporting a memory error. GWP-ASan's signal handler will |; | | | forward the signal to any previously-installed handler, and user programs |; | | | that install further signal handlers should make sure they do the same. Note, |; | | | if the previously installed SIGSEGV handler is SIG_IGN, we terminate the |; | | | process after dumping the error report. |; +----------------------------+---------+--------------------------------------------------------------------------------+. Example; -------. The below code has a use-after-free bug, where the ``string_view`` is created as; a reference to the temporary result of the ``string+`` operator. The; use-after-free occurs when ``sv`` is dereferenced on line 8. .. code:: cpp. 1: #include <iostream>; 2: #include <string>; 3: #include <string_view>; 4:; 5: int main() {; 6: std::string s = ""Hellooooooooooooooo "";; 7: std::string_view sv = s + ""World\n"";; 8: std::cout << sv;; 9: }. Compiling this code with Scudo+GWP-ASan will probabilistically catch this bug; and provide us a detailed error report:. .. code:: console. $ clang++ -fsanitize=scudo -g buggy_code.cpp; $ ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:8712,install,installed,8712,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,2,['install'],"['install', 'installed']"
Deployability,"|; +--------------------+---------------+----------------+----------------+----------------+. ## Mathematical Functions. The mathematical functions are present in both `MathCore` and `MathMore`; libraries. All mathematical functions are implemented as free functions; in the namespace **`ROOT::Math`**. The most used functions are in the; `MathCore` library while the others are in the `MathMore` library. The; functions in `MathMore` are all using the implementation of the GNU; Scientific Library (GSL). The naming of the special functions is the; same defined in the C++; [Technical Report on Standard Library extensions](Technical Report on; Standard Library extensions).; The special functions are defined in the header file `Math/SpecFunc.h`. ### Special Functions in MathCore. - `ROOT::Math::beta(double x,double y) - `evaluates the beta function:; $$B(x,y) = \frac{\Gamma(x) \Gamma(y)}{\Gamma(x+y)}$$. - `double ROOT::Math::erf(double x)` - evaluates the error function; encountered in integrating the normal; distribution:; $$erf(x) = \frac{2}{\sqrt{\pi}} \int_{0}^{x} e^{-t^2} dt$$. - `double ROOT::Math::erfc(double x)` - evaluates the complementary; error function:; $$erfc(x) = 1 - erf(x) = \frac{2}{\sqrt{\pi}} \int_{x}^{\infty} e^{-t^2} dt$$. - `double ROOT::Math::tgamma(double x)` - calculates the gamma; function:; $$\Gamma(x) = \int_{0}^{\infty} t^{x-1} e^{-t} dt$$. ### Special Functions in MathMore. - `double ROOT::Math::assoc_legendre(unsigned l,unsigned m,double x) -`computes; the associated Legendre polynomials (with `m>=0`, `l>=m` and; `|x|<1)`:; $$P_{l}^{m}(x) = (1-x^2)^{m/2} \frac{d^m}{dx^m} P_{l}(x)$$. - `double ROOT::Math::comp_ellint_1(double k)` - calculates the; complete elliptic integral of the first kind (with $0 \le k^2 \le 1$:; $$; K(k) = F(k, \pi / 2) = \int_{0}^{\pi /2} \frac{d \theta}{\sqrt{1 - k^2 \sin^2{\theta}}}; $$. - `double ROOT::Math::comp_ellint_2(double k)` - calculates the; complete elliptic integral of the second kind (with $0 \le k^2 \le 1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:24633,integrat,integrating,24633,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['integrat'],['integrating']
Deployability,"|; | CounterPtr2 || |; | || |; | || |; + --> start(__llvm_prf_cnts) --> +---------------------+ || |; | ... | || |; +---------------------+ -----||----+; | Counter for | ||; | Data 1 | ||; +---------------------+ ||; | ... | ||; +---------------------+ =====||; | Counter for |; | Data 2 |; +---------------------+; | ... |; +---------------------+; | Counter for |; | Data N |; +---------------------+. In the graph,. * The profile header records ``CounterDelta`` with the value as ``start(__llvm_prf_cnts) - start(__llvm_prf_data)``.; We will call it ``CounterDeltaInitVal`` below for convenience.; * For each profile data record ``ProfileDataN``, ``CounterPtr`` is recorded as; ``start(CounterN) - start(ProfileDataN)``, where ``ProfileDataN`` is the N-th; entry in ``__llvm_prf_data``, and ``CounterN`` represents the corresponding; profile counters. Each time the reader advances to the next data record, it `updates`_ ``CounterDelta``; to minus the size of one ``ProfileData``. .. _`updates`: https://github.com/llvm/llvm-project/blob/17ff25a58ee4f29816d932fdb75f0d305718069f/llvm/include/llvm/ProfileData/InstrProfReader.h#L439-L444. For the counter corresponding to the first data record, the byte offset; relative to the start of the counter section is calculated as ``CounterPtr1 - CounterDeltaInitVal``.; When profile reader advances to the second data record, note ``CounterDelta``; is updated to ``CounterDeltaInitVal - sizeof(ProfileData)``.; Thus the byte offset relative to the start of the counter section is calculated; as ``CounterPtr2 - (CounterDeltaInitVal - sizeof(ProfileData))``. .. _`bitmap`:. Bitmap; ^^^^^^^; This section is used for source-based `Modified Condition/Decision Coverage`_ code coverage. Check out `Bitmap RFC`_; for the design. .. _`Modified Condition/Decision Coverage`: https://en.wikipedia.org/wiki/Modified_condition/decision_coverage; .. _`Bitmap RFC`: https://discourse.llvm.org/t/rfc-source-based-mc-dc-code-coverage/59244. Names; ^^^^^^. This section",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst:11107,update,updates,11107,interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,1,['update'],['updates']
Deployability,"}. void foo(bool b); {; if (b); {; baz(2);; }; else; {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_WebKit`` (in configuration: ``WebKit``); Like ``Attach``, but break before functions. .. code-block:: c++. namespace N {; enum E {; E1,; E2,; };. class C {; public:; C();; };. bool baz(int i); {; try {; do {; switch (i) {; case 1: {; foobar();; break;; }; default: {; break;; }; }; } while (--i);; return true;; } catch (...) {; handleError();; return false;; }; }. void foo(bool b); {; if (b) {; baz(2);; } else {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_Custom`` (in configuration: ``Custom``); Configure each individual brace in ``BraceWrapping``. .. _BreakBeforeConceptDeclarations:. **BreakBeforeConceptDeclarations** (``BreakBeforeConceptDeclarationsStyle``) :versionbadge:`clang-format 12` :ref:`¶ <BreakBeforeConceptDeclarations>`; The concept declaration style to use. Possible values:. * ``BBCDS_Never`` (in configuration: ``Never``); Keep the template declaration line together with ``concept``. .. code-block:: c++. template <typename T> concept C = ...;. * ``BBCDS_Allowed`` (in configuration: ``Allowed``); Breaking between template declaration and ``concept`` is allowed. The; actual behavior depends on the content and line breaking rules and; penalties. * ``BBCDS_Always`` (in configuration: ``Always``); Always break before ``concept``, putting it in the line after the; template declaration. .. code-block:: c++. template <typename T>; concept C = ...;. .. _BreakBeforeInlineASMColon:. **BreakBeforeInlineASMColon** (``BreakBeforeInlineASMColonStyle``) :versionbadge:`clang-format 16` :ref:`¶ <BreakBeforeInlineASMColon>`; The inline ASM colon style to use. Possible values:. * ``BBIAS_Never`` (in configuration: ``Never``); No break before inline ASM colon. .. code-block:: c++. asm volatile(""string"", : : val);. * ``BBIAS_OnlyMultiline`` (in configuration: ``OnlyMultiline``); Break before inline ASM colon if the line length is l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:52240,configurat,configuration,52240,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['configurat'],['configuration']
Deployability,"}; ${_CLAD_LIBRARY_PATH}/${CMAKE_STATIC_LIBRARY_PREFIX}cladDifferentiator${CMAKE_STATIC_LIBRARY_SUFFIX}; ); endif(). if(APPLE); set(_clad_extra_cmake_args -DCMAKE_OSX_SYSROOT=${CMAKE_OSX_SYSROOT}); endif(). if (CMAKE_CXX_STANDARD); list(APPEND _clad_extra_cmake_args -DCMAKE_CXX_STANDARD=${CMAKE_CXX_STANDARD}); endif(CMAKE_CXX_STANDARD). if (Clang_DIR); list(APPEND _clad_extra_cmake_args -DClang_DIR=${Clang_DIR} -DClang_CONFIG_EXTRA_PATH_HINTS=${Clang_Config_ExtraPathHints}); endif(Clang_DIR). if (LLVM_FORCE_USE_OLD_TOOLCHAIN); list(APPEND _clad_extra_cmake_args -DLLVM_FORCE_USE_OLD_TOOLCHAIN=${LLVM_FORCE_USE_OLD_TOOLCHAIN}); endif(LLVM_FORCE_USE_OLD_TOOLCHAIN). list(APPEND _clad_extra_cmake_args -DCLAD_BUILD_STATIC_ONLY=ON). # Wrap download, configure and build steps in a script to log output; set(_clad_extra_settings; LOG_DOWNLOAD ON; LOG_CONFIGURE ON; LOG_BUILD ON; LOG_INSTALL ON; LOG_OUTPUT_ON_FAILURE ON; ). # If the CLAD_SOURCE_DIR variable is defined in the CMake configuration, we're; # skipping the download of the repository and use the passed directory.; if (DEFINED CLAD_SOURCE_DIR); list(APPEND _clad_extra_settings DOWNLOAD_COMMAND """"); list(APPEND _clad_extra_settings SOURCE_DIR ${CLAD_SOURCE_DIR}); endif(). #list(APPEND _clad_patches_list ""patch1.patch"" ""patch2.patch""); #set(_clad_patch_command; # ${CMAKE_COMMAND} -E copy_directory; # ${CMAKE_SOURCE_DIR}/interpreter/cling/tools/plugins/clad/patches <SOURCE_DIR>; # && git checkout <SOURCE_DIR>; # && git apply --ignore-space-change --ignore-whitespace ${_clad_patches_list}; # ). ExternalProject_Add(; clad; GIT_REPOSITORY https://github.com/vgvassilev/clad.git; GIT_TAG v1.7; UPDATE_COMMAND """"; PATCH_COMMAND ${_clad_patch_command}; CMAKE_ARGS -G ${CMAKE_GENERATOR}; -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE}; -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}; -DCMAKE_C_FLAGS=${CMAKE_C_FLAGS}; -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER}; -DCMAKE_CXX_FLAGS=${CLAD_CXX_FLAGS}; -DCMAKE_INSTALL_PREFIX=${clad_install_dir}/plugins; -D",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/plugins/clad/CMakeLists.txt:2382,configurat,configuration,2382,interpreter/cling/tools/plugins/clad/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/plugins/clad/CMakeLists.txt,1,['configurat'],['configuration']
Deployability,"~~~~~~~; A *link-declaration* specifies a library or framework against which a program should be linked if the enclosing module is imported in any translation unit in that program. .. parsed-literal::. *link-declaration*:; ``link`` ``framework``:sub:`opt` *string-literal*. The *string-literal* specifies the name of the library or framework against which the program should be linked. For example, specifying ""clangBasic"" would instruct the linker to link with ``-lclangBasic`` for a Unix-style linker. A *link-declaration* with the ``framework`` specifies that the linker should link against the named framework, e.g., with ``-framework MyFramework``. .. note::. Automatic linking with the ``link`` directive is not yet widely; implemented, because it requires support from both the object file; format and the linker. The notion is similar to Microsoft Visual; Studio's ``#pragma comment(lib...)``. Configuration macros declaration; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~; The *config-macros-declaration* specifies the set of configuration macros that have an effect on the API of the enclosing module. .. parsed-literal::. *config-macros-declaration*:; ``config_macros`` *attributes*:sub:`opt` *config-macro-list*:sub:`opt`. *config-macro-list*:; *identifier* (',' *identifier*)*. Each *identifier* in the *config-macro-list* specifies the name of a macro. The compiler is required to maintain different variants of the given module for differing definitions of any of the named macros. A *config-macros-declaration* shall only be present on a top-level module, i.e., a module that is not nested within an enclosing module. The ``exhaustive`` attribute specifies that the list of macros in the *config-macros-declaration* is exhaustive, meaning that no other macro definition is intended to have an effect on the API of that module. .. note::. The ``exhaustive`` attribute implies that any macro definitions; for macros not listed as configuration macros should be ignored; completely when building the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:46312,configurat,configuration,46312,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['configurat'],['configuration']
Deployability,"~~~~~~~~~. ``-fmodules-strict-context-hash``; Enables hashing of all compiler options that could impact the semantics of a; module in an implicit build. This includes things such as header search paths; and diagnostics. Using this option may lead to an excessive number of modules; being built if the command line arguments are not homogeneous across your; build. Using Prebuilt Modules; ----------------------. Below are a few examples illustrating uses of prebuilt modules via the different options. First, let's set up files for our examples. .. code-block:: c. /* A.h */; #ifdef ENABLE_A; void a() {}; #endif. .. code-block:: c. /* B.h */; #include ""A.h"". .. code-block:: c. /* use.c */; #include ""B.h""; void use() {; #ifdef ENABLE_A; a();; #endif; }. .. code-block:: c. /* module.modulemap */; module A {; header ""A.h""; }; module B {; header ""B.h""; export *; }. In the examples below, the compilation of ``use.c`` can be done without ``-cc1``, but the commands used to prebuild the modules would need to be updated to take into account the default options passed to ``clang -cc1``. (See ``clang use.c -v``); Note also that, since we use ``-cc1``, we specify the ``-fmodule-map-file=`` or ``-fimplicit-module-maps`` options explicitly. When using the clang driver, ``-fimplicit-module-maps`` is implied by ``-fmodules``. First let us use an explicit mapping from modules to files. .. code-block:: sh. rm -rf prebuilt ; mkdir prebuilt; clang -cc1 -emit-module -o prebuilt/A.pcm -fmodules module.modulemap -fmodule-name=A; clang -cc1 -emit-module -o prebuilt/B.pcm -fmodules module.modulemap -fmodule-name=B -fmodule-file=A=prebuilt/A.pcm; clang -cc1 -emit-obj use.c -fmodules -fmodule-map-file=module.modulemap -fmodule-file=A=prebuilt/A.pcm -fmodule-file=B=prebuilt/B.pcm. Instead of of specifying the mappings manually, it can be convenient to use the ``-fprebuilt-module-path`` option. Let's also use ``-fimplicit-module-maps`` instead of manually pointing to our module map. .. code-block:: sh.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:19246,update,updated,19246,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['update'],['updated']
Energy Efficiency," 	fldl	8(%esp); 	fisttpll	(%esp); 	movl	4(%esp), %edx; 	movl	(%esp), %eax; 	addl	$20, %esp; 	#FP_REG_KILL; 	ret. This should just fldl directly from the input stack slot. //===---------------------------------------------------------------------===//. This code:; int foo (int x) { return (x & 65535) | 255; }. Should compile into:. _foo:; movzwl 4(%esp), %eax; orl $255, %eax; ret. instead of:; _foo:; 	movl	$65280, %eax; 	andl	4(%esp), %eax; 	orl	$255, %eax; 	ret. //===---------------------------------------------------------------------===//. We're codegen'ing multiply of long longs inefficiently:. unsigned long long LLM(unsigned long long arg1, unsigned long long arg2) {; return arg1 * arg2;; }. We compile to (fomit-frame-pointer):. _LLM:; 	pushl	%esi; 	movl	8(%esp), %ecx; 	movl	16(%esp), %esi; 	movl	%esi, %eax; 	mull	%ecx; 	imull	12(%esp), %esi; 	addl	%edx, %esi; 	imull	20(%esp), %ecx; 	movl	%esi, %edx; 	addl	%ecx, %edx; 	popl	%esi; 	ret. This looks like a scheduling deficiency and lack of remat of the load from; the argument area. ICC apparently produces:. movl 8(%esp), %ecx; imull 12(%esp), %ecx; movl 16(%esp), %eax; imull 4(%esp), %eax ; addl %eax, %ecx ; movl 4(%esp), %eax; mull 12(%esp) ; addl %ecx, %edx; ret. Note that it remat'd loads from 4(esp) and 12(esp). See this GCC PR:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=17236. //===---------------------------------------------------------------------===//. We can fold a store into ""zeroing a reg"". Instead of:. xorl %eax, %eax; movl %eax, 124(%esp). we should get:. movl $0, 124(%esp). if the flags of the xor are dead. Likewise, we isel ""x<<1"" into ""add reg,reg"". If reg is spilled, this should; be folded into: shl [mem], 1. //===---------------------------------------------------------------------===//. In SSE mode, we turn abs and neg into a load from the constant pool plus a xor; or and instruction, for example:. 	xorpd	LCPI1_0, %xmm2. However, if xmm2 gets spilled, we end up with really ugly code like this:.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:21452,schedul,scheduling,21452,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['schedul'],['scheduling']
Energy Efficiency," !<align_node> = !{ i64 <value_alignment> }. Overview:; """""""""""""""""". The '``load``' instruction is used to read from memory. Arguments:; """""""""""""""""""". The argument to the ``load`` instruction specifies the memory address from which; to load. The type specified must be a :ref:`first class <t_firstclass>` type of; known size (i.e. not containing an :ref:`opaque structural type <t_opaque>`). If; the ``load`` is marked as ``volatile``, then the optimizer is not allowed to; modify the number or order of execution of this ``load`` with other; :ref:`volatile operations <volatile>`. If the ``load`` is marked as ``atomic``, it takes an extra :ref:`ordering; <ordering>` and optional ``syncscope(""<target-scope>"")`` argument. The; ``release`` and ``acq_rel`` orderings are not valid on ``load`` instructions.; Atomic loads produce :ref:`defined <memmodel>` results when they may see; multiple atomic stores. The type of the pointee must be an integer, pointer, or; floating-point type whose bit width is a power of two greater than or equal to; eight and less than or equal to a target-specific size limit. ``align`` must be; explicitly specified on atomic loads. Note: if the alignment is not greater or; equal to the size of the `<value>` type, the atomic operation is likely to; require a lock and have poor performance. ``!nontemporal`` does not have any; defined semantics for atomic loads. The optional constant ``align`` argument specifies the alignment of the; operation (that is, the alignment of the memory address). It is the; responsibility of the code emitter to ensure that the alignment information is; correct. Overestimating the alignment results in undefined behavior.; Underestimating the alignment may produce less efficient code. An alignment of; 1 is always safe. The maximum possible alignment is ``1 << 32``. An alignment; value higher than the size of the loaded type implies memory up to the; alignment value bytes can be safely loaded without trapping in the default; address spac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:413481,power,power,413481,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency," ""Depends on D<num>"", where ""<num>"" is the patch number of the previous review.; This must be entirely on its own line, with a blank line before it.; For example::. [llvm] Example commit. Depends on D12345. * If you want a single review to have multiple parent reviews then; add more with ""and"", for example: ""Depends on D12344 and D12345"".; * Upload the commit with the web interface or `arc`; (``arc diff --verbatim`` to update an existing review).; * You will see a ""Stack"" tab in the ""Revision Contents"" section of the review; in the web interface, showing the parent review.; * Repeat these steps until you've uploaded or updated all the patches in; your series. When you push the patches, please remove the ""Depends on"" lines from the; commit messages, since they add noise and duplicate git's implicit ordering. One frequently used workflow for creating a series of patches using patch summaries; is based on git's rebasing. These steps assume that you have a series of commits that; you have not posted for review, but can be adapted to update existing reviews. * git interactive rebase back to the first commit you want to upload for review::. git rebase -i HEAD~<number of commits you have written>. * Mark all commits for editing by changing ""pick"" to ""edit"" in the instructions; git shows.; * Start the rebase (usually by writing and closing the instructions).; * For the first commit:. - Upload the current commit for a review (with ``arc diff`` or the web; interface). - Continue to the next commit with ``git rebase --continue``. * For the rest:. - Add the ""Depends on..."" line using ``git commit --amend``. - Upload for review. - Continue the rebase. * Once the rebase is complete, you've created your patch series. .. _finding-potential-reviewers:. Finding potential reviewers; ---------------------------. Here are a couple of ways to pick the initial reviewer(s):. * Use ``git blame`` and the commit log to find names of people who have; recently modified the same area of code tha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst:7831,adapt,adapted,7831,interpreter/llvm-project/llvm/docs/Phabricator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst,1,['adapt'],['adapted']
Energy Efficiency," ### Interpreter. - cling's LLVM is upgraded to version 9.0; - New interface to enable/disable optional cling features. Currently, it can be used to enable/disable support for redefinitions. See [this](https://github.com/root-project/cling/issues/360) issue for more information. ### Multithreading. - Fix an uninitialized variable in global read-write lock which could have caused deadlocks or crashes in some rare cases.; - Default global read-write lock transitioned to new implementation based on TBB thread local storage when TBB is available on supported platforms (all except Windows). This gives an O(10%) performance improvement for some typical RDataFrame scenarios with 256 threads due to reduced lock contention. ## I/O Libraries. - Exclusive use of the global lock is reduced or migrated to finer grained read and write locks in a few hotspots that occur during file opening/closing or task initialization in RDataFrame. This can lead to O(100x) improvements for some typical RDataFrame scenarios with 256 threads due to massively reduced lock contention. ## TTree Libraries. - `TTree` now supports the inclusion of leaves of types `long` and `unsigned long` (and therefore also `std::size_t` on most systems) also for branches in ""leaflist mode"". The corresponding leaflist letters are 'G' and 'g'.; - when looping over a `TTree` with a friend with a larger number of entries, `TTreeReader` now ends the event loop when the entries in the _main_ `TTree` are exhausted, consistently with other interfaces. See [#6518](https://github.com/root-project/root/issues/6518) for more details.; - `TTreeProcessorMT::SetMaxTasksPerFilePerWorker` is now deprecated in favor of the more flexible and newly introduced `TTreeProcessorMT::SetTasksPerWorkerHint`. See the relevant entries in our reference guide for more information.; - The name of the sub-branches of a split collection no longer have 2 consecutive dots if the top level branche name has a trailing dot. The name of the collection's in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:4596,reduce,reduced,4596,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['reduce'],['reduced']
Energy Efficiency," %struct.Foo = type { i32, i32 }; declare void @Foo_ctor(%struct.Foo* %this); declare void @Foo_dtor(%struct.Foo* %this); declare void @g(<{ %struct.Foo, %struct.Foo }>* inalloca %memargs). define void @f() {; entry:; %base = call i8* @llvm.stacksave(); %memargs = alloca <{ %struct.Foo, %struct.Foo }>; %b = getelementptr <{ %struct.Foo, %struct.Foo }>* %memargs, i32 1; call void @Foo_ctor(%struct.Foo* %b). ; If a's ctor throws, we must destruct b.; %a = getelementptr <{ %struct.Foo, %struct.Foo }>* %memargs, i32 0; invoke void @Foo_ctor(%struct.Foo* %a); to label %invoke.cont unwind %invoke.unwind. invoke.cont:; call void @g(<{ %struct.Foo, %struct.Foo }>* inalloca %memargs); call void @llvm.stackrestore(i8* %base); ... invoke.unwind:; call void @Foo_dtor(%struct.Foo* %b); call void @llvm.stackrestore(i8* %base); ...; }. To avoid stack leaks, the frontend saves the current stack pointer with; a call to :ref:`llvm.stacksave <int_stacksave>`. Then, it allocates the; argument stack space with alloca and calls the default constructor. The; default constructor could throw an exception, so the frontend has to; create a landing pad. The frontend has to destroy the already; constructed argument ``b`` before restoring the stack pointer. If the; constructor does not unwind, ``g`` is called. In the Microsoft C++ ABI,; ``g`` will destroy its arguments, and then the stack is restored in; ``f``. Design Considerations; =====================. Lifetime; --------. The biggest design consideration for this feature is object lifetime.; We cannot model the arguments as static allocas in the entry block,; because all calls need to use the memory at the top of the stack to pass; arguments. We cannot vend pointers to that memory at function entry; because after code generation they will alias. The rule against allocas between argument allocations and the call site; avoids this problem, but it creates a cleanup problem. Cleanup and; lifetime is handled explicitly with stack save and restore",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst:2671,allocate,allocates,2671,interpreter/llvm-project/llvm/docs/InAlloca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst,1,['allocate'],['allocates']
Energy Efficiency," '``sqrt``' function but without; trapping or setting ``errno``. For types specified by IEEE-754, the result; matches a conforming libm implementation. When specified with the fast-math-flag 'afn', the result may be approximated; using a less accurate calculation. '``llvm.powi.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.powi`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. Generally, the only supported type for the exponent is the one matching; with the C type ``int``. ::. declare float @llvm.powi.f32.i32(float %Val, i32 %power); declare double @llvm.powi.f64.i16(double %Val, i16 %power); declare x86_fp80 @llvm.powi.f80.i32(x86_fp80 %Val, i32 %power); declare fp128 @llvm.powi.f128.i32(fp128 %Val, i32 %power); declare ppc_fp128 @llvm.powi.ppcf128.i32(ppc_fp128 %Val, i32 %power). Overview:; """""""""""""""""". The '``llvm.powi.*``' intrinsics return the first operand raised to the; specified (positive or negative) power. The order of evaluation of; multiplications is not defined. When a vector of floating-point type is; used, the second argument remains a scalar integer value. Arguments:; """""""""""""""""""". The second argument is an integer power, and the first is a value to; raise to that power. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power with an; unspecified sequence of rounding operations. '``llvm.sin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.sin`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @llvm.sin.f32(float %Val); declare double @llvm.sin.f64(double %Val); declare x86_fp80 @llvm.sin.f80(x86_fp80 %Val); declare fp128 @llvm.sin.f128(fp128 %Val); declare ppc_fp128 @llvm.sin.ppcf128(ppc_fp128 %Val). Overview:; """""""""""""""""". The '``llvm.sin.*``' intrinsics return the sine of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:558395,power,power,558395,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency," *context,; size_t context_len);; ```. As `llvm_blake3_hasher_init_derive_key` above, except that the context string; is given as a pointer to an array of arbitrary bytes with a provided; length. This is intended for writing language bindings, where C string; conversion would add unnecessary overhead and new error cases. Unicode; strings should be encoded as UTF-8. Application code in C should prefer `llvm_blake3_hasher_init_derive_key`,; which takes the context as a C string. If you need to use arbitrary; bytes as a context string in application code, consider whether you're; violating the requirement that context strings should be hardcoded. ---. ```c; void llvm_blake3_hasher_finalize_seek(; const llvm_blake3_hasher *self,; uint64_t seek,; uint8_t *out,; size_t out_len);; ```. The same as `llvm_blake3_hasher_finalize`, but with an additional `seek`; parameter for the starting byte position in the output stream. To; efficiently stream a large output without allocating memory, call this; function in a loop, incrementing `seek` by the output length each time. ---. ```c; void llvm_blake3_hasher_reset(; llvm_blake3_hasher *self);; ```. Reset the hasher to its initial state, prior to any calls to; `llvm_blake3_hasher_update`. Currently this is no different from calling; `llvm_blake3_hasher_init` or similar again. However, if this implementation gains; multithreading support in the future, and if `llvm_blake3_hasher` holds (optional); threading resources, this function will reuse those resources. # Building. This implementation is just C and assembly files. ## x86. Dynamic dispatch is enabled by default on x86. The implementation will; query the CPU at runtime to detect SIMD support, and it will use the; widest instruction set available. By default, `blake3_dispatch.c`; expects to be linked with code for five different instruction sets:; portable C, SSE2, SSE4.1, AVX2, and AVX-512. For each of the x86 SIMD instruction sets, four versions are available:; three flavors of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:6338,efficient,efficiently,6338,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,1,['efficient'],['efficiently']
Energy Efficiency," - the 16-bit checksum;. This header fits within 8 bytes on all platforms supported, and contributes to a; small overhead for each allocation. The checksum is computed using a CRC32 (made faster with hardware support); of the global secret, the chunk pointer itself, and the 8 bytes of header with; the checksum field zeroed out. It is not intended to be cryptographically; strong. The header is atomically loaded and stored to prevent races. This is important; as two consecutive chunks could belong to different threads. We work on local; copies and use compare-exchange primitives to update the headers in the heap; memory, and avoid any type of double-fetching. Randomness; ----------; Randomness is a critical factor to the additional security provided by the; allocator. The allocator trusts the memory mapping primitives of the OS to; provide pages at (mostly) non-predictable locations in memory, as well as the; binaries to be compiled with ASLR. In the event one of those assumptions is; incorrect, the security will be greatly reduced. Scudo further randomizes how; blocks are allocated in the Primary, can randomize how caches are assigned to; threads. Memory reclaiming; -----------------; Primary and Secondary allocators have different behaviors with regard to; reclaiming. While Secondary mapped allocations can be unmapped on deallocation,; it isn't the case for the Primary, which could lead to a steady growth of the; RSS of a process. To counteract this, if the underlying OS allows it, pages; that are covered by contiguous free memory blocks in the Primary can be; released: this generally means they won't count towards the RSS of a process and; be zero filled on subsequent accesses). This is done in the deallocation path,; and several options exist to tune this behavior. Usage; =====. Platform; --------; If using Fuchsia or an Android version greater than 11, your memory allocations; are already service by Scudo (note that Android Svelte configurations still use; jemallo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:4762,reduce,reduced,4762,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['reduce'],['reduced']
Energy Efficiency," -----------------------. There must be no functionality specified in the interface of ``lib/Support``; that isn't actually used by LLVM. We're not writing a general purpose operating; system wrapper here, just enough to satisfy LLVM's needs. And, LLVM doesn't; need much. This design goal aims to keep the ``lib/Support`` interface small and; understandable which should foster its actual use and adoption. No Duplicate Implementations; ----------------------------. The implementation of a function for a given platform must be written exactly; once. This implies that it must be possible to apply a function's; implementation to multiple operating systems if those operating systems can; share the same implementation. This rule applies to the set of operating; systems supported for a given class of operating system (e.g. Unix, Win32). No Virtual Methods; ------------------. The Support Library interfaces can be called quite frequently by LLVM. In order; to make those calls as efficient as possible, we discourage the use of virtual; methods. There is no need to use inheritance for implementation differences, it; just adds complexity. The ``#include`` mechanism works just fine. No Exposed Functions; --------------------. Any functions defined by system libraries (i.e. not defined by ``lib/Support``); must not be exposed through the ``lib/Support`` interface, even if the header; file for that function is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:5879,efficient,efficient,5879,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst,1,['efficient'],['efficient']
Energy Efficiency," -fprofile-exclude-files=""^/usr/include/.*$"" \; -fprofile-filter-files=""^/usr/.*$"". In that case ``/usr/foo/oof.h`` is instrumented since it matches the filter regex and; doesn't match the exclude regex, but ``/usr/include/foo.h`` doesn't since it matches; the exclude regex. Controlling Debug Information; -----------------------------. Controlling Size of Debug Information; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Debug info kind generated by Clang can be set by one of the flags listed; below. If multiple flags are present, the last one is used. .. option:: -g0. Don't generate any debug info (default). .. option:: -gline-tables-only. Generate line number tables only. This kind of debug info allows to obtain stack traces with function names,; file names and line numbers (by such tools as ``gdb`` or ``addr2line``). It; doesn't contain any other data (e.g. description of local variables or; function parameters). .. option:: -fstandalone-debug. Clang supports a number of optimizations to reduce the size of debug; information in the binary. They work based on the assumption that; the debug type information can be spread out over multiple; compilation units. Specifically, the optimizations are:. - will not emit type definitions for types that are not needed by a; module and could be replaced with a forward declaration.; - will only emit type info for a dynamic C++ class in the module that; contains the vtable for the class.; - will only emit type info for a C++ class (non-trivial, non-aggregate); in the modules that contain a definition for one of its constructors.; - will only emit type definitions for types that are the subject of explicit; template instantiation declarations in the presence of an explicit; instantiation definition for the type. The **-fstandalone-debug** option turns off these optimizations.; This is useful when working with 3rd-party libraries that don't come; with debug information. Note that Clang will never emit type; information for types that are no",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:124994,reduce,reduce,124994,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['reduce'],['reduce']
Energy Efficiency," /// parenexpr ::= '(' expression ')'; static std::unique_ptr<ExprAST> ParseParenExpr() {; getNextToken(); // eat (.; auto V = ParseExpression();; if (!V); return nullptr;. if (CurTok != ')'); return LogError(""expected ')'"");; getNextToken(); // eat ).; return V;; }. This function illustrates a number of interesting things about the; parser:. 1) It shows how we use the LogError routines. When called, this function; expects that the current token is a '(' token, but after parsing the; subexpression, it is possible that there is no ')' waiting. For example,; if the user types in ""(4 x"" instead of ""(4)"", the parser should emit an; error. Because errors can occur, the parser needs a way to indicate that; they happened: in our parser, we return null on an error. 2) Another interesting aspect of this function is that it uses recursion; by calling ``ParseExpression`` (we will soon see that; ``ParseExpression`` can call ``ParseParenExpr``). This is powerful; because it allows us to handle recursive grammars, and keeps each; production very simple. Note that parentheses do not cause construction; of AST nodes themselves. While we could do it this way, the most; important role of parentheses are to guide the parser and provide; grouping. Once the parser constructs the AST, parentheses are not; needed. The next simple production is for handling variable references and; function calls:. .. code-block:: c++. /// identifierexpr; /// ::= identifier; /// ::= identifier '(' expression* ')'; static std::unique_ptr<ExprAST> ParseIdentifierExpr() {; std::string IdName = IdentifierStr;. getNextToken(); // eat identifier. if (CurTok != '(') // Simple variable ref.; return std::make_unique<VariableExprAST>(IdName);. // Call.; getNextToken(); // eat (; std::vector<std::unique_ptr<ExprAST>> Args;; if (CurTok != ')') {; while (true) {; if (auto Arg = ParseExpression()); Args.push_back(std::move(Arg));; else; return nullptr;. if (CurTok == ')'); break;. if (CurTok != ','); return LogError(""Exp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst:9146,power,powerful,9146,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst,1,['power'],['powerful']
Energy Efficiency," //===---------------------------------------------------------------------===//. Are we better off using branches instead of cmove to implement FP to; unsigned i64?. _conv:; 	ucomiss	LC0(%rip), %xmm0; 	cvttss2siq	%xmm0, %rdx; 	jb	L3; 	subss	LC0(%rip), %xmm0; 	movabsq	$-9223372036854775808, %rax; 	cvttss2siq	%xmm0, %rdx; 	xorq	%rax, %rdx; L3:; 	movq	%rdx, %rax; 	ret. instead of. _conv:; 	movss LCPI1_0(%rip), %xmm1; 	cvttss2siq %xmm0, %rcx; 	movaps %xmm0, %xmm2; 	subss %xmm1, %xmm2; 	cvttss2siq %xmm2, %rax; 	movabsq $-9223372036854775808, %rdx; 	xorq %rdx, %rax; 	ucomiss %xmm1, %xmm0; 	cmovb %rcx, %rax; 	ret. Seems like the jb branch has high likelihood of being taken. It would have; saved a few instructions. //===---------------------------------------------------------------------===//. It's not possible to reference AH, BH, CH, and DH registers in an instruction; requiring REX prefix. However, divb and mulb both produce results in AH. If isel; emits a CopyFromReg which gets turned into a movb and that can be allocated a; r8b - r15b. To get around this, isel emits a CopyFromReg from AX and then right shift it; down by 8 and truncate it. It's not pretty but it works. We need some register; allocation magic to make the hack go away (e.g. putting additional constraints; on the result of the movb). //===---------------------------------------------------------------------===//. The x86-64 ABI for hidden-argument struct returns requires that the; incoming value of %rdi be copied into %rax by the callee upon return. The idea is that it saves callers from having to remember this value,; which would often require a callee-saved register. Callees usually; need to keep this value live for most of their body anyway, so it; doesn't add a significant burden on them. We currently implement this in codegen, however this is suboptimal; because it means that it would be quite awkward to implement the; optimization for callers. A better implementation would be to relax the LLVM IR r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-X86-64.txt:1366,allocate,allocated,1366,interpreter/llvm-project/llvm/lib/Target/X86/README-X86-64.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-X86-64.txt,1,['allocate'],['allocated']
Energy Efficiency," 0d a4 13 00 00 lea 0x13a4(%rip),%rcx; 9ac: 48 39 c8 cmp %rcx,%rax; 9af: 75 25 jne 9d6 <main+0x86>; 9b1: 48 89 df mov %rbx,%rdi; 9b4: ff 10 callq *(%rax); [...]; 9d6: 0f 0b ud2. Virtual Table Layout; ~~~~~~~~~~~~~~~~~~~~. The compiler lays out classes of disjoint hierarchies in separate regions; of the object file. At worst, bit vectors in disjoint hierarchies only; need to cover their disjoint hierarchy. But the closer that classes in; sub-hierarchies are laid out to each other, the smaller the bit vectors for; those sub-hierarchies need to be (see ""Stripping Leading/Trailing Zeros in Bit; Vectors"" above). The `GlobalLayoutBuilder`_ class is responsible for laying; out the globals efficiently to minimize the sizes of the underlying bitsets. .. _GlobalLayoutBuilder: https://github.com/llvm/llvm-project/blob/main/llvm/include/llvm/Transforms/IPO/LowerTypeTests.h. Alignment; ~~~~~~~~~. If all gaps between address points in a particular bit vector are multiples; of powers of 2, the compiler can compress the bit vector by strengthening; the alignment requirements of the virtual table pointer. For example, given; this class hierarchy:. .. code-block:: c++. struct A {; virtual void f1();; virtual void f2();; };. struct B : A {; virtual void f1();; virtual void f2();; virtual void f3();; virtual void f4();; virtual void f5();; virtual void f6();; };. struct C : A {; virtual void f1();; virtual void f2();; };. The virtual tables will be laid out like this:. .. csv-table:: Virtual Table Layout for A, B, C; :header: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15. A::offset-to-top, &A::rtti, &A::f1, &A::f2, B::offset-to-top, &B::rtti, &B::f1, &B::f2, &B::f3, &B::f4, &B::f5, &B::f6, C::offset-to-top, &C::rtti, &C::f1, &C::f2. Notice that each address point for A is separated by 4 words. This lets us; emit a compressed bit vector for A that looks like this:. .. csv-table::; :header: 2, 6, 10, 14. 1, 1, 0, 1. At call sites, the compiler will strengthen the alignment requirem",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:7103,power,powers,7103,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['power'],['powers']
Energy Efficiency," 32 0x00000000; Local group LDS 32 0xFFFFFFFF; Global global global 64 0x0000000000000000; Constant constant *same as 64 0x0000000000000000; global*; Generic flat flat 64 0x0000000000000000; Region N/A GDS 32 *not implemented; for AMDHSA*; ================= =========== ======== ======= ==================. The global and constant memory spaces both use global virtual addresses, which; are the same virtual address space used by the CPU. However, some virtual; addresses may only be accessible to the CPU, some only accessible by the GPU,; and some by both. Using the constant memory space indicates that the data will not change during; the execution of the kernel. This allows scalar read instructions to be; used. The vector and scalar L1 caches are invalidated of volatile data before; each kernel dispatch execution to allow constant memory to change values between; kernel dispatches. The local memory space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates work-groups of wavefronts, and; freed when all the wavefronts of a work-group have terminated. The data store; (DS) instructions can be used to access it. The private memory space uses the hardware scratch memory support. If the kernel; uses scratch, then the hardware allocates memory that is accessed using; wavefront lane dword (4 byte) interleaving. The mapping used from private; address to physical address is:. ``wavefront-scratch-base +; (private-address * wavefront-size * 4) +; (wavefront-lane-id * 4)``. There are different ways that the wavefront scratch base address is determined; by a wavefront (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). This; memory can be accessed in an interleaved manner using buffer instruction with; the scratch buffer descriptor and per wavefront scratch offset, by the scratch; instructions, or by flat instructions. If each lane of a wavefront accesses the; same private address, the interleaving results in adjacent dwords bein",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:154178,allocate,allocated,154178,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency," 345; CD1; Misleading comment on example in templates chapter; Yes. 346; NAD; Typo in 15.4; N/A. 347; NAD; Use of derived class name in defining base class nested class; Yes. 348; CD1; delete and user-written deallocation functions; N/A. 349; CD1; Template argument deduction for conversion functions and qualification conversions; No. 350; open; signed char underlying representation for objects; Not resolved. 351; CD1; Sequence point error: unspecified or undefined?; N/A. 352; CD1; Nondeduced contexts; Clang 2.8. 353; CD1; Is deallocation routine called if destructor throws exception in delete?; Unknown. 354; CD1; Null as nontype template argument; Yes (C++11 onwards). 355; C++11; Global-scope :: in nested-name-specifier; Yes. 356; NAD; Wording of behavior of generated copy constructor for scalar members; N/A. 357; CD1; Definition of signature should include name; Yes. 358; NAD; Namespaces and extern ""C""; Yes. 359; NAD; Type definition in anonymous union; Yes. 360; CD6; Using-declaration that reduces access; Yes. 361; open; Forward reference to default argument; Not resolved. 362; CD1; Order of initialization in instantiation units; N/A. 363; NAD; Initialization of class from self; N/A. 364; CD1; Calling overloaded function with static in set, with no object; Yes. 365; open; Storage duration and temporaries; Not resolved. 366; CD1; String literal allowed in integral constant expression?; Yes. 367; CD1; throw operator allowed in constant expression?; Yes. 368; CD1; Uses of non-type parameters that should cause deduction to fail; Clang 3.6. 369; drafting; Are new/delete identifiers or preprocessing-op-or-punc?; Not resolved. 370; CD1; Can #include <...> form be used other than for standard C++ headers?; N/A. 371; open; Interleaving of constructor calls; Not resolved. 372; CD1; Is access granted by base class specifiers available in following base class specifiers?; No. 373; C++11; Lookup on namespace qualified name in using-directive; Clang 5. 374; CD2; Can explicit sp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:24035,reduce,reduces,24035,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,1,['reduce'],['reduces']
Energy Efficiency," 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA; Everyone is permitted to copy and distribute verbatim copies; of this license document, but changing it is not allowed. Preamble. The licenses for most software are designed to take away your; freedom to share and change it. By contrast, the GNU General Public; License is intended to guarantee your freedom to share and change free; software--to make sure the software is free for all its users. This; General Public License applies to most of the Free Software; Foundation's software and to any other program whose authors commit to; using it. (Some other Free Software Foundation software is covered by; the GNU Lesser General Public License instead.) You can apply it to; your programs, too. When we speak of free software, we are referring to freedom, not; price. Our General Public Licenses are designed to make sure that you; have the freedom to distribute copies of free software (and charge for; this service if you wish), that you receive source code or can get it; if you want it, that you can change the software or use pieces of it; in new free programs; and that you know you can do these things. To protect your rights, we need to make restrictions that forbid; anyone to deny you these rights or to ask you to surrender the rights.; These restrictions translate to certain responsibilities for you if you; distribute copies of the software, or if you modify it. For example, if you distribute copies of such a program, whether; gratis or for a fee, you must give the recipients all the rights that; you have. You must make sure that they, too, receive or can get the; source code. And you must show them these terms so they know their; rights. We protect your rights with two steps: (1) copyright the software, and; (2) offer you this license which gives you legal permission to copy,; distribute and/or modify the software. Also, for each author's protection and ours, we want to make certain; that everyone understands th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/misc/rootql/LICENSE.txt:1062,charge,charge,1062,misc/rootql/LICENSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/misc/rootql/LICENSE.txt,2,['charge'],['charge']
Energy Efficiency," <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fadd.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``ADD`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fadd``' intrinsic performs the floating-point ``ADD``; reduction (:ref:`llvm.vector.reduce.fadd <int_vector_reduce_fadd>`) of the; vector operand ``val`` on each enabled lane, adding it to the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``-0.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to ``start_value``. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fadd; <int_vector_reduce_fadd>`) for more detail on the semantics of the reduction. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fadd.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float -0.0, float -0.0, float -0.0, float -0.0>; %also.r = call float @llvm.vector.reduce.fadd.v4f32(float %start, <4 x float> %mask",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:751431,reduce,reduce,751431,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fmul.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MUL`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmul``' intrinsic performs the floating-point ``MUL``; reduction (:ref:`llvm.vector.reduce.fmul <int_vector_reduce_fmul>`) of the; vector operand ``val`` on each enabled lane, multiplying it by the scalar; `start_value``. Disabled lanes are treated as containing the neutral value; ``1.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to the starting value. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fmul; <int_vector_reduce_fmul>`) for more detail on the semantics. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmul.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float 1.0, float 1.0, float 1.0, float 1.0>; %also.r = call float @llvm.vector.reduce.fmul.v4f32(float %start, <4 x float> %masked.a). .. _int_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:755643,reduce,reduce,755643,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," = ..;; TMatrixD a = ..;; .; TDecompLU lu(a);; Bool_t ok;; lu.Solve(b,ok);; ```. In the next example, we show again the same decomposition but now; performed in a loop and all necessary steps are manually invoked. This; example also demonstrates another very important point concerning memory; management! Note that the vector, matrix and decomposition class are; constructed outside the loop since the dimensions of vector/matrix are; constant. If we would have replaced `lu.SetMatrix(a)` by **`TDecompLU`**; `lu(a)`, we would construct/deconstruct the array elements of `lu` on; the stack*.*. ``` {.cpp}; TVectorD b(n);; TMatrixD a(n,n);; TDecompLU lu(n);; Bool_t ok;; for (....) {; b = ..;; a = ..;; lu.SetMatrix(a);; lu.Decompose();; lu.Solve(b,ok);; }; ```. ### Tolerances and Scaling. The tolerance parameter `fTol` (a member of the base class; **`TDecompBase`**) plays a crucial role in all operations of the; decomposition classes. It gives the user a tool to monitor and steer the; operations its default value is $\varepsilon$ where $1+\varepsilon=1$. If you do not want to be bothered by the following considerations, like; in most other linear algebra packages, just set the tolerance with; `SetTol` to an arbitrary small number. The tolerance number is used by; each decomposition method to decide whether the matrix is near singular,; except of course SVD that can handle singular matrices. This will be; checked in a different way for any decomposition. For instance in LU, a; matrix is considered singular in the solving stage when a diagonal; element of the decomposed matrix is smaller than `fTol`. Here an; important point is raised. The `Decompose()` method is successful as; long no zero diagonal element is encountered. Therefore, the user could; perform decomposition and only after this step worry about the tolerance; number. If the matrix is flagged as being singular, operations with the; decomposition will fail and will return matrices or vectors that are; invalid. If on",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md:39772,monitor,monitor,39772,documentation/users-guide/LinearAlgebra.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md,1,['monitor'],['monitor']
Energy Efficiency," API under test.; Like this:. .. code-block:: c++. // fuzz_target.cc; extern ""C"" int LLVMFuzzerTestOneInput(const uint8_t *Data, size_t Size) {; DoSomethingInterestingWithMyAPI(Data, Size);; return 0; // Values other than 0 and -1 are reserved for future use.; }. Note that this fuzz target does not depend on libFuzzer in any way; and so it is possible and even desirable to use it with other fuzzing engines; e.g. AFL_ and/or Radamsa_. Some important things to remember about fuzz targets:. * The fuzzing engine will execute the fuzz target many times with different inputs in the same process.; * It must tolerate any kind of input (empty, huge, malformed, etc).; * It must not `exit()` on any input.; * It may use threads but ideally all threads should be joined at the end of the function.; * It must be as deterministic as possible. Non-determinism (e.g. random decisions not based on the input bytes) will make fuzzing inefficient.; * It must be fast. Try avoiding cubic or greater complexity, logging, or excessive memory consumption.; * Ideally, it should not modify any global state (although that's not strict).; * Usually, the narrower the target the better. E.g. if your target can parse several data formats, split it into several targets, one per format. Fuzzer Usage; ------------. Recent versions of Clang (starting from 6.0) include libFuzzer, and no extra installation is necessary. In order to build your fuzzer binary, use the `-fsanitize=fuzzer` flag during the; compilation and linking. In most cases you may want to combine libFuzzer with; AddressSanitizer_ (ASAN), UndefinedBehaviorSanitizer_ (UBSAN), or both. You can; also build with MemorySanitizer_ (MSAN), but support is experimental::. clang -g -O1 -fsanitize=fuzzer mytarget.c # Builds the fuzz target w/o sanitizers; clang -g -O1 -fsanitize=fuzzer,address mytarget.c # Builds the fuzz target with ASAN; clang -g -O1 -fsanitize=fuzzer,signed-integer-overflow mytarget.c # Builds the fuzz target with a part of UBSAN; c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:2443,consumption,consumption,2443,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['consumption'],['consumption']
Energy Efficiency," ASAN is unsupported. Building fuzzers with the; ``/MD`` (dynamic runtime library) compile option is unsupported. Support for these; may be added in the future. Linking fuzzers with the ``/INCREMENTAL`` link option; (or the ``/DEBUG`` option which implies it) is also unsupported. Send any questions or comments to the mailing list: libfuzzer(#)googlegroups.com. Q. When libFuzzer is not a good solution for a problem?; ---------------------------------------------------------. * If the test inputs are validated by the target library and the validator; asserts/crashes on invalid inputs, in-process fuzzing is not applicable.; * Bugs in the target library may accumulate without being detected. E.g. a memory; corruption that goes undetected at first and then leads to a crash while; testing another input. This is why it is highly recommended to run this; in-process fuzzer with all sanitizers to detect most bugs on the spot.; * It is harder to protect the in-process fuzzer from excessive memory; consumption and infinite loops in the target library (still possible).; * The target library should not have significant global state that is not; reset between the runs.; * Many interesting target libraries are not designed in a way that supports; the in-process fuzzer interface (e.g. require a file path instead of a; byte array).; * If a single test run takes a considerable fraction of a second (or; more) the speed benefit from the in-process fuzzer is negligible.; * If the target library runs persistent threads (that outlive; execution of one test) the fuzzing results will be unreliable. Q. So, what exactly this Fuzzer is good for?; --------------------------------------------. This Fuzzer might be a good choice for testing libraries that have relatively; small inputs, each input takes < 10ms to run, and the library code is not expected; to crash on invalid inputs.; Examples: regular expression matchers, text or binary format parsers, compression,; network, crypto. Q. LibFuzzer cra",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:29894,consumption,consumption,29894,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['consumption'],['consumption']
Energy Efficiency," As with a ``StringRef``, ``Twine`` objects point to external memory and should; almost never be stored or mentioned directly. They are intended solely for use; when defining a function which should be able to efficiently accept concatenated; strings. .. _formatting_strings:. Formatting strings (the ``formatv`` function); ---------------------------------------------; While LLVM doesn't necessarily do a lot of string manipulation and parsing, it; does do a lot of string formatting. From diagnostic messages, to llvm tool; outputs such as ``llvm-readobj`` to printing verbose disassembly listings and; LLDB runtime logging, the need for string formatting is pervasive. The ``formatv`` is similar in spirit to ``printf``, but uses a different syntax; which borrows heavily from Python and C#. Unlike ``printf`` it deduces the type; to be formatted at compile time, so it does not need a format specifier such as; ``%d``. This reduces the mental overhead of trying to construct portable format; strings, especially for platform-specific types like ``size_t`` or pointer types.; Unlike both ``printf`` and Python, it additionally fails to compile if LLVM does; not know how to format the type. These two properties ensure that the function; is both safer and simpler to use than traditional formatting methods such as; the ``printf`` family of functions. Simple formatting; ^^^^^^^^^^^^^^^^^. A call to ``formatv`` involves a single **format string** consisting of 0 or more; **replacement sequences**, followed by a variable length list of **replacement values**.; A replacement sequence is a string of the form ``{N[[,align]:style]}``. ``N`` refers to the 0-based index of the argument from the list of replacement; values. Note that this means it is possible to reference the same parameter; multiple times, possibly with different style and/or alignment options, in any order. ``align`` is an optional string specifying the width of the field to format; the value into, and the alignment of the v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:11788,reduce,reduces,11788,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['reduce'],['reduces']
Energy Efficiency," CXTranslationUnit unit = clang_parseTranslationUnit(; index,; ""file.cpp"", nullptr, 0,; nullptr, 0,; CXTranslationUnit_None); //Parse ""file.cpp"". if (unit == nullptr){; std::cerr << ""Unable to parse translation unit. Quitting.\n"";; return 0;; }; CXCursor cursor = clang_getTranslationUnitCursor(unit); //Obtain a cursor at the root of the translation unit; }. Visiting elements of an AST; ~~~~~~~~~~~~~~~~~~~~~~~~~~~; The elements of an AST can be recursively visited with pre-order traversal with ``clang_visitChildren``. .. code-block:: cpp. clang_visitChildren(; cursor, //Root cursor; [](CXCursor current_cursor, CXCursor parent, CXClientData client_data){. CXString current_display_name = clang_getCursorDisplayName(current_cursor);; //Allocate a CXString representing the name of the current cursor. std::cout << ""Visiting element "" << clang_getCString(current_display_name) << ""\n"";; //Print the char* value of current_display_name. clang_disposeString(current_display_name);; //Since clang_getCursorDisplayName allocates a new CXString, it must be freed. This applies; //to all functions returning a CXString. return CXChildVisit_Recurse;. }, //CXCursorVisitor: a function pointer; nullptr //client_data; );. The return value of ``CXCursorVisitor``, the callable argument of ``clang_visitChildren``, can return one of the three:. #. ``CXChildVisit_Break``: Terminates the cursor traversal. #. ``CXChildVisit_Continue``: Continues the cursor traversal with the next sibling of the cursor just visited, without visiting its children. #. ``CXChildVisit_Recurse``: Recursively traverse the children of this cursor, using the same visitor and client data. The expected output of that program is. .. code-block::. Visiting element foo; Visiting element bar; Visiting element bar_pointer. Extracting information from a Cursor; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~; .. The following functions take a ``CXCursor`` as an argument and return associated information. Extracting the Cursor kind; """"""""""""""""""""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibClang.rst:2485,allocate,allocates,2485,interpreter/llvm-project/clang/docs/LibClang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibClang.rst,1,['allocate'],['allocates']
Energy Efficiency," Different fields of a structure do not alias.; * Indexes into arrays with statically differing subscripts cannot alias.; * Many common standard C library functions `never access memory or only read; memory`_.; * Pointers that obviously point to constant globals ""``pointToConstantMemory``"".; * Function calls can not modify or references stack allocations if they never; escape from the function that allocates them (a common case for automatic; arrays). The ``-globalsmodref-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This pass implements a simple context-sensitive mod/ref and alias analysis for; internal global variables that don't ""have their address taken"". If a global; does not have its address taken, the pass knows that no pointers alias the; global. This pass also keeps track of functions that it knows never access; memory or never read memory. This allows certain optimizations (e.g. GVN) to; eliminate call instructions entirely. The real power of this pass is that it provides context-sensitive mod/ref; information for call instructions. This allows the optimizer to know that calls; to a function do not clobber or read the value of the global, allowing loads and; stores to be eliminated. .. note::. This pass is somewhat limited in its scope (only support non-address taken; globals), but is very quick analysis. The ``-steens-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^^^. The ``-steens-aa`` pass implements a variation on the well-known ""Steensgaard's; algorithm"" for interprocedural alias analysis. Steensgaard's algorithm is a; unification-based, flow-insensitive, context-insensitive, and field-insensitive; alias analysis that is also very scalable (effectively linear time). The LLVM ``-steens-aa`` pass implements a ""speculatively field-**sensitive**""; version of Steensgaard's algorithm using the Data Structure Analysis framework.; This gives it substantially more precision than the standard algorithm while; maintaining excellent analysis scalability. .. note::. ``-steens-aa`` ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:24999,power,power,24999,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['power'],['power']
Energy Efficiency," Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.or.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %masked.a); %also.r = or i32 %reduction, %start. .. _int_vp_reduce_xor:. '``llvm.vp.reduce.xor.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.xor.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.xor.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``XOR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.xor``' intrinsic performs the integer ``XOR`` reduction; (:ref:`llvm.vector.reduce.xor <int_vector_reduce_xor>`) of the vector operand; ``val`` on each enabled lane, performing an '``xor``' of that with the scalar; ``s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:760978,reduce,reduce,760978,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," Encoded data (dissected later); }, section ""__llvm_covmap"", align 8. The current version of the format is version 6. There is one difference between versions 6 and 5:. * The first entry in the filename list is the compilation directory. When the; filename is relative, the compilation directory is combined with the relative; path to get an absolute path. This can reduce size by omitting the duplicate; prefix in filenames. There is one difference between versions 5 and 4:. * The notion of branch region has been introduced along with a corresponding; region kind. Branch regions encode two counters, one to track how many; times a ""true"" branch condition is taken, and one to track how many times a; ""false"" branch condition is taken. There are two differences between versions 4 and 3:. * Function records are now named symbols, and are marked *linkonce_odr*. This; allows linkers to merge duplicate function records. Merging of duplicate; *dummy* records (emitted for functions included-but-not-used in a translation; unit) reduces size bloat in the coverage mapping data. As part of this; change, region mapping information for a function is now included within the; function record, instead of being affixed to the coverage header. * The filename list for a translation unit may optionally be zlib-compressed. The only difference between versions 3 and 2 is that a special encoding for; column end locations was introduced to indicate gap regions. In version 1, the function record for *foo* was defined as follows:. .. code-block:: llvm. { i8*, i32, i32, i64 } { i8* getelementptr inbounds ([3 x i8]* @__profn_foo, i32 0, i32 0), ; Function's name; i32 3, ; Function's name length; i32 9, ; Function's encoded coverage mapping data string length; i64 0 ; Function's structural hash; }. In version 2, the function record for *foo* was defined as follows:. .. code-block:: llvm. { i64, i32, i64 } {; i64 0x5cf8c24cdb18bdac, ; Function's name MD5; i32 9, ; Function's encoded coverage mapping d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:16328,reduce,reduces,16328,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,1,['reduce'],['reduces']
Energy Efficiency," False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). Boost_Num No 100 − Number of times the classifier is boosted. Boost_MonitorMethod No True − Write monitoring histograms for each boosted classifier. Boost_DetailedMonitoring No False − Produce histograms for detailed boost-wise monitoring. Boost_Type No AdaBoost AdaBoost, Bagging, HighEdgeGauss, HighEdgeCoPara Boosting type for the classifiers. Boost_BaggedSampleFraction No 0.6 − Relative size of bagged event sample to original size of the data sample (used whenever bagging is used). Boost_MethodWeightType No ByError ByError, Average, ByROC, ByOverlap, LastMethod How to set the final weight of the boosted classifiers. Boost_RecalculateMVACut No True − Recalculate the classifier MVA Signallike cut at every boost iteration. Boost_AdaBoostBeta No 1 − The ADA boost parameter that sets the effect of every boost step on the events' weights. Boost_Transform No step step, linear, log, gauss Type of transform applied to every boosted method linear, log, step. Boost_RandomSeed No 0 − Seed for random number generator used for bagging. Configuration options for MVA method :. Configuration options reference for MVA method: RuleFit. Option Array Default value Predefined values Description.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:16788,monitor,monitoring,16788,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,1,['monitor'],['monitoring']
Energy Efficiency," Level; Debugging <SourceLevelDebugging.html#format-common-intrinsics>`_; document. Exception Handling Intrinsics; -----------------------------. The LLVM exception handling intrinsics (which all start with; ``llvm.eh.`` prefix), are described in the `LLVM Exception; Handling <ExceptionHandling.html#format-common-intrinsics>`_ document. Pointer Authentication Intrinsics; ---------------------------------. The LLVM pointer authentication intrinsics (which all start with; ``llvm.ptrauth.`` prefix), are described in the `Pointer Authentication; <PointerAuth.html#intrinsics>`_ document. .. _int_trampoline:. Trampoline Intrinsics; ---------------------. These intrinsics make it possible to excise one parameter, marked with; the :ref:`nest <nest>` attribute, from a function. The result is a; callable function pointer lacking the nest parameter - the caller does; not need to provide a value for it. Instead, the value to use is stored; in advance in a ""trampoline"", a block of memory usually allocated on the; stack, which also contains code to splice the nest value into the; argument list. This is used to implement the GCC nested function address; extension. For example, if the function is ``i32 f(ptr nest %c, i32 %x, i32 %y)``; then the resulting function pointer has signature ``i32 (i32, i32)``.; It can be created as follows:. .. code-block:: llvm. %tramp = alloca [10 x i8], align 4 ; size and alignment only correct for X86; call ptr @llvm.init.trampoline(ptr %tramp, ptr @f, ptr %nval); %fp = call ptr @llvm.adjust.trampoline(ptr %tramp). The call ``%val = call i32 %fp(i32 %x, i32 %y)`` is then equivalent to; ``%val = call i32 %f(ptr %nval, i32 %x, i32 %y)``. .. _int_it:. '``llvm.init.trampoline``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.init.trampoline(ptr <tramp>, ptr <func>, ptr <nval>). Overview:; """""""""""""""""". This fills the memory pointed to by ``tramp`` with executable code,; turning it into a trampoline. Arguments:; """"""""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:688422,allocate,allocated,688422,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency," Linux and MacOS X these stacktraces are generated; by the script $ROOTSYS/etc/gdb-backtrace.sh. Using the Root.StackTraceMessage; resource one can customize the message printed by the script. The entire; script can be replaced using the Root.StacktraceScript resource.; Numerous minor bug fixes... New module editline ; The new module editline enhances the prompt, giving type and syntax feedback using e.g. colors.; Class names are highlighted blue when typed, indicating that it is known to ROOT.; Matching parenthesis pairs are highlighted green when typed, or when the cursor is moved to a bracket. This works for () {} and [] brackets.; Any mismatched brackets (those without a matching partner) will be highlighted red when typed or when the cursor is moved to the bracket.; Tab completion output is colored magenta to differentiate between tab completion output and user input.; All of the colors are configurable in the .rootrc file.; They can be specified as #rgb or #rrggbb or color names:; black, red, green, yellow, blue, magenta, cyan or white.; They can be followed by an optional bold (alias light) or underlined.; Rint.ReverseColor allows to quickly toggle between the default ""light on dark"" (yes) instead of ""dark on light"" (no), depending on the terminal background.; An example configuration would be:. Rint.TypeColor: blue; Rint.BracketColor: bold green; Rint.BadBracketColor: underlined red; Rint.TabColor: magenta; Rint.PromptColor: black; Rint.ReverseColor: no. The enhanced prompt is available on all platforms with [n]curses, including Linux, Solaris and MacOS; the bold and underline options are available also for black and white terminals. You can export (or setenv) TERM=xterm-256color for nicer colors.; With editline comes also an improved terminal input handler.; It supports e.g. ^O (Ctrl-o) to replay the history: suppose you have entered. ...; root [3] i = func(); root [4] i += 12; root [5] printf(""i is %d\n"", i). You now want to re-run these three lines.; As a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v526/index.html:2184,green,green,2184,core/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v526/index.html,1,['green'],['green']
Energy Efficiency," Naumann,A. and Moneta,L. and Russo,P.},; title = {{Cling} -- The New Interactive Interpreter for {ROOT} 6}},; journal = {Journal of Physics: Conference Series},; year = 2012,; month = {dec},; volume = {396},; number = {5},; pages = {052071},; doi = {10.1088/1742-6596/396/5/052071},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/396/5/052071/pdf},; publisher = {{IOP} Publishing}; }; ```. Developers' Corner; ==================; [Cling's latest doxygen documentation](http://cling.web.cern.ch/cling/doxygen/). Contributions; -------------; Every contribution is considered a donation and its copyright and any other; related rights become exclusive ownership of the person who merged the code or; in any other case the main developers of the ""Cling Project"". We warmly welcome external contributions to the Cling! By providing code,; you agree to transfer your copyright on the code to the ""Cling project"".; Of course you will be duly credited and your name will appear on the; contributors page, the release notes, and in the [CREDITS file](CREDITS.txt); shipped with every binary and source distribution. The copyright transfer is; necessary for us to be able to effectively defend the project in case of; litigation. License; -------; Please see our [LICENSE](LICENSE.TXT). Releases; --------; Our release steps to follow when cutting a new release:; 1. Update [release notes](docs/ReleaseNotes.md); 2. Remove `~dev` suffix from [VERSION](VERSION); 3. Add a new entry in the news section of our [website](www/news.html); 4. Commit the changes.; 5. `git tag -a v0.x -m ""Tagging release v0.x""`; 6. Tag `cling-patches` of `clang.git`:; `git tag -a cling-v0.x -m ""Tagging clang for cling v0.x""`; 7. Create a draft release in github and copy the contents of the release notes.; 8. Wait for green builds.; 9. Upload binaries to github (Travis should do this automatically).; 10. Publish the tag and announce it on the mailing list.; 11. Increment the current version and append `~dev`.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md:4526,green,green,4526,interpreter/cling/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/README.md,1,['green'],['green']
Energy Efficiency," OTHERWISE, ARISING FROM, OUT OF OR IN; > CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE; > SOFTWARE. LuaXML License; ------. ### Included only if built with Lua and LuaXML support. Version 1.8.0 (Lua 5.2), 2013-06-10 by Gerald Franz, eludi.net. Modified and extended 2015 by Bernhard Nortmann, https://github.com/n1tehawk/LuaXML – version 2.0.x, compatible with Lua 5.1 to 5.3 and LuaJIT. > LuaXML License; >; > LuaXml is licensed under the terms of the MIT license reproduced below,; > the same as Lua itself. This means that LuaXml is free software and can be; > used for both academic and commercial purposes at absolutely no cost.; >; > Copyright (C) 2007-2013 Gerald Franz, eludi.net; >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, publish, distribute, sublicense, and/or sell; > copies of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. Duktape License; ------. ### Included only if built with Duktape support. https://github.com/svaarala/duktape/blob/master/LICENSE.txt. > ===============; > Duktape license; > ===============; >; > (http://opensource.or",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:6497,charge,charge,6497,net/http/civetweb/LICENSE.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md,1,['charge'],['charge']
Energy Efficiency," OUTPUT_NAME LLVM ${INSTALL_WITH_TOOLCHAIN} ${SOURCES}); # Add symlink for backwards compatibility with old library name; llvm_install_library_symlink(LLVM-${LLVM_VERSION_MAJOR}${LLVM_VERSION_SUFFIX} $<TARGET_FILE_NAME:LLVM> SHARED FULL_DEST COMPONENT LLVM); endif(). list(REMOVE_DUPLICATES LIB_NAMES); if(""${CMAKE_SYSTEM_NAME}"" STREQUAL ""Darwin""); set(LIB_NAMES -Wl,-all_load ${LIB_NAMES}); else(); configure_file(; ${CMAKE_CURRENT_SOURCE_DIR}/simple_version_script.map.in; ${LLVM_LIBRARY_DIR}/tools/llvm-shlib/simple_version_script.map). # GNU ld doesn't resolve symbols in the version script.; set(LIB_NAMES -Wl,--whole-archive ${LIB_NAMES} -Wl,--no-whole-archive); if (NOT LLVM_LINKER_IS_SOLARISLD AND NOT MINGW); # Solaris ld does not accept global: *; so there is no way to version *all* global symbols; set(LIB_NAMES -Wl,--version-script,${LLVM_LIBRARY_DIR}/tools/llvm-shlib/simple_version_script.map ${LIB_NAMES}); endif(); if (NOT MINGW AND NOT LLVM_LINKER_IS_SOLARISLD_ILLUMOS); # Optimize function calls for default visibility definitions to avoid PLT and; # reduce dynamic relocations.; # Note: for -fno-pic default, the address of a function may be different from; # inside and outside libLLVM.so.; target_link_options(LLVM PRIVATE LINKER:-Bsymbolic-functions); endif(); endif(). target_link_libraries(LLVM PRIVATE ${LIB_NAMES}). if(LLVM_ENABLE_THREADS AND NOT HAVE_CXX_ATOMICS64_WITHOUT_LIB); target_link_libraries(LLVM PUBLIC atomic); endif(). if (APPLE); set_property(TARGET LLVM APPEND_STRING PROPERTY; LINK_FLAGS; "" -compatibility_version 1 -current_version ${LLVM_VERSION_MAJOR}.${LLVM_VERSION_MINOR}.${LLVM_VERSION_PATCH}""); endif(). if(TARGET libLLVMExports); add_dependencies(LLVM libLLVMExports); endif(); endif(). if(LLVM_BUILD_LLVM_C_DYLIB AND NOT MSVC); if(NOT APPLE); message(FATAL_ERROR ""Generating libLLVM-c is only supported on Darwin""); endif(). if(NOT LLVM_BUILD_LLVM_DYLIB); message(FATAL_ERROR ""Generating libLLVM-c requires LLVM_BUILD_LLVM_C_DYLIB on Darwin""); endif",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-shlib/CMakeLists.txt:2432,reduce,reduce,2432,interpreter/llvm-project/llvm/tools/llvm-shlib/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-shlib/CMakeLists.txt,1,['reduce'],['reduce']
Energy Efficiency," OpTypes {; enum OperandType {; ...; brtarget,; brtarget8,; ...; i32imm,; i64imm,; ...; OPERAND_TYPE_LIST_END; } // End namespace OpTypes; } // End namespace X86. In typical TableGen fashion, to use the enum, you will need to define a; preprocessor macro:. .. code-block:: c++. #define GET_INSTRINFO_OPERAND_TYPES_ENUM // For OpTypes enum; #include ""XXXGenInstrInfo.inc"". Instruction Scheduling; ----------------------. Instruction itineraries can be queried using MCDesc::getSchedClass(). The; value can be named by an enumeration in llvm::XXX::Sched namespace generated; by TableGen in XXXGenInstrInfo.inc. The name of the schedule classes are; the same as provided in XXXSchedule.td plus a default NoItinerary class. The schedule models are generated by TableGen by the SubtargetEmitter,; using the ``CodeGenSchedModels`` class. This is distinct from the itinerary; method of specifying machine resource use. The tool ``utils/schedcover.py``; can be used to determine which instructions have been covered by the; schedule model description and which haven't. The first step is to use the; instructions below to create an output file. Then run ``schedcover.py`` on the; output file:. .. code-block:: shell. $ <src>/utils/schedcover.py <build>/lib/Target/AArch64/tblGenSubtarget.with; instruction, default, CortexA53Model, CortexA57Model, CycloneModel, ExynosM3Model, FalkorModel, KryoModel, ThunderX2T99Model, ThunderXT8XModel; ABSv16i8, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_2VXVY_2cyc, KryoWrite_2cyc_XY_XY_150ln, ,; ABSv1i64, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_1VXVY_2cyc, KryoWrite_2cyc_XY_noRSV_67ln, ,; ... To capture the debug output from generating a schedule model, change to the; appropriate target directory and use the following command:; command with the ``subtarget-emitter`` debug option:. .. code-block:: shell. $ <build>/bin/llvm-tblgen -debug-only=subtarget-emitter -gen-subtarget \; -I <src>/lib/Target/<target> -I <src>/include \; -I <src>/lib/Target <src>/l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:43326,schedul,schedule,43326,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['schedul'],['schedule']
Energy Efficiency," Optimizations`_ --- This optional stage consists of a; series of machine-code optimizations that operate on the SSA-form produced by; the instruction selector. Optimizations like modulo-scheduling or peephole; optimization work here. 4. `Register Allocation`_ --- The target code is transformed from an infinite; virtual register file in SSA form to the concrete register file used by the; target. This phase introduces spill code and eliminates all virtual register; references from the program. 5. `Prolog/Epilog Code Insertion`_ --- Once the machine code has been generated; for the function and the amount of stack space required is known (used for; LLVM alloca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target assembler format or in machine; code. The code generator is based on the assumption that the instruction selector will; use an optimal pattern matching selector to create high-quality sequences of; native instructions. Alternative code generator designs based on pattern; expansion and aggressive iterative peephole optimization are much slower. This; design permits efficient compilation (important for JIT environments) and; aggressive optimization (used when generating code offline) by allowing; components of varying levels of sophistication to be used for any step of; compilation. In addition to these stages, target implementations can insert arbitrary; target-specific passes into the flow. For example, the X86 target uses a; special pass to handle the 80x87 floating point stack architecture.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:7085,schedul,scheduling,7085,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['schedul'],['scheduling']
Energy Efficiency," RNTuple data source also supports multi-threaded dataframes, parallelized on the file and cluster level. The data source exposes inner fields of complex collections.; For instance, if the data model contains a vector of `Event` classes, where each `Event` has `pt` and `eta` floats,; the dataframe can use the event vector itself (`Event` column) as well as the `float` columns `Event.pt` and `Event.eta`. ### RClusterPool; The RClusterPool is an internal class owned be a page source.; The cluster pool maintains an I/O thread that asynchronously prefetches the next few clusters.; Through `RPageSource::SetEntryRange()`, the cluster pool is instructed to not read beyond the given limit.; This is used in the RNTuple data source when multiple threads work on different clusters of the same file. ### RMiniFile; The RMiniFile is an internal class used to read and write RNTuple data in a ROOT file.; It provides a minimal subset of the `TFile` functionality.; Its purpose is to reduce the coupling between RNTuple and the ROOT I/O library. For writing data, the RMiniFile can either use a proper `TFile` (descendant) or a C file stream (only for new ROOT files with a single RNTuple).; For reading, the `RMiniFile` always uses an `RRawFile`. ### RRawFile; The RRawFile internal abstract class provides an interface to read byte ranges from a file, including vector reads.; Concrete implementations exist for local files, XRootD and HTTP (the latter two through the ROOT plugin mechanism).; The local file implementation on Linux uses uring for vector reads, if available.; `RRawFileTFile` wraps an existing `TFile` and provides access to the full set of implementations, e.g. `TMemFile`. Tooling; -------. ### RNTupleMerger; The `RNTupleMerger` is an internal class and part of the core RNTuple library.; It concatenates RNTuple data from several sources into a combined sink.; It implements ""fast merging"", i.e. copy-based merging that does not decompress and recompress pages.; The RNTupler merger",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:15650,reduce,reduce,15650,tree/ntuple/v7/doc/Architecture.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md,1,['reduce'],['reduce']
Energy Efficiency," Recipe. A Recipe; may specify how its ingredients are to be transformed to produce the output IR; instructions; e.g., cloned once, replicated multiple times or widened; according to selected VF. :VPValue:; The base of VPlan's def-use relations class hierarchy. When instantiated, it; models a constant or a live-in Value in VPlan. It has users, which are of type; VPUser, but no operands. :VPUser:; A VPUser represents an entity that uses a number of VPValues as operands.; VPUser is similar in some aspects to LLVM's User class. :VPDef:; A VPDef represents an entity that defines zero, one or multiple VPValues.; It is used to model the fact that recipes in VPlan can define multiple; VPValues. :VPInstruction:; A VPInstruction is both a VPRecipe and a VPUser. It models a single; VPlan-level instruction to be generated if the VPlan is executed, including; its opcode and possibly additional characteristics. It is the basis for; writing instruction-level analyses and optimizations in VPlan as creating,; replacing or moving VPInstructions record both def-use and scheduling; decisions. VPInstructions also extend LLVM IR's opcodes with idiomatic; operations that enrich the Vectorizer's semantics. :VPTransformState:; Stores information used for generating output IR, passed from; LoopVectorizationPlanner to its selected VPlan for execution, and used to pass; additional information down to VPBlocks and VPRecipes. The Planning Process and VPlan Roadmap; ======================================. Transforming the Loop Vectorizer to use VPlan follows a staged approach. First,; VPlan is used to record the final vectorization decisions, and to execute them:; the Hierarchical CFG models the planned control-flow, and Recipes capture; decisions taken inside basic-blocks. Next, VPlan will be used also as the basis; for taking these decisions, effectively turning them into a series of; VPlan-to-VPlan algorithms. Finally, VPlan will support the planning process; itself including cost-based analys",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:7725,schedul,scheduling,7725,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,1,['schedul'],['scheduling']
Energy Efficiency," Security Policy; - [LICENSE.md](https://github.com/civetweb/civetweb/blob/master/LICENSE.md) - Copyright License. Overview; --------. CivetWeb keeps the balance between functionality and; simplicity by a carefully selected list of features:. - Liberal, commercial-friendly, permissive,; [MIT license](http://en.wikipedia.org/wiki/MIT_License); - Free from copy-left licenses, like GPL, because you should innovate without; restrictions.; - Forked from [Mongoose](https://code.google.com/p/mongoose/) in 2013, before; it changed the licence from MIT to commercial + GPL. A lot of enhancements; have been added since that time, see; [RELEASE_NOTES.md](https://github.com/civetweb/civetweb/blob/master/RELEASE_NOTES.md).; - Works on Windows, Mac, Linux, UNIX, iPhone, Android, Buildroot, and many; other platforms.; - Scripting and database support (CGI, SQLite database, Lua Server Pages,; Server side Lua scripts, Server side JavaScript).; This provides a ready to go, powerful web development platform in a one; single-click executable with **no dependencies**.0; - Support for CGI, SSI, HTTP digest (MD5) authorization, WebSocket,; WebDAV.; - HTTPS (SSL/TLS) support using [OpenSSL](https://www.openssl.org/).; - Optional support for authentication using client side X.509 certificates.; - Resumed download, URL rewrite, file blacklist, IP-based ACL.; - May run as Windows service.; - Download speed limit based on client subnet or URI pattern.; - Simple and clean embedding API.; - The source is in single file to make things easy.; - Embedding examples included.; - HTTP client capable of sending arbitrary HTTP/HTTPS requests.; - Websocket client functionality available (WS/WSS). ### Optionally included software. [![Lua](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/lua-logo.jpg ""Lua Logo"")](http://lua.org). [![Sqlite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/sqlite3-logo.jpg ""Sqlite3 Logo"")](http://sqlite.org). [![LuaFileSystem](https:/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:6002,power,powerful,6002,net/http/civetweb/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md,1,['power'],['powerful']
Energy Efficiency," TGraph *gr2 = new TGraph(f_known);; gr2->SetMarkerColor(kRed);; gr2->SetMarkerStyle(8);; gr2->SetMarkerSize(1);; mg->Add(gr2);; //passing data to Rfot fitting; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; r[""x""]<<TVectorD(n, x1);; r[""y""]<<TVectorD(n, y1);; //creating a R data frame; r<<""ds<-data.frame(x=x,y=y)"";; //fitting x and y to X^power using Nonlinear Least Squares; r<<""m <- nls(y ~ I(x^power),data = ds, start = list(power = 1),trace = T)"";; //getting the exponent; Double_t power;; r[""summary(m)$coefficients[1]""]>>power;. TF1 *f_fitted=new TF1(""f_fitted"",""pow(x,[0])"",0,1);; f_fitted->SetParameter(0,power);; //plotting the fitted function; TGraph *gr3 = new TGraph(f_fitted);; gr3->SetMarkerColor(kGreen);; gr3->SetMarkerStyle(8);; gr3->SetMarkerSize(1);. mg->Add(gr3);; mg->Draw(""ap"");. //displaying basic results; TPaveText *pt = new TPaveText(0.1,0.6,0.5,0.9,""brNDC"");; pt->SetFillColor(18);; pt->SetTextAlign(12);; pt->AddText(""Fitting x^power "");; pt->AddText("" \""Blue\"" Points with gaussian noise to be fitted"");; pt->AddText("" \""Red\"" Known function x^3"");; TString fmsg;; fmsg.Form("" \""Green\"" Fitted function with power=%.4lf"",power);; pt->AddText(fmsg);; pt->Draw();; c1->Update();; return c1;; }; ~~~; In the first image you can see the blue dots which are the function `x^3` with gaussian noise, the red dots correspond to; the original function and the green ones correspond to the fitted function. \image html R_image1.png. ## Global Minimization in R using the package DEoptim; DEoptim is a R package for Differential Evolution Minimization that lets you do global; Minimization.; To install this package you just need to run:. ~~~{.cxx}; #include<TRInterface.h>; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; r<<""install.packages('DEoptim',repos='http://cran.rstudio.com/')"";; ~~~. Then create a macro named GlobalMinimization.C with the next code. ~~~{.cxx}; #include<TRInterface.h>; #include<TBenchmark.h>; #include<math.h>; #include<stdlib.h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:16504,power,power,16504,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['power'],['power']
Energy Efficiency," THE SOFTWARE. SQLite3 License; ------. ### Included only if built with Lua and SQLite support. http://www.sqlite.org/copyright.html. > 2001-09-15; >; > The author disclaims copyright to this source code. In place of; > a legal notice, here is a blessing:; >; > May you do good and not evil.; > May you find forgiveness for yourself and forgive others.; > May you share freely, never taking more than you give. lsqlite3 License; ------. ### Included only if built with Lua and SQLite support. > Copyright (C) 2002-2016 Tiago Dionizio, Doug Currie; > All rights reserved.; > Author : Tiago Dionizio <tiago.dionizio@ist.utl.pt>; > Author : Doug Currie <doug.currie@alum.mit.edu>; > Library : lsqlite3 - an SQLite 3 database binding for Lua 5; >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, publish, distribute, sublicense, and/or sell; > copies of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. Lua File System License; ------. ### Included only if built with Lua support. https://github.com/keplerproject/luafilesystem/blob/master/LICENSE. > Copyright © 2003-2020 Kepler Project.;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:3567,charge,charge,3567,net/http/civetweb/LICENSE.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md,1,['charge'],['charge']
Energy Efficiency," The :doc:`AdvancedBuilds` documentation describes the built-in tooling for; generating LLVM profiling information to drive Profile-Guided-Optimization. The; in-tree profiling tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant improvement in; the performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:9933,reduce,reduce,9933,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['reduce'],['reduce']
Energy Efficiency," The difference primarily lies in; the lack of an established standard in the domain of garbage collection --- thus; the need for a flexible extension mechanism. The aspects of the binary interface with which LLVM's GC support is; concerned are:. * Creation of GC safepoints within code where collection is allowed to execute; safely. * Computation of the stack map. For each safe point in the code, object; references within the stack frame must be identified so that the collector may; traverse and perhaps update them. * Write barriers when storing object references to the heap. These are commonly; used to optimize incremental scans in generational collectors. * Emission of read barriers when loading object references. These are useful; for interoperating with concurrent collectors. There are additional areas that LLVM does not directly address:. * Registration of global roots with the runtime. * Registration of stack map entries with the runtime. * The functions used by the program to allocate memory, trigger a collection,; etc. * Computation or compilation of type maps, or registration of them with the; runtime. These are used to crawl the heap for object references. In general, LLVM's support for GC does not include features which can be; adequately addressed with other features of the IR and does not specify a; particular binary interface. On the plus side, this means that you should be; able to integrate LLVM with an existing runtime. On the other hand, it can; have the effect of leaving a lot of work for the developer of a novel; language. We try to mitigate this by providing built in collector strategy; descriptions that can work with many common collector designs and easy; extension points. If you don't already have a specific binary interface; you need to support, we recommend trying to use one of these built in collector; strategies. .. _gc_intrinsics:. LLVM IR Features; ================. This section describes the garbage collection facilities provided by th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:7281,allocate,allocate,7281,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['allocate'],['allocate']
Energy Efficiency," The; ``clang/utils/creduce-clang-crash.py`` script can be used on the files; that clang dumps to help with automating creating a test to check for the; compiler crash. `cvise <https://github.com/marxin/cvise>`_ is an alternative to ``creduce``. .. _middleend-crash:. Middle-end optimization bugs; ----------------------------. If you find that a bug crashes in the optimizer, compile your test-case to a; ``.bc`` file by passing ""``-emit-llvm -O1 -Xclang -disable-llvm-passes -c -o; foo.bc``"". The ``-O1`` is important because ``-O0`` adds the ``optnone``; function attribute to all functions and many passes don't run on ``optnone``; functions. Then run:. .. code-block:: bash. opt -O3 foo.bc -disable-output. If this doesn't crash, please follow the instructions for a :ref:`front-end; bug <frontend-crash>`. If this does crash, then you should be able to debug this with the following; :doc:`bugpoint <Bugpoint>` command:. .. code-block:: bash. bugpoint foo.bc -O3. Run this, then file a bug with the instructions and reduced .bc; files that bugpoint emits. If bugpoint doesn't reproduce the crash, ``llvm-reduce`` is an alternative; way to reduce LLVM IR. Create a script that repros the crash and run:. .. code-block:: bash. llvm-reduce --test=path/to/script foo.bc. which should produce reduced IR that reproduces the crash. Be warned the; ``llvm-reduce`` is still fairly immature and may crash. If none of the above work, you can get the IR before a crash by running the; ``opt`` command with the ``--print-before-all --print-module-scope`` flags to; dump the IR before every pass. Be warned that this is very verbose. .. _backend-crash:. Backend code generator bugs; ---------------------------. If you find a bug that crashes clang in the code generator, compile your; source file to a .bc file by passing ""``-emit-llvm -c -o foo.bc``"" to; clang (in addition to the options you already pass). Once your have; foo.bc, one of the following commands should fail:. #. ``llc foo.bc``; #. ``llc f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:4255,reduce,reduced,4255,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduced']
Energy Efficiency," Using the RecursiveASTVisitor; =============================. Now that everything is hooked up, the next step is to implement a; RecursiveASTVisitor to extract the relevant information from the AST. The RecursiveASTVisitor provides hooks of the form bool; VisitNodeType(NodeType \*) for most AST nodes; the exception are TypeLoc; nodes, which are passed by-value. We only need to implement the methods; for the relevant node types. Let's start by writing a RecursiveASTVisitor that visits all; CXXRecordDecl's. ::. class FindNamedClassVisitor; : public RecursiveASTVisitor<FindNamedClassVisitor> {; public:; bool VisitCXXRecordDecl(CXXRecordDecl *Declaration) {; // For debugging, dumping the AST nodes will show which nodes are already; // being visited.; Declaration->dump();. // The return value indicates whether we want the visitation to proceed.; // Return false to stop the traversal of the AST.; return true;; }; };. In the methods of our RecursiveASTVisitor we can now use the full power; of the Clang AST to drill through to the parts that are interesting for; us. For example, to find all class declaration with a certain name, we; can check for a specific qualified name:. ::. bool VisitCXXRecordDecl(CXXRecordDecl *Declaration) {; if (Declaration->getQualifiedNameAsString() == ""n::m::C""); Declaration->dump();; return true;; }. Accessing the SourceManager and ASTContext; ==========================================. Some of the information about the AST, like source locations and global; identifier information, are not stored in the AST nodes themselves, but; in the ASTContext and its associated source manager. To retrieve them we; need to hand the ASTContext into our RecursiveASTVisitor implementation. The ASTContext is available from the CompilerInstance during the call to; CreateASTConsumer. We can thus extract it there and hand it into our; freshly created FindNamedClassConsumer:. ::. virtual std::unique_ptr<clang::ASTConsumer> CreateASTConsumer(; clang::CompilerInstance",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RAVFrontendAction.rst:2895,power,power,2895,interpreter/llvm-project/clang/docs/RAVFrontendAction.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RAVFrontendAction.rst,1,['power'],['power']
Energy Efficiency," When this is disabled, Clang will not print the ""test.c:28:8: ""; part. .. _opt_fcaret-diagnostics:. .. option:: -f[no-]caret-diagnostics. Print source line and ranges from source code in diagnostic.; This option, which defaults to on, controls whether or not Clang; prints the source line, source ranges, and caret when emitting a; diagnostic. For example, when this is enabled, Clang will print; something like:. ::. test.c:28:8: warning: extra tokens at end of #endif directive [-Wextra-tokens]; #endif bad; ^; //. .. option:: -f[no-]color-diagnostics. This option, which defaults to on when a color-capable terminal is; detected, controls whether or not Clang prints diagnostics in color. When this option is enabled, Clang will use colors to highlight; specific parts of the diagnostic, e.g.,. .. nasty hack to not lose our dignity. .. raw:: html. <pre>; <b><span style=""color:black"">test.c:28:8: <span style=""color:magenta"">warning</span>: extra tokens at end of #endif directive [-Wextra-tokens]</span></b>; #endif bad; <span style=""color:green"">^</span>; <span style=""color:green"">//</span>; </pre>. When this is disabled, Clang will just print:. ::. test.c:2:8: warning: extra tokens at end of #endif directive [-Wextra-tokens]; #endif bad; ^; //. If the ``NO_COLOR`` environment variable is defined and not empty; (regardless of value), color diagnostics are disabled. If ``NO_COLOR`` is; defined and ``-fcolor-diagnostics`` is passed on the command line, Clang; will honor the command line argument. .. option:: -fansi-escape-codes. Controls whether ANSI escape codes are used instead of the Windows Console; API to output colored diagnostics. This option is only used on Windows and; defaults to off. .. option:: -fdiagnostics-format=clang/msvc/vi. Changes diagnostic output format to better match IDEs and command line tools. This option controls the output format of the filename, line number,; and column printed in diagnostic messages. The options, and their; affect on formatting a si",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:7672,green,green,7672,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,2,['green'],['green']
Energy Efficiency," YAML and denormalizes x,y; coordinates into polar when reading YAML. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct MappingTraits<Polar> {. class NormalizedPolar {; public:; NormalizedPolar(IO &io); : x(0.0), y(0.0) {; }; NormalizedPolar(IO &, Polar &polar); : x(polar.distance * cos(polar.angle)),; y(polar.distance * sin(polar.angle)) {; }; Polar denormalize(IO &) {; return Polar(sqrt(x*x+y*y), arctan(x,y));; }. float x;; float y;; };. static void mapping(IO &io, Polar &polar) {; MappingNormalization<NormalizedPolar, Polar> keys(io, polar);. io.mapRequired(""x"", keys->x);; io.mapRequired(""y"", keys->y);; }; };. When writing YAML, the local variable ""keys"" will be a stack allocated; instance of NormalizedPolar, constructed from the supplied polar object which; initializes it x and y fields. The mapRequired() methods then write out the x; and y values as key/value pairs. When reading YAML, the local variable ""keys"" will be a stack allocated instance; of NormalizedPolar, constructed by the empty constructor. The mapRequired; methods will find the matching key in the YAML document and fill in the x and y; fields of the NormalizedPolar object keys. At the end of the mapping() method; when the local keys variable goes out of scope, the denormalize() method will; automatically be called to convert the read values back to polar coordinates,; and then assigned back to the second parameter to mapping(). In some cases, the normalized class may be a subclass of the native type and; could be returned by the denormalize() method, except that the temporary; normalized instance is stack allocated. In these cases, the utility template; MappingNormalizationHeap<> can be used instead. It just like; MappingNormalization<> except that it heap allocates the normalized object; when reading YAML. It never destroys the normalized object. The denormalize(); method can this return ""this"". Default values; --------------; Within a mapping() metho",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:18928,allocate,allocated,18928,interpreter/llvm-project/llvm/docs/YamlIO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst,1,['allocate'],['allocated']
Energy Efficiency," `ROOT::Math::AdaptiveIntegratorMultiDim` |; | `ROOT::Math::IntegratorMultiDim::kVEGAS` | `ROOT::Math:::GSLMCIntegrator` |; | `ROOT::Math::IntegratorMultiDim::kMISER` | `ROOT::Math:::GSLMCIntegrator` |; | `ROOT::Math::IntegratorMultiDim::kPLAIN` | `ROOT::Math:::GSLMCIntegrator` |. The control parameters for the integration algorithms can be specified using the; `ROOT::Math::IntegratorMultiDimOptions` class. Static methods are provided to change the default values.; It is possible to print the list of default control parameters using the `ROOT::Math::IntegratorMultiDimOptions::Print` function.; Example:; ```{.cpp}; ROOT::Math::IntegratorMultiDimOptions opt;; opt.Print();; Integrator Type : ADAPTIVE; Absolute tolerance : 1e-09; Relative tolerance : 1e-09; Workspace size : 100000; (max) function calls : 100000; ```; Depending on the algorithm, some of the control parameters might have no effect. #### `ROOT::Math::AdaptiveIntegratorMultiDim`. This class implements an adaptive quadrature integration method for multi dimensional functions. It is described in this paper; *Genz, A.A. Malik, An adaptive algorithm for numerical integration over an N-dimensional rectangular region, J. Comput. Appl. Math. 6 (1980) 295-302*.; It is part of the *MathCore* library.; The user can control the relative and absolute tolerance and the maximum allowed number of function evaluation. #### `ROOT::Math::GSLMCIntegrator`. It is a class for performing numerical integration of a multidimensional function. It uses the numerical integration algorithms of GSL, which reimplements the algorithms used; in the QUADPACK, a numerical integration package written in Fortran. Plain MC, MISER and VEGAS integration algorithms are supported for integration over finite (hypercubic) ranges.; For a detail description of the GSL methods visit the GSL users guide.; Specific configuration options (documented in the GSL user guide) for the `ROOT::Math::GSLMCIntegration` can be set directly in the class, or when usin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:61208,adapt,adaptive,61208,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['adapt'],['adaptive']
Energy Efficiency," ``InFlightAlloc::finalize`` method should cause content for the allocation to be; transferred from working to executor memory, and permissions to be run. A call; to ``abandon`` should result in both kinds of memory being deallocated. On successful finalization, the ``InFlightAlloc::finalize`` method should; construct a ``FinalizedAlloc`` object (an opaque uint64_t id that the; ``JITLinkMemoryManager`` can use to identify executor memory for deallocation); and pass it to the ``OnFinalized`` callback. Finalized allocations (represented by ``FinalizedAlloc`` objects) can be; deallocated by calling the ``JITLinkMemoryManager::dealloc`` method. This method; takes a vector of ``FinalizedAlloc`` objects, since it is common to deallocate; multiple objects at the same time and this allows us to batch these requests for; transmission to the executing process. JITLink provides a simple in-process implementation of this interface:; ``InProcessMemoryManager``. It allocates pages once and re-uses them as both; working and target memory. ORC provides a cross-process-capable ``MapperJITLinkMemoryManager`` that can use; shared memory or ORC-RPC-based communication to transfer content to the executing; process. JITLinkMemoryManager and Security; ---------------------------------. JITLink's ability to link JIT'd code for a separate executor process can be; used to improve the security of a JIT system: The executor process can be; sandboxed, run within a VM, or even run on a fully separate machine. JITLink's memory manager interface is flexible enough to allow for a range of; trade-offs between performance and security. For example, on a system where code; pages must be signed (preventing code from being updated), the memory manager; can deallocate working memory pages after linking to free memory in the process; running JITLink. Alternatively, on a system that allows RWX pages, the memory; manager may use the same pages for both working and target memory by marking; them as RWX, allow",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:30414,allocate,allocates,30414,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['allocate'],['allocates']
Energy Efficiency," ``TargetJITInfo`` class; ---------------------------. The ``TargetJITInfo`` class exposes an abstract interface used by the; Just-In-Time code generator to perform target-specific activities, such as; emitting stubs. If a ``TargetMachine`` supports JIT code generation, it should; provide one of these objects through the ``getJITInfo`` method. .. _code being generated:; .. _machine code representation:. Machine code description classes; ================================. At the high-level, LLVM code is translated to a machine specific representation; formed out of :raw-html:`<tt>` `MachineFunction`_ :raw-html:`</tt>`,; :raw-html:`<tt>` `MachineBasicBlock`_ :raw-html:`</tt>`, and :raw-html:`<tt>`; `MachineInstr`_ :raw-html:`</tt>` instances (defined in; ``include/llvm/CodeGen``). This representation is completely target agnostic,; representing instructions in their most abstract form: an opcode and a series of; operands. This representation is designed to support both an SSA representation; for machine code, as well as a register allocated, non-SSA form. .. _MachineInstr:. The ``MachineInstr`` class; --------------------------. Target machine instructions are represented as instances of the ``MachineInstr``; class. This class is an extremely abstract way of representing machine; instructions. In particular, it only keeps track of an opcode number and a set; of operands. The opcode number is a simple unsigned integer that only has meaning to a; specific backend. All of the instructions for a target should be defined in the; ``*InstrInfo.td`` file for the target. The opcode enum values are auto-generated; from this description. The ``MachineInstr`` class does not have any information; about how to interpret the instruction (i.e., what the semantics of the; instruction are); for that you must refer to the :raw-html:`<tt>`; `TargetInstrInfo`_ :raw-html:`</tt>` class. The operands of a machine instruction can be of several different types: a; register reference, a constant",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:15833,allocate,allocated,15833,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['allocate'],['allocated']
Energy Efficiency," ``delete[]``).; Direct use of ``malloc`` and ``new`` should be avoided for C++ classes, as; these may override ``operator new`` to control their own allocation.; However these low-level allocators can be necessary for builtin types on; occasion if the C++ side takes ownership (otherwise, prefer either; ``array`` from the builtin module ``array`` or ``ndarray`` from Numpy). The low-level module adds the following functions:. * **ll.malloc**: an interface on top of C's malloc.; Use it as a template with the number of elements (not the number types) to; be allocated.; The result is a ``cppyy.LowLevelView`` with the proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.malloc[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. The actual C malloc can also be used directly, through ``cppyy.gbl.malloc``,; taking the number of *bytes* to be allocated and returning a ``void*``. * **ll.free**: an interface to C's free, to deallocate memory allocated by; C's malloc.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.free(arr); >>>. The actual C free can also be used directly, through ``cppyy.gbl.free``. * **ll.array_new**: an interface on top of C++'s ``new[]``.; Use it as a template; the result is a ``cppyy.LowLevelView`` with the; proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.array_new[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. * **ll.array_delete**: an interface on top of C++'s ``delete[]``.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.array_delete(arr); >>>. `argc/argv`; -----------. C/C++'s ``main`` function can take the number of command line arguments; (``argc``) and their values (``argv``) as function arguments.; A common idiom has these values subsequently passed on to the entry point of; e.g. a framework or library.; Since the type of ``argv`` in particular (``char*[]``) ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:10346,allocate,allocated,10346,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,1,['allocate'],['allocated']
Energy Efficiency," a '#'. Can be specified multiple times to read names from multiple files. .. option:: --weaken. Mark all defined global symbols as weak in the output. MACH-O-SPECIFIC OPTIONS; -----------------------. .. option:: --keep-undefined. Keep undefined symbols, even if they would otherwise be stripped. COFF-SPECIFIC OPTIONS; ---------------------. .. option:: --subsystem <name>[:<version>]. Set the PE subsystem, and optionally subsystem version. SUPPORTED FORMATS; -----------------. The following values are currently supported by :program:`llvm-objcopy` for the; :option:`--input-target`, :option:`--output-target`, and :option:`--target`; options. For GNU :program:`objcopy` compatibility, the values are all bfdnames. - `binary`; - `ihex`; - `elf32-i386`; - `elf32-x86-64`; - `elf64-x86-64`; - `elf32-iamcu`; - `elf32-littlearm`; - `elf64-aarch64`; - `elf64-littleaarch64`; - `elf32-littleriscv`; - `elf64-littleriscv`; - `elf32-powerpc`; - `elf32-powerpcle`; - `elf64-powerpc`; - `elf64-powerpcle`; - `elf32-bigmips`; - `elf32-ntradbigmips`; - `elf32-ntradlittlemips`; - `elf32-tradbigmips`; - `elf32-tradlittlemips`; - `elf64-tradbigmips`; - `elf64-tradlittlemips`; - `elf32-sparc`; - `elf32-sparcel`; - `elf32-hexagon`; - `elf32-loongarch`; - `elf64-loongarch`; - `elf64-s390`. Additionally, all targets except `binary` and `ihex` can have `-freebsd` as a; suffix. BINARY INPUT AND OUTPUT; -----------------------. If `binary` is used as the value for :option:`--input-target`, the input file; will be embedded as a data section in an ELF relocatable object, with symbols; ``_binary_<file_name>_start``, ``_binary_<file_name>_end``, and; ``_binary_<file_name>_size`` representing the start, end and size of the data,; where ``<file_name>`` is the path of the input file as specified on the command; line with non-alphanumeric characters converted to ``_``. If `binary` is used as the value for :option:`--output-target`, the output file; will be a raw binary file, containing the memory image of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:18909,power,powerpc,18909,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,4,['power'],"['powerpc', 'powerpcle']"
Energy Efficiency," a gaussian and an exponential.; - `TF1(""voigt"", ""CONV(breitwigner, gausn) , -15, 15)` will create a TF1 object made of a convolution between a Breit-Wigner and a Gaussian. ; - `TFormula` supports vectorization. All the `TF1` objected created with a formula expression can have a vectorized signature using `ROOT::Double_v`: `TF1::EvalPar( ROOT::Double_v * x,; double * p)`. The vectorization can then be used to speed-up fitting. It is not enabled by default, but it can be enabled by callig `TF1::SetVectorized(true)` or using the `""VEC""` option in the; constructor of TF1, when ROOT has been built with VecCore and one vectorization library such as Vc. ; - Added new auto-binning algorithm, referred to as `power-2`, which uses power of 2 bin widths to create bins; that are mergeable. The target use-case is support for auto-binning in multi-process or multi-thread execution,; e.g. `TDataFrame`, without the need of a synchronization point.; The new `power-2` algorithm is activated by setting the new `TH1::kAutoBinPTwo` status bit on the histogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats classes have been updated to include the `GlobalObservables` option.; - Remove the `Roo1DMomentMorphFunction` and replace it with `RooMomentMorphFunction` and `RooMomentMorphFunctionND`. ## TMVA Library. - Improvement and fixes in ROCCurve class.; - Add support for event weights in ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:17907,power,power-,17907,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['power'],['power-']
Energy Efficiency," a header file; is rarely a source of confusion. But namespaces both anonymous and named in; source files that are being closed half way through the file probably could use; clarification. .. _static:. Anonymous Namespaces; ^^^^^^^^^^^^^^^^^^^^. After talking about namespaces in general, you may be wondering about anonymous; namespaces in particular. Anonymous namespaces are a great language feature; that tells the C++ compiler that the contents of the namespace are only visible; within the current translation unit, allowing more aggressive optimization and; eliminating the possibility of symbol name collisions. Anonymous namespaces are; to C++ as ""static"" is to C functions and global variables. While ""``static``""; is available in C++, anonymous namespaces are more general: they can make entire; classes private to a file. The problem with anonymous namespaces is that they naturally want to encourage; indentation of their body, and they reduce locality of reference: if you see a; random function definition in a C++ file, it is easy to see if it is marked; static, but seeing if it is in an anonymous namespace requires scanning a big; chunk of the file. Because of this, we have a simple guideline: make anonymous namespaces as small; as possible, and only use them for class declarations. For example:. .. code-block:: c++. namespace {; class StringSort {; ...; public:; StringSort(...); bool operator<(const char *RHS) const;; };; } // namespace. static void runHelper() {; ...; }. bool StringSort::operator<(const char *RHS) const {; ...; }. Avoid putting declarations other than classes into anonymous namespaces:. .. code-block:: c++. namespace {. // ... many declarations ... void runHelper() {; ...; }. // ... many declarations ... } // namespace. When you are looking at ""``runHelper``"" in the middle of a large C++ file,; you have no immediate way to tell if this function is local to the file. In; contrast, when the function is marked static, you don't need to cross-referenc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:60336,reduce,reduce,60336,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['reduce'],['reduce']
Energy Efficiency," a range check. At a high level, the interleaving scheme consists of three steps: 1) split virtual table groups into; separate virtual tables, 2) order virtual tables by a pre-order traversal of the class hierarchy; and 3) interleave virtual tables. The interleaving scheme implemented in LLVM is inspired by [1]_ but has its own; enhancements (more in `Interleave virtual tables`_). .. [1] `Protecting C++ Dynamic Dispatch Through VTable Interleaving <https://cseweb.ucsd.edu/~lerner/papers/ivtbl-ndss16.pdf>`_. Dimitar Bounov, Rami Gökhan Kıcı, Sorin Lerner. Split virtual table groups into separate virtual tables; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. The Itanium C++ ABI glues multiple individual virtual tables for a class into a combined virtual table (virtual table group).; The interleaving scheme, however, can only work with individual virtual tables so it must split the combined virtual tables first.; In comparison, the old scheme does not require the splitting but it is more efficient when the combined virtual tables have been split.; The `GlobalSplit`_ pass is responsible for splitting combined virtual tables into individual ones. .. _GlobalSplit: https://github.com/llvm/llvm-project/blob/main/llvm/lib/Transforms/IPO/GlobalSplit.cpp. Order virtual tables by a pre-order traversal of the class hierarchy; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. This step is common to both the old scheme described above and the interleaving scheme.; For the interleaving scheme, since the combined virtual tables have been split in the previous step,; this step ensures that for any class all the compatible virtual tables will appear consecutively.; For the old scheme, the same property may not hold since it may work on combined virtual tables. For example, consider the following four C++ classes:. .. code-block:: c++. struct A {; virtual void f1();; };. struct B : A {; virtual void f1();; virtual void f2();; };. struct C : A {; virtual voi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:11089,efficient,efficient,11089,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['efficient'],['efficient']
Energy Efficiency," a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smax``' intrinsic performs the signed-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.smax <int_vector_reduce_smax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MIN`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smax.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 -128, i8 -128, i8 -128, i8 -128>; %reduction = call i8 @llvm.vector.reduce.smax.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smax.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_smin:. '``llvm.vp.reduce.smin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:764343,reduce,reduce,764343,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smin``' intrinsic performs the signed-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.smin <int_vector_reduce_smin>`) of the; vector operand ``val`` on each enabled lane, and taking the minimum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MAX`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smin.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 127, i8 127, i8 127, i8 127>; %reduction = call i8 @llvm.vector.reduce.smin.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smin.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_umax:. '``llvm.vp.reduce.umax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The fi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:766408,reduce,reduce,766408,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," a source language type; which may apply to objects allocated in different kinds of storage. Therefore,; it is desirable that the expression that uses the address can do so without; regard to what kind of storage it specifies, including the address space of a; memory location description. For example, a pointer to member value may want to; be applied to an object that may reside in any address space. The DWARF ``DW_OP_xderef*`` operations allow a value to be converted into an; address of a specified address space which is then read. But it provides no; way to create a memory location description for an address in the non-default; address space. For example, AMDGPU variables can be allocated in the local; address space at a fixed address. The ``DW_OP_LLVM_form_aspace_address`` (see; :ref:`amdgpu-dwarf-memory-location-description-operations`) operation is defined; to create a memory location description from an address and address space. If; can be used to specify the location of a variable that is allocated in a; specific address space. This allows the size of addresses in an address space to; be larger than the generic type. It also allows a consumer great implementation; freedom. It allows the implicit conversion back to a value to be limited only to; the default address space to maintain compatibility with DWARF Version 5. For; other address spaces the producer can use the new operations that explicitly; specify the address space. In contrast, if the ``DW_OP_LLVM_form_aspace_address`` operation had been; defined to produce a value, and an implicit conversion to a memory location; description was defined, then it would be limited to the size of the generic; type (which matches the size of the default address space). An implementation; would likely have to use *reserved ranges* of value to represent different; address spaces. Such a value would likely not match any address value in the; actual hardware. That would require the consumer to have special treatment for; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:19764,allocate,allocated,19764,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['allocate'],['allocated']
Energy Efficiency," a token returned by a call to '``llvm.coro.id``'; identifying the coroutine. The second argument is a pointer to a block of memory where coroutine frame; will be stored if it is allocated dynamically. This pointer is ignored; for returned-continuation coroutines. Semantics:; """""""""""""""""""". Depending on the alignment requirements of the objects in the coroutine frame; and/or on the codegen compactness reasons the pointer returned from `coro.begin`; may be at offset to the `%mem` argument. (This could be beneficial if; instructions that express relative access to data can be more compactly encoded; with small positive and negative offsets). A frontend should emit exactly one `coro.begin` intrinsic per coroutine. .. _coro.free:. 'llvm.coro.free' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.free(token %id, ptr <frame>). Overview:; """""""""""""""""". The '``llvm.coro.free``' intrinsic returns a pointer to a block of memory where; coroutine frame is stored or `null` if this instance of a coroutine did not use; dynamically allocated memory for its coroutine frame. This intrinsic is not; supported for returned-continuation coroutines. Arguments:; """""""""""""""""""". The first argument is a token returned by a call to '``llvm.coro.id``'; identifying the coroutine. The second argument is a pointer to the coroutine frame. This should be the same; pointer that was returned by prior `coro.begin` call. Example (custom deallocation function):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %frame); %mem_not_null = icmp ne ptr %mem, null; br i1 %mem_not_null, label %if.then, label %if.end; if.then:; call void @CustomFree(ptr %mem); br label %if.end; if.end:; ret void. Example (standard deallocation functions):; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". .. code-block:: llvm. cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %frame); call void @free(ptr %mem); ret void. .. _coro.alloc:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:33661,allocate,allocated,33661,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['allocate'],['allocated']
Energy Efficiency," about the; latest release, please see the `Clang Web Site <https://clang.llvm.org>`_ or the; `LLVM Web Site <https://llvm.org>`_. Potentially Breaking Changes; ============================; These changes are ones which we think may surprise users when upgrading to; Clang |release| because of the opportunity they pose for disruption to existing; code bases. - Fix a bug in reversed argument for templated operators.; This breaks code in C++20 which was previously accepted in C++17.; Clang did not properly diagnose such casese in C++20 before this change. Eg:. .. code-block:: cpp. struct P {};; template<class S> bool operator==(const P&, const S&);. struct A : public P {};; struct B : public P {};. // This equality is now ambiguous in C++20.; bool ambiguous(A a, B b) { return a == b; }. template<class S> bool operator!=(const P&, const S&);; // Ok. Found a matching operator!=.; bool fine(A a, B b) { return a == b; }. To reduce such widespread breakages, as an extension, Clang accepts this code; with an existing warning ``-Wambiguous-reversed-operator`` warning.; Fixes `#53954 <https://github.com/llvm/llvm-project/issues/53954>`_. - The CMake variable ``GCC_INSTALL_PREFIX`` (which sets the default; ``--gcc-toolchain=``) is deprecated and will be removed. Specify; ``--gcc-install-dir=`` or ``--gcc-triple=`` in a `configuration file; <https://clang.llvm.org/docs/UsersManual.html#configuration-files>`_ as a; replacement.; (`#77537 <https://github.com/llvm/llvm-project/pull/77537>`_). C/C++ Language Potentially Breaking Changes; -------------------------------------------. - The default extension name for PCH generation (``-c -xc-header`` and ``-c; -xc++-header``) is now ``.pch`` instead of ``.gch``.; - ``-include a.h`` probing ``a.h.gch`` will now ignore ``a.h.gch`` if it is not; a clang pch file or a directory containing any clang pch file.; - Fixed a bug that caused ``__has_cpp_attribute`` and ``__has_c_attribute``; return incorrect values for some C++-11-style attributes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:2027,reduce,reduce,2027,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['reduce'],['reduce']
Energy Efficiency," alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a loa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:41320,schedul,scheduling,41320,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency," an ""emergency break"" and should prevent very compressible clusters from growing too large. Given the two settings, writing works as follows:; when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally.; When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too.; The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise.; The following clusters use the average compression ratio of all so-far written clusters as an estimate.; See the notes below on a discussion of this approximation. Page Sizes; ==========. Pages contain consecutive elements of a certain column.; They are the unit of compression and of addressability on storage.; RNTuple puts a configurable maximum uncompressed size for pages.; This limit is by default set to 1 MiB.; When the limit is reached, a page will be flushed to disk. In addition, RNTuple maintains a memory budget for the combined allocated size of the pages that are currently filled.; By default, this limit is set to twice the compressed target cluster size when compression is used,; and to the cluster target size for uncompressed data.; Initially, and after flushing, all columns use small pages,; just big enough to hold the configurable minimum number of elements (64 by default).; Page sizes are doubled as more data is filled into them.; When a page reaches the maximum page size (see above), it is flushed.; When the overall page budget is reached,; pages larger than the page at hand are flushed before the page at hand is flushed.; For the parallel writer, every fill context maintains the page memory budget independently. Note that the total amount of memory consumed for writing is usually larger than the write page budget.; For instance, if buffered writing is used (the default), additional memory is required.; Use RNTupleModel::EstimateWriteMemoryUsage() for the total estimated memory use for writing. Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:1862,allocate,allocated,1862,tree/ntuple/v7/doc/tuning.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md,1,['allocate'],['allocated']
Energy Efficiency," and `TDataSource` together with their federation of classes have been renamed according to the coding conventions for new interfaces and extracted from the `Experimental` namespace: they can now be found in the ROOT namespace and they are called `ROOT::RDataFrame` and `ROOT::RDataSource`.; - `ROOT::Experimental::TDF::TResultProxy` has been renamed to `ROOT::RDF::RResultPtr`.; - `Report` now behaves identically to all other actions: it executes lazily and returns a `RResultPtr` (see the `New features` section for more details).; - `Snapshot` now returns a `RResultPtr` like all other actions: specifically, this is a pointer to a new `RDataFrame` which will run on the snapshotted dataset.; - `RDataFrame` has been removed from tree/treeplayer and put in its own package, tree/dataframe. The library where this code can be found is `libROOTDataFrame`. This new library is included in the list provided by `root-config --libs`.; - The `TArrayBranch` class has been removed and replaced by the more powerful `RVec` (see the `New features` section for more details).; - All `RDataFrame` tutorials are now prefixed with `df` rather than `tdf`.; - Histograms and profiles returned by RDataFrame (e.g. by a Histo1D action) are now not associated to a ROOT directory (their fDirectory is a nullptr).; The following still works as expected:; ```; auto h = tdf.Histo1D(""x"");; TFile f(fname, ""RECREATE"");; h->Write(); // event loop is run here and h is written to the TFile f; ```. #### New features; - The TDataSource interface changed. The `TDataSource::SetEntry` method now returns a boolean. If true the entry is processed within the event loop managed by the tdf, skipped otherwise.; - The TLazyDS data source has been added. It allows to create a source starting from ResultProxies to vectors.; - `TDataFrameInterface<T>::Report` returns a `TCutflowReport` object which can be inspected programmatically.; - Add `Aggregate` action and implement `Reduce` in terms of it.; - Add support for a more gen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:6709,power,powerful,6709,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['power'],['powerful']
Energy Efficiency," and categorize scalar; expressions in loops. It specializes in recognizing general induction; variables, representing them with the abstract and opaque ``SCEV`` class.; Given this analysis, trip counts of loops and other important properties can be; obtained. This analysis is primarily useful for induction variable substitution and; strength reduction. ``scev-aa``: ScalarEvolution-based Alias Analysis; -------------------------------------------------. Simple alias analysis implemented in terms of ``ScalarEvolution`` queries. This differs from traditional loop dependence analysis in that it tests for; dependencies within a single iteration of a loop, rather than dependencies; between different iterations. ``ScalarEvolution`` has a more complete understanding of pointer arithmetic; than ``BasicAliasAnalysis``' collection of ad-hoc analyses. ``stack-safety``: Stack Safety Analysis; ---------------------------------------. The ``StackSafety`` analysis can be used to determine if stack allocated; variables can be considered safe from memory access bugs. This analysis' primary purpose is to be used by sanitizers to avoid unnecessary; instrumentation of safe variables. Transform Passes; ================. This section describes the LLVM Transform Passes. ``adce``: Aggressive Dead Code Elimination; ------------------------------------------. ADCE aggressively tries to eliminate code. This pass is similar to :ref:`DCE; <passes-dce>` but it assumes that values are dead until proven otherwise. This; is similar to :ref:`SCCP <passes-sccp>`, except applied to the liveness of; values. ``always-inline``: Inliner for ``always_inline`` functions; ----------------------------------------------------------. A custom inliner that handles only functions that are marked as ""always; inline"". ``argpromotion``: Promote 'by reference' arguments to scalars; -------------------------------------------------------------. This pass promotes ""by reference"" arguments to be ""by value"" arguments. I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:11522,allocate,allocated,11522,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['allocate'],['allocated']
Energy Efficiency," and stores will; result in a copy of the label of the stored value to the shadow of all; bytes stored to. Propagating labels through arguments; ------------------------------------. In order to propagate labels through function arguments and return values,; DataFlowSanitizer changes the ABI of each function in the translation unit.; There are currently two supported ABIs:. * Args -- Argument and return value labels are passed through additional; arguments and by modifying the return type. * TLS -- Argument and return value labels are passed through TLS variables; ``__dfsan_arg_tls`` and ``__dfsan_retval_tls``. The main advantage of the TLS ABI is that it is more tolerant of ABI mismatches; (TLS storage is not shared with any other form of storage, whereas extra; arguments may be stored in registers which under the native ABI are not used; for parameter passing and thus could contain arbitrary values). On the other; hand the args ABI is more efficient and allows ABI mismatches to be more easily; identified by checking for nonzero labels in nominally unlabelled programs. Implementing the ABI list; -------------------------. The `ABI list <DataFlowSanitizer.html#abi-list>`_ provides a list of functions; which conform to the native ABI, each of which is callable from an instrumented; program. This is implemented by replacing each reference to a native ABI; function with a reference to a function which uses the instrumented ABI.; Such functions are automatically-generated wrappers for the native functions.; For example, given the ABI list example provided in the user manual, the; following wrappers will be generated under the args ABI:. .. code-block:: llvm. define linkonce_odr { i8*, i16 } @""dfsw$malloc""(i64 %0, i16 %1) {; entry:; %2 = call i8* @malloc(i64 %0); %3 = insertvalue { i8*, i16 } undef, i8* %2, 0; %4 = insertvalue { i8*, i16 } %3, i16 0, 1; ret { i8*, i16 } %4; }. define linkonce_odr { i32, i16 } @""dfsw$tolower""(i32 %0, i16 %1) {; entry:; %2 = call i32 @tolow",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst:10691,efficient,efficient,10691,interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,1,['efficient'],['efficient']
Energy Efficiency," and we sort it in different ways:; ``` {.cpp}; root [0] using doubles = std::vector<double>;; root [1] auto pVec = [](const doubles& v){for (auto&& x:v) cout << x << endl;};; root [2] doubles v{0,3,5,4,1,2};; root [3] pVec(v);; 0; 3; 5; 4; 1; 2; root [4] std::sort(v.begin(),v.end());; root [5] pVec(v);; 0; 1; 2; 3; 4; 5; root [6] std::sort(v.begin(),v.end(),[](double a, double b){return a>b;});; root [7] pVec(v);; 5; 4; 3; 2; 1; 0; ```; Or, if you prefer random number generation:; ``` {.cpp}; root [0] std::default_random_engine generator;; root [1] std::normal_distribution<double> distribution(0.,1.);; root [2] distribution(generator); (std::normal_distribution<double>::result_type) -1.219658e-01; root [3] distribution(generator); (std::normal_distribution<double>::result_type) -1.086818e+00; root [4] distribution(generator); (std::normal_distribution<double>::result_type) 6.842899e-01; ```; Impressive isn't it?. ## ROOT as function plotter ##; Using one of ROOT's powerful classes, here `TF1` [^2], will allow us to; display a function of one variable, *x*. Try the following:. ``` {.cpp}; root [11] TF1 f1(""f1"",""sin(x)/x"",0.,10.);; root [12] f1.Draw();; ```. `f1` is an instance of a TF1 class, the arguments are used; in the constructor; the first one of type string is a name to be entered; in the internal ROOT memory management system, the second string type; parameter defines the function, here `sin(x)/x`, and the two parameters; of type double define the range of the variable *x*. The `Draw()`; method, here without any parameters, displays the function in a window; which should pop up after you typed the above two lines. A slightly extended version of this example is the definition of a; function with parameters, called `[0]`, `[1]` and so on in the ROOT; formula syntax. We now need a way to assign values to these parameters;; this is achieved with the method; `SetParameter(<parameter_number>,<parameter_value>)` of class `TF1`.; Here is an example:. ``` {.cpp}; roo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md:3170,power,powerful,3170,documentation/primer/ROOT_as_calculator.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md,1,['power'],['powerful']
Energy Efficiency," and; Scratch Wavefront Offset SGPR registers (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`):. 1. The low word of Flat Scratch Init is the 32-bit byte offset from; ``SH_HIDDEN_PRIVATE_BASE_VIMID`` to the base of scratch backing memory; being managed by SPI for the queue executing the kernel dispatch. This is; the same value used in the Scratch Segment Buffer V# base address. CP obtains this from the runtime. (The Scratch Segment Buffer base address; is ``SH_HIDDEN_PRIVATE_BASE_VIMID`` plus this offset.). The prolog must add the value of Scratch Wavefront Offset to get the; wavefront's byte scratch backing memory offset from; ``SH_HIDDEN_PRIVATE_BASE_VIMID``. The Scratch Wavefront Offset must also be used as an offset with Private; segment address when using the Scratch Segment Buffer. Since FLAT_SCRATCH_LO is in units of 256 bytes, the offset must be right; shifted by 8 before moving into FLAT_SCRATCH_HI. FLAT_SCRATCH_HI corresponds to SGPRn-4 on GFX7, and SGPRn-6 on GFX8 (where; SGPRn is the highest numbered SGPR allocated to the wavefront).; FLAT_SCRATCH_HI is multiplied by 256 (as it is in units of 256 bytes) and; added to ``SH_HIDDEN_PRIVATE_BASE_VIMID`` to calculate the per wavefront; FLAT SCRATCH BASE in flat memory instructions that access the scratch; aperture.; 2. The second word of Flat Scratch Init is 32-bit byte size of a single; work-items scratch memory usage. CP obtains this from the runtime, and it is always a multiple of DWORD. CP; checks that the value in the kernel dispatch packet Private Segment Byte; Size is not larger and requests the runtime to increase the queue's scratch; size if necessary. CP directly loads from the kernel dispatch packet Private Segment Byte Size; field and rounds up to a multiple of DWORD. Having CP load it once avoids; loading it at the beginning of every wavefront. The kernel prolog code must move it to FLAT_SCRATCH_LO which is SGPRn-3 on; GFX7 and SGPRn-5 on GFX8. FLAT_SCRATCH_LO is used as the FLAT SCRATCH",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:195423,allocate,allocated,195423,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency," and; ``new[]``) and three corresponding ways of deallocation (``free``,; ``delete``, and ``delete[]``).; Direct use of ``malloc`` and ``new`` should be avoided for C++ classes, as; these may override ``operator new`` to control their own allocation.; However these low-level allocators can be necessary for builtin types on; occasion if the C++ side takes ownership (otherwise, prefer either; ``array`` from the builtin module ``array`` or ``ndarray`` from Numpy). The low-level module adds the following functions:. * **ll.malloc**: an interface on top of C's malloc.; Use it as a template with the number of elements (not the number types) to; be allocated.; The result is a ``cppyy.LowLevelView`` with the proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.malloc[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. The actual C malloc can also be used directly, through ``cppyy.gbl.malloc``,; taking the number of *bytes* to be allocated and returning a ``void*``. * **ll.free**: an interface to C's free, to deallocate memory allocated by; C's malloc.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.free(arr); >>>. The actual C free can also be used directly, through ``cppyy.gbl.free``. * **ll.array_new**: an interface on top of C++'s ``new[]``.; Use it as a template; the result is a ``cppyy.LowLevelView`` with the; proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.array_new[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. * **ll.array_delete**: an interface on top of C++'s ``delete[]``.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.array_delete(arr); >>>. `argc/argv`; -----------. C/C++'s ``main`` function can take the number of command line arguments; (``argc``) and their values (``argv``) as function arguments.; A common idiom has these values subsequently passed on to the entry point ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:10247,allocate,allocated,10247,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,1,['allocate'],['allocated']
Energy Efficiency," another vector; pp2v2 = v.Perp(v1);; ```. there are two more set functions `SetPtEtaPhiE(pt,eta,phi,e)` and; `SetPtEtaPhiM(pt,eta,phi,m)` for convenience. ### Arithmetic and Comparison Operators. The **`TLorentzVector`** class provides operators to add subtract or; compare four-vectors:. ``` {.cpp}; v3 = -v1;; v1 = v2+v3;; v1+= v3;; v1 = v2 + v3;; v1-= v3;; if (v1 == v2) {...}; if (v1 != v3) {...}; ```. ### Magnitude/Invariant mass, beta, gamma, scalar product. The scalar product of two four-vectors is calculated with the; `(-,-,-,+) `metric:. **`s = v1*v2 `** `= t1*t2-x1*x2-y1*y2-z1*z2 `. The magnitude squared `mag2` of a four-vector is therefore:. **`mag2 = v*v`** ` = t*t-x*x-y*y-z*z `. If `mag2` is negative: **`mag = -Sqrt(-mag*mag)`**. The methods are:. ``` {.cpp}; Double_t s, s2;; s = v1.Dot(v2);// scalar product; s = v1*v2;// scalar product; s2 = v.Mag2();ors2 = v.M2();; s = v.Mag();s = v.M();; ```. Since in case of momentum and energy the magnitude has the meaning of; invariant mass **`TLorentzVector`** provides the more meaningful aliases; `M2()` and `M()`. The methods `Beta()` and `Gamma()` returns `beta` and; `gamma = 1/Sqrt(1-beta*beta)`. ### Lorentz Boost. A boost in a general direction can be parameterized with three; parameters which can be taken as the components of a three vector; `b=(bx,by,bz)`. With `x=(x,y,z)` and `gamma=1/Sqrt(1-beta*beta)` (beta; being the module of vector b)`,` an arbitrary active Lorentz boost; transformation (from the rod frame to the original frame) can be written; as:. `x = x' + (gamma-1)/(beta*beta)*(b*x')*b + gamma*t'*b `. `t = gamma(t'+ b*x') `. The `Boost()` method performs a boost transformation from the rod frame; to the original frame. `BoostVector()` returns a **`TVector3`** of the; spatial components divided by the time component:. ``` {.cpp}; TVector3 b;; v.Boost(bx,by,bz);; v.Boost(b);; b = v.BoostVector();// b=(x/t,y/t,z/t); ```. ### Rotations. There are four sets of functions to rotate the **`TVector3`** compon",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md:12942,energy,energy,12942,documentation/users-guide/PhysicsVectors.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md,1,['energy'],['energy']
Energy Efficiency," any; floating-point type or vector of floating-point type. Not all targets; support all types however. ::. declare i64 @llvm.llrint.i64.f32(float %Val); declare i64 @llvm.llrint.i64.f64(double %Val); declare i64 @llvm.llrint.i64.f80(float %Val); declare i64 @llvm.llrint.i64.f128(double %Val); declare i64 @llvm.llrint.i64.ppcf128(double %Val). Overview:; """""""""""""""""". The '``llvm.llrint.*``' intrinsics return the operand rounded to the nearest; integer. Arguments:; """""""""""""""""""". The argument is a floating-point number and the return value is an integer; type. Semantics:; """""""""""""""""""". This function returns the same values as the libm ``llrint`` functions; would, but without setting errno. If the rounded value is too large to; be stored in the result type, the return value is a non-deterministic; value (equivalent to `freeze poison`). Bit Manipulation Intrinsics; ---------------------------. LLVM provides intrinsics for a few important bit manipulation; operations. These allow efficient code generation for some algorithms. .. _int_bitreverse:. '``llvm.bitreverse.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic function. You can use bitreverse on any; integer type. ::. declare i16 @llvm.bitreverse.i16(i16 <id>); declare i32 @llvm.bitreverse.i32(i32 <id>); declare i64 @llvm.bitreverse.i64(i64 <id>); declare <4 x i32> @llvm.bitreverse.v4i32(<4 x i32> <id>). Overview:; """""""""""""""""". The '``llvm.bitreverse``' family of intrinsics is used to reverse the; bitpattern of an integer value or vector of integer values; for example; ``0b10110110`` becomes ``0b01101101``. Semantics:; """""""""""""""""""". The ``llvm.bitreverse.iN`` intrinsic returns an iN value that has bit; ``M`` in the input moved to bit ``N-M-1`` in the output. The vector; intrinsics, such as ``llvm.bitreverse.v4i32``, operate on a per-element; basis and the element order is not affected. .. _int_bswap:. '``llvm.bswap.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:590265,efficient,efficient,590265,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['efficient'],['efficient']
Energy Efficiency," args*. Pass all arguments specified after **--tool-args** to the LLVM tool under test; (**llc**, **lli**, etc.) whenever it runs. You should use this option in the; following way:. .. code-block:: bash. bugpoint [bugpoint args] --tool-args -- [tool args]. The ""``--``"" right after the **--tool-args** option tells **bugpoint** to; consider any options starting with ""``-``"" to be part of the **--tool-args**; option, not as options to **bugpoint** itself. (See **--args**, above.). **--safe-tool-args** *tool args*. Pass all arguments specified after **--safe-tool-args** to the ""safe"" execution; tool. **--gcc-tool-args** *gcc tool args*. Pass all arguments specified after **--gcc-tool-args** to the invocation of; **gcc**. **--opt-args** *opt args*. Pass all arguments specified after **--opt-args** to the invocation of **opt**. **--disable-{dce,simplifycfg}**. Do not run the specified passes to clean up and reduce the size of the test; program. By default, **bugpoint** uses these passes internally when attempting to; reduce test programs. If you're trying to find a bug in one of these passes,; **bugpoint** may crash. **--enable-valgrind**. Use valgrind to find faults in the optimization phase. This will allow; bugpoint to find otherwise asymptomatic problems caused by memory; mis-management. **-find-bugs**. Continually randomize the specified passes and run them on the test program; until a bug is found or the user kills **bugpoint**. **-help**. Print a summary of command line options. **--input** *filename*. Open *filename* and redirect the standard input of the test program, whenever; it runs, to come from that file. **--load** *plugin*. Load the dynamic object *plugin* into **bugpoint** itself. This object should; register new optimization passes. Once loaded, the object will add new command; line options to enable various optimizations. To see the new complete list of; optimizations, use the **-help** and **--load** options together; for example:. .. code-block:: bash",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst:2678,reduce,reduce,2678,interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,1,['reduce'],['reduce']
Energy Efficiency," argument is a pointer; to the object. Semantics:; """""""""""""""""""". If ``ptr`` is a stack-allocated object and it points to the first byte of; the object, the object is initially marked as dead.; ``ptr`` is conservatively considered as a non-stack-allocated object if; the stack coloring algorithm that is used in the optimization pipeline cannot; conclude that ``ptr`` is a stack-allocated object. After '``llvm.lifetime.start``', the stack object that ``ptr`` points is marked; as alive and has an uninitialized value.; The stack object is marked as dead when either; :ref:`llvm.lifetime.end <int_lifeend>` to the alloca is executed or the; function returns. After :ref:`llvm.lifetime.end <int_lifeend>` is called,; '``llvm.lifetime.start``' on the stack object can be called again.; The second '``llvm.lifetime.start``' call marks the object as alive, but it; does not change the address of the object. If ``ptr`` is a non-stack-allocated object, it does not point to the first; byte of the object or it is a stack object that is already alive, it simply; fills all bytes of the object with ``poison``. .. _int_lifeend:. '``llvm.lifetime.end``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.lifetime.end(i64 <size>, ptr nocapture <ptr>). Overview:; """""""""""""""""". The '``llvm.lifetime.end``' intrinsic specifies the end of a memory object's; lifetime. Arguments:; """""""""""""""""""". The first argument is a constant integer representing the size of the; object, or -1 if it is variable sized. The second argument is a pointer; to the object. Semantics:; """""""""""""""""""". If ``ptr`` is a stack-allocated object and it points to the first byte of the; object, the object is dead.; ``ptr`` is conservatively considered as a non-stack-allocated object if; the stack coloring algorithm that is used in the optimization pipeline cannot; conclude that ``ptr`` is a stack-allocated object. Calling ``llvm.lifetime.end`` on an already dead alloca is no-op. If ``ptr`` is a non-stack-all",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:862376,allocate,allocated,862376,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency," arm64 (which may be passed by Xcode 5.0), but for the time being analyzes code in such cases as -arch armv7s.; Many sundry fixes, improvements to C++ support, etc. checker-275; built: May 23, 2013; download: checker-275.tar.bz2; highlights:. Xcode: Includes a new arrow layout algorithm for issue presentation within Xcode. The goal is for interprocedural bug reports to look cleaner and less busy (and easier to read). Feedback appreciated.; Xcode: Bugs that occur within header code (e.g., C++) are now reported within the callers in the main source file. For example, if you misuse a C++ function declared in a header the primary diagnostic will be in the caller (in the main source file). The full expanded path, however, will show the bug in the header code as well. These kind of cross-file issues are currently only support by Xcode, not the HTML output.; This build is built with LLVM's Link-Time Optimization (LTO), which should make it slightly faster.; LTO also reduces the download size (about 19% smaller than checker-274).; Many sundry fixes. checker-274; built: April 23, 2013; download: checker-274.tar.bz2; highlights:. Improved use-after-free and mismatched deallocator checking.; Diagnostic polish.; Fixes crashes found in checker-273. checker-273; built: April 8, 2013; download: checker-273.tar.bz2; highlights:. Additional checks for misuse of Foundation collection APIs.; New C++ checker for attempting to create a reference to null.; New use-after-free checker for C++ 'delete'.; New checker for simple cases of mismatched allocators and deallocators, e.g. ""delete malloc(4);""; Support for basic interprocedural analysis of C++ destructors.; Additional heuristics for suppressing null pointer false positives.; Misc. bug fixes and performance enhancements. checker-272; built: March 1, 2013; highlights:. Better modeling of C++ constructors:; ; Interprocedural analysis support for constructors of types with trivial destructors; Efficient model of trivial copy and move cons",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:4323,reduce,reduces,4323,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,1,['reduce'],['reduces']
Energy Efficiency," as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1->Clone(0);; for (Int_t i = 0; i < 10; ++i) {; t1->GetEntry(i);; t2->Fill();; }; t2->Write(); delete f2;; f2 = 0;; delete f1;; f1 = 0;. An example of a branch with an object allocated by us,; but owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = 0;; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. Notice that the only difference between this example; and the following example is that the event pointer; is zero when the branch is created. An example of a branch with an object allocated and; owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = new Event();; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. TTreeFormula (TTree::Draw, TTree::Scan). Fix CollectionTree->Scan(""reco_ee_et[][2]:reco_ee_et[0][2]""); where reco_ee_et is a vector<vector<double> > See http://root.cern/phpBB2/viewtopic.php?t=6536; Insure that the formula that are used as indices or as argument to special functions have their branch(es) loaded once. This fixes http://root.cern/phpBB2/viewtopic.php?p=27080#27080; Correct the drawing of ""X[1]:X[5]"" when X is a vector< vector<float> >; and X[1].size()!=X[5].size(). (reported at http://root.cern/phpBB2/viewtopic.php?p=27070); Correct the passing of NaN to function being called by TTree::Draw. Splitting STL col",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:2841,allocate,allocated,2841,tree/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html,1,['allocate'],['allocated']
Energy Efficiency," automatically freed at this point */; }. **Description**:. ``__builtin_alloca`` is meant to be used to allocate a dynamic amount of memory; on the stack. This amount is subject to stack allocation limits. Query for this feature with ``__has_builtin(__builtin_alloca)``. ``__builtin_alloca_with_align``; -------------------------------. ``__builtin_alloca_with_align`` is used to dynamically allocate memory on the; stack while controlling its alignment. Memory is automatically freed upon; function termination. **Syntax**:. .. code-block:: c++. __builtin_alloca_with_align(size_t n, size_t align). **Example of Use**:. .. code-block:: c++. void init(float* data, size_t nbelems);; void process(float* data, size_t nbelems);; int foo(size_t n) {; auto mem = (float*)__builtin_alloca_with_align(; n * sizeof(float),; CHAR_BIT * alignof(float));; init(mem, n);; process(mem, n);; /* mem is automatically freed at this point */; }. **Description**:. ``__builtin_alloca_with_align`` is meant to be used to allocate a dynamic amount of memory; on the stack. It is similar to ``__builtin_alloca`` but accepts a second; argument whose value is the alignment constraint, as a power of 2 in *bits*. Query for this feature with ``__has_builtin(__builtin_alloca_with_align)``. .. _langext-__builtin_assume:. ``__builtin_assume``; --------------------. ``__builtin_assume`` is used to provide the optimizer with a boolean; invariant that is defined to be true. **Syntax**:. .. code-block:: c++. __builtin_assume(bool). **Example of Use**:. .. code-block:: c++. int foo(int x) {; __builtin_assume(x != 0);; // The optimizer may short-circuit this check using the invariant.; if (x == 0); return do_something();; return do_something_else();; }. **Description**:. The boolean argument to this function is defined to be true. The optimizer may; analyze the form of the expression provided as the argument and deduce from; that information used to optimize the program. If the condition is violated; during execution",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:98330,allocate,allocate,98330,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['allocate'],['allocate']
Energy Efficiency," be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umax``' intrinsic performs the unsigned-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.umax <int_vector_reduce_umax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``0`` (i.e. having no effect on the reduction operation). If the; vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umax.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umax.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_umin:. '``llvm.vp.reduce.umin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """"""""""""""""""""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:768468,reduce,reduce,768468,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," be equal to ``start_value``. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fadd; <int_vector_reduce_fadd>`) for more detail on the semantics of the reduction. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fadd.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float -0.0, float -0.0, float -0.0, float -0.0>; %also.r = call float @llvm.vector.reduce.fadd.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_mul:. '``llvm.vp.reduce.mul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.mul.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.mul.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``MUL`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.mul``' intrinsic performs the integer ``MUL`` reduction; (:ref:`llvm.vector.reduce.mul <int_vector_reduce_mul>`) of the vector operand ``val``; on each enabled lane, multiplying it by the scalar ``start_value``. Disabl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:752733,reduce,reduce,752733,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," before every pass. Be warned that this is very verbose. .. _backend-crash:. Backend code generator bugs; ---------------------------. If you find a bug that crashes clang in the code generator, compile your; source file to a .bc file by passing ""``-emit-llvm -c -o foo.bc``"" to; clang (in addition to the options you already pass). Once your have; foo.bc, one of the following commands should fail:. #. ``llc foo.bc``; #. ``llc foo.bc -relocation-model=pic``; #. ``llc foo.bc -relocation-model=static``. If none of these crash, please follow the instructions for a :ref:`front-end; bug<frontend-crash>`. If one of these do crash, you should be able to reduce; this with one of the following :doc:`bugpoint <Bugpoint>` command lines (use; the one corresponding to the command above that failed):. #. ``bugpoint -run-llc foo.bc``; #. ``bugpoint -run-llc foo.bc --tool-args -relocation-model=pic``; #. ``bugpoint -run-llc foo.bc --tool-args -relocation-model=static``. Please run this, then file a bug with the instructions and reduced .bc file; that bugpoint emits. If something goes wrong with bugpoint, please submit; the ""foo.bc"" file and the option that llc crashes with. LTO bugs; ---------------------------. If you encounter a bug that leads to crashes in the LLVM LTO phase when using; the ``-flto`` option, follow these steps to diagnose and report the issue:. Compile your source file to a ``.bc`` (Bitcode) file with the following options,; in addition to your existing compilation options:. .. code-block:: bash. export CFLAGS=""-flto -fuse-ld=lld"" CXXFLAGS=""-flto -fuse-ld=lld"" LDFLAGS=""-Wl,-plugin-opt=save-temps"". These options enable LTO and save temporary files generated during compilation; for later analysis. On Windows, you should be using lld-link as the linker. Adjust your compilation ; flags as follows:; * Add ``/lldsavetemps`` to the linker flags.; * When linking from the compiler driver, add ``/link /lldsavetemps`` in order to forward that flag to the linker. Using the spe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:5829,reduce,reduced,5829,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduced']
Energy Efficiency," being in-bounds of a deallocated; object is sufficient.; * If the type of an index is larger than the pointer index type, the; truncation to the pointer index type preserves the signed value.; * The multiplication of an index by the type size does not wrap the pointer; index type in a signed sense (``nsw``).; * The successive addition of each offset (without adding the base address) does; not wrap the pointer index type in a signed sense (``nsw``).; * The successive addition of the current address, interpreted as an unsigned; number, and each offset, interpreted as a signed number, does not wrap the; unsigned address space and remains *in bounds* of the allocated object.; As a corollary, if the added offset is non-negative, the addition does not; wrap in an unsigned sense (``nuw``).; * In cases where the base is a vector of pointers, the ``inbounds`` keyword; applies to each of the computations element-wise. Note that ``getelementptr`` with all-zero indices is always considered to be; ``inbounds``, even if the base pointer does not point to an allocated object.; As a corollary, the only pointer in bounds of the null pointer in the default; address space is the null pointer itself. These rules are based on the assumption that no allocated object may cross; the unsigned address space boundary, and no allocated object may be larger; than half the pointer index type space. If the ``inrange`` keyword is present before any index, loading from or; storing to any pointer derived from the ``getelementptr`` has undefined; behavior if the load or store would access memory outside of the bounds of; the element selected by the index marked as ``inrange``. The result of a; pointer comparison or ``ptrtoint`` (including ``ptrtoint``-like operations; involving memory) involving a pointer derived from a ``getelementptr`` with; the ``inrange`` keyword is undefined, with the exception of comparisons; in the case where both operands are in the range of the element selected; by the ``in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:438525,allocate,allocated,438525,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency," both left and right *GEPs*, then compare it as; numbers, and return comparison result. Otherwise treat it like a regular operation (see previous paragraph). cmpOperation; ------------; Compares instruction opcodes and some important operation properties. 1. Compare opcodes, if it differs return the result. 2. Compare number of operands. If it differs – return the result. 3. Compare operation types, use *cmpType*. All the same – if types are; different, return result. 4. Compare *subclassOptionalData*, get it with ``getRawSubclassOptionalData``; method, and compare it like a numbers. 5. Compare operand types. 6. For some particular instructions, check equivalence (relation in our case) of; some significant attributes. For example, we have to compare alignment for; ``load`` instructions. O(log(N)); ---------; Methods described above implement order relationship. And latter, could be used; for nodes comparison in a binary tree. So we can organize functions set into; the binary tree and reduce the cost of lookup procedure from; O(N*N) to O(log(N)). Merging process, mergeTwoFunctions; ==================================; Once *MergeFunctions* detected that current function (*G*) is equal to one that; were analyzed before (function *F*) it calls ``mergeTwoFunctions(Function*,; Function*)``. Operation affects ``FnTree`` contents with next way: *F* will stay in; ``FnTree``. *G* being equal to *F* will not be added to ``FnTree``. Calls of; *G* would be replaced with something else. It changes bodies of callers. So,; functions that calls *G* would be put into ``Deferred`` set and removed from; ``FnTree``, and analyzed again. The approach is next:. 1. Most wished case: when we can use alias and both of *F* and *G* are weak. We; make both of them with aliases to the third strong function *H*. Actually *H*; is *F*. See below how it's made (but it's better to look straight into the; source code). Well, this is a case when we can just replace *G* with *F*; everywhere, we use ``rep",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst:25946,reduce,reduce,25946,interpreter/llvm-project/llvm/docs/MergeFunctions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst,1,['reduce'],['reduce']
Energy Efficiency," buffer.; }. More details at the corresponding `GitHub issue <https://github.com/llvm/llvm-project/issues/43459>`_. .. _alpha-nondeterminism-PointerIteration:. alpha.nondeterminism.PointerIteration (C++); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for non-determinism caused by iterating unordered containers of pointers. .. code-block:: c. void test() {; int a = 1, b = 2;; std::unordered_set<int *> UnorderedPtrSet = {&a, &b};. for (auto i : UnorderedPtrSet) // warn; f(i);; }. .. _alpha-nondeterminism-PointerSorting:. alpha.nondeterminism.PointerSorting (C++); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for non-determinism caused by sorting of pointers. .. code-block:: c. void test() {; int a = 1, b = 2;; std::vector<int *> V = {&a, &b};; std::sort(V.begin(), V.end()); // warn; }. alpha.WebKit; ^^^^^^^^^^^^. .. _alpha-webkit-UncountedCallArgsChecker:. alpha.webkit.UncountedCallArgsChecker; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; The goal of this rule is to make sure that lifetime of any dynamically allocated ref-countable object passed as a call argument spans past the end of the call. This applies to call to any function, method, lambda, function pointer or functor. Ref-countable types aren't supposed to be allocated on stack so we check arguments for parameters of raw pointers and references to uncounted types. Here are some examples of situations that we warn about as they *might* be potentially unsafe. The logic is that either we're able to guarantee that an argument is safe or it's considered if not a bug then bug-prone. .. code-block:: cpp. RefCountable* provide_uncounted();; void consume(RefCountable*);. // In these cases we can't make sure callee won't directly or indirectly call `deref()` on the argument which could make it unsafe from such point until the end of the call. void foo1() {; consume(provide_uncounted()); // warn; }. void foo2() {; RefCountable* uncounted = provide_uncounted();; consume(uncounted); // warn; }. Although we are enforcing",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:81023,allocate,allocated,81023,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['allocate'],['allocated']
Energy Efficiency," but can use; ``.llvm.lto`` sections when passed the correct command line options. .. _encoding of LLVM IR:. LLVM IR Encoding; ================. LLVM IR is encoded into a bitstream by defining blocks and records. It uses; blocks for things like constant pools, functions, symbol tables, etc. It uses; records for things like instructions, global variable descriptors, type; descriptions, etc. This document does not describe the set of abbreviations; that the writer uses, as these are fully self-described in the file, and the; reader is not allowed to build in any knowledge of this. Basics; ------. LLVM IR Magic Number; ^^^^^^^^^^^^^^^^^^^^. The magic number for LLVM IR files is:. :raw-html:`<tt><blockquote>`; ['B'\ :sub:`8`, 'C'\ :sub:`8`, 0x0\ :sub:`4`, 0xC\ :sub:`4`, 0xE\ :sub:`4`, 0xD\ :sub:`4`]; :raw-html:`</blockquote></tt>`. .. _Signed VBRs:. Signed VBRs; ^^^^^^^^^^^. `Variable Width Integer`_ encoding is an efficient way to encode arbitrary sized; unsigned values, but is an extremely inefficient for encoding signed values, as; signed values are otherwise treated as maximally large unsigned values. As such, signed VBR values of a specific width are emitted as follows:. * Positive values are emitted as VBRs of the specified width, but with their; value shifted left by one. * Negative values are emitted as VBRs of the specified width, but the negated; value is shifted left by one, and the low bit is set. With this encoding, small positive and small negative values can both be emitted; efficiently. Signed VBR encoding is used in ``CST_CODE_INTEGER`` and; ``CST_CODE_WIDE_INTEGER`` records within ``CONSTANTS_BLOCK`` blocks.; It is also used for phi instruction operands in `MODULE_CODE_VERSION`_ 1. LLVM IR Blocks; ^^^^^^^^^^^^^^. LLVM IR is defined with the following blocks:. * 8 --- `MODULE_BLOCK`_ --- This is the top-level block that contains the entire; module, and describes a variety of per-module information. * 9 --- `PARAMATTR_BLOCK`_ --- This enumerates the param",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:20791,efficient,efficient,20791,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,1,['efficient'],['efficient']
Energy Efficiency," can pass through all pointer types.; The addresses will be adjusted internally by cppyy. Note that ``ctypes.c_char_p`` is expected to be a NULL-terminated C string,; not a character array (see the `ctypes module`_ documentation), and that; ``ctypes.c_bool`` is a C ``_Bool`` type, not C++ ``bool``. `Memory`; --------. C++ has three ways of allocating heap memory (``malloc``, ``new``, and; ``new[]``) and three corresponding ways of deallocation (``free``,; ``delete``, and ``delete[]``).; Direct use of ``malloc`` and ``new`` should be avoided for C++ classes, as; these may override ``operator new`` to control their own allocation.; However these low-level allocators can be necessary for builtin types on; occasion if the C++ side takes ownership (otherwise, prefer either; ``array`` from the builtin module ``array`` or ``ndarray`` from Numpy). The low-level module adds the following functions:. * **ll.malloc**: an interface on top of C's malloc.; Use it as a template with the number of elements (not the number types) to; be allocated.; The result is a ``cppyy.LowLevelView`` with the proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.malloc[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. The actual C malloc can also be used directly, through ``cppyy.gbl.malloc``,; taking the number of *bytes* to be allocated and returning a ``void*``. * **ll.free**: an interface to C's free, to deallocate memory allocated by; C's malloc.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.free(arr); >>>. The actual C free can also be used directly, through ``cppyy.gbl.free``. * **ll.array_new**: an interface on top of C++'s ``new[]``.; Use it as a template; the result is a ``cppyy.LowLevelView`` with the; proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.array_new[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. * **ll.arr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:9892,allocate,allocated,9892,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,1,['allocate'],['allocated']
Energy Efficiency," changing PSTATE.SM the execution of FP/vector operations may be transferred; to another processing element. This has three important implications:. * The runtime SVE vector length may change. * The contents of FP/AdvSIMD/SVE registers are zeroed. * The set of allowable instructions changes. This leads to certain restrictions on IR and optimizations. For example, it; is undefined behaviour to share vector-length dependent state between functions; that may operate with different values for PSTATE.SM. Front-ends must honour; these restrictions when generating LLVM IR. Even though the runtime SVE vector length may change, for the purpose of LLVM IR; and almost all parts of CodeGen we can assume that the runtime value for; ``vscale`` does not. If we let the compiler insert the appropriate ``smstart``; and ``smstop`` instructions around call boundaries, then the effects on SVE; state can be mitigated. By limiting the state changes to a very brief window; around the call we can control how the operations are scheduled and how live; values remain preserved between state transitions. In order to control PSTATE.SM at this level of granularity, we use function and; callsite attributes rather than intrinsics. Restrictions on attributes; --------------------------. * It is undefined behaviour to pass or return (pointers to) scalable vector; objects to/from functions which may use a different SVE vector length.; This includes functions with a non-streaming interface, but marked with; ``aarch64_pstate_sm_body``. * It is not allowed for a function to be decorated with both; ``aarch64_pstate_sm_compatible`` and ``aarch64_pstate_sm_enabled``. * It is not allowed for a function to be decorated with both; ``aarch64_pstate_za_new`` and ``aarch64_pstate_za_preserved``. * It is not allowed for a function to be decorated with both; ``aarch64_pstate_za_new`` and ``aarch64_pstate_za_shared``. These restrictions also apply in the higher level SME ACLE, which means we can; emit diagnostics in ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst:2837,schedul,scheduled,2837,interpreter/llvm-project/llvm/docs/AArch64SME.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst,1,['schedul'],['scheduled']
Energy Efficiency," code can call MakeStruct(). Unfortunately, this idiom isn't compatible with nvcc, because it doesn't allow; you to overload based on the H/D attributes. Here's an idiom that works with; both clang and nvcc:. .. code-block:: c++. struct HostS { ... };; struct DeviceS { ... };. #ifdef __NVCC__; #ifndef __CUDA_ARCH__; __host__ HostS MakeStruct() { return HostS(); }; #else; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif; #else; __host__ HostS MakeStruct() { return HostS(); }; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif. // Now host and device code can call MakeStruct(). Hopefully you don't have to do this sort of thing often. Optimizations; =============. Modern CPUs and GPUs are architecturally quite different, so code that's fast; on a CPU isn't necessarily fast on a GPU. We've made a number of changes to; LLVM to make it generate good GPU code. Among these changes are:. * `Straight-line scalar optimizations <https://goo.gl/4Rb9As>`_ -- These; reduce redundancy within straight-line code. * `Aggressive speculative execution; <https://llvm.org/docs/doxygen/html/SpeculativeExecution_8cpp_source.html>`_; -- This is mainly for promoting straight-line scalar optimizations, which are; most effective on code along dominator paths. * `Memory space inference; <https://llvm.org/doxygen/NVPTXInferAddressSpaces_8cpp_source.html>`_ --; In PTX, we can operate on pointers that are in a particular ""address space""; (global, shared, constant, or local), or we can operate on pointers in the; ""generic"" address space, which can point to anything. Operations in a; non-generic address space are faster, but pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend. 64-bit integer divides are much slower than 32-bit ones on ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:18487,reduce,reduce,18487,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,1,['reduce'],['reduce']
Energy Efficiency," combined; together. Within a selection, ranges along the same axis are combined with; logical OR, and ranges on different axes with logical AND. A selection is; displayed on top of the complete data set using its own color. Only the; events fulfilling the selection criteria (ranges) are displayed. Ranges; are defined interactively using cursors, like on the first axis on the; figure. Several selections can be defined at the same time,; each selection having its own color. ![Selections are set of ranges which can be defined interactively.](pictures/para7.png). Several selections can been defined. Each cluster is now clearly visible; and the zone with crossing clusters is now understandable whereas,; without any selection or with only a single one, it was not easy to; understand. ![Several selections can be defined each of them having its own color.](pictures/para8.png). Interactive selections on Parallel Coordinates are a powerful tool because; they can be defined graphically on many variables (graphical cuts in ROOT can; be defined on two variables only) which allow a very accurate events; filtering. Selections allow making precise events choices: a single outlying; event is clearly visible when the lines are displayed as “solid” therefore; it is easy to make cuts in order to eliminate one single event from a; selection. Such selection (to filter one single event) on a scatter plot; would be much more difficult. ![Selections allow to easily filter one single event.](pictures/para9.png). Once a selection has been defined, it is possible to use it to generate a; `TEntryList` which is applied on the tree and used at drawing time. In our; example the selection we defined allows to select exactly the two; correlated “random spheres”. ![Output of `nt->Draw(“x:y:z”)` and `nt->Draw(“u:v:w”)` after applying the selection.](pictures/para10.png). Another technique has been implemented in order to show clusters when; the picture is cluttered. A weight is assigned to each event",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:101341,power,powerful,101341,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['power'],['powerful']
Energy Efficiency," command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, two instructions were retired during the; same cycle 399 times (65.4%) and there were 109 cycles where no instructions; were retired. The retire statistics are displayed by using the command option; ``-all-stats`` or ``-retire-stats``. The last table presented is *Register File statistics*. Each physical register; file (PRF) used by the pipeline is presented in this tabl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31900,schedul,scheduler,31900,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency," config takes ~2 hours, you'll; need something on the order of 20-30 workers. The rest of this section; focuses on how to reduce cycle times. Restrict what you build and test; Think hard about why you're setting up a bot, and restrict your build; configuration as much as you can. Basic functionality is probably; already covered by other bots, and you don't need to duplicate that; testing. You only need to be building and testing the *unique* parts; of the configuration. (e.g. For a multi-stage clang builder, you probably; don't need to be enabling every target or building all the various utilities.). It can sometimes be worthwhile splitting a single builder into two or more,; if you have multiple distinct purposes for the same builder. As an example,; if you want to both a) confirm that all of LLVM builds with your host; compiler, and b) want to do a multi-stage clang build on your target, you; may be better off with two separate bots. Splitting increases resource; consumption, but makes it easy for each bot to keep up with commit flow.; Additionally, splitting bots may assist in triage by narrowing attention to; relevant parts of the failing configuration. In general, we recommend Release build types with Assertions enabled. This; generally provides a good balance between build times and bug detection for; most buildbots. There may be room for including some debug info (e.g. with; `-gmlt`), but in general the balance between debug info quality and build; times is a delicate one. Use Ninja & LLD; Ninja really does help build times over Make, particularly for highly; parallel builds. LLD helps to reduce both link times and memory usage; during linking significantly. With a build machine with sufficient; parallelism, link times tend to dominate critical path of the build, and are; thus worth optimizing. Use CCache and NOT incremental builds; Using ccache materially improves average build times. Incremental builds; can be slightly faster, but introduce the risk of build",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:10193,consumption,consumption,10193,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['consumption'],['consumption']
Energy Efficiency," consumed by instructions.; It delegates the management of processor resource units and resource groups to a; resource manager. The resource manager is responsible for selecting resource; units that are consumed by instructions. For example, if an instruction; consumes 1cy of a resource group, the resource manager selects one of the; available units from the group; by default, the resource manager uses a; round-robin selector to guarantee that resource usage is uniformly distributed; between all units of a group. :program:`llvm-mca`'s scheduler internally groups instructions into three sets:. * WaitSet: a set of instructions whose operands are not ready.; * ReadySet: a set of instructions ready to execute.; * IssuedSet: a set of instructions executing. Depending on the operands availability, instructions that are dispatched to the; scheduler are either placed into the WaitSet or into the ReadySet. Every cycle, the scheduler checks if instructions can be moved from the WaitSet; to the ReadySet, and if instructions from the ReadySet can be issued to the; underlying pipelines. The algorithm prioritizes older instructions over younger; instructions. Write-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculati",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:38357,schedul,scheduler,38357,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency," control compilation; and installation of the library. Activities other than copying, distribution and modification are not; covered by this License; they are outside its scope. The act of; running a program using the Library is not restricted, and output from; such a program is covered only if its contents constitute a work based; on the Library (independent of the use of the Library in a tool for; writing it). Whether that is true depends on what the Library does; and what the program that uses the Library does. 1. You may copy and distribute verbatim copies of the Library's; complete source code as you receive it, in any medium, provided that; you conspicuously and appropriately publish on each copy an; appropriate copyright notice and disclaimer of warranty; keep intact; all the notices that refer to this License and to the absence of any; warranty; and distribute a copy of this License along with the; Library. You may charge a fee for the physical act of transferring a copy,; and you may at your option offer warranty protection in exchange for a; fee. 2. You may modify your copy or copies of the Library or any portion; of it, thus forming a work based on the Library, and copy and; distribute such modifications or work under the terms of Section 1; above, provided that you also meet all of these conditions:. a) The modified work must itself be a software library. b) You must cause the files modified to carry prominent notices; stating that you changed the files and the date of any change. c) You must cause the whole of the work to be licensed at no; charge to all third parties under the terms of this License. d) If a facility in the modified Library refers to a function or a; table of data to be supplied by an application program that uses; the facility, other than as an argument passed when the facility; is invoked, then you must make a good faith effort to ensure that,; in the event an application does not supply such function or; table, the facility still ope",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/LICENSE.TXT:10499,charge,charge,10499,interpreter/cling/LICENSE.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/LICENSE.TXT,1,['charge'],['charge']
Energy Efficiency," controls whether or not the atomic operation is ordered with respect to the; whole system, the current device, an OpenCL workgroup, wavefront, or just a; single thread. If these are used on a target that does not support atomic; scopes, then they will behave exactly as the standard GNU atomic builtins. Low-level ARM exclusive memory builtins; ---------------------------------------. Clang provides overloaded builtins giving direct access to the three key ARM; instructions for implementing atomic operations. .. code-block:: c. T __builtin_arm_ldrex(const volatile T *addr);; T __builtin_arm_ldaex(const volatile T *addr);; int __builtin_arm_strex(T val, volatile T *addr);; int __builtin_arm_stlex(T val, volatile T *addr);; void __builtin_arm_clrex(void);. The types ``T`` currently supported are:. * Integer types with width at most 64 bits (or 128 bits on AArch64).; * Floating-point types; * Pointer types. Note that the compiler does not guarantee it will not insert stores which clear; the exclusive monitor in between an ``ldrex`` type operation and its paired; ``strex``. In practice this is only usually a risk when the extra store is on; the same cache line as the variable being modified and Clang will only insert; stack stores on its own, so it is best not to use these operations on variables; with automatic storage duration. Also, loads and stores may be implicit in code written between the ``ldrex`` and; ``strex``. Clang will not necessarily mitigate the effects of these either, so; care should be exercised. For these reasons the higher level atomic primitives should be preferred where; possible. Non-temporal load/store builtins; --------------------------------. Clang provides overloaded builtins allowing generation of non-temporal memory; accesses. .. code-block:: c. T __builtin_nontemporal_load(T *addr);; void __builtin_nontemporal_store(T value, T *addr);. The types ``T`` currently supported are:. * Integer types.; * Floating-point types.; * Vector types. Note t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:144118,monitor,monitor,144118,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['monitor'],['monitor']
Energy Efficiency," count is specified by ``interleave_count(_value_)``, where; _value_ is a positive integer. This is useful for specifying the optimal; width/count of the set of target architectures supported by your application. .. code-block:: c++. #pragma clang loop vectorize_width(2); #pragma clang loop interleave_count(2); for(...) {; ...; }. Specifying a width/count of 1 disables the optimization, and is equivalent to; ``vectorize(disable)`` or ``interleave(disable)``. Vector predication is enabled by ``vectorize_predicate(enable)``, for example:. .. code-block:: c++. #pragma clang loop vectorize(enable); #pragma clang loop vectorize_predicate(enable); for(...) {; ...; }. This predicates (masks) all instructions in the loop, which allows the scalar; remainder loop (the tail) to be folded into the main vectorized loop. This; might be more efficient when vector predication is efficiently supported by the; target platform. Loop Unrolling; --------------. Unrolling a loop reduces the loop control overhead and exposes more; opportunities for ILP. Loops can be fully or partially unrolled. Full unrolling; eliminates the loop and replaces it with an enumerated sequence of loop; iterations. Full unrolling is only possible if the loop trip count is known at; compile time. Partial unrolling replicates the loop body within the loop and; reduces the trip count. If ``unroll(enable)`` is specified the unroller will attempt to fully unroll the; loop if the trip count is known at compile time. If the fully unrolled code size; is greater than an internal limit the loop will be partially unrolled up to this; limit. If the trip count is not known at compile time the loop will be partially; unrolled with a heuristically chosen unroll factor. .. code-block:: c++. #pragma clang loop unroll(enable); for(...) {; ...; }. If ``unroll(full)`` is specified the unroller will attempt to fully unroll the; loop if the trip count is known at compile time identically to; ``unroll(enable)``. However, with ``unro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:166053,reduce,reduces,166053,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['reduce'],['reduces']
Energy Efficiency," current graph attributes, then you can; ``call DAG.clearGraphAttrs()``. Note that graph visualization features are compiled out of Release builds to; reduce file size. This means that you need a Debug+Asserts or Release+Asserts; build to use these features. .. _datastructure:. Picking the Right Data Structure for a Task; ===========================================. LLVM has a plethora of data structures in the ``llvm/ADT/`` directory, and we; commonly use STL data structures. This section describes the trade-offs you; should consider when you pick one. The first step is a choose your own adventure: do you want a sequential; container, a set-like container, or a map-like container? The most important; thing when choosing a container is the algorithmic properties of how you plan to; access the container. Based on that, you should use:. * a :ref:`map-like <ds_map>` container if you need efficient look-up of a; value based on another value. Map-like containers also support efficient; queries for containment (whether a key is in the map). Map-like containers; generally do not support efficient reverse mapping (values to keys). If you; need that, use two maps. Some map-like containers also support efficient; iteration through the keys in sorted order. Map-like containers are the most; expensive sort, only use them if you need one of these capabilities. * a :ref:`set-like <ds_set>` container if you need to put a bunch of stuff into; a container that automatically eliminates duplicates. Some set-like; containers support efficient iteration through the elements in sorted order.; Set-like containers are more expensive than sequential containers. * a :ref:`sequential <ds_sequential>` container provides the most efficient way; to add elements and keeps track of the order they are added to the collection.; They permit duplicates and support efficient iteration, but do not support; efficient look-up based on a key. * a :ref:`string <ds_string>` container is a specialized sequenti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:55480,efficient,efficient,55480,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency," debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation, then reduce the portion of the test; program which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:4550,reduce,reduce,4550,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,2,['reduce'],['reduce']
Energy Efficiency," declare i32 @llvm.vp.reduce.add.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.add.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``ADD`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.add``' intrinsic performs the integer ``ADD`` reduction; (:ref:`llvm.vector.reduce.add <int_vector_reduce_add>`) of the vector operand; ``val`` on each enabled lane, adding it to the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``0`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is equal; to ``start_value``. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.add.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> zeroinitializer; %reduction = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %masked.a); %also.r = add i32 %reduction, %start. .. _int_vp_reduce_fadd:. '``llvm.vp.reduce.fadd.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:749392,reduce,reduce,749392,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," declare i32 @llvm.vp.reduce.and.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.and.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``AND`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.and``' intrinsic performs the integer ``AND`` reduction; (:ref:`llvm.vector.reduce.and <int_vector_reduce_and>`) of the vector operand; ``val`` on each enabled lane, performing an '``and``' of that with with the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.and.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %masked.a); %also.r = and i32 %reduction, %start. .. _int_vp_reduce_or:. '``llvm.vp.reduce.or.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:757792,reduce,reduce,757792,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," declare i32 @llvm.vp.reduce.mul.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.mul.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``MUL`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.mul``' intrinsic performs the integer ``MUL`` reduction; (:ref:`llvm.vector.reduce.mul <int_vector_reduce_mul>`) of the vector operand ``val``; on each enabled lane, multiplying it by the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``1`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is the; start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.mul.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 1, i32 1, i32 1, i32 1>; %reduction = call i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %masked.a); %also.r = mul i32 %reduction, %start. .. _int_vp_reduce_fmul:. '``llvm.vp.reduce.fmul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:753595,reduce,reduce,753595,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," declare i32 @llvm.vp.reduce.xor.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.xor.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``XOR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.xor``' intrinsic performs the integer ``XOR`` reduction; (:ref:`llvm.vector.reduce.xor <int_vector_reduce_xor>`) of the vector operand; ``val`` on each enabled lane, performing an '``xor``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.xor.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %masked.a); %also.r = xor i32 %reduction, %start. .. _int_vp_reduce_smax:. '``llvm.vp.reduce.smax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overlo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:761840,reduce,reduce,761840,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," default. .. option:: -register-file-stats. Enable register file usage statistics. .. option:: -dispatch-stats. Enable extra dispatch statistics. This view collects and analyzes instruction; dispatch events, as well as static/dynamic dispatch stall events. This view; is disabled by default. .. option:: -scheduler-stats. Enable extra scheduler statistics. This view collects and analyzes instruction; issue events. This view is disabled by default. .. option:: -retire-stats. Enable extra retire control unit statistics. This view is disabled by default. .. option:: -instruction-info. Enable the instruction info view. This is enabled by default. .. option:: -show-encoding. Enable the printing of instruction encodings within the instruction info view. .. option:: -show-barriers. Enable the printing of LoadBarrier and StoreBarrier flags within the; instruction info view. .. option:: -all-stats. Print all hardware statistics. This enables extra statistics related to the; dispatch logic, the hardware schedulers, the register file(s), and the retire; control unit. This option is disabled by default. .. option:: -all-views. Enable all the view. .. option:: -instruction-tables. Prints resource pressure information based on the static information; available from the processor model. This differs from the resource pressure; view because it doesn't require that the code is simulated. It instead prints; the theoretical uniform distribution of resource pressure for every; instruction in sequence. .. option:: -bottleneck-analysis. Print information about bottlenecks that affect the throughput. This analysis; can be expensive, and it is disabled by default. Bottlenecks are highlighted; in the summary view. Bottleneck analysis is currently not supported for; processors with an in-order backend. .. option:: -json. Print the requested views in valid JSON format. The instructions and the; processor resources are printed as members of special top level JSON objects.; The individual views re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:6183,schedul,schedulers,6183,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['schedulers']
Energy Efficiency," diagnostics from Clang's; `static analyzer <https://clang-analyzer.llvm.org>`_ can also be; influenced by the user via changes to the source code. See the available; `annotations <https://clang-analyzer.llvm.org/annotations.html>`_ and the; analyzer's `FAQ; page <https://clang-analyzer.llvm.org/faq.html#exclude_code>`_ for more; information. .. _usersmanual-precompiled-headers:. Precompiled Headers; -------------------. `Precompiled headers <https://en.wikipedia.org/wiki/Precompiled_header>`_; are a general approach employed by many compilers to reduce compilation; time. The underlying motivation of the approach is that it is common for; the same (and often large) header files to be included by multiple; source files. Consequently, compile times can often be greatly improved; by caching some of the (redundant) work done by a compiler to process; headers. Precompiled header files, which represent one of many ways to; implement this optimization, are literally files that represent an; on-disk cache that contains the vital information necessary to reduce; some of the work needed to process a corresponding header file. While; details of precompiled headers vary between compilers, precompiled; headers have been shown to be highly effective at speeding up program; compilation on systems with very large system headers (e.g., macOS). Generating a PCH File; ^^^^^^^^^^^^^^^^^^^^^. To generate a PCH file using Clang, one invokes Clang with the; `-x <language>-header` option. This mirrors the interface in GCC; for generating PCH files:. .. code-block:: console. $ gcc -x c-header test.h -o test.h.gch; $ clang -x c-header test.h -o test.h.pch. Using a PCH File; ^^^^^^^^^^^^^^^^. A PCH file can then be used as a prefix header when a ``-include-pch``; option is passed to ``clang``:. .. code-block:: console. $ clang -include-pch test.h.pch test.c -o test. The ``clang`` driver will check if the PCH file ``test.h.pch`` is; available; if so, the contents of ``test.h`` (and the files i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:46302,reduce,reduce,46302,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['reduce'],['reduce']
Energy Efficiency," does now. This; would lead to a pipeline like this:. Static optimizations, xlation unit at a time:; .c --GCC--> .llvm --llvmopt--> .llvm . Link time optimizations:; .llvm --llvm-ld--> .llvm --llvm-link-opt--> .llvm . Of course, many optimizations could be shared between llvmopt and; llvm-link-opt, but the wouldn't need to be shared... Thus compile time; could be faster, because we are using a ""smarter"" IR (SSA based). > BTW, about SGI, ""borrowing"" SSA-based optimizations from one compiler and; > putting it into another is not necessarily easier than re-doing it.; > Optimization code is usually heavily tied in to the specific IR they use. Understood. The only reason that I brought this up is because SGI's IR is; more similar to LLVM than it is different in many respects (SSA based,; relatively low level, etc), and could be easily adapted. Also their; optimizations are written in C++ and are actually somewhat; structured... of course it would be no walk in the park, but it would be; much less time consuming to adapt, say, SSA-PRE than to rewrite it. > But your larger point is valid that adding SSA based optimizations is; > feasible and should be fun. (Again, link time cost is the issue.). Assuming linktime cost wasn't an issue, the question is: ; Does using GCC's backend buy us anything?. > It also occurs to me that GCC is probably doing quite a bit of back-end; > optimization (step 16 in your list). Do you have a breakdown of that?. Not really. The irritating part of GCC is that it mixes it all up and; doesn't have a clean separation of concerns. A lot of the ""back end; optimization"" happens right along with other data optimizations (ie, CSE; of machine specific things). As far as REAL back end optimizations go, it looks something like this:. 1. Instruction combination: try to make CISCy instructions, if available; 2. Register movement: try to get registers in the right places for the; architecture to avoid register to register moves. For example, try to get; the fi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt:1516,adapt,adapt,1516,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,1,['adapt'],['adapt']
Energy Efficiency," draw options:; - ""RX"" and ""RY"" for TGraph to reverse axis; - ""noopt"" for TGraph to disable drawing optimization; - ""CPN"" for TCanvas to create color palette from N last colors; - ""line"" for TGraph2D; * New features:; - support LZ4 compression; - tooltips and zooming in TGraphPolar drawings; - TPavesText with multiple underlying paves; - implement all fill styles; - draw borders for TWbox; - draw all objects from TList/TObjArray as they appear in list of primitives; - let enable/disable highlight of extra objects in geometry viewer; - draw axis labels on both sides when pad.fTick[x/y] > 1; - make drawing of TCanvas with many primitives smoother; - add fOptTitle, fOptLogx/y/z fields in JSROOT.gStyle; * Behavior changes:; - disable automatic frame adjustment, can be enabled with ""&adjframe"" parameter in URL; - when drawing TH2/TH3 scatter plots, always generate same ""random"" pattern; - use barwidth/baroffset parameters in lego plots; * Bug fixes:; - use same number of points to draw lines and markers on the TGraph; - correctly draw filled TArrow endings; - let combine ""L"" or ""C"" TGraph draw option with others; - correct positioning of custom axis labels; - correctly toggle lin/log axes in lego plot; - let correctly change marker attributes interactively ; - monitoring mode in draw.htm page; - zooming in colz palette; - support both 9.x and 10.x jsdom version in Node.js (#149); - draw axis main line with appropriate attributes (#150); - use axis color when drawing grids lines (#150); - when set pad logx/logy, reset existing user ranges in pad; - avoid too deep calling stack when drawing many graphs or histos (#154); - correctly (re)draw tooltips on canvas with many subpads. ## Code Examples. - New graphics tutorial AtlasExample.C illustrating the ATLAS style.; - New TLazyDS tutorial added tdf015_LazyDataSource.C.; - Show how to inspect a `TCutFlowReport` object. ## Class Reference Guide. - Replace low resolution images with bigger ones more suited for modern screens. ##",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:16898,monitor,monitoring,16898,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['monitor'],['monitoring']
Energy Efficiency," due to importing all C++ Modules at startup; we see overhead which depends on the number of preloaded modules. For; ROOT it is between 40-60 MB depending on the concrete configuration.; When the workload increases we notice that the overall memory performance; decreases in number of cases.; * Execution times -- likewise we have an execution overhead. For ; workflows which take ms the slowdown can be 2x. Increasing of the work; to seconds shows 50-60% slowdowns. The performance is dependent on many factors such as configuration of ROOT and; workflow. You can read more at our Intel IPCC-ROOT Showcase presentation; here (pp 25-33)[[8]]. #### Loading C++ Modules on Demand. In long term, we should optimize the preloading of modules to be a no-op and; avoid recursive behavior based on identifier lookup callbacks. Unfortunately,; at the moment the loading of C++ modules on demand shows significantly better; performance results. You can visit our continuous performance monitoring tool where we compare; the performance of ROOT against ROOT with a PCH [[9]].; *Note: if you get error 400, clean your cache or open a private browser session.*. ## How to use; C++ Modules in ROOT are default since v6.20 (Unix) and v6.22 (OSX). Enjoy. To disable C++ Modules in ROOT use `-Druntime_cxxmodules=Off`. ## Citing ROOT's C++ Modules; ```latex; % Peer-Reviewed Publication; %; % 22nd International Conference on Computing in High Energy and Nuclear Physics (CHEP); % 8-14 October, 2016, San Francisco, USA; %; @inproceedings{Vassilev_ROOTModules,; author = {Vassilev,V.},; title = {{Optimizing ROOT's Performance Using C++ Modules}},; journal = {Journal of Physics: Conference Series},; year = 2017,; month = {oct},; volume = {898},; number = {7},; pages = {072023},; doi = {10.1088/1742-6596/898/7/072023},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/898/7/072023/pdf},; publisher = {{IOP} Publishing}; }; ```; ; # Acknowledgement. We would like to thank the ROOT team. We would like ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:19181,monitor,monitoring,19181,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['monitor'],['monitoring']
Energy Efficiency," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:2729,reduce,reduce,2729,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,4,['reduce'],"['reduce', 'reduced']"
Energy Efficiency," each enabled lane, and taking the minimum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MAX`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smin.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 127, i8 127, i8 127, i8 127>; %reduction = call i8 @llvm.vector.reduce.smin.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smin.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_umax:. '``llvm.vp.reduce.umax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umax``' intrinsic performs the unsigned-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:767011,reduce,reduce,767011,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," each enabled lane, performing an '``and``' of that with with the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.and.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %masked.a); %also.r = and i32 %reduction, %start. .. _int_vp_reduce_or:. '``llvm.vp.reduce.or.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.or.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.or.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``OR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.or``' intrinsic performs the integer ``OR`` reduction; (:ref:`llvm.vector.reduce.or <int_vector_reduce_or>`)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:758859,reduce,reduce,758859,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," efficient CPU library loaded will also handle parts of the computations in parallel with the GPU (or potentially, if it's faster, all of them), thus gaining full advantage of the available hardware. For this purpose `RooFitDriver`, a newly created RooFit class (in roofitcore) takes over the task of analyzing the computations and assigning each to the correct piece of hardware, taking into consideration the performance boost or penalty that may arise with every method of computing. #### Multithread computations; The CPU instance of the computing library can furthermore execute multithread computations. This also applies for computations handled by the CPU in the `""cuda""` mode. To use them, one needs to set the desired number of parallel tasks before calling `fitTo()` as shown below:; ``` {.cpp}; ROOT::EnableImplicitMT(nThreads);; RooMyPDF.fitTo(data, BatchMode(""cuda"")); // can also use ""cuda""; ```. ### User-made PDFs; The easiest and most efficient way of accelerating your PDFs is to request their addition to the official RooFit by submitting a ticket [here](https://github.com/root-project/root/issues/new). The ROOT team will gladly assist you and take care of the details. While your code is integrated, you are able to significantly improve the speed of fitting (but not take full advantage of the RooBatchCompute library), at least by using the batch evaluation feature.; To make use of it, one should override `RooAbsReal::computeBatch()`; ``` {.cpp}; void RooMyPDF::computeBatch(RooBatchCompute::RooBatchComputeInterface*, double* output, size_t nEvents, RooBatchCompute::DataMap& dataMap) const; ```; This method must be implemented so that it fills the `output` array with the **normalized** probabilities computed for `nEvents` events, the data of which can be retrieved from `dataMap`. `dataMap` is a simple `std::map<RooRealVar*, std::span<const double>>`. Note that it is not necessary to evaluate any of the objects that the PDF relies to, because they have already been ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md:3600,efficient,efficient,3600,roofit/doc/developers/batchcompute.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md,1,['efficient'],['efficient']
Energy Efficiency," emitted separately``. This container type expects only a :ref:`META_BLOCK <bitstreamremarksmetablock>` containing only:. * :ref:`RECORD_META_CONTAINER_INFO <bitstreamremarksrecordmetacontainerinfo>`; * :ref:`RECORD_META_STRTAB <bitstreamremarksrecordmetastrtab>`; * :ref:`RECORD_META_EXTERNAL_FILE <bitstreamremarksrecordmetaexternalfile>`. Typically, this is emitted in a section in the object files, allowing; clients to retrieve remarks and their associated metadata directly from; intermediate products. ``SeparateRemarksFile: the remark entries emitted separately``. This container type expects only a :ref:`META_BLOCK <bitstreamremarksmetablock>` containing only:. * :ref:`RECORD_META_CONTAINER_INFO <bitstreamremarksrecordmetacontainerinfo>`; * :ref:`RECORD_META_REMARK_VERSION <bitstreamremarksrecordmetaremarkversion>`. This container type expects 0 or more :ref:`REMARK_BLOCK <bitstreamremarksremarkblock>`. Typically, this is emitted in a side-file alongside an object file, and is; made to be able to stream to without increasing the memory consumption of; the compiler. This is referenced by the :ref:`RECORD_META_EXTERNAL_FILE; <bitstreamremarksrecordmetaexternalfile>` entry in the; :ref:`SeparateRemarksMeta <bitstreamremarksseparateremarksmeta>` container. When the parser tries to parse a container that contains the metadata for the; separate remarks, it should parse the version and type, then keep the string; table in memory while opening the external file, validating its metadata and; parsing the remark entries. The container versions from the separate container should match in order to; have a well-formed file. ``Standalone: the metadata and the remark entries emitted together``. This container type expects only a :ref:`META_BLOCK <bitstreamremarksmetablock>` containing only:. * :ref:`RECORD_META_CONTAINER_INFO <bitstreamremarksrecordmetacontainerinfo>`; * :ref:`RECORD_META_REMARK_VERSION <bitstreamremarksrecordmetaremarkversion>`; * :ref:`RECORD_META_STRTAB <bitstr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst:12080,consumption,consumption,12080,interpreter/llvm-project/llvm/docs/Remarks.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst,1,['consumption'],['consumption']
Energy Efficiency," enabled the display of inherited members you will see; some members with a class name prefix. It tells you where this method has been defined.; Display Options; The info box contains options that influence how; the list of members is displayed: you can e.g. show or hide non-public methods. If you; just want to use ROOT you should hide them - you cannot access protected or private; members anyway. And you can select whether member that are inherited from a base class; should be shown. Again, if you just want to use ROOT you should probably show them,; as you often want to use them whether they are defined in the current class or in one; of its base classes. Whatever you set these options to should be stored in a cookie,; so you will have the same setting next time you look at the class documentation. Access (public / protected / private); Not all members are available to everyone (check any C++ introduction to learn why).; Public members have a green bar on their left, protected ones have a yellow one, and; private members are marked with a red bar. Of course you won't see any protected or; private members if you hide them in the display options. Inheritance; You can often access members of a class's base classes, just as if they are defined; in the derived class. A histogram,; for example, has a name, and you can access it using GetName() as defined in its base; class TNamed. If you want to see; all available members, and not just the ones defined in the current class, in the; display options. They will be prefixed with the name of; the class they are defined in. Class Charts; The class charts are shown in a tabbed box; click on the names ontop to select a tab. Inheritance; This chart shows the inheritance hierarchy for the current class. Arrows point to; base classes. You can click the classes to get to their reference page. Inherited Members; The second chart shows a list of all members of all base classes. You can see at what; level they are defined or at what l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/etc/html/HELP.html:6215,green,green,6215,etc/html/HELP.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/etc/html/HELP.html,1,['green'],['green']
Energy Efficiency," example:. .. code-block:: llvm. call void @llvm.assume(i1 true) [""align""(ptr %val, i32 8)]. allows the optimizer to assume that at location of call to; :ref:`llvm.assume <int_assume>` ``%val`` has an alignment of at least 8. .. code-block:: llvm. call void @llvm.assume(i1 %cond) [""cold""(), ""nonnull""(ptr %val)]. allows the optimizer to assume that the :ref:`llvm.assume <int_assume>`; call location is cold and that ``%val`` may not be null. Just like for the argument of :ref:`llvm.assume <int_assume>`, if any of the; provided guarantees are violated at runtime the behavior is undefined. While attributes expect constant arguments, assume operand bundles may be; provided a dynamic value, for example:. .. code-block:: llvm. call void @llvm.assume(i1 true) [""align""(ptr %val, i32 %align)]. If the operand bundle value violates any requirements on the attribute value,; the behavior is undefined, unless one of the following exceptions applies:. * ``""align""`` operand bundles may specify a non-power-of-two alignment; (including a zero alignment). If this is the case, then the pointer value; must be a null pointer, otherwise the behavior is undefined. In addition to allowing operand bundles encoding function and parameter; attributes, an assume operand bundle my also encode a ``separate_storage``; operand bundle. This has the form:. .. code-block:: llvm. separate_storage(<val1>, <val2>)``. This indicates that no pointer :ref:`based <pointeraliasing>` on one of its; arguments can alias any pointer based on the other. Even if the assumed property can be encoded as a boolean value, like; ``nonnull``, using operand bundles to express the property can still have; benefits:. * Attributes that can be expressed via operand bundles are directly the; property that the optimizer uses and cares about. Encoding attributes as; operand bundles removes the need for an instruction sequence that represents; the property (e.g., `icmp ne ptr %p, null` for `nonnull`) and for the; optimizer to deduc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:125150,power,power-of-two,125150,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power-of-two']
Energy Efficiency," external symbols and resolve their addresses asynchronously. Calls the ``JITLinkContext`` to resolve the target address of any external; symbols in the graph. #. Phase 3. #. Apply external symbol resolution results. This updates the addresses of all external symbols. At this point all; nodes in the graph have their final target addresses, however node; content still points back to the original data in the object file. #. Run pre-fixup passes. These passes are called on the graph after all nodes have been assigned; their final target addresses, but before node content is copied into; working memory and fixed up. Passes run at this stage can make late; optimizations to the graph and content based on address layout. Notable use cases: GOT and PLT relaxation, where GOT and PLT accesses are; bypassed for fixup targets that are directly accessible under the assigned; memory layout. #. Copy block content to working memory and apply fixups. Copies all block content into allocated working memory (following the; target layout) and applies fixups. Graph blocks are updated to point at; the fixed up content. #. Run post-fixup passes. These passes are called on the graph after fixups have been applied and; blocks updated to point to the fixed up content. Post-fixup passes can inspect blocks contents to see the exact bytes that; will be copied to the assigned target addresses. #. Finalize memory asynchronously. Calls the ``JITLinkMemoryManager`` to copy working memory to the executor; process and apply the requested permissions. #. Phase 3. #. Notify the context that the graph has been emitted. Calls ``JITLinkContext::notifyFinalized`` and hands off the; ``JITLinkMemoryManager::FinalizedAlloc`` object for this graph's memory; allocation. This allows the context to track/hold memory allocations and; react to the newly emitted definitions. In ORC this is used to update the; ``ExecutionSession`` instance's dependence graph, which may result in; these symbols (and possibly others) be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:21680,allocate,allocated,21680,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['allocate'],['allocated']
Energy Efficiency," float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_mul:. '``llvm.vector.reduce.mul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.mul.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.mul.*``' intrinsics do an integer ``MUL``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmul:. '``llvm.vector.reduce.fmul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fmul.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmul.*``' intrinsics do a floating-point; ``MUL`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. Otherwise; the reduction will be *sequential*, thus implying that the operation respects; the associativity of a scalarized reduction. That is, the reduction begins with; the start value and performs an fmul operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fmul(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result * input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vecto",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:653551,reduce,reduce,653551,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fadd``' intrinsic performs the floating-point ``ADD``; reduction (:ref:`llvm.vector.reduce.fadd <int_vector_reduce_fadd>`) of the; vector operand ``val`` on each enabled lane, adding it to the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``-0.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to ``start_value``. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fadd; <int_vector_reduce_fadd>`) for more detail on the semantics of the reduction. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fadd.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float -0.0, float -0.0, float -0.0, float -0.0>; %also.r = call float @llvm.vector.reduce.fadd.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_mul:. '``llvm.vp.reduce.mul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.mul.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.mul.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``MUL`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:752032,reduce,reduce,752032,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," for blocks that capture uninitialized values. void test() {; int x;; ^{ int y = x; }(); // warn; }. core.uninitialized.UndefReturn; (C); Check for uninitialized values being returned to the caller. int test() {; int x;; return x; // warn; }. C++ Checkers. Name, DescriptionExample. cplusplus.NewDelete; (C++); Check for double-free, use-after-free and offset problems involving C++ ; delete. void f(int *p);. void testUseMiddleArgAfterDelete(int *p) {; delete p;; f(p); // warn: use after free; }. class SomeClass {; public:; void f();; };. void test() {; SomeClass *c = new SomeClass;; delete c;; c->f(); // warn: use after free; }. void test() {; int *p = (int *)__builtin_alloca(sizeof(int));; delete p; // warn: deleting memory allocated by alloca; }. void test() {; int *p = new int;; delete p;; delete p; // warn: attempt to free released; }. void test() {; int i;; delete &i; // warn: delete address of local; }. void test() {; int *p = new int[1];; delete[] (++p);; // warn: argument to 'delete[]' is offset by 4 bytes; // from the start of memory allocated by 'new[]'; }. cplusplus.NewDeleteLeaks; (C++); Check for memory leaks. Traces memory managed by new/; delete. void test() {; int *p = new int;; } // warn. Dead Code Checkers. Name, DescriptionExample. deadcode.DeadStores; (C); Check for values stored to variables that are never read afterwards. void test() {; int x;; x = 1; // warn; }. Nullability Checkers. Name, DescriptionExample. nullability.NullPassedToNonnull; (ObjC); Warns when a null pointer is passed to a pointer which has a; _Nonnull type. if (name != nil); return;; // Warning: nil passed to a callee that requires a non-null 1st parameter; NSString *greeting = [@""Hello "" stringByAppendingString:name];. nullability.NullReturnedFromNonnull; (ObjC); Warns when a null pointer is returned from a function that has; _Nonnull return type. - (nonnull id)firstChild {; id result = nil;; if ([_children count] > 0); result = _children[0];. // Warning: nil returned from a me",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html:5854,allocate,allocated,5854,interpreter/llvm-project/clang/www/analyzer/available_checks.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html,1,['allocate'],['allocated']
Energy Efficiency," for each weight, always with the same scalar value.; - The `Histo*D` methods do not work on columns of type `std::string` anymore. They used to fill the histogram with the integer value corresponding to each of the characters in the string. Please use `Fill` with a custom class to recover the old behavior if that was what was desired. ### Other improvements. - The scaling to a large amount of threads of computation graphs with many simple `Filter`s or `Define`s has been greatly improved, see also [this talk](https://indico.cern.ch/event/1036730/#1-a-performance-study-of-the-r) for more details; - The output format of `Display` has been significantly improved.; - The `Fill` method now correctly supports user-defined classes with arbitrary `Fill` signatures (see [#9428](https://github.com/root-project/root/issues/9428)). ### Experimental Distributed RDataFrame. The distributed RDataFrame module has been improved. Now it supports sending RDataFrame tasks to a [Dask](https://dask.org/) scheduler. Through Dask, RDataFrame can be also scaled to a cluster of machines managed through a batch system like HTCondor or Slurm. Here is an example:. ```python; import ROOT; from dask.distributed import Client; RDataFrame = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame. # In a Python script the Dask client needs to be initalized in a context; # Jupyter notebooks / Python session don't need this; if __name__ == ""__main__"":; client = Client(""SCHEDULER_ADDRESS""); df = RDataFrame(""mytree"",""myfile.root"", daskclient=client); # Proceed as usual; df.Define(""x"",""someoperation"").Histo1D(""x""); ```. Other notable additions and improvements include:. - Enable triggering multiple distributed computation graphs through `RunGraphs`. This also allows sending both Spark and Dask jobs at the same time through a single function call.; - Greatly reduce distributed tasks processing overhead in TTree-based analyses by refactoring the translation from task metadata to RDataFrame object on the workers.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:10408,schedul,scheduler,10408,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['schedul'],['scheduler']
Energy Efficiency," for these type qualifiers. By storing the type qualifiers as bits in the conceptual pair, it is extremely; efficient to get the set of qualifiers on a ``QualType`` (just return the field; of the pair), add a type qualifier (which is a trivial constant-time operation; that sets a bit), and remove one or more type qualifiers (just return a; ``QualType`` with the bitfield set to empty). Further, because the bits are stored outside of the type itself, we do not need; to create duplicates of types with different sets of qualifiers (i.e. there is; only a single heap allocated ""``int``"" type: ""``const int``"" and ""``volatile; const int``"" both point to the same heap allocated ""``int``"" type). This; reduces the heap size used to represent bits and also means we do not have to; consider qualifiers when uniquing types (:ref:`Type <Type>` does not even; contain qualifiers). In practice, the two most common type qualifiers (``const`` and ``restrict``); are stored in the low bits of the pointer to the ``Type`` object, together with; a flag indicating whether extended qualifiers are present (which must be; heap-allocated). This means that ``QualType`` is exactly the same size as a; pointer. .. _DeclarationName:. Declaration names; -----------------. The ``DeclarationName`` class represents the name of a declaration in Clang.; Declarations in the C family of languages can take several different forms.; Most declarations are named by simple identifiers, e.g., ""``f``"" and ""``x``"" in; the function declaration ``f(int x)``. In C++, declaration names can also name; class constructors (""``Class``"" in ``struct Class { Class(); }``), class; destructors (""``~Class``""), overloaded operator names (""``operator+``""), and; conversion functions (""``operator void const *``""). In Objective-C,; declaration names can refer to the names of Objective-C methods, which involve; the method name and the parameters, collectively called a *selector*, e.g.,; ""``setWidth:height:``"". Since all of these kinds of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:68016,allocate,allocated,68016,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['allocate'],['allocated']
Energy Efficiency," frames to be created. The cost of; creating unsafe stack frames for large functions is amortized by the cost of; executing the function. In some cases, SafeStack actually improves the performance. Objects that end up; being moved to the unsafe stack are usually large arrays or variables that are; used through multiple stack frames. Moving such objects away from the safe; stack increases the locality of frequently accessed values on the stack, such; as register spills, return addresses, and small local variables. Compatibility; -------------. Most programs, static libraries, or individual files can be compiled; with SafeStack as is. SafeStack requires basic runtime support, which, on most; platforms, is implemented as a compiler-rt library that is automatically linked; in when the program is compiled with SafeStack. Linking a DSO with SafeStack is not currently supported. Known compatibility limitations; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Certain code that relies on low-level stack manipulations requires adaption to; work with SafeStack. One example is mark-and-sweep garbage collection; implementations for C/C++ (e.g., Oilpan in chromium/blink), which must be; changed to look for the live pointers on both safe and unsafe stacks. SafeStack supports linking statically modules that are compiled with and; without SafeStack. An executable compiled with SafeStack can load dynamic; libraries that are not compiled with SafeStack. At the moment, compiling; dynamic libraries with SafeStack is not supported. Signal handlers that use ``sigaltstack()`` must not use the unsafe stack (see; ``__attribute__((no_sanitize(""safe-stack"")))`` below). Programs that use APIs from ``ucontext.h`` are not supported yet. Security; --------. SafeStack protects return addresses, spilled registers and local variables that; are always accessed in a safe way by separating them in a dedicated safe stack; region. The safe stack is automatically protected against stack-based buffer; overflows, since it i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst:2151,adapt,adaption,2151,interpreter/llvm-project/clang/docs/SafeStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst,1,['adapt'],['adaption']
Energy Efficiency," from; different object files tightly (the word-level alignment assumption is baked in; too deeply). .. code-block:: llvm. @__llvm_coverage_mapping = internal constant { { i32, i32, i32, i32 }, [32 x i8] }; {; { i32, i32, i32, i32 } ; Coverage map header; {; i32 0, ; Always 0. In prior versions, the number of affixed function records; i32 32, ; The length of the string that contains the encoded translation unit filenames; i32 0, ; Always 0. In prior versions, the length of the affixed string that contains the encoded coverage mapping data; i32 3, ; Coverage mapping format version; },; [32 x i8] c""..."" ; Encoded data (dissected later); }, section ""__llvm_covmap"", align 8. The current version of the format is version 6. There is one difference between versions 6 and 5:. * The first entry in the filename list is the compilation directory. When the; filename is relative, the compilation directory is combined with the relative; path to get an absolute path. This can reduce size by omitting the duplicate; prefix in filenames. There is one difference between versions 5 and 4:. * The notion of branch region has been introduced along with a corresponding; region kind. Branch regions encode two counters, one to track how many; times a ""true"" branch condition is taken, and one to track how many times a; ""false"" branch condition is taken. There are two differences between versions 4 and 3:. * Function records are now named symbols, and are marked *linkonce_odr*. This; allows linkers to merge duplicate function records. Merging of duplicate; *dummy* records (emitted for functions included-but-not-used in a translation; unit) reduces size bloat in the coverage mapping data. As part of this; change, region mapping information for a function is now included within the; function record, instead of being affixed to the coverage header. * The filename list for a translation unit may optionally be zlib-compressed. The only difference between versions 3 and 2 is that a special encoding f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:15664,reduce,reduce,15664,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,1,['reduce'],['reduce']
Energy Efficiency," frontend has to; create a landing pad. The frontend has to destroy the already; constructed argument ``b`` before restoring the stack pointer. If the; constructor does not unwind, ``g`` is called. In the Microsoft C++ ABI,; ``g`` will destroy its arguments, and then the stack is restored in; ``f``. Design Considerations; =====================. Lifetime; --------. The biggest design consideration for this feature is object lifetime.; We cannot model the arguments as static allocas in the entry block,; because all calls need to use the memory at the top of the stack to pass; arguments. We cannot vend pointers to that memory at function entry; because after code generation they will alias. The rule against allocas between argument allocations and the call site; avoids this problem, but it creates a cleanup problem. Cleanup and; lifetime is handled explicitly with stack save and restore calls. In; the future, we may want to introduce a new construct such as ``freea``; or ``afree`` to make it clear that this stack adjusting cleanup is less; powerful than a full stack save and restore. Nested Calls and Copy Elision; -----------------------------. We also want to be able to support copy elision into these argument; slots. This means we have to support multiple live argument; allocations. Consider the evaluation of:. .. code-block:: c++. // Foo is non-trivial.; struct Foo { int a; Foo(); Foo(const &Foo); ~Foo(); };; Foo bar(Foo b);; int main() {; bar(bar(Foo()));; }. In this case, we want to be able to elide copies into ``bar``'s argument; slots. That means we need to have more than one set of argument frames; active at the same time. First, we need to allocate the frame for the; outer call so we can pass it in as the hidden struct return pointer to; the middle call. Then we do the same for the middle call, allocating a; frame and passing its address to ``Foo``'s default constructor. By; wrapping the evaluation of the inner ``bar`` with stack save and; restore, we can have",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst:3864,power,powerful,3864,interpreter/llvm-project/llvm/docs/InAlloca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst,1,['power'],['powerful']
Energy Efficiency," generated the code. This would be much quicker; than having to validate consistency (especially if bounds checks have; been removed, for example). > This is important because the audiences for these two goals are very; > different. Architects and many compiler people care much more about; > the second question. The Java compiler and OS community care much more; > about the first one. 3. By focusing on a more low level virtual machine, we have much more room; for value add. The nice safe ""sandbox"" VM can be provided as a layer; on top of it. It also lets us focus on the more interesting compilers; related projects. > 2. Design issues to consider (an initial list that we should continue; > to modify). Note that I'm not trying to suggest actual solutions here,; > but just various directions we can pursue:. Understood. :). > a. A single-assignment VM, which we've both already been thinking; > about. Yup, I think that this makes a lot of sense. I am still intrigued,; however, by the prospect of a minimally allocated VM representation... I; think that it could have definite advantages for certain applications; (think very small machines, like PDAs). I don't, however, think that our; initial implementations should focus on this. :). Here are some other auxiliary goals that I think we should consider:. 1. Primary goal: Support a high performance dynamic compilation; system. This means that we have an ""ideal"" division of labor between; the runtime and static compilers. Of course, the other goals of the; system somewhat reduce the importance of this point (f.e. portability; reduces performance, but hopefully not much); 2. Portability to different processors. Since we are most familiar with; x86 and solaris, I think that these two are excellent candidates when; we get that far...; 3. Support for all languages & styles of programming (general purpose; VM). This is the point that disallows java style bytecodes, where all; array refs are checked for bounds, etc...; 4. Support li",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:2890,allocate,allocated,2890,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,1,['allocate'],['allocated']
Energy Efficiency," grid dimensionality; is 1 or 2, then must be 1. ""hidden_remainder_x""; The grid dispatch work group size of the partial work group; of the X dimension, if it exists. Must be zero if a partial; work group does not exist in the X dimension. ""hidden_remainder_y""; The grid dispatch work group size of the partial work group; of the Y dimension, if it exists. Must be zero if a partial; work group does not exist in the Y dimension. ""hidden_remainder_z""; The grid dispatch work group size of the partial work group; of the Z dimension, if it exists. Must be zero if a partial; work group does not exist in the Z dimension. ""hidden_grid_dims""; The grid dispatch dimensionality. This is the same value; as the AQL dispatch packet dimensionality. Must be a value; between 1 and 3. ""hidden_heap_v1""; A global address space pointer to an initialized memory; buffer that conforms to the requirements of the malloc/free; device library V1 version implementation. ""hidden_dynamic_lds_size""; Size of the dynamically allocated LDS memory is passed in the kernarg. ""hidden_private_base""; The high 32 bits of the flat addressing private aperture base.; Only used by GFX8 to allow conversion between private segment; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_shared_base""; The high 32 bits of the flat addressing shared aperture base.; Only used by GFX8 to allow conversion between shared segment; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_queue_ptr""; A global memory address space pointer to the ROCm runtime; ``struct amd_queue_t`` structure for the HSA queue of the; associated dispatch AQL packet. It is only required for pre-GFX9; devices for the trap handler ABI (see :ref:`amdgpu-amdhsa-trap-handler-abi`). ====================== ============== ========= ================================. .. Kernel Dispatch; ~~~~~~~~~~~~~~~. The HSA architected queuing language (AQL) defines a user space memory interface; that can be used to cont",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:147962,allocate,allocated,147962,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency," have to delete it; and return the node that already exists. To support this style of client, FoldingSet perform a query with a; FoldingSetNodeID (which wraps SmallVector) that can be used to describe the; element that we want to query for. The query either returns the element; matching the ID or it returns an opaque ID that indicates where insertion should; take place. Construction of the ID usually does not require heap traffic. Because FoldingSet uses intrusive links, it can support polymorphic objects in; the set (for example, you can have SDNode instances mixed with LoadSDNodes).; Because the elements are individually allocated, pointers to the elements are; stable: inserting or removing elements does not invalidate any pointers to other; elements. .. _dss_set:. <set>; ^^^^^. ``std::set`` is a reasonable all-around set class, which is decent at many; things but great at nothing. std::set allocates memory for each element; inserted (thus it is very malloc intensive) and typically stores three pointers; per element in the set (thus adding a large amount of per-element space; overhead). It offers guaranteed log(n) performance, which is not particularly; fast from a complexity standpoint (particularly if the elements of the set are; expensive to compare, like strings), and has extremely high constant factors for; lookup, insertion and removal. The advantages of std::set are that its iterators are stable (deleting or; inserting an element from the set does not affect iterators or pointers to other; elements) and that iteration over the set is guaranteed to be in sorted order.; If the elements in the set are large, then the relative overhead of the pointers; and malloc traffic is not a big deal, but if the elements of the set are small,; std::set is almost never a good choice. .. _dss_setvector:. llvm/ADT/SetVector.h; ^^^^^^^^^^^^^^^^^^^^. LLVM's ``SetVector<Type>`` is an adapter class that combines your choice of a; set-like container along with a :ref:`Sequential Co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:83331,allocate,allocates,83331,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocates']
Energy Efficiency," hist->GetZaxis()->SetLabelSize();; ```. #### Setting the Color Palette. You can set the color palette with **`TStyle`**`::SetPalette` , e.g. ``` {.cpp}; gStyle->SetPalette(ncolors,colors);; ```. For example, the option `COL` draws a 2-D histogram with cells; represented by a box filled with a color index, which is a function of; the cell content. If the cell content is N, the color index used will; be the color number in `colors[N]` . If the maximum cell content is; greater than `ncolors` , all cell contents are scaled to `ncolors`. If; `ncolors<=0`, a default palette of 50 colors is defined. This palette; is recommended for pads, labels. It defines:. - Index 0 to 9: shades of gray; - Index 10 to 19:shades of brown; - Index 20 to 29:shades of blue; - Index 30 to 39: shades of red; - Index 40 to 49:basic colors. The color numbers specified in this palette can be viewed by selecting; the menu entry Colors in the View menu of the canvas menu bar. The; color's red, green, and blue values can be changed via; **`TColor`**`::SetRGB`. If `ncolors == 1 && colors == 0`, then a Pretty Palette with a; spectrum violet to red is created with 50 colors. That's the default; rain bow palette. Other predefined palettes with 255 colors are available when; `colors == 0`. The following value of `ncolors` (with `colors = 0`); give access to:. - `ncolors = 51` : Deep Sea palette.; - `ncolors = 52` : Grey Scale palette.; - `ncolors = 53` : Dark Body Radiator palette.; - `ncolors = 54` : Two-color hue palette palette. (dark blue through; neutral gray to bright yellow); - `ncolors = 55` : Rain Bow palette.; - `ncolors = 56` : Inverted Dark Body Radiator palette. The color numbers specified in the palette can be viewed by selecting; the item ""colors"" in the ""VIEW"" menu of the canvas toolbar.; The color parameters can be changed via `TColor::SetRGB`. Note that when drawing a 2D histogram `h2` with the option ""`COL`"" or; ""`COLZ`"" or with any ""`CONT`"" options using the color map, the number; of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Histograms.md:32095,green,green,32095,documentation/users-guide/Histograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Histograms.md,1,['green'],['green']
Energy Efficiency," however, when; compiling a call, typechecking is done based on the methods declared in the; ``@interface``. Method declarations may also be grouped into :arc-term:`protocols`, which are not; inherently associated with any class, but which classes may claim to follow.; Object pointer types may be qualified with additional protocols that the object; is known to support. :arc-term:`Class extensions` are collections of ivars and methods, designed to; allow a class's ``@interface`` to be split across multiple files; however,; there is still a primary implementation file which must see the; ``@interface``\ s of all class extensions. :arc-term:`Categories` allow; methods (but not ivars) to be declared *post hoc* on an arbitrary class; the; methods in the category's ``@implementation`` will be dynamically added to that; class's method tables which the category is loaded at runtime, replacing those; methods in case of a collision. In the standard environment, objects are allocated on the heap, and their; lifetime is manually managed using a reference count. This is done using two; instance methods which all classes are expected to implement: ``retain``; increases the object's reference count by 1, whereas ``release`` decreases it; by 1 and calls the instance method ``dealloc`` if the count reaches 0. To; simplify certain operations, there is also an :arc-term:`autorelease pool`, a; thread-local list of objects to call ``release`` on later; an object can be; added to this pool by calling ``autorelease`` on it. Block pointers may be converted to type ``id``; block objects are laid out in a; way that makes them compatible with Objective-C objects. There is a builtin; class that all block objects are considered to be objects of; this class; implements ``retain`` by adjusting the reference count, not by calling; ``Block_copy``. .. _arc.meta.evolution:. Evolution; ---------. ARC is under continual evolution, and this document must be updated as the; language progresses. If a chang",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:6634,allocate,allocated,6634,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['allocate'],['allocated']
Energy Efficiency," i32 0, i32 1; %t4 = getelementptr [10 x [20 x i32]], ptr %t3, i32 0, i32 5; %t5 = getelementptr [20 x i32], ptr %t4, i32 0, i32 13; ret ptr %t5; }. The indices are first converted to offsets in the pointer's index type. If the; currently indexed type is a struct type, the struct offset corresponding to the; index is sign-extended or truncated to the pointer index type. Otherwise, the; index itself is sign-extended or truncated, and then multiplied by the type; allocation size (that is, the size rounded up to the ABI alignment) of the; currently indexed type. The offsets are then added to the low bits of the base address up to the index; type width, with silently-wrapping two's complement arithmetic. If the pointer; size is larger than the index size, this means that the bits outside the index; type width will not be affected. The result value of the ``getelementptr`` may be outside the object pointed; to by the base pointer. The result value may not necessarily be used to access; memory though, even if it happens to point into allocated storage. See the; :ref:`Pointer Aliasing Rules <pointeraliasing>` section for more; information. If the ``inbounds`` keyword is present, the result value of a; ``getelementptr`` with any non-zero indices is a; :ref:`poison value <poisonvalues>` if one of the following rules is violated:. * The base pointer has an *in bounds* address of an allocated object, which; means that it points into an allocated object, or to its end. Note that the; object does not have to be live anymore; being in-bounds of a deallocated; object is sufficient.; * If the type of an index is larger than the pointer index type, the; truncation to the pointer index type preserves the signed value.; * The multiplication of an index by the type size does not wrap the pointer; index type in a signed sense (``nsw``).; * The successive addition of each offset (without adding the base address) does; not wrap the pointer index type in a signed sense (``nsw``).; * The suc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:436971,allocate,allocated,436971,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency," i32 <element_size>); declare void @llvm.memcpy.element.unordered.atomic.p0.p0.i64(ptr <dest>,; ptr <src>,; i64 <len>,; i32 <element_size>). Overview:; """""""""""""""""". The '``llvm.memcpy.element.unordered.atomic.*``' intrinsic is a specialization of the; '``llvm.memcpy.*``' intrinsic. It differs in that the ``dest`` and ``src`` are treated; as arrays with elements that are exactly ``element_size`` bytes, and the copy between; buffers uses a sequence of :ref:`unordered atomic <ordering>` load/store operations; that are a positive integer multiple of the ``element_size`` in size. Arguments:; """""""""""""""""""". The first three arguments are the same as they are in the :ref:`@llvm.memcpy <int_memcpy>`; intrinsic, with the added constraint that ``len`` is required to be a positive integer; multiple of the ``element_size``. If ``len`` is not a positive integer multiple of; ``element_size``, then the behaviour of the intrinsic is undefined. ``element_size`` must be a compile-time constant positive power of two no greater than; target-specific atomic access size limit. For each of the input pointers ``align`` parameter attribute must be specified. It; must be a power of two no less than the ``element_size``. Caller guarantees that; both the source and destination pointers are aligned to that boundary. Semantics:; """""""""""""""""""". The '``llvm.memcpy.element.unordered.atomic.*``' intrinsic copies ``len`` bytes of; memory from the source location to the destination location. These locations are not; allowed to overlap. The memory copy is performed as a sequence of load/store operations; where each access is guaranteed to be a multiple of ``element_size`` bytes wide and; aligned at an ``element_size`` boundary. The order of the copy is unspecified. The same value may be read from the source; buffer many times, but only one write is issued to the destination buffer per; element. It is well defined to have concurrent reads and writes to both source and; destination provided those reads and writes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:958454,power,power,958454,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency," in normal PROOF, though some functionality may; not have been ported yet. To start a standard PROOF; session (i.e. via daemons) on the localhost use; TProof::Open(""localhost"").XrdProofd plug-in. Possibility to define the list worker directly in the; xrootd config file (new directive xpd.worker, see Wiki reference pages); Support for automatic reconnections in the case xrootd; is restarted; Dedicated admin area (under <xrd.admin>/.xproofd.<port>) to; keep information about active and terminated sessions, and active; clients. This is used to reguraly check the client and session; activity, to cleanup orphalin sessions and to shutdown inactive client; connections. ; domain + level control of printout message. Dynamic ""per-query"" scheduling. Dynamic worker startup. It can be enabled by the cluster; administrator with the 'xpd.putrc Proof.DynamicStartup 1' directive; in the config file. The effect is that a session starts only on; the master. When a query is submitted (call to TProof::Process),; the session master contacts the scheduler.; In response it receives a list of workers and starts the worker; processes. The environment is copied from the master to the workers.; It consist of: the include and library paths, the set of enabled; packages as well as the macros loaded by the user. . Flexible and fault-tolerant workers. A packet resubmitting mechanism. When a worker dies all the; packets that it processed are resubmitted.; Added the possibility to handle dynamically removed workers and partly processed; packets (when a worker is stopped while processing a packet it finishes; the current event and the rest of the packet is reassigned to another workers).; It's done by a new method TPacketizerAdaptive::AddProcessed(TSlave *sl,; TProofProgressStatus *st, TList **) and TPacketizerAdaptive::ReassignPacket. ; Memory controlAdd; the possibility to display the memory footprint on workers and master as a; function of the entry processed (workers) or of the merging step; (mast",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:1334,schedul,scheduler,1334,proof/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html,1,['schedul'],['scheduler']
Energy Efficiency," including section, symbol and relocation information. RuntimeDyldImpl::loadObject then iterates through the symbols in the; image. Information about common symbols is collected for later use. For; each function or data symbol, the associated section is loaded into memory; and the symbol is stored in a symbol table map data structure. When the; iteration is complete, a section is emitted for the common symbols. Next, RuntimeDyldImpl::loadObject iterates through the sections in the; object image and for each section iterates through the relocations for; that sections. For each relocation, it calls the format-specific; processRelocationRef method, which will examine the relocation and store; it in one of two data structures, a section-based relocation list map and; an external symbol relocation map. .. image:: MCJIT-load-object.png. When RuntimeDyldImpl::loadObject returns, all of the code and data; sections for the object will have been loaded into memory allocated by the; memory manager and relocation information will have been prepared, but the; relocations have not yet been applied and the generated code is still not; ready to be executed. [Currently (as of August 2013) the MCJIT engine will immediately apply; relocations when loadObject completes. However, this shouldn't be; happening. Because the code may have been generated for a remote target,; the client should be given a chance to re-map the section addresses before; relocations are applied. It is possible to apply relocations multiple; times, but in the case where addresses are to be re-mapped, this first; application is wasted effort.]. Address Remapping; =================. At any time after initial code has been generated and before; finalizeObject is called, the client can remap the address of sections in; the object. Typically this is done because the code was generated for an; external process and is being mapped into that process' address space.; The client remaps the section address by calling MCJIT::",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst:5265,allocate,allocated,5265,interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,1,['allocate'],['allocated']
Energy Efficiency," increasing; vector element indices. See the following pseudocode:. ::. float sequential_fmul(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result * input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, one (``1.0``) can be used, as it is the neutral; value of floating point multiplication. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fmul.v4f32(float 1.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_and:. '``llvm.vector.reduce.and.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.and.*``' intrinsics do a bitwise ``AND``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_or:. '``llvm.vector.reduce.or.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scalar. The return type matches the; element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_xor:. '``llvm.vector.reduce.xor.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.xor.v4i32(<4 x i32>",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:655108,reduce,reduce,655108,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," instruction must be; :ref:`floating-point <t_floating>` or :ref:`vector <t_vector>` of; floating-point values. Both arguments must have identical types. Semantics:; """""""""""""""""""". The value produced is the floating-point remainder of the two operands.; This is the same output as a libm '``fmod``' function, but without any; possibility of setting ``errno``. The remainder has the same sign as the; dividend.; This instruction is assumed to execute in the default :ref:`floating-point; environment <floatenv>`.; This instruction can also take any number of :ref:`fast-math; flags <fastmath>`, which are optimization hints to enable otherwise; unsafe floating-point optimizations:. Example:; """""""""""""""". .. code-block:: text. <result> = frem float 4.0, %var ; yields float:result = 4.0 % %var. .. _bitwiseops:. Bitwise Binary Operations; -------------------------. Bitwise binary operators are used to do various forms of bit-twiddling; in a program. They are generally very efficient instructions and can; commonly be strength reduced from other instructions. They require two; operands of the same type, execute an operation on them, and produce a; single value. The resulting value is the same type as its operands. .. _i_shl:. '``shl``' Instruction; ^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = shl <ty> <op1>, <op2> ; yields ty:result; <result> = shl nuw <ty> <op1>, <op2> ; yields ty:result; <result> = shl nsw <ty> <op1>, <op2> ; yields ty:result; <result> = shl nuw nsw <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``shl``' instruction returns the first operand shifted to the left; a specified number of bits. Arguments:; """""""""""""""""""". Both arguments to the '``shl``' instruction must be the same; :ref:`integer <t_integer>` or :ref:`vector <t_vector>` of integer type.; '``op2``' is treated as an unsigned value. Semantics:; """""""""""""""""""". The value produced is ``op1`` \* 2\ :sup:`op2` mod 2\ :sup:`n`,; where ``n`` is the width of the result. If ``op2`` is (staticall",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:392105,efficient,efficient,392105,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['efficient', 'reduce']","['efficient', 'reduced']"
Energy Efficiency," integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.and``' intrinsic performs the integer ``AND`` reduction; (:ref:`llvm.vector.reduce.and <int_vector_reduce_and>`) of the vector operand; ``val`` on each enabled lane, performing an '``and``' of that with with the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.and.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %masked.a); %also.r = and i32 %reduction, %start. .. _int_vp_reduce_or:. '``llvm.vp.reduce.or.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.or.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.or.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``OR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:758276,reduce,reduce,758276,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," into .debug_str (""collision""); | 0x00000002 | A 32 bit array count - number of HashData with name ""collision""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x00001203 | String offset into .debug_str (""dump""); | 0x00000003 | A 32 bit array count - number of HashData with name ""dump""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x00000000 | String offset into .debug_str (terminate data for hash); |------------|; 0x00003550: | 0x00001203 | String offset into .debug_str (""main""); | 0x00000009 | A 32 bit array count - number of HashData with name ""main""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x........ | HashData[3]; | 0x........ | HashData[4]; | 0x........ | HashData[5]; | 0x........ | HashData[6]; | 0x........ | HashData[7]; | 0x........ | HashData[8]; | 0x00000000 | String offset into .debug_str (terminate data for hash); `------------'. So we still have all of the same data, we just organize it more efficiently for; debugger lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:67106,efficient,efficiently,67106,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['efficient'],['efficiently']
Energy Efficiency," intrinsic returns the first operand; raised to the (positive or negative) power specified by the second operand. Arguments:; """""""""""""""""""". The first two arguments and the return value are floating-point numbers of the; same type. The second argument specifies the power to which the first argument; should be raised. The third and fourth arguments specify the rounding mode and exception; behavior as described above. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power,; returning the same values as the libm ``pow`` functions would, and; handles error conditions in the same way. '``llvm.experimental.constrained.powi``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.experimental.constrained.powi(<type> <op1>, i32 <op2>,; metadata <rounding mode>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.experimental.constrained.powi``' intrinsic returns the first operand; raised to the (positive or negative) power specified by the second operand. The; order of evaluation of multiplications is not defined. When a vector of; floating-point type is used, the second argument remains a scalar integer value. Arguments:; """""""""""""""""""". The first argument and the return value are floating-point numbers of the same; type. The second argument is a 32-bit signed integer specifying the power to; which the first argument should be raised. The third and fourth arguments specify the rounding mode and exception; behavior as described above. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power with an; unspecified sequence of rounding operations. '``llvm.experimental.constrained.ldexp``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type0>; @llvm.experimental.constrained.ldexp(<type0> <op1>, <type1> <op2>,; metadata <rounding mode>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.exper",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:892241,power,power,892241,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency," is irrelevant; it's perfectly; valid to compute arbitrary element indices, as the computation only depends on; the size of the array element, not the number of elements. Note that zero-sized; arrays are not a special case here. This sense is unconnected with ``inbounds`` keyword. The ``inbounds`` keyword is; designed to describe low-level pointer arithmetic overflow conditions, rather; than high-level array indexing rules. Analysis passes which wish to understand array indexing should not assume that; the static array type bounds are respected. The second sense of being out of bounds is computing an address that's beyond; the actual underlying allocated object. With the ``inbounds`` keyword, the result value of the GEP is ``poison`` if the; address is outside the actual underlying allocated object and not the address; one-past-the-end. Without the ``inbounds`` keyword, there are no restrictions on computing; out-of-bounds addresses. Obviously, performing a load or a store requires an; address of allocated and sufficiently aligned memory. But the GEP itself is only; concerned with computing addresses. Can array indices be negative?; ------------------------------. Yes. This is basically a special case of array indices being out of bounds. Can I compare two values computed with GEPs?; --------------------------------------------. Yes. If both addresses are within the same allocated object, or; one-past-the-end, you'll get the comparison result you expect. If either is; outside of it, integer arithmetic wrapping may occur, so the comparison may not; be meaningful. Can I do GEP with a different pointer type than the type of the underlying object?; ----------------------------------------------------------------------------------. Yes. There are no restrictions on bitcasting a pointer value to an arbitrary; pointer type. The types in a GEP serve only to define the parameters for the; underlying integer computation. They need not correspond with the actual type of; the un",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:14086,allocate,allocated,14086,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['allocate'],['allocated']
Energy Efficiency," is painted the same way in GL and non-GL mode.; The mismatch was reported in [this post](https://root-forum.cern.ch/t/how-to-specify-the-level-value-in-isosurface-drawing-with-tf3-and-gl/32179). ## Geometry Libraries. ## Database Libraries. The CMake module `FindOracle.cmake` was updated to support version 18.x; of the Oracle client libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ## JavaScript ROOT. ### New functionality from 5.7.0 release. - Add support of `TProfile2Poly` class; - Add support of `TGeoOverlap` class; - Add support of `TGeoHalfSpace` for composites; - Implement update of `TF2` drawings, see `tutorials/graphics/anim.C`; - Improve windows handling in flex(ible) layout; - Provide special widget for object inspector; - Use `requestAnimationFrame` when do monitoring, improves performance; - Better position for text in `TH2Poly` drawings; - Support eve7 geometry viewer - render data generated in ROOT itself; - Provide initial WebVR support, thanks to Diego Marcos; - Use `gStyle` attributes to draw histogram title; - Enable projections drawing also with `TH2` lego plots; - Many adjustment with new `TWebCanvas` - interactivity, attributes/position updates, context menus; - Upgrade three.js 86 -> 102, use `SoftwareRenderer` instead of `CanvasRenderer`; - Upgrade d3.js 4.4.4 -> 5.7.0; - Fix - support clipping for tracks and points in geo painter; - Fix - drawing of TGeoNode with finder; - Fix - key press events processed only in active pad (ROOT-9128); - Fix - use X0/Y0 in xtru shape, thanks to @altavir. ### New files location. JSROOT sources were moved from `etc/http/` into `js/` subfolder in ROOT sources tree.; OpenUI5 files were moved to `ui5/` subfolder. After ROOT compilation they can be found in; `$ROOTSYS/js/` and `$ROOTSYS/ui5/` subfolders respectively. ## Tutorials; - Add `RSqliteDS` examples.; - Make RCsvDS and RLazyDS tutorials standalone, i.e. downloading input csv directly us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:20694,monitor,monitoring,20694,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['monitor'],['monitoring']
Energy Efficiency," is the major; 2 integers version.; - The second integer is the; minor version.; "".args"" sequence of Sequence of maps of the; map kernel arguments. See; :ref:`amdgpu-amdhsa-code-object-kernel-argument-metadata-map-table-v3`; for the definition of the keys; included in that map.; "".reqd_workgroup_size"" sequence of If not 0, 0, 0 then all values; 3 integers must be >=1 and the dispatch; work-group size X, Y, Z must; correspond to the specified; values. Defaults to 0, 0, 0. Corresponds to the OpenCL; ``reqd_work_group_size``; attribute.; "".workgroup_size_hint"" sequence of The dispatch work-group size; 3 integers X, Y, Z is likely to be the; specified values. Corresponds to the OpenCL; ``work_group_size_hint``; attribute.; "".vec_type_hint"" string The name of a scalar or vector; type. Corresponds to the OpenCL; ``vec_type_hint`` attribute. "".device_enqueue_symbol"" string The external symbol name; associated with a kernel.; OpenCL runtime allocates a; global buffer for the symbol; and saves the kernel's address; to it, which is used for; device side enqueueing. Only; available for device side; enqueued kernels.; "".kernarg_segment_size"" integer Required The size in bytes of; the kernarg segment; that holds the values; of the arguments to; the kernel.; "".group_segment_fixed_size"" integer Required The amount of group; segment memory; required by a; work-group in; bytes. This does not; include any; dynamically allocated; group segment memory; that may be added; when the kernel is; dispatched.; "".private_segment_fixed_size"" integer Required The amount of fixed; private address space; memory required for a; work-item in; bytes. If the kernel; uses a dynamic call; stack then additional; space must be added; to this value for the; call stack.; "".kernarg_segment_align"" integer Required The maximum byte; alignment of; arguments in the; kernarg segment. Must; be a power of 2.; "".wavefront_size"" integer Required Wavefront size. Must; be a power of 2.; "".sgpr_count"" integer Required Nu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:133362,allocate,allocates,133362,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocates']
Energy Efficiency," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5569,monitor,monitoring,5569,proof/doc/confman/DatasetStager.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md,4,['monitor'],['monitoring']
Energy Efficiency," is; StringRef. For more information on choosing string containers for APIs, please see; :ref:`Passing Strings <string_apis>`. .. _dss_stringref:. llvm/ADT/StringRef.h; ^^^^^^^^^^^^^^^^^^^^. The StringRef class is a simple value class that contains a pointer to a; character and a length, and is quite related to the :ref:`ArrayRef; <dss_arrayref>` class (but specialized for arrays of characters). Because; StringRef carries a length with it, it safely handles strings with embedded nul; characters in it, getting the length does not require a strlen call, and it even; has very convenient APIs for slicing and dicing the character range that it; represents. StringRef is ideal for passing simple strings around that are known to be live,; either because they are C string literals, std::string, a C array, or a; SmallVector. Each of these cases has an efficient implicit conversion to; StringRef, which doesn't result in a dynamic strlen being executed. StringRef has a few major limitations which make more powerful string containers; useful:. #. You cannot directly convert a StringRef to a 'const char*' because there is; no way to add a trailing nul (unlike the .c_str() method on various stronger; classes). #. StringRef doesn't own or keep alive the underlying string bytes.; As such it can easily lead to dangling pointers, and is not suitable for; embedding in datastructures in most cases (instead, use an std::string or; something like that). #. For the same reason, StringRef cannot be used as the return value of a; method if the method ""computes"" the result string. Instead, use std::string. #. StringRef's do not allow you to mutate the pointed-to string bytes and it; doesn't allow you to insert or remove bytes from the range. For editing; operations like this, it interoperates with the :ref:`Twine <dss_twine>`; class. Because of its strengths and limitations, it is very common for a function to; take a StringRef and for a method on an object to return a StringRef that points; i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:72511,power,powerful,72511,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['power'],['powerful']
Energy Efficiency," it is almost certainly an error if the; constructed object is also the object being copied from. class A {};. void test(A *dst, A *src) {; ::new (dst) A(*dst); // warn (should be 'src'); }. exceptions. Name, DescriptionExampleProgress. exceptions.ThrowSpecButNotThrow; (C++); Function declaration has a throw(type) specifier but the; function do not throw exceptions. void test() throw(int) {; } // warn. exceptions.NoThrowSpecButThrows; (C++); An exception is throw from a function having a throw(); specifier. void test() throw() {; throw(1); // warn; }. exceptions.ThrownTypeDiffersSpec; (C++); The type of a thrown exception differs from those specified in; a throw(type) specifier. struct S{};. void test() throw(int) {; S s;; throw (s); // warn; }. smart pointers. Name, DescriptionExampleProgress. smartptr.SmartPtrInit; (C++); C++03: auto_ptr should store a pointer to an object obtained via; new as allocated memory will be cleaned using delete.; C++11: one should use unique_ptr<type[]> to keep a; pointer to memory allocated by new[].; C++11: to keep a pointer to memory allocated by new[] in; a shared_ptr one should use a custom deleter that calls ; delete[]..; Source: C++03 20.4.5p1; C++11 auto_ptr is deprecated (D.10). #include <stdlib.h>; #include <memory>. void test() {; std::auto_ptr<int> p1(new int); // Ok; std::auto_ptr<int> p2(new int[3]); // warn; }. #include <stdlib.h>; #include <memory>. void test() {; std::auto_ptr<int> p((int *)malloc(sizeof(int))); // warn; }. dead code. Name, DescriptionExampleProgress. deadcode.UnmodifiedVariable; (C, C++); A variable is never modified but was not declared const and is not a; reference.(opt-in checker). extern int computeDelta();. int test(bool cond) {; int i = 0;; if (cond) {; const int delta = computeDelta();; // warn: forgot to modify 'i'; }; return i;; }. PR16890. deadcode.IdempotentOperations; (C); Warn about idempotent operations. void test() {; int x = 7;; x = x; // warn: value is always the same; }. void test() {;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:3670,allocate,allocated,3670,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,1,['allocate'],['allocated']
Energy Efficiency," just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need them to be as efficient as possible. However, no routines in the system; library should actually throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system classifications. To; distinguish which implementation to compile, the code in ``lib/Support`` uses; the ``LLVM_ON_UNIX`` and ``_WIN32`` ``#defines``. Each source file in; ``lib/Support``, after implementing the generic (operating system independent); functionality needs to include the correct implementation using a set of; ``#if defined(LLVM_ON_XYZ)`` directives. For example, if we had; ``lib/Support/Path.cpp``, we'd expect to see in that file:. .. code-block:: c++. #if defined(LLVM_ON_UNIX); #include ""Unix/Path.inc""; #endif; #if defined(_WIN32); #include ""Windows/Path.inc""; #endif. The implementation in ``lib/Support/Unix/Path.inc`` should h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:9768,efficient,efficient,9768,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst,1,['efficient'],['efficient']
Energy Efficiency," linking statically modules that are compiled with and; without SafeStack. An executable compiled with SafeStack can load dynamic; libraries that are not compiled with SafeStack. At the moment, compiling; dynamic libraries with SafeStack is not supported. Signal handlers that use ``sigaltstack()`` must not use the unsafe stack (see; ``__attribute__((no_sanitize(""safe-stack"")))`` below). Programs that use APIs from ``ucontext.h`` are not supported yet. Security; --------. SafeStack protects return addresses, spilled registers and local variables that; are always accessed in a safe way by separating them in a dedicated safe stack; region. The safe stack is automatically protected against stack-based buffer; overflows, since it is disjoint from the unsafe stack in memory, and it itself; is always accessed in a safe way. In the current implementation, the safe stack; is protected against arbitrary memory write vulnerabilities though; randomization and information hiding: the safe stack is allocated at a random; address and the instrumentation ensures that no pointers to the safe stack are; ever stored outside of the safe stack itself (see limitations below). Known security limitations; ~~~~~~~~~~~~~~~~~~~~~~~~~~. A complete protection against control-flow hijack attacks requires combining; SafeStack with another mechanism that enforces the integrity of code pointers; that are stored on the heap or the unsafe stack, such as `CPI; <https://dslab.epfl.ch/research/cpi/>`_, or a forward-edge control flow integrity; mechanism that enforces correct calling conventions at indirect call sites,; such as `IFCC <https://research.google.com/pubs/archive/42808.pdf>`_ with arity; checks. Clang has control-flow integrity protection scheme for :doc:`C++ virtual; calls <ControlFlowIntegrity>`, but not non-virtual indirect calls. With; SafeStack alone, an attacker can overwrite a function pointer on the heap or; the unsafe stack and cause a program to call arbitrary location, which in tur",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst:3398,allocate,allocated,3398,interpreter/llvm-project/clang/docs/SafeStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst,1,['allocate'],['allocated']
Energy Efficiency," mapping small dense integers (or; values that can be mapped to small dense integers) to some other type. It is; internally implemented as a vector with a mapping function that maps the keys; to the dense integer range. This is useful for cases like virtual registers in the LLVM code generator: they; have a dense mapping that is offset by a compile-time constant (the first; virtual register ID). .. _dss_densemap:. llvm/ADT/DenseMap.h; ^^^^^^^^^^^^^^^^^^^. DenseMap is a simple quadratically probed hash table. It excels at supporting; small keys and values: it uses a single allocation to hold all of the pairs; that are currently inserted in the map. DenseMap is a great way to map; pointers to pointers, or map other small types to each other. There are several aspects of DenseMap that you should be aware of, however.; The iterators in a DenseMap are invalidated whenever an insertion occurs,; unlike map. Also, because DenseMap allocates space for a large number of; key/value pairs (it starts with 64 by default), it will waste a lot of space if; your keys or values are large. Finally, you must implement a partial; specialization of DenseMapInfo for the key that you want, if it isn't already; supported. This is required to tell DenseMap about two special marker values; (which can never be inserted into the map) that it needs internally. DenseMap's find_as() method supports lookup operations using an alternate key; type. This is useful in cases where the normal key type is expensive to; construct, but cheap to compare against. The DenseMapInfo is responsible for; defining the appropriate comparison and hashing methods for each alternate key; type used. DenseMap.h also contains a SmallDenseMap variant, that similar to; :ref:`SmallVector <dss_smallvector>` performs no heap allocation until the; number of elements in the template parameter N are exceeded. .. _dss_valuemap:. llvm/IR/ValueMap.h; ^^^^^^^^^^^^^^^^^^^. ValueMap is a wrapper around a :ref:`DenseMap <dss_densemap>` ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:91144,allocate,allocates,91144,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocates']
Energy Efficiency," marking nodes live, accessing/copying graph data that; will be pruned (e.g. metadata that's important for the JIT, but not needed; for the link process). #. Prune (dead-strip) the ``LinkGraph``. Removes all symbols and blocks not reachable from the initial set of live; symbols. This allows JITLink to remove unreachable symbols / content, including; overridden weak and redundant ODR definitions. #. Run post-prune passes. These passes are run on the graph after dead-stripping, but before memory; is allocated or nodes assigned their final target vmaddrs. Passes run at this stage benefit from pruning, as dead functions and data; have been stripped from the graph. However new content can still be added; to the graph, as target and working memory have not been allocated yet. Notable use cases: Building Global Offset Table (GOT), Procedure Linkage; Table (PLT), and Thread Local Variable (TLV) entries. #. Asynchronously allocate memory. Calls the ``JITLinkContext``'s ``JITLinkMemoryManager`` to allocate both; working and target memory for the graph. As part of this process the; ``JITLinkMemoryManager`` will update the addresses of all nodes; defined in the graph to their assigned target address. Note: This step only updates the addresses of nodes defined in this graph.; External symbols will still have null addresses. #. Phase 2. #. Run post-allocation passes. These passes are run on the graph after working and target memory have; been allocated, but before the ``JITLinkContext`` is notified of the; final addresses of the symbols in the graph. This gives these passes a; chance to set up data structures associated with target addresses before; any JITLink clients (especially ORC queries for symbol resolution) can; attempt to access them. Notable use cases: Setting up mappings between target addresses and; JIT data structures, such as a mapping between ``__dso_handle`` and; ``JITDylib*``. #. Notify the ``JITLinkContext`` of the assigned symbol addresses. Calls ``JITLinkContex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:19307,allocate,allocate,19307,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['allocate'],['allocate']
Energy Efficiency," may also ""tie""; themselves to an output constraint, by providing an integer as the constraint; string. Tied inputs still consume an argument from the call instruction, and; take up a position in the asm template numbering as is usual -- they will simply; be constrained to always use the same register as the output they've been tied; to. For example, a constraint string of ""``=r,0``"" says to assign a register for; output, and use that register as an input as well (it being the 0'th; constraint). It is permitted to tie an input to an ""early-clobber"" output. In that case, no; *other* input may share the same register as the input tied to the early-clobber; (even when the other input has the same value). You may only tie an input to an output which has a register constraint, not a; memory constraint. Only a single input may be tied to an output. There is also an ""interesting"" feature which deserves a bit of explanation: if a; register class constraint allocates a register which is too small for the value; type operand provided as input, the input value will be split into multiple; registers, and all of them passed to the inline asm. However, this feature is often not as useful as you might think. Firstly, the registers are *not* guaranteed to be consecutive. So, on those; architectures that have instructions which operate on multiple consecutive; instructions, this is not an appropriate way to support them. (e.g. the 32-bit; SparcV8 has a 64-bit load, which instruction takes a single 32-bit register. The; hardware then loads into both the named register, and the next register. This; feature of inline asm would not be useful to support that.). A few of the targets provide a template string modifier allowing explicit access; to the second register of a two-register operand (e.g. MIPS ``L``, ``M``, and; ``D``). On such an architecture, you can actually access the second allocated; register (yet, still, not any subsequent ones). But, in that case, you're still; probably bet",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:214271,allocate,allocates,214271,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocates']
Energy Efficiency," measurement, fits a bi-dimensional function to it and draws; it together with its x and y projections. Some points of the code will; be explained in detail. This time, the graph is populated with data; points using random numbers, introducing a new and very important; ingredient, the ROOT `TRandom3` random number generator using the; Mersenne Twister algorithm [@MersenneTwister]. ``` {.cpp .numberLines}; @ROOT_INCLUDE_FILE macros/macro4.C; ```. Let's go through the code, step by step to understand what is going on:. - Line *3*: This sets the palette colour code to a much nicer one than; the default. Comment this line to give it a try.; [This article](https://root.cern/blog/rainbow-color-map/); gives more details about colour map choice. - Line *7*: The instance of the random generator. You can then draw; out of this instance random numbers distributed according to; different probability density functions, like the Uniform one at; lines *27-29*. See the on-line documentation to appreciate the full; power of this ROOT feature. - Line *8*: You are already familiar with the `TF1` class. This is; its two-dimensional version. At line *16* two random numbers; distributed according to the `TF2` formula are drawn with the method; `TF2::GetRandom2(double& a, double&b)`. - Line *27-29*: Fitting a 2-dimensional function just works like in; the one-dimensional case, i.e. initialisation of parameters and; calling of the `Fit()` method. - Line *34*: The *Surf1* option draws the `TF2` objects (but also; bi-dimensional histograms) as coloured surfaces with a wire-frame on; three-dimensional canvases. See Figure [4.3](#f43). - Line *35-40*: Retrieve the axis pointer and define the axis titles. - Line *41*: Draw the cloud of points on top of the coloured surface. - Line *43-49*: Here you learn how to create a canvas, partition it in; two sub-pads and access them. It is very handy to show multiple; plots in the same window or image. [f43]: figures/fitted2dFunction.png ""f43""; <a name=""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/graphs.md:3593,power,power,3593,documentation/primer/graphs.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/graphs.md,1,['power'],['power']
Energy Efficiency," metadata section specifies that the module was; compiled with a ``wchar_t`` width of 4 bytes, and the underlying type of an; enum is the smallest type which can represent all of its values::. !llvm.module.flags = !{!0, !1}; !0 = !{i32 1, !""short_wchar"", i32 1}; !1 = !{i32 1, !""short_enum"", i32 0}. Stack Alignment Metadata; ------------------------. Changes the default stack alignment from the target ABI's implicit default; stack alignment. Takes an i32 value in bytes. It is considered an error to link; two modules together with different values for this metadata. For example:. !llvm.module.flags = !{!0}; !0 = !{i32 1, !""override-stack-alignment"", i32 8}. This will change the stack alignment to 8B. Embedded Objects Names Metadata; ===============================. Offloading compilations need to embed device code into the host section table to; create a fat binary. This metadata node references each global that will be; embedded in the module. The primary use for this is to make referencing these; globals more efficient in the IR. The metadata references nodes containing; pointers to the global to be embedded followed by the section name it will be; stored at::. !llvm.embedded.objects = !{!0}; !0 = !{ptr @object, !"".section""}. Automatic Linker Flags Named Metadata; =====================================. Some targets support embedding of flags to the linker inside individual object; files. Typically this is used in conjunction with language extensions which; allow source files to contain linker command line options, and have these; automatically be transmitted to the linker via object files. These flags are encoded in the IR using named metadata with the name; ``!llvm.linker.options``. Each operand is expected to be a metadata node; which should be a list of other metadata nodes, each of which should be a; list of metadata strings defining linker options. For example, the following metadata section specifies two separate sets of; linker options, presumably to link agai",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:335985,efficient,efficient,335985,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['efficient'],['efficient']
Energy Efficiency," modified, then all; load instructions from that set may be hoisted out of the loop. If any alias; sets are stored to **and** are must alias sets, then the stores may be sunk; to outside of the loop, promoting the memory location to a register for the; duration of the loop nest. Both of these transformations only apply if the; pointer argument is loop-invariant. The AliasSetTracker implementation; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The AliasSetTracker class is implemented to be as efficient as possible. It; uses the union-find algorithm to efficiently merge AliasSets when a pointer is; inserted into the AliasSetTracker that aliases multiple sets. The primary data; structure is a hash table mapping pointers to the AliasSet they are in. The AliasSetTracker class must maintain a list of all of the LLVM ``Value*``\s; that are in each AliasSet. Since the hash table already has entries for each; LLVM ``Value*`` of interest, the AliasesSets thread the linked list through; these hash-table nodes to avoid having to allocate memory unnecessarily, and to; make merging alias sets extremely efficient (the linked list merge is constant; time). You shouldn't need to understand these details if you are just a client of the; AliasSetTracker, but if you look at the code, hopefully this brief description; will help make sense of why things are designed the way they are. Using the ``AliasAnalysis`` interface directly; ----------------------------------------------. If neither of these utility class are what your pass needs, you should use the; interfaces exposed by the ``AliasAnalysis`` class directly. Try to use the; higher-level methods when possible (e.g., use mod/ref information instead of the; `alias`_ method directly if possible) to get the best precision and efficiency. Existing alias analysis implementations and clients; ===================================================. If you're going to be working with the LLVM alias analysis infrastructure, you; should know what clients ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:22225,allocate,allocate,22225,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,2,"['allocate', 'efficient']","['allocate', 'efficient']"
Energy Efficiency," more extended, memory region.; - Add `ROOT::Experimental::VecOps::TVec<T>` a class which represents a contiguous array, inspired by Numpy arrays. `TVec` offer a convenient interface, almost identical to the one of `std::vector`. It can own or adopt its memory. As well as a set of tools which make analysis of collections easier, avoiding to loop over the individual elements of the collections. Basic arithmetic operations such as +,-,*,/,% between TVecs and scalars and TVecs are supported. Most popular math functions which act on TVecs are provided. Helpers to calculate basic quantities such as sum, mean, variance or standard deviation of TVecs are provided.; A powerful and concise syntax for expressing cuts is available:; ```; // mu_pts_tvec and mu_etas_tvec are two equally sized TVecs holding kinematic properties of muons; // a filter on muons pseudorapidities is applied considering a range in pseudo rapidity.; filtered_mu_pts_tvec = mu_pts_tvec[abs(mu_etas_tvec) < 2)];; ```; - The `TArrayBranch` class has been removed and replaced by the more powerful `TVec`.; - Columns on disk stored as C arrays should be read as `TVec`s, `std::vector` columns can be read as `TVec`s if requested. Jitted transformations and actions consider `std::vector` columns as well as C array columns `TVec`s.; - In jitted transformations and actions, `std::vector` and C array columns are read as `TVec`s.; - When snapshotting, columns read from trees which are of type `std::vector` or C array and read as TVecs are persistified on disk as a `std::vector` or C arrays respectively - no transformation happens. `TVec` columns, for example coming from `Define`s, are written as `std::vector<T, TAdoptAllocator<T>>`. #### Fixes; - Do not alphabetically order columns before snapshotting to avoid issues when writing C arrays the size of which varies and is stored in a separate branch.; - Validate columns before writing datasets on disk.; - Check the type of the columns via type info in CSV, ROOT and trivi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:9449,power,powerful,9449,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['power'],['powerful']
Energy Efficiency," names using; ``-filter-print-funcs=<function names>``. One great way to visualize what is going on here is to take advantage of a few; LLC command line options. The following options pop up a window displaying the; SelectionDAG at specific times (if you only get errors printed to the console; while using this, you probably `need to configure your; system <ProgrammersManual.html#viewing-graphs-while-debugging-code>`_ to add support for it). * ``-view-dag-combine1-dags`` displays the DAG after being built, before the; first optimization pass. * ``-view-legalize-dags`` displays the DAG before Legalization. * ``-view-dag-combine2-dags`` displays the DAG before the second optimization; pass. * ``-view-isel-dags`` displays the DAG before the Select phase. * ``-view-sched-dags`` displays the DAG before Scheduling. The ``-view-sunit-dags`` displays the Scheduler's dependency graph. This graph; is based on the final SelectionDAG, with nodes that must be scheduled together; bundled into a single scheduling-unit node, and with immediate operands and; other nodes that aren't relevant for scheduling omitted. The option ``-filter-view-dags`` allows to select the name of the basic block; that you are interested to visualize and filters all the previous; ``view-*-dags`` options. .. _Build initial DAG:. Initial SelectionDAG Construction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The initial SelectionDAG is na\ :raw-html:`&iuml;`\ vely peephole expanded from; the LLVM input by the ``SelectionDAGBuilder`` class. The intent of this pass; is to expose as much low-level, target-specific details to the SelectionDAG as; possible. This pass is mostly hard-coded (e.g. an LLVM ``add`` turns into an; ``SDNode add`` while a ``getelementptr`` is expanded into the obvious; arithmetic). This pass requires target-specific hooks to lower calls, returns,; varargs, etc. For these features, the :raw-html:`<tt>` `TargetLowering`_; :raw-html:`</tt>` interface is used. .. _legalize types:; .. _Legalize Selectio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:39794,schedul,scheduled,39794,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,3,['schedul'],"['scheduled', 'scheduling', 'scheduling-unit']"
Energy Efficiency," new internal `RNTupleMerger` class has been added, enabling the merging of different page sources into one page sink. This also means that RNTuples can be merged through `hadd`.; - Zero-copy bulk reading has been added, with extra optimizations for `ROOT::RVec` fields.; - It is now possible to use the `RNTupleView` with an external address with type erasure, e.g.:; ```cpp; std::shared_ptr<void> data{new float()};; auto view = reader->GetView(""pt"", data);; ```; This enables use cases such as reading one specific entry of one specific field into a previously allocated memory location.; - Further integration with [RDataFrame](#rdataframe): it is now possible to create RDataFrame for chains of RNTuples. This addition also comes with improvements to the multi-threaded work scheduling.; - Many additional bug fixes and improvements. Please, report any issues regarding the above mentioned features should you encounter them. RNTuple is still in pre-production. The on-disk format is scheduled to be finalized by the end of 2024. Thus, we appreciate feedback and suggestions for improvement. ## Histogram Libraries. - Implement the FLT_MAX mechanism for `THStack::GetMaximum()` and `THStack::GetMiniumum()`.; - Print a warning when the range given to `TAxis::SetRange` is invalid.; - Fix projection name in `TH3` as requested [here](https://root-forum.cern.ch/t/project3d-letter-d-in-name-option/57612). ## Parallelism; - The ROOT::Experimental::TFuture template has been removed. ## RooFit Libraries. ### New CPU likelihood evaluation backend by default. The new vectorizing CPU evaluation backend is not the default for RooFit likelihoods.; Likelihood minimization is now up to 10x faster on a single CPU core. If you experience unexpected problems related to the likelihood evaluation, you; can revert back to the old backend by passing `RooFit::EvalBackend(""legacy"")`; to `RooAbsPdf::fitTo()` or `RooAbsPdf::createNLL()`. In case you observe any slowdowns with the new likelihood evaluation,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:6491,schedul,scheduled,6491,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['schedul'],['scheduled']
Energy Efficiency," normal returned-continuation lowering, the coroutine may suspend; itself multiple times. This means that a continuation function; itself returns another continuation pointer, as well as a list of; yielded values. The coroutine indicates that it has run to completion by returning; a null continuation pointer. Any yielded values will be `undef`; should be ignored. - In yield-once returned-continuation lowering, the coroutine must; suspend itself exactly once (or throw an exception). The ramp; function returns a continuation function pointer and yielded; values, the continuation function may optionally return ordinary; results when the coroutine has run to completion. The coroutine frame is maintained in a fixed-size buffer that is; passed to the `coro.id` intrinsic, which guarantees a certain size; and alignment statically. The same buffer must be passed to the; continuation function(s). The coroutine will allocate memory if the; buffer is insufficient, in which case it will need to store at; least that pointer in the buffer; therefore the buffer must always; be at least pointer-sized. How the coroutine uses the buffer may; vary between suspend points. In addition to the buffer pointer, continuation functions take an; argument indicating whether the coroutine is being resumed normally; (zero) or abnormally (non-zero). LLVM is currently ineffective at statically eliminating allocations; after fully inlining returned-continuation coroutines into a caller.; This may be acceptable if LLVM's coroutine support is primarily being; used for low-level lowering and inlining is expected to be applied; earlier in the pipeline. Async Lowering; --------------. In async-continuation lowering, signaled by the use of `llvm.coro.id.async`,; handling of control-flow must be handled explicitly by the frontend. In this lowering, a coroutine is assumed to take the current `async context` as; one of its arguments (the argument position is determined by; `llvm.coro.id.async`). It is used to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:6925,allocate,allocate,6925,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['allocate'],['allocate']
Energy Efficiency," not want to be bothered by the following considerations, like; in most other linear algebra packages, just set the tolerance with; `SetTol` to an arbitrary small number. The tolerance number is used by; each decomposition method to decide whether the matrix is near singular,; except of course SVD that can handle singular matrices. This will be; checked in a different way for any decomposition. For instance in LU, a; matrix is considered singular in the solving stage when a diagonal; element of the decomposed matrix is smaller than `fTol`. Here an; important point is raised. The `Decompose()` method is successful as; long no zero diagonal element is encountered. Therefore, the user could; perform decomposition and only after this step worry about the tolerance; number. If the matrix is flagged as being singular, operations with the; decomposition will fail and will return matrices or vectors that are; invalid. If one would like to monitor the tolerance parameter but not; have the code stop in case of a number smaller than `fTol`, one could; proceed as follows:. ``` {.cpp}; TVectorD b = ..;; TMatrixD a = ..;; .; TDecompLU lu(a);; Bool_t ok;; TVectorD x = lu.Solve(b,ok);; Int_t nr = 0;; while (!ok) {; lu.SetMatrix(a);; lu.SetTol(0.1*lu.GetTol());; if (nr++ > 10) break;; x = lu.Solve(b,ok);; }; if (x.IsValid()); cout << ""solved with tol ="" << lu.GetTol() << endl;; else; cout << ""solving failed "" << endl;; ```. The observant reader will notice that by scaling the complete matrix by; some small number the decomposition will detect a singular matrix. In; this case, the user will have to reduce the tolerance number by this; factor. (For CPU time saving we decided not to make this an automatic procedure). ### Condition number. The numerical accuracy of the solution `x` in `Ax = b` can be accurately; estimated by calculating the condition number `k` of matrix $A$, which is defined as:. $k = ||A||_{1}||A^{-1}||_{1}$ where $||A||_{1} = \underset{j}{max}(\sum_{i}|A_{ij}|)$. A g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md:40820,monitor,monitor,40820,documentation/users-guide/LinearAlgebra.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md,1,['monitor'],['monitor']
Energy Efficiency," notion of a ""legal"" vs.; ""illegal"" DAG. A legal DAG for a target is one that only uses supported; operations and supported types. On a 32-bit PowerPC, for example, a DAG with a; value of type i1, i8, i16, or i64 would be illegal, as would a DAG that uses a; SREM or UREM operation. The `legalize types`_ and `legalize operations`_ phases; are responsible for turning an illegal DAG into a legal DAG. .. _SelectionDAG-Process:. SelectionDAG Instruction Selection Process; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. SelectionDAG-based instruction selection consists of the following steps:. #. `Build initial DAG`_ --- This stage performs a simple translation from the; input LLVM code to an illegal SelectionDAG. #. `Optimize SelectionDAG`_ --- This stage performs simple optimizations on the; SelectionDAG to simplify it, and recognize meta instructions (like rotates; and ``div``/``rem`` pairs) for targets that support these meta operations.; This makes the resultant code more efficient and the `select instructions; from DAG`_ phase (below) simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target instruction selector; matches the DAG operations to target instructions. This process translates; the target-independent input DAG into another DAG of target instructions. #. `SelectionDAG Scheduling and Formation`_ --- The last phase assigns a linear; order to the instructions in the target-instruction DAG and emits them into; the MachineFunction",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:37326,efficient,efficient,37326,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['efficient'],['efficient']
Energy Efficiency," object libraries, so we have to trick it into; # linking the static libraries instead.; list(APPEND _DEPS ""-force_load"" ${lib}); else(); list(APPEND _OBJECTS $<TARGET_OBJECTS:obj.${lib}>); endif(); if (BUILD_SHARED_LIBS); # If we are building static libraries, then we don't need to add the static; # libraries as a dependency, because we are already linking against the; # individual object files.; list(APPEND _DEPS $<TARGET_PROPERTY:${lib},INTERFACE_LINK_LIBRARIES>); endif(). # clang libraries are redundant since we are linking all the individual; # object files into libclang-cpp.so, so filter them out from _DEPS.; # This avoids problems with LLVM global data when building with; # BUILD_SHARED_LIBS=ON; # FIXME: We could use list(FILTER) with cmake >= 3.6; # FIXME: With cmake >= 3.15 we could use the generator expression; # $<FILTER:list,INCLUDE|EXCLUDE,regex>; get_target_property(interface ${lib} LINK_LIBRARIES); if (interface); foreach(lib ${interface}); if (NOT ${lib} MATCHES ""^clang""); list(APPEND _DEPS ${lib}); endif(); endforeach(); endif(); endforeach (). if (CLANG_LINK_CLANG_DYLIB); set(INSTALL_WITH_TOOLCHAIN INSTALL_WITH_TOOLCHAIN); endif(). add_clang_library(clang-cpp; SHARED; ${INSTALL_WITH_TOOLCHAIN}; clang-shlib.cpp; ${_OBJECTS}; LINK_LIBS; ${_DEPS}); # Optimize function calls for default visibility definitions to avoid PLT and; # reduce dynamic relocations.; if (NOT APPLE AND NOT MINGW AND NOT LLVM_LINKER_IS_SOLARISLD_ILLUMOS); target_link_options(clang-cpp PRIVATE LINKER:-Bsymbolic-functions); endif(); if (MINGW OR CYGWIN); # The clang-cpp DLL is supposed to export all symbols (except for ones; # that are explicitly hidden). Normally, this is what happens anyway, but; # if there are symbols that are marked explicitly as dllexport, we'd only; # export them and nothing else. Therefore, add --export-all-symbols to; # make sure we export all symbols despite potential dllexports.; target_link_options(clang-cpp PRIVATE LINKER:--export-all-symbols); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-shlib/CMakeLists.txt:1590,reduce,reduce,1590,interpreter/llvm-project/clang/tools/clang-shlib/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-shlib/CMakeLists.txt,1,['reduce'],['reduce']
Energy Efficiency," objected created with a formula expression can have a vectorized signature using `ROOT::Double_v`: `TF1::EvalPar( ROOT::Double_v * x,; double * p)`. The vectorization can then be used to speed-up fitting. It is not enabled by default, but it can be enabled by callig `TF1::SetVectorized(true)` or using the `""VEC""` option in the; constructor of TF1, when ROOT has been built with VecCore and one vectorization library such as Vc. ; - Added new auto-binning algorithm, referred to as `power-2`, which uses power of 2 bin widths to create bins; that are mergeable. The target use-case is support for auto-binning in multi-process or multi-thread execution,; e.g. `TDataFrame`, without the need of a synchronization point.; The new `power-2` algorithm is activated by setting the new `TH1::kAutoBinPTwo` status bit on the histogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats classes have been updated to include the `GlobalObservables` option.; - Remove the `Roo1DMomentMorphFunction` and replace it with `RooMomentMorphFunction` and `RooMomentMorphFunctionND`. ## TMVA Library. - Improvement and fixes in ROCCurve class.; - Add support for event weights in the DNN; - Add in the DNN the option to use a validation data set independent of the training/test set used for training the DNN.; - Add option to suppress correlation outputs; - Improvements in the support for multi-class cla",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:18148,power,power-,18148,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['power'],['power-']
Energy Efficiency," objects this will be a major performance penalty. With such big amount of data one will never achieve higher update rate. The second problem is I/O. To read the first object from the ROOT file, one need to perform several (about 5) file-reading operations via http protocol.; There is no http file locking mechanism (at least not for standard web servers),; therefore there is no guarantee that the file content is not changed/replaced between consequent read operations. Therefore, one should expect frequent I/O failures while trying to monitor data from ROOT binary files. There is a workaround for the problem - one could load the file completely and exclude many partial I/O operations by this. To achieve this with JSROOT, one should add ""+"" sign at the end of the file name. Of course, it only could work for small files. If somebody still wants to use monitoring of data from ROOT files, could try link like:. - <https://root.cern/js/latest/?nobrowser&file=../files/hsimple.root+&item=hpx;1&monitoring=2000>. In this particular case, the histogram is not changing. ## JSROOT API. JSROOT can be used in arbitrary HTML pages to display data, produced with or without ROOT-based applications. Many different examples of JSROOT API usage can be found on [JSROOT API examples](https://root.cern/js/latest/api.htm) page. ### Import JSROOT functionality. Major JSROOT functions are located in `main.mjs` module and can be imported like:. ```javascript; <script type='module'>; import { openFile, draw } from 'https://root.cern/js/latest/modules/main.mjs';; let filename = ""https://root.cern/js/files/hsimple.root"";; let file = await openFile(filename);; let obj = await file.readObject(""hpxpy;1"");; await draw(""drawing"", obj, ""colz"");; </script>; ```. Here the default location `https://root.cern/js/latest/` is specified. One always can install JSROOT on private web server.; When JSROOT is used with THttpServer, the address looks like:. ```javascript; <script type='module'>; import { httpReques",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:33736,monitor,monitoring,33736,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['monitor'],['monitoring']
Energy Efficiency," of class Background (default: 0 = all). V No False − Verbosity (default: true). VerboseLevel No Info Debug, Verbose, Info VerboseLevel (Debug/Verbose/Info). Configuration options for the PDF class :. Configuration options reference for class: PDF. Option Array Default value Predefined values Description. NSmooth No 0 − Number of smoothing iterations for the input histograms. MinNSmooth No -1 − Min number of smoothing iterations, for bins with most data. MaxNSmooth No -1 − Max number of smoothing iterations, for bins with least data. NAvEvtPerBin No 50 − Average number of events per PDF bin. Nbins No 0 − Defined number of bins for the histogram from which the PDF is created. CheckHist No False − Whether or not to check the source histogram of the PDF. PDFInterpol No Spline2 Spline0, Spline1, Spline2, Spline3, Spline5, KDE Interpolation method for reference histograms (e.g. Spline2 or KDE). KDEtype No Gauss Gauss KDE kernel type (1=Gauss). KDEiter No Nonadaptive Nonadaptive, Adaptive Number of iterations (1=non-adaptive, 2=adaptive). KDEFineFactor No 1 − Fine tuning factor for Adaptive KDE: Factor to multyply the width of the kernel. KDEborder No None None, Renorm, Mirror Border effects treatment (1=no treatment , 2=kernel renormalization, 3=sample mirroring). Configuration options for Factory running :. Configuration options reference for class: Factory. Option Array Default value Predefined values Description. V No False − Verbose flag. Color No True − Flag for coloured screen output (default: True, if in batch mode: False). Transformations No − List of transformations to test; formatting example: Transformations=I;D;P;U;G,D, for identity, decorrelation, PCA, Uniform and Gaussianisation followed by decorrelation transformations. Silent No False − Batch mode: boolean silent flag inhibiting any output from TMVA after the creation of the factory class object (default: False). DrawProgressBar No True − Draw progress bar to display training, testing and evaluation sched",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:34300,adapt,adaptive,34300,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['adapt'],['adaptive']
Energy Efficiency," of the existence of ROOT's interactive features and use; them if you find them convenient. Some trial-and-error is certainly necessary; to find your way through the huge number of menus and parameter; settings. ## ROOT Beginners' FAQ ##. At this point of the guide, some basic questions could have already come; to your mind. We will try to clarify some of them with further; explanations in the following. ### ROOT type declarations for basic data types ###. In the official ROOT documentation, you find special data types; replacing the normal ones, e.g. `Double_t`, `Float_t` or `Int_t`; replacing the standard `double`, `float` or `int` types. Using the ROOT; types makes it easier to port code between platforms (64/32 bit) or; operating systems (windows/Linux), as these types are mapped to suitable; ones in the ROOT header files. If you want adaptive code of this type,; use the ROOT type declarations. However, usually you do not need such; adaptive code, and you can safely use the standard C type declarations; for your private code, as we did and will do throughout this guide. If; you intend to become a ROOT developer, however, you better stick to the; official coding rules!. ### Configure ROOT at start-up ###. The behaviour of a ROOT session can be tailored with the options in the; `.rootrc` file. Examples of the tunable parameters are the ones related; to the operating and window system, to the fonts to be used, to the; location of start-up files. At start-up, ROOT looks for a `.rootrc` file; in the following order:. - `./.rootrc //local directory`. - `$HOME/.rootrc //user directory`. - `$ROOTSYS/etc/system.rootrc //global ROOT directory`. If more than one `.rootrc` files are found in the search paths above,; the options are merged, with precedence local, user, global. The parsing; and interpretation of this file is handled by the ROOT class `TEnv`.; Have a look to its documentation if you need such rather advanced; features. The file `.rootrc` defines the location of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md:17633,adapt,adaptive,17633,documentation/primer/ROOT_as_calculator.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md,1,['adapt'],['adaptive']
Energy Efficiency," of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.mul``' intrinsic performs the integer ``MUL`` reduction; (:ref:`llvm.vector.reduce.mul <int_vector_reduce_mul>`) of the vector operand ``val``; on each enabled lane, multiplying it by the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``1`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is the; start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.mul.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 1, i32 1, i32 1, i32 1>; %reduction = call i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %masked.a); %also.r = mul i32 %reduction, %start. .. _int_vp_reduce_fmul:. '``llvm.vp.reduce.fmul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmul.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fmul.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MUL`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first op",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:754037,reduce,reduce,754037,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," of the volume containing the point; one level down, printing the path to the deepest physical node holding; this point. It also computes the closest distance to any boundary. ![Random points](pictures/030001E1.png). A method to check the validity of a given geometry is shooting random; points. This can be called with the method; **`TGeoVolume`**`::RandomPoints()` and it draws a volume with the current; visualization settings. Random points are generated in the bounding box; of the drawn volume. The points are drawn with the color of their; deepest container. Only points inside visible nodes are drawn. ![Random rays](pictures/030001E2.png). A ray tracing method can be called `TGeoVolume::RandomRays()`. This; shoots rays from a given point in the local reference frame with random; directions. The intersections with displayed nodes appear as segments; having the color of the touched node. ## The Drawing Package. ![](pictures/030001E3.png)The modeller provides a powerful drawing; package, supporting several different options of visualization. A; library separated from the main one provides all functionality being; linked with the underlying ROOT visualization system. This library is; dynamically loaded by the plug-in manager only when drawing features are; requested. The geometrical structures that can be visualized are volumes; and volume hierarchies. The main component of the visualization system is volume primitive; painting in a ROOT pad. Starting from this one, several specific options; or subsystems are available, like: X3D viewing using hidden line and; surface removal algorithms, OpenGL viewing\* or ray tracing. The method `TGeoManager::GetGeomPainter()`loads the painting library in; memory. This is generally not needed since it is called automatically by; `TGeoVolume::Draw()` as well as by few other methods setting; visualization attributes. ### Drawing Volumes and Hierarchies of Volumes. The first thing one would like to do after building some geometry is to; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:136427,power,powerful,136427,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['power'],['powerful']
Energy Efficiency," of this instruction for gfx11 targets. llvm.amdgcn.sudot4 Provides direct access to v_dot4_i32_iu8 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42592,schedul,scheduled,42592,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency," of using or redistributing the Work and assume any; risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory,; whether in tort (including negligence), contract, or otherwise,; unless required by applicable law (such as deliberate and grossly; negligent acts) or agreed to in writing, shall any Contributor be; liable to You for damages, including any direct, indirect, special,; incidental, or consequential damages of any character arising as a; result of this License or out of the use or inability to use the; Work (including but not limited to damages for loss of goodwill,; work stoppage, computer failure or malfunction, or any and all; other commercial damages or losses), even if such Contributor; has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing; the Work or Derivative Works thereof, You may choose to offer,; and charge a fee for, acceptance of support, warranty, indemnity,; or other liability obligations and/or rights consistent with this; License. However, in accepting such obligations, You may act only; on Your own behalf and on Your sole responsibility, not on behalf; of any other Contributor, and only if You agree to indemnify,; defend, and hold each Contributor harmless for any liability; incurred by, or claims asserted against, such Contributor by reason; of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS. APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following; boilerplate notice, with the fields enclosed by brackets ""[]""; replaced with your own identifying information. (Don't include; the brackets!) The text should be enclosed in the appropriate; comment syntax for the file format. We also recommend that a; file or class name and description of purpose be included on the; same ""printed page"" as the copyright n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT:8946,charge,charge,8946,interpreter/llvm-project/clang/LICENSE.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT,4,['charge'],['charge']
Energy Efficiency," of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebF",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:24050,adapt,adapter,24050,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['adapt'],['adapter']
Energy Efficiency," on the `TLegend` object is 0, then the `gStyle` value is; used to draw the legend text. If the text size directly set on the `TLegend`; object is not null, then it is used to draw the legend text. ### TTexDump. - The hollow fill style was not rendered correctly.; (see https://sft.its.cern.ch/jira/browse/ROOT-6841); - Better line width matching with screen and pdf output.; - Text color was ignored. It was always black.; - Text color was ignored. It was always black.; - The underscore `_` produced an error outside the TeX math context.; - Fix an issue with transparent pads.; - Implement transparent colors using TiKZ ""opacity"".; - Implement `TStyle::SetLineScalePS()` to control le global basic line width.; - Offer 0 as line width option. Useful to make a line invisible. ### TPostScript. - Small fix for fill patterns 1, 2 and 3.; - With `TMathtext`, only the fonts really used are now loaded in the PostScript; file. Typically it reduces the file size by a factor 10 (compare to the previous; implementation) for normal plots with math formulae and greek characters.; - Offer 0 as line width option. Useful to make a line invisible. ### TPDF. - When a text size was equal or smaller than 0 the PDF file was corrupted.; - Small fix for fill patterns 1, 2 and 3.; - When printing a coloured 2D histograms (with option COLZ) into a PDF or PostScript; file, the preview on screen using many standard PDF previewer tools showed very; thin white lines between the bins as well as in the color palette.; This made very ugly the final output.; This problem is due to bad implementation of anti-aliasing in these previewers.; A way to bypass this issue was to turn off the anti-aliasing in the previewer; but then the rest of the document does not look nice. This problem is now bypassed; with a fix in both PDF and PostScript output.; - Offer 0 as line width option. Useful to make a line invisible. ### TSVG. - Use float numbers instead of integer to describe graphics paths to avoid; rounding prob",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:21876,reduce,reduces,21876,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['reduce'],['reduces']
Energy Efficiency," one or more talks. You do; not have to stick to one format forever.; * Whatever format you choose, `LLVM Weekly <http://llvmweekly.org/>`_ is an; excellent topic starter: go through the 3-4 recent LLVM Weekly posts and; prepare a list of the most interesting/notable news and discuss them with the; group. Advertisement; -------------. * Try to advertise via similar meetups/user groups; * Advertise your meetup on the mailing lists (llvm-dev, cfe-dev, lldb-dev,; ...). Feel free to post to all of them, or at least to llvm-dev.; But as these mailing lists have high traffic and some LLVM developers are not; very active on them, you may reach more interested people using the mailing; feature from meetup.com.; * Advertise the meetup on Twitter and mention; `@llvmweekly <http://twitter.com/llvmweekly>`_ and; `@llvmorg <http://twitter.com/llvmorg>`_.; * Announce the next meetup in advance, and remind in one week or so. Tech talks; ----------. * It’s a great idea to have several talks scheduled for several upcoming; meetups to get the ball rolling.; * Keep looking for speakers far in advance, ideally you should have 2-3; speakers ready in the pipeline.; * Try to record the talks if possible. It adds visibility to the meetup and; just a good idea in general. Any modern smartphone or tablet should work, but; you can also get a camera. Though, it is recommended to get an external; microphone for better sound. Where to host the meetup?; -------------------------. * Look around for bars/café with projectors.; * Talk to tech companies in the area.; * Some co-working spaces provide their facilities for non-profit (i.e., you do; not charge attendees any fees) meetups.; * Ask nearby universities or university departments. How to pick the date?; ---------------------. * Make sure you do not clash with the similar meetups in the city (e.g.,; C++ user groups).; * Prefer not to have a meetup the same week when the other similar meetups; happen (e.g., it’s not a good idea to have LLVM meetu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MeetupGuidelines.rst:2247,schedul,scheduled,2247,interpreter/llvm-project/llvm/docs/MeetupGuidelines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MeetupGuidelines.rst,1,['schedul'],['scheduled']
Energy Efficiency," operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umax``' intrinsic performs the unsigned-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.umax <int_vector_reduce_umax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``0`` (i.e. having no effect on the reduction operation). If the; vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umax.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umax.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_umin:. '``llvm.vp.reduce.umin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vecto",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:768795,reduce,reduce,768795,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," optin.portability.UnixAPI; """"""""""""""""""""""""""""""""""""""""""""""""""; Finds implementation-defined behavior in UNIX/Posix functions. .. _security-checkers:. security; ^^^^^^^^. Security related checkers. .. _security-cert-env-InvalidPtr:. security.cert.env.InvalidPtr; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Corresponds to SEI CERT Rules `ENV31-C <https://wiki.sei.cmu.edu/confluence/display/c/ENV31-C.+Do+not+rely+on+an+environment+pointer+following+an+operation+that+may+invalidate+it>`_ and `ENV34-C <https://wiki.sei.cmu.edu/confluence/display/c/ENV34-C.+Do+not+store+pointers+returned+by+certain+functions>`_. * **ENV31-C**:; Rule is about the possible problem with ``main`` function's third argument, environment pointer,; ""envp"". When environment array is modified using some modification function; such as ``putenv``, ``setenv`` or others, It may happen that memory is reallocated,; however ""envp"" is not updated to reflect the changes and points to old memory; region. * **ENV34-C**:; Some functions return a pointer to a statically allocated buffer.; Consequently, subsequent call of these functions will invalidate previous; pointer. These functions include: ``getenv``, ``localeconv``, ``asctime``, ``setlocale``, ``strerror``. .. code-block:: c. int main(int argc, const char *argv[], const char *envp[]) {; if (setenv(""MY_NEW_VAR"", ""new_value"", 1) != 0) {; // setenv call may invalidate 'envp'; /* Handle error */; }; if (envp != NULL) {; for (size_t i = 0; envp[i] != NULL; ++i) {; puts(envp[i]);; // envp may no longer point to the current environment; // this program has unanticipated behavior, since envp; // does not reflect changes made by setenv function.; }; }; return 0;; }. void previous_call_invalidation() {; char *p, *pp;. p = getenv(""VAR"");; setenv(""SOMEVAR"", ""VALUE"", /*overwrite = */1);; // call to 'setenv' may invalidate p. *p;; // dereferencing invalid pointer; }. The ``InvalidatingGetEnv`` option is available for treating ``getenv`` calls as; invalidating. When enabled, the checke",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:20653,allocate,allocated,20653,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['allocate'],['allocated']
Energy Efficiency," option is not to vectorize at all, the; vectorization process terminates before reaching Step 3, and compilation; should proceed as if VPlans had not been built. 2. Align Cost & Execute: each VPlan must support both estimating the cost and; generating the output IR code, such that the cost estimation evaluates the; to-be-generated code reliably. 3. Support vectorizing additional constructs:. a. Outer-loop vectorization. In particular, VPlan must be able to model the; control-flow of the output IR which may include multiple basic-blocks and; nested loops.; b. SLP vectorization.; c. Combinations of the above, including nested vectorization: vectorizing; both an inner loop and an outer-loop at the same time (each with its own; VF and UF), mixed vectorization: vectorizing a loop with SLP patterns; inside [4]_, (re)vectorizing input IR containing vector code.; d. Function vectorization [2]_. 4. Support multiple candidates efficiently. In particular, similar candidates; related to a range of possible VF's and UF's must be represented efficiently.; Potential versioning needs to be supported efficiently. 5. Support vectorizing idioms, such as interleaved groups of strided loads or; stores. This is achieved by modeling a sequence of output instructions using; a ""Recipe"", which is responsible for computing its cost and generating its; code. 6. Encapsulate Single-Entry Single-Exit regions (SESE). During vectorization; such regions may need to be, for example, predicated and linearized, or; replicated VF*UF times to handle scalarized and predicated instructions.; Innerloops are also modelled as SESE regions. 7. Support instruction-level analysis and transformation, as part of Planning; Step 2.b: During vectorization instructions may need to be traversed, moved,; replaced by other instructions or be created. For example, vector idiom; detection and formation involves searching for and optimizing instruction; patterns. Definitions; ===========; The low-level design of VPlan compr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:3058,efficient,efficiently,3058,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,1,['efficient'],['efficiently']
Energy Efficiency," or Legal Entity authorized to submit on behalf of; the copyright owner. For the purposes of this definition, ""submitted""; means any form of electronic, verbal, or written communication sent; to the Licensor or its representatives, including but not limited to; communication on electronic mailing lists, source code control systems,; and issue tracking systems that are managed by, or on behalf of, the; Licensor for the purpose of discussing and improving the Work, but; excluding communication that is conspicuously marked or otherwise; designated in writing by the copyright owner as ""Not a Contribution."". ""Contributor"" shall mean Licensor and any individual or Legal Entity; on behalf of whom a Contribution has been received by Licensor and; subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of; this License, each Contributor hereby grants to You a perpetual,; worldwide, non-exclusive, no-charge, royalty-free, irrevocable; copyright license to reproduce, prepare Derivative Works of,; publicly display, publicly perform, sublicense, and distribute the; Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of; this License, each Contributor hereby grants to You a perpetual,; worldwide, non-exclusive, no-charge, royalty-free, irrevocable; (except as stated in this section) patent license to make, have made,; use, offer to sell, sell, import, and otherwise transfer the Work,; where such license applies only to those patent claims licensable; by such Contributor that are necessarily infringed by their; Contribution(s) alone or by combination of their Contribution(s); with the Work to which such Contribution(s) was submitted. If You; institute patent litigation against any entity (including a; cross-claim or counterclaim in a lawsuit) alleging that the Work; or a Contribution incorporated within the Work constitutes direct; or contributory patent infrin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT:3558,charge,charge,3558,interpreter/llvm-project/clang/LICENSE.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT,4,['charge'],['charge']
Energy Efficiency," or Twine as a scratch buffer, but then use std::string to persist; the result. .. _ds_set:. Set-Like Containers (std::set, SmallSet, SetVector, etc); --------------------------------------------------------. Set-like containers are useful when you need to canonicalize multiple values; into a single representation. There are several different choices for how to do; this, providing various trade-offs. .. _dss_sortedvectorset:. A sorted 'vector'; ^^^^^^^^^^^^^^^^^. If you intend to insert a lot of elements, then do a lot of queries, a great; approach is to use an std::vector (or other sequential container) with; std::sort+std::unique to remove duplicates. This approach works really well if; your usage pattern has these two distinct phases (insert then query), and can be; coupled with a good choice of :ref:`sequential container <ds_sequential>`. This combination provides the several nice properties: the result data is; contiguous in memory (good for cache locality), has few allocations, is easy to; address (iterators in the final vector are just indices or pointers), and can be; efficiently queried with a standard binary search (e.g.; ``std::lower_bound``; if you want the whole range of elements comparing; equal, use ``std::equal_range``). .. _dss_smallset:. llvm/ADT/SmallSet.h; ^^^^^^^^^^^^^^^^^^^. If you have a set-like data structure that is usually small and whose elements; are reasonably small, a ``SmallSet<Type, N>`` is a good choice. This set has; space for N elements in place (thus, if the set is dynamically smaller than N,; no malloc traffic is required) and accesses them with a simple linear search.; When the set grows beyond N elements, it allocates a more expensive; representation that guarantees efficient access (for most types, it falls back; to :ref:`std::set <dss_set>`, but for pointers it uses something far better,; :ref:`SmallPtrSet <dss_smallptrset>`. The magic of this class is that it handles small sets extremely efficiently, but; gracefully handles",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:77711,efficient,efficiently,77711,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficiently']
Energy Efficiency," parallel writes, e.g. in object storages. - Large read/write throughput improvements in the experimental Intel DAOS backend. - `RNTupleWriter::Fill()` now returns the number of uncompressed bytes written, which is align with TTree behavior. - Support for user-defined classes that behave as a collection via the `TVirtualCollectionProxy` interface.; Fields created via `RFieldBase::Create()` automatically detect the presence of a collection proxy at run-time. However, if `RField<T>` (`T` being a class) is used instead, the trait `IsCollectionProxy<T>` must be set for the given type (see PR [#11525](https://github.com/root-project/root/pull/11525) for details).; Note that associative collections are not yet supported. - Some internal support for per field post-read callbacks. This functionality will be presented in upcoming releases through custom I/O rules. Please, report any issues regarding the abovementioned features should you encounter them.; RNTuple is still experimental and is scheduled to become production grade in 2024. Thus, we appreciate feedback and suggestions for improvement. ## RDataFrame. ### New features. - Add [`GraphAsymmErrors`](https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#acea30792eef607489d498bf6547a00a6) action that fills a TGraphAsymmErrors object.; - Introduce [`RDatasetSpec`](https://root.cern/doc/master/classROOT_1_1RDF_1_1Experimental_1_1RDatasetSpec.html) as an; experimental class to specify the input dataset to an RDataFrame.; - Arbitrary metadata can be associated to the samples in the dataset specified via `RDatasetSpect`. The metadata of each; sample can then be retrieved during the execution by calling `DefinePerSample`.; - Users can create an RDataFrame with a dataset specification written in a JSON file via the factory function; [ROOT::RDF::Experimental::FromSpec](https://root.cern/doc/master/namespaceROOT_1_1RDF_1_1Experimental.html#a7193987f3c1b65c649399656cc6acce8). ### Notable bug fixes and improvements. - Fi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:10568,schedul,scheduled,10568,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,1,['schedul'],['scheduled']
Energy Efficiency," pattern follows a strict insert-then-query approach, you can; trivially use the same approach as :ref:`sorted vectors for set-like containers; <dss_sortedvectorset>`. The only difference is that your query function (which; uses std::lower_bound to get efficient log(n) lookup) should only compare the; key, not both the key and value. This yields the same advantages as sorted; vectors for sets. .. _dss_stringmap:. llvm/ADT/StringMap.h; ^^^^^^^^^^^^^^^^^^^^. Strings are commonly used as keys in maps, and they are difficult to support; efficiently: they are variable length, inefficient to hash and compare when; long, expensive to copy, etc. StringMap is a specialized container designed to; cope with these issues. It supports mapping an arbitrary range of bytes to an; arbitrary other object. The StringMap implementation uses a quadratically-probed hash table, where the; buckets store a pointer to the heap allocated entries (and some other stuff).; The entries in the map must be heap allocated because the strings are variable; length. The string data (key) and the element object (value) are stored in the; same allocation with the string data immediately after the element object.; This container guarantees the ""``(char*)(&Value+1)``"" points to the key string; for a value. The StringMap is very fast for several reasons: quadratic probing is very cache; efficient for lookups, the hash value of strings in buckets is not recomputed; when looking up an element, StringMap rarely has to touch the memory for; unrelated objects when looking up a value (even when hash collisions happen),; hash table growth does not recompute the hash values for strings already in the; table, and each pair in the map is store in a single allocation (the string data; is stored in the same allocation as the Value of a pair). StringMap also provides query methods that take byte ranges, so it only ever; copies a string if a value is inserted into the table. StringMap iteration order, however, is not guar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:89003,allocate,allocated,89003,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocated']
Energy Efficiency," performance; issues. Given an assembly code sequence, :program:`llvm-mca` estimates the Instructions; Per Cycle (IPC), as well as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-mca` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-mca` will send its output; to standard output if the input is from standard input. If the :option:`-o`; option specifies ""``-``"", then the output will also be sent to standard output. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Use ``<filename>`` as the output filename. See the summary above for more; details. .. option:: -mtriple=<target triple>. Specify a target triple string. .. option:: -march=<arch>. Specify the architecture for which to analyze the code. It defaults to the; host defaul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:1772,schedul,scheduling,1772,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency," performed correctly. Otherwise, however, ARC requires; programmer cooperation to establish its initialization invariants; because it is infeasible for ARC to dynamically infer whether they; are intact. For example, there is no syntactic difference in C between; an assignment that is intended by the programmer to initialize a variable; and one that is intended to replace the existing value stored there,; but ARC must perform one operation or the other. ARC chooses to always; assume that objects are initialized (except when it is in charge of; initializing them) because the only workable alternative would be to; ban all code patterns that could potentially be used to access; uninitialized memory, and that would be too limiting. In practice,; this is rarely a problem because programmers do not generally need to; work with objects for which the requirements are not handled; automatically. Note that dynamically-allocated Objective-C++ arrays of; nontrivially-ownership-qualified type are not ABI-compatible with non-ARC; code because the non-ARC code will consider the element type to be POD.; Such arrays that are ``new[]``'d in ARC translation units cannot be; ``delete[]``'d in non-ARC translation units and vice-versa. .. _arc.ownership.restrictions.pass_by_writeback:. Passing to an out parameter by writeback; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If the argument passed to a parameter of type ``T __autoreleasing *`` has type; ``U oq *``, where ``oq`` is an ownership qualifier, then the argument is a; candidate for :arc-term:`pass-by-writeback`` if:. * ``oq`` is ``__strong`` or ``__weak``, and; * it would be legal to initialize a ``T __strong *`` with a ``U __strong *``. For purposes of overload resolution, an implicit conversion sequence requiring; a pass-by-writeback is always worse than an implicit conversion sequence not; requiring a pass-by-writeback. The pass-by-writeback is ill-formed if the argument expression does not have a; legal form:. * ``&var``, where ``v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:48069,allocate,allocated,48069,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['allocate'],['allocated']
Energy Efficiency," permits efficient compilation (important for JIT environments) and; aggressive optimization (used when generating code offline) by allowing; components of varying levels of sophistication to be used for any step of; compilation. In addition to these stages, target implementations can insert arbitrary; target-specific passes into the flow. For example, the X86 target uses a; special pass to handle the 80x87 floating point stack architecture. Other; targets with unusual requirements can be supported with custom passes as needed. Using TableGen for target description; -------------------------------------. The target description classes require a detailed description of the target; architecture. These target descriptions often have a large amount of common; information (e.g., an ``add`` instruction is almost identical to a ``sub``; instruction). In order to allow the maximum amount of commonality to be; factored out, the LLVM code generator uses the; :doc:`TableGen/index` tool to describe big chunks of the; target machine, which allows the use of domain-specific and target-specific; abstractions to reduce the amount of repetition. As LLVM continues to be developed and refined, we plan to move more and more of; the target description to the ``.td`` form. Doing so gives us a number of; advantages. The most important is that it makes it easier to port LLVM because; it reduces the amount of C++ code that has to be written, and the surface area; of the code generator that needs to be understood before someone can get; something working. Second, it makes it easier to change things. In particular,; if tables and other things are all emitted by ``tblgen``, we only need a change; in one place (``tblgen``) to update all of the targets to a new interface. .. _Abstract target description:; .. _target description:. Target description classes; ==========================. The LLVM target description classes (located in the ``include/llvm/Target``; directory) provide an abstract descr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:8712,reduce,reduce,8712,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['reduce'],['reduce']
Energy Efficiency," pointee types; outweight the benefits, and that they should be removed. Many operations do not actually care about the underlying type. These; operations, typically intrinsics, usually end up taking an arbitrary pointer; type ``i8*`` and sometimes a size. This causes lots of redundant no-op bitcasts; in the IR to and from a pointer with a different pointee type. No-op bitcasts take up memory/disk space and also take up compile time to look; through. However, perhaps the biggest issue is the code complexity required to; deal with bitcasts. When looking up through def-use chains for pointers it's; easy to forget to call `Value::stripPointerCasts()` to find the true underlying; pointer obfuscated by bitcasts. And when looking down through def-use chains; passes need to iterate through bitcasts to handle uses. Removing no-op pointer; bitcasts prevents a category of missed optimizations and makes writing LLVM; passes a little bit easier. Fewer no-op pointer bitcasts also reduces the chances of incorrect bitcasts in; regards to address spaces. People maintaining backends that care a lot about; address spaces have complained that frontends like Clang often incorrectly; bitcast pointers, losing address space information. An analogous transition that happened earlier in LLVM is integer signedness.; Currently there is no distinction between signed and unsigned integer types, but; rather each integer operation (e.g. add) contains flags to signal how to treat; the integer. Previously LLVM IR distinguished between unsigned and signed; integer types and ran into similar issues of no-op casts. The transition from; manifesting signedness in types to instructions happened early on in LLVM's; timeline to make LLVM easier to work with. Opaque Pointers Mode; ====================. During the transition phase, LLVM can be used in two modes: In typed pointer; mode all pointer types have a pointee type and opaque pointers cannot be used.; In opaque pointers mode (the default), all pointers",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst:4380,reduce,reduces,4380,interpreter/llvm-project/llvm/docs/OpaquePointers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst,1,['reduce'],['reduces']
Energy Efficiency," process. The default pipeline implements the following sequence of stages used to; process instructions. * Dispatch (Instruction is dispatched to the schedulers).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers that are; globally available for register renaming by using the command option; ``-register-file-size``. A value of zero for this option means *unbounded*. By; knowing how many registers are available ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:35088,schedul,schedulers,35088,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['schedulers']
Energy Efficiency," project, which also compiles executables; requiring their own ``main`` symbol, it may be desirable to request just the; instrumentation without linking::. clang -fsanitize=fuzzer-no-link mytarget.c. Then libFuzzer can be linked to the desired driver by passing in; ``-fsanitize=fuzzer`` during the linking stage. .. _libfuzzer-corpus:. Corpus; ------. Coverage-guided fuzzers like libFuzzer rely on a corpus of sample inputs for the; code under test. This corpus should ideally be seeded with a varied collection; of valid and invalid inputs for the code under test; for example, for a graphics; library the initial corpus might hold a variety of different small PNG/JPG/GIF; files. The fuzzer generates random mutations based around the sample inputs in; the current corpus. If a mutation triggers execution of a previously-uncovered; path in the code under test, then that mutation is saved to the corpus for; future variations. LibFuzzer will work without any initial seeds, but will be less; efficient if the library under test accepts complex,; structured inputs. The corpus can also act as a sanity/regression check, to confirm that the; fuzzing entrypoint still works and that all of the sample inputs run through; the code under test without problems. If you have a large corpus (either generated by fuzzing or acquired by other means); you may want to minimize it while still preserving the full coverage. One way to do that; is to use the `-merge=1` flag:. .. code-block:: console. mkdir NEW_CORPUS_DIR # Store minimized corpus here.; ./my_fuzzer -merge=1 NEW_CORPUS_DIR FULL_CORPUS_DIR. You may use the same flag to add more interesting items to an existing corpus.; Only the inputs that trigger new coverage will be added to the first corpus. .. code-block:: console. ./my_fuzzer -merge=1 CURRENT_CORPUS_DIR NEW_POTENTIALLY_INTERESTING_INPUTS_DIR. Running; -------. To run the fuzzer, first create a Corpus_ directory that holds the; initial ""seed"" sample inputs:. .. code-block:: consol",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:4701,efficient,efficient,4701,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['efficient'],['efficient']
Energy Efficiency," properties. Another hook for material shading properties is currently; not in use. Mixtures are materials made of several elements. They are; represented by the class **`TGeoMixture`**, deriving from; **`TGeoMaterial`** and defined by their number of components and the; density:. ``` {.cpp}; TGeoMixture(const char *name,Int_t nel,Double_t rho);; ```. Elements have to be further defined one by one:. ``` {.cpp}; void TGeoMixture::DefineElement(Int_t iel,Double_t a,Double_t z,; Double_t weigth);; void TGeoMixture::DefineElement(Int_t iel, TGeoElement *elem,; Double_t weight);; void TGeoMixture::DefineElement(Int_t iel, Int_t z, Int_t natoms);; ```. or:. ``` {.cpp}; void AddElement(TGeoMaterial* mat, Double_t weight);; void AddElement(TGeoElement* elem, Double_t weight);; void AddElement(TGeoElement* elem, Int_t natoms);; void AddElement(Double_t a, Double_t z, Double_t weight); ```. - `iel:` index of the element` [0,nel-1]`; - `a` and `z:` the atomic mass and charge; - `weight:` proportion by mass of the elements; - `natoms`: number of atoms of the element in the molecule making the; mixture. The radiation length is automatically computed when all elements are; defined. Since tracking MC provide several other ways to create; materials/mixtures, the materials classes are likely to evolve as the; interfaces to these engines are being developed. Generally in the; process of tracking material properties are not enough and more specific; media properties have to be defined. These highly depend on the MC; performing tracking and sometimes allow the definition of different; media properties (e.g. energy or range cuts) for the same material. ### Radionuclides. A new class **`TGeoElementRN`** was introduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (**`TGeoElementTable`** class). One can make then materials/mixtures; based on these radionuclides and use the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:16789,charge,charge,16789,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['charge'],['charge']
Energy Efficiency," quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11330,reduce,reduce,11330,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['reduce'],['reduce']
Energy Efficiency," result is a condition; that is used by the conditional branch controlling the loop. Vector Reduction Intrinsics; ---------------------------. Horizontal reductions of vectors can be expressed using the following; intrinsics. Each one takes a vector operand as an input and applies its; respective operation across all elements of the vector, returning a single; scalar result of the same element type. .. _int_vector_reduce_add:. '``llvm.vector.reduce.add.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.add.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.add.*``' intrinsics do an integer ``ADD``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fadd:. '``llvm.vector.reduce.fadd.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fadd.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fadd.*``' intrinsics do a floating-point; ``ADD`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. Otherwise; the reduction will be *sequential*, thus implying that the operation respects; the associativity of a scalarized reduction. That is, the reduction begins with; the start value and performs an fadd operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fadd(start_value, input_vector); result = start_value;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:650951,reduce,reduce,650951,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," return 1;; }; CommonOptionsParser& OptionsParser = ExpectedParser.get();; ClangTool Tool(OptionsParser.getCompilations(),; OptionsParser.getSourcePathList());; return Tool.run(newFrontendActionFactory<clang::SyntaxOnlyAction>().get());; }. And that's it! You can compile our new tool by running ninja from the; ``build`` directory. .. code-block:: console. cd ~/clang-llvm/build; ninja. You should now be able to run the syntax checker, which is located in; ``~/clang-llvm/build/bin``, on any source file. Try it!. .. code-block:: console. echo ""int main() { return 0; }"" > test.cpp; bin/loop-convert test.cpp --. Note the two dashes after we specify the source file. The additional; options for the compiler are passed after the dashes rather than loading; them from a compilation database - there just aren't any options needed; right now. Intermezzo: Learn AST matcher basics; ====================================. Clang recently introduced the :doc:`ASTMatcher; library <LibASTMatchers>` to provide a simple, powerful, and; concise way to describe specific patterns in the AST. Implemented as a; DSL powered by macros and templates (see; `ASTMatchers.h <../doxygen/ASTMatchers_8h_source.html>`_ if you're; curious), matchers offer the feel of algebraic data types common to; functional programming languages. For example, suppose you wanted to examine only binary operators. There; is a matcher to do exactly that, conveniently named ``binaryOperator``.; I'll give you one guess what this matcher does:. .. code-block:: c++. binaryOperator(hasOperatorName(""+""), hasLHS(integerLiteral(equals(0)))). Shockingly, it will match against addition expressions whose left hand; side is exactly the literal 0. It will not match against other forms of; 0, such as ``'\0'`` or ``NULL``, but it will match against macros that; expand to 0. The matcher will also not match against calls to the; overloaded operator ``'+'``, as there is a separate ``operatorCallExpr``; matcher to handle overloaded operators.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst:5800,power,powerful,5800,interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,1,['power'],['powerful']
Energy Efficiency," returns. After :ref:`llvm.lifetime.end <int_lifeend>` is called,; '``llvm.lifetime.start``' on the stack object can be called again.; The second '``llvm.lifetime.start``' call marks the object as alive, but it; does not change the address of the object. If ``ptr`` is a non-stack-allocated object, it does not point to the first; byte of the object or it is a stack object that is already alive, it simply; fills all bytes of the object with ``poison``. .. _int_lifeend:. '``llvm.lifetime.end``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.lifetime.end(i64 <size>, ptr nocapture <ptr>). Overview:; """""""""""""""""". The '``llvm.lifetime.end``' intrinsic specifies the end of a memory object's; lifetime. Arguments:; """""""""""""""""""". The first argument is a constant integer representing the size of the; object, or -1 if it is variable sized. The second argument is a pointer; to the object. Semantics:; """""""""""""""""""". If ``ptr`` is a stack-allocated object and it points to the first byte of the; object, the object is dead.; ``ptr`` is conservatively considered as a non-stack-allocated object if; the stack coloring algorithm that is used in the optimization pipeline cannot; conclude that ``ptr`` is a stack-allocated object. Calling ``llvm.lifetime.end`` on an already dead alloca is no-op. If ``ptr`` is a non-stack-allocated object or it does not point to the first; byte of the object, it is equivalent to simply filling all bytes of the object; with ``poison``. '``llvm.invariant.start``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The memory object can belong to any address space. ::. declare ptr @llvm.invariant.start.p0(i64 <size>, ptr nocapture <ptr>). Overview:; """""""""""""""""". The '``llvm.invariant.start``' intrinsic specifies that the contents of; a memory object will not change. Arguments:; """""""""""""""""""". The first argument is a constant integer representing the size of the; object, or -1 if it is va",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:863065,allocate,allocated,863065,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency," safe to store an instance of the; class (unless you know that the external storage will not be freed).; ``StringRef`` is small and pervasive enough in LLVM that it should always be; passed by value. The ``Twine`` class; ^^^^^^^^^^^^^^^^^^^. The ``Twine`` (`doxygen <https://llvm.org/doxygen/classllvm_1_1Twine.html>`__); class is an efficient way for APIs to accept concatenated strings. For example,; a common LLVM paradigm is to name one instruction based on the name of another; instruction with a suffix, for example:. .. code-block:: c++. New = CmpInst::Create(..., SO->getName() + "".cmp"");. The ``Twine`` class is effectively a lightweight `rope; <http://en.wikipedia.org/wiki/Rope_(computer_science)>`_ which points to; temporary (stack allocated) objects. Twines can be implicitly constructed as; the result of the plus operator applied to strings (i.e., a C strings, an; ``std::string``, or a ``StringRef``). The twine delays the actual concatenation; of strings until it is actually required, at which point it can be efficiently; rendered directly into a character array. This avoids unnecessary heap; allocation involved in constructing the temporary results of string; concatenation. See ``llvm/ADT/Twine.h`` (`doxygen; <https://llvm.org/doxygen/Twine_8h_source.html>`__) and :ref:`here <dss_twine>`; for more information. As with a ``StringRef``, ``Twine`` objects point to external memory and should; almost never be stored or mentioned directly. They are intended solely for use; when defining a function which should be able to efficiently accept concatenated; strings. .. _formatting_strings:. Formatting strings (the ``formatv`` function); ---------------------------------------------; While LLVM doesn't necessarily do a lot of string manipulation and parsing, it; does do a lot of string formatting. From diagnostic messages, to llvm tool; outputs such as ``llvm-readobj`` to printing verbose disassembly listings and; LLDB runtime logging, the need for string formatting is per",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:10552,efficient,efficiently,10552,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficiently']
Energy Efficiency," same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.add``' intrinsic performs the integer ``ADD`` reduction; (:ref:`llvm.vector.reduce.add <int_vector_reduce_add>`) of the vector operand; ``val`` on each enabled lane, adding it to the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``0`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is equal; to ``start_value``. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.add.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> zeroinitializer; %reduction = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %masked.a); %also.r = add i32 %reduction, %start. .. _int_vp_reduce_fadd:. '``llvm.vp.reduce.fadd.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fadd.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fadd.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``ADD`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:750151,reduce,reduce,750151,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," scc; ---. A single bit flag indicating the result of a scalar compare operation. .. _amdgpu_synid_lds_direct:. lds_direct; ----------. A special operand which supplies a 32-bit value; fetched from *LDS* memory using :ref:`m0<amdgpu_synid_m0>` as an address. .. _amdgpu_synid_null:. null; ----. This is a special operand that may be used as a source or a destination. When used as a destination, the result of the operation is discarded. When used as a source, it supplies zero value. .. _amdgpu_synid_constant:. inline constant; ---------------. An *inline constant* is an integer or a floating-point value; encoded as a part of an instruction. Compare *inline constants*; with :ref:`literals<amdgpu_synid_literal>`. Inline constants include:. * :ref:`Integer inline constants<amdgpu_synid_iconst>`;; * :ref:`Floating-point inline constants<amdgpu_synid_fconst>`;; * :ref:`Inline values<amdgpu_synid_ival>`. If a number may be encoded as either; a :ref:`literal<amdgpu_synid_literal>` or; a :ref:`constant<amdgpu_synid_constant>`,; the assembler selects the latter encoding as more efficient. .. _amdgpu_synid_iconst:. iconst; ~~~~~~. An :ref:`integer number<amdgpu_synid_integer_number>` or; an :ref:`absolute expression<amdgpu_synid_absolute_expression>`; encoded as an *inline constant*. Only a small fraction of integer numbers may be encoded as *inline constants*.; They are enumerated in the table below.; Other integer numbers are encoded as :ref:`literals<amdgpu_synid_literal>`. ================================== ====================================; Value Note; ================================== ====================================; {0..64} Positive integer inline constants.; {-16..-1} Negative integer inline constants.; ================================== ====================================. .. _amdgpu_synid_fconst:. fconst; ~~~~~~. A :ref:`floating-point number<amdgpu_synid_floating-point_number>`; encoded as an *inline constant*. Only a small fraction of floating-point numbers ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:22102,efficient,efficient,22102,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,1,['efficient'],['efficient']
Energy Efficiency," show better where the clusters on the various axes; are, a 1D histogram is associated to each axis. These histograms; (one per axis) are filled according to the number of lines passing; through the bins. ![The histogram’s axis can be represented with colors or as bar charts.](pictures/para4.png). These histograms can be represented which colors (get from a palette; according to the bin contents) or as bar charts. Both representations; can be cumulated on the same plot. This technique allows seeing clearly; where the clusters are on an individual axis but it does not give any; hints about the correlations between the axes. Avery simple technique allows to make the clusters appearing:; Instead of painting solid lines we paint dotted lines. The cluttering of; each individual line is reduced and the clusters show clearly as we can; see on the next figure. The spacing between the dots is a parameter which; can be adjusted in order to get the best results. ![Using dotted lines is a very simple method to reduce the cluttering.](pictures/para5.png). Interactivity is a very important aspect of the Parallel Coordinates plots.; To really explore the data set it is essential to act directly with the; events and the axes. For instance, changing the axes order may show clusters; which were not visible in a different order. On the next figure the axes; order has been changed interactively. We can see that many more clusters; appear and all the “random spheres” we put in the data set are now; clearly visible. Having moved the variables `u,v,w` after the variables; `x,y,z` the correlation between these two sets of variables is clear also. ![Axis order is very important to show clusters.](pictures/para6.png). To pursue further data sets exploration we have implemented the possibility; to define selections interactively. A selection is a set of ranges combined; together. Within a selection, ranges along the same axis are combined with; logical OR, and ranges on different axes with log",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:99554,reduce,reduce,99554,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['reduce'],['reduce']
Energy Efficiency," simple type that simply specifies an; arbitrary bit width for the integer type desired. Any bit width from 1; bit to 2\ :sup:`23`\ (about 8 million) can be specified. :Syntax:. ::. iN. The number of bits the integer will occupy is specified by the ``N``; value. Examples:; *********. +----------------+------------------------------------------------+; | ``i1`` | a single-bit integer. |; +----------------+------------------------------------------------+; | ``i32`` | a 32-bit integer. |; +----------------+------------------------------------------------+; | ``i1942652`` | a really big integer of over 1 million bits. |; +----------------+------------------------------------------------+. .. _t_floating:. Floating-Point Types; """""""""""""""""""""""""""""""""""""""". .. list-table::; :header-rows: 1. * - Type; - Description. * - ``half``; - 16-bit floating-point value. * - ``bfloat``; - 16-bit ""brain"" floating-point value (7-bit significand). Provides the; same number of exponent bits as ``float``, so that it matches its dynamic; range, but with greatly reduced precision. Used in Intel's AVX-512 BF16; extensions and Arm's ARMv8.6-A extensions, among others. * - ``float``; - 32-bit floating-point value. * - ``double``; - 64-bit floating-point value. * - ``fp128``; - 128-bit floating-point value (113-bit significand). * - ``x86_fp80``; - 80-bit floating-point value (X87). * - ``ppc_fp128``; - 128-bit floating-point value (two 64-bits). The binary format of half, float, double, and fp128 correspond to the; IEEE-754-2008 specifications for binary16, binary32, binary64, and binary128; respectively. X86_amx Type; """""""""""""""""""""""". :Overview:. The x86_amx type represents a value held in an AMX tile register on an x86; machine. The operations allowed on it are quite limited. Only few intrinsics; are allowed: stride load and store, zero and dot product. No instruction is; allowed for this type. There are no arguments, arrays, pointers, vectors; or constants of this type. :Syntax:. ::. x86_amx. X86_mm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:169323,reduce,reduced,169323,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduced']
Energy Efficiency," sized arrays in C99. The address space should typically be; the :ref:`alloca address space <alloca_addrspace>`. Semantics:; """""""""""""""""""". See the description for :ref:`llvm.stacksave <int_stacksave>`. .. _int_get_dynamic_area_offset:. '``llvm.get.dynamic.area.offset``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.get.dynamic.area.offset.i32(); declare i64 @llvm.get.dynamic.area.offset.i64(). Overview:; """""""""""""""""". The '``llvm.get.dynamic.area.offset.*``' intrinsic family is used to; get the offset from native stack pointer to the address of the most; recent dynamic alloca on the caller's stack. These intrinsics are; intended for use in combination with; :ref:`llvm.stacksave <int_stacksave>` to get a; pointer to the most recent dynamic alloca. This is useful, for example,; for AddressSanitizer's stack unpoisoning routines. Semantics:; """""""""""""""""""". These intrinsics return a non-negative integer value that can be used to; get the address of the most recent dynamic alloca, allocated by :ref:`alloca <i_alloca>`; on the caller's stack. In particular, for targets where stack grows downwards,; adding this offset to the native stack pointer would get the address of the most; recent dynamic alloca. For targets where stack grows upwards, the situation is a bit more; complicated, because subtracting this value from stack pointer would get the address; one past the end of the most recent dynamic alloca. Although for most targets `llvm.get.dynamic.area.offset <int_get_dynamic_area_offset>`; returns just a zero, for others, such as PowerPC and PowerPC64, it returns a; compile-time-known constant value. The return value type of :ref:`llvm.get.dynamic.area.offset <int_get_dynamic_area_offset>`; must match the target's default address space's (address space 0) pointer type. '``llvm.prefetch``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.prefetch(ptr <address>, i32 <rw>, i32 <locality>, i32 <cache t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:522057,allocate,allocated,522057,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency," small number of objects identified by unsigned keys of; moderate size. It uses a lot of memory, but provides operations that are almost; as fast as a vector. Typical keys are physical registers, virtual registers, or; numbered basic blocks. SparseSet is useful for algorithms that need very fast clear/find/insert/erase; and fast iteration over small sets. It is not intended for building composite; data structures. .. _dss_sparsemultiset:. llvm/ADT/SparseMultiSet.h; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. SparseMultiSet adds multiset behavior to SparseSet, while retaining SparseSet's; desirable attributes. Like SparseSet, it typically uses a lot of memory, but; provides operations that are almost as fast as a vector. Typical keys are; physical registers, virtual registers, or numbered basic blocks. SparseMultiSet is useful for algorithms that need very fast; clear/find/insert/erase of the entire collection, and iteration over sets of; elements sharing a key. It is often a more efficient choice than using composite; data structures (e.g. vector-of-vectors, map-of-vectors). It is not intended for; building composite data structures. .. _dss_FoldingSet:. llvm/ADT/FoldingSet.h; ^^^^^^^^^^^^^^^^^^^^^. FoldingSet is an aggregate class that is really good at uniquing; expensive-to-create or polymorphic objects. It is a combination of a chained; hash table with intrusive links (uniqued objects are required to inherit from; FoldingSetNode) that uses :ref:`SmallVector <dss_smallvector>` as part of its ID; process. Consider a case where you want to implement a ""getOrCreateFoo"" method for a; complex object (for example, a node in the code generator). The client has a; description of **what** it wants to generate (it knows the opcode and all the; operands), but we don't want to 'new' a node, then try inserting it into a set; only to find out it already exists, at which point we would have to delete it; and return the node that already exists. To support this style of client, FoldingSet per",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:81514,efficient,efficient,81514,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency," so they can be used to read memory with only the memory location; description and no extra information. The same set of operations can operate on; locations independent of their kind of storage. The ``DW_OP_deref*`` therefore; can be used on any storage kind, including memory location descriptions of; different address spaces. Therefore, the ``DW_OP_xderef*`` operations are; unnecessary, except to become a more compact way to encode a non-default address; space address followed by dereferencing it. See; :ref:`amdgpu-dwarf-general-operations`. 2.9 Support for Vector Base Types; ---------------------------------. The vector registers of the AMDGPU are represented as their full wavefront; size, meaning the wavefront size times the dword size. This reflects the; actual hardware and allows the compiler to generate DWARF for languages that; map a thread to the complete wavefront. It also allows more efficient DWARF to; be generated to describe the CFI as only a single expression is required for; the whole vector register, rather than a separate expression for each lane's; dword of the vector register. It also allows the compiler to produce DWARF; that indexes the vector register if it spills scalar registers into portions; of a vector register. Since DWARF stack value entries have a base type and AMDGPU registers are a; vector of dwords, the ability to specify that a base type is a vector is; required. See ``DW_AT_LLVM_vector_size`` in :ref:`amdgpu-dwarf-base-type-entries`. .. _amdgpu-dwarf-operation-to-create-vector-composite-location-descriptions:. 2.10 DWARF Operations to Create Vector Composite Location Descriptions; ----------------------------------------------------------------------. AMDGPU optimized code may spill vector registers to non-global address space; memory, and this spilling may be done only for SIMT lanes that are active on; entry to the subprogram. To support this the CFI rule for the partially spilled; register needs to use an expression that uses t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:23852,efficient,efficient,23852,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['efficient'],['efficient']
Energy Efficiency," some only accessible; by the GPU, and some by both. Using the constant address space indicates that the data will not change; during the execution of the kernel. This allows scalar read instructions to; be used. As the constant address space could only be modified on the host; side, a generic pointer loaded from the constant address space is safe to be; assumed as a global pointer since only the device global memory is visible; and managed on the host side. The vector and scalar L1 caches are invalidated; of volatile data before each kernel dispatch execution to allow constant; memory to change values between kernel dispatches. **Region**; The region address space uses the hardware Global Data Store (GDS). All; wavefronts executing on the same device will access the same memory for any; given region address. However, the same region address accessed by wavefronts; executing on different devices will access different memory. It is higher; performance than global memory. It is allocated by the runtime. The data; store (DS) instructions can be used to access it. **Local**; The local address space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates the wavefronts of a; work-group, and freed when all the wavefronts of a work-group have; terminated. All wavefronts belonging to the same work-group will access the; same memory for any given local address. However, the same local address; accessed by wavefronts belonging to different work-groups will access; different memory. It is higher performance than global memory. The data store; (DS) instructions can be used to access it. **Private**; The private address space uses the hardware scratch memory support which; automatically allocates memory when it creates a wavefront and frees it when; a wavefronts terminates. The memory accessed by a lane of a wavefront for any; given private address will be different to the memory accessed by another lane; of the same or different wave",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:25842,allocate,allocated,25842,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency," some stack location. The store is dead. The llvm-gcc generated code looks like this:. csretcc void %foo(%struct.s* %agg.result) {; entry:; 	%S = alloca %struct.s, align 4		; <%struct.s*> [#uses=1]; 	%memtmp = alloca %struct.s		; <%struct.s*> [#uses=1]; 	cast %struct.s* %S to sbyte*		; <sbyte*>:0 [#uses=2]; 	call void %llvm.memcpy.i32( sbyte* %0, sbyte* cast ({ double, int }* %C.0.904 to sbyte*), uint 12, uint 4 ); 	cast %struct.s* %agg.result to sbyte*		; <sbyte*>:1 [#uses=2]; 	call void %llvm.memcpy.i32( sbyte* %1, sbyte* %0, uint 12, uint 0 ); 	cast %struct.s* %memtmp to sbyte*		; <sbyte*>:2 [#uses=1]; 	call void %llvm.memcpy.i32( sbyte* %2, sbyte* %1, uint 12, uint 0 ); 	ret void; }. llc ends up issuing two memcpy's (the first memcpy becomes 3 loads from; constantpool). Perhaps we should 1) fix llvm-gcc so the memcpy is translated; into a number of load and stores, or 2) custom lower memcpy (of small size) to; be ldmia / stmia. I think option 2 is better but the current register; allocator cannot allocate a chunk of registers at a time. A feasible temporary solution is to use specific physical registers at the; lowering time for small (<= 4 words?) transfer size. * ARM CSRet calling convention requires the hidden argument to be returned by; the callee. //===---------------------------------------------------------------------===//. We can definitely do a better job on BB placements to eliminate some branches.; It's very common to see llvm generated assembly code that looks like this:. LBB3:; ...; LBB4:; ...; beq LBB3; b LBB2. If BB4 is the only predecessor of BB3, then we can emit BB3 after BB4. We can; then eliminate beq and turn the unconditional branch to LBB2 to a bne. See McCat/18-imp/ComputeBoundingBoxes for an example. //===---------------------------------------------------------------------===//. Pre-/post- indexed load / stores:. 1) We should not make the pre/post- indexed load/store transform if the base ptr; is guaranteed to be live beyond the load/st",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:7368,allocate,allocate,7368,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,1,['allocate'],['allocate']
Energy Efficiency," space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive with; ""hidden_hostcall_buffer""; before Code Object V5. ""hidden_hostcall_buffer""; A global address space pointer; to the runtime hostcall buffer; is passed in kernarg. Mutually; exclusive with; ""hidden_printf_buffer""; before Code Object V5. ""hidden_default_queue""; A global address space pointer; to the OpenCL device enqueue; queue that should be used by; the kernel by default is; passed in the kernarg. ""hidden_completion_action""; A global address space pointer; to help link enqueued kernels into; the ancestor tree for determining; when the parent kernel has finished. ""hidden_multigrid_sync_arg""; A global address space pointer for; multi-grid synchronization is; passed in the kernarg. "".value_type"" string Unused and deprecated. This should no longer; be emitted, but is accepted for compatibility. "".pointee_align"" integer Alignment in bytes of pointee; type for pointer type kernel; argument. Must be a power; of 2. Only present if; "".value_kind"" is; ""dynamic_shared_pointer"".; "".address_space"" string Kernel argument address space; qualifier. Only present if; "".value_kind"" is ""global_buffer"" or; ""dynamic_shared_pointer"". Values; are:. - ""private""; - ""global""; - ""constant""; - ""local""; - ""generic""; - ""region"". .. TODO::. Is ""global_buffer"" only ""global""; or ""constant""? Is; ""dynamic_shared_pointer"" always; ""local""? Can HCC allow ""generic""?; How can ""private"" or ""region""; ever happen?. "".access"" string Kernel argument access; qualifier. Only present if; "".value_kind"" is ""image"" or; ""pipe"". Values; are:. - ""read_only""; - ""write_only""; - ""read_write"". .. TODO::. Does this apply to; ""global_buffer""?. "".actual_access"" string The actual memory accesses; performed by the kernel on the; kernel argument. Only present if; "".value_kind"" is ""global_buffer"",; ""image"", or ""pipe"". This may be; more restrictive than indicated; by "".access"" to reflect what the; kernel actual does. If not; present then the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:139034,power,power,139034,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['power'],['power']
Energy Efficiency," specify icon name which will be displayed with the command. ```cpp; serv->RegisterCommand(""/DoSomething"", ""SomeFunction()"", ""rootsys/icons/ed_execute.png"");; ```. In example usage of images from `$ROOTSYS/icons` directory is shown. One could prepend `button;`; string to the icon name to let browser show command as extra button. In last case one could hide command element from elements list:. ```cpp; serv->Hide(""/DoSomething"");; ```. One can find example of command interface usage in [tutorials/http/httpcontrol.C](https://github.com/root-project/root/blob/master/tutorials/http/httpcontrol.C) macro. ## Customize user interface. JSROOT is used to implement UI for the THttpServer. Default webpage shows list of registered objects on the left side and drawing area on the right side - [see example](https://root.cern/js/latest/httpserver.C/). JSROOT allows to configure different parameters via URL - like monitoring interval or name of displayed items [item=Files/job1.root/hpxpy&opt=colz&monitoring=1000](https://root.cern/js/latest/httpserver.C/?item=Files/job1.root/hpxpy&opt=colz&monitoring=1000). Some of such parameters can be configured already on the server:. ```cpp; serv->SetItemField(""/"", ""_monitoring"", ""1000""); // monitoring interval in ms; serv->SetItemField(""/"", ""_drawitem"", ""Files/job1.root/hpxpy""); // item to draw; serv->SetItemField(""/"", ""_drawopt"", ""colz"");; ```. In such case URL parameters are not required - specified item will be displayed automatically when web page is opened.; One also can configure to display several items at once. For that one also can configure layout of the drawing area:. ```cpp; serv->SetItemField(""/"", ""_layout"", ""grid2x2""); // layout for drawing area; serv->SetItemField(""/"", ""_drawitem"", ""[Files/job1.root/hpxpy,Files/job1.root/hpx]""); // items; serv->SetItemField(""/"", ""_drawopt"", ""[colz,hist]""); // options; ```. One also can change appearance of hierarchy browser on the left side of the web page:. ```cpp; serv->SetItemField(""/"", ""_bro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:6732,monitor,monitoring,6732,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['monitor'],['monitoring']
Energy Efficiency," stack, meaning that references to the shadow call stack do not have; to be stored in memory. This makes it possible to implement a runtime that; avoids exposing the address of the shadow call stack to attackers that can; read arbitrary memory. However, attackers could still try to exploit side; channels exposed by the operating system `[1]`_ `[2]`_ or processor `[3]`_; to discover the address of the shadow call stack. .. _`[1]`: https://eyalitkin.wordpress.com/2017/09/01/cartography-lighting-up-the-shadows/; .. _`[2]`: https://www.blackhat.com/docs/eu-16/materials/eu-16-Goktas-Bypassing-Clangs-SafeStack.pdf; .. _`[3]`: https://www.vusec.net/projects/anc/. Unless care is taken when allocating the shadow call stack, it may be; possible for an attacker to guess its address using the addresses of; other allocations. Therefore, the address should be chosen to make this; difficult. One way to do this is to allocate a large guard region without; read/write permissions, randomly select a small region within it to be; used as the address of the shadow call stack and mark only that region as; read/write. This also mitigates somewhat against processor side channels.; The intent is that the Android runtime `will do this`_, but the platform will; first need to be `changed`_ to avoid using ``setrlimit(RLIMIT_AS)`` to limit; memory allocations in certain processes, as this also limits the number of; guard regions that can be allocated. .. _`will do this`: https://android-review.googlesource.com/c/platform/bionic/+/891622; .. _`changed`: https://android-review.googlesource.com/c/platform/frameworks/av/+/837745. The runtime will need the address of the shadow call stack in order to; deallocate it when destroying the thread. If the entire program is compiled; with ``SCSReg`` reserved, this is trivial: the address can be derived from the; value stored in ``SCSReg`` (e.g. by masking out the lower bits). If a guard; region is used, the address of the start of the guard region could then",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ShadowCallStack.rst:5883,allocate,allocate,5883,interpreter/llvm-project/clang/docs/ShadowCallStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ShadowCallStack.rst,1,['allocate'],['allocate']
Energy Efficiency," structure to end-users: when; developing a Python package that exposes C++ classes through ``cppyy``,; consider ``cppyy.gbl`` an ""internal"" module, and expose the classes in any; structure you see fit.; The C++ names will continue to follow the C++ structure, however, as is needed; for e.g. pickling:. .. code-block:: python. >>> from cppyy.gbl import Namespace; >>> Concrete == Namespace.Concrete; False; >>> n = Namespace.Concrete.NestedClass(); >>> type(n); <class cppyy.gbl.Namespace.Concrete.NestedClass at 0x22114c0>; >>> type(n).__name__; NestedClass; >>> type(n).__module__; cppyy.gbl.Namespace.Concrete; >>> type(n).__cpp_name__; Namespace::Concrete::NestedClass; >>>. `Constructors`; --------------. Python and C++ both make a distinction between allocation (``__new__`` in; Python, ``operator new`` in C++) and initialization (``__init__`` in Python,; the constructor call in C++).; When binding, however, there comes a subtle semantic difference: the Python; ``__new__`` allocates memory for the proxy object only, and ``__init__``; initializes the proxy by creating or binding the C++ object.; Thus, no C++ memory is allocated until ``__init__``.; The advantages are simple: the proxy can now check whether it is initialized,; because the pointer to C++ memory will be NULL if not; it can be a reference; to another proxy holding the actual C++ memory; and it can now transparently; implement a C++ smart pointer.; If ``__init__`` is never called, eg. when a call to the base class; ``__init__`` is missing in a derived class override, then accessing the proxy; will result in a Python ``ReferenceError`` exception. `Destructors`; -------------. There should no be reason to call a destructor directly in CPython, but e.g.; PyPy uses a garbage collector and that makes it sometimes useful to destruct; a C++ object exactly when you want it destroyed.; Destructors are by convention accessible through the ``__destruct__`` method; (since ""~"" can not be part of a Python method name).; If",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:2063,allocate,allocates,2063,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,1,['allocate'],['allocates']
Energy Efficiency," structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ""AnalysisType"" in the Factory. The default value is; ""Auto"" where TMVA tries to determine the most suitable analysis; type from the targets and classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:2574,monitor,monitoring,2574,tmva/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html,1,['monitor'],['monitoring']
Energy Efficiency," support; <langext-vectors>` instead of builtins, in order to reduce the number of; builtins that we need to implement. ``__builtin_alloca``; --------------------. ``__builtin_alloca`` is used to dynamically allocate memory on the stack. Memory; is automatically freed upon function termination. **Syntax**:. .. code-block:: c++. __builtin_alloca(size_t n). **Example of Use**:. .. code-block:: c++. void init(float* data, size_t nbelems);; void process(float* data, size_t nbelems);; int foo(size_t n) {; auto mem = (float*)__builtin_alloca(n * sizeof(float));; init(mem, n);; process(mem, n);; /* mem is automatically freed at this point */; }. **Description**:. ``__builtin_alloca`` is meant to be used to allocate a dynamic amount of memory; on the stack. This amount is subject to stack allocation limits. Query for this feature with ``__has_builtin(__builtin_alloca)``. ``__builtin_alloca_with_align``; -------------------------------. ``__builtin_alloca_with_align`` is used to dynamically allocate memory on the; stack while controlling its alignment. Memory is automatically freed upon; function termination. **Syntax**:. .. code-block:: c++. __builtin_alloca_with_align(size_t n, size_t align). **Example of Use**:. .. code-block:: c++. void init(float* data, size_t nbelems);; void process(float* data, size_t nbelems);; int foo(size_t n) {; auto mem = (float*)__builtin_alloca_with_align(; n * sizeof(float),; CHAR_BIT * alignof(float));; init(mem, n);; process(mem, n);; /* mem is automatically freed at this point */; }. **Description**:. ``__builtin_alloca_with_align`` is meant to be used to allocate a dynamic amount of memory; on the stack. It is similar to ``__builtin_alloca`` but accepts a second; argument whose value is the alignment constraint, as a power of 2 in *bits*. Query for this feature with ``__has_builtin(__builtin_alloca_with_align)``. .. _langext-__builtin_assume:. ``__builtin_assume``; --------------------. ``__builtin_assume`` is used to provide the optimizer",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:97719,allocate,allocate,97719,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['allocate'],['allocate']
Energy Efficiency," switch (OptimizationList[i]); ... ... to iterate through the list of options specified. Note that the ""``cl::list``"" template is completely general and may be used with; any data types or other arguments that you can use with the ""``cl::opt``""; template. One especially useful way to use a list is to capture all of the; positional arguments together if there may be more than one specified. In the; case of a linker, for example, the linker takes several '``.o``' files, and; needs to capture them into a list. This is naturally specified as:. .. code-block:: c++. ...; cl::list<std::string> InputFilenames(cl::Positional, cl::desc(""<Input files>""), cl::OneOrMore);; ... This variable works just like a ""``vector<string>``"" object. As such, accessing; the list is simple, just like above. In this example, we used the; `cl::OneOrMore`_ modifier to inform the CommandLine library that it is an error; if the user does not specify any ``.o`` files on our command line. Again, this; just reduces the amount of checking we have to do. Collecting options as a set of flags; ------------------------------------. Instead of collecting sets of options in a list, it is also possible to gather; information for enum values in a **bit vector**. The representation used by the; `cl::bits`_ class is an ``unsigned`` integer. An enum value is represented by a; 0/1 in the enum's ordinal value bit position. 1 indicating that the enum was; specified, 0 otherwise. As each specified value is parsed, the resulting enum's; bit is set in the option's bit vector:. .. code-block:: c++. bits |= 1 << (unsigned)enum;. Options that are specified multiple times are redundant. Any instances after; the first are discarded. Reworking the above list example, we could replace `cl::list`_ with `cl::bits`_:. .. code-block:: c++. cl::bits<Opts> OptimizationBits(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumVal",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:21341,reduce,reduces,21341,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,1,['reduce'],['reduces']
Energy Efficiency," system** classes:; * ROOT::Math::Cartesian2D, based on <em>(x,y)</em> ;; * ROOT::Math::Polar2D, based on <em>(r, phi)</em> ;; * **3D coordinate system** classes:; * ROOT::Math::Cartesian3D, based on <em>(x,y,z)</em>;; * ROOT::Math::Polar3D, based on <em>(r, theta, phi)</em>;; * ROOT::Math::Cylindrical3D, based on <em>(rho, z, phi)</em>; * ROOT::Math::CylindricalEta3D, based on <em>(rho, eta, phi)</em>;; * **4D coordinate system** classes:; * ROOT::Math::PxPyPzE4D, based on based on <em>(px,py,pz,E)</em>;; * ROOT::Math::PxPyPzM4D, based on based on <em>(px,py,pz,M)</em>;; * ROOT::Math::PtEtaPhiE4D, based on based on <em>(pt,eta,phi,E)</em>;; * ROOT::Math::PtEtaPhiM4D, based on based on <em>(pt,eta,phi,M)</em>;. The angle _theta_ is defined between [0,\f$\pi\f$] and _phi_ between [-\f$\pi\f$,\f$\pi\f$].; The angles are expressed in radians.; The _eta_ component is known as [pseudo-rapidity](https://en.wikipedia.org/wiki/Pseudorapidity). Users can define the Vectors according to the coordinate type which; is most efficient for their use. Transformations between the various coordinate; systems are available through copy constructors or the assignment `operator =`.; The coordinate system classes are templated on the scalar type for maximum flexibility,; and to minimize memory usage for some use cases. ### Coordinate System Tag. The 2D and 3D point and vector classes can be associated to a tag defining the; coordinate system. This can be used to distinguish between vectors of different; coordinate systems like global or local vectors. The coordinate system tag is a; template parameter of the ROOT::Math::DisplacementVector3D; (and ROOT::Math::DisplacementVector2D) and ROOT::Math::PositionVector3D; (and ROOT::Math::PositionVector2D) classes. A default tag,; ROOT::Math::DefaultCoordinateSystemTag, exists for users who don't need this; functionality. \anchor GenVectorTypedefs; ## Concrete Vector typedefs. To avoid exposing templated parameters to the users, typedefs are defi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md:2827,efficient,efficient,2827,math/genvector/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md,1,['efficient'],['efficient']
Energy Efficiency," temporary in that block will be ""%1"", etc. If a; numeric label is explicitly specified, it must match the numeric label that; would be used implicitly. The first basic block in a function is special in two ways: it is; immediately executed on entrance to the function, and it is not allowed; to have predecessor basic blocks (i.e. there can not be any branches to; the entry block of a function). Because the block can have no; predecessors, it also cannot have any :ref:`PHI nodes <i_phi>`. LLVM allows an explicit section to be specified for functions. If the; target supports it, it will emit functions to the section specified.; Additionally, the function can be placed in a COMDAT. An explicit alignment may be specified for a function. If not present,; or if the alignment is set to zero, the alignment of the function is set; by the target to whatever it feels convenient. If an explicit alignment; is specified, the function is forced to have at least that much; alignment. All alignments must be a power of 2. If the ``unnamed_addr`` attribute is given, the address is known to not; be significant and two identical functions can be merged. If the ``local_unnamed_addr`` attribute is given, the address is known to; not be significant within the module. If an explicit address space is not given, it will default to the program; address space from the :ref:`datalayout string<langref_datalayout>`. .. _langref_aliases:. Aliases; -------. Aliases, unlike function or variables, don't create any new data. They; are just a new symbol and metadata for an existing position. Aliases have a name and an aliasee that is either a global value or a; constant expression. Aliases may have an optional :ref:`linkage type <linkage>`, an optional; :ref:`runtime preemption specifier <runtime_preemption_model>`, an optional; :ref:`visibility style <visibility>`, an optional :ref:`DLL storage class; <dllstorageclass>` and an optional :ref:`tls model <tls_model>`. Syntax::. @<Name> = [Linkage] [Preempt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:41967,power,power,41967,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency," test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3672,reduce,reduced,3672,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,2,['reduce'],"['reduce', 'reduced']"
Energy Efficiency," the ""last line of defense"" to guarantee that all; patches that are committed are actually reviewed. Being a code owner is a somewhat unglamorous position, but it is incredibly; important for the ongoing success of the project. Because people get busy,; interests change, and unexpected things happen, code ownership is purely opt-in,; and anyone can choose to resign their ""title"" at any time. For now, we do not; have an official policy on how one gets elected to be a code owner. .. _include a testcase:. Test Cases; ----------. Developers are required to create test cases for any bugs fixed and any new; features added. Some tips for getting your testcase approved:. * All feature and regression test cases are added to the ``llvm/test``; directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:9971,reduce,reduced,9971,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['reduce'],['reduced']
Energy Efficiency," the Tree; TTree t2(""t2"",""a Tree with data from a fake Geant3"");; // declare a variable of the C structure type; Gctrak_t gstep;. // add the branches for a subset of gstep; t2.Branch(""vect"",gstep.vect,""vect[7]/F"");; t2.Branch(""getot"",&gstep.getot,""getot/F"");; t2.Branch(""gekin"",&gstep.gekin,""gekin/F"");; t2.Branch(""nmec"",&gstep.nmec,""nmec/I"");; t2.Branch(""lmec"",gstep.lmec,""lmec[nmec]/I"");; t2.Branch(""destep"",&gstep.destep,""destep/F"");; t2.Branch(""pid"",&gstep.pid,""pid/I"");. //Initialize particle parameters at first point; Float_t px,py,pz,p,charge=0;; Float_t vout[7];; Float_t mass = 0.137;; Bool_t newParticle = kTRUE;; gstep.step = 0.1;; gstep.destep = 0;; gstep.nmec = 0;; gstep.pid = 0;. //transport particles; for (Int_t i=0; i<10000; i++) {; //generate a new particle if necessary (Geant3 emulation); if (newParticle) {; px = gRandom->Gaus(0,.02);; py = gRandom->Gaus(0,.02);; pz = gRandom->Gaus(0,.02);; p = TMath::Sqrt(px*px+py*py+pz*pz);; charge = 1;; if (gRandom->Rndm() < 0.5) charge = -1;; gstep.pid += 1;; gstep.vect[0] = 0;; gstep.vect[1] = 0;; gstep.vect[2] = 0;; gstep.vect[3] = px/p;; gstep.vect[4] = py/p;; gstep.vect[5] = pz/p;; gstep.vect[6] = p*charge;; gstep.getot = TMath::Sqrt(p*p + mass*mass);; gstep.gekin = gstep.getot - mass;; newParticle = kFALSE;; }; // fill the Tree with current step parameters; t2.Fill();. //transport particle in magnetic field (Geant3 emulation); helixStep(gstep.step, gstep.vect, vout);; //make one step; //apply energy loss; gstep.destep = gstep.step*gRandom->Gaus(0.0002,0.00001);; gstep.gekin -= gstep.destep;; gstep.getot = gstep.gekin + mass;; gstep.vect[6]= charge*TMath::Sqrt(gstep.getot*gstep.getot; - mass*mass);; gstep.vect[0] = vout[0];; gstep.vect[1] = vout[1];; gstep.vect[2] = vout[2];; gstep.vect[3] = vout[3];; gstep.vect[4] = vout[4];; gstep.vect[5] = vout[5];; gstep.nmec = (Int_t)(5*gRandom->Rndm());; for (Int_t l=0; l<gstep.nmec; l++) gstep.lmec[l] = l;; if (gstep.gekin < 0.001) newParticle = kTRUE;; if (TMath::Abs(gstep.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:46586,charge,charge,46586,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['charge'],['charge']
Energy Efficiency," the cluster target size for uncompressed data.; Initially, and after flushing, all columns use small pages,; just big enough to hold the configurable minimum number of elements (64 by default).; Page sizes are doubled as more data is filled into them.; When a page reaches the maximum page size (see above), it is flushed.; When the overall page budget is reached,; pages larger than the page at hand are flushed before the page at hand is flushed.; For the parallel writer, every fill context maintains the page memory budget independently. Note that the total amount of memory consumed for writing is usually larger than the write page budget.; For instance, if buffered writing is used (the default), additional memory is required.; Use RNTupleModel::EstimateWriteMemoryUsage() for the total estimated memory use for writing. The default values are tuned for a total write memory of around 300 MB per writer resp. fill context.; In order to decrease the memory consumption,; users should decrease the target cluster size before tuning more intricate memory settings. Notes; =====. Approximation of the compressed cluster size; --------------------------------------------. The estimator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.; More code compared to the average compression factor or all so-far written clusters.; It would be faster in adjusting to system",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:2990,consumption,consumption,2990,tree/ntuple/v7/doc/tuning.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md,1,['consumption'],['consumption']
Energy Efficiency," the command line, the ``/clang:``; arguments are treated as if they were passed at the end of the clang-cl command; line. The /Zc:dllexportInlines- Option; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This causes the class-level `dllexport` and `dllimport` attributes to not apply; to inline member functions, as they otherwise would. For example, in the code; below `S::foo()` would normally be defined and exported by the DLL, but when; using the ``/Zc:dllexportInlines-`` flag it is not:. .. code-block:: c. struct __declspec(dllexport) S {; void foo() {}; }. This has the benefit that the compiler doesn't need to emit a definition of; `S::foo()` in every translation unit where the declaration is included, as it; would otherwise do to ensure there's a definition in the DLL even if it's not; used there. If the declaration occurs in a header file that's widely used, this; can save significant compilation time and output size. It also reduces the; number of functions exported by the DLL similarly to what; ``-fvisibility-inlines-hidden`` does for shared objects on ELF and Mach-O.; Since the function declaration comes with an inline definition, users of the; library can use that definition directly instead of importing it from the DLL. Note that the Microsoft Visual C++ compiler does not support this option, and; if code in a DLL is compiled with ``/Zc:dllexportInlines-``, the code using the; DLL must be compiled in the same way so that it doesn't attempt to dllimport; the inline member functions. The reverse scenario should generally work though:; a DLL compiled without this flag (such as a system library compiled with Visual; C++) can be referenced from code compiled using the flag, meaning that the; referencing code will use the inline definitions instead of importing them from; the DLL. Also note that like when using ``-fvisibility-inlines-hidden``, the address of; `S::foo()` will be different inside and outside the DLL, breaking the C/C++; standard requirement that functions have ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:187566,reduce,reduces,187566,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['reduce'],['reduces']
Energy Efficiency," the framework. - More consistent and modular code - the code reuse provides; consistency and common capabilities between programs, no matter; who writes them. Frameworks make it easier to break programs into; smaller pieces. - More focus on areas of expertise - users can concentrate on their; particular problem domain. They do not have to be experts at; writing user interfaces, graphics, or networking to use the; frameworks that provide those services. ### Why Object-Oriented?. Object-Oriented Programming offers considerable benefits compared to; Procedure-Oriented Programming:. - Encapsulation enforces data abstraction and increases opportunity; for reuse. - Sub classing and inheritance make it possible to extend and modify; objects. - Class hierarchies and containment containment hierarchies provide; a flexible mechanism for modeling real-world objects and the; relationships among them. - Complexity is reduced because there is little growth of the global; state, the state is contained within each object, rather than; scattered through the program in the form of global variables. - Objects may come and go, but the basic structure of the program; remains relatively static, increases opportunity for reuse of; design. ## Installing ROOT; \index{install ROOT}. To install ROOT you have the choice to; download the binaries or the source. The source is quicker to transfer; since it is only \~22 MB, but you will need to compile and link it. The; binaries compiled with no debug information range from \~35 MB to \~45; MB depending on the target platform. The installation and building of ROOT is described in Appendix A:; Install and Build ROOT. You can download the binaries, or the source.; The GNU g++ compiler on most UNIX platforms can compile ROOT. Before downloading a binary version make sure your machine contains the; right run-time environment. In most cases it is not possible to run a; version compiled with, e.g., gcc4.0 on a platform where only gcc 3.2 is; installed.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:8434,reduce,reduced,8434,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['reduce'],['reduced']
Energy Efficiency," the scheduler's queue is full. Looking at the *Dispatch Logic* table, we see that the pipeline was only able to; dispatch two micro opcodes 51.5% of the time. The dispatch group was limited to; one micro opcode 44.6% of the cycles, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, two instructions were retired during the; same cyc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31616,schedul,scheduler,31616,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency," the shape. Note: At present modifications to the shapes are local to the viewer -; they are not propagated back to external objects/client that published; to the viewer. The changes are preserved only until the viewer is; closed. In some cases, this will never be feasible as there is not a; one-to-one correspondence between a shape in the viewer and a single; external object in which the modification could be stored. #### Colors / Style. Viewer Controls Pane ‘Style' tab. A full description of OpenGL materials, colors and lighting is beyond; the scope of this document. You should refer to the OpenGL programming; manual (Red Book) for a full discussion. In most cases adjustment of the; Diffuse color material + Opacity/Shine properties is sufficient to; achieve desired results. A shape has four-color materials (components):. - Diffuse. - Ambient. - Specular. - Emissive. For each of these you can select the component via the radio buttons.; Each component can have the red, green and blue values for the component; adjusted via the sliders. You can apply this adjustment to the shape; itself, or to all shapes sharing a common ‘family'. Shapes of the same; family have external objects with the same **`TObject`** name string.; You can also adjust the ‘Opacity' and ‘Shine' for the shapes materials; via the sliders. #### Geometry. Viewer Controls Pane ‘Geometry' tab. Review and modify the shapes X/Y/Z center and scaling factors via the; edit boxes. Selection and editing of shapes is not available via the API; at present. #### Outputting Viewer Contents. The current viewer rendering can be output to an external `EPS` or; `PDF`, using the options under the ‘File' menu on the top menu bar. The; file is named ‘`viewer.eps`' or ‘`viewer.pdf`' and written to the; current ROOT directory. ### The X3D Viewer. The X3D viewer is a fairly simple and limited viewer, capable of showing; basic lines and polygons. It lacks the quality, performance and more; advanced features of the GL Viewer,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:120239,green,green,120239,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['green'],['green']
Energy Efficiency," the steps; you need to take in order to make your Dockerfiles functional. Usage; =====; The ``llvm/utils/build_docker_image.sh`` script provides a rather high degree of; control on how to run the build. It allows you to specify the projects to; checkout from git and provide a list of CMake arguments to use during when; building LLVM inside docker container. Here's a very simple example of getting a docker image with clang binary,; compiled by the system compiler in the debian10 image:. .. code-block:: bash. ./llvm/utils/docker/build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i install-clang -i install-clang-resource-headers \; 	-- \; 	-DCMAKE_BUILD_TYPE=Release. Note that a build like that doesn't use a 2-stage build process that; you probably want for clang. Running a 2-stage build is a little more intricate,; this command will do that:. .. code-block:: bash. # Run a 2-stage build.; # LLVM_TARGETS_TO_BUILD=Native is to reduce stage1 compile time.; # Options, starting with BOOTSTRAP_* are passed to stage2 cmake invocation.; ./build_docker_image.sh \; 	--source debian10 \; 	--docker-repository clang-debian10 --docker-tag ""staging"" \; 	-p clang -i stage2-install-clang -i stage2-install-clang-resource-headers \; 	-- \; 	-DLLVM_TARGETS_TO_BUILD=Native -DCMAKE_BUILD_TYPE=Release \; 	-DBOOTSTRAP_CMAKE_BUILD_TYPE=Release \; 	-DCLANG_ENABLE_BOOTSTRAP=ON -DCLANG_BOOTSTRAP_TARGETS=""install-clang;install-clang-resource-headers""; 	; This will produce a new image ``clang-debian10:staging`` from the latest; upstream revision.; After the image is built you can run bash inside a container based on your image; like this:. .. code-block:: bash. docker run -ti clang-debian10:staging bash. Now you can run bash commands as you normally would:. .. code-block:: bash. root@80f351b51825:/# clang -v; clang version 5.0.0 (trunk 305064); Target: x86_64-unknown-linux-gnu; Thread model: posix; InstalledDir: /bin; Found candi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst:4201,reduce,reduce,4201,interpreter/llvm-project/llvm/docs/Docker.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Docker.rst,1,['reduce'],['reduce']
Energy Efficiency," the; ``MachinePassRegistry`` class and subclasses of ``MachinePassRegistryNode``. An instance of ``MachinePassRegistry`` is used to maintain a list of; ``MachinePassRegistryNode`` objects. This instance maintains the list and; communicates additions and deletions to the command line interface. An instance of ``MachinePassRegistryNode`` subclass is used to maintain; information provided about a particular pass. This information includes the; command line name, the command help string and the address of the function used; to create an instance of the pass. A global static constructor of one of these; instances *registers* with a corresponding ``MachinePassRegistry``, the static; destructor *unregisters*. Thus a pass that is statically linked in the tool; will be registered at start up. A dynamically loaded pass will register on; load and unregister at unload. Using existing registries; -------------------------. There are predefined registries to track instruction scheduling; (``RegisterScheduler``) and register allocation (``RegisterRegAlloc``) machine; passes. Here we will describe how to *register* a register allocator machine; pass. Implement your register allocator machine pass. In your register allocator; ``.cpp`` file add the following include:. .. code-block:: c++. #include ""llvm/CodeGen/RegAllocRegistry.h"". Also in your register allocator ``.cpp`` file, define a creator function in the; form:. .. code-block:: c++. FunctionPass *createMyRegisterAllocator() {; return new MyRegisterAllocator();; }. Note that the signature of this function should match the type of; ``RegisterRegAlloc::FunctionPassCtor``. In the same file add the ""installing""; declaration, in the form:. .. code-block:: c++. static RegisterRegAlloc myRegAlloc(""myregalloc"",; ""my register allocator help string"",; createMyRegisterAllocator);. Note the two spaces prior to the help string produces a tidy result on the; :option:`-help` query. .. code-block:: console. $ llc -help; ...; -regalloc - Registe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:49368,schedul,scheduling,49368,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['schedul'],['scheduling']
Energy Efficiency," therefore can be used directly after loading JSRootCore.js script; 5. Same is done with JSROOT.draw function. It is defined in the JSRootCore.js; and can be used directly. Makes usage of JSROOT easier; 6. Introduce JSRootPainter.more.js script, where painters for auxiliary classes; will be implemented.; 7. Implement painter for TEllipse, TLine, TArrow classes; 8. Fix several problems with markers drawing; implement plus, asterisk, mult symbols.; 9. Implement custom layout, which allows to configure user-defined layout for displayed objects; 10. Fix errors with scaling of axis labels.; 11. Support also Y axis with custom labels like: http://jsroot.gsi.de/dev/?nobrowser&file=../files/atlas.root&item=LEDShapeHeightCorr_Gain0;1&opt=col. ## Changes in 3.7; 1. Support of X axis with custom labels like: http://jsroot.gsi.de/dev/?nobrowser&json=../files/hist_xlabels.json; 2. Extend functionality of JSROOT.addDrawFunc() function. One could register type-specific; `make_request` and `after_request` functions; `icon`, `prereq`, `script`, `monitor` properties.; This let add more custom elements to the generic gui, implemented with JSROOT.HierarchyPainter; 3. Provide full support of require.js. One could load now JSRootCore.js script like:. <script type=""text/javascript"" src=""require.js"" data-main=""scripts/JSRootCore.js""></script>. After this several modules are defined and can be used with syntax like:. require(['JSRootPainter'], function(jsroot) { /*any user code*/});. Also inside JSROOT require.js used to load all dependencies. ## Changes in 3.6; 1. Try to provide workaround for websites where require.js already loaded.; This makes problem by direct loading of jquery and jquery-ui; 2. Provide workaround for older version of jquery-ui; 3. Prompt for input of command arguments; 4. After command execution one could automatically reload hierarchy (_hreload property) or; update view of displayed object (_update_item property); 5. Use HierarchyPainter for implementing draw.htm. Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:63333,monitor,monitor,63333,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['monitor'],['monitor']
Energy Efficiency," these are fully self-described in the file, and the; reader is not allowed to build in any knowledge of this. Basics; ------. LLVM IR Magic Number; ^^^^^^^^^^^^^^^^^^^^. The magic number for LLVM IR files is:. :raw-html:`<tt><blockquote>`; ['B'\ :sub:`8`, 'C'\ :sub:`8`, 0x0\ :sub:`4`, 0xC\ :sub:`4`, 0xE\ :sub:`4`, 0xD\ :sub:`4`]; :raw-html:`</blockquote></tt>`. .. _Signed VBRs:. Signed VBRs; ^^^^^^^^^^^. `Variable Width Integer`_ encoding is an efficient way to encode arbitrary sized; unsigned values, but is an extremely inefficient for encoding signed values, as; signed values are otherwise treated as maximally large unsigned values. As such, signed VBR values of a specific width are emitted as follows:. * Positive values are emitted as VBRs of the specified width, but with their; value shifted left by one. * Negative values are emitted as VBRs of the specified width, but the negated; value is shifted left by one, and the low bit is set. With this encoding, small positive and small negative values can both be emitted; efficiently. Signed VBR encoding is used in ``CST_CODE_INTEGER`` and; ``CST_CODE_WIDE_INTEGER`` records within ``CONSTANTS_BLOCK`` blocks.; It is also used for phi instruction operands in `MODULE_CODE_VERSION`_ 1. LLVM IR Blocks; ^^^^^^^^^^^^^^. LLVM IR is defined with the following blocks:. * 8 --- `MODULE_BLOCK`_ --- This is the top-level block that contains the entire; module, and describes a variety of per-module information. * 9 --- `PARAMATTR_BLOCK`_ --- This enumerates the parameter attributes. * 10 --- `PARAMATTR_GROUP_BLOCK`_ --- This describes the attribute group table. * 11 --- `CONSTANTS_BLOCK`_ --- This describes constants for a module or; function. * 12 --- `FUNCTION_BLOCK`_ --- This describes a function body. * 14 --- `VALUE_SYMTAB_BLOCK`_ --- This describes a value symbol table. * 15 --- `METADATA_BLOCK`_ --- This describes metadata items. * 16 --- `METADATA_ATTACHMENT`_ --- This contains records associating metadata; with function ins",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:21377,efficient,efficiently,21377,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,1,['efficient'],['efficiently']
Energy Efficiency," this:. _test:; movl 8(%esp), %eax; cmpl %eax, 4(%esp); setl %al; movzbl %al, %eax; ret. on some processors (which ones?), it is more efficient to do this:. _test:; movl 8(%esp), %ebx; xor %eax, %eax; cmpl %ebx, 4(%esp); setl %al; ret. Doing this correctly is tricky though, as the xor clobbers the flags. //===---------------------------------------------------------------------===//. We should generate bts/btr/etc instructions on targets where they are cheap or; when codesize is important. e.g., for:. void setbit(int *target, int bit) {; *target |= (1 << bit);; }; void clearbit(int *target, int bit) {; *target &= ~(1 << bit);; }. //===---------------------------------------------------------------------===//. Instead of the following for memset char*, 1, 10:. 	movl $16843009, 4(%edx); 	movl $16843009, (%edx); 	movw $257, 8(%edx). It might be better to generate. 	movl $16843009, %eax; 	movl %eax, 4(%edx); 	movl %eax, (%edx); 	movw al, 8(%edx); 	; when we can spare a register. It reduces code size. //===---------------------------------------------------------------------===//. Evaluate what the best way to codegen sdiv X, (2^C) is. For X/8, we currently; get this:. define i32 @test1(i32 %X) {; %Y = sdiv i32 %X, 8; ret i32 %Y; }. _test1:; movl 4(%esp), %eax; movl %eax, %ecx; sarl $31, %ecx; shrl $29, %ecx; addl %ecx, %eax; sarl $3, %eax; ret. GCC knows several different ways to codegen it, one of which is this:. _test1:; movl 4(%esp), %eax; cmpl $-1, %eax; leal 7(%eax), %ecx; cmovle %ecx, %eax; sarl $3, %eax; ret. which is probably slower, but it's interesting at least :). //===---------------------------------------------------------------------===//. We are currently lowering large (1MB+) memmove/memcpy to rep/stosl and rep/movsl; We should leave these as libcalls for everything over a much lower threshold,; since libc is hand tuned for medium and large mem ops (avoiding RFO for large; stores, TLB preheating, etc). //===----------------------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:4102,reduce,reduces,4102,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['reduce'],['reduces']
Energy Efficiency," to Numeric Differentiation and works fine, since `; gamma_cdf()` doesn't have a lot of parameters. > In such cases, Numeric Differentiation fallback is only used for that; specific function. In above example, `gamma_cdf()` falls back to Numeric; Differentiation but other functions in `MathFuncs.h` will still be; able to use AD. This is because Clad is going to assume that you have a; derivative for this `gamma_cdf()` function, and the remaining functions will; use AD as expected. In the end, the remaining functions (including; `gamma_cdf()`) will try to fall back to Numeric Differentiation. However, if you want to add pure AD support, you need to make sure that all; your external functions are supported by Clad (meaning there is a custom; derivative defined for each of them). ### How do I test my new class while adding AD support?. Please look at the test classes that test the derivatives, evaluates,; fixtures, etc. (defined in 'roofit/roofitcore/test'). You can clone and adapt; these tests to your class as needed. For example:. > [roofit/roofitcore/test/testRooFuncWrapper.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooFuncWrapper.cxx). > Tip: Tests like above can be referenced to see which parts of RooFit already; support AD. ### How do I control my compile time?. This is an area of research that still needs some work. In most cases, the; compile times are reasonable, but with an increase in the level of complexity,; higher compile times may be encountered. ## Appendix B - Where does AD Logic Implementation reside?. Following classes provide several Helper Functions to translate existing logic; into AD-supported logic. a - RooFit::Detail::CodeSquashContext. b - RooFuncWrapper. ### a. RooFit::Detail::CodeSquashContext. > [roofit/roofitcore/inc/RooFit/Detail/CodeSquashContext.h](https://github.com/root-project/root/blob/master/roofit/roofitcore/inc/RooFit/Detail/CodeSquashContext.h). It handles how to create a C++ function out of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:29084,adapt,adapt,29084,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['adapt'],['adapt']
Energy Efficiency," to address spaces. For example,; ``DW_OP_push_object_address`` pushes the address of an object. Other contexts; implicitly push an address on the stack before evaluating an expression. For; example, the ``DW_AT_use_location`` attribute of the; ``DW_TAG_ptr_to_member_type``. The expression belongs to a source language type; which may apply to objects allocated in different kinds of storage. Therefore,; it is desirable that the expression that uses the address can do so without; regard to what kind of storage it specifies, including the address space of a; memory location description. For example, a pointer to member value may want to; be applied to an object that may reside in any address space. The DWARF ``DW_OP_xderef*`` operations allow a value to be converted into an; address of a specified address space which is then read. But it provides no; way to create a memory location description for an address in the non-default; address space. For example, AMDGPU variables can be allocated in the local; address space at a fixed address. The ``DW_OP_LLVM_form_aspace_address`` (see; :ref:`amdgpu-dwarf-memory-location-description-operations`) operation is defined; to create a memory location description from an address and address space. If; can be used to specify the location of a variable that is allocated in a; specific address space. This allows the size of addresses in an address space to; be larger than the generic type. It also allows a consumer great implementation; freedom. It allows the implicit conversion back to a value to be limited only to; the default address space to maintain compatibility with DWARF Version 5. For; other address spaces the producer can use the new operations that explicitly; specify the address space. In contrast, if the ``DW_OP_LLVM_form_aspace_address`` operation had been; defined to produce a value, and an implicit conversion to a memory location; description was defined, then it would be limited to the size of the generic; type (which m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:19442,allocate,allocated,19442,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['allocate'],['allocated']
Energy Efficiency," to an initialized memory buffer; that conforms to the requirements of the malloc/free device library V1; version implementation. If this attribute is absent, then the; amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-multigrid-sync-arg"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the multigrid synchronization pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-default-queue"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the default queue pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-completion-action"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the completion action pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-lds-size""=""min[,max]"" Min is the minimum number of bytes that will be allocated in the Local; Data Store at address zero. Variables are allocated within this frame; using absolute symbol metadata, primarily by the AMDGPULowerModuleLDS; pass. Optional max is the maximum number of bytes that will be allocated.; Note that min==max indicates that no further variables can be added to; the frame. This is an internal detail of how LDS variables are lowered,; language front ends should not set this attribute. ======================================= ==========================================================. Calling Conventions; -------------------. The AMDGPU backend supports the following calling conventions:. .. table:: AMDGPU Calling Conventions; :name: amdgpu-cc. =============================== ==========================================================; Calling Convention Description; =============================== ==========================================================; ``ccc`` The C calling convention. Used by default.; See :ref:`amdgpu-a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:51423,allocate,allocated,51423,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency," to define the range; TMultiGraph *mg = new TMultiGraph();. // create the first graph (points with gaussian noise); const Int_t n = 24;; Double_t x1[n] ;; Double_t y1[n] ;; //Generate the points along a X^3 with noise; TRandom rg;; rg.SetSeed(520);; for (Int_t i = 0; i < n; i++) {; x1[i] = rg.Uniform(0, 1);; y1[i] = TMath::Power(x1[i], 3) + rg.Gaus() * 0.06;; }. TGraph *gr1 = new TGraph(n,x1,y1);; gr1->SetMarkerColor(kBlue);; gr1->SetMarkerStyle(8);; gr1->SetMarkerSize(1);; mg->Add(gr1);. // create the second graph; TF1 *f_known=new TF1(""f_known"",""pow(x,3)"",0,1);; TGraph *gr2 = new TGraph(f_known);; gr2->SetMarkerColor(kRed);; gr2->SetMarkerStyle(8);; gr2->SetMarkerSize(1);; mg->Add(gr2);; //passing data to Rfot fitting; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; r[""x""]<<TVectorD(n, x1);; r[""y""]<<TVectorD(n, y1);; //creating a R data frame; r<<""ds<-data.frame(x=x,y=y)"";; //fitting x and y to X^power using Nonlinear Least Squares; r<<""m <- nls(y ~ I(x^power),data = ds, start = list(power = 1),trace = T)"";; //getting the exponent; Double_t power;; r[""summary(m)$coefficients[1]""]>>power;. TF1 *f_fitted=new TF1(""f_fitted"",""pow(x,[0])"",0,1);; f_fitted->SetParameter(0,power);; //plotting the fitted function; TGraph *gr3 = new TGraph(f_fitted);; gr3->SetMarkerColor(kGreen);; gr3->SetMarkerStyle(8);; gr3->SetMarkerSize(1);. mg->Add(gr3);; mg->Draw(""ap"");. //displaying basic results; TPaveText *pt = new TPaveText(0.1,0.6,0.5,0.9,""brNDC"");; pt->SetFillColor(18);; pt->SetTextAlign(12);; pt->AddText(""Fitting x^power "");; pt->AddText("" \""Blue\"" Points with gaussian noise to be fitted"");; pt->AddText("" \""Red\"" Known function x^3"");; TString fmsg;; fmsg.Form("" \""Green\"" Fitted function with power=%.4lf"",power);; pt->AddText(fmsg);; pt->Draw();; c1->Update();; return c1;; }; ~~~; In the first image you can see the blue dots which are the function `x^3` with gaussian noise, the red dots correspond to; the original function and the green ones correspond to the fitted ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:15887,power,power,15887,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,5,['power'],['power']
Energy Efficiency," to easily exchange ideas or; collaborate by sharing their analyses in a straight-forward and reproducible; way. Jupyter’s official C++ kernel(`Xeus-Cling; <https://github.com/jupyter-xeus/xeus-cling>`_) relies on Xeus, a C++; implementation of the kernel protocol, and Cling. Using C++ in the Jupyter; environment yields a different experience to C++ users. For example, Jupyter’s; visualization system can be used to render rich content such as images,; therefore bringing more interactivity into the Jupyter’s world. You can find; more information on `Xeus Cling's Read the Docs; <https://xeus-cling.readthedocs.io/en/latest/>`_ webpage. 2. **Interactive CUDA C++ with Cling:**. `CUDA <https://blogs.nvidia.com/blog/2012/09/10/what-is-cuda-2/>`_ is a platform; and Application Programming Interface (API) created by `NVIDIA; <https://www.nvidia.com/en-us/>`_. It controls `GPU; <https://en.wikipedia.org/wiki/Graphics_processing_unit>`_ (Graphical Processing; Unit) for parallel programming, enabling developers to harness the power of; graphic processing units (GPUs) to speed up applications. As an example,; `PIConGPU <https://github.com/ComputationalRadiationPhysics/picongpu>`_ is a; CUDA-based plasma physics application to solve the dynamics of a plasma by; computing the motion of electrons and ions in the plasma field. Interactive GPU; programming was made possible by extending Cling functionality to compile CUDA; C++ code. The new Cling-CUDA C++ can be used on Jupyter Notebook platform, and; enables big, interactive simulation with GPUs, easy GPU development and; debugging, and effective GPU programming learning. 3. **Clad:**. `Clad <https://compiler-research.org/clad/>`_ enables automatic differentiation; (AD) for C++. It was first developed as a plugin for Cling, and is now a plugin; for Clang compiler. Clad is based on source code transformation. Given C++; source code of a mathematical function, it can automatically generate C++ code; for computing derivatives of the fu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:1303,power,power,1303,interpreter/cling/docs/chapters/applications.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst,1,['power'],['power']
Energy Efficiency," to parse identifiers) has been updated to 15.1. * Clang now defines macro ``__LLVM_INSTR_PROFILE_GENERATE`` when compiling with; PGO instrumentation profile generation, and ``__LLVM_INSTR_PROFILE_USE`` when; compiling with PGO profile use. New Compiler Flags; ------------------. * ``-fverify-intermediate-code`` and its complement ``-fno-verify-intermediate-code``.; Enables or disables verification of the generated LLVM IR.; Users can pass this to turn on extra verification to catch certain types of; compiler bugs at the cost of extra compile time.; Since enabling the verifier adds a non-trivial cost of a few percent impact on; build times, it's disabled by default, unless your LLVM distribution itself is; compiled with runtime checks enabled.; * ``-fkeep-system-includes`` modifies the behavior of the ``-E`` option,; preserving ``#include`` directives for ""system"" headers instead of copying; the preprocessed text to the output. This can greatly reduce the size of the; preprocessed output, which can be helpful when trying to reduce a test case.; * ``-fassume-nothrow-exception-dtor`` is added to assume that the destructor of; a thrown exception object will not throw. The generated code for catch; handlers will be smaller. A throw expression of a type with a; potentially-throwing destructor will lead to an error. * ``-fopenacc`` was added as a part of the effort to support OpenACC in Clang. * ``-fcx-limited-range`` enables the naive mathematical formulas for complex; division and multiplication with no NaN checking of results. The default is; ``-fno-cx-limited-range``, but this option is enabled by ``-ffast-math``. * ``-fcx-fortran-rules`` enables the naive mathematical formulas for complex; multiplication and enables application of Smith's algorithm for complex; division. See SMITH, R. L. Algorithm 116: Complex division. Commun. ACM 5, 8; (1962). The default is ``-fno-cx-fortran-rules``. * ``-fvisibility-global-new-delete=<value>`` gives more freedom to users to; cont",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:15977,reduce,reduce,15977,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,2,['reduce'],['reduce']
Energy Efficiency," two maps. Some map-like containers also support efficient; iteration through the keys in sorted order. Map-like containers are the most; expensive sort, only use them if you need one of these capabilities. * a :ref:`set-like <ds_set>` container if you need to put a bunch of stuff into; a container that automatically eliminates duplicates. Some set-like; containers support efficient iteration through the elements in sorted order.; Set-like containers are more expensive than sequential containers. * a :ref:`sequential <ds_sequential>` container provides the most efficient way; to add elements and keeps track of the order they are added to the collection.; They permit duplicates and support efficient iteration, but do not support; efficient look-up based on a key. * a :ref:`string <ds_string>` container is a specialized sequential container or; reference structure that is used for character or byte arrays. * a :ref:`bit <ds_bit>` container provides an efficient way to store and; perform set operations on sets of numeric id's, while automatically; eliminating duplicates. Bit containers require a maximum of 1 bit for each; identifier you want to store. Once the proper category of container is determined, you can fine tune the; memory use, constant factors, and cache behaviors of access by intelligently; picking a member of the category. Note that constant factors and cache behavior; can be a big deal. If you have a vector that usually only contains a few; elements (but could contain many), for example, it's much better to use; :ref:`SmallVector <dss_smallvector>` than :ref:`vector <dss_vector>`. Doing so; avoids (relatively) expensive malloc/free calls, which dwarf the cost of adding; the elements to the container. .. _ds_sequential:. Sequential Containers (std::vector, std::list, etc); ---------------------------------------------------. There are a variety of sequential containers available for you, based on your; needs. Pick the first in this section that will do what",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:56622,efficient,efficient,56622,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency," type'd; pointers like the builtin function would) if one is available, otherwise; fall back on a system malloc/free. Does this sound like a good compromise? It would give us all of the; typesafety/elegance in the language while still allowing the user to do; all the cool stuff they want to... > 'alloca' on the other hand sounds like a good idea, and the; > implementation seems fairly language-independent so it doesn't have the; > problems with malloc listed above. Okay, once we get the above stuff figured out, I'll put it all in the; spec. > About indirect call:; > Your option #2 sounded good to me. I'm not sure I understand your; > concern about an explicit 'icall' instruction?. I worry too much. :) The other alternative has been removed. 'icall' is; now up in the instruction list next to 'call'. > I believe tail calls are relatively easy to identify; do you know why; > .NET has a tailcall instruction?. Although I am just guessing, I believe it probably has to do with the fact; that they want languages like Haskell and lisp to be efficiently runnable; on their VM. Of course this means that the VM MUST implement tail calls; 'correctly', or else life will suck. :) I would put this into a future; feature bin, because it could be pretty handy... > A pair of important synchronization instr'ns to think about:; > load-linked; > store-conditional. What is 'load-linked'? I think that (at least for now) I should add these; to the 'possible extensions' section, because they are not immediately; needed... > Other classes of instructions that are valuable for pipeline; > performance:; > conditional-move ; > predicated instructions. Conditional move is effectly a special case of a predicated; instruction... and I think that all predicated instructions can possibly; be implemented later in LLVM. It would significantly change things, and; it doesn't seem to be very necessary right now. It would seem to; complicate flow control analysis a LOT in the virtual machine. I would; tend ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt:5627,efficient,efficiently,5627,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,1,['efficient'],['efficiently']
Energy Efficiency," types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43280,schedul,scheduled,43280,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency," used now for building Deep Learning architecture in TMVA, while `TMVA::Types::kDNN` is now deprecated. `TMVA::Types::kDL` provides all the functionality of `TMVA::Types::kDNN`, i.e building fully connected dense layer, but in addition supports building convolutional and recurrent neural network architectures.; These release contains improvements in the `MethodDL` such as:; - fix droput support for dense layer; - add protection to avoid returning NaN in the cross-entropy loss function. In addition we have :. - New `TMVA::Executor` class to control the multi-thread running of TMVA. By default now MT running will be enabled only when `ROOT::EnabledImplicitMT()` is called. But we can take the control of the threads by using `TMVA::gConfig().EnableMT(...)` and `TMVA::gConfig().DisableMT()`. ### PyMVA; - add support when using the Tensorflow backend in Keras to control the number of threads; - add possibility to control options for configuring GPU running. FOr example we can now set the mode to allocate memory only as needed. This is required when using the new RTX gaming cards from NVIDIA. ## 2D Graphics Libraries. - In the statistics painting for 2D histograms, the central cell of; the underflow/overflow grid was not properly rendered for very large contents.; This problem was reported [here](https://root-forum.cern.ch/t/stat-box-for-th2/).; - The automatic placement of legend now ""sees"" TMultiGraph and THStack.; - Improve and simplify the drawing the 2D histogram's option ""ARR"".; - The option ARR can be combined with the option COL or COLZ.; - `TBox::DistancetoPrimitive` and `TBox::ExecuteEvent` now work in log scales (by Jérémie Dudouet).; - Take the line attributes into account when drawing a histogram with option bar or hbar.; They were ignored until now.; - The new draw option MIN0 makes same effect as gStyle->SetHistMinimumZero(1), but can be specified; individually for each histogram.; - Improve the line clipping when a histogram is drawn with option ""L"". The fol",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:18365,allocate,allocate,18365,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['allocate'],['allocate']
Energy Efficiency," used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42840,schedul,scheduled,42840,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency," v1.cend()); // warn: iterators of; // different containers; // used where the same; // container is; // expected; }. alpha.cplusplus.Move; (C++); Method calls on a moved-from object and copying a moved-from object will be; reported. struct A {; void foo() {}; };. void f() {; A a;; A b = std::move(a); // note: 'a' became 'moved-from' here; a.foo(); // warn: method call on a 'moved-from' object 'a'; }. Dead Code Alpha Checkers. Name, DescriptionExample. alpha.deadcode.UnreachableCode; (C, C++, ObjC); Check unreachable code. // C; int test() {; int x = 1;; while(x);; return x; // warn; }. // C++; void test() {; int a = 2;. while (a > 1); a--;. if (a > 1); a++; // warn; }. // Objective-C; void test(id x) {; return;; [x retain]; // warn; }. LLVM Checkers. Name, DescriptionExample. alpha.llvm.Conventions; (C); Check code for LLVM codebase conventions:. A StringRef should not be bound to a temporary std::string; whose lifetime is shorter than the StringRef's.; Clang AST nodes should not have fields that can allocate memory. OS X Alpha Checkers. Name, DescriptionExample. alpha.osx.cocoa.DirectIvarAssignment; (ObjC); Check that Objective C properties follow the following rule: the property; should be set with the setter, not though a direct assignment. @interface MyClass : NSObject {}; @property (readonly) id A;; - (void) foo;; @end. @implementation MyClass; - (void) foo {; _A = 0; // warn; }; @end. alpha.osx.cocoa.DirectIvarAssignmentForAnnotatedFunctions; (ObjC); Check for direct assignments to instance variables in the methods annotated; with objc_no_direct_instance_variable_assignment. @interface MyClass : NSObject {}; @property (readonly) id A;; - (void) fAnnotated __attribute__((; annotate(""objc_no_direct_instance_variable_assignment"")));; - (void) fNotAnnotated;; @end. @implementation MyClass; - (void) fAnnotated {; _A = 0; // warn; }; - (void) fNotAnnotated {; _A = 0; // no warn; }; @end. alpha.osx.cocoa.InstanceVariableInvalidation; (ObjC); Check that the invalidat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/alpha_checks.html:7058,allocate,allocate,7058,interpreter/llvm-project/clang/www/analyzer/alpha_checks.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/alpha_checks.html,1,['allocate'],['allocate']
Energy Efficiency," validation.; (The original use case was for filling database fields, requiring an exact; field label and data type match.). If, however, all methods fail and there is only one C++ exception (the other; exceptions originating from argument conversion, never succeeding to call; into C++), this C++ exception will be preferentially reported and will have; the original C++ type. `Return values`; ---------------. Most return types are readily amenable to automatic memory management: builtin; returns, by-value returns, (const-)reference returns to internal data, smart; pointers, etc.; The important exception is pointer returns.; ; A function that returns a pointer to an object over which Python should claim; ownership, should have its ``__creates__`` flag set through its; :doc:`pythonization <pythonizations>`.; Well-written APIs will have clear clues in their naming convention about the; ownership rules.; For example, functions called ``New...``, ``Clone...``, etc. can be expected; to return freshly allocated objects.; A basic name-matching in the pythonization then makes it simple to mark all; these functions as creators. The return values are :ref:`auto-casted <sec-auto-casting-label>`. `\*args and \*\*kwds`; ---------------------. C++ default arguments work as expected.; Keywords, however, are a Python language feature that does not exist in C++.; Many C++ function declarations do have formal arguments, but these are not; part of the C++ interface (the argument names are repeated in the definition,; making the names in the declaration irrelevant: they do not even need to be; provided).; Thus, although ``cppyy`` will map keyword argument names to formal argument; names from the C++ declaration, use of this feature is not recommended unless; you have a guarantee that the names in C++ the interface are maintained.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete() # uses default argument; >>> c.m_int; 42; >>> c = Concrete(13) # uses ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:12929,allocate,allocated,12929,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,1,['allocate'],['allocated']
Energy Efficiency," vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmin``' intrinsic performs the floating-point ``MIN``; reduction (:ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>`) of the; vector operand ``val`` on each enabled lane, taking the minimum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``+QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the largest floating-point value for the; result type. If only ``nnan`` is set then the neutral value is ``+Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>` intrinsic (and thus the; '``llvm.minnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum element magnitude ``0.0`` and containing both ``+0.0`` and; ``-0.0`` elements, the sign of the result is unspecified. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmin.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float QNAN, float QNAN, float QNAN, float QNAN>; %reduction = call float @llvm.vector.reduce.fmin.v4f32(<4 x float> %masked.a); %also.r = call float @llvm.minnum.f32(float %reduction, float %start). .. _int_get_active_lane_mask:. '``llvm.get.active.la",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:775779,reduce,reduce,775779,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency," vector operations. Instead of using builtins, you should use the functions; defined in target-specific header files like ``<xmmintrin.h>``, which define; portable wrappers for these. Many of the Clang versions of these functions are; implemented directly in terms of :ref:`extended vector support; <langext-vectors>` instead of builtins, in order to reduce the number of; builtins that we need to implement. ``__builtin_alloca``; --------------------. ``__builtin_alloca`` is used to dynamically allocate memory on the stack. Memory; is automatically freed upon function termination. **Syntax**:. .. code-block:: c++. __builtin_alloca(size_t n). **Example of Use**:. .. code-block:: c++. void init(float* data, size_t nbelems);; void process(float* data, size_t nbelems);; int foo(size_t n) {; auto mem = (float*)__builtin_alloca(n * sizeof(float));; init(mem, n);; process(mem, n);; /* mem is automatically freed at this point */; }. **Description**:. ``__builtin_alloca`` is meant to be used to allocate a dynamic amount of memory; on the stack. This amount is subject to stack allocation limits. Query for this feature with ``__has_builtin(__builtin_alloca)``. ``__builtin_alloca_with_align``; -------------------------------. ``__builtin_alloca_with_align`` is used to dynamically allocate memory on the; stack while controlling its alignment. Memory is automatically freed upon; function termination. **Syntax**:. .. code-block:: c++. __builtin_alloca_with_align(size_t n, size_t align). **Example of Use**:. .. code-block:: c++. void init(float* data, size_t nbelems);; void process(float* data, size_t nbelems);; int foo(size_t n) {; auto mem = (float*)__builtin_alloca_with_align(; n * sizeof(float),; CHAR_BIT * alignof(float));; init(mem, n);; process(mem, n);; /* mem is automatically freed at this point */; }. **Description**:. ``__builtin_alloca_with_align`` is meant to be used to allocate a dynamic amount of memory; on the stack. It is similar to ``__builtin_alloca`` but accepts a s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:97431,allocate,allocate,97431,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['allocate'],['allocate']
Energy Efficiency," version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (**`TGeoElementTable`** class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ``` {.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ```. One can make materials or mixtures from radionuclides:. ``` {.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""C14"", c14, 2.0);; ```. The following properties of radionuclides can be currently accessed via; getters in the **`TGeoElementRN`** class:. Atomic number and charge (from the base class **`TGeoElement`**). - Isomeric number (`ISO`); - ENDF code - following the convention: `ENDF=10000*Z+100*A+ISO`; - Isomeric energy level [`MeV`]; - Mass excess [`MeV`]; - Half life [`s`]; - Spin/Parity - can be retrieved with: `TGeoElementRN::GetTitle()`; - Hynalation and ingestion toxicities; - List of decays - `TGeoElementRN::GetDecays()`. The radioactive decays of a radionuclide are represented by the class; **`TGeoDecayChannel`** and they are stored in a **`TObjArray`**. Decay; provides:. - Decay mode; - Variation of isomeric number; - `Q` value for the decay [`GeV`]; - Parent element; - Daughter element. Radionuclides are linked one to each other via their decays, until the; last element in the decay chain which must be stable. One can iterate; decay chains using the iterator **`TGeoElemIter`**:. ``` {.cpp}; root[] TGeoElemIter next(c14);; root[] TGeoElementRN *elem;; root[] while ((elem=next())) next.Print();; 6-C-014 (100% BetaMinus) T1/2=1.81e+11; 7-N-014 stable; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:18536,charge,charge,18536,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['charge'],['charge']
Energy Efficiency," via refactoring of the; (:doc:`IR standard<LangRef>`) **before** the merge of the new target changes,; following the :ref:`IR backwards compatibility`. * The code conforms to all of the policies laid out in this developer policy; document, including license, patent, and coding standards. * The target should have either reasonable documentation on how it; works (ISA, ABI, etc.) or a publicly available simulator/hardware; (either free or cheap enough) - preferably both. This allows; developers to validate assumptions, understand constraints and review code; that can affect the target. In addition, the rules for a back-end to be promoted to **official** are:. * The target must have addressed every other minimum requirement and; have been stable in tree for at least 3 months. This cool down; period is to make sure that the back-end and the target community can; endure continuous upstream development for the foreseeable future. * The target's code must have been completely adapted to this policy; as well as the :doc:`coding standards<CodingStandards>`. Any exceptions that; were made to move into experimental mode must have been fixed **before**; becoming official. * The test coverage needs to be broad and well written (small tests,; well documented). The build target ``check-all`` must pass with the; new target built, and where applicable, the ``test-suite`` must also; pass without errors, in at least one configuration (publicly; demonstrated, for example, via buildbots). * Public buildbots need to be created and actively maintained, unless; the target requires no additional buildbots (ex. ``check-all`` covers; all tests). The more relevant and public the new target's CI infrastructure; is, the more the LLVM community will embrace it. To **continue** as a supported and official target:. * The maintainer(s) must continue following these rules throughout the lifetime; of the target. Continuous violations of aforementioned rules and policies; could lead to complete removal ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:41558,adapt,adapted,41558,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['adapt'],['adapted']
Energy Efficiency," way you use it is you take the original code and provide it to; BinInterface; then you do optimizations to it, then you put it in the; trace cache. The BinInterface tries to find live-outs for traces so that it can do; register allocation on just the trace, and stitch the trace back into; the original code. It has to preserve the live-ins and live-outs when; it does its register allocation. (On exits from the trace we have; epilogues that copy live-outs back into the right registers, but; live-ins have to be in the right registers.). Limitations of BinInterface; ---------------------------. It does copy insertions for PHIs, which it infers from the machine; code. The mapping info inserted by LLC is not sufficient to determine; the PHIs. It does not handle integer or floating-point condition codes and it; does not handle floating-point register allocation. It is not aggressively able to use lots of registers. There is a problem with alloca: we cannot find our spill space for; spilling registers, normally allocated on the stack, if the trace; follows an alloca(). What might be an acceptable solution would be to; disable trace generation on functions that have variable-sized; alloca()s. Variable-sized allocas in the trace would also probably; screw things up. Because of the FP and alloca limitations, the BinInterface is; completely disabled right now. Demo; ----. This is a demo of the Ball & Larus version that does NOT use 2-level; profiling. 1. Compile program with llvm-gcc.; 2. Run opt -lowerswitch -paths -emitfuncs on the bytecode.; -lowerswitch change switch statements to branches; -paths Ball & Larus path-profiling algorithm; -emitfuncs emit the table of functions; 3. Run llc to generate SPARC assembly code for the result of step 2.; 4. Use g++ to link the (instrumented) assembly code. We use a script to do all this:; ------------------------------------------------------------------------------; #!/bin/sh; llvm-gcc $1.c -o $1; opt -lowerswitch -paths -emitfuncs ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-26-Reoptimizer2.txt:1629,allocate,allocated,1629,interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-26-Reoptimizer2.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-26-Reoptimizer2.txt,1,['allocate'],['allocated']
Energy Efficiency," we look at the *Dynamic Dispatch Stall Cycles* table, we see the counter for; SCHEDQ reports 272 cycles. This counter is incremented every time the dispatch; logic is unable to dispatch a full group because the scheduler's queue is full. Looking at the *Dispatch Logic* table, we see that the pipeline was only able to; dispatch two micro opcodes 51.5% of the time. The dispatch group was limited to; one micro opcode 44.6% of the cycles, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, pre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31400,schedul,scheduler,31400,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency," will create an ``AllocaInst`` instance that represents the allocation of one; integer in the current stack frame, at run time. Each ``Instruction`` subclass; is likely to have varying default parameters which change the semantics of the; instruction, so refer to the `doxygen documentation for the subclass of; Instruction <https://llvm.org/doxygen/classllvm_1_1Instruction.html>`_ that; you're interested in instantiating. *Naming values*. It is very useful to name the values of instructions when you're able to, as; this facilitates the debugging of your transformations. If you end up looking; at generated LLVM machine code, you definitely want to have logical names; associated with the results of instructions! By supplying a value for the; ``Name`` (default) parameter of the ``Instruction`` constructor, you associate a; logical name with the result of the instruction's execution at run time. For; example, say that I'm writing a transformation that dynamically allocates space; for an integer on the stack, and that integer is going to be used as some kind; of index by some other code. To accomplish this, I place an ``AllocaInst`` at; the first point in the first ``BasicBlock`` of some ``Function``, and I'm; intending to use it within the same ``Function``. I might do:. .. code-block:: c++. auto *pa = new AllocaInst(Type::Int32Ty, 0, ""indexLoc"");. where ``indexLoc`` is now the logical name of the instruction's execution value,; which is a pointer to an integer on the run time stack. *Inserting instructions*. There are essentially three ways to insert an ``Instruction`` into an existing; sequence of instructions that form a ``BasicBlock``:. * Insertion into the instruction list of the ``BasicBlock``. Given a ``BasicBlock* pb``, an ``Instruction* pi`` within that ``BasicBlock``,; and a newly-created instruction we wish to insert before ``*pi``, we do the; following:. .. code-block:: c++. BasicBlock *pb = ...;; Instruction *pi = ...;; auto *newInst = new Instruction(...);. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:114963,allocate,allocates,114963,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocates']
Energy Efficiency," with the Library, with the complete machine-readable ""work that; uses the Library"", as object code and/or source code, so that the; user can modify the Library and then relink to produce a modified; executable containing the modified Library. (It is understood; that the user who changes the contents of definitions files in the; Library will not necessarily be able to recompile the application; to use the modified definitions.). b) Use a suitable shared library mechanism for linking with the; Library. A suitable mechanism is one that (1) uses at run time a; copy of the library already present on the user's computer system,; rather than copying library functions into the executable, and (2); will operate properly with a modified version of the library, if; the user installs one, as long as the modified version is; interface-compatible with the version that the work was made with. c) Accompany the work with a written offer, valid for at; least three years, to give the same user the materials; specified in Subsection 6a, above, for a charge no more; than the cost of performing this distribution. d) If distribution of the work is made by offering access to copy; from a designated place, offer equivalent access to copy the above; specified materials from the same place. e) Verify that the user has already received a copy of these; materials or that you have already sent this user a copy. For an executable, the required form of the ""work that uses the; Library"" must include any data and utility programs needed for; reproducing the executable from it. However, as a special exception,; the materials to be distributed need not include anything that is; normally distributed (in either source or binary form) with the major; components (compiler, kernel, and so on) of the operating system on; which the executable runs, unless that component itself accompanies; the executable. It may happen that this requirement contradicts the license; restrictions of other proprietary librarie",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/LGPL2_1.txt:16171,charge,charge,16171,LGPL2_1.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/LGPL2_1.txt,2,['charge'],['charge']
Energy Efficiency," you that `inf != inf` if you define `inf` as `std::numeric_limits<double>::infinity()`, which is inconsistent with the regular `==` operator. This is unexpected, because one would expect that if two numbers are considered exactly equal, they would also be considered equal within any range.; Therefore, the behavior of `TMath::AreEqualAbs()` was changed to return always `true` if the `==` comparison would return `true`. ## RooFit Libraries. ### Changes in RooFormulaVar and RooGenericPdf. The TFormula-based RooFit classes `RooFormulaVar` and `RooGenericPdf` change a bit their behavior to be more consistent:. 1. No matter which variables you pass to the constructor, only the variables that the formula depends on are registered as value servers.; 2. Similarly, the `dependents()` method of RooFormulaVar and RooGenericPdf will only return the list of actual value servers. ### Removal of the RooGenFunction and RooMultiGenFunction classes. The `RooGenFunction` was only a lightweight adaptor that exports a RooAbsReal as a `ROOT::Math::IGenFunction`.; The same can be easily achieved with the generic `ROOT::Math::Functor1D`, so in the spirit of not duplicating interfaces, the `RooGenFunction` is removed in this release. Here is an example that shows how to replace it in the unlikely case you were using it:. ```C++; RooArgSet normSet{x}; // normalization set. // Old way 1: create a RooGenFunction:; RooGenFunction func1{pdf, x, {}, normSet};. // Old way 2: use `RooAbsReal::iGenFunction()`:; std::unique_ptr<ROOT::Math::IGenFunction> func2{; pdf.iGenFunction(x, normSet); };. // How to do it now:; RooFunctor functor{pdf, x, {}, normSet};; ROOT::Math::Functor1D func3{functor};; // Functor1D takes by reference, so the RooFunctor also needs to stay alive.; ```. For the same reason, the `RooMultiGenFunction` class that implements a multidimensional `ROOT::Math::IMultiGenFunction` is removed too.; It can easily be replaced by a `ROOT::Math::Functor`:. ```C++; RooFunctor functor{pdf, obse",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:11704,adapt,adaptor,11704,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,1,['adapt'],['adaptor']
Energy Efficiency," { fp128, i32 } @llvm.frexp.f128.i32(fp128 %Val); declare { ppc_fp128, i32 } @llvm.frexp.ppcf128.i32(ppc_fp128 %Val); declare { <2 x float>, <2 x i32> } @llvm.frexp.v2f32.v2i32(<2 x float> %Val). Overview:; """""""""""""""""". The '``llvm.frexp.*``' intrinsics perform the frexp function. Arguments:; """""""""""""""""""". The argument is a :ref:`floating-point <t_floating>` or; :ref:`vector <t_vector>` of floating-point values. Returns two values; in a struct. The first struct field matches the argument type, and the; second field is an integer or a vector of integer values with the same; number of elements as the argument. Semantics:; """""""""""""""""""". This intrinsic splits a floating point value into a normalized; fractional component and integral exponent. For a non-zero argument, returns the argument multiplied by some power; of two such that the absolute value of the returned value is in the; range [0.5, 1.0), with the same sign as the argument. The second; result is an integer such that the first result raised to the power of; the second result is the input argument. If the argument is a zero, returns a zero with the same sign and a 0; exponent. If the argument is a NaN, a NaN is returned and the returned exponent; is unspecified. If the argument is an infinity, returns an infinity with the same sign; and an unspecified exponent. .. _int_log:. '``llvm.log.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.log`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @llvm.log.f32(float %Val); declare double @llvm.log.f64(double %Val); declare x86_fp80 @llvm.log.f80(x86_fp80 %Val); declare fp128 @llvm.log.f128(fp128 %Val); declare ppc_fp128 @llvm.log.ppcf128(ppc_fp128 %Val). Overview:; """""""""""""""""". The '``llvm.log.*``' intrinsics compute the base-e logarithm of the specified; value. Arguments:; """""""""""""""""""". The argument and return value are floating-point numbers of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:567192,power,power,567192,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency," | pinf | Positive infinity | 512 |; +-------+----------------------+---------------+. ``alignstack(<n>)``; This indicates the alignment that should be considered by the backend when; assigning this parameter to a stack slot during calling convention; lowering. The enforcement of the specified alignment is target-dependent,; as target-specific calling convention rules may override this value. This; attribute serves the purpose of carrying language specific alignment; information that is not mapped to base types in the backend (for example,; over-alignment specification through language attributes). ``allocalign``; The function parameter marked with this attribute is the alignment in bytes of the; newly allocated block returned by this function. The returned value must either have; the specified alignment or be the null pointer. The return value MAY be more aligned; than the requested alignment, but not less aligned. Invalid (e.g. non-power-of-2); alignments are permitted for the allocalign parameter, so long as the returned pointer; is null. This attribute may only be applied to integer parameters. ``allocptr``; The function parameter marked with this attribute is the pointer; that will be manipulated by the allocator. For a realloc-like; function the pointer will be invalidated upon success (but the; same address may be returned), for a free-like function the; pointer will always be invalidated. ``readnone``; This attribute indicates that the function does not dereference that; pointer argument, even though it may read or write the memory that the; pointer points to if accessed through other pointers. If a function reads from or writes to a readnone pointer argument, the; behavior is undefined. ``readonly``; This attribute indicates that the function does not write through this; pointer argument, even though it may write to the memory that the pointer; points to. If a function writes to a readonly pointer argument, the behavior is; undefined. ``writeonly``; This at",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:68559,power,power-of-,68559,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power-of-']
Energy Efficiency," | use server in read-only mode (default) |; | readwrite, rw | use server in read-write mode |; | global | let scan global directories for canvases and files (default) |; | noglobal | disable scan of global directories |; | basic_sniffer | use basic `TRootSniffer` without support of hist, gpad, graph, tree classes |. Example:. ```cpp; new THttpServer(""http:8080;ro;noglobal""); ```. ## Registering objects. At any time, one could register other objects with the command:. ```cpp; TGraph* gr = new TGraph(10);; gr->SetName(""gr1"");; serv->Register(""graphs/subfolder"", gr);; ```. One should specify sub-folder name, where objects will be registered.; If sub-folder name does not starts with slash `/`, than top-name folder `/Objects/` will be prepended.; At any time one could unregister objects:. ```cpp; serv->Unregister(gr);; ```. THttpServer does not take ownership over registered objects - they should be deleted by user. If the objects content is changing in the application, one could enable monitoring flag in the browser - then objects view will be regularly updated. ## Accessing file system. THttpServer provides partial access to the files from file system.; First of all, JSROOT scripts and files can be accessed via ""jsrootsys/"" path like ""http://localhost:8080/jsrootsys/modules/core.mjs"".; Files from ROOT install directory can be get via ""rootsys/"" path like ""http://localhost:8080/rootsys/icons/about.xpm"".; Also files from current directory where ROOT is running can be accessed via ""currentdir/"" path like ""http://localhost:8080/currentdir/file.txt"". If necessary, one can add custom path as well, using [THttpServer::AddLocation](https://root.cern/doc/master/classTHttpServer.html#a5322c3bbfddb8eb6849297d83ccaf87f) method:. ```cpp; serv->AddLocation(""mydir/"", ""/home/user/specials"");; ```. Then files from that directory could be addressed via URL like ""http://localhost:8080/mydir/myfile.root"". ## Command interface. THttpServer class provide simple interface to invoke command ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:3967,monitor,monitoring,3967,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['monitor'],['monitoring']
Energy Efficiency," | vertical frame - it will fit the whole width. If it is |; | | a horizontal frame - after the positioning of all |; | | frames the available ""free"" width space is shared |; | | between the frames having this hint |; +------------------+---------------------------------------------------------+; | `kLHintsExpandY` | specifies the frame to be expanded up to the height of |; | | the container frame. If the container frame is a |; | | horizontal frame - it will fit the whole height. If the |; | | container frame is a vertical frame - after the |; | | arrangement of all frames the available ""free"" height |; | | space is shared between the frames having this hint |; +------------------+---------------------------------------------------------+; | `kLHintsNormal` | = `kLHintsLeft | kLHintsTop` - default hints |; +------------------+---------------------------------------------------------+. Layout policy:. Child frames never modify their container frame. The container frame can; (or cannot) adapt its size in the layout process. It can show all or a; part of its frames. Every **`TGFrame`** object has a default minimum; size (1, 1) assured by **`TGWindow`**. ## Event Processing: Signals and Slots. Event handling covers the interaction between different objects and; between the user and the objects in an application. There are two; general ways for the user to interact with an application: the keyboard; and the mouse. The Graphical User Interface is as a bridge between the; user and the program - it provides methods to detect the user actions; and instruments that do something as a reaction of these actions. The; user communicates with an application through the window system. The; window system reports interaction events to the application. The; application in turn forwards them to the currently active window. The; objects/widgets receive the events and react to them according to the; application functionality. ![](pictures/0200020B.jpg). The signals/slot communication mech",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md:39721,adapt,adapt,39721,documentation/users-guide/WritingGUI.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md,1,['adapt'],['adapt']
Energy Efficiency," }. void f();. void test() {; pthread_once_t pred = {0x30B1BCBA, {0}};; pthread_once(&pred, f);; // warn: call to 'pthread_once' uses the local variable; }. void test() {; void *p = malloc(0); // warn: allocation size of 0 bytes; }. void test() {; void *p = calloc(0, 42); // warn: allocation size of 0 bytes; }. void test() {; void *p = malloc(1);; p = realloc(p, 0); // warn: allocation size of 0 bytes; }. void test() {; void *p = alloca(0); // warn: allocation size of 0 bytes; }. void test() {; void *p = valloc(0); // warn: allocation size of 0 bytes; }. unix.Malloc; (C); Check for memory leaks, double free, and use-after-free and offset problems; involving malloc. void test() {; int *p = malloc(1);; free(p);; free(p); // warn: attempt to free released memory; }. void test() {; int *p = malloc(sizeof(int));; free(p);; *p = 1; // warn: use after free; }. void test() {; int *p = malloc(1);; if (p); return; // warn: memory is never released; }. void test() {; int a[] = { 1 };; free(a); // warn: argument is not allocated by malloc; }. void test() {; int *p = malloc(sizeof(char));; p = p - 1;; free(p); // warn: argument to free() is offset by -4 bytes; }. unix.MallocSizeof; (C); Check for dubious malloc, calloc or; realloc arguments involving sizeof. void test() {; long *p = malloc(sizeof(short));; // warn: result is converted to 'long *', which is; // incompatible with operand type 'short'; free(p);; }. unix.MismatchedDeallocator; (C, C++, ObjC); Check for mismatched deallocators (e.g. passing a pointer allocating; with new to free()). // C, C++; void test() {; int *p = (int *)malloc(sizeof(int));; delete p; // warn; }. // C, C++; void __attribute((ownership_returns(malloc))) *user_malloc(size_t);. void test() {; int *p = (int *)user_malloc(sizeof(int));; delete p; // warn; }. // C, C++; void test() {; int *p = new int;; free(p); // warn; }. // C, C++; void test() {; int *p = new int[1];; realloc(p, sizeof(long)); // warn; }. // C, C++; template <typename T>; struct Simp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html:24630,allocate,allocated,24630,interpreter/llvm-project/clang/www/analyzer/available_checks.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html,1,['allocate'],['allocated']
Energy Efficiency,"""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mca` isn't always able to simulate them; perfectly. Modifying the scheduling model isn't always a viable; option though (maybe because the instruction is modeled incorrectly on; purpose or the instruction's behaviour is quite complex). The; CustomBehaviour class can be used in these cases to enforce proper; instruction modeling (often by customizing data dependencies and detecting; hazards that :program:`llvm-mca` has no way of knowing about). :program:`llvm-mca` comes with one generic and multiple target specific; CustomBehaviour classes. The generic class will be used if the ``-disable-cb``; flag is used or if a target specific CustomBehaviour class doesn't exist for; that target. (The generic class does nothing.) Currently, the CustomBehaviour; class is only a part of the in-order pipeline, but there are plans to add it; to the out-of-order pipeline in the future. CustomBehaviour's main method is `checkCustomHazard()` which uses the; current instruction and a list of all instructions still executing within; the pipeline to determine if the current instruction should be dispatched.; As output, the method returns an integer ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:44085,schedul,scheduling,44085,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency,""""""""""""". The '``llvm.vp.reduce.or``' intrinsic performs the integer ``OR`` reduction; (:ref:`llvm.vector.reduce.or <int_vector_reduce_or>`) of the vector operand; ``val`` on each enabled lane, performing an '``or``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.or.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %masked.a); %also.r = or i32 %reduction, %start. .. _int_vp_reduce_xor:. '``llvm.vp.reduce.xor.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.xor.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.xor.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``XOR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:760722,reduce,reduce,760722,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"""""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fadd.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fadd.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``ADD`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fadd``' intrinsic performs the floating-point ``ADD``; reduction (:ref:`llvm.vector.reduce.fadd <int_vector_reduce_fadd>`) of the; vector operand ``val`` on each enabled lane, adding it to the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``-0.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to ``start_value``. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fadd; <int_vector_reduce_fadd>`) for more detail on the semantics of the reduction. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fadd.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float -0.0, float -0.0, float -0.0, float",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:751340,reduce,reduce,751340,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"""""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmul.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fmul.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MUL`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmul``' intrinsic performs the floating-point ``MUL``; reduction (:ref:`llvm.vector.reduce.fmul <int_vector_reduce_fmul>`) of the; vector operand ``val`` on each enabled lane, multiplying it by the scalar; `start_value``. Disabled lanes are treated as containing the neutral value; ``1.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to the starting value. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fmul; <int_vector_reduce_fmul>`) for more detail on the semantics. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmul.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float 1.0, float 1.0, float 1.0, float 1.0>; %also.r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:755552,reduce,reduce,755552,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmaximum:. '``llvm.vector.reduce.fmaximum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmaximum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmaximum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmaximum.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maximum.*``'; intrinsic. That is, this intrinsic propagates NaNs and +0.0 is considered; greater than -0.0. If any element of the vector is a NaN, the result is NaN. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fminimum:. '``llvm.vector.reduce.fminimum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fminimum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fminimum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fminimum.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minimum.*``'; intrinsic. That is, this intrinsic propagates NaNs and -0.0 is considered less; than +0.0. If any element of the vector is a NaN, the result is NaN. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. '``llvm.vector.insert``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. ; Insert fixed type into scalable type; declare <vscale x 4 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:661434,reduce,reduce,661434,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmax.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmax.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmax``' intrinsic performs the floating-point ``MAX``; reduction (:ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>`) of the; vector operand ``val`` on each enabled lane, taking the maximum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``-QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the smallest floating-point value for the; result type. If only ``nnan`` is set then the neutral value is ``-Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>` intrinsic (and thus the; '``llvm.maxnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:772098,reduce,reduce,772098,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmin.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmin.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmin``' intrinsic performs the floating-point ``MIN``; reduction (:ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>`) of the; vector operand ``val`` on each enabled lane, taking the minimum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``+QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the largest floating-point value for the; result type. If only ``nnan`` is set then the neutral value is ``+Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>` intrinsic (and thus the; '``llvm.minnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:774972,reduce,reduce,774972,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,""", ""std::vector<float>"").Unwrap();; model->AddProjectedField(std::move(aliasVec), [](const std::string &fieldName) {; if (fieldName == ""aliasVec"") return ""vec"";; else return ""vec._0"";; });; ```; Projected fields are stored as part of the metadata. - Improvements on the internal `RField` value API. The `RFieldValue` class has been deprecated in favor of `RField::Value` and the related interfaces have changed accordingly (see [#13219](https://github.com/root-project/root/pull/13219) and [#13264](https://github.com/root-project/root/pull/13264)).; If you were not using `RField::(Read|Append)` directly, this change should not impact you. - The new `RNTupleImporter` class provides automatic conversion of TTree to RNTuple.; Note that not all of the C++ types supported in TTree are currently supported in RNTuple. - Many bug fixes and performance improvements. Please, report any issues regarding the abovementioned features should you encounter them.; RNTuple is still experimental and is scheduled to become production grade by end of 2024.; Thus, we appreciate feedback and suggestions for improvement. ## Histogram Libraries. ## Math Libraries. ### Minuit2 is now the default minimizer. Many ROOT-based frameworks and users employ Minuit2 as the minimizer of choice for a long time already.; Therefore, Minuit2 is now the default minimizer used by ROOT.; This affects also **RooFit**, which inherits the default minimizer from ROOT Math. The default can be changed back to the old Minuit implementation as follows:; ```c++; ROOT::Math::MinimizerOptions::SetDefaultMinimizer(""Minuit"");; ```. Alternatively, you can add this line to your `~/.rootrc` file:; ```; Root.Fitter: Minuit; ```. ### Behavior change of `TMath::AreEqualAbs()`. The `TMath::AreEqualAbs()` compares two numbers for equality within a certain absolute range.; So far, it would tell you that `inf != inf` if you define `inf` as `std::numeric_limits<double>::infinity()`, which is inconsistent with the regular `==` operator. T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:9851,schedul,scheduled,9851,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Diff",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1918,reduce,reduces,1918,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['reduce'],['reduces']
Energy Efficiency,"# C++ Modules in ROOT. Technology Overview. *Vassil Vassilev, Oksana Shadura, Yuka Takahashi and Raphael Isemann*. ## Overview. ROOT has several features which interact with libraries and require implicit; header inclusion. This can be triggered by reading or writing data on disk,; or user actions at the prompt. Often, the headers are immutable and reparsing is; redundant. C++ Modules are designed to minimize the reparsing of the same; header content by providing an efficient on-disk representation of C++ Code. The ROOT v6.16 release came with a preview of the module technology;; dedicated binaries have been built and can be reproduced by passing; `-Druntime_cxxmodules=On` as configure flag. The goals of this technology are:; * Gain feedback from early adoption -- the technology is being long anticipated; by some of the users of ROOT. It improves correctness of ROOT and improves; performance when carefully adopted.; * Study performance bottlenecks -- the feature is designed with performance; considerations in mind. In this document we describe the current performance; bottlenecks and trade-offs.; * Understand if the gradual migration policy is sufficient -- C++ Modules in; ROOT support gradual migration. In particular, ROOT can enable C++ Modules for; itself and still run in legacy mode for the third-party code (generating; rootmap files and other scaffolding). C++ Modules are here and we would like to give a brief introduction of how the; feature works, what are its pros and cons, what's the current state of the; implementation and how third-party code can use it. Read more [[1]]. C++ Modules in ROOT are default since v6.20 (Unix) and v6.22 (OSX). ## Design Goals. * Coherence with standard C++ -- C++ Modules TS is advancing and will be; likely part the upcoming C++20 standard;; * Performance -- provide performance that is competitive to ROOT with PCH and; advance further the implementation of the C++ Modules in clang to optimize; memory footprint and execution time;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:471,efficient,efficient,471,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['efficient'],['efficient']
Energy Efficiency,"# Concluding Remarks #. This is the end of our guided tour for beginners through ROOT. There is; still a lot coming to mind to be said, but by now you are experienced; enough to use the ROOT documentation, most importantly the **[ROOT home; page](http://root.cern.ch)** and the **[ROOT reference; guide](https://root.cern/doc/master/)** with the; documentation of all ROOT classes, or the **[ROOT users; manual](https://root.cern/manual/)**. A very useful way for you to continue exploring ROOT is to study the; examples in the sub-directory `tutorials/` of any ROOT installation. There are some powerful features of ROOT which were not treated in this; document, e.g. packages named RooFit and RooStats providing an advanced; framework for model building, fitting and statistical analysis. The ROOT; namespace `TMVA` offers multi-variate analysis tools including an artificial; neural network and many other advanced tools for classification; problems. The remarkable ability of ROOT to handle large data volumes; was already mentioned in this guide, implemented through the class; `TTree`. But there is still much more for you to explore!. **End of this guide ... but hopefully not of your interaction with ROOT !**; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/concludingRemarks.md:596,power,powerful,596,documentation/primer/concludingRemarks.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/concludingRemarks.md,1,['power'],['powerful']
Energy Efficiency,"# Copyright (C) 1995-2019, Rene Brun and Fons Rademakers.; # All rights reserved.; #; # For the licensing terms see $ROOTSYS/LICENSE.; # For the list of contributors see $ROOTSYS/README/CREDITS. ROOT_ADD_GTEST(drawUnit draw.cxx LIBRARIES ROOTHistDraw); # On Windows, this test receives ""unexpected diagnostic of severity 2000""; # because ""pointer was truncated (due a missing dictionary)"" and then trying; # to allocate ""an object of abstract class type 'RHistImplBase'"".; if(NOT MSVC OR win_broken_tests); ROOT_ADD_GTEST(ioUnit io.cxx LIBRARIES ROOTHistDraw); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/histdrawv7/test/CMakeLists.txt:411,allocate,allocate,411,hist/histdrawv7/test/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/histdrawv7/test/CMakeLists.txt,1,['allocate'],['allocate']
Energy Efficiency,"# Example Analysis. This chapter is an example of a typical physics analysis. Large data; files are chained together and analyzed using the **`TSelector`** class. ## Explanation. This script uses four large data sets from the H1 collaboration at DESY; Hamburg. One can access these data sets (277 Mbytes) from the ROOT web; site at: <ftp://root.cern.ch/root/h1analysis/>. The physics plots generated by this example cannot be produced using; smaller data sets. There are several ways to analyze data stored in a ROOT Tree. - Using `TTree::Draw`:. - This is very convenient and efficient for small tasks. A; **`TTree`**::Draw call produces one histogram at the time. The; histogram is automatically generated. The selection expression may; be specified in the command line. - Using the **`TTreeViewer`**:. - This is a graphical interface to `TTree::Draw` with the same; functionality. - Using the code generated by `TTree::MakeClass`:. - In this case, the user creates an instance of the analysis class. They; have the control over the event loop and can generate an unlimited; number of histograms. - Using the code generated by `TTree::MakeSelector`: Like for the code; generated by **`TTree::MakeClass`**, the user can do complex analysis.; However, they cannot control the event loop. The event loop is; controlled by `TTree::Process` called by the user. This solution is; illustrated by the code below. The advantage of this method is that; it can be run in a parallel environment using PROOF (the Parallel; Root Facility). A chain of four files (originally converted from PAW ntuples) is used to; illustrate the various ways to loop on ROOT data sets. Each contains a; ROOT Tree named ""`h42`"". The class definition in h1analysis.h has been; generated automatically by the ROOT utility **`TTree`**`::MakeSelector`; using one of the files with:. ``` {.cpp}; h42->MakeSelector(""h1analysis"");; ```. This produces two files: h1analysis.h and `h1analysis.C`. A skeleton of; `h1analysis.C` file is made ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/ExampleAnalysis.md:577,efficient,efficient,577,documentation/users-guide/ExampleAnalysis.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/ExampleAnalysis.md,1,['efficient'],['efficient']
Energy Efficiency,"# Fitting Histograms. To fit a histogram you can use the Fit Panel on a visible histogram; via the context menu, or you can use the `TH1::Fit` method. The; Fit Panel, which is limited, is best for prototyping. The histogram; needs to be drawn in a pad before the Fit Panel is invoked. The method; `TH1::Fit` is more powerful and is used in scripts and programs. ## The Fit Method. The Fit method is implemented in ROOT for the histogram classes **`TH1`**,; the sparse histogram classes, `THnSparse`, the graph classes, `TGraph`,; `TGraph2D` and `TMultiGraph` for fitting a collection of Graphs with the same function. ### The TH1::Fit Method. To fit a histogram programmatically, you can use the `TH1::Fit`; method. Here is the signatures of `TH1::Fit` and an explanation of the; parameters:. ``` {.cpp}; TFitResultPtr Fit(TF1 *function, Option_t *option, Option_t *goption,; Axis_t xxmin, Axis_t xxmax); ```; - `function` a pointer to the fitted function (the fit model) object.; One can also use the function name. This name may be one of ROOT pre-defined; function names or a user-defined function. See the next paragraph for the list of pre-defined functions. - `*option:` The second parameter is the fitting option. Here is the; list of fitting options:. 	- ""`W`"" Set all weights to 1 for non empty bins; ignore error bars. 	- ""`WW`"" Set all weights to 1 including empty bins; ignore error; bars. 	- ""`I`"" Use integral of function in bin instead of value at bin; center. 	- ""`L`"" Use log likelihood method (default is chi-square method). To be used when; the histogram represents counts. 	- ""`WL`"" Weighted log likelihood method. To be used when the histogram has been filled with; 	weights different than 1. - ""`P`"" Use Pearson chi-square method, using expected errors instead of the observed one given by `TH1::GetBinError` (default case).; The expected error is instead estimated from the square-root of the bin function value. 	- ""`Q`"" Quiet mode (minimum printing). 	- ""`V`"" Verbose mode (de",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:316,power,powerful,316,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['power'],['powerful']
Energy Efficiency,"# Folders and Tasks. ## Folders. ![](pictures/030000E1.png). A **`TFolder`** is a collection of objects; visible and expandable in the ROOT object browser. Folders have a name; and a title and are identified in the folder hierarchy by an ""UNIX-like""; naming convention. The base of all folders is `//root`. It is visible at; the top of the left panel in the browser. The browser shows several; folders under `//root`. New folders can be added and removed to/from a folder. ## Why Use Folders?. One reason to use folders is to reduce class dependencies and improve; modularity. Each set of data has a producer class and one or many; consumer classes. When using folders, the producer class places a; pointer to the data into a folder, and the consumer class retrieves a; reference to the folder. The consumer can access the objects in a folder by specifying the path; name of the folder. Here is an example of a folder's path name:. `//root/Event/Hits/TCP`. One does not have to specify the full path name. If the partial path; name is unique, it will find it; otherwise it will return the first; occurrence of the path. The first diagram shows a system without folders. The objects have; pointers to each other to access each other's data. Pointers are an; efficient way to share data between classes. However, a direct pointer; creates a direct coupling between classes. This design can become a very; tangled web of dependencies in a system with a large number of classes. ![](pictures/020000E2.jpg). In the second diagram, a reference to the data is in the folder and the; consumers refer to the folder rather than each other to access the data.; The naming and search service provided by the ROOT folders hierarchy; provides an alternative. It loosely couples the classes and greatly; enhances I/O operations. In this way, folders separate the data from the; algorithms and greatly improve the modularity of an application by; minimizing the class dependencies. ![](pictures/020000E3.jpg). In addi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FoldersTasks.md:526,reduce,reduce,526,documentation/users-guide/FoldersTasks.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FoldersTasks.md,1,['reduce'],['reduce']
Energy Efficiency,"# Histograms #. Histograms play a fundamental role in any type of physics analysis, not; only to visualise measurements but being a powerful form of data; reduction. ROOT offers many classes that represent histograms, all; inheriting from the `TH1` class. We will focus in this chapter on uni-; and bi- dimensional histograms the bin contents of which are represented by; floating point numbers [^4], the `TH1F` and `TH2F` classes respectively. ## Your First Histogram ##. Let's suppose you want to measure the counts of a Geiger detector located in; proximity of a radioactive source in a given time interval. This would; give you an idea of the activity of your source. The count distribution; in this case is a Poisson distribution. Let's see how operatively you; can fill and draw a histogram with the following example macro. ``` {.cpp .numberLines}; @ROOT_INCLUDE_FILE macros/macro5.C; ```. Which gives you the following plot (Figure [5.1](#f51)):. [f51]: figures/poisson.png ""f51""; <a name=""f51""></a>. ![The result of a counting (pseudo) experiment. Only bins corresponding; to integer values are filled given the discrete nature of the poissonian; distribution. \label{f51}][f51]. Using histograms is rather simple. The main differences with respect to; graphs that emerge from the example are:. - line *5*: The histograms have a name and a title right from the; start, no predefined number of entries but a number of bins and a; lower-upper range. - line *15*: An entry is stored in the histogram through the; `TH1F::Fill` method. - line *18* and *21*: The histogram can be drawn also normalised, ROOT; automatically takes cares of the necessary rescaling. - line *24* to *30*: This small snippet shows how easy it is to access; the moments and associated errors of a histogram. ## Add and Divide Histograms ##. Quite a large number of operations can be carried out with histograms.; The most useful are addition and division. In the following macro we; will learn how to manage these procedu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/histograms.md:132,power,powerful,132,documentation/primer/histograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/histograms.md,1,['power'],['powerful']
Energy Efficiency,"# Latency tests for RWebWindow. Provide round-trip test under different conditions.; To run, execute `root ""ping.cxx(10,0)""`, where first argument is number of connections tested and; second argument is running mode. Can be tested:; 0 - default communication, no extra threads; 1 - minimal timer for THttpServer, should reduce round-trip significantly; 2 - use special thread for process requests in THttpServer, web window also runs in the thread; 3 - in addition to special THttpThread also window starts own thread; 4 - let invoke webwindow callbacks in the civetweb threads, expert mode only. One also can perform same tests with longpoll emulation of web sockets, if adding 10 to second parameter. When running in batch mode, function blocked until 200 round-trip packets send by the client; or 50s elappsed. Therefore ping.cxx test can be used for RWebWindow functionality tests ; like `root -l -b ""ping.cxx(10,2)"" -q`; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md:320,reduce,reduce,320,tutorials/webgui/ping/Readme.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md,1,['reduce'],['reduce']
Energy Efficiency,"# Library which powers fast batch computations in Roofit. ROOT_LINKER_LIBRARY(RooBatchCompute; src/Initialisation.cxx; DEPENDENCIES; Core; MathCore; ). target_include_directories(RooBatchCompute PUBLIC $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/res>). if(vdt OR builtin_vdt); target_link_libraries(RooBatchCompute PUBLIC VDT::VDT); endif(); if(builtin_vdt); add_dependencies(RooBatchCompute VDT); endif(). ############################################################################################################################################; # Instantiations of the shared objects which provide the actual computation functions. set(shared_object_sources src/RooBatchCompute.cxx src/ComputeFunctions.cxx). # Generic implementation for CPUs that don't support vector instruction sets.; ROOT_LINKER_LIBRARY(RooBatchCompute_GENERIC ${shared_object_sources} TYPE SHARED DEPENDENCIES RooBatchCompute); target_compile_options(RooBatchCompute_GENERIC PRIVATE ${common-flags} -DRF_ARCH=GENERIC). # Windows platform and ICC compiler need special code and testing, thus the feature has not been implemented yet for these.; if (ROOT_PLATFORM MATCHES ""linux|macosx"" AND CMAKE_SYSTEM_PROCESSOR MATCHES x86_64 AND CMAKE_CXX_COMPILER_ID MATCHES ""GNU|Clang""). target_compile_options(RooBatchCompute PRIVATE -DR__RF_ARCHITECTURE_SPECIFIC_LIBS). ROOT_LINKER_LIBRARY(RooBatchCompute_SSE4.1 ${shared_object_sources} TYPE SHARED DEPENDENCIES RooBatchCompute); ROOT_LINKER_LIBRARY(RooBatchCompute_AVX ${shared_object_sources} TYPE SHARED DEPENDENCIES RooBatchCompute); ROOT_LINKER_LIBRARY(RooBatchCompute_AVX2 ${shared_object_sources} TYPE SHARED DEPENDENCIES RooBatchCompute); ROOT_LINKER_LIBRARY(RooBatchCompute_AVX512 ${shared_object_sources} TYPE SHARED DEPENDENCIES RooBatchCompute). # Flags -fno-signaling-nans, -fno-trapping-math and -O3 are necessary to enable autovectorization (especially for GCC).; set(common-flags $<$<CXX_COMPILER_ID:GNU>:-fno-signaling-nans>); list(APPEND common-flags $<$<OR:$<CONFI",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/batchcompute/CMakeLists.txt:16,power,powers,16,roofit/batchcompute/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/batchcompute/CMakeLists.txt,1,['power'],['powers']
Energy Efficiency,"# Motivation and Introduction #. ***Welcome to data analysis!***. Comparison of measurements to theoretical models is one of the standard; tasks in experimental physics. In the most simple case, a ""model"" is; just a function providing predictions of measured data. Very often, the; model depends on parameters. Such a model may simply state ""the current; *I* is proportional to the voltage *U*"", and the task of the; experimentalist consists of determining the resistance, *R*, from a set; of measurements. As a first step, a visualisation of the data is needed. Next, some; manipulations typically have to be applied, e.g. corrections or; parameter transformations. Quite often, these manipulations are complex; ones, and a powerful library of mathematical functions and procedures; should be provided - think for example of an integral or peak-search or; a Fourier transformation applied to an input spectrum to obtain the; actual measurement described by the model. One specialty of experimental physics are the inevitable uncertainties; affecting each measurement, and visualisation tools have to include; these. In subsequent analysis, the statistical nature of the errors must; be handled properly. As the last step, measurements are compared to models, and free model; parameters need to be determined in this process. See Figure [1.1](#f11) for an; example of a function (model) fit to data points. Several standard methods are; available, and a data analysis tool should provide easy access to more; than one of them. Means to quantify the level of agreement between; measurements and model must also be available.; <!--; [f11]: figures/examplefit.png ""f11""; <a name=""f11""></a>. ![Measured data points with error bars and fitted quadratic; function.\label{f11}][f11]-->. Quite often, the data volume to be analyzed is large - think of; fine-granular measurements accumulated with the aid of computers. A; usable tool therefore must contain easy-to-use and efficient methods for; storing and h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/Introduction.md:725,power,powerful,725,documentation/primer/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/Introduction.md,1,['power'],['powerful']
Energy Efficiency,"# PROOF: Parallel Processing; \index{PROOF}; \index{parallel processing}. The Parallel ROOT Facility, PROOF, is an extension of ROOT allowing; transparent analysis of large sets of ROOT files in parallel on remote; computer clusters or multi-core computers. The main design goals for the; PROOF system are:. *Transparency* : there should be as little difference as possible; between a local ROOT based analysis session and a remote parallel PROOF; session, both being interactive and giving the same results. *Scalability* : the basic architecture should not put any implicit; limitations on the number of computers that can be used in parallel. *Adaptability* : the system should be able to adapt itself to variations; in the remote environment (changing load on the cluster nodes, network; interruptions, etc.). Being an extension of the ROOT system, PROOF is designed to work on; objects in ROOT data stores, though, for the time being, it mainly; addresses the case of **`TTree`** based object collections. PROOF is primarily meant as an interactive alternative to batch systems; for Central Analysis Facilities and departmental workgroups (Tier-2's).; However, thanks to a multi-tier architecture allowing multiple levels of; masters, it can be easily adapted to wide range virtual clusters; distributed over geographically separated domains and heterogeneous; machines (GRIDs). While pure interactivity might not always be possible when performing a; complicated analysis on a very large data set, PROOF still tries to give; the user the interactive experience with something we call ""interactive; batch"". With ""interactive batch"" the user can start very long running; queries, disconnect the client and at any time, any location and from; any computer reconnect to the query to monitor its progress or retrieve; the results. This feature gives it a distinct advantage over purely; batch based solutions, that only provide an answer once all sub-jobs; have been finished. ![The Multi-tier struct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PROOF.md:692,adapt,adapt,692,documentation/users-guide/PROOF.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PROOF.md,1,['adapt'],['adapt']
Energy Efficiency,"# Preface {.unnumbered}. In late 1994, we decided to learn; and investigate Object Oriented programming and C++ to better judge; the suitability of these relatively new techniques for scientific; programming. We knew that there is no better way to learn a new; programming environment than to use it to write a program that can; solve a real problem. After a few weeks, we had our first; histogramming package in C++. A few weeks later we had a rewrite of; the same package using the, at that time, very new template features; of C++. Again, a few weeks later we had another rewrite of the package; without templates since we could only compile the version with; templates on one single platform using a specific compiler. Finally,; after about four months we had a histogramming package that was faster; and more efficient than the well-known FORTRAN based HBOOK; histogramming package. This gave us enough confidence in the new; technologies to decide to continue the development. Thus was born; ROOT. Since its first public release at the end of 1995, ROOT has; enjoyed an ever-increasing popularity. Currently it is being used in; all major High Energy and Nuclear Physics laboratories around the; world to monitor, to store and to analyse data. In the other sciences; as well as the medical and financial industries, many people are using; ROOT. We estimate the current user base to be around several thousand; people. In 1997, Eric Raymond analysed in his paper ""The Cathedral and; the Bazaar"" the development method that makes Linux such a success.; The essence of that method is: ""release early, release often and; listen to your customers"". This is precisely how ROOT is being; developed. Over the last five years, many of our ""customers"" became; co-developers. Here we would like to thank our main co-developers and; contributors:. **Masaharu Goto** wrote the C++ interpreter CINT that was an; essential part of ROOT before ROOT 6. Despite being 8 time zones ahead; of us, we have the feelin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Preface.md:814,efficient,efficient,814,documentation/users-guide/Preface.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Preface.md,1,['efficient'],['efficient']
Energy Efficiency,"# ROOT in Python #. ROOT offers the possibility to interface to Python via a set of bindings called; PyROOT.; Python is used in a wide variety of application areas and one of the most used; scripting languages today.; With the help of PyROOT it becomes possible to combine the power of a scripting; language with ROOT tools. Introductory material to Python is available from many; sources on the web, see e. g. http://docs.python.org. ## PyROOT ##. The access to ROOT classes and their methods in PyROOT is almost identical to C++; macros, except for the special language features of Python, most importantly dynamic; type declaration at the time of assignment. Coming back to our first example, simply; plotting a function in ROOT, the following C++ code:. ``` {.cpp}; TF1 *f1 = new TF1(""f2"",""[0]*sin([1]*x)/x"",0.,10.);; f1->SetParameter(0,1);; f1->SetParameter(1,1);; f1->Draw();; ```. in Python becomes:. ``` {.python}; import ROOT; f1 = ROOT.TF1(""f2"",""[0]*sin([1]*x)/x"",0.,10.); f1.SetParameter(0,1);; f1.SetParameter(1,1);; f1.Draw();; ```. A slightly more advanced example hands over data defined in the macro to the ROOT; class `TGraphErrors`. Note that a Python array can be used to pass data between; Python and ROOT. The first line in the Python script allows it to be executed; directly from the operating system, without the need to start the script from; python or the highly recommended powerful interactive shell ipython. The last line; in the python script is there to allow you to have a look at the graphical output; in the ROOT canvas before it disappears upon termination of the script. Here is the C++ version:. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/TGraphFit.C; ```. In Python it looks like this:. ``` {.python}; @ROOT_INCLUDE_FILE macros/TGraphFit.py; ```. Comparing the C++ and Python versions in these two examples, it now should be; clear how easy it is to convert any ROOT Macro in C++ to a Python version. As another example, let us revisit macro3 from Chapter 4. A straigh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/root_in_python.md:277,power,power,277,documentation/primer/root_in_python.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/root_in_python.md,1,['power'],['power']
Energy Efficiency,"# Threads. A thread is an independent flow of control that operates within the same; address space as other independent flows of controls within a process.; In most UNIX systems, thread and process characteristics are grouped; into a single entity called a process. Sometimes, threads are called; ""lightweight processes''. Note: This introduction is adapted from the AIX 4.3 Programmer's Manual. ## Threads and Processes. In traditional single-threaded process systems, a process has a set of; properties. In multi-threaded systems, these properties are divided; between processes and threads. ### Process Properties. A process in a multi-threaded system is the changeable entity. It must; be considered as an execution frame. It has all traditional process; attributes, such as:. - Process ID, process group ID, user ID, and group ID. - Environment. - Working directory. A process also provides a common address space and common system; resources:. - File descriptors. - Signal actions. - Shared libraries. - Inter-process communication tools (such as message queues, pipes,; semaphores, or shared memory). ### Thread Properties. A thread is the schedulable entity. It has only those properties that; are required to ensure its independent flow of control. These include; the following properties:. - Stack. - Scheduling properties (such as policy or priority). - Set of pending and blocked signals. - Some thread-specific data (TSD). An example of thread-specific data is the error indicator, `errno`. In; multi-threaded systems, `errno` is no longer a global variable, but; usually a subroutine returning a thread-specific `errno` value. Some; other systems may provide other implementations of `errno`. With respect; to ROOT, a thread specific data is for example the ***`gPad`*** pointer,; which is treated in a different way, whether it is accessed from any; thread or the main thread. Threads within a process must not be considered as a group of processes; (even though in Linux each thread re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:350,adapt,adapted,350,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,1,['adapt'],['adapted']
Energy Efficiency,"# Trees. ## Why Should You Use a Tree?. In the ""Input/Output"" chapter, we saw how objects can be saved in ROOT; files. In case you want to store large quantities of same-class objects,; ROOT has designed the **`TTree`** and **`TNtuple`** classes specifically; for that purpose. The **`TTree`** class is optimized to reduce disk; space and enhance access speed. A **`TNtuple`** is a **`TTree`** that is; limited to only hold floating-point numbers; a **`TTree`** on the other; hand can hold all kind of data, such as objects or arrays in addition to; all the simple types. When using a **`TTree`**, we fill its branch buffers with leaf data and; the buffers are written to disk when it is full. Branches, buffers, and; leafs, are explained a little later in this chapter, but for now, it is; important to realize that each object is not written individually, but; rather collected and written a bunch at a time. This is where the **`TTree`** takes advantage of compression and will; produce a much smaller file than if the objects were written; individually. Since the unit to be compressed is a buffer, and the; **`TTree`** contains many same-class objects, the header of the objects; can be compressed. The **`TTree`** reduces the header of each object, but it still contains; the class name. Using compression, the class name of each same-class; object has a good chance of being compressed, since the compression; algorithm recognizes the bit pattern representing the class name. Using; a **`TTree`** and compression the header is reduced to about 4 bytes; compared to the original 60 bytes. However, if compression is turned; off, you will not see these large savings. The **`TTree`** is also used to optimize the data access. A tree uses a; hierarchy of branches, and each branch can be read independently from; any other branch. Now, assume that `Px` and `Py` are data members of the; event, and we would like to compute `Px2 + Py2` for every event; and histogram the result. If we had saved the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:316,reduce,reduce,316,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['reduce'],['reduce']
Energy Efficiency,"## 2D Graphics Libraries. ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## PROOF Libraries. ## PyROOT. ### Typesafe `TTree::SetBranchAddress()` for array inputs. If you call `TTree::SetBranchAddress` with NumPy array or `array.array` inputs, ROOT will now check if the array type matches with the column type.; If it doesn't, `SetBranchAddress()` will return a negative status code and print an error.; Take for example this code snippet:; ```python; arr = array.array(typecode, ""d""); status = t.SetBranchAddress(""name"", arr); print(""Status = %s"" % (status, )); ```; If the branch type is also `double` (like the type of the array indicated by `""d""`), the call to `SetBranchAddress()` would succeed with status code zero.; If the type doesn't match, you now get a clear error instead of garbage values.; ```txt; Error in <TTree::SetBranchAddress>: The pointer type given ""Double_t"" (8) does not correspond to the type needed ""Float_t"" (5) by the branch: a; Status = -2; ```. ### Deprecation of `TPython::Eval()`. The `TPython::Eval()` method is deprecated and scheduled for removal in ROOT 6.36.; Its implementation was fragile, and the same functionality can be achieved with `TPython::Exec()`, using a C++ variable that is known to the ROOT interpreter for crossing over from Python to C++. Example:; ```c++; // Before, with TPython::Eval(); std::string stringVal = static_cast<const char*>(TPython::Eval(""'done'""));; std::cout << stringVal << std::endl;. // Now, with TPython::Exec(). You can set `_anyresult` to whatever std::any you want.; // It will be swapped into the return variable in the end. std::any result;; TPython::Exec(""_anyresult = ROOT.std.make_any['std::string']('done')"", &result);; std::cout << std::any_cast<std::string>(result) << std::endl;; ```. ## Language Bindings. ## JavaScript ROOT. ## Tutorials. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v634/index.md:7903,schedul,scheduled,7903,README/ReleaseNotes/v634/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v634/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"## Introduction to TableGen Part 1: Classes, Defs, Basic Types and Let. **Note:** The content in this notebook is adapted from [this document](https://llvm.org/docs/TableGen/index.html). Refer to it if you want more details. This tutorial will cover:; * Classes; * Defs; * Basic types; * `let` in various forms; * Class template arguments. ## What is TableGen?. TableGen is a language used in LLVM to automate the generation of certain types of code. Usually repetitive code that has a common structure. TableGen is used to generate ""records"" that are then processed by a ""backend"" into domain specific code. The compiler for TableGen is the binary `llvm-tblgen`. This contains the logic to convert TableGen source into records that can then be passed to a TableGen backend. TableGen allows you to define Classes and Defs (which are instances of classes) but it doesn't encode what to do with that structure. That's what the backend does. The backend converts this structure into something useful, for example C++ code. These backends are included in the `llvm-tblgen` binary and you can choose which one to run using a command line option. If you don't choose a backend you get a dump of the structure, and that is what this notebook will be showing. This tutorial will focus on the language itself only. The only thing you need to know now is that in addition to `llvm-tblgen` you will see other `*-tblgen` like `clang-tblgen`. The difference between them is the backends they include. The default output from `llvm-tblgen` looks like this:. ```tablegen; %config cellreset on. // Empty source file; ```. ------------- Classes -----------------; ------------- Defs -----------------. **Note:** `%config` is not a TableGen command but a ""magic"" command to the Jupyter kernel for this notebook. By default new cells include the content of previously run cells, but for this notebook we mostly want each to be isolated. On occasion we will use the `%noreset` magic to override this. No source means no c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:114,adapt,adapted,114,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,1,['adapt'],['adapted']
Energy Efficiency,"% ROOT Version 6.06 Release Notes; % 2015-12-08; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.06/00 is scheduled for release in November, 2015. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. David Abdurachmanov, CERN, CMS,\; Bertrand Bellenot, CERN/SFT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Cristina Cristescu, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Kyle Cranmer, NYU, RooStats,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT, \; Burt Holzman, Fermilab, CMS,\; Lukasz Janyst, CERN/IT,\; Christopher Jones, Fermilab, CMS,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http, JSROOT, \; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/IT/Openlab,\; Enric Tejedor Saavedra, CERN/SFT,\; Liza Sakellari, CERN/SFT,\; Manuel Tobias Schiller,CERN, LHCb\; David Smith, CERN/IT,\; Matevz Tadel, UCSD/CMS, Eve, \; Vassil Vassilev, CERN/SFT \; Wouter Verkerke, NIKHEF/Atlas, RooFit, \; Omar, Zapata, Medellin, Columbia \; Maciej Zimnoch, GSoC, Poland. ## ROOT reference manual. The ROOT reference manual has been moved into Doxygen. Still some work and; polish has to be done but the reference guide in this new format is now online; and can be seen from the [ROOT home page](https://root.cern.ch/doc/master/index.html). ## Core Libraries. ### Dictionary generation. Fixed the dictionary generation in the case of class inside a namespace; marked inlined. Added mechanisms to stop the dictionary generation while parsing the XML and while selecting in presence of duplicates. Fix [ROOT-7760] : fully allow the usage of the dylib extension on OSx. Fix [ROOT-7723] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter pa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:116,schedul,scheduled,116,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"% ROOT Version 6.08 Release Notes; % 2015-11-12; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.08/00 is scheduled for release in October, 2016. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. David Abdurachmanov, CERN, CMS,\; Adrian Bevan, Queen Mary University of London, ATLAS,\; Attila Bagoly, GSoC,\; Bertrand Bellenot, CERN/SFT,\; Rene Brun, CERN/SFT,\; Philippe Canal, Fermilab,\; Andrew Carnes, University of Florida, CMS, \; Cristina Cristescu, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Paul Gessinger, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Luca Giommi, CERN/SFT,\; Sergei Gleyzer, University of Florida, CMS\; Christopher Jones, Fermilab, CMS,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Abhinav Moudgil, GSoC, \; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh, GSoC, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/IT,\; Paul Russo, Fermilab,\; Enric Tejedor Saavedra, CERN/SFT,\; George Troska, Dortmund Univ.,\; Liza Sakellari, CERN/SFT,\; Alex Saperstein, ANL,\; Manuel Tobias Schiller, CERN/LHCb,\; David Smith, CERN/IT,\; Peter Speckmayer,\; Tom Stevenson, Queen Mary University of London, ATLAS\; Matevz Tadel, UCSD/CMS, Eve,\; Peter van Gemmeren, ANL, ATLAS,\; Xavier Valls, CERN/SFT, \; Vassil Vassilev, Fermilab/CMS,\; Stefan Wunsch, KIT, CMS\; Omar Zapata, University of Antioquia, CERN/SFT.; . <a name=""core-libs""></a>. ## General. * Remove many instances of new warnings issued by gcc 6.1; * Significant update of the valgrind suppression file to hide intentional lack; of delete of some entities at the end of the process.; * Resolved several memory leaks.; * Added deprecation system: when compiling against interfaces marked R__DEPRECATED, the compiler will issue a warning showing the ROOT version when the interface will be removed.; * From this version",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:116,schedul,scheduled,116,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"% ROOT Version 6.10 Release Notes; % 2016-09-30; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.10/00 is scheduled for release in 2017. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Bertrand Bellenot, CERN/SFT,\; Georgios Bitzes, CERN/IT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Vassil Vassilev, Fermilab/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.08. ### CINT remnants, dysfunctional for ROOT 6. - `TInterpreter`'s `Getgvp()`, `Getp2f2funcname(void*)`, `Setgvp(Long_t)`, `SetRTLD_NOW()`, `SetRTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:116,schedul,scheduled,116,README/ReleaseNotes/v610/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"% ROOT Version 6.12 Release Notes; % 2017-05-18. <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.12/00 is scheduled for release in 2018. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Kim Albertsson, CERN,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Brian Bockelman, UNL,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; David Clark, ANL (SULI),\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Sergey Linev, GSI,\; Timur Pocheptsov, CERN/SFT,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Arthur Tsang, CERN/SFT, \; Peter van Gemmeren, ANL,\; Vassil Vassilev, Princeton Univ./CMS,\; Xavier Valls Pla, CERN/UJI, \; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, KIT,\; Omar Zapata. ## General News. This release now supports building with C++17 enabled using either libstdc++ or; libc++. This requires Clang >= 5.0, or GCC >= 7.3.0. At the date of this; release, GCC 7.2.0 still does not provide full support to compile ROOT with C++17. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.10. - Remove the deprecated `TSelectorCint.h` and `TSelectorCint.cxx`.; - Remove the deprecated `Riosfwd.h` and `Rtypeinfo.h`.; - `TTreeReader::SetLastEntry()` was replaced by `TTreeReader::SetEntriesRange()`. ## Core Libraries. - Added support for XCode 9 and MacOS High Sierra.; - When invoking root with the ""-t"" argument, ROOT enables thread-safety and,; if configured, implicit multithreading within ROOT.; - `NULL` is not defined by `Rtypes.h` anymore. Instead, its definition is expected to be; provided by `Rtype.h`'s `#include` of `stddef.h`.; - ROOT now supports dic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:116,schedul,scheduled,116,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"% ROOT Version 6.14 Release Notes; % 2017-11-19. <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.14/00 is scheduled for release in 2018. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Kim Albertsson, CERN/EP-ADP-OS,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Brian Bockelman, UNL,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Vladimir Ilievski, GSOC 2017,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Saurav Shekhar, GSOC 2017,\; Xavier Valls Pla, UJI, CERN/SFT,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, CERN/SFT, \; Zhe Zhang, UNL. ## Important Notice. The default compression algorithm used when writing ROOT files has been updated to use LZ4 in particular to improve read (decompression) performance. You can change this default for each file through (for example) the `TFile constructor` or `TFile::SetCompressionAlgorithm`. It should be noted that ROOT files written with LZ4 compression can not be read with older release of ROOT. Support for LZ4 was however back-ported to the patch branches of previous releases and the following tags (and later release in the same patch series) can read ROOT files written with LZ4 compression:. * v5.34/38; * v6.08/06 [not yet released]; * v6.10/08; * v6.12/02. ## Removed interfaces. ## Core Libraries; - Optimize away redundant deserialization of template specializations. This reduces the memory footprint for hsimple by around 30% while improving the runtime performance for various cases by around 15%.; - When ROOT is signaled with a SIGUSR2 (i.e. on Linux and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:116,schedul,scheduled,116,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"% ROOT Version 6.16 Release Notes; % 2018-06-25; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.16/00 is scheduled for release end of 2018. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Kim Albertsson, CERN/ATLAS,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Iliana Betsou, CERN/SFT,\; Brian Bockelman, UNL,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Stephan Hageboeck, CERN/SFT,\; Siddhartha Rao Kamalakara, GSOC, \; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Alja Mrak Tadel, UCSD/CMS,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Ravi Kiran Selvam, GSOC, \; Manos, Stergiadis, GSOC, \; Matevz Tadel, UCSD/CMS,\; Yuka Takahashi, Princeton,\; Massimo Tumolo, Politecnico di Torino,\; Mohammad Uzair, CERN/SFT, \; Xavier Valls, CERN/SFT,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas,\; Stefan Wunsch, CERN/SFT. ## Deprecation and Removal. ### Ruby bindings. The ruby binding has been unmaintained for several years; it does not build with current ruby versions.; Given that this effectively meant that Ruby was dysfunctional and given that nobody (but package maintainers) has complained, we decided to remove it. ### Removal of previously deprecated or disabled packages. The packages `afs`, `chirp`, `glite`, `sapdb`, `srp` and `ios` have been removed from ROOT.; They were deprecated before, or never ported from configure, make to CMake. ### Remove GLUtesselator forward declaration from TVirtualX.h. It was never used in TVirtualX interfaces. If GLUtesselator forward declaration is required, use TGLUtil.h include instead. ## C++ Modules Technology Preview. ROOT has several features which interact with libraries and require",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md:116,schedul,scheduled,116,README/ReleaseNotes/v616/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"% ROOT Version 6.18 Release Notes; % 2019-05-28; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.18/00 is scheduled for release in June, 2019. For more information, see [http://root.cern](http://root.cern). The following people have contributed to this new version:. Kim Albertsson, CERN/ATLAS,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Iliana Betsou, CERN/SFT,\; Jakob Blomer, CERN/SFT,\; Brian Bockelman, Nebraska,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Javier Cervantes Villanueva, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Alexandra Dobrescu, CERN/SFT,\; Giulio Eulisse, CERN/ALICE,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Stephan Hageboeck, CERN/SFT,\; Jan Knedlik, GSI,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Alja Mrak-Tadel, UCSD/CMS,\; Axel Naumann, CERN/SFT,\; Vincenzo Eduardo Padulano, Bicocca/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Henry Schreiner, Princeton,\; Oksana Shadura, Nebraska,\; Simon Spies, GSI,\; Yuka Takahashi, Princeton and CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas,\; Zhe Zhang, Nebraska,\; Stefan Wunsch, CERN/SFT. ## Deprecation and Removal. ### Deprecated packages. The Virtual Monte Carlo (VMC) interfaces have been deprecated for this release; and will be removed in a future release. It is no longer built by default, but; can still be enabled with the option `-Dvmc=ON` in the CMake configuration phase.; A standalone version of VMC is being developed at [https://github.com/vmc-project/vmc](https://github.com/vmc-project/vmc); to replace the deprecated version in ROOT. ### Removed packages. Support for the following optional components of ROOT has been removed:. * afdsmgrd (Dataset manager for PROOF-based analysis facilities); * bonjour (Avahi/Bonjour/Zeroconf); * castor (CERN Advanced STORage manager); * geocad (OpenCasca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:116,schedul,scheduled,116,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"% ROOT Version 6.20 Release Notes; % 2019-05-29; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.20/00 is scheduled for release in November 2019. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Kim Albertsson, CERN/ATLAS,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Iliana Betsou, CERN/SFT,\; Jakob Blomer, CERN/SFT,\; Brian Bockelman, Nebraska,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Javier Cervantes Villanueva, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Alexandra Dobrescu, CERN/SFT,\; Giulio Eulisse, CERN/ALICE,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Stephan Hageboeck, CERN/SFT,\; Desislava Kalaydjieva, CERN/SFT,\; Jan Knedlik, GSI,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Alja Mrak-Tadel, UCSD/CMS,\; Axel Naumann, CERN/SFT,\; Vincenzo Eduardo Padulano, CERN/SFT and UPV,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Otto Schaile, Uni-Muenchen,\; Henry Schreiner, Princeton,\; Oksana Shadura, Nebraska,\; Simon Spies, GSI,\; Yuka Takahashi, Princeton and CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas,\; Zhe Zhang, Nebraska,\; Stefan Wunsch, CERN/SFT. ## ROOT. ### Splash screen. The venerable splash screen is now disabled by default to make ROOT's startup; faster. Many users already use `root -l` to start ROOT, but this also hides the; useful text banner with version information along with the splash screen. With; this new default, starting up ROOT as just `root` will show only the text banner; instead of the splash screen. The splash screen can still be seen with `root -a`; or in `TBrowser` by opening `Browser Help → About ROOT`. ## Deprecation and Removal; * rootcling flags `-cint`, `-gccxml`, `-p`, `-r` and `-c` have no effect; and will be removed. Please remove them from the rootcl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md:116,schedul,scheduled,116,README/ReleaseNotes/v620/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"% ROOT Version 6.22 Release Notes; % 2020-05-19; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.22/00 is scheduled for release in May, 2020. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Jakob Blomer, CERN/SFT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Stephan Hageboeck, CERN/SFT,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Alja Mrak-Tadel, UCSD/CMS,\; Jan Musinsky, SAS Kosice,\; Axel Naumann, CERN/SFT,\; Vincenzo Eduardo Padulano, CERN/SFT and UPV,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsoff, Qt Company,\; Renato Quagliani, LPNHE, CNRS/IN2P3, Sorbonne Université,\; Fons Rademakers, CERN/SFT,\; Oksana Shadura, Nebraska,\; Enric Tejedor Saavedra, CERN/SFT,\; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas,\; Stefan Wunsch, CERN/SFT. ## Deprecation and Removal. - `ROOT::GetImplicitMTPoolSize` has been deprecated in favor of the newly added `ROOT::GetThreadPoolSize` and; will be removed in v6.24.; - Manually setting `TThreadedObject::fgMaxSlots` is deprecated: TThreadedObject now increases the number of slots; on-demand rather than running out and throwing an exception. ## Core Libraries. - ROOT comes with C++ Modules enabled. More details about the technology found [here](../../README.CXXMODULES.md).; - The `ACLiC` can be configured to pass options to the `rootcling` invocation by enabling in the `.rootrc` the `ACLiC.ExtraRootclingFlags [-opts]` line.; - A call to `ROOT::EnableThreadSafety` is not required before using `TThreadExecutor` or `TTreeProcessorMT` anymore; - `TTreeProcessorMT` does not silently activate implicit multi-threading features anymore. An explicit call to; `ROOT::EnableImplicitMT` is required instead; - `TTreeProcessorMT` now has a constr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md:116,schedul,scheduled,116,README/ReleaseNotes/v622/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"% ROOT Version 6.24 Release Notes; % 2020-05-19; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.24/00 is scheduled for release in November 2020. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Josh Bendavid, CERN/CMS,\; Jakob Blomer, CERN/SFT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Massimiliano Galli, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Hadrien Grasland, IJCLab/LAL,\; Enrico Guiraud, CERN/SFT,\; Claire Guyot, CERN/SFT,\; Jonas Hahnfeld, CERN/SFT,\; Emmanouil Michalainas, CERN/SFT,\; Stephan Hageboeck, CERN/SFT,\; Sergey Linev, GSI,\; Javier Lopez-Gomez, CERN/SFT,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Alja Mrak-Tadel, UCSD/CMS,\; Axel Naumann, CERN/SFT,\; Vincenzo Eduardo Padulano, CERN/SFT and UPV,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Jonas Rembser, CERN/SFT,\; Andrea Sciandra, SCIPP-UCSC/Atlas, \; Oksana Shadura, UNL/CMS,\; Enric Tejedor Saavedra, CERN/SFT,\; Christian Tacke, GSI, \; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas,\; Stefan Wunsch, CERN/SFT,\; Anirudh Dagar, CERN-HSF/GSoC. ## Deprecation and Removal. - [`RooAbsReal::evaluateBatch()`](https://root.cern/doc/v624/classRooAbsReal.html#a261580dfe94f2b107f9b9a77cad78a62) has been removed in favour of the faster evaluateSpan(). See section ""RooFit Libraries"" for instructions on how to use [`RooAbsReal::evaluateSpan()`](https://root.cern/doc/v624/classRooAbsReal.html#a1e5129ffbc63bfd04c01511fd354b1b8).; - `TTreeProcessorMT::SetMaxTasksPerFilePerWorker` has been deprecated in favour of `TTreeProcessorMT::SetTasksPerWorkerHint`. ## Core Libraries. Due to internal changes required to comply with the deprecation of Intel TBB's `task_scheduler_init` and related; interfaces in recent TBB versions, as of v6.24 ROOT will not honor a maximum concurrency",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:116,schedul,scheduled,116,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"% ROOT Version 6.26 Release Notes; % 2021-03-03; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.26/00 is scheduled for release in May, 2021. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Sitong An, CERN/SFT,\; Simone Azeglio, CERN/SFT,\; Rahul Balasubramanian, NIKHEF/ATLAS,\; Bertrand Bellenot, CERN/SFT,\; Josh Bendavid, CERN/CMS,\; Jakob Blomer, CERN/SFT,\; Patrick Bos, Netherlands eScience Center,\; Rene Brun, CERN/SFT,\; Carsten D. Burgard, DESY/ATLAS,\; Will Buttinger, STFC/ATLAS,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Mattias Ellert, Uppsala University, \; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Stephan Hageboeck, CERN/IT,\; Jonas Hahnfeld, CERN/SFT,\; Ahmat Hamdan, GSOC, \; Fernando Hueso-González, University of Valencia,\; Ivan Kabadzhov, CERN/SFT,\; Shamrock Lee (@ShamrockLee),\; Sergey Linev, GSI,\; Javier Lopez-Gomez, CERN/SFT,\; Pere Mato, CERN/SFT,\; Emmanouil Michalainas, CERN/SFT, \; Lorenzo Moneta, CERN/SFT,\; Nicolas Morange, CNRS/IJCLab, \; Axel Naumann, CERN/SFT,\; Vincenzo Eduardo Padulano, CERN/SFT and UPV,\; Max Orok, U Ottawa,\; Alexander Penev, University of Plovdiv,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Jonas Rembser, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Aaradhya Saxena, GSOC,\; Oksana Shadura, UNL/CMS,\; Sanjiban Sengupta, GSOC,\; Federico Sossai, CERN/SFT,\; Harshal Shende, GSOC,\; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/ATLAS,\; Zef Wolffs, NIKHEF/ATLAS,\; Stefan Wunsch, CERN/SFT. ## Deprecation, Removal, Backward Incompatibilities. - The ""Virtual MonteCarlo"" facility VMC (`montecarlo/vmc`) has been removed from ROOT. The development of this package has moved to a [separate project](https://github.com/vmc-project/). ROOT's copy of VMC was deprecated since v6.18.; - `TTreeProcessorMT::SetMaxTasksPerFilePerWorker` has been rem",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:116,schedul,scheduled,116,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"% ROOT Version 6.28 Release Notes; % 2022-01-05; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.28/00 is scheduled for release in May 2022. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Rahul Balasubramanian, NIKHEF/ATLAS,\; Bertrand Bellenot, CERN/SFT,\; Jakob Blomer, CERN/SFT,\; Patrick Bos, Netherlands eScience Center,\; Rene Brun, CERN/SFT,\; Carsten D. Burgard, TU Dortmund University/ATLAS,\; Will Buttinger, RAL/ATLAS,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Michel De Cian, EPFL/LHCb,\; Mattias Ellert, Uppsala University,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Konstantin Gizdov, University of Edinburgh/LHCb,\; Max Goblirsch, CERN/ATLAS,\; Enrico Guiraud, CERN/SFT,\; Stephan Hageboeck, CERN/IT,\; Jonas Hahnfeld, CERN/SFT,\; Ahmat Mahamat Hamdan, CERN/SFT,\; Fernando Hueso-González, University of Valencia,\; Subham Jyoti, ITER Bhubaneswar,\; Sergey Linev, GSI,\; Javier Lopez-Gomez, CERN/SFT,\; Enrico Lusiani, INFN/CMS,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Nicolas Morange, CNRS/ATLAS,\; Axel Naumann, CERN/SFT,\; Hanna Olvhammar, CERN/SFT,\; Vincenzo Eduardo Padulano, CERN/SFT and UPV,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Jonas Rembser, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Neel Shah, GSOC,\; Sanjiban Sengupta, CERN/SFT,\; Harshal Shende, GSOC,\; Garima Singh, Princeton/SFT,\; Matevz Tadel, UCSD/CMS,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/ATLAS,\; Zef Wolffs, NIKHEF/ATLAS,\; Ivan Kabadzhov, CERN/SFT,\; David Poulton, Wits/SFT. ## Deprecation and Removal. - The deprecated types `ROOT::Experimental::TBufferMerger` and `ROOT::Experimental::TBufferMergerFile` are removed.; Please use their non-experimental counterparts `ROOT::TBufferMerger` and `ROOT::TBufferMergerFile` instead.; - `ROOT::RVec::shrink_to_fit()` has now been removed after deprecation; it is not needed.; - `ROOT::RVec::em",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:116,schedul,scheduled,116,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"% ROOT Version 6.30 Release Notes; % 2022-12-21; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.30/00 is scheduled for release in October, 2023. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Daniel Álvarez Conde, CERN/EP-SFT,\; Guilherme Amadio, CERN/IT,\; Bertrand Bellenot, CERN/EP-SFT,\; Jakob Blomer, CERN/EP-SFT,\; Patrick Bos, Netherlands eScience Center,\; Rene Brun,\; Carsten Burgard, TU Dortmund,\; Will Buttinger, Rutherford Appleton Lab,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/EP-SFT,\; Marta Czurylo, CERN/EP-SFT,\; Mattias Ellert, Uppsala Uni,\; Edward Finkelstein, JGU Mainz,\; Gerri Ganis, CERN/EP-SFT,\; Paul Gessinger, CERN/EP-SFT,\; Florine de Geus, CERN/ATLAS,\; Andrei Gheata, CERN/EP-SFT,\; Enrico Guiraud, CERN/EP-SFT and Princeton,\; Ahmat Hamdan, CERN/EP-SFT,\; Stephan Hageboeck, CERN/IT,\; Jonas Hahnfeld, CERN/EP-SFT,\; Fernando Hueso González, CSIC/UV,\; Attila Krasznahorkay, CERN/ATLAS,\; Baidyanath Kundu, CERN/EP-SFT and Princeton,\; Giovanna Lazzari Miotto, CERN/EP-SFT,\; Sergey Linev, GSI,\; Jerry Ling, Harvard Uni,\; Javier Lopez-Gomez, CERN/EP-SFT,\; Pere Mato, CERN/EP-SFT,\; Lorenzo Moneta, CERN/EP-SFT,\; Ole Morud, CERN/EP-SFT,\; Alja Mrak Tadel, UCSD/CMS,\; Axel Naumann, CERN/EP-SFT,\; Dante Niewenhuis, UvA and CERN/EP-SFT,\; Vincenzo Eduardo Padulano, CERN/EP-SFT,\; Ioanna Maria Panagou, CERN/EP-SFT,\; Danilo Piparo, CERN/EP-SFT,\; Fons Rademakers, CERN/IT,\; Jonas Rembser, CERN/EP-SFT,\; Jakob Schneekloth, CERN/EP-SFT,\; Sanjiban Sengupta, CERN/EP-SFT,\; Neel Shah, GSoC,\; Garima Singh, CERN/EP-SFT and Princeton,\; Yash Solanki, GSoC,\; Uri Stern, CERN/EP-SFT,\; Silia Taider, CPE Lyon and CERN EP-SFT,\; Enric Tejedor Saavedra, CERN/IT,\; Matevz Tadel, UCSD/CMS,\; [QuillPusher](https://github.com/QuillPusher), [Compiler Research Group](https://compiler-research.org/team/),\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/ATLAS,\; Dan",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:116,schedul,scheduled,116,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"% ROOT Version 6.34 Release Notes; % 2025-05; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.34.00 is scheduled for release at the end of May 2025. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Anton Alkin, Sungkyunkwan University\; Guilherme Amadio, CERN/IT,\; Abhigyan Acherjee, University of Cincinnati,\; Bertrand Bellenot, CERN/EP-SFT,\; Jakob Blomer, CERN/EP-SFT,\; Rene Brun,\; Carsten Burgard, DESY\; Will Buttinger, RAL,\; Philippe Canal, FNAL,\; Jolly Chen, CERN/EP-SFT,\; Olivier Couet, CERN/EP-SFT,\; Marta Czurylo, CERN/EP-SFT,\; Monica Dessole, CERN/EP-SFT,\; Mattias Ellert, Uppsala University,\; Gerri Ganis, CERN/EP-SFT,\; Florine de Geus, CERN/University of Twente,\; Andrei Gheata, CERN/EP-SFT,\; Bernhard Manfred Gruber,\; Enrico Guiraud,\; Jonas Hahnfeld, CERN/Goethe University Frankfurt,\; Fernando Hueso Gonzalez, University of Valencia\; Attila Krasznahorkay, CERN/EP-ADP-OS,\; Wim Lavrijsen, LBL,\; Valerii Kholoimov, National University of Kyiv/IRIS-HEP, \; Dennis Klein, GSI,\; Christoph Langenbruch, Heidelberg University/LHCb,\; Sergey Linev, GSI,\; Javier Lopez-Gomez,\; Pere Mato, CERN/EP-SFT,\; Alaettin Serhan Mete, Argonne,\; Thomas Madlener, DESY,\; Lorenzo Moneta, CERN/EP-SFT,\; Alja Mrak Tadel, UCSD/CMS,\; Axel Naumann, CERN/EP-SFT,\; Dante Niewenhuis, VU Amsterdam\; Luis Antonio Obis Aparicio, University of Zaragoza,\; Ianna Osborne, Princeton University,\; Vincenzo Eduardo Padulano, CERN/EP-SFT,\; Danilo Piparo, CERN/EP-SFT,\; Fons Rademakers, CERN/IT,\; Jonas Rembser, CERN/EP-SFT,\; Andrea Rizzi, University of Pisa,\; Andre Sailer, CERN/EP-SFT,\; Garima Singh, ETH,\; Juraj Smiesko, CERN/RCS-PRJ-FC,\; Pavlo Svirin, National Technical University of Ukraine,\; Robin Syring, Leibniz University Hannover, CERN/EP-SFT,\; Maciej Szymanski, Argonne,\; Christian Tacke, Darmstadt University,\; Matevz Tadel, UCSD/CMS,\; Alvaro Tolosa Delgado, CERN/RCS-PRJ-FC,\; Devaj",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v634/index.md:113,schedul,scheduled,113,README/ReleaseNotes/v634/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v634/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"% ROOT Version ?.?? Release Notes; % 20??-??-??; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.??.00 is scheduled for release in ???. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Anton Alkin, Sungkyunkwan University\; Guilherme Amadio, CERN/IT,\; Abhigyan Acherjee, University of Cincinnati,\; Bertrand Bellenot, CERN/EP-SFT,\; Jakob Blomer, CERN/EP-SFT,\; Rene Brun,\; Carsten Burgard, DESY\; Will Buttinger, RAL,\; Philippe Canal, FNAL,\; Jolly Chen, CERN/EP-SFT,\; Olivier Couet, CERN/EP-SFT,\; Marta Czurylo, CERN/EP-SFT,\; Monica Dessole, CERN/EP-SFT,\; Mattias Ellert, Uppsala University,\; Gerri Ganis, CERN/EP-SFT,\; Florine de Geus, CERN/University of Twente,\; Andrei Gheata, CERN/EP-SFT,\; Bernhard Manfred Gruber,\; Enrico Guiraud,; Jonas Hahnfeld, CERN/Goethe University Frankfurt,\; Fernando Hueso Gonzalez, University of Valencia\; Attila Krasznahorkay, CERN/EP-ADP-OS,\; Wim Lavrijsen, LBL,\; Dennis Klein, GSI,\; Christoph Langenbruch, Heidelberg University/LHCb,\; Sergey Linev, GSI,\; Javier Lopez-Gomez,\; Pere Mato, CERN/EP-SFT,\; Alaettin Serhan Mete, Argonne,\; Thomas Madlener, DESY,\; Lorenzo Moneta, CERN/EP-SFT,\; Alja Mrak Tadel, UCSD/CMS,\; Axel Naumann, CERN/EP-SFT,\; Dante Niewenhuis, VU Amsterdam\; Luis Antonio Obis Aparicio, University of Zaragoza,; Ianna Osborne, Princeton University,\; Vincenzo Eduardo Padulano, CERN/EP-SFT,\; Danilo Piparo, CERN/EP-SFT,\; Fons Rademakers, CERN/IT,\; Jonas Rembser, CERN/EP-SFT,\; Andrea Rizzi, University of Pisa,\; Andre Sailer, CERN/EP-SFT,\; Garima Singh, ETH,\; Juraj Smiesko, CERN/RCS-PRJ-FC,; Pavlo Svirin, National Technical University of Ukraine,\; Maciej Szymanski, Argonne,\; Christian Tacke, Darmstadt University,\; Matevz Tadel, UCSD/CMS,\; Alvaro Tolosa Delgado, CERN/RCS-PRJ-FC,\; Devajith Valaparambil Sreeramaswamy, CERN/EP-SFT,\; Peter Van Gemmeren, Argonne,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHE",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/empty.md:116,schedul,scheduled,116,README/ReleaseNotes/empty.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/empty.md,1,['schedul'],['scheduled']
Energy Efficiency,"' extension is appended. Like:. ```bash; [shell] wget http://localhost:8080/Objects/subfolder/obj/root.json.gz; ```. If the access to the server is restricted with htdigest, it is recommended to use the **curl** program since only curl correctly implements such authentication method. The command will look like:. ```bash; [shell] curl --user ""accout:password"" http://localhost:8080/Objects/subfolder/obj/root.json --digest -o root.json; ```. ### Objects data access in JSON format. Request `root.json` implemented with [TBufferJSON](https://root.cern/doc/master/classTBufferJSON.html) class. TBufferJSON generates such object representation, which could be directly used in [JSROOT](https://root.cern/js/) for drawing. `root.json` request returns either complete object or just object member like:. ```bash; [shell] wget http://localhost:8080/Objects/subfolder/obj/fTitle/root.json; ```. The result will be: `""title""`. For the `root.json` request one could specify the 'compact' parameter, which allow to reduce the number of spaces and new lines without data lost. This parameter can have values from '0' (no compression) till '3' (no spaces and new lines at all).; In addition, one can use simple compression algorithm for big arrays. If compact='10', zero values in the begin and at the end; of the array will be excluded. If compact='20', similar values or large zero gaps in-between will be compressed. Such array; compression support in JSROOT from version 4.8.2. Usage of `root.json` request is about as efficient as binary `root.bin` request. Comparison of different request methods with TH2 histogram from hsimple.C shown in the table:. | Request | Size |; | :---------------------- | :--------- |; | root.bin | 7672 bytes |; | root.bin.gz | 1582 bytes |; | root.json | 8570 bytes |; | root.json?compact=3 | 6004 bytes |; | root.json?compact=23 | 5216 bytes |; | root.json.gz?compact=23 | 1855 bytes |. One should remember that JSON representation always includes names of the data fields w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:17031,reduce,reduce,17031,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['reduce'],['reduce']
Energy Efficiency,"(),; OptionsParser.getSourcePathList());; return Tool.run(newFrontendActionFactory<clang::SyntaxOnlyAction>().get());; }. And that's it! You can compile our new tool by running ninja from the; ``build`` directory. .. code-block:: console. cd ~/clang-llvm/build; ninja. You should now be able to run the syntax checker, which is located in; ``~/clang-llvm/build/bin``, on any source file. Try it!. .. code-block:: console. echo ""int main() { return 0; }"" > test.cpp; bin/loop-convert test.cpp --. Note the two dashes after we specify the source file. The additional; options for the compiler are passed after the dashes rather than loading; them from a compilation database - there just aren't any options needed; right now. Intermezzo: Learn AST matcher basics; ====================================. Clang recently introduced the :doc:`ASTMatcher; library <LibASTMatchers>` to provide a simple, powerful, and; concise way to describe specific patterns in the AST. Implemented as a; DSL powered by macros and templates (see; `ASTMatchers.h <../doxygen/ASTMatchers_8h_source.html>`_ if you're; curious), matchers offer the feel of algebraic data types common to; functional programming languages. For example, suppose you wanted to examine only binary operators. There; is a matcher to do exactly that, conveniently named ``binaryOperator``.; I'll give you one guess what this matcher does:. .. code-block:: c++. binaryOperator(hasOperatorName(""+""), hasLHS(integerLiteral(equals(0)))). Shockingly, it will match against addition expressions whose left hand; side is exactly the literal 0. It will not match against other forms of; 0, such as ``'\0'`` or ``NULL``, but it will match against macros that; expand to 0. The matcher will also not match against calls to the; overloaded operator ``'+'``, as there is a separate ``operatorCallExpr``; matcher to handle overloaded operators. There are AST matchers to match all the different nodes of the AST,; narrowing matchers to only match AST nodes fulfil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst:5891,power,powered,5891,interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,1,['power'],['powered']
Energy Efficiency,"(*CreateIterators_t)(void *collection, void **begin_arena, void **end_arena);; virtual CreateIterators_t GetFunctionCreateIterators(Bool_t read = kTRUE) = 0;; // begin_arena and end_arena should contain the location of a memory arena of size fgIteratorSize.; // If the collection iterator are of that size or less, the iterators will be constructed in place in those location; // (new with placement.) Otherwise the iterators will be allocated via a regular new and their address returned by; // modifying the value of begin_arena and end_arena. typedef void* (*CopyIterator_t)(void *dest, const void *source);; virtual CopyIterator_t GetFunctionCopyIterator(Bool_t read = kTRUE) = 0;; // Copy the iterator source, into dest. dest should contain the location of a memory arena of size fgIteratorSize.; // If the collection iterator is of that size or less, the iterator will be constructed in place in this location; // (new with placement.) Otherwise the iterator will be allocated via a regular new and its address returned by; // modifying the value of dest. typedef void* (*Next_t)(void *iter, const void *end);; virtual Next_t GetFunctionNext(Bool_t read = kTRUE) = 0;; // iter and end should be pointers to respectively an iterator to be incremented and the result of collection.end(); // If the iterator has not reached the end of the collection, 'Next' increment the iterator 'iter' and return 0 if; // the iterator reached the end.; // If the end was not reached, 'Next' returns the address of the content pointed to by the iterator before the; // incrementation ; if the collection contains pointers, 'Next' will return the value of the pointer. typedef void (*DeleteIterator_t)(void *iter);; typedef void (*DeleteTwoIterators_t)(void *begin, void *end);. virtual DeleteIterator_t GetFunctionDeleteIterator(Bool_t read = kTRUE) = 0;; virtual DeleteTwoIterators_t GetFunctionDeleteTwoIterators(Bool_t read = kTRUE) = 0;; // If the size of the iterator is greater than fgIteratorArenaSize, cal",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html:6845,allocate,allocated,6845,io/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html,1,['allocate'],['allocated']
Energy Efficiency,"(0); ```. If you have a divided pad, you need to set the scale on each of the; sub-pads. Setting it on the containing pad does not automatically; propagate to the sub-pads. Here is an example of how to set the log; scale for the x-axis on a canvas with four sub-pads:. ``` {.cpp}; root[] TCanvas MyCanvas(""MyCanvas"",""My Canvas""); root[] MyCanvas->Divide(2,2); root[] MyCanvas->cd(1); root[] gPad->SetLogx(); root[] MyCanvas->cd(2); root[] gPad->SetLogx(); root[] MyCanvas->cd(3); root[] gPad->SetLogx(); ```. ### WaitPrimitive method. When the `TPad::WaitPrimitive()` method is called with no arguments, it; will wait until a double click or any key pressed is executed in the; canvas. A call to `gSystem->Sleep(10)` has been added in the loop to; avoid consuming at all the CPU. This new option is convenient when; executing a macro. By adding statements like:. ``` {.cpp}; canvas->WaitPrimitive();; ```. You can monitor the progress of a running macro, stop it at convenient; places with the possibility to interact with the canvas and resume the; execution with a double click or a key press. ### Locking the Pad. You can make the **`TPad`** non-editable. Then no new objects can be; added, and the existing objects and the pad can not be changed with the; mouse or programmatically. By default the **`TPad`** is editable. ``` {.cpp}; TPad::SetEditable(kFALSE); ```. ## Graphical Objects. In this paragraph, we describe the various simple 2D graphical objects; defined in ROOT. Usually, one defines these objects with their; constructor and draws them with their `Draw()` method. Therefore, the; examples will be very brief. Most graphical objects have line and fill; attributes (color, width) that will be described in ""Graphical objects; attributes"". If the user wants more information, the class names are; given and they may refer to the online developer documentation. This is; especially true for functions and methods that set and get internal; values of the objects described here. By defa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:31112,monitor,monitor,31112,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['monitor'],['monitor']
Energy Efficiency,"(Twine(""-fpass-plugin="") + A->getValue()));; + A->claim();; + }; }. The last step is implementing the ``-cc1`` command line argument; parsing/generation that initializes/serializes the option class (in our case; ``CodeGenOptions``) stored within ``CompilerInvocation``. This can be done; automatically by using the marshalling annotations on the option definition:. .. code-block:: diff. // Options.td. def fpass_plugin_EQ : Joined<[""-""], ""fpass-plugin="">,; Group<f_Group>, Flags<[CC1Option]>,; HelpText<""Load pass plugin from a dynamic shared object file."">,; + MarshallingInfoStringVector<CodeGenOpts<""PassPlugins"">>;. Inner workings of the system are introduced in the :ref:`marshalling; infrastructure <OptionMarshalling>` section and the available annotations are; listed :ref:`here <OptionMarshallingAnnotations>`. In case the marshalling infrastructure does not support the desired semantics,; consider simplifying it to fit the existing model. This makes the command line; more uniform and reduces the amount of custom, manually written code. Remember; that the ``-cc1`` command line interface is intended only for Clang developers,; meaning it does not need to mirror the driver interface, maintain backward; compatibility or be compatible with GCC. If the option semantics cannot be encoded via marshalling annotations, you can; resort to parsing/serializing the command line arguments manually:. .. code-block:: diff. // CompilerInvocation.cpp. static bool ParseCodeGenArgs(CodeGenOptions &Opts, ArgList &Args /*...*/) {; // ... + Opts.PassPlugins = Args.getAllArgValues(OPT_fpass_plugin_EQ);; }. static void GenerateCodeGenArgs(const CodeGenOptions &Opts,; SmallVectorImpl<const char *> &Args,; CompilerInvocation::StringAllocator SA /*...*/) {; // ... + for (const std::string &PassPlugin : Opts.PassPlugins); + GenerateArg(Args, OPT_fpass_plugin_EQ, PassPlugin, SA);; }. Finally, you can specify the argument on the command line:; ``clang -fpass-plugin=a -fpass-plugin=b`` and use the ne",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:32654,reduce,reduces,32654,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['reduce'],['reduces']
Energy Efficiency,"(auto &E : B.edges()); if (E.getKind() == CallEdgeKind &&; E.getTarget().hasName() &&; E.getTraget().getName() == FunctionName); CallSitesForFunction.push_back(B.getFixupAddress(E));; return Error::success();; };. Memory Management with JITLinkMemoryManager; -------------------------------------------. JIT linking requires allocation of two kinds of memory: working memory in the; JIT process and target memory in the execution process (these processes and; memory allocations may be one and the same, depending on how the user wants; to build their JIT). It also requires that these allocations conform to the; requested code model in the target process (e.g. MachO/x86-64's Small code; model requires that all code and data for a simulated dylib is allocated within; 4Gb). Finally, it is natural to make the memory manager responsible for; transferring memory to the target address space and applying memory protections,; since the memory manager must know how to communicate with the executor, and; since sharing and protection assignment can often be efficiently managed (in; the common case of running across processes on the same machine for security); via the host operating system's virtual memory management APIs. To satisfy these requirements ``JITLinkMemoryManager`` adopts the following; design: The memory manager itself has just two virtual methods for asynchronous; operations (each with convenience overloads for calling synchronously):. .. code-block:: c++. /// Called when allocation has been completed.; using OnAllocatedFunction =; unique_function<void(Expected<std::unique_ptr<InFlightAlloc>)>;. /// Called when deallocation has completed.; using OnDeallocatedFunction = unique_function<void(Error)>;. /// Call to allocate memory.; virtual void allocate(const JITLinkDylib *JD, LinkGraph &G,; OnAllocatedFunction OnAllocated) = 0;. /// Call to deallocate memory.; virtual void deallocate(std::vector<FinalizedAlloc> Allocs,; OnDeallocatedFunction OnDeallocated) = 0;. The ``all",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:26382,efficient,efficiently,26382,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['efficient'],['efficiently']
Energy Efficiency,"(c1_n/sum_1, c2_n/sum_2). The result overlap distribution is a percentage number, ranging from 0.0% to; 100.0%, where 0.0% means there is no overlap and 100.0% means a perfect; overlap. Here is an example, if *base profile file* has counts of {400, 600}, and; *test profile file* has matched counts of {60000, 40000}. The *overlap* is 80%. OPTIONS; ^^^^^^^. .. option:: --function=<string>. Print details for a function if the function's name contains the given string. .. option:: --help. Print a summary of command line options. .. option:: --output=<output>, -o. Specify the output file name. If *output* is ``-`` or it isn't specified,; then the output is sent to standard output. .. option:: --value-cutoff=<n>. Show only those functions whose max count values are greater or equal to ``n``.; By default, the value-cutoff is set to max of unsigned long long. .. option:: --cs. Only show overlap for the context sensitive profile counts. The default is to show; non-context sensitive profile counts. .. program:: llvm-profdata order. .. _profdata-order:. ORDER; -------. SYNOPSIS; ^^^^^^^^. :program:`llvm-profdata order` [*options*] [*filename*]. DESCRIPTION; ^^^^^^^^^^^. :program:`llvm-profdata order` uses temporal profiling traces from a profile and; finds a function order that reduces the number of page faults for those traces.; This output can be directly passed to ``lld`` via ``--symbol-ordering-file=``; for ELF or ``-order-file`` for Mach-O. If the traces found in the profile are; representative of the real world, then this order should improve startup; performance. OPTIONS; ^^^^^^^. .. option:: --help. Print a summary of command line options. .. option:: --output=<output>, -o. Specify the output file name. If *output* is ``-`` or it isn't specified,; then the output is sent to standard output. EXIT STATUS; -----------. :program:`llvm-profdata` returns 1 if the command is omitted or is invalid,; if it cannot read input files, or if there is a mismatch between their data.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:13863,reduce,reduces,13863,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,1,['reduce'],['reduces']
Energy Efficiency,"(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }; ~~~. Validation code `$ROOTSYS/test/vmatrix.cxx` and `vvector.cxx` contain; a few more examples of that kind. #### 6. Lazy matrices:. instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; ~~~. THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. ### Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:19288,adapt,adapted,19288,math/matrix/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md,2,['adapt'],['adapted']
Energy Efficiency,"(i = 0; i < background->GetEntries(); i++) {; background->GetEntry(i);; params[0] = msumf; params[1] = ptsumf;; params[2] = acolin; params[3] = acopl;; bg->Fill(mlp->Evaluate(0,params));; }; for (i = 0; i < signal->GetEntries(); i++) {; signal->GetEntry(i);; params[0] = msumf;; params[1] = ptsumf;; params[2] = acolin;; params[3] = acopl;; sig->Fill(mlp->Evaluate(0,params));; }; TCanvas *cv = new TCanvas(""NNout_cv"",""Neural net output"");; bg->SetFillStyle(3008);; bg->SetFillColor(kBlue);; sig->SetFillStyle(3003);; sig->SetFillColor(kRed);; bg->SetStats(0);; sig->SetStats(0);; bg->Draw();; sig->Draw(""same"");; TLegend *legend = new TLegend(.75,.80,.95,.95);; legend->AddEntry(bg,""Background(WW)"");; legend->AddEntry(sig,""Signal(Higgs)"");; legend->Draw();; ```. The neural net output is then used to display the final difference; between background and signal events. The figure ""The neural net; output"" shows this plot. ![The neural net output](pictures/image144.png). As it can be seen, this is a quite efficient technique. As mentioned; earlier, neural networks are also used for fitting function. For some; application with a cylindrical symmetry, a magnetic field simulation; gives as output the angular component of the potential vector `A`, as; well as the radial and `z` components of the `B` field. One wants to fit those distributions with a function in order to plug; them into the `Geant` simulation code. Polynomial fits could be tried,; but it seems difficult to reach the desired precision over the full; range. One could also use a `spline` interpolation between known; points. In all cases, the resulting field would not be `C`-infinite. An example of output (for Br) is shown. First the initial function can; be seen as the target. Then, the resulting (normalized) neural net; output. In order to ease the learning, the ""normalize output"" was used; here. The initial amplitude can be recovered by multiplying by the; original RMS and then shifting by the original mean. ![The ori",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:80453,efficient,efficient,80453,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['efficient'],['efficient']
Energy Efficiency,"(with parallelMergerServer.C being the prototype of the upcoming; parallel merger server executable). Other. Introduce the new function TFileMerger::PartialMerge(Int_t) which; will Merge the list of file _with_ the content of the output; file (if any). This allows make several successive Merge; into the same TFile object.; Yhe argument defines the type of merge as define by the bit values in EPartialMergeType:; ; kRegular : normal merge, overwritting the output file.; kIncremental : merge the input file with the content of the output file (if already exising) (default).; kAll : merge all type of objects (default).; kResetable : merge only the objects with a MergeAfterReset member function. ; kNonResetable : merge only the objects without a MergeAfterReset member function. . Removed TFileMerger::RecursiveMerge from the interface. Prevent TFileMerger (and hadd) from trying to open too many files.; Add a new member function TFileMerger::SetMaxOpenedFiles and; new command line option to hadd ( -n requested_max ) to allow; the user to reduce the number of files opened even further. Update hadd and TFileMerger so that they prefix all their information message; with their names (when running hadd, the TFileMerger message are prefixed by hadd):. $ hadd -v 0 -f output.root input1.root input2.root; $ hadd -v 1 -f output.root input1.root input2.root; hadd merged 2 input files in output.root.; $ hadd -v 2 -f output.root input1.root input2.root; hadd target file: output.root; hadd Source file 1: input1.root; hadd Source file 2: input2.root; hadd Target path: output.root:/. Introduce non-static version of TFile::Cp allows the copy of; an existing TFile object. Introduce new explicit interface for providing reseting; capability after a merge. If a class has a method with; the name and signature:. void ResetAfterMerge(TFileMergeInfo*);. it will be used by a TMemFile to reset its objects after; a merge operation has been done. If this method does not exist, the TClass will use; a me",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html:7737,reduce,reduce,7737,io/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html,1,['reduce'],['reduce']
Energy Efficiency,") simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target instruction selector; matches the DAG operations to target instructions. This process translates; the target-independent input DAG into another DAG of target instructions. #. `SelectionDAG Scheduling and Formation`_ --- The last phase assigns a linear; order to the instructions in the target-instruction DAG and emits them into; the MachineFunction being compiled. This step uses traditional prepass; scheduling techniques. After all of these steps are complete, the SelectionDAG is destroyed and the; rest of the code generation passes are run. One of the most common ways to debug these steps is using ``-debug-only=isel``,; which prints out the DAG, along with other information like debug info,; after each of these steps. Alternatively, ``-debug-only=isel-dump`` shows only; the DAG dumps, but the results can be filtered by function names using; ``-filter-print-funcs=<function names>``. One great way to visualize what is going on here is to take advantage of a few; LLC command line options. The following options pop up a window displaying the; SelectionDAG at specific times (if you only get errors printed to the console; while using this, you probably `need to configure your; system <ProgrammersManual.html#viewing-graphs-while-debugging-code>`_ to add support for it). * ``-view-dag-combine1-dags`` displays the DAG after being built, before the; first optimization pass. * ``-vie",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:38397,schedul,scheduling,38397,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['schedul'],['scheduling']
Energy Efficiency,")); // S == ""8+9+10""; S = formatv(""{0:$[ + ]@[x]}"", make_range(V.begin(), V.end())); // S == ""0x8 + 0x9 + 0xA"". .. _error_apis:. Error handling; --------------. Proper error handling helps us identify bugs in our code, and helps end-users; understand errors in their tool usage. Errors fall into two broad categories:; *programmatic* and *recoverable*, with different strategies for handling and; reporting. Programmatic Errors; ^^^^^^^^^^^^^^^^^^^. Programmatic errors are violations of program invariants or API contracts, and; represent bugs within the program itself. Our aim is to document invariants, and; to abort quickly at the point of failure (providing some basic diagnostic) when; invariants are broken at runtime. The fundamental tools for handling programmatic errors are assertions and the; llvm_unreachable function. Assertions are used to express invariant conditions,; and should include a message describing the invariant:. .. code-block:: c++. assert(isPhysReg(R) && ""All virt regs should have been allocated already."");. The llvm_unreachable function can be used to document areas of control flow; that should never be entered if the program invariants hold:. .. code-block:: c++. enum { Foo, Bar, Baz } X = foo();. switch (X) {; case Foo: /* Handle Foo */; break;; case Bar: /* Handle Bar */; break;; default:; llvm_unreachable(""X should be Foo or Bar here"");; }. Recoverable Errors; ^^^^^^^^^^^^^^^^^^. Recoverable errors represent an error in the program's environment, for example; a resource failure (a missing file, a dropped network connection, etc.), or; malformed input. These errors should be detected and communicated to a level of; the program where they can be handled appropriately. Handling the error may be; as simple as reporting the issue to the user, or it may involve attempts at; recovery. .. note::. While it would be ideal to use this error handling scheme throughout; LLVM, there are places where this hasn't been practical to apply. In; situations where ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:17205,allocate,allocated,17205,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocated']
Energy Efficiency,"));; } else {; do {; i--;; } while (f());; }; }. alpha.core.PointerArithm; (C); Check for pointer arithmetic on locations other than array; elements. void test() {; int x;; int *p;; p = &x + 1; // warn; }. alpha.core.PointerSub; (C); Check for pointer subtractions on two pointers pointing to different memory; chunks. void test() {; int x, y;; int d = &y - &x; // warn; }. alpha.core.SizeofPtr; (C); Warn about unintended use of sizeof() on pointer; expressions. struct s {};. int test(struct s *p) {; return sizeof(p);; // warn: sizeof(ptr) can produce an unexpected result; }. alpha.core.StackAddressAsyncEscape; (C); Check that addresses to stack memory do not escape the function that involves; dispatch_after or dispatch_async. This checker is; a part of core.StackAddressEscape, but is; temporarily disabled until some; false positives are fixed. dispatch_block_t test_block_inside_block_async_leak() {; int x = 123;; void (^inner)(void) = ^void(void) {; int y = x;; ++y;; };; void (^outer)(void) = ^void(void) {; int z = x;; ++z;; inner();; };; return outer; // warn: address of stack-allocated block is captured by a; // returned block; }. alpha.core.TestAfterDivZero; (C, C++, ObjC); Check for division by variable that is later compared against 0.; Either the comparison is useless or there is division by zero. void test(int x) {; var = 77 / x;; if (x == 0) { } // warn; }. C++ Alpha Checkers. Name, DescriptionExample. alpha.cplusplus.ArrayDelete; (C++); Reports destructions of arrays of polymorphic objects that are destructed as; their base class. Base *create() {; Base *x = new Derived[10]; // note: Casting from 'Derived' to 'Base' here; return x;; }. void sink(Base *x) {; delete[] x; // warn: Deleting an array of 'Derived' objects as their base class 'Base' undefined; }. alpha.cplusplus.DeleteWithNonVirtualDtor; (C++); Reports destructions of polymorphic objects with a non-virtual destructor in; their base class. NonVirtual *create() {; NonVirtual *x = new NVDerived(); // no",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/alpha_checks.html:3990,allocate,allocated,3990,interpreter/llvm-project/clang/www/analyzer/alpha_checks.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/alpha_checks.html,1,['allocate'],['allocated']
Energy Efficiency,"), and the; command `ch->SetProof();` enables processing of the chain using PROOF.; Now, when issuing the command `ch->Process(""MySelector.C+);`, the code; in `MySelector.C` is compiled and executed on each slave node. The; methods `Begin()` and `Terminate()` are executed on the master only. The; list of n-tuple files is analysed, and portions of the data are assigned; to the available slave processes. Histograms booked in `SlaveBegin()`; exist in the processes on the slave nodes, and are filled accordingly.; Upon termination, the PROOF master collects the histograms from the; slaves and merges them. In `Terminate()` all merged histograms are; available and can be inspected, analysed or stored. The histograms are; handled via the instances `fOutput` of class `TList` in each slave; process, and can be retrieved from this list after merging in; `Terminate`. To explore the power of this mechanism, generate some very large; n-tuples using the script from the section; [Storing Arbitrary N-tuples](#storing-arbitrary-n-tuples) -; you could try 10 000 000 events (this; results in a large n-tuple of about 160 MByte in size). You could also; generate a large number of files and use wildcards to add the to the; `TChain`. Now execute: `> root -l RunMySelector.C` and watch what; happens:. ``` {.cpp}; Processing RunMySelector.C...; +++ Starting PROOF-Lite with 4 workers +++; Opening connections to workers: OK (4 workers); Setting up worker servers: OK (4 workers); PROOF set to parallel mode (4 workers). Info in <TProofLite::SetQueryRunning>: starting query: 1; Info in <TProofQueryResult::SetRunning>: nwrks: 4; Info in <TUnixSystem::ACLiC>: creating shared library; ~/DivingROOT/macros/MySelector_C.so; *==* ----- Begin of Job ----- Date/Time = Wed Feb 15 23:00:04 2012; Looking up for exact location of files: OK (4 files); Looking up for exact location of files: OK (4 files); Info in <TPacketizerAdaptive::TPacketizerAdaptive>:; Setting max number of workers per node to 4; Validating",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md:11121,power,power,11121,documentation/primer/filio.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md,1,['power'],['power']
Energy Efficiency,"); ==============================================. .. contents::; :local:. .. _arc.meta:. About this document; ===================. .. _arc.meta.purpose:. Purpose; -------. The first and primary purpose of this document is to serve as a complete; technical specification of Automatic Reference Counting. Given a core; Objective-C compiler and runtime, it should be possible to write a compiler and; runtime which implements these new semantics. The secondary purpose is to act as a rationale for why ARC was designed in this; way. This should remain tightly focused on the technical design and should not; stray into marketing speculation. .. _arc.meta.background:. Background; ----------. This document assumes a basic familiarity with C. :arc-term:`Blocks` are a C language extension for creating anonymous functions.; Users interact with and transfer block objects using :arc-term:`block; pointers`, which are represented like a normal pointer. A block may capture; values from local variables; when this occurs, memory must be dynamically; allocated. The initial allocation is done on the stack, but the runtime; provides a ``Block_copy`` function which, given a block pointer, either copies; the underlying block object to the heap, setting its reference count to 1 and; returning the new block pointer, or (if the block object is already on the; heap) increases its reference count by 1. The paired function is; ``Block_release``, which decreases the reference count by 1 and destroys the; object if the count reaches zero and is on the heap. Objective-C is a set of language extensions, significant enough to be; considered a different language. It is a strict superset of C. The extensions; can also be imposed on C++, producing a language called Objective-C++. The; primary feature is a single-inheritance object system; we briefly describe the; modern dialect. Objective-C defines a new type kind, collectively called the :arc-term:`object; pointer types`. This kind has two notable builtin ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:2632,allocate,allocated,2632,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['allocate'],['allocated']
Energy Efficiency,");; ```. Here we have a `Quad` pointer that has been initialized with the; address of a stack object. Be very careful if you take the address of; stack objects. As we shall see soon, they are deleted automatically,; which could leave you with an illegal pointer. Using it will corrupt; and may as well crash the program!. It is time to look at the destruction of objects. A destructor is a; special C++ function that releases resources for (or destroys) an; object of a class. It is the opposite of a constructor that creates the; object of a class when it is called. The compiler will provide a; destructor that does nothing if none is provided. We will add one to; our Quad class so that we can see when it is called. The class names; the destructor but with a prefix \~ which is the C++ one's complement; i.e. bit wise complement, and hence has destruction overtones! We; declare it in the .h file and define it in the `.cxx` file. It does; not do much except print out that it has been called (still a useful; debug technique despite today's powerful debuggers!). Now run root, load the Quad class and create a heap object:. ``` {.cpp}; root[] .L Quad.cxx; root[] Quad *my_objptr = new Quad(1.,2.,-3.);; ```. To delete the object:. ``` {.cpp}; root[] delete my_objptr;; root[] my_objptr = 0;; ```. You should see the print out from its destructor. Setting the pointer; to zero afterwards is not strictly necessary (and Cling does it; automatically), but the object is no more accessible, and any attempt; to use the pointer again will, as has already been stated, cause; grief. So much for heap objects, but how are stack objects deleted? In; C++, a stack object is deleted as soon as control leaves the innermost; compound statement that encloses it. Therefore, it is singularly; futile to do something like:. ``` {.cpp}; root[] { Quad my_object(1.,2.,-3.); }; ```. Cling does not follow this rule; if you type in the above line, you; will not see the destructor message. As explained in the Scri",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/ALittleC++.md:12849,power,powerful,12849,documentation/users-guide/ALittleC++.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/ALittleC++.md,1,['power'],['powerful']
Energy Efficiency,"* MASSES, WIDTHS, AND MC ID NUMBERS FROM 2008 EDITION OF RPP; *; * The following values were generated on July 2008 by the Berkeley Particle; * Data Group from the Review of Particle Physics database and are intended; * for use in Monte Carlo programs.; *; * For questions regarding distribution or content of this file, contact; * the Particle Data Group at pdg@lbl.gov.; *; * To process the images in this file:; * 1) ignore documentation lines that begin with an asterisk; * 2) in a FORTRAN program, process data lines with; * FORMAT (BN, A1, 4I8, 1X, E15.0, 2(1X, E8.0), 1X, A21); * 3) column 1 contains either ""M"" or ""W"" indicating mass or width; * 2 - 9 \ Monte Carlo particle numbers as described in the ""Review of; * 10 - 17 | Particle Physics"". Charge states appear, as appropriate,; * 18 - 25 | from left-to-right in the order -, 0, +, ++.; * 26 - 33 /; * 34 blank; * 35 - 49 central value of the mass or width (double precision); * 50 blank; * 51 - 58 positive error; * 59 blank; * 60 - 67 negative error; * 68 blank; * 69 - 89 particle name left-justified in the field and; * charge states right-justified in the field.; * This field is for ease of visual examination of the file and; * should not be taken as a standardized presentation of; * particle names.; *; * Particle ID(s) Value (GeV) Errors (GeV) Name Charges; M 22 0.E+00 +0.0E+00 -0.0E+00 gamma 0; W 22 0.E+00 +0.0E+00 -0.0E+00 gamma 0; M 24 8.0398E+01 +2.5E-02 -2.5E-02 W +; W 24 2.14E+00 +4.0E-02 -4.0E-02 W +; M 23 9.11876E+01 +2.1E-03 -2.1E-03 Z 0; W 23 2.4952E+00 +2.3E-03 -2.3E-03 Z 0; M 11 5.10998910E-04 +1.3E-11 -1.3E-11 e -; W 11 0.E+00 +0.0E+00 -0.0E+00 e -; M 13 1.05658367E-01 +4.0E-09 -4.0E-09 mu -; W 13 3.015937E-19 +2.9E-24 -2.9E-24 mu -; M 15 1.77684E+00 +1.7E-04 -1.7E-04 tau -; W 15 2.280E-12 +8.0E-15 -8.0E-15 tau -; M 2 2.4E-03 +9.0E-04 -9.0E-04 u +2/3; M 1 4.8E-03 +1.2E-03 -1.2E-03 d -1/3; M 3 1.04E-01 +2.6E-02 -3.4E-02 s -1/3; M 4 1.27E+00 +7.0E-02 -1.1E-01 c +2/3; M 5 4.68E+00 +1.7E-01 -7.0E-02 b -1/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/mc/mass_width_2008.mc.txt:1088,charge,charge,1088,tutorials/mc/mass_width_2008.mc.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/mc/mass_width_2008.mc.txt,1,['charge'],['charge']
Energy Efficiency,"**************** CLING ******************; * Type C++ code and press enter to run it *; * Type .q to exit *; *******************************************; [cling]$ #include <string>; [cling]$ std::string s(""abc"");; [cling]$ s.find('b'); (std::basic_string<char, std::char_traits<char>, std::allocator<char> >::size_type) 1; [cling]$. Cling is built on the top of LLVM and Clang libraries. In addition to standard interpreters it has a command line prompt and uses just-in-time (JIT) compiler. This kind of software application is commonly known as an interactive compiler.; ; Cling started off as a contemporary, high-performance alternative of the current C++ interpreter in the ROOT project - CINT.; ; Why interpreting C++ with Cling?. Learning C++ . ; One use case of cling is to aid the C++ learning process. Offering imediate feedback the user can easily get familiar with the structures and spelling of the language. ; . Creating scripts; ; The power of an interpreter lays as well in the compactness and ease of repeatedly running a small snippet of code - aka a script. This can be done in cling by inserting the bash-like style line: ; . #!/usr/bin/cling; . Rapid Application Development (RAD) . ; Cling can be used successfully for Rapid Application Development allowing for prototyping and proofs of concept taking advantage of dynamicity and feedback during the implementation process.; . Runtime-Generated Code ; ; Sometime it's convenient to create code as a reaction to input; (user/network/configuration).; Runtime-generated code can interface with C++ libraries.; . Embedding Cling . The functionality of an application can be enriched by embedding Cling. To embed Cling, the main program has to be provided. One of the things this main program has to do is initialize the Cling interpreter. There are optional calls to pass command line arguments to Cling. Afterwards, you can call the interpreter from any anywhere within the application. For compilation and linkage the application ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/index.html:983,power,power,983,interpreter/cling/www/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/index.html,1,['power'],['power']
Energy Efficiency,"**. Methods 2, 3 and 4 can also easily iterate backwards using either a; backward **`TIter`** (using argument `kIterBackward`) or by using; `LastLink()` and `lnk>Prev`() or by using the `Before()` method. ## The TObjArray Collection. A **`TObjArray`** is a collection which supports traditional array; semantics via the overloading of `operator[]`. Objects can be directly; accessed via an index. The array expands automatically when objects are; added. At creation time one specifies the default array size (default =; 16) and lower bound (default = 0). Resizing involves a re-allocation and; a copy of the old array to the new. This can be costly if done too; often. If possible, set initial size close to expected final size. Index; validity is always checked (if you are 100% sure and maximum performance; is needed you can use `UnCheckedAt()` instead of `At()` or; `operator[]`). If the stored objects are sort able the array can be; sorted using `Sort()`. Once sorted, efficient searching is possible via; the `BinarySearch()` method. The figure shows the internal data; structure of a **`TObjArray`**:. ![The internal data structure of a TObjArray](pictures/020001A7.jpg). Iterating can be done using a **`TIter`** iterator or via a simple for; loop:. ``` {.cpp}; for (int i = 0; i <= fArr.GetLast(); i++); if ((track = (TTrack*)fArr[i])) // or fArr.At(i); track->Draw();; ```. Main features of **`TObjArray`** are simple, well-known array semantics.; **Overhead per element**: none, except possible over sizing of `fCont`. ## TClonesArray An Array of Identical Objects. A **`TClonesArray`** is an array of identical (clone) objects. The; memory for the objects stored in the array is allocated only once in the; lifetime of the clones array. All objects must be of the same class. For; the rest this class has the same properties as a **`TObjArray`**. ![The internal data structure of a TClonesArray](pictures/020001A8.jpg). The figure above shows the internal data structure of a; **`TClonesA",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/CollectionClasses.md:15519,efficient,efficient,15519,documentation/users-guide/CollectionClasses.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/CollectionClasses.md,1,['efficient'],['efficient']
Energy Efficiency,"++++. This section describes the call convention ABI for the outer kernel function. See :ref:`amdgpu-amdhsa-initial-kernel-execution-state` for the kernel call; convention. The following is not part of the AMDGPU kernel calling convention but describes; how the AMDGPU implements function calls:. 1. Clang decides the kernarg layout to match the *HSA Programmer's Language; Reference* [HSA]_. - All structs are passed directly.; - Lambda values are passed *TBA*. .. TODO::. - Does this really follow HSA rules? Or are structs >16 bytes passed; by-value struct?; - What is ABI for lambda values?. 4. The kernel performs certain setup in its prolog, as described in; :ref:`amdgpu-amdhsa-kernel-prolog`. .. _amdgpu-amdhsa-function-call-convention-non-kernel-functions:. Non-Kernel Functions; ++++++++++++++++++++. This section describes the call convention ABI for functions other than the; outer kernel function. If a kernel has function calls then scratch is always allocated and used for; the call stack which grows from low address to high address using the swizzled; scratch address space. On entry to a function:. 1. SGPR0-3 contain a V# with the following properties (see; :ref:`amdgpu-amdhsa-kernel-prolog-private-segment-buffer`):. * Base address pointing to the beginning of the wavefront scratch backing; memory.; * Swizzled with dword element size and stride of wavefront size elements. 2. The FLAT_SCRATCH register pair is setup. See; :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; 3. GFX6-GFX8: M0 register set to the size of LDS in bytes. See; :ref:`amdgpu-amdhsa-kernel-prolog-m0`.; 4. The EXEC register is set to the lanes active on entry to the function.; 5. MODE register: *TBD*; 6. VGPR0-31 and SGPR4-29 are used to pass function input arguments as described; below.; 7. SGPR30-31 return address (RA). The code address that the function must; return to when it completes. The value is undefined if the function is *no; return*.; 8. SGPR32 is used for the stack pointer (SP). It is ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:387214,allocate,allocated,387214,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,", &B::f2, &B::f3, &B::f4, &B::f5, &B::f6, C::offset-to-top, &C::rtti, &C::f1, &C::f2. Notice that each address point for A is separated by 4 words. This lets us; emit a compressed bit vector for A that looks like this:. .. csv-table::; :header: 2, 6, 10, 14. 1, 1, 0, 1. At call sites, the compiler will strengthen the alignment requirements by; using a different rotate count. For example, on a 64-bit machine where the; address points are 4-word aligned (as in A from our example), the ``rol``; instruction may look like this:. .. code-block:: none. dd2: 48 c1 c1 3b rol $0x3b,%rcx. Padding to Powers of 2; ~~~~~~~~~~~~~~~~~~~~~~. Of course, this alignment scheme works best if the address points are; in fact aligned correctly. To make this more likely to happen, we insert; padding between virtual tables that in many cases aligns address points to; a power of 2. Specifically, our padding aligns virtual tables to the next; highest power of 2 bytes; because address points for specific base classes; normally appear at fixed offsets within the virtual table, this normally; has the effect of aligning the address points as well. This scheme introduces tradeoffs between decreased space overhead for; instructions and bit vectors and increased overhead in the form of padding. We; therefore limit the amount of padding so that we align to no more than 128; bytes. This number was found experimentally to provide a good tradeoff. Eliminating Bit Vector Checks for All-Ones Bit Vectors; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. If the bit vector is all ones, the bit vector check is redundant; we simply; need to check that the address is in range and well aligned. This is more; likely to occur if the virtual tables are padded. Forward-Edge CFI for Virtual Calls by Interleaving Virtual Tables; -----------------------------------------------------------------. Dimitar et. al. proposed a novel approach that interleaves virtual tables in [1]_.; This approach is more efficient in ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:8727,power,power,8727,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['power'],['power']
Energy Efficiency,", `+V` and `+STUB` have no effect and will be; removed. Please remove them from the rootcling invocations.; * genreflex flag `--deep` has no effect and will be removed. Please remove it; from the genreflex invocation.; * rootcling warns if it sees and unrecognized flag (usually coming from the; CXXFLAGS of the build system). Please remove them from the invocation because; the warning will become a hard error in the next releases.; * The empty headers `Gtypes.h` and `Htypes.h` are deprecated. Please include; `Rtypes.h`; * TInterpreter::EnableAutoLoading currently does nothing and is deprecated. ### Deprecated packages. ### Removed packages. ## Core Libraries. * Speed-up startup, in particular in case of no or poor network accesibility, by avoiding; a network access that was used as input to generate a globally unique ID for the current; process.; * This network access is replaced by a passive scan of the network interface. This; reduces somewhat the uniqueness of the unique ID as the IP address is no longer; guaranteed by the DNS server to be unique. Note that this was already the case when; the network access (used to look up the hostname and its IP address) failed. ## I/O Libraries. * TFile: A new bit `TFile::kReproducible` was introduced. It can be enabled by; specifying the `""reproducible""` url option when creating the file:; ~~~ {.cpp}; TFile *f = TFile::Open(""name.root?reproducible"",""RECREATE"",""File title"");; ~~~; Unlike regular `TFile`s, the content of such file has reproducible binary; content when writing exactly same data. This achieved by writing pre-defined; values for creation and modification date of TKey/TDirectory objects and null; value for TUUID objects inside TFile. As drawback, TRef objects stored in such; file cannot be read correctly.; * Significantly improved the scaling of hadd tear-down/cleanup-phase in the presence; of large number histograms and in the presence of large number of directories.; * TMemFile: Apply customization of minimal bloc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md:2995,reduce,reduces,2995,README/ReleaseNotes/v620/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md,1,['reduce'],['reduces']
Energy Efficiency,", and can be; coupled with a good choice of :ref:`sequential container <ds_sequential>`. This combination provides the several nice properties: the result data is; contiguous in memory (good for cache locality), has few allocations, is easy to; address (iterators in the final vector are just indices or pointers), and can be; efficiently queried with a standard binary search (e.g.; ``std::lower_bound``; if you want the whole range of elements comparing; equal, use ``std::equal_range``). .. _dss_smallset:. llvm/ADT/SmallSet.h; ^^^^^^^^^^^^^^^^^^^. If you have a set-like data structure that is usually small and whose elements; are reasonably small, a ``SmallSet<Type, N>`` is a good choice. This set has; space for N elements in place (thus, if the set is dynamically smaller than N,; no malloc traffic is required) and accesses them with a simple linear search.; When the set grows beyond N elements, it allocates a more expensive; representation that guarantees efficient access (for most types, it falls back; to :ref:`std::set <dss_set>`, but for pointers it uses something far better,; :ref:`SmallPtrSet <dss_smallptrset>`. The magic of this class is that it handles small sets extremely efficiently, but; gracefully handles extremely large sets without loss of efficiency. .. _dss_smallptrset:. llvm/ADT/SmallPtrSet.h; ^^^^^^^^^^^^^^^^^^^^^^. ``SmallPtrSet`` has all the advantages of ``SmallSet`` (and a ``SmallSet`` of; pointers is transparently implemented with a ``SmallPtrSet``). If more than N; insertions are performed, a single quadratically probed hash table is allocated; and grows as needed, providing extremely efficient access (constant time; insertion/deleting/queries with low constant factors) and is very stingy with; malloc traffic. Note that, unlike :ref:`std::set <dss_set>`, the iterators of ``SmallPtrSet``; are invalidated whenever an insertion occurs. Also, the values visited by the; iterators are not visited in sorted order. .. _dss_stringset:. llvm/ADT/StringSe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:78294,allocate,allocates,78294,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,2,"['allocate', 'efficient']","['allocates', 'efficient']"
Energy Efficiency,", buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spec](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf),; but this implementation doesn't currently support that strategy. ## Common API Functions. ```c++; BLAKE3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *self);; ```. Initialize a `llvm_blake3_hasher` in the default hashing mode. ---. ```c++; void BLAKE3::update(ArrayRef<uint8_t> Data);. void BLAKE3::update(StringRef Str);; ```; ```c; void llvm_blake3_hasher_update(; llvm_blake3_hasher *self,; const void *input,; size_t input_len);; ```. Add input to the hasher. This can be called any number of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using BLAKE3Result = std::array<uint8_t, NumBytes>;. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; void BLAKE3::final(BLAKE3Result<NumBytes> &Result);. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; BLAKE3Result<NumBytes> BLAKE3::final",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:2260,reduce,reduced,2260,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,1,['reduce'],['reduced']
Energy Efficiency,", including palette; 8. Let change TH2 values range via context menu; 9. Fix problem with TH2 col drawing when bins size too small. ## Changes in 5.8.2; 1. Fix - tooltip handling for TH2 Error draw; 2. Fix - use proper ""fixed"" position for enlarged drawing; 3. Fix - correctly extract TF1 parameter names; 4. Fix - keep stat box when update histogram drawing; 5. Fix - context menu for axes in 3D drawings. ## Changes in 5.8.1; 1. Fix - use Math.floor when search for bin label; 2. Fix - renable correct highlight of TGraphErrors; 3. Fix - adjust TH1/TH2/TAxis values to let stream them in ROOT; 4. Fix - adjust TH[1,2,3].Fill() method to update entries count. ## Changes in 5.8.0; 1. Many TGeo-related changes:; - use TGeoManager::fVisLevel in geometry painter; - ""showtop"" draw option for TGeoManager (equivalent to gGeoManager->SetTopVisible()); - ""no_screen"" draw option to let ignore kVisOnScreen bits for display, checked first by default; - radial and z-axis interactive transformation for TGeo drawings; - improve ""comp"" and ""compx"" option to show TGeoCompositeShape components; - support of TGeo objects embed in TCanvas; - monitoring of TGeoManager with THttpServer; - ""rotyNN"" and ""rotzNN"" options to TGeo painter - let customize camera position; - context menu command to show current camera position; 2. New and simpler TArrow drawing without use of svg markers, interactive movement of TArrow class; 3. Support different marker styles in 3D drawings; 4. Support ""texte"" and ""texte0"" draw options for TH2/TProfile2D classes; 5. Provide wrong_http_response workaround (#189); 6. Update objects from list of histogram functions (#190). ## Changes in 5.7.2; 1. Fix - add missing factor in TGeoPgon shape; 2. Fix - correctly handle ""sync"" specifier in JSROOT.NewHttpRequest; 3. Fix - verify that TH1/TH2 superimposing in 3D works properly; 4. Fix - use provided options in JSROOT.redraw function; 5. Fix - arb8 shape, used in composite. ## Changes in 5.7.1; 1. Fix - cover for WebVR API inco",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:28650,monitor,monitoring,28650,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['monitor'],['monitoring']
Energy Efficiency,", returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with minimum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmaximum:. '``llvm.vector.reduce.fmaximum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmaximum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmaximum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmaximum.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maximum.*``'; intrinsic. That is, this intrinsic propagates NaNs and +0.0 is considered; greater than -0.0. If any element of the vector is a NaN, the result is NaN. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fminimum:. '``llvm.vector.reduce.fminimum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fminimum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fminimum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fminimum.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:660875,reduce,reduce,660875,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,", then maybe it makes more sense to move language; construct modeling to the engine when the checker API is not sufficient instead; of complicating the API. Right now I have no preference or objections between the alternatives but there; are some random thoughts:. * Maybe it would be great to have a guideline how to evolve the analyzer and; follow it, so it can help us to decide in similar situations. * I do care about performance in this case. The reason is that we have a; limited performance budget. And I think we should not expect most of the checker; writers to add modeling of language constructs. So, in my opinion, it is ok to; have less nice/more verbose API for language modeling if we can have better; performance this way, since it only needs to be done once, and is done by the; framework developers. **Artem:** These are some great questions, i guess it'd be better to discuss; them more openly. As a quick dump of my current mood:. * To me it seems obvious that we need to aim for a checker API that is both; simple and powerful. This can probably by keeping the API as powerful as; necessary while providing a layer of simple ready-made solutions on top of it.; Probably a few reusable components for assembling checkers. And this layer; should ideally be pleasant enough to work with, so that people would prefer to; extend it when something is lacking, instead of falling back to the complex; omnipotent API. I'm thinking of AST matchers vs. AST visitors as a roughly; similar situation: matchers are not omnipotent, but they're so nice. * Separation between core and checkers is usually quite strange. Once we have; shared state traits, i generally wouldn't mind having region store or range; constraint manager as checkers (though it's probably not worth it to transform; them - just a mood). The main thing to avoid here would be the situation when; the checker overwrites stuff written by the core because it thinks it has a; better idea what's going on, so the core should",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst:6238,power,powerful,6238,interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,1,['power'],['powerful']
Energy Efficiency,",; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-memory-model-gfx90a:. Memory Model GFX90A; +++++++++++++++++++. For GFX90A:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs. The exception is when in tgsplit execution mode; when the wavefronts may be executed by different SIMDs in different CUs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it. The exception is when in tgsplit execution mode when no LDS; is allocated as wavefronts of the same work-group can be in different CUs.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` ins",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:234705,allocate,allocated,234705,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,",; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-memory-model-gfx942:. Memory Model GFX942; +++++++++++++++++++. For GFX942:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs. The exception is when in tgsplit execution mode; when the wavefronts may be executed by different SIMDs in different CUs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it. The exception is when in tgsplit execution mode when no LDS; is allocated as wavefronts of the same work-group can be in different CUs.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` ins",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:284853,allocate,allocated,284853,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,",rmin,rmax,; dz,phi1,phi2);. // See class TGeoManager for the rest of shapes.; // Making a volume with a given shape with a unique prototype; TGeoVolume *vol = gGeoManager->Volume(""VNAME"",""XXXX"",nmed,upar,; npar);. // Where XXXX stands for the first 4 letters of the specific shape; // classes, nmed is the medium number, upar is an Double_t * array; // of the shape parameters and npar is the number of parameters.; // This prototype allows (npar = 0) to define volumes with shape; // defined only at positioning time (volumes defined in this way; // need to be positioned using TGeoManager::Node() method); ~~~. \anchor GP01bc; #### Positioned Volumes (Nodes). Geometrical modeling is a difficult task when the number of different; geometrical objects is 106-108. This is more or less the case for; detector geometries of complex experiments, where a ‘flat' CSG model; description cannot scale with the current CPU performances. This is the; reason why models like GEANT [1] introduced an additional dimension; (depth) in order to reduce the complexity of the problem. This concept; is also preserved by the ROOT modeller and introduces a pure geometrical; constraint between objects (volumes in our case) - containment. This; means in fact that any positioned volume has to be contained by another.; Now what means contained and positioned?. - We will say that a volume `contains` a point if this is inside the; shape associated to the volume. For instance, a volume having a box; shape will contain all points `P=(X,Y,Z)` verifying the conditions:; `Abs(Pi)dXi`. The points on the shape boundaries are considered as; inside the volume. The volume contains a daughter if it contains all; the points contained by the daughter.; - The definition of containment works of course only with points; defined in the local coordinate system of the considered volume.; `Positioning` a volume inside another have to introduce a; geometrical transformation between the two. If `M` defines this; transformation",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:26392,reduce,reduce,26392,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['reduce'],['reduce']
Energy Efficiency,"-+---------+-------------+----------+------------+; | \* Derived pointers only pose a hazard to copying collections. |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | **?** denotes a feature which could be utilized if available. |; +------------+------+--------+----------+-------+---------+-------------+----------+------------+. To be clear, the collection techniques above are defined as:. Shadow Stack; The mutator carefully maintains a linked list of stack roots. Reference Counting; The mutator maintains a reference count for each object and frees an object; when its count falls to zero. Mark-Sweep; When the heap is exhausted, the collector marks reachable objects starting; from the roots, then deallocates unreachable objects in a sweep phase. Copying; As reachability analysis proceeds, the collector copies objects from one heap; area to another, compacting them in the process. Copying collectors enable; highly efficient ""bump pointer"" allocation and can improve locality of; reference. Incremental; (Including generational collectors.) Incremental collectors generally have all; the properties of a copying collector (regardless of whether the mature heap; is compacting), but bring the added complexity of requiring write barriers. Threaded; Denotes a multithreaded mutator; the collector must still stop the mutator; (""stop the world"") before beginning reachability analysis. Stopping a; multithreaded mutator is a complicated problem. It generally requires highly; platform-specific code in the runtime, and the production of carefully; designed machine code at safe points. Concurrent; In this technique, the mutator and the collector run concurrently, with the; goal of eliminating pause times. In a *cooperative* collector, the mutator; further aids with collection should a pause occur, allowing collection to take; advantage of multiprocessor hosts. The ""stop the world"" problem of threaded; collectors is generally still ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:30591,efficient,efficient,30591,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['efficient'],['efficient']
Energy Efficiency,"-+--------------------------+-----------------------------------------------------------------------+; | OMPT | new barrier types added to ompt_sync_region_t enum | :none:`unclaimed` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | OMPT | async data transfers added to ompt_target_data_op_t enum | :none:`unclaimed` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | OMPT | new barrier state values added to ompt_state_t enum | :none:`unclaimed` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | OMPT | new 'emi' callbacks for external monitoring interfaces | :good:`done` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | OMPT | device tracing interface | :none:`unclaimed` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | task | 'strict' modifier for taskloop construct | :none:`unclaimed` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | task | inoutset in depend clause | :good:`done` | D97085, D118383 |; +------------------------------+--------------------------------------------------------------+--------------------------+-------------------------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst:34222,monitor,monitoring,34222,interpreter/llvm-project/clang/docs/OpenMPSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst,1,['monitor'],['monitoring']
Energy Efficiency,"---------------+----------------------------------------+; | buffer_size | ``8`` | The size in bytes of the data portion |; | | | of the trace following the header. |; +-------------------+-----------------+----------------------------------------+; | reserved | ``8`` | Reserved for future use. |; +-------------------+-----------------+----------------------------------------+. The bitfield parameter of the file header is composed of the following fields. +-------------------+----------------+-----------------------------------------+; | Field | Size (bits) | Description |; +===================+================+=========================================+; | constant_tsc | ``1`` | Whether the platform's timestamp |; | | | counter used to record ticks between |; | | | events ticks at a constant frequency |; | | | despite CPU frequency changes. |; | | | 0 == non-constant. 1 == constant. |; +-------------------+----------------+-----------------------------------------+; | nonstop_tsc | ``1`` | Whether the tsc continues to count |; | | | despite whether the CPU is in a low |; | | | power state. 0 == stop. 1 == non-stop. |; +-------------------+----------------+-----------------------------------------+; | reserved | ``30`` | Not meaningful. |; +-------------------+----------------+-----------------------------------------+. Data Section; ============. Following the header in a trace is a data section with size matching the; buffer_size field in the header. The data section is a stream of elements of different types. There are a few categories of data in the sequence. - ``Function Records``: Function Records contain the timing of entry into and; exit from function execution. Function Records have 8 bytes each. - ``Metadata Records``: Metadata records serve many purposes. Mostly, they; capture information that may be too costly to record for each function, but; that is required to contextualize the fine-grained timings. They also are used; as markers for user-defined Event ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:2947,power,power,2947,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,1,['power'],['power']
Energy Efficiency,"----------------+-----------------------------------------------------------------------+; | loop | collapse imperfectly nested loop | :good:`done` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | loop | collapse non-rectangular nested loop | :good:`done` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | loop | C++ range-base for loop | :good:`done` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | loop | clause: if for SIMD directives | :good:`done` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | loop | inclusive scan (matching C++17 PSTL) | :good:`done` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | memory management | memory allocators | :good:`done` | r341687,r357929 |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | memory management | allocate directive and allocate clause | :good:`done` | r355614,r335952 |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | OMPD | OMPD interfaces | :good:`done` | https://reviews.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst:6039,allocate,allocate,6039,interpreter/llvm-project/clang/docs/OpenMPSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst,2,['allocate'],['allocate']
Energy Efficiency,"-------------------------------+; | ``[41 x i32]`` | Array of 41 32-bit integer values. |; +------------------+--------------------------------------+; | ``[4 x i8]`` | Array of 4 8-bit integer values. |; +------------------+--------------------------------------+. Here are some examples of multidimensional arrays:. +-----------------------------+----------------------------------------------------------+; | ``[3 x [4 x i32]]`` | 3x4 array of 32-bit integer values. |; +-----------------------------+----------------------------------------------------------+; | ``[12 x [10 x float]]`` | 12x10 array of single precision floating-point values. |; +-----------------------------+----------------------------------------------------------+; | ``[2 x [3 x [4 x i16]]]`` | 2x3x4 array of 16-bit integer values. |; +-----------------------------+----------------------------------------------------------+. There is no restriction on indexing beyond the end of the array implied; by a static type (though there are restrictions on indexing beyond the; bounds of an allocated object in some cases). This means that; single-dimension 'variable sized array' addressing can be implemented in; LLVM with a zero length array type. An implementation of 'pascal style; arrays' in LLVM could use the type ""``{ i32, [0 x float]}``"", for; example. .. _t_struct:. Structure Type; """""""""""""""""""""""""""". :Overview:. The structure type is used to represent a collection of data members; together in memory. The elements of a structure may be any type that has; a size. Structures in memory are accessed using '``load``' and '``store``' by; getting a pointer to a field with the '``getelementptr``' instruction.; Structures in registers are accessed using the '``extractvalue``' and; '``insertvalue``' instructions. Structures may optionally be ""packed"" structures, which indicate that; the alignment of the struct is one byte, and that there is no padding; between the elements. In non-packed structs, padding between field",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:180910,allocate,allocated,180910,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | loop | Loop tiling transformation | :good:`done` | D76342 |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | loop | Loop unrolling transformation | :good:`done` | D99459 |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | loop | 'reproducible'/'unconstrained' modifiers in 'order' clause | :part:`partial` | D127855 |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | memory management | alignment for allocate directive and clause | :good:`done` | D115683 |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | memory management | new memory management routines | :none:`unclaimed` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | memory management | changes to omp_alloctrait_key enum | :none:`unclaimed` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; | memory model | seq_cst clause on flush construct | :none:`unclaimed` | |; +------------------------------+--------------------------------------------------------------+--------------------------+-,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst:27879,allocate,allocate,27879,interpreter/llvm-project/clang/docs/OpenMPSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst,1,['allocate'],['allocate']
Energy Efficiency,"----------------------------------------------------------------===//. WebAssemblyRegStackify could use AliasAnalysis to reorder loads and stores more; aggressively. //===---------------------------------------------------------------------===//. WebAssemblyRegStackify is currently a greedy algorithm. This means that, for; example, a binary operator will stackify with its user before its operands.; However, if moving the binary operator to its user moves it to a place where; its operands can't be moved to, it would be better to leave it in place, or; perhaps move it up, so that it can stackify its operands. A binary operator; has two operands and one result, so in such cases there could be a net win by; preferring the operands. //===---------------------------------------------------------------------===//. Instruction ordering has a significant influence on register stackification and; coloring. Consider experimenting with the MachineScheduler (enable via; enableMachineScheduler) and determine if it can be configured to schedule; instructions advantageously for this purpose. //===---------------------------------------------------------------------===//. WebAssemblyRegStackify currently assumes that the stack must be empty after; an instruction with no return values, however wasm doesn't actually require; this. WebAssemblyRegStackify could be extended, or possibly rewritten, to take; full advantage of what WebAssembly permits. //===---------------------------------------------------------------------===//. Add support for mergeable sections in the Wasm writer, such as for strings and; floating-point constants. //===---------------------------------------------------------------------===//. The function @dynamic_alloca_redzone in test/CodeGen/WebAssembly/userstack.ll; ends up with a local.tee in its prolog which has an unused result, requiring; an extra drop:. global.get $push8=, 0; local.tee $push9=, 1, $pop8; drop $pop9; [...]. The prologue code initially thinks it",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt:6092,schedul,schedule,6092,interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt,1,['schedul'],['schedule']
Energy Efficiency,"-------------------------------------------------------------===//. To time GCC preprocessing speed without output, use:; ""time gcc -MM file""; This is similar to -Eonly. //===---------------------------------------------------------------------===//. C++ Template Instantiation benchmark:; http://users.rcn.com/abrahams/instantiation_speed/index.html. //===---------------------------------------------------------------------===//. TODO: File Manager Speedup:. We currently do a lot of stat'ing for files that don't exist, particularly; when lots of -I paths exist (e.g. see the <iostream> example, check for; failures in stat in FileManager::getFile). It would be far better to make; the following changes:; 1. FileEntry contains a sys::Path instead of a std::string for Name.; 2. sys::Path contains timestamp and size, lazily computed. Eliminate from; FileEntry.; 3. File UIDs are created on request, not when files are opened.; These changes make it possible to efficiently have FileEntry objects for; files that exist on the file system, but have not been used yet. Once this is done:; 1. DirectoryEntry gets a boolean value ""has read entries"". When false, not; all entries in the directory are in the file mgr, when true, they are.; 2. Instead of stat'ing the file in FileManager::getFile, check to see if; the dir has been read. If so, fail immediately, if not, read the dir,; then retry.; 3. Reading the dir uses the getdirentries syscall, creating a FileEntry; for all files found. //===---------------------------------------------------------------------===//; // Specifying targets: -triple and -arch; //===---------------------------------------------------------------------===//. The clang supports ""-triple"" and ""-arch"" options. At most one -triple and one; -arch option may be specified. Both are optional. The ""selection of target"" behavior is defined as follows:. (1) If the user does not specify -triple, we default to the host triple.; (2) If the user specifies a -arch, that ove",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/NOTES.txt:1158,efficient,efficiently,1158,interpreter/llvm-project/clang/NOTES.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/NOTES.txt,1,['efficient'],['efficiently']
Energy Efficiency,"--------------------------------------------------------===//. We can definitely do a better job on BB placements to eliminate some branches.; It's very common to see llvm generated assembly code that looks like this:. LBB3:; ...; LBB4:; ...; beq LBB3; b LBB2. If BB4 is the only predecessor of BB3, then we can emit BB3 after BB4. We can; then eliminate beq and turn the unconditional branch to LBB2 to a bne. See McCat/18-imp/ComputeBoundingBoxes for an example. //===---------------------------------------------------------------------===//. Pre-/post- indexed load / stores:. 1) We should not make the pre/post- indexed load/store transform if the base ptr; is guaranteed to be live beyond the load/store. This can happen if the base; ptr is live out of the block we are performing the optimization. e.g. mov r1, r2; ldr r3, [r1], #4; ... vs. ldr r3, [r2]; add r1, r2, #4; ... In most cases, this is just a wasted optimization. However, sometimes it can; negatively impact the performance because two-address code is more restrictive; when it comes to scheduling. Unfortunately, liveout information is currently unavailable during DAG combine; time. 2) Consider spliting a indexed load / store into a pair of add/sub + load/store; to solve #1 (in TwoAddressInstructionPass.cpp). 3) Enhance LSR to generate more opportunities for indexed ops. 4) Once we added support for multiple result patterns, write indexed loads; patterns instead of C++ instruction selection code. 5) Use VLDM / VSTM to emulate indexed FP load / store. //===---------------------------------------------------------------------===//. Implement support for some more tricky ways to materialize immediates. For; example, to get 0xffff8000, we can use:. mov r9, #&3f8000; sub r9, r9, #&400000. //===---------------------------------------------------------------------===//. We sometimes generate multiple add / sub instructions to update sp in prologue; and epilogue if the inc / dec value is too large to fit in a single imm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:8704,schedul,scheduling,8704,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,1,['schedul'],['scheduling']
Energy Efficiency,"---------------------------------------------===//; The save/restore sequence for CR in prolog/epilog is terrible:; - Each CR subreg is saved individually, rather than doing one save as a unit.; - On Darwin, the save is done after the decrement of SP, which means the offset; from SP of the save slot can be too big for a store instruction, which means we; need an additional register (currently hacked in 96015+96020; the solution there; is correct, but poor).; - On SVR4 the same thing can happen, and I don't think saving before the SP; decrement is safe on that target, as there is no red zone. This is currently; broken AFAIK, although it's not a target I can exercise.; The following demonstrates the problem:; extern void bar(char *p);; void foo() {; char x[100000];; bar(x);; __asm__("""" ::: ""cr2"");; }. //===-------------------------------------------------------------------------===; Naming convention for instruction formats is very haphazard.; We have agreed on a naming scheme as follows:. <INST_form>{_<OP_type><OP_len>}+. Where:; INST_form is the instruction format (X-form, etc.); OP_type is the operand type - one of OPC (opcode), RD (register destination),; RS (register source),; RDp (destination register pair),; RSp (source register pair), IM (immediate),; XO (extended opcode); OP_len is the length of the operand in bits. VSX register operands would be of length 6 (split across two fields),; condition register fields of length 3.; We would not need denote reserved fields in names of instruction formats. //===----------------------------------------------------------------------===//. Instruction fusion was introduced in ISA 2.06 and more opportunities added in; ISA 2.07. LLVM needs to add infrastructure to recognize fusion opportunities; and force instruction pairs to be scheduled together. -----------------------------------------------------------------------------. More general handling of any_extend and zero_extend:. See https://reviews.llvm.org/D24924#555306; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt:14856,schedul,scheduled,14856,interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,1,['schedul'],['scheduled']
Energy Efficiency,"--------------------------------------------===//. Better codegen for vector_shuffles like this { x, 0, 0, 0 } or { x, 0, x, 0}.; Perhaps use pxor / xorp* to clear a XMM register first?. //===---------------------------------------------------------------------===//. External test Nurbs exposed some problems. Look for; __ZN15Nurbs_SSE_Cubic17TessellateSurfaceE, bb cond_next140. This is what icc; emits:. movaps (%edx), %xmm2 #59.21; movaps (%edx), %xmm5 #60.21; movaps (%edx), %xmm4 #61.21; movaps (%edx), %xmm3 #62.21; movl 40(%ecx), %ebp #69.49; shufps $0, %xmm2, %xmm5 #60.21; movl 100(%esp), %ebx #69.20; movl (%ebx), %edi #69.20; imull %ebp, %edi #69.49; addl (%eax), %edi #70.33; shufps $85, %xmm2, %xmm4 #61.21; shufps $170, %xmm2, %xmm3 #62.21; shufps $255, %xmm2, %xmm2 #63.21; lea (%ebp,%ebp,2), %ebx #69.49; negl %ebx #69.49; lea -3(%edi,%ebx), %ebx #70.33; shll $4, %ebx #68.37; addl 32(%ecx), %ebx #68.37; testb $15, %bl #91.13; jne L_B1.24 # Prob 5% #91.13. This is the llvm code after instruction scheduling:. cond_next140 (0xa910740, LLVM BB @0xa90beb0):; 	%reg1078 = MOV32ri -3; 	%reg1079 = ADD32rm %reg1078, %reg1068, 1, %noreg, 0; 	%reg1037 = MOV32rm %reg1024, 1, %noreg, 40; 	%reg1080 = IMUL32rr %reg1079, %reg1037; 	%reg1081 = MOV32rm %reg1058, 1, %noreg, 0; 	%reg1038 = LEA32r %reg1081, 1, %reg1080, -3; 	%reg1036 = MOV32rm %reg1024, 1, %noreg, 32; 	%reg1082 = SHL32ri %reg1038, 4; 	%reg1039 = ADD32rr %reg1036, %reg1082; 	%reg1083 = MOVAPSrm %reg1059, 1, %noreg, 0; 	%reg1034 = SHUFPSrr %reg1083, %reg1083, 170; 	%reg1032 = SHUFPSrr %reg1083, %reg1083, 0; 	%reg1035 = SHUFPSrr %reg1083, %reg1083, 255; 	%reg1033 = SHUFPSrr %reg1083, %reg1083, 85; 	%reg1040 = MOV32rr %reg1039; 	%reg1084 = AND32ri8 %reg1039, 15; 	CMP32ri8 %reg1084, 0; 	JE mbb<cond_next204,0xa914d30>. Still ok. After register allocation:. cond_next140 (0xa910740, LLVM BB @0xa90beb0):; 	%eax = MOV32ri -3; 	%edx = MOV32rm %stack.3, 1, %noreg, 0; 	ADD32rm %eax<def&use>, %edx, 1, %noreg, 0; 	%edx = MOV32rm %s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:4445,schedul,scheduling,4445,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,1,['schedul'],['scheduling']
Energy Efficiency,"-----------------------------------------. Combine instructions to form fewer, simple instructions. This pass does not; modify the CFG. This pass is where algebraic simplification happens. This pass combines things like:. .. code-block:: llvm. %Y = add i32 %X, 1; %Z = add i32 %Y, 1. into:. .. code-block:: llvm. %Z = add i32 %X, 2. This is a simple worklist driven algorithm. This pass guarantees that the following canonicalizations are performed on the; program:. #. If a binary operator has a constant operand, it is moved to the right-hand; side.; #. Bitwise operators with constant operands are always grouped so that shifts; are performed first, then ``or``\ s, then ``and``\ s, then ``xor``\ s.; #. Compare instructions are converted from ``<``, ``>``, ``≤``, or ``≥`` to; ``=`` or ``≠`` if possible.; #. All ``cmp`` instructions on boolean values are replaced with logical; operations.; #. ``add X, X`` is represented as ``mul X, 2`` ⇒ ``shl X, 1``; #. Multiplies with a constant power-of-two argument are transformed into; shifts.; #. … etc. This pass can also simplify calls to specific well-known function calls (e.g.; runtime library functions). For example, a call ``exit(3)`` that occurs within; the ``main()`` function can be transformed into simply ``return 3``. Whether or; not library calls are simplified is controlled by the; :ref:`-function-attrs <passes-function-attrs>` pass and LLVM's knowledge of; library calls on different targets. .. _passes-aggressive-instcombine:. ``aggressive-instcombine``: Combine expression patterns; --------------------------------------------------------. Combine expression patterns to form expressions with fewer, simple instructions. For example, this pass reduce width of expressions post-dominated by TruncInst; into smaller width when applicable. It differs from instcombine pass in that it can modify CFG and contains pattern; optimization that requires higher complexity than the O(1), thus, it should run fewer; times than instcombine pa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:20336,power,power-of-two,20336,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['power'],['power-of-two']
Energy Efficiency,"---------------------------------------. **Abstract**. ROOT is a software framework for data analysis and I/O: a powerful tool to cope; with the demanding tasks typical of state of the art scientific data analysis.; Among its prominent features are an advanced graphical user; interface, ideal for interactive analysis, an interpreter for the C++; programming language, for rapid and efficient prototyping and a; persistency mechanism for C++ objects, used also to write every year; petabytes of data recorded by the Large Hadron Collider experiments.; This introductory guide illustrates the main features of ROOT which are; relevant for the typical problems of data analysis: input and plotting of data; from measurements and fitting of analytical functions. *Original Authors*; - D. Piparo; - G. Quast; - M. Zeise. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/abstract.md:113,power,powerful,113,documentation/primer/abstract.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/abstract.md,2,"['efficient', 'power']","['efficient', 'powerful']"
Energy Efficiency,"------------------------------------. As unbelievable as it may sound, Clang does crash from time to time.; Generally, this only occurs to those living on the `bleeding; edge <https://llvm.org/releases/download.html#svn>`_. Clang goes to great; lengths to assist you in filing a bug report. Specifically, Clang; generates preprocessed source file(s) and associated run script(s) upon; a crash. These files should be attached to a bug report to ease; reproducibility of the failure. Below are the command line options to; control the crash diagnostics. .. option:: -fcrash-diagnostics=<val>. Valid values are:. * ``off`` (Disable auto-generation of preprocessed source files during a clang crash.); * ``compiler`` (Generate diagnostics for compiler crashes (default)); * ``all`` (Generate diagnostics for all tools which support it). .. option:: -fno-crash-diagnostics. Disable auto-generation of preprocessed source files during a clang crash. The -fno-crash-diagnostics flag can be helpful for speeding the process; of generating a delta reduced test case. .. option:: -fcrash-diagnostics-dir=<dir>. Specify where to write the crash diagnostics files; defaults to the; usual location for temporary files. .. envvar:: CLANG_CRASH_DIAGNOSTICS_DIR=<dir>. Like ``-fcrash-diagnostics-dir=<dir>``, specifies where to write the; crash diagnostics files, but with lower precedence than the option. Clang is also capable of generating preprocessed source file(s) and associated; run script(s) even without a crash. This is specially useful when trying to; generate a reproducer for warnings or errors while using modules. .. option:: -gen-reproducer. Generates preprocessed source files, a reproducer script and if relevant, a; cache containing: built module pcm's and all headers needed to rebuild the; same modules. .. _rpass:. Options to Emit Optimization Reports; ------------------------------------. Optimization reports trace, at a high-level, all the major decisions; done by compiler transformations",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:22712,reduce,reduced,22712,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['reduce'],['reduced']
Energy Efficiency,"-------------------------. If you find that a bug crashes in the optimizer, compile your test-case to a; ``.bc`` file by passing ""``-emit-llvm -O1 -Xclang -disable-llvm-passes -c -o; foo.bc``"". The ``-O1`` is important because ``-O0`` adds the ``optnone``; function attribute to all functions and many passes don't run on ``optnone``; functions. Then run:. .. code-block:: bash. opt -O3 foo.bc -disable-output. If this doesn't crash, please follow the instructions for a :ref:`front-end; bug <frontend-crash>`. If this does crash, then you should be able to debug this with the following; :doc:`bugpoint <Bugpoint>` command:. .. code-block:: bash. bugpoint foo.bc -O3. Run this, then file a bug with the instructions and reduced .bc; files that bugpoint emits. If bugpoint doesn't reproduce the crash, ``llvm-reduce`` is an alternative; way to reduce LLVM IR. Create a script that repros the crash and run:. .. code-block:: bash. llvm-reduce --test=path/to/script foo.bc. which should produce reduced IR that reproduces the crash. Be warned the; ``llvm-reduce`` is still fairly immature and may crash. If none of the above work, you can get the IR before a crash by running the; ``opt`` command with the ``--print-before-all --print-module-scope`` flags to; dump the IR before every pass. Be warned that this is very verbose. .. _backend-crash:. Backend code generator bugs; ---------------------------. If you find a bug that crashes clang in the code generator, compile your; source file to a .bc file by passing ""``-emit-llvm -c -o foo.bc``"" to; clang (in addition to the options you already pass). Once your have; foo.bc, one of the following commands should fail:. #. ``llc foo.bc``; #. ``llc foo.bc -relocation-model=pic``; #. ``llc foo.bc -relocation-model=static``. If none of these crash, please follow the instructions for a :ref:`front-end; bug<frontend-crash>`. If one of these do crash, you should be able to reduce; this with one of the following :doc:`bugpoint <Bugpoint>` command lines",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:4527,reduce,reduced,4527,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduced']
Energy Efficiency,"------------------------===//. We need a way to teach tblgen that some operands of an intrinsic are required to; be constants. The verifier should enforce this constraint. //===----------------------------------------------------------------------===//. We currently codegen SCALAR_TO_VECTOR as a store of the scalar to a 16-byte; aligned stack slot, followed by a load/vperm. We should probably just store it; to a scalar stack slot, then use lvsl/vperm to load it. If the value is already; in memory this is a big win. //===----------------------------------------------------------------------===//. extract_vector_elt of an arbitrary constant vector can be done with the ; following instructions:. vTemp = vec_splat(v0,2); // 2 is the element the src is in.; vec_ste(&destloc,0,vTemp);. We can do an arbitrary non-constant value by using lvsr/perm/ste. //===----------------------------------------------------------------------===//. If we want to tie instruction selection into the scheduler, we can do some; constant formation with different instructions. For example, we can generate; ""vsplti -1"" with ""vcmpequw R,R"" and 1,1,1,1 with ""vsubcuw R,R"", and 0,0,0,0 with; ""vsplti 0"" or ""vxor"", each of which use different execution units, thus could; help scheduling. This is probably only reasonable for a post-pass scheduler. //===----------------------------------------------------------------------===//. For this function:. void test(vector float *A, vector float *B) {; vector float C = (vector float)vec_cmpeq(*A, *B);; if (!vec_any_eq(*A, *B)); *B = (vector float){0,0,0,0};; *A = C;; }. we get the following basic block:. 	...; lvx v2, 0, r4; lvx v3, 0, r3; vcmpeqfp v4, v3, v2; vcmpeqfp. v2, v3, v2; bne cr6, LBB1_2 ; cond_next. The vcmpeqfp/vcmpeqfp. instructions currently cannot be merged when the; vcmpeqfp. result is used by a branch. This can be improved. //===----------------------------------------------------------------------===//. The code generated for this is truly awefu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt:2613,schedul,scheduler,2613,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,1,['schedul'],['scheduler']
Energy Efficiency,"---------------------. Horizontal reductions of vectors can be expressed using the following; intrinsics. Each one takes a vector operand as an input and applies its; respective operation across all elements of the vector, returning a single; scalar result of the same element type. .. _int_vector_reduce_add:. '``llvm.vector.reduce.add.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.add.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.add.*``' intrinsics do an integer ``ADD``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fadd:. '``llvm.vector.reduce.fadd.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fadd.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fadd.*``' intrinsics do a floating-point; ``ADD`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. Otherwise; the reduction will be *sequential*, thus implying that the operation respects; the associativity of a scalarized reduction. That is, the reduction begins with; the start value and performs an fadd operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fadd(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result + input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:651071,reduce,reduce,651071,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"---------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there can be different types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optimized out:; in IR the location would be assigned ``undef`` by a debug intrinsic, and in MIR; the equivalent location is used. After MIR locations are assigned to each variable, machine pseudo-instructions; corresponding to each ``llvm.dbg.value`` intrinsic are inserted. There are two; forms of this type of instruction. The first form, ``DBG_VALUE``, appears thus:. .. code-block:: text. DBG_VALUE %1, $noreg, !123, !DIExpression(). And has the following operands:; * The first operand can record the variable location as a register,; a frame index, an immediate, or the base address register if the original; debug intrinsic referred to memory. ``$noreg`` indicates the variable; loc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:26588,allocate,allocated,26588,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['allocate'],['allocated']
Energy Efficiency,"---------------------===//; // LVDoubleMap to return optional<ValueType> instead of null pointer.; //===----------------------------------------------------------------------===//; https://reviews.llvm.org/D125783#inline-1294164. The more idiomatic LLVM way to handle this would be to have 'find '; return Optional<ValueType>. //===----------------------------------------------------------------------===//; // Pass references instead of pointers (Comparison functions).; //===----------------------------------------------------------------------===//; https://reviews.llvm.org/D125782#inline-1293920. In the comparison functions, pass references instead of pointers (when; pointers cannot be null). //===----------------------------------------------------------------------===//; // Use StringMap where possible.; //===----------------------------------------------------------------------===//; https://reviews.llvm.org/D125783#inline-1294211. LLVM has a StringMap class that is advertised as more efficient than; std::map<std::string, ValueType>. Mainly it does fewer allocations; because the key is not a std::string. Replace the use of std::map<std::string, ValueType> with String Map.; One specific case is the LVSymbolNames definitions. //===----------------------------------------------------------------------===//; // Calculate unique offset for CodeView elements.; //===----------------------------------------------------------------------===//; In order to have the same logical functionality as the ELF Reader, such; as:. - find scopes contribution to debug info; - sort by its physical location. The logical elements must have an unique offset (similar like the DWARF; DIE offset). //===----------------------------------------------------------------------===//; // Move 'initializeFileAndStringTables' to the COFF Library.; //===----------------------------------------------------------------------===//; There is some code in the CodeView reader that was extracted/adapted; fro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt:4613,efficient,efficient,4613,interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt,1,['efficient'],['efficient']
Energy Efficiency,"-------------------. Any memory access must be done through a pointer value associated with; an address range of the memory access, otherwise the behavior is; undefined. Pointer values are associated with address ranges according; to the following rules:. - A pointer value is associated with the addresses associated with any; value it is *based* on.; - An address of a global variable is associated with the address range; of the variable's storage.; - The result value of an allocation instruction is associated with the; address range of the allocated storage.; - A null pointer in the default address-space is associated with no; address.; - An :ref:`undef value <undefvalues>` in *any* address-space is; associated with no address.; - An integer constant other than zero or a pointer value returned from; a function not defined within LLVM may be associated with address; ranges allocated through mechanisms other than those provided by; LLVM. Such ranges shall not overlap with any ranges of addresses; allocated by mechanisms provided by LLVM. A pointer value is *based* on another pointer value according to the; following rules:. - A pointer value formed from a scalar ``getelementptr`` operation is *based* on; the pointer-typed operand of the ``getelementptr``.; - The pointer in lane *l* of the result of a vector ``getelementptr`` operation; is *based* on the pointer in lane *l* of the vector-of-pointers-typed operand; of the ``getelementptr``.; - The result value of a ``bitcast`` is *based* on the operand of the; ``bitcast``.; - A pointer value formed by an ``inttoptr`` is *based* on all pointer; values that contribute (directly or indirectly) to the computation of; the pointer's value.; - The ""*based* on"" relationship is transitive. Note that this definition of *""based""* is intentionally similar to the; definition of *""based""* in C99, though it is slightly weaker. LLVM IR does not associate types with memory. The result type of a; ``load`` merely indicates the size and al",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:142372,allocate,allocated,142372,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"-------------------; When a function with ""``aarch64_pstate_sm_enabled``"" calls a function that is not; streaming compatible, the compiler has to insert a SMSTOP before the call and; insert a SMSTOP after the call. If the function that is called is an intrinsic with no side-effects which in; turn is lowered to a function call (e.g. ``@llvm.cos()``), then the call to; ``@llvm.cos()`` is not part of any Chain; it can be scheduled freely. Lowering of a Callsite creates a small chain of nodes which:. - starts a call sequence. - copies input values from virtual registers to physical registers specified by; the ABI. - executes a branch-and-link. - stops the call sequence. - copies the output values from their physical registers to virtual registers. When the callsite's Chain is not used, only the result value from the chained; sequence is used, but the Chain itself is discarded. The ``SMSTART`` and ``SMSTOP`` ISD nodes return a Chain, but no real; values, so when the ``SMSTART/SMSTOP`` nodes are part of a Chain that isn't; used, these nodes are not considered for scheduling and are; removed from the DAG. In order to prevent these nodes; from being removed, we need a way to ensure the results from the; ``CopyFromReg`` can only be **used after** the ``SMSTART/SMSTOP`` has been; executed. We can use a CopyToReg -> CopyFromReg sequence for this, which moves the; value to/from a virtual register and chains these nodes with the; SMSTART/SMSTOP to make them part of the expression that calculates; the result value. The resulting COPY nodes are removed by the register; allocator. The example below shows how this is used in a DAG that does not link; together the result by a Chain, but rather by a value:. .. code-block:: none. t0: ch,glue = AArch64ISD::SMSTOP ...; t1: ch,glue = ISD::CALL ....; t2: res,ch,glue = CopyFromReg t1, ...; t3: ch,glue = AArch64ISD::SMSTART t2:1, .... <- this is now part of the expression that returns the result value.; t4: ch = CopyToReg t3, Register:f64 %v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst:9825,schedul,scheduling,9825,interpreter/llvm-project/llvm/docs/AArch64SME.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst,1,['schedul'],['scheduling']
Energy Efficiency,"---------------===//. We compile vector multiply-by-constant into poor code:. define <4 x i32> @f(<4 x i32> %i) nounwind {; 	%A = mul <4 x i32> %i, < i32 10, i32 10, i32 10, i32 10 >; 	ret <4 x i32> %A; }. On targets without SSE4.1, this compiles into:. LCPI1_0:					## <4 x i32>; 	.long	10; 	.long	10; 	.long	10; 	.long	10; 	.text; 	.align	4,0x90; 	.globl	_f; _f:; 	pshufd	$3, %xmm0, %xmm1; 	movd	%xmm1, %eax; 	imull	LCPI1_0+12, %eax; 	movd	%eax, %xmm1; 	pshufd	$1, %xmm0, %xmm2; 	movd	%xmm2, %eax; 	imull	LCPI1_0+4, %eax; 	movd	%eax, %xmm2; 	punpckldq	%xmm1, %xmm2; 	movd	%xmm0, %eax; 	imull	LCPI1_0, %eax; 	movd	%eax, %xmm1; 	movhlps	%xmm0, %xmm0; 	movd	%xmm0, %eax; 	imull	LCPI1_0+8, %eax; 	movd	%eax, %xmm0; 	punpckldq	%xmm0, %xmm1; 	movaps	%xmm1, %xmm0; 	punpckldq	%xmm2, %xmm0; 	ret. It would be better to synthesize integer vector multiplication by constants; using shifts and adds, pslld and paddd here. And even on targets with SSE4.1,; simple cases such as multiplication by powers of two would be better as; vector shifts than as multiplications. //===---------------------------------------------------------------------===//. We compile this:. __m128i; foo2 (char x); {; return _mm_set_epi8 (1, 0, 0, 0, 0, 0, 0, 0, 0, x, 0, 1, 0, 0, 0, 0);; }. into:; 	movl	$1, %eax; 	xorps	%xmm0, %xmm0; 	pinsrw	$2, %eax, %xmm0; 	movzbl	4(%esp), %eax; 	pinsrw	$3, %eax, %xmm0; 	movl	$256, %eax; 	pinsrw	$7, %eax, %xmm0; 	ret. gcc-4.2:; 	subl	$12, %esp; 	movzbl	16(%esp), %eax; 	movdqa	LC0, %xmm0; 	pinsrw	$3, %eax, %xmm0; 	addl	$12, %esp; 	ret; 	.const; 	.align 4; LC0:; 	.word	0; 	.word	0; 	.word	1; 	.word	0; 	.word	0; 	.word	0; 	.word	0; 	.word	256. With SSE4, it should be; movdqa .LC0(%rip), %xmm0; pinsrb $6, %edi, %xmm0. //===---------------------------------------------------------------------===//. We should transform a shuffle of two vectors of constants into a single vector; of constants. Also, insertelement of a constant into a vector of constants; should also result in a vector of con",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:17549,power,powers,17549,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,1,['power'],['powers']
Energy Efficiency,"------------===//. Reimplement 'select' in terms of 'SEL'. * We would really like to support UXTAB16, but we need to prove that the; add doesn't need to overflow between the two 16-bit chunks. * Implement pre/post increment support. (e.g. PR935); * Implement smarter constant generation for binops with large immediates. A few ARMv6T2 ops should be pattern matched: BFI, SBFX, and UBFX. Interesting optimization for PIC codegen on arm-linux:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=43129. //===---------------------------------------------------------------------===//. Crazy idea: Consider code that uses lots of 8-bit or 16-bit values. By the; time regalloc happens, these values are now in a 32-bit register, usually with; the top-bits known to be sign or zero extended. If spilled, we should be able; to spill these to a 8-bit or 16-bit stack slot, zero or sign extending as part; of the reload. Doing this reduces the size of the stack frame (important for thumb etc), and; also increases the likelihood that we will be able to reload multiple values; from the stack with a single load. //===---------------------------------------------------------------------===//. The constant island pass is in good shape. Some cleanups might be desirable,; but there is unlikely to be much improvement in the generated code. 1. There may be some advantage to trying to be smarter about the initial; placement, rather than putting everything at the end. 2. There might be some compile-time efficiency to be had by representing; consecutive islands as a single block rather than multiple blocks. 3. Use a priority queue to sort constant pool users in inverse order of; position so we always process the one closed to the end of functions; first. This may simply CreateNewWater. //===---------------------------------------------------------------------===//. Eliminate copysign custom expansion. We are still generating crappy code with; default expansion + if-conversion. //===-------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:1097,reduce,reduces,1097,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,1,['reduce'],['reduces']
Energy Efficiency,"----------===//. //===---------------------------------------------------------------------===//. Some targets (e.g. athlons) prefer freep to fstp ST(0):; http://gcc.gnu.org/ml/gcc-patches/2004-04/msg00659.html. //===---------------------------------------------------------------------===//. This should use fiadd on chips where it is profitable:; double foo(double P, int *I) { return P+*I; }. We have fiadd patterns now but the followings have the same cost and; complexity. We need a way to specify the later is more profitable. def FpADD32m : FpI<(ops RFP:$dst, RFP:$src1, f32mem:$src2), OneArgFPRW,; [(set RFP:$dst, (fadd RFP:$src1,; (extloadf64f32 addr:$src2)))]>;; // ST(0) = ST(0) + [mem32]. def FpIADD32m : FpI<(ops RFP:$dst, RFP:$src1, i32mem:$src2), OneArgFPRW,; [(set RFP:$dst, (fadd RFP:$src1,; (X86fild addr:$src2, i32)))]>;; // ST(0) = ST(0) + [mem32int]. //===---------------------------------------------------------------------===//. The FP stackifier should handle simple permutates to reduce number of shuffle; instructions, e.g. turning:. fld P	->		fld Q; fld Q			fld P; fxch. or:. fxch	->		fucomi; fucomi			jl X; jg X. Ideas:; http://gcc.gnu.org/ml/gcc-patches/2004-11/msg02410.html. //===---------------------------------------------------------------------===//. Add a target specific hook to DAG combiner to handle SINT_TO_FP and; FP_TO_SINT when the source operand is already in memory. //===---------------------------------------------------------------------===//. Open code rint,floor,ceil,trunc:; http://gcc.gnu.org/ml/gcc-patches/2004-08/msg02006.html; http://gcc.gnu.org/ml/gcc-patches/2004-08/msg02011.html. Opencode the sincos[f] libcall. //===---------------------------------------------------------------------===//. None of the FPStack instructions are handled in; X86RegisterInfo::foldMemoryOperand, which prevents the spiller from; folding spill code into the instructions. //===---------------------------------------------------------------------===//. Cur",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-FPStack.txt:1212,reduce,reduce,1212,interpreter/llvm-project/llvm/lib/Target/X86/README-FPStack.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-FPStack.txt,1,['reduce'],['reduce']
Energy Efficiency,"--------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6375,reduce,reduces,6375,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,1,['reduce'],['reduces']
Energy Efficiency,"-. There are a variety of sequential containers available for you, based on your; needs. Pick the first in this section that will do what you want. .. _dss_arrayref:. llvm/ADT/ArrayRef.h; ^^^^^^^^^^^^^^^^^^^. The ``llvm::ArrayRef`` class is the preferred class to use in an interface that; accepts a sequential list of elements in memory and just reads from them. By; taking an ``ArrayRef``, the API can be passed a fixed size array, an; ``std::vector``, an ``llvm::SmallVector`` and anything else that is contiguous; in memory. .. _dss_fixedarrays:. Fixed Size Arrays; ^^^^^^^^^^^^^^^^^. Fixed size arrays are very simple and very fast. They are good if you know; exactly how many elements you have, or you have a (low) upper bound on how many; you have. .. _dss_heaparrays:. Heap Allocated Arrays; ^^^^^^^^^^^^^^^^^^^^^. Heap allocated arrays (``new[]`` + ``delete[]``) are also simple. They are good; if the number of elements is variable, if you know how many elements you will; need before the array is allocated, and if the array is usually large (if not,; consider a :ref:`SmallVector <dss_smallvector>`). The cost of a heap allocated; array is the cost of the new/delete (aka malloc/free). Also note that if you; are allocating an array of a type with a constructor, the constructor and; destructors will be run for every element in the array (re-sizable vectors only; construct those elements actually used). .. _dss_tinyptrvector:. llvm/ADT/TinyPtrVector.h; ^^^^^^^^^^^^^^^^^^^^^^^^. ``TinyPtrVector<Type>`` is a highly specialized collection class that is; optimized to avoid allocation in the case when a vector has zero or one; elements. It has two major restrictions: 1) it can only hold values of pointer; type, and 2) it cannot hold a null pointer. Since this container is highly specialized, it is rarely used. .. _dss_smallvector:. llvm/ADT/SmallVector.h; ^^^^^^^^^^^^^^^^^^^^^^. ``SmallVector<Type, N>`` is a simple class that looks and smells just like; ``vector<Type>``: it suppo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:58530,allocate,allocated,58530,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocated']
Energy Efficiency,"-block:: c++. std::set<Instruction*> worklist;; // or better yet, SmallPtrSet<Instruction*, 64> worklist;. for (inst_iterator I = inst_begin(F), E = inst_end(F); I != E; ++I); worklist.insert(&*I);. The STL set ``worklist`` would now contain all instructions in the ``Function``; pointed to by F. .. _iterate_convert:. Turning an iterator into a class pointer (and vice-versa); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Sometimes, it'll be useful to grab a reference (or pointer) to a class instance; when all you've got at hand is an iterator. Well, extracting a reference or a; pointer from an iterator is very straight-forward. Assuming that ``i`` is a; ``BasicBlock::iterator`` and ``j`` is a ``BasicBlock::const_iterator``:. .. code-block:: c++. Instruction& inst = *i; // Grab reference to instruction reference; Instruction* pinst = &*i; // Grab pointer to instruction reference; const Instruction& inst = *j;. It's also possible to turn a class pointer into the corresponding iterator, and; this is a constant time operation (very efficient). The following code snippet; illustrates use of the conversion constructors provided by LLVM iterators. By; using these, you can explicitly grab the iterator of something without actually; obtaining it via iteration over some structure:. .. code-block:: c++. void printNextInstruction(Instruction* inst) {; BasicBlock::iterator it(inst);; ++it; // After this line, it refers to the instruction after *inst; if (it != inst->getParent()->end()) errs() << *it << ""\n"";; }. .. _iterate_complex:. Finding call sites: a slightly more complex example; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Say that you're writing a FunctionPass and would like to count all the locations; in the entire module (that is, across every ``Function``) where a certain; function (i.e., some ``Function *``) is already in scope. As you'll learn; later, you may want to use an ``InstVisitor`` to accomplish this in a much more; straight-forward manner",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:108803,efficient,efficient,108803,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"-enable-unsafe-fp-math. Causes :program:`lli` to enable optimizations that may decrease floating point; precision. .. option:: -soft-float. Causes :program:`lli` to generate software floating point library calls instead of; equivalent hardware instructions. CODE GENERATION OPTIONS; -----------------------. .. option:: -code-model=model. Choose the code model from:. .. code-block:: text. default: Target default code model; tiny: Tiny code model; small: Small code model; kernel: Kernel code model; medium: Medium code model; large: Large code model. .. option:: -disable-post-RA-scheduler. Disable scheduling after register allocation. .. option:: -disable-spill-fusing. Disable fusing of spill code into instructions. .. option:: -jit-enable-eh. Exception handling should be enabled in the just-in-time compiler. .. option:: -join-liveintervals. Coalesce copies (default=true). .. option:: -nozero-initialized-in-bss. Don't place zero-initialized symbols into the BSS section. .. option:: -pre-RA-sched=scheduler. Instruction schedulers available (before register allocation):. .. code-block:: text. =default: Best scheduler for the target; =none: No scheduling: breadth first sequencing; =simple: Simple two pass scheduling: minimize critical path and maximize processor utilization; =simple-noitin: Simple two pass scheduling: Same as simple except using generic latency; =list-burr: Bottom-up register reduction list scheduling; =list-tdrr: Top-down register reduction list scheduling; =list-td: Top-down list scheduler. .. option:: -regalloc=allocator. Register allocator to use (default=linearscan). .. code-block:: text. =bigblock: Big-block register allocator; =linearscan: linear scan register allocator; =local: local register allocator; =simple: simple register allocator. .. option:: -relocation-model=model. Choose relocation model from:. .. code-block:: text. =default: Target default relocation model; =static: Non-relocatable code; =pic: Fully relocatable, position independent cod",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst:4256,schedul,scheduler,4256,interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,1,['schedul'],['scheduler']
Energy Efficiency,"-no-multigrid-sync-arg"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the multigrid synchronization pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-default-queue"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the default queue pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-completion-action"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the completion action pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-lds-size""=""min[,max]"" Min is the minimum number of bytes that will be allocated in the Local; Data Store at address zero. Variables are allocated within this frame; using absolute symbol metadata, primarily by the AMDGPULowerModuleLDS; pass. Optional max is the maximum number of bytes that will be allocated.; Note that min==max indicates that no further variables can be added to; the frame. This is an internal detail of how LDS variables are lowered,; language front ends should not set this attribute. ======================================= ==========================================================. Calling Conventions; -------------------. The AMDGPU backend supports the following calling conventions:. .. table:: AMDGPU Calling Conventions; :name: amdgpu-cc. =============================== ==========================================================; Calling Convention Description; =============================== ==========================================================; ``ccc`` The C calling convention. Used by default.; See :ref:`amdgpu-amdhsa-function-call-convention-non-kernel-functions`; for more details. ``fastcc`` The fast calling convention. Mostly the same as the ``ccc``. ``coldcc`` The cold calling convention. Mostly the same as the ``ccc``. ``a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:51652,allocate,allocated,51652,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"-register-set-up-order-table`. 7. Work-Group ID Y (1 SGPR). The value comes from the initial kernel execution state. See; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. 8. Work-Group ID Z (1 SGPR). The value comes from the initial kernel execution state. See; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. 9. Implicit Argument Ptr (2 SGPRs). The value is computed by adding an offset to Kernarg Segment Ptr to get the; global address space pointer to the first kernarg implicit argument. The input and result arguments are assigned in order in the following manner:. .. note::. There are likely some errors and omissions in the following description that; need correction. .. TODO::. Check the Clang source code to decipher how function arguments and return; results are handled. Also see the AMDGPU specific values used. * VGPR arguments are assigned to consecutive VGPRs starting at VGPR0 up to; VGPR31. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. .. TODO::. How are overly aligned structures allocated on the stack?. * SGPR arguments are assigned to consecutive SGPRs starting at SGPR0 up to; SGPR29. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. Note that decomposed struct type arguments may have some fields passed in; registers and some in memory. .. TODO::. So, a struct which can pass some fields as decomposed register arguments, will; pass the rest as decomposed stack elements? But an argument that will not start; in registers will not be decomposed and will be passed as a non-decomposed; stack value?. The following is not part of the AMDGPU function calling convention but; describes how the AMDGPU implements function calls:. 1. SGPR33 is used as a frame pointer (FP) if necessary. Like the SP it is an; unswizzled scratch address. It is only n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:397047,allocate,allocated,397047,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"-unroll-count=n` and `-mllvm -pragma-unroll-threshold=n`. Loop Distribution; -----------------. Loop Distribution allows splitting a loop into multiple loops. This is; beneficial for example when the entire loop cannot be vectorized but some of the; resulting loops can. If ``distribute(enable))`` is specified and the loop has memory dependencies; that inhibit vectorization, the compiler will attempt to isolate the offending; operations into a new loop. This optimization is not enabled by default, only; loops marked with the pragma are considered. .. code-block:: c++. #pragma clang loop distribute(enable); for (i = 0; i < N; ++i) {; S1: A[i + 1] = A[i] + B[i];; S2: C[i] = D[i] * E[i];; }. This loop will be split into two loops between statements S1 and S2. The; second loop containing S2 will be vectorized. Loop Distribution is currently not enabled by default in the optimizer because; it can hurt performance in some cases. For example, instruction-level; parallelism could be reduced by sequentializing the execution of the; statements S1 and S2 above. If Loop Distribution is turned on globally with; ``-mllvm -enable-loop-distribution``, specifying ``distribute(disable)`` can; be used the disable it on a per-loop basis. Additional Information; ----------------------. For convenience multiple loop hints can be specified on a single line. .. code-block:: c++. #pragma clang loop vectorize_width(4) interleave_count(8); for(...) {; ...; }. If an optimization cannot be applied any hints that apply to it will be ignored.; For example, the hint ``vectorize_width(4)`` is ignored if the loop is not; proven safe to vectorize. To identify and diagnose optimization issues use; `-Rpass`, `-Rpass-missed`, and `-Rpass-analysis` command line options. See the; user guide for details. Extensions to specify floating-point flags; ====================================================. The ``#pragma clang fp`` pragma allows floating-point options to be specified; for a section of the source c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:168743,reduce,reduced,168743,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['reduce'],['reduced']
Energy Efficiency,". '``llvm.vector.reduce.or.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scalar. The return type matches the; element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_xor:. '``llvm.vector.reduce.xor.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.xor.*``' intrinsics do a bitwise ``XOR``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smax:. '``llvm.vector.reduce.smax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smax.*``' intrinsics do a signed integer; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smin:. '``llvm.vector.reduce.smin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smin.*``' intrinsics do a signed integer; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umax:. '``llvm.vec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:656463,reduce,reduce,656463,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,". - Shared libraries. - Inter-process communication tools (such as message queues, pipes,; semaphores, or shared memory). ### Thread Properties. A thread is the schedulable entity. It has only those properties that; are required to ensure its independent flow of control. These include; the following properties:. - Stack. - Scheduling properties (such as policy or priority). - Set of pending and blocked signals. - Some thread-specific data (TSD). An example of thread-specific data is the error indicator, `errno`. In; multi-threaded systems, `errno` is no longer a global variable, but; usually a subroutine returning a thread-specific `errno` value. Some; other systems may provide other implementations of `errno`. With respect; to ROOT, a thread specific data is for example the ***`gPad`*** pointer,; which is treated in a different way, whether it is accessed from any; thread or the main thread. Threads within a process must not be considered as a group of processes; (even though in Linux each thread receives an own process id, so that it; can be scheduled by the kernel scheduler). All threads share the same; address space. This means that two pointers having the same value in two; threads refer to the same data. Also, if any thread changes one of the; shared system resources, all threads within the process are affected.; For example, if a thread closes a file, the file is closed for all; threads. ### The Initial Thread. When a process is created, one thread is automatically created. This; thread is called the initial thread or the main thread. The initial; thread executes the main routine in multi-threaded programs. Note: At the end of this chapter is a glossary of thread specific terms. ## Implementation of Threads in ROOT. The **`TThread`** class has been developed to provide a platform; independent interface to threads for ROOT. ### Installation. For the time being, it is still necessary to compile a threaded version; of ROOT to enable some very special treatments ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:2046,schedul,scheduled,2046,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,2,['schedul'],"['scheduled', 'scheduler']"
Energy Efficiency,". .. code-block:: c++. // RUN: %clang_cc1 %s -emit-llvm -o - | FileCheck %s. struct Foo { virtual void method(); };; Foo f; // emit vtable; // CHECK-DAG: @_ZTV3Foo =. struct Bar { virtual void method(); };; Bar b;; // CHECK-DAG: @_ZTV3Bar =. ``CHECK-NOT:`` directives could be mixed with ``CHECK-DAG:`` directives to; exclude strings between the surrounding ``CHECK-DAG:`` directives. As a result,; the surrounding ``CHECK-DAG:`` directives cannot be reordered, i.e. all; occurrences matching ``CHECK-DAG:`` before ``CHECK-NOT:`` must not fall behind; occurrences matching ``CHECK-DAG:`` after ``CHECK-NOT:``. For example,. .. code-block:: llvm. ; CHECK-DAG: BEFORE; ; CHECK-NOT: NOT; ; CHECK-DAG: AFTER. This case will reject input strings where ``BEFORE`` occurs after ``AFTER``. With captured variables, ``CHECK-DAG:`` is able to match valid topological; orderings of a DAG with edges from the definition of a variable to its use.; It's useful, e.g., when your test cases need to match different output; sequences from the instruction scheduler. For example,. .. code-block:: llvm. ; CHECK-DAG: add [[REG1:r[0-9]+]], r1, r2; ; CHECK-DAG: add [[REG2:r[0-9]+]], r3, r4; ; CHECK: mul r5, [[REG1]], [[REG2]]. In this case, any order of that two ``add`` instructions will be allowed. If you are defining `and` using variables in the same ``CHECK-DAG:`` block,; be aware that the definition rule can match `after` its use. So, for instance, the code below will pass:. .. code-block:: text. ; CHECK-DAG: vmov.32 [[REG2:d[0-9]+]][0]; ; CHECK-DAG: vmov.32 [[REG2]][1]; vmov.32 d0[1]; vmov.32 d0[0]. While this other code, will not:. .. code-block:: text. ; CHECK-DAG: vmov.32 [[REG2:d[0-9]+]][0]; ; CHECK-DAG: vmov.32 [[REG2]][1]; vmov.32 d1[1]; vmov.32 d0[0]. While this can be very useful, it's also dangerous, because in the case of; register sequence, you must have a strong order (read before write, copy before; use, etc). If the definition your test is looking for doesn't match (because; of a bug i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:19292,schedul,scheduler,19292,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,1,['schedul'],['scheduler']
Energy Efficiency,". .. contents::; :local:. Introduction; ============. Segmented stack allows stack space to be allocated incrementally than as a; monolithic chunk (of some worst case size) at thread initialization. This is; done by allocating stack blocks (henceforth called *stacklets*) and linking them; into a doubly linked list. The function prologue is responsible for checking if; the current stacklet has enough space for the function to execute; and if not,; call into the libgcc runtime to allocate more stack space. Segmented stacks are; enabled with the ``""split-stack""`` attribute on LLVM functions. The runtime functionality is `already there in libgcc; <http://gcc.gnu.org/wiki/SplitStacks>`_. Implementation Details; ======================. .. _allocating stacklets:. Allocating Stacklets; --------------------. As mentioned above, the function prologue checks if the current stacklet has; enough space. The current approach is to use a slot in the TCB to store the; current stack limit (minus the amount of space needed to allocate a new block) -; this slot's offset is again dictated by ``libgcc``. The generated; assembly looks like this on x86-64:. .. code-block:: text. leaq -8(%rsp), %r10; cmpq %fs:112, %r10; jg .LBB0_2. # More stack space needs to be allocated; movabsq $8, %r10 # The amount of space needed; movabsq $0, %r11 # The total size of arguments passed on stack; callq __morestack; ret # The reason for this extra return is explained below; .LBB0_2:; # Usual prologue continues here. The size of function arguments on the stack needs to be passed to; ``__morestack`` (this function is implemented in ``libgcc``) since that number; of bytes has to be copied from the previous stacklet to the current one. This is; so that SP (and FP) relative addressing of function arguments work as expected. The unusual ``ret`` is needed to have the function which made a call to; ``__morestack`` return correctly. ``__morestack``, instead of returning, calls; into ``.LBB0_2``. This is possible sin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst:1099,allocate,allocate,1099,interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,1,['allocate'],['allocate']
Energy Efficiency,". ::. declare i32 @llvm.vp.reduce.or.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.or.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``OR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.or``' intrinsic performs the integer ``OR`` reduction; (:ref:`llvm.vector.reduce.or <int_vector_reduce_or>`) of the vector operand; ``val`` on each enabled lane, performing an '``or``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.or.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %masked.a); %also.r = or i32 %reduction, %start. .. _int_vp_reduce_xor:. '``llvm.vp.reduce.xor.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:759829,reduce,reduce,759829,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,". ; PROOF. Warning. The; classes; TProofDataSetManager; and TProofDataSetManagerFile have been renamed; TDataSetManager; and TDataSetManagerFile. New; functionality. Add support for session; queuing in the scheduler. This; allows to control the number of sessions allowed to process queries; concurrently. The feature is enabled by a new parameter 'queue:fifo' in; the 'xpd.schedparam'; directive. In case of static worker assignment; (default, random,; round-robin) the max number of running sessions can be limited by; another new parameter 'mxrun';; for; example;            ;     xpd.schedparam default; mxrun:3 queue:fifo; will run concurrently only 3 sessions. Additional requests are queued; and run as soon as one of the running; sessions goes idle. The current policy is FIFO, so that there is a; rotation among queued; sessions. In the case of load-based worker assignment, the max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' direct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:206,schedul,scheduler,206,proof/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html,1,['schedul'],['scheduler']
Energy Efficiency,". Adjust your compilation ; flags as follows:; * Add ``/lldsavetemps`` to the linker flags.; * When linking from the compiler driver, add ``/link /lldsavetemps`` in order to forward that flag to the linker. Using the specified flags will generate four intermediate bytecode files:. #. a.out.0.0.preopt.bc (Before any link-time optimizations (LTO) are applied); #. a.out.0.2.internalize.bc (After initial optimizations are applied); #. a.out.0.4.opt.bc (After an extensive set of optimizations); #. a.out.0.5.precodegen.bc (After LTO but before translating into machine code). Execute one of the following commands to identify the source of the problem:. #. ``opt ""-passes=lto<O3>"" a.out.0.2.internalize.bc``; #. ``llc a.out.0.5.precodegen.bc``. If one of these do crash, you should be able to reduce; this with :program:`llvm-reduce`; command line (use the bc file corresponding to the command above that failed):. .. code-block:: bash. llvm-reduce --test reduce.sh a.out.0.2.internalize.bc. Example of reduce.sh script. .. code-block:: bash. $ cat reduce.sh; #!/bin/bash -e. path/to/not --crash path/to/opt ""-passes=lto<O3>"" $1 -o temp.bc 2> err.log; grep -q ""It->second == &Insn"" err.log. Here we have grepped the failed assert message. Please run this, then file a bug with the instructions and reduced .bc file; that llvm-reduce emits. .. _miscompiling:. Miscompilations; ===============. If clang successfully produces an executable, but that executable doesn't run; right, this is either a bug in the code or a bug in the compiler. The first; thing to check is to make sure it is not using undefined behavior (e.g.; reading a variable before it is defined). In particular, check to see if the; program is clean under various `sanitizers; <https://github.com/google/sanitizers>`_ (e.g. ``clang; -fsanitize=undefined,address``) and `valgrind <http://valgrind.org/>`_. Many; ""LLVM bugs"" that we have chased down ended up being bugs in the program being; compiled, not LLVM. Once you determine that ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:7587,reduce,reduce,7587,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduce']
Energy Efficiency,". After the current value is; assigned to the register ``ST0`` or ``ST1``, the ``RetCC_X86Common`` is; invoked. .. code-block:: text. def RetCC_X86_32_C : CallingConv<[; CCIfType<[f32], CCAssignToReg<[ST0, ST1]>>,; CCIfType<[f64], CCAssignToReg<[ST0, ST1]>>,; CCDelegateTo<RetCC_X86Common>; ]>;. ``CCIfCC`` is an interface that attempts to match the given name to the current; calling convention. If the name identifies the current calling convention,; then a specified action is invoked. In the following example (in; ``X86CallingConv.td``), if the ``Fast`` calling convention is in use, then; ``RetCC_X86_32_Fast`` is invoked. If the ``SSECall`` calling convention is in; use, then ``RetCC_X86_32_SSE`` is invoked. .. code-block:: text. def RetCC_X86_32 : CallingConv<[; CCIfCC<""CallingConv::Fast"", CCDelegateTo<RetCC_X86_32_Fast>>,; CCIfCC<""CallingConv::X86_SSECall"", CCDelegateTo<RetCC_X86_32_SSE>>,; CCDelegateTo<RetCC_X86_32_C>; ]>;. ``CCAssignToRegAndStack`` is the same as ``CCAssignToReg``, but also allocates; a stack slot, when some register is used. Basically, it works like:; ``CCIf<CCAssignToReg<regList>, CCAssignToStack<size, align>>``. .. code-block:: text. class CCAssignToRegAndStack<list<Register> regList, int size, int align>; : CCAssignToReg<regList> {; int Size = size;; int Align = align;; }. Other calling convention interfaces include:. * ``CCIf <predicate, action>`` --- If the predicate matches, apply the action. * ``CCIfInReg <action>`` --- If the argument is marked with the ""``inreg``""; attribute, then apply the action. * ``CCIfNest <action>`` --- If the argument is marked with the ""``nest``""; attribute, then apply the action. * ``CCIfNotVarArg <action>`` --- If the current function does not take a; variable number of arguments, apply the action. * ``CCAssignToRegWithShadow <registerList, shadowList>`` --- similar to; ``CCAssignToReg``, but with a shadow list of registers. * ``CCPassByVal <size, align>`` --- Assign value to a stack slot with the; minimum spe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:65336,allocate,allocates,65336,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['allocate'],['allocates']
Energy Efficiency,". Clang - Expressive Diagnostics. Expressive Diagnostics. In addition to being fast and functional, we aim to make Clang extremely user; friendly. As far as a command-line compiler goes, this basically boils down to; making the diagnostics (error and warning messages) generated by the compiler; be as useful as possible. There are several ways that we do this. This section; talks about the experience provided by the command line compiler, contrasting; Clang output to GCC 4.9's output in some cases. Column Numbers and Caret Diagnostics; First, all diagnostics produced by clang include full column number; information. The clang command-line compiler driver uses this information; to print ""point diagnostics"".; (IDEs can use the information to display in-line error markup.); This is nice because it makes it very easy to understand exactly; what is wrong in a particular piece of code.; The point (the green ""^"" character) exactly shows where the problem is, even; inside of a string. This makes it really easy to jump to the problem and; helps when multiple instances of the same character occur on a line. (We'll; revisit this more in following examples.). $ clang -fsyntax-only format-strings.c; format-strings.c:91:13: warning: '.*' specified field precision is missing a matching 'int' argument; printf(""%.*d"");; ^. Note that modern versions of GCC have followed Clang's lead, and are; now able to give a column for a diagnostic, and include a snippet of source; text in the result. However, Clang's column number is much more accurate,; pointing at the problematic format specifier, rather than the ); character the parser had reached when the problem was detected.; Also, Clang's diagnostic is colored by default, making it easier to; distinguish from nearby text.; Range Highlighting for Related Text; Clang captures and accurately tracks range information for expressions,; statements, and other constructs in your program and uses this to make; diagnostics highlight related informatio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/diagnostics.html:908,green,green,908,interpreter/llvm-project/clang/www/diagnostics.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/diagnostics.html,1,['green'],['green']
Energy Efficiency,". Core. New class TBase64 providing Base64 encoding and decoding. Base64 encoded; messages are typically used in authentication protocols and to pack binary; data in HTTP or mail messages. New method in TSystem:. TString TSystem::GetFromPipe(const char *command). which executes ""command"" in the shell and returns the output in the TString.; Multi-line output is separated by \n's. Add proper support for Microsoft Visual C++ 9.0; Add support for 'unix' sockets on Windows.; New method TString::Clear() to reset the string but not to resize it to the default; (small) size. Useful when the string was pre-allocated to a large size and; has to be re-used.; Insure that ROOT's autoloader is always enabled whenever loading rootmap files.; Add function void TAttAxis::SetNdivisions(Int_t n1, Int_t n2, Int_t n3, Bool_t optim); ; Enable autoloading of typedef.; The statically linked roota executable and libRoot.a are currently; only supported on Linux platforms. We hope to extend this to MacOS X; soon. Meta. Add new macro ClassDefNV (ClassDef Non Virtual) which does not define any virtual function. ClassDef does define IsA, Streamer and ShowMember as virtual. This should be used only in classes that are never inherited from!; Improve performance of TClass::GetMethod (and friends). ACLiC. Implement TClassEdit::InsertStd() which puts ""std::"" in front of all STL classes.; The generated library now always checks with which version of ROOT the library was build and rebuilt the library if the running version of ROOT is different.; Add support for '+' character embedded in the script's name or directory name.; The dependency tracking file (script_C.d) is now always created when the library is built.; The dependency tracking file now records with which version of ROOT the library was built and the library is now rebuilt if it is loaded in a different version of ROOT. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v524/index.html:605,allocate,allocated,605,core/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v524/index.html,1,['allocate'],['allocated']
Energy Efficiency,". Eve; Major changes. Add support for hierarchical positioning of TEveElements in any; specific scene. This allows for easier positioning of elements in; dynamic scenes when child elements are attached to their parent; elements and are supposed to follow their movements / rotations.; Several significant improvements in TEveCaloLego classes. Calo classes now support individal tower selection. The; selection is properly maintained across all views (3D / RPhi / RhoZ; / Lego). See screenshot below.; In top view draw cell values, if their screen size is above given limit.; New energy-scales drawn as overlay (in color and size mode). The; legend can be moved around the screen with the mouse.; Fix transition between orthographic and perspective camera in; TEveCaloLego event handler.; Use color-sets in overlays and axis in order to automatically; keep same contrast when changing background color. In TEveTrackPropagator improve overall trajectory extrapolation; through the path-marks. Fix a problem with path-mark / boundary; approach with near-zero magnetic field. Maximum R / Z of extrapolation that can be set in the object; editor can now be changed via static data-members; fgEditorMaxR and fgEditorMaxZ.; Generalization of selection from GL viewers to support internal; multiple selection from the elements.; Add support for selection of individual calorimeter towers in; TEveCalo classes.; Add support for 3D -> 3D projections. This also allows for; scaling (compression/extension) of certain space region as required by; NA62 to show the 200m long detector in a meaningful way. Several generalizations of the projection infrastructure were; required:; TEveProjectable::ProjectedClass() takes an argument:; virtual TClass* ProjectedClass(const TEveProjection* p) const = 0;; thus allowing different projected classes for different projections.; All TEveProjection::ProjectPoint/Vector(...) functions have an; additional ""depth"" argument thus allowing the projected classes to; skip explic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v526/index.html:579,energy,energy-scales,579,graf3d/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v526/index.html,1,['energy'],['energy-scales']
Energy Efficiency,". Filing Bugs and Feature Requests. Filing Bugs and Feature Requests; We encourage users to file bug reports for any problems that they encounter.; We also welcome feature requests. When filing a bug report, please do the; following:. Include the checker build (for prebuilt Mac OS X binaries) or the git hash. Provide a self-contained, reduced test case that exhibits the issue you are; experiencing.; Test cases don't tell us everything. Please briefly describe the problem you; are seeing, including what you thought should have been the expected behavior; and why. Please file; bugs and feature requests in; LLVM's issue tracker; and label the report with the clang:static analyzer label. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/filing_bugs.html:337,reduce,reduced,337,interpreter/llvm-project/clang/www/analyzer/filing_bugs.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/filing_bugs.html,1,['reduce'],['reduced']
Energy Efficiency,". Open Projects. Open Projects; This page lists several projects that would boost analyzer's usability and; power. Most of the projects listed here are infrastructure-related so this list; is an addition to the potential checkers; list. If you are interested in tackling one of these, please send an email; to the cfe-dev; mailing list to notify other members of the community. Release checkers from ""alpha""; New checkers which were contributed to the analyzer,; but have not passed a rigorous evaluation process,; are committed as ""alpha checkers"" (from ""alpha version""),; and are not enabled by default.; Ideally, only the checkers which are actively being worked on should be in; ""alpha"",; but over the years the development of many of those has stalled.; Such checkers should either be improved; up to a point where they can be enabled by default,; or removed from the analyzer entirely. ; alpha.security.ArrayBound and; alpha.security.ArrayBoundV2; Array bounds checking is a desired feature,; but having an acceptable rate of false positives might not be possible; without a proper; loop widening support.; Additionally, it might be more promising to perform index checking based on; tainted index values.; (Difficulty: Medium). alpha.unix.StreamChecker; A SimpleStreamChecker has been presented in the Building a Checker in 24; Hours talk; (slides; video).; This alpha checker is an attempt to write a production grade stream checker.; However, it was found to have an unacceptably high false positive rate.; One of the found problems was that eagerly splitting the state; based on whether the system call may fail leads to too many reports.; A delayed split where the implication is stored in the state; (similarly to nullability implications in TrustNonnullChecker); may produce much better results.; (Difficulty: Medium). Improve C++ support; ; Handle construction as part of aggregate initialization.; Aggregates; are objects that can be brace-initialized without calling a; constructor (th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html:108,power,power,108,interpreter/llvm-project/clang/www/analyzer/open_projects.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html,1,['power'],['power']
Energy Efficiency,". PROOF System; NB: Starting with version 5.32/00, Xrootd; is not distributed any longer with ROOT but has become an external package.; If not avaibable the PROOF modules 'proofx' and 'proofd' will not be built.; The PROOF core modules, however, are built. Namely, PROOF-Lite will be; available even when Xrootd is not.; New functionality. Creating PAR packages from ROOT data files: it is now possible to; use TFile::MakeProject to create a PAR file to read the file.; Add support for backend-dependent record formatting of PROOF monitoring.; This is achieved by introducing a new layer, described by the abstract; interface TProofMonSender, with the record format defined in the backend; implemenation (currently TProofMonSenderML, for MonaLisa, and; TProofMonSenderSQL, for SQL backends). Currently three types of records; are sent: 'summary' (derived from what was currently posted), 'dataset',; with entries per dataset processed in the query, and 'files', with; entries per file processed in the query. In SQL terms, each of this; records corresponds to a different table. Sending of any of the three; records can be toggled independently.; In TProofMgr, add 'ping' functionality to test in non-blocking way if; a PROOF service is listening at a given port of a given host.; Improvements. In PROOF-Bench, file generation, add the possibility to change; only the generating function, passed as TMacro. Add also check on the; free space on the device and skip file generation if less than 10% or; less than 1 GB.; Record in TStatus also the max memory usage on the master and printed; via TStatus::Print; this allow a quick visualisation of the overall; memory usage at the end of the query.; Import version 0.9.6 of afdsmgrd; Make sure that the name(s) of the processed dataset(s) are registered; in the TFileInfo objects being processed, so that it can be used for; monitoring.; In XrdProofd, add possibility to skip the checks for the data; directories during session startup, as they may signi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:531,monitor,monitoring,531,proof/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html,1,['monitor'],['monitoring']
Energy Efficiency,". ROOT Version 5.30/00 Release Notes. Quick Links:; ROOT Homepage; Download; Reference Guide. Search. ROOT. » Download; » Release Notes. ROOT Version 5.30/00 Release Notes. ROOT version 5.28/00 has been released on December 15 2010.; In case you are upgrading from an old version, please read the releases notes; of version 5.16, 5.18, 5.20, 5.22, 5.24, 5,26 and version 5.28 in addition to these notes. The release of version 5.30 is scheduled for June 27, 2011. Bindings - packages related to the interplay with other programming languages (Python, Ruby); Cint - the C++ interpreter; Core - the basic ROOT functionality; Geometry - building, representing and drawing geometrical objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; RooStats - a collection of statistical tools ; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities; Tutorials - ROOT's Tutorials. Binaries for all supported platforms are available at:. https://root.cern/releases/release-52800/. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Bertrand Bellenot, CERN/SFT,; Dario Berzano, INFN and University of Torino, ALICE, Proof,; Rene Brun, CERN/SFT,; Philippe Canal, FNAL,; Olivier Couet, CERN/SFT,; Kyle Cranmer, NYU, RooStats,; Gerr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v530/index.html:435,schedul,scheduled,435,doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v530/index.html,1,['schedul'],['scheduled']
Energy Efficiency,". ROOT Version 5.32/00 Release Notes. Quick Links:; ROOT Homepage; Download; Reference Guide. Search. ROOT. » Download; » Release Notes. ROOT Version 5.32/00 Release Notes. ROOT version 5.32/00 has been released on Nov 29, 2011.; In case you are upgrading from an old version, please read the releases notes; of version 5.26, 5,28 and version 5.30 in addition to these notes. The release of version 5.34 is scheduled for May 29, 2012. Bindings - packages related to the interplay with other programming languages (Python, Ruby); Cint - the C++ interpreter; Core - the basic ROOT functionality; Geometry - building, representing and drawing geometrical objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; RooStats - a collection of statistical tools ; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities; Tutorials - ROOT's Tutorials. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Bertrand Bellenot, CERN/SFT,; Rene Brun, CERN/SFT,; Philippe Canal, FNAL,; Olivier Couet, CERN/SFT,; Kyle Cranmer, NYU/ATLAS, RooStats,; Sven Kreiss, NYU/ATLAS, RooStats,; Gena Kukartsev, CERN and FNAL/CMS, ; Gerri Ganis, CERN/SFT,; Andrei Gheata, CERN/Alice,; Christian Gumpert, CERN and University Dresden/ATLAS, Math,; Wi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v532/index.html:407,schedul,scheduled,407,doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v532/index.html,1,['schedul'],['scheduled']
Energy Efficiency,". ROOT Version 5.33/01 Release Notes. Quick Links:; ROOT Homepage; Download; Reference Guide. Search. ROOT. » Download; » Release Notes. ROOT Version 5.33/01 Release Notes. ROOT version 5.32/00 has been released on November 29, 2011.; In case you are upgrading from an old version, please read the releases notes; of version 5.26, 5,28 and version 5.30 in addition to these notes. The release of version 5.34 is scheduled for May 30, 2012. Bindings - packages related to the interplay with other programming languages (Python, Ruby); Cint - the C++ interpreter; Core - the basic ROOT functionality; Geometry - building, representing and drawing geometrical objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; RooStats - a collection of statistical tools ; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities; Tutorials - ROOT's Tutorials. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Bertrand Bellenot, CERN/SFT,; Rene Brun, CERN/SFT,; Philippe Canal, FNAL,; Olivier Couet, CERN/SFT,; Kyle Cranmer, NYU, RooStats,; Gerri Ganis, CERN/SFT,; Andrei Gheata, CERN/Alice,; Wim Lavrijsen, LBNL, PyRoot,; Lorenzo Moneta, CERN/SFT,; Axel Naumann, CERN/SFT,; Fons Rademakers, CERN/SFT,; Paul Russo, FNAL, ; Joerg ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v534/index.html:412,schedul,scheduled,412,doc/v534/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v534/index.html,1,['schedul'],['scheduled']
Energy Efficiency,". Release notes for checker-XXX builds. Release notes for checker-XXX builds; checker-279; built: November 14, 2016; download: checker-279.tar.bz2; highlights:. The analyzer includes new checks for:; ; Improper instance cleanup up in Objective-C -dealloc methods under manual retain/release.; Inadvertent comparisons of NSNumber, CFNumberRef, and other number object pointers against scalar values.; Unsafe usage of dispatch_once_t predicates stored in Objective-C instance variables and other heap-allocated memory.; Issues resulting from self-assignment in C++.; Incorrect usage of MPI APIs in C and C++. This check can be enabled by passing the following command to scan-build: ;   -enable-checker optin.mpi.MPI-Checker. The scan-build tool now supports a --force-analyze-debug-code flag that forces projects to analyze in debug mode. This flag leaves in assertions and so typically results in fewer false positives.; Additional miscellaneous improvements.; Now requires macOS 10.8 or later. checker-278; built: February 5, 2016; download: checker-278.tar.bz2; highlights:. Greatly improves analysis of C++ lambdas, including interprocedural analysis of lambda applications and reduced 'dead store'; false positives for variables captured by reference.; The analyzer now checks for misuse of 'vfork()'. This check is enabled by default.; The analyzer can now detect excessively-padded structs. This check can be enabled by passing the following; command to scan-build:;   -enable-checker optin.performance.Padding ; The checks to detect misuse of _Nonnull are now enabled by default.; The checks to detect misuse of Objective-C generics are now enabled by default.; Many miscellaneous improvements. checker-277; built: October 28, 2015; download: checker-277.tar.bz2; highlights:. Includes about 20 months of change to Clang itself.; New checker for C++ leaks is turned on by default.; Added various small checks and bug fixes.; Added experimental checkers for Objective-C:. New localizability chec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:499,allocate,allocated,499,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,1,['allocate'],['allocated']
Energy Efficiency,". SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:1142,reduce,reduced,1142,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,1,['reduce'],['reduced']
Energy Efficiency,". TMVA. TMVA version 4.0.4 is included in this root release. Methods. A new Category method allowing the user to; separate the training data (and accordingly the application; data) into disjoint sub-populations exhibiting significantly; different properties. The separation into phase space regions is; done by applying requirements on the input and/or spectator; variables. In each of these disjoint regions (each event must; belong to one and only one region), an independent training is; performed using the most appropriate MVA method, training; options and set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:672,reduce,reduces,672,tmva/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html,1,['reduce'],['reduces']
Energy Efficiency,". The; number of entries in the reorder buffer defaults to the value specified by field; `MicroOpBufferSize` in the target scheduling model. Instructions that are dispatched to the schedulers consume scheduler buffer; entries. :program:`llvm-mca` queries the scheduling model to determine the set; of buffered resources consumed by an instruction. Buffered resources are; treated like scheduler resources. Instruction Issue; """"""""""""""""""""""""""""""""""; Each processor scheduler implements a buffer of instructions. An instruction; has to wait in the scheduler's buffer until input register operands become; available. Only at that point, does the instruction becomes eligible for; execution and may be issued (potentially out-of-order) for execution.; Instruction latencies are computed by :program:`llvm-mca` with the help of the; scheduling model. :program:`llvm-mca`'s scheduler is designed to simulate multiple processor; schedulers. The scheduler is responsible for tracking data dependencies, and; dynamically selecting which processor resources are consumed by instructions.; It delegates the management of processor resource units and resource groups to a; resource manager. The resource manager is responsible for selecting resource; units that are consumed by instructions. For example, if an instruction; consumes 1cy of a resource group, the resource manager selects one of the; available units from the group; by default, the resource manager uses a; round-robin selector to guarantee that resource usage is uniformly distributed; between all units of a group. :program:`llvm-mca`'s scheduler internally groups instructions into three sets:. * WaitSet: a set of instructions whose operands are not ready.; * ReadySet: a set of instructions ready to execute.; * IssuedSet: a set of instructions executing. Depending on the operands availability, instructions that are dispatched to the; scheduler are either placed into the WaitSet or into the ReadySet. Every cycle, the scheduler checks if instru",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:37316,schedul,scheduler,37316,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,". These originate mainly from methods present previously in the implementation of the TF1 class. Now they can be used also outside this class. In addition, in order to have a common entry point, interfaces classes for these numerical algorithms have been; included.; These interfaces are as well implemented by classes using the GSL library and located in the MathMore library. The library can be loaded automatically using the ROOT plug-in manager.; In detail, the new classes containing implementations present previously in TF1 are:. ; GaussIntegrator and GaussLegendreIntegrator for numerical integration of one-dimensional functions. The first class uses Gaussian 8 and 16 point quadrature approximation, it provides the translation of the CERNLIB algorithm; DGAUSS by Sigfried Kolbig, and it is used by the TF1::Integral method. The second one uses the Gauss Legendre quadrature formula. It is used by the TF1::IntegralFast method.; These classes implement both the same virtual interface as the adaptive integration methods provided by the MathMore library. They can all be created and used easily via the common class ROOT::Math::IntegratorOneDim providing the interfaces for numerical integration.; New template methods have been also included in the common Integration class in order to be able to integrate automatically any C++ callable object. ROOT::Math::RichardsonDerivator implementing numerical derivation using the Richardson's extrapolation formula (use 2 derivative estimates to compute a third, more accurate estimation). This is used by the TD1::Derivative method. ; BrentRootFinder for finding the root of one-dimensional function using the Brent algorithm. The class inherits from a virtual interface, which is also implemented by the MathMore root finder methods. The user can instantiate, via the common ROOT::Math::RootFinder class, all the various root finder algorithms. The BrentRootFinder class is used by TF1::GetX . ; A similar class, BrentMinimizer1D, provides the po",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v520/index.html:7108,adapt,adaptive,7108,math/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v520/index.html,1,['adapt'],['adaptive']
Energy Efficiency,". Tree. Branch creation enhancement and clarifications. Make the leaflist optional if the address points to a single numerical variable:; Int_t value;; tree->Branch(branchname, &value);. Introduce a way to create branch using directly; an object:; MyClass object;; TBranch *branch = tree->Branch(branchname, &object, bufsize, splitlevel); Clarify the ownership rules of user objects in a TTree. This clarification (and the improved auto-add-to-directory behavior; of the TH1*) allows for the TTree to now delete the memory that; its has allocated and whose ownsership was _not_ transfer back; to the user (this is happens any time the user give the TTree; the address of a pointer):. For a top-level branch the meaning of addr is as follows:. If addr is zero, then we allocate a branch object; internally and the branch is the owner of the allocated; object, not the caller. However the caller may obtain; a pointer to the branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:537,allocate,allocated,537,tree/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html,3,['allocate'],"['allocate', 'allocated']"
Energy Efficiency,". Tree. Introduce TBranch::Set/GetMakeClass to independently set each branch in MakeClass mode; and to have a good place to switch the ReadLeaves function appropriately (to and from; the MakeClass mode (also known as the decomposed object mode)). This can also be; used to reset the mode of some branch with a MakeClass/MakeSelector file. Dramatically reduce the amount of memory allocation induces by the management of the TBasket and TBuffer; for each branch. Instead of creating one TBasket object and one TBuffer object and its associated memory buffer; for each onfile basket of each branch, we now create only one TBasket and one TBuffer object for the lifetime of; each branch. The memory buffer associated with the TBuffer object is also created once and rarely reallocated;; it is reallocated only when the buffer size is reset (for example by the AutoFlush mechanism) and when the user; object do not fit in the currently allocated memory (but we do not shrink it after that. The same minization; is applied to the scratch area used to read the compressed version of a basket from the file.; In TTree and TChain's LoadTree fReadEntry is now set to -1 in case of failure to find the proper row.; In TTree::CloneTree, TChain::Merge and TTree::CopyEntries introduces more flexibility; in the handling of the case where a TTreeIndex is 'missing' in one or more of the; TTree objects being collated. If the tree or any of the underlying tree of the chain has an index,; that index and any index in the subsequent underlying TTree objects will be merged. There are currently three 'options'; to control this merging:; ; NoIndex : all the TTreeIndex object are dropped.; DropIndexOnError : if any of the underlying TTree object do no have a TTreeIndex,; they are all dropped.; AsIsIndexOnError [default]: In case of missing TTreeIndex, the resulting TTree index has gaps.; BuildIndexOnError : If any of the underlying TTree object do no have a TTreeIndex,; all TTreeIndex are 'ignored' and the misi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:352,reduce,reduce,352,tree/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html,2,"['allocate', 'reduce']","['allocated', 'reduce']"
Energy Efficiency,". Tree. Restore support for IsAutoDelete in a TBranchElement (IsAutoDelete is an explicit request by the user to have the object deleted/newed each time GetEntry is called).; Allow .root in the name of directory in TChain::Add and TChain::AddFile (however in this case the root file must be ending .root.); Improve support for circular TTree friendship in LoadTree.; Insure that the in-memory tree (not attached to a file) are saved in their new style (i.e. each basket saved separately) and prevent the printing of the misleading error message:; Error in : Cannot create key without file ; Repaired TTreeSQL:; The existing code was not compatible with the change made in TTree to reduce the number of baskets in memory.; If the TreeFriend is entered via a TTree*, properly detect that it is in the same file and do not record the filename (since we will alway know where to find it.); Add "","" in the list of special characters replaced by ""_"" in the TTree::MakeClass; and TTree::MakeCode functions.; The fast cloning now explicitly rejects trying to merge TTrees with different split level; The fast cloning now supports the case where one of the branch in the output tree in; not present and also supports the case where branch are not the same order.; New bit flag kMapObject [mybranch->ResetBit(kMapObject)] to explicitly disable the; object registration during streaming within a branch (Use only if you are sure that there; is not a pointer pointing back to the nesting object within this branch). Fix tree->Draw(""s1.value"");; when the top level branch does not have a trailing dot; (and hence the real branch name is only 'value'). Fixed support for vector<bool> and vector<string> ; Added support for top level object that do not inherit from TObject _AND_ have a custom streamer (like std::string and TString);; Tree Viewer. In TParallelCoordVar the ""average marker"" for candle plots was not painted at; the right place in case of horizontal view.; Protection added in:; TParallelCoord::TPara",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html:681,reduce,reduce,681,tree/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html,1,['reduce'],['reduce']
Energy Efficiency,". While this example is somewhat silly, it illustrates the point: we want to; retain typedef information where possible, so that we can emit errors about; ""``std::string``"" instead of ""``std::basic_string<char, std:...``"". Doing this; requires properly keeping typedef information (for example, the type of ``X``; is ""``foo``"", not ""``int``""), and requires properly propagating it through the; various operators (for example, the type of ``*Y`` is ""``foo``"", not; ""``int``""). In order to retain this information, the type of these expressions; is an instance of the ``TypedefType`` class, which indicates that the type of; these expressions is a typedef for ""``foo``"". Representing types like this is great for diagnostics, because the; user-specified type is always immediately available. There are two problems; with this: first, various semantic checks need to make judgements about the; *actual structure* of a type, ignoring typedefs. Second, we need an efficient; way to query whether two types are structurally identical to each other,; ignoring typedefs. The solution to both of these problems is the idea of; canonical types. .. _CanonicalType:. Canonical Types; ^^^^^^^^^^^^^^^. Every instance of the ``Type`` class contains a canonical type pointer. For; simple types with no typedefs involved (e.g., ""``int``"", ""``int*``"",; ""``int**``""), the type just points to itself. For types that have a typedef; somewhere in their structure (e.g., ""``foo``"", ""``foo*``"", ""``foo**``"",; ""``bar``""), the canonical type pointer points to their structurally equivalent; type without any typedefs (e.g., ""``int``"", ""``int*``"", ""``int**``"", and; ""``int*``"" respectively). This design provides a constant time operation (dereferencing the canonical type; pointer) that gives us access to the structure of types. For example, we can; trivially tell that ""``bar``"" and ""``foo*``"" are the same type by dereferencing; their canonical type pointers and doing a pointer comparison (they both point; to the single """,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:63396,efficient,efficient,63396,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['efficient'],['efficient']
Energy Efficiency,". ``` {.cpp}; TVector3 v;; TRotation r;; v.Transform(r);; ```. ## TLorentzVector. **`TLorentzVector`** is a general four-vector class, which can be used; either for the description of position and time (`x`, `y`, `z`, `t`) or; momentum and energy (`px`, `py`, `pz`, `E`). ### Declaration. **`TLorentzVector`** has been implemented as a set a **`TVector3`** and; a `Double_t` variable. By default, all components are initialized by; zero. ``` {.cpp}; TLorentzVector v1; // initialized by (0.,0.,0.,0.); TLorentzVector v2(1.,1.,1.,1.);; TLorentzVector v3(v1);; TLorentzVector v4(TVector3(1.,2.,3.),4.);; ```. For backward compatibility there are two constructors from a `Double_t`; and `Float_t` array. ### Access to Components. There are two sets of access functions to the components of a; **`TLorentzVector`**: `X()`, `Y()`, `Z()`, `T()` and `Px()`, `Py()`,; `Pz()` and `E()`. Both sets return the same values but the first set is; more relevant for use where **`TLorentzVector`** describes a combination; of position and time and the second set is more relevant where; **`TLorentzVector`** describes momentum and energy:. ``` {.cpp}; Double_t xx =v.X();; ...; Double_t tt = v.T();; Double_t px = v.Px();; ...; Double_t ee = v.E();; ```. The components of **`TLorentzVector`** can also accessed by index:. ``` {.cpp}; xx = v(0);orxx = v[0];; yy = v(1);yy = v[1];; zz = v(2);zz = v[2];; tt = v(3);tt = v[3];; ```. You can use the `Vect()` method to get the vector component of; **`TLorentzVector`**:. ``` {.cpp}; TVector3 p = v.Vect();; ```. For setting components there are two methods: `SetX(),.., SetPx(),..:`. ``` {.cpp}; v.SetX(1.); orv.SetPx(1.);; ......; v.SetT(1.);v.SetE(1.);; ```. To set more the one component by one call you can use the `SetVect()`; function for the **`TVector3`** part or `SetXYZT()`, `SetPxPyPzE()`. For; convenience there is also a `SetXYZM()`:. ``` {.cpp}; v.SetVect(TVector3(1,2,3));; v.SetXYZT(x,y,z,t);; v.SetPxPyPzE(px,py,pz,e);; v.SetXYZM(x,y,z,m); // v = (x,y,z",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md:10415,energy,energy,10415,documentation/users-guide/PhysicsVectors.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md,1,['energy'],['energy']
Energy Efficiency,". and each category should be sorted lexicographically by the full path. The `Main Module Header`_ file applies to ``.cpp`` files which implement an; interface defined by a ``.h`` file. This ``#include`` should always be included; **first** regardless of where it lives on the file system. By including a; header file first in the ``.cpp`` files that implement the interfaces, we ensure; that the header does not have any hidden dependencies which are not explicitly; ``#include``\d in the header, but should be. It is also a form of documentation; in the ``.cpp`` file to indicate where the interfaces it implements are defined. LLVM project and subproject headers should be grouped from most specific to least; specific, for the same reasons described above. For example, LLDB depends on; both clang and LLVM, and clang depends on LLVM. So an LLDB source file should; include ``lldb`` headers first, followed by ``clang`` headers, followed by; ``llvm`` headers, to reduce the possibility (for example) of an LLDB header; accidentally picking up a missing include due to the previous inclusion of that; header in the main source file or some earlier header file. clang should; similarly include its own headers before including llvm headers. This rule; applies to all LLVM subprojects. .. _fit into 80 columns:. Source Code Width; ^^^^^^^^^^^^^^^^^. Write your code to fit within 80 columns. There must be some limit to the width of the code in; order to allow developers to have multiple files side-by-side in; windows on a modest display. If you are going to pick a width limit, it is; somewhat arbitrary but you might as well pick something standard. Going with 90; columns (for example) instead of 80 columns wouldn't add any significant value; and would be detrimental to printing out code. Also many other projects have; standardized on 80 columns, so some people have already configured their editors; for it (vs something else, like 90 columns). Whitespace; ^^^^^^^^^^. In all cases, prefer s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:17168,reduce,reduce,17168,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['reduce'],['reduce']
Energy Efficiency,". void test(A *dst, A *src) {; ::new (dst) A(*dst); // warn (should be 'src'); }. exceptions. Name, DescriptionExampleProgress. exceptions.ThrowSpecButNotThrow; (C++); Function declaration has a throw(type) specifier but the; function do not throw exceptions. void test() throw(int) {; } // warn. exceptions.NoThrowSpecButThrows; (C++); An exception is throw from a function having a throw(); specifier. void test() throw() {; throw(1); // warn; }. exceptions.ThrownTypeDiffersSpec; (C++); The type of a thrown exception differs from those specified in; a throw(type) specifier. struct S{};. void test() throw(int) {; S s;; throw (s); // warn; }. smart pointers. Name, DescriptionExampleProgress. smartptr.SmartPtrInit; (C++); C++03: auto_ptr should store a pointer to an object obtained via; new as allocated memory will be cleaned using delete.; C++11: one should use unique_ptr<type[]> to keep a; pointer to memory allocated by new[].; C++11: to keep a pointer to memory allocated by new[] in; a shared_ptr one should use a custom deleter that calls ; delete[]..; Source: C++03 20.4.5p1; C++11 auto_ptr is deprecated (D.10). #include <stdlib.h>; #include <memory>. void test() {; std::auto_ptr<int> p1(new int); // Ok; std::auto_ptr<int> p2(new int[3]); // warn; }. #include <stdlib.h>; #include <memory>. void test() {; std::auto_ptr<int> p((int *)malloc(sizeof(int))); // warn; }. dead code. Name, DescriptionExampleProgress. deadcode.UnmodifiedVariable; (C, C++); A variable is never modified but was not declared const and is not a; reference.(opt-in checker). extern int computeDelta();. int test(bool cond) {; int i = 0;; if (cond) {; const int delta = computeDelta();; // warn: forgot to modify 'i'; }; return i;; }. PR16890. deadcode.IdempotentOperations; (C); Warn about idempotent operations. void test() {; int x = 7;; x = x; // warn: value is always the same; }. void test() {; int x = 7;; x /= x; // warn: value is always 1; }. void test() {; int x = 7, one = 1;; x *= one; // warn: ri",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:3726,allocate,allocated,3726,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,1,['allocate'],['allocated']
Energy Efficiency,".*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smax.*``' intrinsics do a signed integer; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smin:. '``llvm.vector.reduce.smin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smin.*``' intrinsics do a signed integer; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umax:. '``llvm.vector.reduce.umax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umax.*``' intrinsics do an unsigned; integer ``MAX`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umin:. '``llvm.vector.reduce.umin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umin.*``' intrinsics do an unsigned; integer ``MIN`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmax:. '``ll",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:657471,reduce,reduce,657471,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,".*``' intrinsics do a signed integer; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smin:. '``llvm.vector.reduce.smin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smin.*``' intrinsics do a signed integer; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umax:. '``llvm.vector.reduce.umax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umax.*``' intrinsics do an unsigned; integer ``MAX`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umin:. '``llvm.vector.reduce.umin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umin.*``' intrinsics do an unsigned; integer ``MIN`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmax:. '``llvm.vector.reduce.fmax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmax.v4f32(<4 x float> %a); declare double @llvm.vector",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:657663,reduce,reduce,657663,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,".. Clang documentation master file, created by; sphinx-quickstart on Sun Dec 9 20:01:55 2012.; You can adapt this file completely to your liking, but it should at least; contain the root `toctree` directive. .. title:: Welcome to Clang's documentation!. .. toctree::; :maxdepth: 1. ReleaseNotes. Using Clang as a Compiler; =========================. .. toctree::; :maxdepth: 1. UsersManual; Toolchain; LanguageExtensions; ClangCommandLineReference; AttributeReference; DiagnosticsReference; CrossCompilation; ClangStaticAnalyzer; ThreadSafetyAnalysis; DataFlowAnalysisIntro; AddressSanitizer; ThreadSanitizer; MemorySanitizer; UndefinedBehaviorSanitizer; DataFlowSanitizer; LeakSanitizer; SanitizerCoverage; SanitizerStats; SanitizerSpecialCaseList; BoundsSafety; BoundsSafetyImplPlans; ControlFlowIntegrity; LTOVisibility; SafeStack; ShadowCallStack; SourceBasedCodeCoverage; StandardCPlusPlusModules; Modules; MSVCCompatibility; MisExpect; OpenCLSupport; OpenMPSupport; SYCLSupport; HIPSupport; HLSL/HLSLDocs; ThinLTO; APINotes; DebuggingCoroutines; AMDGPUSupport; CommandGuide/index; FAQ. Using Clang as a Library; ========================. .. toctree::; :maxdepth: 1. Tooling; ExternalClangExamples; IntroductionToTheClangAST; LibTooling; LibClang; LibFormat; ClangPlugins; RAVFrontendAction; LibASTMatchersTutorial; LibASTMatchers; ClangTransformerTutorial; LibASTImporter; HowToSetupToolingForLLVM; JSONCompilationDatabase; RefactoringEngine. Using Clang Tools; =================. .. toctree::; :maxdepth: 1. ClangTools; ClangCheck; ClangFormat; ClangFormatStyleOptions; ClangFormattedStatus; ClangLinkerWrapper; ClangOffloadBundler; ClangOffloadPackager; ClangRepl. Design Documents; ================. .. toctree::; :maxdepth: 1. CodeOwners; InternalsManual; DriverInternals; Multilib; OffloadingDesign; PCHInternals; ItaniumMangleAbiTags; HardwareAssistedAddressSanitizerDesign.rst; ConstantInterpreter. Indices and tables; ==================. * :ref:`genindex`; * :ref:`search`. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/index.rst:103,adapt,adapt,103,interpreter/llvm-project/clang/docs/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/index.rst,1,['adapt'],['adapt']
Energy Efficiency,".. _functions:. Functions; =========. C++ functions are first-class objects in Python and can be used wherever; Python functions can be used, including for dynamically constructing; classes. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. Function argument type conversions follow the expected rules, with implicit; conversions allowed, including between Python builtin types and STL types,; but it is rather more efficient to make conversions explicit. `Free functions`; ----------------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can directly import C++ functions from it and other namespaces that; themselves may contain more functions.; All lookups on namespaces are done lazily, thus if loading more headers bring; in more functions (incl. new overloads), these become available dynamically. .. code-block:: python. >>> from cppyy.gbl import global_function, Namespace; >>> global_function == Namespace.global_function; False; >>> from cppyy.gbl.Namespace import global_function; >>> global_function == Namespace.global_function; True; >>> from cppyy.gbl import global_function; >>>. Free functions can be bound to a class, following the same rules as apply to; Python functions: unless marked as static, they will turn into member; functions when bound to an instance, but act as static functions when called; through the class.; Consider this example:. .. code-block:: python. >>> from cppyy.gbl import Concrete, call_abstract_method; >>> c = Concrete(); >>> Concrete.callit = call_abstract_method; >>> Concrete.callit(c); called Concrete::abstract_method; >>> c.callit(); ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:678,efficient,efficient,678,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,1,['efficient'],['efficient']
Energy Efficiency,".. _numba:. Numba support; =============. .. caution::. This is an **experimental** feature, available starting with release; 2.4.0.; It is still incomplete (see listing below) and has only been tested on; Linux on x86_64. Numba `is a JIT compiler`_ for Python functions that can be statically typed; based on their input arguments.; Since C++ objects are always statically typed and already implemented at the; machine level, they can be dynamically integrated into the Numba type tracing; and lowering by exposing type details through C++ reflection at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; woul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:616,reduce,reduces,616,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,2,['reduce'],"['reduce', 'reduces']"
Energy Efficiency,".. _phabricator-reviews:. =============================; Code Reviews with Phabricator; =============================. .. warning::. Phabricator is deprecated and will be switched to read-only mode in October; 2023, for new code contributions use :ref:`GitHub Pull Requests <github-reviews>`. .. contents::; :local:. If you prefer to use a web user interface for code reviews, you can now submit; your patches for Clang and LLVM at `LLVM's Phabricator`_ instance. While Phabricator is a useful tool for some, the relevant -commits mailing list; is the system of record for all LLVM code review. The mailing list should be; added as a subscriber on all reviews, and Phabricator users should be prepared; to respond to free-form comments in mail sent to the commits list. Sign up; -------. To get started with Phabricator, navigate to `https://reviews.llvm.org`_ and; click the power icon in the top right. You can register with a GitHub account,; a Google account, or you can create your own profile. Make *sure* that the email address registered with Phabricator is subscribed; to the relevant -commits mailing list. If you are not subscribed to the commit; list, all mail sent by Phabricator on your behalf will be held for moderation. Note that if you use your git user name as Phabricator user name,; Phabricator will automatically connect your submits to your Phabricator user in; the `Code Repository Browser`_. Requesting a review via the command line; ----------------------------------------. Phabricator has a tool called *Arcanist* to upload patches from; the command line. To get you set up, follow the; `Arcanist Quick Start`_ instructions. You can learn more about how to use arc to interact with; Phabricator in the `Arcanist User Guide`_.; The basic way of creating a revision for the current commit in your local; repository is to run:. ::. arc diff HEAD~. Sometime you may want to create a draft revision to show the proof of concept; or for experimental purposes, In that case you ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst:876,power,power,876,interpreter/llvm-project/llvm/docs/Phabricator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Phabricator.rst,1,['power'],['power']
Energy Efficiency,".. _starting:. Trying it out; =============. This is a basic guide to try cppyy and see whether it works for you.; Large code bases will benefit from more advanced features such as; :doc:`pythonizations <pythonizations>` for a cleaner interface to clients;; precompiled modules for faster parsing and reduced memory usage;; "":ref:`dictionaries <dictionaries>`"" to package locations and manage; dependencies; and mapping files for automatic, lazy, loading.; You can, however, get very far with just the basics and it may even be; completely sufficient for small packages with fewer classes. cppyy works by parsing C++ definitions through ``cling``, generating tiny; wrapper codes to honor compile-time features and create standardized; interfaces, then compiling/linking those wrappers with the ``clang`` JIT.; It thus requires only those two ingredients: *C++ definitions* and; *linker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which ad",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:301,reduce,reduced,301,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,1,['reduce'],['reduced']
Energy Efficiency,".. _wineh:. Exception Handling using the Windows Runtime; =================================================. Background on Windows exceptions; ---------------------------------. Interacting with exceptions on Windows is significantly more complicated than; on Itanium C++ ABI platforms. The fundamental difference between the two models; is that Itanium EH is designed around the idea of ""successive unwinding,"" while; Windows EH is not. Under Itanium, throwing an exception typically involves allocating thread local; memory to hold the exception, and calling into the EH runtime. The runtime; identifies frames with appropriate exception handling actions, and successively; resets the register context of the current thread to the most recently active; frame with actions to run. In LLVM, execution resumes at a ``landingpad``; instruction, which produces register values provided by the runtime. If a; function is only cleaning up allocated resources, the function is responsible; for calling ``_Unwind_Resume`` to transition to the next most recently active; frame after it is finished cleaning up. Eventually, the frame responsible for; handling the exception calls ``__cxa_end_catch`` to destroy the exception,; release its memory, and resume normal control flow. The Windows EH model does not use these successive register context resets.; Instead, the active exception is typically described by a frame on the stack.; In the case of C++ exceptions, the exception object is allocated in stack memory; and its address is passed to ``__CxxThrowException``. General purpose structured; exceptions (SEH) are more analogous to Linux signals, and they are dispatched by; userspace DLLs provided with Windows. Each frame on the stack has an assigned EH; personality routine, which decides what actions to take to handle the exception.; There are a few major personalities for C and C++ code: the C++ personality; (``__CxxFrameHandler3``) and the SEH personalities (``_except_handler3``,; ``_except_ha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:20841,allocate,allocated,20841,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,1,['allocate'],['allocated']
Energy Efficiency,".. code-block:: c++. New = CmpInst::Create(..., SO->getName() + "".cmp"");. The ``Twine`` class is effectively a lightweight `rope; <http://en.wikipedia.org/wiki/Rope_(computer_science)>`_ which points to; temporary (stack allocated) objects. Twines can be implicitly constructed as; the result of the plus operator applied to strings (i.e., a C strings, an; ``std::string``, or a ``StringRef``). The twine delays the actual concatenation; of strings until it is actually required, at which point it can be efficiently; rendered directly into a character array. This avoids unnecessary heap; allocation involved in constructing the temporary results of string; concatenation. See ``llvm/ADT/Twine.h`` (`doxygen; <https://llvm.org/doxygen/Twine_8h_source.html>`__) and :ref:`here <dss_twine>`; for more information. As with a ``StringRef``, ``Twine`` objects point to external memory and should; almost never be stored or mentioned directly. They are intended solely for use; when defining a function which should be able to efficiently accept concatenated; strings. .. _formatting_strings:. Formatting strings (the ``formatv`` function); ---------------------------------------------; While LLVM doesn't necessarily do a lot of string manipulation and parsing, it; does do a lot of string formatting. From diagnostic messages, to llvm tool; outputs such as ``llvm-readobj`` to printing verbose disassembly listings and; LLDB runtime logging, the need for string formatting is pervasive. The ``formatv`` is similar in spirit to ``printf``, but uses a different syntax; which borrows heavily from Python and C#. Unlike ``printf`` it deduces the type; to be formatted at compile time, so it does not need a format specifier such as; ``%d``. This reduces the mental overhead of trying to construct portable format; strings, especially for platform-specific types like ``size_t`` or pointer types.; Unlike both ``printf`` and Python, it additionally fails to compile if LLVM does; not know how to format the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:11069,efficient,efficiently,11069,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficiently']
Energy Efficiency,".. code-block:: python. >>> v += range(10, 20); >>> len(v); 20; >>>. Indexing and slicing of a vector follows the normal Python slicing rules;; printing a vector prints all its elements:. .. code-block:: python. >>> v[1]; 1; >>> v[-1]; 19; >>> v[-4:]; <cppyy.gbl.std.vector<int> object at 0x7f9051057650>; >>> print(v[-4:]); { 6, 7, 8, 9 }; >>>. The usual iteration operations work on vector, but the C++ rules still apply,; so a vector that is being iterated over can *not* be modified in the loop; body.; (On the plus side, this makes it much faster to iterate over a vector than,; say, a numpy ndarray.). .. code-block:: python. >>> for i in v[2:5]:; ... print(i); ...; 2; 3; 4; >>> 2 in v; True; >>> sum(v); 190; >>>. When a function takes a non-l-value (const-ref, move, or by-value) vector as; a parameter, another sequence can be used and cppyy will automatically; generate a temporary.; Typically, this will be faster than coding up such a temporary on the Python; side, but if the same sequence is used multiple times, creating a temporary; once and re-using it will be the most efficient approach.o. .. code-block:: python. >>> cppyy.cppdef(""""""; ... int sumit1(const std::vector<int>& data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }; ... int sumit2(std::vector<int> data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }; ... int sumit3(const std::vector<int>&& data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }""""""); ...; True; >>> cppyy.gbl.sumit1(range(5)); 10; >>> cppyy.gbl.sumit2(range(6)); 16; >>> cppyy.gbl.sumit3(range(7)); 21; >>>. The temporary vector is created using the vector constructor taking an; ``std::initializer_list``, which is more flexible than constructing a; temporary vector and filling it: it allows the data in the container to be; implicitly converted (e.g. from ``int`` to ``double`` type, or from; pointer to derived to pointer to base class).; As a consequence, however, with STL containers b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:4484,efficient,efficient,4484,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,1,['efficient'],['efficient']
Energy Efficiency,".. cppyy documentation master file, created by; sphinx-quickstart on Wed Jul 12 14:35:45 2017.; You can adapt this file completely to your liking, but it should at least; contain the root `toctree` directive. .. meta::; :description: cppyy: Automatic Python-C++ bindings; :keywords: Python, C++, llvm, cling, binding, bindings, automatic bindings, bindings generator, cross-language inheritance, calling C++ from Python, calling Python from C++, high performance, data science. cppyy: Automatic Python-C++ bindings; ====================================. cppyy is an automatic, run-time, Python-C++ bindings generator, for calling; C++ from Python and Python from C++.; Run-time generation enables detailed specialization for higher performance,; lazy loading for reduced memory use in large scale projects, Python-side; cross-inheritance and callbacks for working with C++ frameworks, run-time; template instantiation, automatic object downcasting, exception mapping, and; interactive exploration of C++ libraries.; cppyy delivers this without any language extensions, intermediate languages,; or the need for boiler-plate hand-written code.; For design and performance, see this `PyHPC'16 paper`_, albeit that the; CPython/cppyy performance has been vastly improved since, as well as this; `CAAS presentation`_.; For a quick teaser, see `Jason Turner's`_ introduction video. cppyy is based on `Cling`_, the C++ interpreter, to match Python's dynamism,; interactivity, and run-time behavior.; Consider this session, showing dynamic, interactive, mixing of C++ and Python; features (there are more examples throughout the documentation and in the; `tutorial`_):. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""; ... class MyClass {; ... public:; ... MyClass(int i) : m_data(i) {}; ... virtual ~MyClass() {}; ... virtual int add_int(int i) { return m_data + i; }; ... int m_data;; ... };""""""); True; >>> from cppyy.gbl import MyClass; >>> m = MyClass(42); >>> cppyy.cppdef(""""""; ... void sa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:104,adapt,adapt,104,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst,2,"['adapt', 'reduce']","['adapt', 'reduced']"
Energy Efficiency,"........... ........+++++++++++++++++++++++****; ++++++++++++++++++++++........... ..........++++++++++++++++++++++***; ++++++++++++++++++++........... .........++++++++++++++++++++++*; ++++++++++++++++++............ ...........++++++++++++++++++++; ++++++++++++++++............... .............++++++++++++++++++; ++++++++++++++................. ...............++++++++++++++++; ++++++++++++.................. .................++++++++++++++; +++++++++.................. .................+++++++++++++; ++++++........ . ......... ..++++++++++++; ++............ ...... ....++++++++++; .............. ...++++++++++; .............. ....+++++++++; .............. .....++++++++; ............. ......++++++++; ........... .......++++++++; ......... ........+++++++; ......... ........+++++++; ......... ....+++++++; ........ ...+++++++; ....... ...+++++++; ....+++++++; .....+++++++; ....+++++++; ....+++++++; ....+++++++; Evaluated to 0.000000; ready> ^D. At this point, you may be starting to realize that Kaleidoscope is a; real and powerful language. It may not be self-similar :), but it can be; used to plot things that are!. With this, we conclude the ""adding user-defined operators"" chapter of; the tutorial. We have successfully augmented our language, adding the; ability to extend the language in the library, and we have shown how; this can be used to build a simple but interesting end-user application; in Kaleidoscope. At this point, Kaleidoscope can build a variety of; applications that are functional and can call functions with; side-effects, but it can't actually define and mutate a variable itself. Strikingly, variable mutation is an important feature of some languages,; and it is not at all obvious how to `add support for mutable; variables <LangImpl07.html>`_ without having to add an ""SSA construction""; phase to your front-end. In the next chapter, we will describe how you; can add variable mutation without building SSA in your front-end. Full Code Listing; ================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst:25794,power,powerful,25794,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst,1,['power'],['powerful']
Energy Efficiency,"..; This work is licensed under a Creative Commons Attribution 3.0 Unported License.; SPDX-License-Identifier: CC-BY-3.0. =================================; LLVM CoC Incident Reporting Guide; =================================. First of all, please do not feel like you may be a burden to us by reporting; incidents. We consider reports an opportunity for us to act: by knowing about; an incident, we can act on it if appropriate, and reduce continuation of; problematic behavior. If we don't know, we can't learn or take any appropriate; actions. If you are not sure the situation being reported was a :doc:`Code of; Conduct<CodeOfConduct>` violation, we encourage you to still report it. We; would much rather have reports where we decide to take no action, rather than; miss a report of an actual violation. There is no harm in reporting an incident; which is later determined not to be a violation, and knowing about incidents; that are not violations can also help us to improve the Code of Conduct or the; processes surrounding it. Reporting and Contact Information; =================================. * For any incident involving an online platform (e.g., mailing lists, forums, ; irc/discord/slack, etc) we ask that you make any reports by emailing ; conduct@llvm.org. This is received by all members of the CoC Committee. * For LLVM Developers' Meetings, please file a report with the on-site Code ; of Conduct team. Their names and contact details are listed on the event ; webpage. You can also approach any other staff member, who can be ; identified by special badges and often found at the registration desk, ; to help you locate a member of the Code of Conduct team. All incidents ; reported in-person at a LLVM Developers' Meeting will be emailed to the ; Code of Conduct Committee. . * For meetups, please report the incident to the local meetup organizers first; and then email conduct@llvm.org with your report. Each meetup will have a ; contact listed on the associated meetup page.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReportingGuide.rst:434,reduce,reduce,434,interpreter/llvm-project/llvm/docs/ReportingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReportingGuide.rst,1,['reduce'],['reduce']
Energy Efficiency,".; - ``z``: Print $0 if an immediate zero, otherwise print normally.; - ``L``: Print the low-order register of a two-register operand, or prints the; address of the low-order word of a double-word memory operand. .. FIXME: L seems to be missing memory operand support. - ``M``: Print the high-order register of a two-register operand, or prints the; address of the high-order word of a double-word memory operand. .. FIXME: M seems to be missing memory operand support. - ``D``: Print the second register of a two-register operand, or prints the; second word of a double-word memory operand. (On a big-endian system, ``D`` is; equivalent to ``L``, and on little-endian system, ``D`` is equivalent to; ``M``.); - ``w``: No effect. Provided for compatibility with GCC which requires this; modifier in order to print MSA registers (``W0-W31``) with the ``f``; constraint. NVPTX:. - ``r``: No effect. PowerPC:. - ``L``: Print the second register of a two-register operand. Requires that it; has been allocated consecutively to the first. .. FIXME: why is it restricted to consecutive ones? And there's; nothing that ensures that happens, is there?. - ``I``: Print the letter 'i' if the operand is an integer constant, otherwise; nothing. Used to print 'addi' vs 'add' instructions.; - ``y``: For a memory operand, prints formatter for a two-register X-form; instruction. (Currently always prints ``r0,OPERAND``).; - ``U``: Prints 'u' if the memory operand is an update form, and nothing; otherwise. (NOTE: LLVM does not support update form, so this will currently; always print nothing); - ``X``: Prints 'x' if the memory operand is an indexed form. (NOTE: LLVM does; not support indexed form, so this will currently always print nothing). RISC-V:. - ``i``: Print the letter 'i' if the operand is not a register, otherwise print; nothing. Used to print 'addi' vs 'add' instructions, etc.; - ``z``: Print the register ``zero`` if an immediate zero, otherwise print; normally. Sparc:. - ``L``: Print the low",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:238968,allocate,allocated,238968,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,".; One can specify arbitrary scripts list, which asynchronously loaded by browser.; 7. Method to build simple GUI changed and more simplified :). The example in index.htm.; While loadScript and AssertPrerequisites functions moved to JSROOT, one; can easily build many different kinds of GUIs, reusing provided JSRootCore.js functions.; 8. In example.htm also use AssertPrerequisites to load necessary scripts.; This helps to keep code up-to-date even by big changes in JavaScript code.; 9. Provide monitoring of online THttpServer with similar interface as for ROOT files.; 10. Fix several errors in TKey Streamer, use member names as in ROOT itself.; 11. Keep the only version identifier JSROOT.version for JS code; 12. One can specify in JSROOT.AssertPrerequisites functionality which is required.; One could specify '2d', 'io' (default) or '3d'.; 13. Use new AssertPrerequisites functionality to load only required functionality.; 14. When displaying single element, one could specify draw options and monitor property like:; <http://localhost:8080/Files/job1.root/hpxpy/draw.htm?opt=col&monitor=2000>; Such link is best possibility to integrate display into different HTML pages,; using `<iframe/>` tag like:; `<iframe src=""http://localhost:8080/Files/job1.root/hpx/draw.htm""`; `style=""width: 800px; height:600px""></iframe>`; 15. Remove 'JSROOTIO.' prefix from _typename. Now real class name is used.; 16. Use in all scripts JSROOT as central 'namespace'; 17. Introduce context menu in 3D, use it for switch between 2D/3D modes; 18. Use own code to generate hierarchical structure in HTML, replace dtree.js which is; extremely slow for complex hierarchies. Dramatically improve performance for; structures with large (~1000) number of items.; 19. Deliver to the server title of the objects, display it as hint in the browser.; 20. Better handling of special characters in the hierarchies - allows to display; symbols like ' or "" in the file structure. ### July 2014; 1. Migration to d3.v3.js and ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:75451,monitor,monitor,75451,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['monitor'],['monitor']
Energy Efficiency,".; While loadScript and AssertPrerequisites functions moved to JSROOT, one; can easily build many different kinds of GUIs, reusing provided JSRootCore.js functions.; 8. In example.htm also use AssertPrerequisites to load necessary scripts.; This helps to keep code up-to-date even by big changes in JavaScript code.; 9. Provide monitoring of online THttpServer with similar interface as for ROOT files.; 10. Fix several errors in TKey Streamer, use member names as in ROOT itself.; 11. Keep the only version identifier JSROOT.version for JS code; 12. One can specify in JSROOT.AssertPrerequisites functionality which is required.; One could specify '2d', 'io' (default) or '3d'.; 13. Use new AssertPrerequisites functionality to load only required functionality.; 14. When displaying single element, one could specify draw options and monitor property like:; <http://localhost:8080/Files/job1.root/hpxpy/draw.htm?opt=col&monitor=2000>; Such link is best possibility to integrate display into different HTML pages,; using `<iframe/>` tag like:; `<iframe src=""http://localhost:8080/Files/job1.root/hpx/draw.htm""`; `style=""width: 800px; height:600px""></iframe>`; 15. Remove 'JSROOTIO.' prefix from _typename. Now real class name is used.; 16. Use in all scripts JSROOT as central 'namespace'; 17. Introduce context menu in 3D, use it for switch between 2D/3D modes; 18. Use own code to generate hierarchical structure in HTML, replace dtree.js which is; extremely slow for complex hierarchies. Dramatically improve performance for; structures with large (~1000) number of items.; 19. Deliver to the server title of the objects, display it as hint in the browser.; 20. Better handling of special characters in the hierarchies - allows to display; symbols like ' or "" in the file structure. ### July 2014; 1. Migration to d3.v3.js and jQuery v2.1.1; 2. Fix errors in filling of histogram statbox; 3. Possibility of move and resize of statbox, title, color palete; 4. Remove many (not all) global variables",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:75537,monitor,monitor,75537,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['monitor'],['monitor']
Energy Efficiency,".; hardcodedContiguousStorage(const SmallVectorImpl<Foo> &In);; // ENCOURAGED: Clients can pass any contiguous storage of Foo.; allowsAnyContiguousStorage(ArrayRef<Foo> In);. void someFunc1() {; Foo Vec[] = { /* ... */ };; hardcodedContiguousStorage(Vec); // Error.; allowsAnyContiguousStorage(Vec); // Works.; }. // DISCOURAGED: Clients cannot pass e.g. SmallVector<Foo, 8>.; hardcodedSmallSize(SmallVector<Foo, 2> &Out);; // ENCOURAGED: Clients can pass any SmallVector<Foo, N>.; allowsAnySmallSize(SmallVectorImpl<Foo> &Out);. void someFunc2() {; SmallVector<Foo, 8> Vec;; hardcodedSmallSize(Vec); // Error.; allowsAnySmallSize(Vec); // Works.; }. Even though it has ""``Impl``"" in the name, SmallVectorImpl is widely used; and is no longer ""private to the implementation"". A name like; ``SmallVectorHeader`` might be more appropriate. .. _dss_pagedvector:. llvm/ADT/PagedVector.h; ^^^^^^^^^^^^^^^^^^^^^^. ``PagedVector<Type, PageSize>`` is a random access container that allocates; ``PageSize`` elements of type ``Type`` when the first element of a page is; accessed via the ``operator[]``. This is useful for cases where the number of; elements is known in advance; their actual initialization is expensive; and; they are sparsely used. This utility uses page-granular lazy initialization; when the element is accessed. When the number of used pages is small; significant memory savings can be achieved. The main advantage is that a ``PagedVector`` allows to delay the actual; allocation of the page until it's needed, at the extra cost of one pointer per; page and one extra indirection when accessing elements with their positional; index. In order to minimise the memory footprint of this container, it's important to; balance the PageSize so that it's not too small (otherwise the overhead of the; pointer per page might become too high) and not too big (otherwise the memory; is wasted if the page is not fully used). Moreover, while retaining the order of the elements based on their insert",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:63109,allocate,allocates,63109,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocates']
Energy Efficiency,.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337556,reduce,reduce,337556,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,".d.f on the parameters of a model that; represents the result of a fit, from any RooFitResult object. RooAbsPdf* paramPdf = fitresult->createHessePdf(RooArgSet(a,b)) ;. The returned object is an instance of the newly added class RooMultiVarGaussian, that can; model correlated Gaussian distributions in an arbitrary number of dimensions, given a; vector of mean values and a covariance matrix. Class RooMultivarGaussian implements analytical; integration as well as analytical partial integrals over the first 31 dimensions (if you have; that many) and implements in effect internal generation strategy for its observables. A new tutorial macro rf608_fitresultaspdf.C has been added to illustrate the use MV Gaussians constructed from a RooFitResult; Improved functionality of RooFFTConvPdf; The FFT convolution operator p.d.f. class RooFFTConvPdf has been substantially upgraded; for improved performance has several new options. For the overflow buffering, which aims to reduce cylical spillover from the FFT convolution,; a choice of three algorithms is now provided:. Extend the p.d.f. somewhat beyond its original domain (the new default); Fill the buffer 50/50 with the value of the p.d.f at the upper/lower bound of the convolution observable (the previous default); Mirror the p.d.f. over the boundary. The new default algorithm provides a more sensible result for p.d.f.s with significant; spillover issues, provided that the p.d.f. can be continuated beyond its original domain.; Convolution in non-observables is also explicitly supported now. One can e.g. construct a p.d.f; of the form G(x) = Int[dy] ( F(x,y) (*) H(y) ). A new tutorial macro rf211_paramconv illustrates; how such convolutions can be constructed; It is now also possible to express FFT convolutions in terms of other observables than the; convolution observable itself. A common occurrence of that situation is a (circular) convolution a polar; angle theta, for a p.d.f. that is ultimately expressed in terms of cos(theta",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:11159,reduce,reduce,11159,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,1,['reduce'],['reduce']
Energy Efficiency,".h file with all the explicit template instances; // that will be needed at link time; #ifdef __CLING__. #pragma link C++ class MyClass1<float>+;; #pragma link C++ class MyClass1<double>+;; #pragma link C++ class MyClass2<float,int>+;; #pragma link C++ class MyClass2<float,double>+;; #pragma link C++ class MyClass3<float,int,TObject*>+;; #pragma link C++ class MyClass3<float,TEvent*,TObject*>+;. #endif; ```. ## The Default Constructor. ROOT object I/O requires every class to have either a default; constructor or an I/O constructor. A default constructor is a; constructor with zero parameters or with one or more parameters all with; default values. An I/O constructor is a constructor with exactly one; parameter which type is a pointer to one of the type marked as an 'io; constructor type'. We will come back to this context in a few; paragraphs. This default or I/O constructor is called whenever an object; is being read from a ROOT database. Be sure that you do not allocate any; space for embedded pointer objects in this constructor. This space will; be lost (memory leak) while reading in the object. For example:. ``` {.cpp}; class T49Event : public TObject {; private:; Int_t fId;; TCollection *fTracks;; ...; public:; // Error space for TList pointer will be lost; T49Event() { fId = 0; fTrack = new TList; }; // Correct default initialization of pointer; T49Event() { fId = 0; fTrack = 0; }; ...; };; ```. The memory will be lost because during reading of the object the pointer; will be set to the object it was pointing to at the time the object was; written. Create the `fTrack` list when you need it, e.g. when you start; filling the list or in a **not-default** constructor. ``` {.cpp}; ...; if (!fTrack) fTrack = new TList;; ...; ```. The constructor actually called by the ROOT I/O can be customized by; using the rootcling pragma:. ``` {.cpp}; #pragma link C++ ioctortype UserClass;; ```. For example, with this pragma and a class named MyClass, the ROOT I/O; will call the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md:11627,allocate,allocate,11627,documentation/users-guide/AddingaClass.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md,1,['allocate'],['allocate']
Energy Efficiency,".masked.scatter.v8i32.v8p0 (<8 x i32> <value>, <8 x ptr> <ptrs>, i32 <alignment>, <8 x i1> <mask>); declare void @llvm.masked.scatter.v16f32.v16p1(<16 x float> <value>, <16 x ptr addrspace(1)> <ptrs>, i32 <alignment>, <16 x i1> <mask>); declare void @llvm.masked.scatter.v4p0.v4p0 (<4 x ptr> <value>, <4 x ptr> <ptrs>, i32 <alignment>, <4 x i1> <mask>). Overview:; """""""""""""""""". Writes each element from the value vector to the corresponding memory address. The memory addresses are represented as a vector of pointers. Writing is done according to the provided mask. The mask holds a bit for each vector lane, and is used to prevent memory accesses to the masked-off lanes. Arguments:; """""""""""""""""""". The first operand is a vector value to be written to memory. The second operand is a vector of pointers, pointing to where the value elements should be stored. It has the same underlying type as the value operand. The third operand is an alignment of the destination addresses. It must be 0 or a power of two constant integer value. The fourth operand, mask, is a vector of boolean values. The types of the mask and the value operand must have the same number of vector elements. Semantics:; """""""""""""""""""". The '``llvm.masked.scatter``' intrinsics is designed for writing selected vector elements to arbitrary memory addresses in a single IR operation. The operation may be conditional, when not all bits in the mask are switched on. It is useful for targets that support vector masked scatter and allows vectorizing basic blocks with data and control divergence. Other targets may support this intrinsic differently, for example by lowering it into a sequence of branches that guard scalar store operations. ::. ;; This instruction unconditionally stores data vector in multiple addresses; call @llvm.masked.scatter.v8i32.v8p0(<8 x i32> %value, <8 x ptr> %ptrs, i32 4, <8 x i1> <true, true, .. true>). ;; It is equivalent to a list of scalar stores; %val0 = extractelement <8 x i32> %value, i32 0; %val1 = e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:853009,power,power,853009,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,".pid,""pid/I"");. //Initialize particle parameters at first point; Float_t px,py,pz,p,charge=0;; Float_t vout[7];; Float_t mass = 0.137;; Bool_t newParticle = kTRUE;; gstep.step = 0.1;; gstep.destep = 0;; gstep.nmec = 0;; gstep.pid = 0;. //transport particles; for (Int_t i=0; i<10000; i++) {; //generate a new particle if necessary (Geant3 emulation); if (newParticle) {; px = gRandom->Gaus(0,.02);; py = gRandom->Gaus(0,.02);; pz = gRandom->Gaus(0,.02);; p = TMath::Sqrt(px*px+py*py+pz*pz);; charge = 1;; if (gRandom->Rndm() < 0.5) charge = -1;; gstep.pid += 1;; gstep.vect[0] = 0;; gstep.vect[1] = 0;; gstep.vect[2] = 0;; gstep.vect[3] = px/p;; gstep.vect[4] = py/p;; gstep.vect[5] = pz/p;; gstep.vect[6] = p*charge;; gstep.getot = TMath::Sqrt(p*p + mass*mass);; gstep.gekin = gstep.getot - mass;; newParticle = kFALSE;; }; // fill the Tree with current step parameters; t2.Fill();. //transport particle in magnetic field (Geant3 emulation); helixStep(gstep.step, gstep.vect, vout);; //make one step; //apply energy loss; gstep.destep = gstep.step*gRandom->Gaus(0.0002,0.00001);; gstep.gekin -= gstep.destep;; gstep.getot = gstep.gekin + mass;; gstep.vect[6]= charge*TMath::Sqrt(gstep.getot*gstep.getot; - mass*mass);; gstep.vect[0] = vout[0];; gstep.vect[1] = vout[1];; gstep.vect[2] = vout[2];; gstep.vect[3] = vout[3];; gstep.vect[4] = vout[4];; gstep.vect[5] = vout[5];; gstep.nmec = (Int_t)(5*gRandom->Rndm());; for (Int_t l=0; l<gstep.nmec; l++) gstep.lmec[l] = l;; if (gstep.gekin < 0.001) newParticle = kTRUE;; if (TMath::Abs(gstep.vect[2]) > 30) newParticle = kTRUE;; }; //save the Tree header. The file will be automatically; // closed when going out of the function scope; t2.Write();; }; ```. #### Adding a Branch with a Fixed Length Array. At first, we create a tree and create branches for a subset of variables; in the C structure` Gctrak_t`. Then we add several types of branches.; The first branch reads seven floating-point values beginning at the; address of `'gstep.vect'`. You d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:47064,energy,energy,47064,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['energy'],['energy']
Energy Efficiency,".reduce.umax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umax``' intrinsic performs the unsigned-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.umax <int_vector_reduce_umax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``0`` (i.e. having no effect on the reduction operation). If the; vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umax.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umax.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_umin:. '``llvm.vp.reduce.umin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:768007,reduce,reduce,768007,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,".reduce.umin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umin``' intrinsic performs the unsigned-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.umin <int_vector_reduce_umin>`) of the; vector operand ``val`` on each enabled lane, taking the minimum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umin.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umin.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_fmax:. '``llvm.vp.reduce.fmax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:770075,reduce,reduce,770075,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,".size` intrinsic is lowered to a constant representing the size of; the coroutine frame. .. _coro.align:. 'llvm.coro.align' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i32 @llvm.coro.align.i32(); declare i64 @llvm.coro.align.i64(). Overview:; """""""""""""""""". The '``llvm.coro.align``' intrinsic returns the alignment of a `coroutine frame`_.; This is only supported for switched-resume coroutines. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". The `coro.align` intrinsic is lowered to a constant representing the alignment of; the coroutine frame. .. _coro.begin:. 'llvm.coro.begin' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.begin(token <id>, ptr <mem>). Overview:; """""""""""""""""". The '``llvm.coro.begin``' intrinsic returns an address of the coroutine frame. Arguments:; """""""""""""""""""". The first argument is a token returned by a call to '``llvm.coro.id``'; identifying the coroutine. The second argument is a pointer to a block of memory where coroutine frame; will be stored if it is allocated dynamically. This pointer is ignored; for returned-continuation coroutines. Semantics:; """""""""""""""""""". Depending on the alignment requirements of the objects in the coroutine frame; and/or on the codegen compactness reasons the pointer returned from `coro.begin`; may be at offset to the `%mem` argument. (This could be beneficial if; instructions that express relative access to data can be more compactly encoded; with small positive and negative offsets). A frontend should emit exactly one `coro.begin` intrinsic per coroutine. .. _coro.free:. 'llvm.coro.free' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare ptr @llvm.coro.free(token %id, ptr <frame>). Overview:; """""""""""""""""". The '``llvm.coro.free``' intrinsic returns a pointer to a block of memory where; coroutine frame is stored or `null` if this instance of a coroutine did not use; dynamically allocated memory for its coroutine frame. This intrinsic is not; supported for re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:32782,allocate,allocated,32782,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['allocate'],['allocated']
Energy Efficiency,".v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smax.*``' intrinsics do a signed integer; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smin:. '``llvm.vector.reduce.smin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smin.*``' intrinsics do a signed integer; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umax:. '``llvm.vector.reduce.umax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umax.*``' intrinsics do an unsigned; integer ``MAX`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umin:. '``llvm.vector.reduce.umin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umin.*``' intrinsics do an unsigned; integer ``MIN`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmax:. '``llvm.vector.reduce.fmax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:657589,reduce,reduce,657589,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"//. It appears gcc place string data with linkonce linkage in; .section __TEXT,__const_coal,coalesced instead of; .section __DATA,__const_coal,coalesced.; Take a look at darwin.h, there are other Darwin assembler directives that we; do not make use of. //===---------------------------------------------------------------------===//. define i32 @foo(i32* %a, i32 %t) {; entry:; 	br label %cond_true. cond_true:		; preds = %cond_true, %entry; 	%x.0.0 = phi i32 [ 0, %entry ], [ %tmp9, %cond_true ]		; <i32> [#uses=3]; 	%t_addr.0.0 = phi i32 [ %t, %entry ], [ %tmp7, %cond_true ]		; <i32> [#uses=1]; 	%tmp2 = getelementptr i32* %a, i32 %x.0.0		; <i32*> [#uses=1]; 	%tmp3 = load i32* %tmp2		; <i32> [#uses=1]; 	%tmp5 = add i32 %t_addr.0.0, %x.0.0		; <i32> [#uses=1]; 	%tmp7 = add i32 %tmp5, %tmp3		; <i32> [#uses=2]; 	%tmp9 = add i32 %x.0.0, 1		; <i32> [#uses=2]; 	%tmp = icmp sgt i32 %tmp9, 39		; <i1> [#uses=1]; 	br i1 %tmp, label %bb12, label %cond_true. bb12:		; preds = %cond_true; 	ret i32 %tmp7; }; is pessimized by -loop-reduce and -indvars. //===---------------------------------------------------------------------===//. u32 to float conversion improvement:. float uint32_2_float( unsigned u ) {; float fl = (int) (u & 0xffff);; float fh = (int) (u >> 16);; fh *= 0x1.0p16f;; return fh + fl;; }. 00000000 subl $0x04,%esp; 00000003 movl 0x08(%esp,1),%eax; 00000007 movl %eax,%ecx; 00000009 shrl $0x10,%ecx; 0000000c cvtsi2ss %ecx,%xmm0; 00000010 andl $0x0000ffff,%eax; 00000015 cvtsi2ss %eax,%xmm1; 00000019 mulss 0x00000078,%xmm0; 00000021 addss %xmm1,%xmm0; 00000025 movss %xmm0,(%esp,1); 0000002a flds (%esp,1); 0000002d addl $0x04,%esp; 00000030 ret. //===---------------------------------------------------------------------===//. When using fastcc abi, align stack slot of argument of type double on 8 byte; boundary to improve performance. //===---------------------------------------------------------------------===//. GCC's ix86_expand_int_movcc function (in i386.c) has a ton of inte",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:8767,reduce,reduce,8767,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['reduce'],['reduce']
Energy Efficiency,"//===----------------------------------------------------------------------===//; // Representing sign/zero extension of function results; //===----------------------------------------------------------------------===//. Mar 25, 2009 - Initial Revision. Most ABIs specify that functions which return small integers do so in a; specific integer GPR. This is an efficient way to go, but raises the question:; if the returned value is smaller than the register, what do the high bits hold?. There are three (interesting) possible answers: undefined, zero extended, or; sign extended. The number of bits in question depends on the data-type that; the front-end is referencing (typically i1/i8/i16/i32). Knowing the answer to this is important for two reasons: 1) we want to be able; to implement the ABI correctly. If we need to sign extend the result according; to the ABI, we really really do need to do this to preserve correctness. 2); this information is often useful for optimization purposes, and we want the; mid-level optimizers to be able to process this (e.g. eliminate redundant; extensions). For example, lets pretend that X86 requires the caller to properly extend the; result of a return (I'm not sure this is the case, but the argument doesn't; depend on this). Given this, we should compile this:. int a();; short b() { return a(); }. into:. _b:; 	subl	$12, %esp; 	call	L_a$stub; 	addl	$12, %esp; 	cwtl; 	ret. An optimization example is that we should be able to eliminate the explicit; sign extension in this example:. short y();; int z() {; return ((int)y() << 16) >> 16;; }. _z:; 	subl	$12, %esp; 	call	_y; 	;; movswl %ax, %eax -> not needed because eax is already sext'd; 	addl	$12, %esp; 	ret. //===----------------------------------------------------------------------===//; // What we have right now.; //===----------------------------------------------------------------------===//. Currently, these sorts of things are modelled by compiling a function to return; the small type a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendedIntegerResults.txt:360,efficient,efficient,360,interpreter/llvm-project/llvm/docs/ExtendedIntegerResults.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendedIntegerResults.txt,1,['efficient'],['efficient']
Energy Efficiency,"//===---------------------------------------------------------------------===//; // Random notes about and ideas for the SystemZ backend.; //===---------------------------------------------------------------------===//. The initial backend is deliberately restricted to z10. We should add support; for later architectures at some point. --. If an inline asm ties an i32 ""r"" result to an i64 input, the input; will be treated as an i32, leaving the upper bits uninitialised.; For example:. define void @f4(i32 *%dst) {; %val = call i32 asm ""blah $0"", ""=r,0"" (i64 103); store i32 %val, i32 *%dst; ret void; }. from CodeGen/SystemZ/asm-09.ll will use LHI rather than LGHI.; to load 103. This seems to be a general target-independent problem. --. The tuning of the choice between LOAD ADDRESS (LA) and addition in; SystemZISelDAGToDAG.cpp is suspect. It should be tweaked based on; performance measurements. --. There is no scheduling support. --. We don't use the BRANCH ON INDEX instructions. --. We only use MVC, XC and CLC for constant-length block operations.; We could extend them to variable-length operations too,; using EXECUTE RELATIVE LONG. MVCIN, MVCLE and CLCLE may be worthwhile too. --. We don't use CUSE or the TRANSLATE family of instructions for string; operations. The TRANSLATE ones are probably more difficult to exploit. --. We don't take full advantage of builtins like fabsl because the calling; conventions require f128s to be returned by invisible reference. --. ADD LOGICAL WITH SIGNED IMMEDIATE could be useful when we need to; produce a carry. SUBTRACT LOGICAL IMMEDIATE could be useful when we; need to produce a borrow. (Note that there are no memory forms of; ADD LOGICAL WITH CARRY and SUBTRACT LOGICAL WITH BORROW, so the high; part of 128-bit memory operations would probably need to be done; via a register.). --. We don't use ICM, STCM, or CLM. --. We don't use ADD (LOGICAL) HIGH, SUBTRACT (LOGICAL) HIGH,; or COMPARE (LOGICAL) HIGH yet. --. DAGCombiner doesn't yet f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/README.txt:920,schedul,scheduling,920,interpreter/llvm-project/llvm/lib/Target/SystemZ/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/README.txt,1,['schedul'],['scheduling']
Energy Efficiency,"//ci.appveyor.com/api/projects/status/github/civetweb/civetweb?svg=true)](https://ci.appveyor.com/project/civetweb/civetweb/branch/master). Test coverage check ([coveralls](https://coveralls.io/github/civetweb/civetweb), [codecov](https://codecov.io/gh/civetweb/civetweb/branch/master)) (using different tools/settings):. [![Coveralls](https://img.shields.io/coveralls/civetweb/civetweb.svg?maxAge=3600)](); [![Coverage Status](https://coveralls.io/repos/github/civetweb/civetweb/badge.svg?branch=master)](https://coveralls.io/github/civetweb/civetweb?branch=master). [![codecov](https://codecov.io/gh/civetweb/civetweb/branch/master/graph/badge.svg)](https://codecov.io/gh/civetweb/civetweb). Static source code analysis ([Coverity](https://scan.coverity.com/projects/5784)):. [![Coverity Scan Build Status](https://scan.coverity.com/projects/5784/badge.svg)](https://scan.coverity.com/projects/5784). Project Mission; -----------------. Project mission is to provide easy to use, powerful, C (C/C++) embeddable web server with optional CGI, SSL and Lua support.; CivetWeb has a MIT license so you can innovate without restrictions. CivetWeb can be used by developers as a library, to add web server functionality to an existing application. It can also be used by end users as a stand-alone web server running on a Windows or Linux PC. It is available as single executable, no installation is required. Where to find the official version?; -----------------------------------. End users can download CivetWeb binaries / releases from SourceForge; [https://sourceforge.net/projects/civetweb/](https://sourceforge.net/projects/civetweb/). Developers can contribute to CivetWeb via GitHub; [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb). Due to a [bug in Git for Windows V2.24](https://github.com/git-for-windows/git/issues/2435); CivetWeb must be used with an earlier or later version (see also [here](https://github.com/civetweb/civetweb/issues/812)). Trouble tickets sh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:1868,power,powerful,1868,net/http/civetweb/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md,1,['power'],['powerful']
Energy Efficiency,/Parser/parsing.cpp; flang/lib/Parser/preprocessor.cpp; flang/lib/Parser/preprocessor.h; flang/lib/Parser/prescan.cpp; flang/lib/Parser/prescan.h; flang/lib/Parser/program-parsers.cpp; flang/lib/Parser/provenance.cpp; flang/lib/Parser/source.cpp; flang/lib/Parser/stmt-parser.h; flang/lib/Parser/token-parsers.h; flang/lib/Parser/token-sequence.cpp; flang/lib/Parser/token-sequence.h; flang/lib/Parser/tools.cpp; flang/lib/Parser/type-parser-implementation.h; flang/lib/Parser/type-parsers.h; flang/lib/Parser/unparse.cpp; flang/lib/Parser/user-state.cpp; flang/lib/Semantics/assignment.cpp; flang/lib/Semantics/assignment.h; flang/lib/Semantics/attr.cpp; flang/lib/Semantics/canonicalize-acc.cpp; flang/lib/Semantics/canonicalize-acc.h; flang/lib/Semantics/canonicalize-do.cpp; flang/lib/Semantics/canonicalize-do.h; flang/lib/Semantics/canonicalize-omp.cpp; flang/lib/Semantics/canonicalize-omp.h; flang/lib/Semantics/check-acc-structure.cpp; flang/lib/Semantics/check-allocate.cpp; flang/lib/Semantics/check-allocate.h; flang/lib/Semantics/check-arithmeticif.cpp; flang/lib/Semantics/check-arithmeticif.h; flang/lib/Semantics/check-call.h; flang/lib/Semantics/check-case.cpp; flang/lib/Semantics/check-case.h; flang/lib/Semantics/check-coarray.cpp; flang/lib/Semantics/check-coarray.h; flang/lib/Semantics/check-data.cpp; flang/lib/Semantics/check-data.h; flang/lib/Semantics/check-deallocate.cpp; flang/lib/Semantics/check-deallocate.h; flang/lib/Semantics/check-declarations.h; flang/lib/Semantics/check-directive-structure.h; flang/lib/Semantics/check-do-forall.cpp; flang/lib/Semantics/check-do-forall.h; flang/lib/Semantics/check-if-stmt.cpp; flang/lib/Semantics/check-if-stmt.h; flang/lib/Semantics/check-io.cpp; flang/lib/Semantics/check-io.h; flang/lib/Semantics/check-namelist.cpp; flang/lib/Semantics/check-namelist.h; flang/lib/Semantics/check-nullify.cpp; flang/lib/Semantics/check-nullify.h; flang/lib/Semantics/check-omp-structure.cpp; flang/lib/Semantics/check-omp-structure.h; flan,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:121888,allocate,allocate,121888,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['allocate'],['allocate']
Energy Efficiency,/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llvm/tools/llvm-tapi-diff/llvm-tapi-diff.cpp; llvm/tools/llvm-undname/llvm-undname.cpp; llvm/tools/llvm-xray/func-id-helper.cpp; llvm/tools/llvm-xray/func-id-helper.h; llvm/tools/llvm-xray/llvm-xray.cpp; llvm/tools/llvm-xray/trie-node.h; llvm/tools/llvm-xray/xray-account.h; llvm/tools/llvm-xray/xray-color-helper.cpp; llvm/tools/llvm-xray/xray-color-helper.h; llvm/tools/llvm-xray/xray-converter.cpp; llvm/tools/llvm-xray/xray-converter.h; llvm/tools/llvm-xray/xray-fdr-dump.cpp;,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:339099,reduce,reduce,339099,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"/opt/SUNWspro/bin/cc -xarch=v9 hello.s -o hello.native # On Solaris. % gcc hello.s -o hello.native # On others. #. Execute the native code program:. .. code-block:: console. % ./hello.native. Note that using clang to compile directly to native code (i.e. when the; ``-emit-llvm`` option is not present) does steps 6/7/8 for you. Common Problems; ===============. If you are having problems building or using LLVM, or if you have any other; general questions about LLVM, please consult the `Frequently Asked; Questions <FAQ.html>`_ page. If you are having problems with limited memory and build time, please try; building with ninja instead of make. Please consider configuring the; following options with cmake:. * -G Ninja; Setting this option will allow you to build with ninja instead of make.; Building with ninja significantly improves your build time, especially with; incremental builds, and improves your memory usage. * -DLLVM_USE_LINKER; Setting this option to lld will significantly reduce linking time for LLVM; executables on ELF-based platforms, such as Linux. If you are building LLVM; for the first time and lld is not available to you as a binary package, then; you may want to use the gold linker as a faster alternative to GNU ld. * -DCMAKE_BUILD_TYPE; Controls optimization level and debug information of the build. This setting; can affect RAM and disk usage, see :ref:`CMAKE_BUILD_TYPE <cmake_build_type>`; for more information. * -DLLVM_ENABLE_ASSERTIONS; This option defaults to ON for Debug builds and defaults to OFF for Release; builds. As mentioned in the previous option, using the Release build type and; enabling assertions may be a good alternative to using the Debug build type. * -DLLVM_PARALLEL_LINK_JOBS; Set this equal to number of jobs you wish to run simultaneously. This is; similar to the -j option used with make, but only for link jobs. This option; can only be used with ninja. You may wish to use a very low number of jobs,; as this will greatly reduce th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:44477,reduce,reduce,44477,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['reduce'],['reduce']
Energy Efficiency,"0"") characters, and do not have a length; available efficiently. The general replacement for '``const char*``' is; StringRef. For more information on choosing string containers for APIs, please see; :ref:`Passing Strings <string_apis>`. .. _dss_stringref:. llvm/ADT/StringRef.h; ^^^^^^^^^^^^^^^^^^^^. The StringRef class is a simple value class that contains a pointer to a; character and a length, and is quite related to the :ref:`ArrayRef; <dss_arrayref>` class (but specialized for arrays of characters). Because; StringRef carries a length with it, it safely handles strings with embedded nul; characters in it, getting the length does not require a strlen call, and it even; has very convenient APIs for slicing and dicing the character range that it; represents. StringRef is ideal for passing simple strings around that are known to be live,; either because they are C string literals, std::string, a C array, or a; SmallVector. Each of these cases has an efficient implicit conversion to; StringRef, which doesn't result in a dynamic strlen being executed. StringRef has a few major limitations which make more powerful string containers; useful:. #. You cannot directly convert a StringRef to a 'const char*' because there is; no way to add a trailing nul (unlike the .c_str() method on various stronger; classes). #. StringRef doesn't own or keep alive the underlying string bytes.; As such it can easily lead to dangling pointers, and is not suitable for; embedding in datastructures in most cases (instead, use an std::string or; something like that). #. For the same reason, StringRef cannot be used as the return value of a; method if the method ""computes"" the result string. Instead, use std::string. #. StringRef's do not allow you to mutate the pointed-to string bytes and it; doesn't allow you to insert or remove bytes from the range. For editing; operations like this, it interoperates with the :ref:`Twine <dss_twine>`; class. Because of its strengths and limitations, it is very",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:72355,efficient,efficient,72355,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"1.3 for raw data files and around two on; most DST files is the optimum. The choice of one for the default is a; compromise between the time it takes to read and write the object vs.; the disk space savings. To specify no compression, set the level to zero. We recommend using compression when the time spent in I/O is small; compared to the total processing time. If the I/O operation is increased; by a factor of 5 it is still a small percentage of the total time and it; may compress the data by a factor of 10. On the other hand if the time; spend on I/O is large, compression may have a large impact on the; program's performance. The compression factor, i.e. the savings of disk space, varies with the; type of data. A buffer with a same value array is compressed so that the; value is only written once. For example, a track has the mass of a pion; that it is always the same, and the charge of the pion that is either; positive or negative. For 1000 pions, the mass will be written only; once, and the charge only twice (positive and negative). When the data; is sparse, i.e. when there are many zeros, the compression factor is; also high. +---------------------+------------------+-------------------+-------------------+; | Compression level | Bytes | Write Time (sec) | Read Time (sec.) |; +---------------------+------------------+-------------------+-------------------+; | 0 | 1,004,998 | 4.77 | 0.07 |; +---------------------+------------------+-------------------+-------------------+; | 1 | 438,366 | 6.67 | 0.05 |; +---------------------+------------------+-------------------+-------------------+; | 5 | 429,871 | 7.03 | 0.06 |; +---------------------+------------------+-------------------+-------------------+; | 9 | 426,899 | 8.47 | 0.05 |; +---------------------+------------------+-------------------+-------------------+. The time to uncompress an object is small compared to the compression; time and is independent of the selected compression level. Note that the; compres",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:92778,charge,charge,92778,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['charge'],['charge']
Energy Efficiency,"15. 123; NAD; 'Type categories' and qualified types; Yes. 124; C89; Casts to 'a void type' versus casts to 'the void type'; Yes. 125; NAD; Using things declared as 'extern (qualified) void'; Yes. 126; NAD; What does 'synonym' mean with respect to typedef names?; Yes. 127; Dup; Composite type of an enumerated type and an integral type; Duplicate of 13. 128; NAD; Editorial issue relating to tag declarations in type specifiers; Yes. 129; NAD; Tags and name spaces; Yes. 130; NAD; Guarantees when writing text to a stream; N/A. 131; C89; const member qualification and assignment; Yes. 132; Dup; Can undefined behavior occur at translation time, or only at run time?; Duplicate of 109. 133; NAD; Undefined behavior not previously listed in subclause G2; Yes. 134; NAD; What is an 'error number' for strerror?; N/A. 135; NAD; Can the size argument to 'fwrite' be zero?; N/A. 136; NAD; 'mktime' and time gaps; N/A. 137; NAD; 'printf' and negative floating point values; N/A. 138; C89; Is there an allocated storage duration?; Yes. 139; C89; Compatibility of complete and incomplete types; Yes. 140; NAD; Behavior of 'setvbuf'; N/A. 141; NAD; What is the meaning of EOF?; N/A. 142; C89; Reservation of macro names; Yes. 143; C89; 'fopen' modes; N/A. 144; C89; Preprocessing of preprocessing directives; Yes. 145; C89; Constant expressions; Unknown. 146; C89; Nugatory constraint; Yes. 147; C89; Sequence points in library functions; Yes. 148; NAD; Defining library functions; Yes. 149; C89; The term ""variable""; Yes. 150; C89; Initialization of a char array from a string literal; Yes. 151; C89; Behavior of 'printf' and flags; N/A. 152; NAD; Can you 'longjmp' out of a signal handler?; N/A. 153; Dup; Can 'f()' be considered a call to a function-like macro with one empty argument?; Duplicate of 3. 154; NAD; Consistency of implementation-defined values; Yes. 155; C89; Zero-sized allocations; N/A. 156; C89; Closed streams; N/A. 157; C89; Legitimacy of type synonyms; Yes. 158; C89; Null pointer conve",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html:9580,allocate,allocated,9580,interpreter/llvm-project/clang/www/c_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html,1,['allocate'],['allocated']
Energy Efficiency,"2 <len>,; i32 <element_size>); declare void @llvm.memset.element.unordered.atomic.p0.i64(ptr <dest>,; i8 <value>,; i64 <len>,; i32 <element_size>). Overview:; """""""""""""""""". The '``llvm.memset.element.unordered.atomic.*``' intrinsic is a specialization of the; '``llvm.memset.*``' intrinsic. It differs in that the ``dest`` is treated as an array; with elements that are exactly ``element_size`` bytes, and the assignment to that array; uses uses a sequence of :ref:`unordered atomic <ordering>` store operations; that are a positive integer multiple of the ``element_size`` in size. Arguments:; """""""""""""""""""". The first three arguments are the same as they are in the :ref:`@llvm.memset <int_memset>`; intrinsic, with the added constraint that ``len`` is required to be a positive integer; multiple of the ``element_size``. If ``len`` is not a positive integer multiple of; ``element_size``, then the behaviour of the intrinsic is undefined. ``element_size`` must be a compile-time constant positive power of two no greater than; target-specific atomic access size limit. The ``dest`` input pointer must have the ``align`` parameter attribute specified. It; must be a power of two no less than the ``element_size``. Caller guarantees that; the destination pointer is aligned to that boundary. Semantics:; """""""""""""""""""". The '``llvm.memset.element.unordered.atomic.*``' intrinsic sets the ``len`` bytes of; memory starting at the destination location to the given ``value``. The memory is; set with a sequence of store operations where each access is guaranteed to be a; multiple of ``element_size`` bytes wide and aligned at an ``element_size`` boundary. The order of the assignment is unspecified. Only one write is issued to the; destination buffer per element. It is well defined to have concurrent reads and; writes to the destination provided those reads and writes are unordered atomic; when specified. This intrinsic does not provide any additional ordering guarantees over those; provided by a set of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:964678,power,power,964678,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"2. System specific shared linker environment variables like; `LD_LIBRARY_PATH`, `LIBPATH`, or `PATH`.; 3. Setting from rootrc; 4. ROOT's builtin library directory. ### Interpreter. - cling's LLVM is upgraded to version 9.0; - New interface to enable/disable optional cling features. Currently, it can be used to enable/disable support for redefinitions. See [this](https://github.com/root-project/cling/issues/360) issue for more information. ### Multithreading. - Fix an uninitialized variable in global read-write lock which could have caused deadlocks or crashes in some rare cases.; - Default global read-write lock transitioned to new implementation based on TBB thread local storage when TBB is available on supported platforms (all except Windows). This gives an O(10%) performance improvement for some typical RDataFrame scenarios with 256 threads due to reduced lock contention. ## I/O Libraries. - Exclusive use of the global lock is reduced or migrated to finer grained read and write locks in a few hotspots that occur during file opening/closing or task initialization in RDataFrame. This can lead to O(100x) improvements for some typical RDataFrame scenarios with 256 threads due to massively reduced lock contention. ## TTree Libraries. - `TTree` now supports the inclusion of leaves of types `long` and `unsigned long` (and therefore also `std::size_t` on most systems) also for branches in ""leaflist mode"". The corresponding leaflist letters are 'G' and 'g'.; - when looping over a `TTree` with a friend with a larger number of entries, `TTreeReader` now ends the event loop when the entries in the _main_ `TTree` are exhausted, consistently with other interfaces. See [#6518](https://github.com/root-project/root/issues/6518) for more details.; - `TTreeProcessorMT::SetMaxTasksPerFilePerWorker` is now deprecated in favor of the more flexible and newly introduced `TTreeProcessorMT::SetTasksPerWorkerHint`. See the relevant entries in our reference guide for more information.; - The",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:4333,reduce,reduced,4333,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['reduce'],['reduced']
Energy Efficiency,"2.png). ![Fitted function](figures/image194.png). We have implemented the fitting function with matrix inversion based on; Stiefel-Hestens method of the solution of the system of linear equations; also for 2-dimensional data. The form of the function is as follows. ```{.cpp}; char* Fit2Stiefel(float **source,; TSpectrumTwoDimFit* p,; int sizex,; int sizey);; ```. This function fits the source spectrum. The calling program should; fill in the input parameters of the `two_dim_fit structure`. The fitted; parameters are written into structure pointed by `two_dim_fit` structure; pointer and fitted data are written back into the source spectrum. Function parameters:. - **`source`**: pointer to the matrix of the source spectrum; - **`p`**: pointer to the `two_dim_fit` structure pointer, see manual; - **`sizex`**: length x of the source spectrum; - **`sizey`**: length y of the source spectrum. The structure `two_dim_fit` is the same as in the awmi function. The; parameters power, `fit_taylor` are not applicable for this function. The results for small number of fitted parameters are the same as with; awmi function. However, it converges faster. The example for data given; in Figure 5.6 (38 parameters) is presented in the following table:. | # of iterations | Chi awmi | Chi-Stiefel |; | ---------------- | ---------| ------------ |; | 1 | 24.989 | 10.415 |; | 5 | 20.546 | 1.0553 |; | 10 | 6.256 | 0.84383 |; | 50 | 1.0985 | 0.64297 |; | 100 | 0.6571 | 0.64297 |; | 500 | 0.65194 | 0.64297 |. Again, Stiefel-Hestens method converges faster. However, its calculation; is for this number of parameters takes approximately 3 times longer. For; larger number of parameters the time needed to calculate the inversion; grows with the cube of the number of fitted parameters. For example, the; fit of large number of parameters (2068) for data in Figure 5.8 using awmi; algorithm took about 12 hours (using 450 MHz PC). The calculation; using matrix inversion method is not realizable in any rea",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:56762,power,power,56762,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['power'],['power']
Energy Efficiency,"26000 was deallocated by thread 31027 here:; | ...; | #7 ./a.out(main+0x83) [0x55585c0af7b3]; | #8 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7fecc966952b]; | #9 ./a.out(_start+0x2a) [0x55585c0867ba]; |; | 0x7feccab26000 was allocated by thread 31027 here:; | ...; | #12 ./a.out(main+0x57) [0x55585c0af787]; | #13 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7fecc966952b]; | #14 ./a.out(_start+0x2a) [0x55585c0867ba]; |; | *** End GWP-ASan report ***; | Segmentation fault. To symbolize these stack traces, some care has to be taken. Scudo currently uses; GNU's ``backtrace_symbols()`` from ``<execinfo.h>`` to unwind. The unwinder; provides human-readable stack traces in ``function+offset`` form, rather than; the normal ``binary+offset`` form. In order to use addr2line or similar tools to; recover the exact line number, we must convert the ``function+offset`` to; ``binary+offset``. A helper script is available at; ``compiler-rt/lib/gwp_asan/scripts/symbolize.sh``. Using this script will; attempt to symbolize each possible line, falling back to the previous output if; anything fails. This results in the following output:. .. code:: console. $ cat my_gwp_asan_error.txt | symbolize.sh; |; | *** GWP-ASan detected a memory error ***; | Use after free at 0x7feccab26000 (0 bytes into a 41-byte allocation at 0x7feccab26000) by thread 31027 here:; | ...; | #9 /usr/lib/gcc/x86_64-linux-gnu/8.0.1/../../../../include/c++/8.0.1/string_view:547; | #10 /tmp/buggy_code.cpp:8; |; | 0x7feccab26000 was deallocated by thread 31027 here:; | ...; | #7 /tmp/buggy_code.cpp:8; | #8 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7fecc966952b]; | #9 ./a.out(_start+0x2a) [0x55585c0867ba]; |; | 0x7feccab26000 was allocated by thread 31027 here:; | ...; | #12 /tmp/buggy_code.cpp:7; | #13 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7fecc966952b]; | #14 ./a.out(_start+0x2a) [0x55585c0867ba]; |; | *** End GWP-ASan report ***; | Segmentation fault; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:12046,allocate,allocated,12046,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['allocate'],['allocated']
Energy Efficiency,"3 25 jae 11f5 <main+0xb5>; 11d0: 48 89 df mov %rbx,%rdi; 11d3: ff 10 callq *(%rax); [...]; 11f5: 0f 0b ud2. If the bit vector consists of a single bit, there is only one possible; virtual table, and the check can consist of a single equality comparison:. .. code-block:: none. 9a2: 48 8b 03 mov (%rbx),%rax; 9a5: 48 8d 0d a4 13 00 00 lea 0x13a4(%rip),%rcx; 9ac: 48 39 c8 cmp %rcx,%rax; 9af: 75 25 jne 9d6 <main+0x86>; 9b1: 48 89 df mov %rbx,%rdi; 9b4: ff 10 callq *(%rax); [...]; 9d6: 0f 0b ud2. Virtual Table Layout; ~~~~~~~~~~~~~~~~~~~~. The compiler lays out classes of disjoint hierarchies in separate regions; of the object file. At worst, bit vectors in disjoint hierarchies only; need to cover their disjoint hierarchy. But the closer that classes in; sub-hierarchies are laid out to each other, the smaller the bit vectors for; those sub-hierarchies need to be (see ""Stripping Leading/Trailing Zeros in Bit; Vectors"" above). The `GlobalLayoutBuilder`_ class is responsible for laying; out the globals efficiently to minimize the sizes of the underlying bitsets. .. _GlobalLayoutBuilder: https://github.com/llvm/llvm-project/blob/main/llvm/include/llvm/Transforms/IPO/LowerTypeTests.h. Alignment; ~~~~~~~~~. If all gaps between address points in a particular bit vector are multiples; of powers of 2, the compiler can compress the bit vector by strengthening; the alignment requirements of the virtual table pointer. For example, given; this class hierarchy:. .. code-block:: c++. struct A {; virtual void f1();; virtual void f2();; };. struct B : A {; virtual void f1();; virtual void f2();; virtual void f3();; virtual void f4();; virtual void f5();; virtual void f6();; };. struct C : A {; virtual void f1();; virtual void f2();; };. The virtual tables will be laid out like this:. .. csv-table:: Virtual Table Layout for A, B, C; :header: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15. A::offset-to-top, &A::rtti, &A::f1, &A::f2, B::offset-to-top, &B::rtti, &B::f1, &B::f2, &B::f3, &",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:6817,efficient,efficiently,6817,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['efficient'],['efficiently']
Energy Efficiency,"32(<4 x float> %a); declare double @llvm.vector.reduce.fmaximum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmaximum.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maximum.*``'; intrinsic. That is, this intrinsic propagates NaNs and +0.0 is considered; greater than -0.0. If any element of the vector is a NaN, the result is NaN. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fminimum:. '``llvm.vector.reduce.fminimum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fminimum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fminimum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fminimum.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minimum.*``'; intrinsic. That is, this intrinsic propagates NaNs and -0.0 is considered less; than +0.0. If any element of the vector is a NaN, the result is NaN. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. '``llvm.vector.insert``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. ; Insert fixed type into scalable type; declare <vscale x 4 x float> @llvm.vector.insert.nxv4f32.v4f32(<vscale x 4 x float> %vec, <4 x float> %subvec, i64 <idx>); declare <vscale x 2 x double> @llvm.vector.insert.nxv2f64.v2f64(<vscale x 2 x double> %vec, <2 x double> %subvec, i64 <idx>). ; Insert scalable type into scalable type; declare <vscale x 4 x float> @llvm.ve",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:661743,reduce,reduce,661743,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"4 x float> @llvm.fma(<4 x float> %a, <4 x float> %b, <4 x float> %c); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_fmuladd:. '``llvm.vp.fmuladd.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.fmuladd.v16f32 (<16 x float> <left_op>, <16 x float> <middle_op>, <16 x float> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.fmuladd.nxv4f32 (<vscale x 4 x float> <left_op>, <vscale x 4 x float> <middle_op>, <vscale x 4 x float> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.fmuladd.v256f64 (<256 x double> <left_op>, <256 x double> <middle_op>, <256 x double> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point multiply-add of two vectors of floating-point values; that can be fused if code generator determines that (a) the target instruction; set has support for a fused operation, and (b) that the fused operation is more; efficient than the equivalent, separate pair of mul and add instructions. Arguments:; """""""""""""""""""". The first three operands and the result have the same vector of floating-point; type. The fourth operand is the vector mask and has the same number of elements; as the result vector type. The fifth operand is the explicit vector length of; the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.fmuladd``' intrinsic performs floating-point multiply-add (:ref:`llvm.fuladd <int_fmuladd>`); of the first, second, and third vector operand on each enabled lane. The result; on disabled lanes is a :ref:`poison value <poisonvalues>`. The operation is; performed in the default floating-point environment. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.fmuladd.v4f32(<4 x float> %a, <4 x float> %b, <4 x float> %c, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:747156,efficient,efficient,747156,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['efficient'],['efficient']
Energy Efficiency,"4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umax.*``' intrinsics do an unsigned; integer ``MAX`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umin:. '``llvm.vector.reduce.umin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umin.*``' intrinsics do an unsigned; integer ``MIN`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmax:. '``llvm.vector.reduce.fmax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmax.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmax.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmax.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maxnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with maximum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmin:. '``llvm.vector.reduce.fmin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an ov",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:658605,reduce,reduce,658605,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"5sbHZtLndnQGdtYWlsLmNvbQ>`__; - `Meeting details/agenda <https://docs.google.com/document/d/1ivYDSn_5ChTeiZ7TiO64WC_jYJnGwAUiT9Ngi9cAdFU/edit?usp=sharing>`__; * - GlobalISel; - Every 2nd Tuesday of the month; - `gcal <https://calendar.google.com/calendar/u/0?cid=ZDcyMjc0ZjZiZjNhMzFlYmE3NTNkMWM2MGM2NjM5ZWU3ZDE2MjM4MGFlZDc2ZjViY2UyYzMwNzVhZjk4MzQ4ZEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t>`__; - `Meeting details/agenda <https://docs.google.com/document/d/1Ry8O4-Tm5BFj9AMjr8qTQFU80z-ptiNQ62687NaIvLs/edit?usp=sharing>`__; * - Floating Point Working Group; - Every 3rd Wednesday of the month; - `gcal <https://calendar.google.com/calendar/u/0?cid=MDI1ODI1MDdiYWM3OWQxODY5MDA3MTI1NjZlYzNmYzY5YjMzYWMyNGQ3ZGUwYThjNzZjN2IxOTk3NmYxOTBjMEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t>`__; - `Meeting details/agenda: <https://docs.google.com/document/d/1QcmUlWftPlBi-Wz6b6PipqJfvjpJ-OuRMRnN9Dm2t0c>`__. .. _office-hours:. Office hours; ------------. A number of experienced LLVM contributors make themselves available for a chat; on a regular schedule, to anyone who is looking for some guidance. Please find; the list of who is available when, through which medium, and what their area of; expertise is. Don't be too shy to dial in!. The :doc:`CodeOfConduct` applies to all office hours. Of course, people take time off from time to time, so if you dial in and you; don't find anyone present, chances are they happen to be off that day. .. list-table:: LLVM office hours; :widths: 15 40 15 15 15; :header-rows: 1. * - Name; - In-scope topics; - When?; - Where?; - Languages; * - Kristof Beyls; - General questions on how to contribute to LLVM; organizing meetups;; submitting talks; and other general LLVM-related topics. Arm/AArch64; codegen. LLVM security group. LLVM Office Hours.; - Every 2nd and 4th Wednesday of the month at 9.30am CET, for 30 minutes.; `ics <https://calendar.google.com/calendar/ical/co0h4ndpvtfe64opn7eraiq3ac%40group.calendar.google.com/public/basic.ics>`__; - `Jitsi <https://meet.jit.si/Kristof",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingInvolved.rst:10101,schedul,schedule,10101,interpreter/llvm-project/llvm/docs/GettingInvolved.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingInvolved.rst,1,['schedul'],['schedule']
Energy Efficiency,"626/rf613__global_observables_8C.html) / [.py](https://root.cern/doc/v626/rf613__global_observables_8py.html) tutorial. ### Changes in `RooAbsPdf::fitTo` behaviour for multi-range fits. The `RooAbsPdf::fitTo` and `RooAbsPdf::createNLL` functions accept a command argument to specify the fit range.; One can also fit in multiple ranges simultaneously.; The definition of such multi-range likelihoods for non-extended fits changes in this release.; Previously, the individual likelihoods were normalized separately in each range, which meant that the relative number of events in each sub-range was not used to estimate the PDF parameters.; From now on, the likelihoods are normalized by the sum of integrals in each range. This implies that the likelihood takes into account all inter-range and intra-range information. ### Deprecation of the `RooMinuit` class. The `RooMinuit` class was the old interface between RooFit and minuit. With ROOT version 5.24, the more general `RooMinimizer` adapter was introduced, which became the default with ROOT 6.08. Before 6.26, it was possible to still use the `RooMinuit` by passing the `Minimizer(""OldMinuit"", ""minimizer"")` command argument to `RooAbsPdf::fitTo()`. This option is now removed. ### Increase of the `RooAbsArg` class version. The class version of `RooAbsArg` was incremented from 7 to 8 in this release. In some circumstances, this can cause warnings in `TStreamerInfo` for classes inheriting from `RooAbsArg` when reading; older RooFit models from a file. These warnings are harmless and can be avoided by incrementing also the class version of the inheriting class. ### Compile-time protection against creating empty `RooCmdArg`s from strings. The implicit [RooCmdArg](https://root.cern/doc/v626/classRooCmdArg.html) constructor from `const char*` was removed to avoid the accidental construction of meaningless RooCmdArgs that only have a name but no payload.; This causes new compiler errors in your code if you pass a string instead of a Roo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:30455,adapt,adapter,30455,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['adapt'],['adapter']
Energy Efficiency,"64, it is all of the integer registers.; - ``Q``: An 8, 16, 32, or 64-bit register which can be accessed as an 8-bit; ``h`` integer register. This is the ``a``, ``b``, ``c``, and ``d`` registers.; - ``r`` or ``l``: An 8, 16, 32, or 64-bit integer register.; - ``R``: An 8, 16, 32, or 64-bit ""legacy"" integer register -- one which has; existed since i386, and can be accessed without the REX prefix.; - ``f``: A 32, 64, or 80-bit '387 FPU stack pseudo-register.; - ``y``: A 64-bit MMX register, if MMX is enabled.; - ``v``: If SSE is enabled: a 32 or 64-bit scalar operand, or 128-bit vector; operand in a SSE register. If AVX is also enabled, can also be a 256-bit; vector operand in an AVX register. If AVX-512 is also enabled, can also be a; 512-bit vector operand in an AVX512 register. Otherwise, an error.; - ``Ws``: A symbolic reference with an optional constant addend or a label; reference.; - ``x``: The same as ``v``, except that when AVX-512 is enabled, the ``x`` code; only allocates into the first 16 AVX-512 registers, while the ``v`` code; allocates into any of the 32 AVX-512 registers.; - ``Y``: The same as ``x``, if *SSE2* is enabled, otherwise an error.; - ``A``: Special case: allocates EAX first, then EDX, for a single operand (in; 32-bit mode, a 64-bit integer operand will get split into two registers). It; is not recommended to use this constraint, as in 64-bit mode, the 64-bit; operand will get allocated only to RAX -- if two 32-bit operands are needed,; you're better off splitting it yourself, before passing it to the asm; statement. XCore:. - ``r``: A 32-bit integer register. .. _inline-asm-modifiers:. Asm template argument modifiers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In the asm template string, modifiers can be used on the operand reference, like; ""``${0:n}``"". The modifiers are, in general, expected to behave the same way they do in; GCC. LLVM's support is often implemented on an 'as-needed' basis, to support C; inline asm code which was supported by GCC. A",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:234047,allocate,allocates,234047,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['allocate'],['allocates']
Energy Efficiency,"64ISD::SMSTOP ...; t1: ch,glue = ISD::CALL ....; t2: res,ch,glue = CopyFromReg t1, ...; t3: ch,glue = AArch64ISD::SMSTART t2:1, .... <- this is now part of the expression that returns the result value.; t4: ch = CopyToReg t3, Register:f64 %vreg, t2; t5: res,ch = CopyFromReg t4, Register:f64 %vreg; t6: res = FADD t5, t9. We also need this for locally streaming functions, where an ``SMSTART`` needs to; be inserted into the DAG at the start of the function. Functions with __attribute__((arm_locally_streaming)); -----------------------------------------------------. If a function is marked as ``arm_locally_streaming``, then the runtime SVE; vector length in the prologue/epilogue may be different from the vector length; in the function's body. This happens because we invoke smstart after setting up; the stack-frame and similarly invoke smstop before deallocating the stack-frame. To ensure we use the correct SVE vector length to allocate the locals with, we; can use the streaming vector-length to allocate the stack-slots through the; ``ADDSVL`` instruction, even when the CPU is not yet in streaming mode. This only works for locals and not callee-save slots, since LLVM doesn't support; mixing two different scalable vector lengths in one stack frame. That means that the; case where a function is marked ``arm_locally_streaming`` and needs to spill SVE; callee-saves in the prologue is currently unsupported. However, it is unlikely; for this to happen without user intervention, because ``arm_locally_streaming``; functions cannot take or return vector-length-dependent values. This would otherwise; require forcing both the SVE PCS using '``aarch64_sve_pcs``' combined with using; ``arm_locally_streaming`` in order to encounter this problem. This combination; can be prevented in Clang through emitting a diagnostic. An example of how the prologue/epilogue would look for a function that is; attributed with ``arm_locally_streaming``:. .. code-block:: c++. #define N 64. void __attribut",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst:11447,allocate,allocate,11447,interpreter/llvm-project/llvm/docs/AArch64SME.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst,2,['allocate'],['allocate']
Energy Efficiency,86%`; * - clang-tools-extra/clang-tidy/tool; - `3`; - `2`; - `1`; - :part:`66%`; * - clang-tools-extra/clang-tidy/utils; - `35`; - `31`; - `4`; - :part:`88%`; * - clang-tools-extra/clang-tidy/zircon; - `3`; - `3`; - `0`; - :good:`100%`; * - clang-tools-extra/clangd; - `97`; - `81`; - `16`; - :part:`83%`; * - clang-tools-extra/clangd/benchmarks; - `1`; - `1`; - `0`; - :good:`100%`; * - clang-tools-extra/clangd/benchmarks/CompletionModel; - `1`; - `0`; - `1`; - :none:`0%`; * - clang-tools-extra/clangd/fuzzer; - `2`; - `2`; - `0`; - :good:`100%`; * - clang-tools-extra/clangd/index; - `39`; - `36`; - `3`; - :part:`92%`; * - clang-tools-extra/clangd/index/dex; - `9`; - `7`; - `2`; - :part:`77%`; * - clang-tools-extra/clangd/index/dex/dexp; - `1`; - `1`; - `0`; - :good:`100%`; * - clang-tools-extra/clangd/index/remote; - `2`; - `2`; - `0`; - :good:`100%`; * - clang-tools-extra/clangd/index/remote/marshalling; - `2`; - `2`; - `0`; - :good:`100%`; * - clang-tools-extra/clangd/index/remote/monitor; - `1`; - `1`; - `0`; - :good:`100%`; * - clang-tools-extra/clangd/index/remote/server; - `1`; - `1`; - `0`; - :good:`100%`; * - clang-tools-extra/clangd/index/remote/unimplemented; - `1`; - `1`; - `0`; - :good:`100%`; * - clang-tools-extra/clangd/indexer; - `1`; - `1`; - `0`; - :good:`100%`; * - clang-tools-extra/clangd/refactor; - `6`; - `5`; - `1`; - :part:`83%`; * - clang-tools-extra/clangd/refactor/tweaks; - `14`; - `10`; - `4`; - :part:`71%`; * - clang-tools-extra/clangd/support; - `25`; - `24`; - `1`; - :part:`96%`; * - clang-tools-extra/clangd/tool; - `2`; - `2`; - `0`; - :good:`100%`; * - clang-tools-extra/clangd/unittests; - `79`; - `66`; - `13`; - :part:`83%`; * - clang-tools-extra/clangd/unittests/decision_forest_model; - `1`; - `1`; - `0`; - :good:`100%`; * - clang-tools-extra/clangd/unittests/remote; - `1`; - `1`; - `0`; - :good:`100%`; * - clang-tools-extra/clangd/unittests/support; - `11`; - `11`; - `0`; - :good:`100%`; * - clang-tools-extra/clangd/unittests/tweaks;,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst:19440,monitor,monitor,19440,interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,1,['monitor'],['monitor']
Energy Efficiency,"9; DW_TAG_union_type = 23. For ``DW_TAG_array_type``, the ``elements:`` should be :ref:`subrange; descriptors <DISubrange>`, each representing the range of subscripts at that; level of indexing. The ``DIFlagVector`` flag to ``flags:`` indicates that an; array type is a native packed vector. The optional ``dataLocation`` is a; DIExpression that describes how to get from an object's address to the actual; raw data, if they aren't equivalent. This is only supported for array types,; particularly to describe Fortran arrays, which have an array descriptor in; addition to the array data. Alternatively it can also be DIVariable which; has the address of the actual raw data. The Fortran language supports pointer; arrays which can be attached to actual arrays, this attachment between pointer; and pointee is called association. The optional ``associated`` is a; DIExpression that describes whether the pointer array is currently associated.; The optional ``allocated`` is a DIExpression that describes whether the; allocatable array is currently allocated. The optional ``rank`` is a; DIExpression that describes the rank (number of dimensions) of fortran assumed; rank array (rank is known at runtime). For ``DW_TAG_enumeration_type``, the ``elements:`` should be :ref:`enumerator; descriptors <DIEnumerator>`, each representing the definition of an enumeration; value for the set. All enumeration type descriptors are collected in the; ``enums:`` field of the :ref:`compile unit <DICompileUnit>`. For ``DW_TAG_structure_type``, ``DW_TAG_class_type``, and; ``DW_TAG_union_type``, the ``elements:`` should be :ref:`derived types; <DIDerivedType>` with ``tag: DW_TAG_member``, ``tag: DW_TAG_inheritance``, or; ``tag: DW_TAG_friend``; or :ref:`subprograms <DISubprogram>` with; ``isDefinition: false``. .. _DISubrange:. DISubrange; """""""""""""""""""". ``DISubrange`` nodes are the elements for ``DW_TAG_array_type`` variants of; :ref:`DICompositeType`. - ``count: -1`` indicates an empty array.; - ``count: !",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:252981,allocate,allocated,252981,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['allocate'],['allocated']
Energy Efficiency,": ""-I"", Values: {""foo""}; Option 3 - Name: ""-I"", Values: {""foo""}; Option 4 - Name: ""<input>"", Values: {""t.c""}. After this stage is complete the command line should be broken down; into well defined option objects with their appropriate parameters.; Subsequent stages should rarely, if ever, need to do any string; processing. #. **Pipeline: Compilation Action Construction**. Once the arguments are parsed, the tree of subprocess jobs needed for; the desired compilation sequence are constructed. This involves; determining the input files and their types, what work is to be done; on them (preprocess, compile, assemble, link, etc.), and constructing; a list of Action instances for each task. The result is a list of one; or more top-level actions, each of which generally corresponds to a; single output (for example, an object or linked executable). The majority of Actions correspond to actual tasks, however there are; two special Actions. The first is InputAction, which simply serves to; adapt an input argument for use as an input to other Actions. The; second is BindArchAction, which conceptually alters the architecture; to be used for all of its input Actions. The clang driver can dump the results of this stage using the; ``-ccc-print-phases`` flag. For example:. .. code-block:: console. $ clang -ccc-print-phases -x c t.c -x assembler t.s; 0: input, ""t.c"", c; 1: preprocessor, {0}, cpp-output; 2: compiler, {1}, assembler; 3: assembler, {2}, object; 4: input, ""t.s"", assembler; 5: assembler, {4}, object; 6: linker, {3, 5}, image. Here the driver is constructing seven distinct actions, four to; compile the ""t.c"" input into an object file, two to assemble the; ""t.s"" input, and one to link them together. A rather different compilation pipeline is shown here; in this; example there are two top level actions to compile the input files; into two separate object files, where each object file is built using; ``lipo`` to merge results built for two separate architectures. .. code-blo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst:6640,adapt,adapt,6640,interpreter/llvm-project/clang/docs/DriverInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst,1,['adapt'],['adapt']
Energy Efficiency,": GOFF mangling: Private symbols get a ``@`` prefix.; * ``m``: Mips mangling: Private symbols get a ``$`` prefix.; * ``o``: Mach-O mangling: Private symbols get ``L`` prefix. Other; symbols get a ``_`` prefix.; * ``x``: Windows x86 COFF mangling: Private symbols get the usual prefix.; Regular C symbols get a ``_`` prefix. Functions with ``__stdcall``,; ``__fastcall``, and ``__vectorcall`` have custom mangling that appends; ``@N`` where N is the number of bytes used to pass parameters. C++ symbols; starting with ``?`` are not mangled in any way.; * ``w``: Windows COFF mangling: Similar to ``x``, except that normal C; symbols do not receive a ``_`` prefix.; * ``a``: XCOFF mangling: Private symbols get a ``L..`` prefix.; ``n<size1>:<size2>:<size3>...``; This specifies a set of native integer widths for the target CPU in; bits. For example, it might contain ``n32`` for 32-bit PowerPC,; ``n32:64`` for PowerPC 64, or ``n8:16:32:64`` for X86-64. Elements of; this set are considered to support most general arithmetic operations; efficiently.; ``ni:<address space0>:<address space1>:<address space2>...``; This specifies pointer types with the specified address spaces; as :ref:`Non-Integral Pointer Type <nointptrtype>` s. The ``0``; address space cannot be specified as non-integral. On every specification that takes a ``<abi>:<pref>``, specifying the; ``<pref>`` alignment is optional. If omitted, the preceding ``:``; should be omitted too and ``<pref>`` will be equal to ``<abi>``. When constructing the data layout for a given target, LLVM starts with a; default set of specifications which are then (possibly) overridden by; the specifications in the ``datalayout`` keyword. The default; specifications are given in this list:. - ``e`` - little endian; - ``p:64:64:64`` - 64-bit pointers with 64-bit alignment.; - ``p[n]:64:64:64`` - Other address spaces are assumed to be the; same as the default address space.; - ``S0`` - natural stack alignment is unspecified; - ``i1:8:8`` - i1 is ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:136473,efficient,efficiently,136473,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['efficient'],['efficiently']
Energy Efficiency,":; """""""""""""""""""". The argument and return value are floating-point numbers of the same type. Semantics:; """""""""""""""""""". Return the same value as a corresponding libm '``sqrt``' function but without; trapping or setting ``errno``. For types specified by IEEE-754, the result; matches a conforming libm implementation. When specified with the fast-math-flag 'afn', the result may be approximated; using a less accurate calculation. '``llvm.powi.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.powi`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. Generally, the only supported type for the exponent is the one matching; with the C type ``int``. ::. declare float @llvm.powi.f32.i32(float %Val, i32 %power); declare double @llvm.powi.f64.i16(double %Val, i16 %power); declare x86_fp80 @llvm.powi.f80.i32(x86_fp80 %Val, i32 %power); declare fp128 @llvm.powi.f128.i32(fp128 %Val, i32 %power); declare ppc_fp128 @llvm.powi.ppcf128.i32(ppc_fp128 %Val, i32 %power). Overview:; """""""""""""""""". The '``llvm.powi.*``' intrinsics return the first operand raised to the; specified (positive or negative) power. The order of evaluation of; multiplications is not defined. When a vector of floating-point type is; used, the second argument remains a scalar integer value. Arguments:; """""""""""""""""""". The second argument is an integer power, and the first is a value to; raise to that power. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power with an; unspecified sequence of rounding operations. '``llvm.sin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.sin`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @llvm.sin.f32(float %Val); declare double @llvm.sin.f64(double %Val); declare x86_fp80 @llvm.sin.f80(x86_fp80 %Val); declare ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:558189,power,power,558189,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,":Notify()`***. When building in interactive application the use of the **`TRint`**; object handles the `kSigInterrupt` signal. It causes the printing of the; message: ***`*** Break *** keyboard interrupt `***and makes a long jump; back to the ROOT command prompt. If no **`TRint`** object is created,; there will be no `kSigInterrupt` handling. All signals can be reset to; their default UNIX behavior via the call of; **`TSytem`**`::ResetSignal()`. All signals can be ignored via; `TSytem::IgnoreSignal()`. The **`TSytem::IgnoreInterrupt()`** is a method; to toggle the handling of the interrupt signal. Typically it is called; to prevent a `SIGINT` to interrupt some important call (like writing to; a ROOT file). If **`TRint`** is used and the default ROOT interrupt handler is not; desired, you should use `GetSignalHandler()` of **`TApplication`** to; get the interrupt handler and to remove it by `RemoveSignalHandler()`of; **`TSystem`** . ## Glossary. The following glossary is adapted from the description of the Rogue Wave; `Threads.h`++ package. A **`process`** is a program that is loaded into memory and prepared for; execution. Each process has a private address space. Processes begin; with a single thread. A **`thread`** is a sequence of instructions being executed in a; program. A thread has a program counter and a private stack to keep; track of local variables and return addresses. A multithreaded process; is associated with one or more threads. Threads execute independently.; All threads in a given process share the private address space of that; process. **`Concurrency`** exists when at least two threads are in progress at; the same time. A system with only a single processor can support; concurrency by switching execution contexts among multiple threads. **`Parallelism`** arises when at least two threads are executing; simultaneously. This requires a system with multiple processors.; Parallelism implies concurrency, but not vice-versa. A function is **`reentrant`*",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:19570,adapt,adapted,19570,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,1,['adapt'],['adapted']
Energy Efficiency,:`100%`; * - mlir/include/mlir/Target/LLVMIR/Dialect/AMX; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/include/mlir/Target/LLVMIR/Dialect/ArmNeon; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/include/mlir/Target/LLVMIR/Dialect/ArmSVE; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/include/mlir/Target/LLVMIR/Dialect/LLVMIR; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/include/mlir/Target/LLVMIR/Dialect/NVVM; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/include/mlir/Target/LLVMIR/Dialect/OpenACC; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/include/mlir/Target/LLVMIR/Dialect/OpenMP; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/include/mlir/Target/LLVMIR/Dialect/ROCDL; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/include/mlir/Target/LLVMIR/Dialect/X86Vector; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/include/mlir/Target/SPIRV; - `3`; - `3`; - `0`; - :good:`100%`; * - mlir/include/mlir/Tools/mlir-lsp-server; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/include/mlir/Tools/mlir-reduce; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/include/mlir/Tools/PDLL/AST; - `4`; - `2`; - `2`; - :part:`50%`; * - mlir/include/mlir/Tools/PDLL/CodeGen; - `2`; - `2`; - `0`; - :good:`100%`; * - mlir/include/mlir/Tools/PDLL/ODS; - `4`; - `4`; - `0`; - :good:`100%`; * - mlir/include/mlir/Tools/PDLL/Parser; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/include/mlir/Transforms; - `9`; - `7`; - `2`; - :part:`77%`; * - mlir/include/mlir-c; - `15`; - `15`; - `0`; - :good:`100%`; * - mlir/include/mlir-c/Bindings/Python; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/include/mlir-c/Dialect; - `11`; - `11`; - `0`; - :good:`100%`; * - mlir/lib/Analysis; - `7`; - `7`; - `0`; - :good:`100%`; * - mlir/lib/Analysis/AliasAnalysis; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/lib/Analysis/Presburger; - `8`; - `8`; - `0`; - :good:`100%`; * - mlir/lib/Bindings/Python; - `23`; - `23`; - `0`; - :good:`100%`; * - mlir/lib/Bindings/Python/Conversions; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/lib/Bin,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst:107292,reduce,reduce,107292,interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,1,['reduce'],['reduce']
Energy Efficiency,":`llvm.get.fpmode.i32 <int_get_fpmode>` The natural floating-point mode type is i32. This; implemented by extracting relevant bits out of the MODE; register with s_getreg_b32. The first 10 bits are the; core floating-point mode. Bits 12:18 are the exception; mask. On gfx9+, bit 23 is FP16_OVFL. Bitfields not; relevant to floating-point instructions are 0s. :ref:`llvm.get.rounding<int_get_rounding>` AMDGPU supports two separately controllable rounding; modes depending on the floating-point type. One; controls float, and the other controls both double and; half operations. If both modes are the same, returns; one of the standard return values. If the modes are; different, returns one of :ref:`12 extended values; <amdgpu-rounding-mode-enumeration-values-table>`; describing the two modes. To nearest, ties away from zero is not a supported; mode. The raw rounding mode values in the MODE; register do not exactly match the FLT_ROUNDS values,; so a conversion is performed. llvm.amdgcn.wave.reduce.umin Performs an arithmetic unsigned min reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.wave.reduce.umax Performs an arithmetic unsigned max reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.udot2 Provides direct access to v_dot2_u32_u16 across targets which; support such instructions. This ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:38245,reduce,reduce,38245,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['reduce'],['reduce']
Energy Efficiency,":cout << sv;; 9: }. Compiling this code with Scudo+GWP-ASan will probabilistically catch this bug; and provide us a detailed error report:. .. code:: console. $ clang++ -fsanitize=scudo -g buggy_code.cpp; $ for i in `seq 1 500`; do; SCUDO_OPTIONS=""GWP_ASAN_SampleRate=100"" ./a.out > /dev/null;; done; |; | *** GWP-ASan detected a memory error ***; | Use after free at 0x7feccab26000 (0 bytes into a 41-byte allocation at 0x7feccab26000) by thread 31027 here:; | ...; | #9 ./a.out(_ZStlsIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_St17basic_string_viewIS3_S4_E+0x45) [0x55585c0afa55]; | #10 ./a.out(main+0x9f) [0x55585c0af7cf]; | #11 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7fecc966952b]; | #12 ./a.out(_start+0x2a) [0x55585c0867ba]; |; | 0x7feccab26000 was deallocated by thread 31027 here:; | ...; | #7 ./a.out(main+0x83) [0x55585c0af7b3]; | #8 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7fecc966952b]; | #9 ./a.out(_start+0x2a) [0x55585c0867ba]; |; | 0x7feccab26000 was allocated by thread 31027 here:; | ...; | #12 ./a.out(main+0x57) [0x55585c0af787]; | #13 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7fecc966952b]; | #14 ./a.out(_start+0x2a) [0x55585c0867ba]; |; | *** End GWP-ASan report ***; | Segmentation fault. To symbolize these stack traces, some care has to be taken. Scudo currently uses; GNU's ``backtrace_symbols()`` from ``<execinfo.h>`` to unwind. The unwinder; provides human-readable stack traces in ``function+offset`` form, rather than; the normal ``binary+offset`` form. In order to use addr2line or similar tools to; recover the exact line number, we must convert the ``function+offset`` to; ``binary+offset``. A helper script is available at; ``compiler-rt/lib/gwp_asan/scripts/symbolize.sh``. Using this script will; attempt to symbolize each possible line, falling back to the previous output if; anything fails. This results in the following output:. .. code:: console. $ cat my_gwp_asan_error.txt | symbolize.sh; |; |",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:10537,allocate,allocated,10537,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['allocate'],['allocated']
Energy Efficiency,":list`` also only supports bidirectional iteration, not random access; iteration. In exchange for this high cost, std::list supports efficient access to both ends; of the list (like ``std::deque``, but unlike ``std::vector`` or; ``SmallVector``). In addition, the iterator invalidation characteristics of; std::list are stronger than that of a vector class: inserting or removing an; element into the list does not invalidate iterator or pointers to other elements; in the list. .. _dss_ilist:. llvm/ADT/ilist.h; ^^^^^^^^^^^^^^^^. ``ilist<T>`` implements an 'intrusive' doubly-linked list. It is intrusive,; because it requires the element to store and provide access to the prev/next; pointers for the list. ``ilist`` has the same drawbacks as ``std::list``, and additionally requires an; ``ilist_traits`` implementation for the element type, but it provides some novel; characteristics. In particular, it can efficiently store polymorphic objects,; the traits class is informed when an element is inserted or removed from the; list, and ``ilist``\ s are guaranteed to support a constant-time splice; operation. An ``ilist`` and an ``iplist`` are ``using`` aliases to one another and the; latter only currently exists for historical purposes. These properties are exactly what we want for things like ``Instruction``\ s and; basic blocks, which is why these are implemented with ``ilist``\ s. Related classes of interest are explained in the following subsections:. * :ref:`ilist_traits <dss_ilist_traits>`. * :ref:`llvm/ADT/ilist_node.h <dss_ilist_node>`. * :ref:`Sentinels <dss_ilist_sentinel>`. .. _dss_packedvector:. llvm/ADT/PackedVector.h; ^^^^^^^^^^^^^^^^^^^^^^^. Useful for storing a vector of values using only a few number of bits for each; value. Apart from the standard operations of a vector-like container, it can; also perform an 'or' set operation. For example:. .. code-block:: c++. enum State {; None = 0x0,; FirstCondition = 0x1,; SecondCondition = 0x2,; Both = 0x3; };. State get",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:66995,efficient,efficiently,66995,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficiently']
Energy Efficiency,"; # Foreword #. ## What M is intended to do ##. M is conceived as a tool to find the minimum value of a multi-parameter; function (the ""$\mbox{FCN}$"") and analyze the shape of the function; around the minimum. The principal application is foreseen for; statistical analysis, working on chisquare or log-likelihood functions,; to compute the best-fit parameter values and uncertainties, including; correlations between the parameters. It is especially suited to handle; difficult problems, including those which may require guidance in order; to find the correct solution. ## What M is not intended to do ##. Although M will of course solve easy problems faster than complicated; ones, it is not intended for the repeated solution of identically; parametrized problems (such as track fitting in a detector) where a; specialized program will in general be much more efficient. ## Further remarks ##. M was initially written in Fortran around 1975-1980 at CERN by Fred; James @bib-MINUIT. Its main field of usage is statistical data analysis; of experimental data recorded at CERN, but it is also used by people; doing data analysis outside CERN or outside high energy physics (HEP).; In 2002 Fred James started a project aiming to re-implement M in an; object-oriented way using . More information about recent developments, releases and installation; can be obtained from the M homepage @bib-C++MINUIT. The names of M applications are written in capital letters (e.g.; $\mbox{MIGRAD}$, $\mbox{MINOS}$, $\mbox{CONTOURS}$), the; corresponding names of the classes are written using sans-serif font; type (MnMigrad, MnMinos, MnContours). # Introduction: M basic concepts #. [sec:intro]. ## The organization of M ##. The M package acts on a multiparameter *objective function* which is; called — for historical reasons — the $\mbox{FCN}$ function (see; [howto:fcn]). This function is usually a chisquared or a log–likelihood,; but it could also be a mathematical function. The $\mbox{FCN}$; function needs ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:864,efficient,efficient,864,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['efficient'],['efficient']
Energy Efficiency,"; ## Platform Support. Temporarily for version 6.00/00, ROOT has a reduced set of supported; platforms. Most notably Windows is not supported until at least 6.02.; 6.00/00 supports only. - Linux 32 bit and 64 bit, i32 and x86-64 and x32 (see below).; - OSX 64 bit on x86-64. More platforms are expected to be available later; the lack of support; stems from Cling and Clang/LLVM not being ported to these platforms yet. To aleviate the pain for Windows users who want to try ROOT 6 we provide; a recipe on how to run ROOT 6 in a VM on Windows. Building ROOT also requires a C++11 compatible compiler, so one needs to either have installed gcc >= 4.8 or Clang >= 3.4. On most lecagy platforms these newer compilers are available via a special install.; See the [build prerequisites](https://root.cern/install/dependencies/) page. Despite that, an additional platform as been added: the [x32; psAPI](https://sites.google.com/site/x32abi/), called linuxx32gcc. It is; a regular x86-64 ABI but with shorter pointers (4 bytes instead of 8).; This reduces the addressable memory per process to 4GB - but that is; usally sufficient. The advantages are reduced memory consumption (due to; the smaller pointers) and increased performance compared to 32 bit; applications due to the availability of the 64 bit instructions. The; Clang developers mailing list archive [contains a good; comparison](http://clang-developers.42468.n3.nabble.com/Re-PATCH-add-x32-psABI-support-td4024297.html). To build and run binaries compiled in x32, toolchain support is needed.; That is available in the in binutils (2.22), GCC (4.8), glibc (2.16),; Linux kernel (3.4) and even GDB (7.5). These versions are not available; in regular distributions yet (except for [this beta Gentoo; distro](http://dev.gentoo.org/~vapier/x32/stage3-amd64-x32-20120605.tar.xz); built in x32); once they are, building and running x86-64 and x32; side-by-side will be possible. ## Build System; ROOT 6.00/00 can be built either using the classic "".",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md:67,reduce,reduced,67,core/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md,1,['reduce'],['reduced']
Energy Efficiency,"; %d = call float @fabsf(float %x); ret float %d; }. //===---------------------------------------------------------------------===//. This IR (from PR6194):. target datalayout = ""e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v64:64:64-v128:128:128-a0:0:64-s0:64:64-f80:128:128-n8:16:32:64-S128""; target triple = ""x86_64-apple-darwin10.0.0"". %0 = type { double, double }; %struct.float3 = type { float, float, float }. define void @test(%0, %struct.float3* nocapture %res) nounwind noinline ssp {; entry:; %tmp18 = extractvalue %0 %0, 0 ; <double> [#uses=1]; %tmp19 = bitcast double %tmp18 to i64 ; <i64> [#uses=1]; %tmp20 = zext i64 %tmp19 to i128 ; <i128> [#uses=1]; %tmp10 = lshr i128 %tmp20, 32 ; <i128> [#uses=1]; %tmp11 = trunc i128 %tmp10 to i32 ; <i32> [#uses=1]; %tmp12 = bitcast i32 %tmp11 to float ; <float> [#uses=1]; %tmp5 = getelementptr inbounds %struct.float3* %res, i64 0, i32 1 ; <float*> [#uses=1]; store float %tmp12, float* %tmp5; ret void; }. Compiles to:. _test: ## @test; 	movd	%xmm0, %rax; 	shrq	$32, %rax; 	movl	%eax, 4(%rdi); 	ret. This would be better kept in the SSE unit by treating XMM0 as a 4xfloat and; doing a shuffle from v[1] to v[0] then a float store. //===---------------------------------------------------------------------===//. [UNSAFE FP]. void foo(double, double, double);; void norm(double x, double y, double z) {; double scale = __builtin_sqrt(x*x + y*y + z*z);; foo(x/scale, y/scale, z/scale);; }. We currently generate an sqrtsd and 3 divsd instructions. This is bad, fp div is; slow and not pipelined. In -ffast-math mode we could compute ""1.0/scale"" first; and emit 3 mulsd in place of the divs. This can be done as a target-independent; transform. If we're dealing with floats instead of doubles we could even replace the sqrtss; and inversion with an rsqrtss instruction, which computes 1/sqrt faster at the; cost of reduced accuracy. //===---------------------------------------------------------------------===//; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:22592,reduce,reduced,22592,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,1,['reduce'],['reduced']
Energy Efficiency,"; 'asctime' limits; N/A. 218; C99; Signs of non-numeric floating point values; Yes. 219; NAD; Effective types; Yes. 220; C99; Definition of ""decimal integer""; N/A. 221; NAD; Lacuna in pointer arithmetic; Yes. 222; C99; Partially initialized structures; Yes. 223; C99; 'FP_FAST_FMAF' and 'FP_FAST_FMAL' should be integer constant; N/A. 224; C99; fpclassify return is not defined; N/A. 225; C99; strtod, strtof and strtold expected form of the subject sequence; N/A. 226; NAD; strftime references; N/A. 227; NAD; strftime %U, %V, and %W conversion specifiers; N/A. 228; C99; wmemcmp declaration in Annex B; N/A. 229; C99; localeconv() *_sep_by_space table entries issues; N/A. 230; C99; Enumerated type rank; Yes. 231; NAD; Semantics of text-line and non-directive; No. 232; C99; Typo in Annex I; N/A. 233; C99; %g, %G precision specification; N/A. 234; C99; Miscellaneous Typos; Yes. 235; C99; ""C"" locale collating behaviour not defined; N/A. 236; NAD; The interpretation of type based aliasing rule when applied to union objects or allocated objects; Unknown. 237; NAD; Declarations using [static]; No. 238; C99; Decriptions of fma() overflow and underflow errors are missing; N/A. 239; C99; Annex F nexttoward description is inconsistent with 7.12.11.4 and F.9.8.3; N/A. 240; C99; lrint, llrint, lround, llround, and ilogb descriptions are not consistent for unrepresentable results; N/A. 241; C99; Make the base standard and Annex F consistent for pow(0, <0); N/A. 242; C99; Make the base standard and Annex F consistent for logb(0); N/A. 243; C99; Make the base standard and Annex F consistent for fmod(), remainder(), and remquo() for a zero divisor; N/A. 244; C99; tgamma(zero or negative integer) should be considered a pole error; N/A. 245; C99; Missing paragraph numbers; Yes. 246; NAD; Completion of declarators; Yes. 247; C99; Are values a form of behaviour?; Yes. 248; C99; Limits are required for optional types; Yes. 249; Dup; Lacuna applying C89:TC1 to C99; Duplicate of 9. 250; C99; No",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html:13856,allocate,allocated,13856,interpreter/llvm-project/clang/www/c_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html,1,['allocate'],['allocated']
Energy Efficiency,"; * - `Compiler Research - Calling C++ libraries from a D-written DSL: A cling/cppyy-based approach <https://www.youtube.com/watch?v=7teqrCNzrD8>`_; - *Alexandru Militaru* 2021 Compiler-Research Meeting; - This video presents D and C++ interoperability through SIL-Cling architecture. .. list-table:: Interactive CUDA C++ with Cling:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Adding CUDA® Support to Cling: JIT Compile to GPUs <https://www.youtube.com/watch?v=XjjZRhiFDVs>`_; - *Simeon Ehrig* 2020 LLVM Developer Meeting; - Interactive CUDA-C++ through Cling is presented. Cling-CUDA architecture is discussed in detail, and an example of interactive simulation for laser plasma applications is shown. . .. list-table:: C++ in Jupyter Notebook - Xeus Cling:; :widths: 25 25 50; :header-rows: 1; ; * - Link; - Info ; - Description; * - `Interactive C++ code development using C++Explorer and GitHub Classroom for educational purposes <https://www.youtube.com/watch?v=HBgF2Yr0foA>`_; - *Patrick Diehl* 2020 Youtube; - C++Explorer is a novel teaching environment based on Jupyterhub and Cling, adapted to teaching C++ programming and source code management.; * - `Deep dive into the Xeus-based Cling kernel for Jupyter <https://www.youtube.com/watch?v=kx3wvKk4Qss>`_; - *Vassil Vassilev* 2021 Youtube; - Xeus-Cling is a Cling-based notebook kernel which delivers interactive C++. ; * - `Xeus-Cling: Run C++ code in Jupyter Notebook <https://www.youtube.com/watch?v=4fcKlJ_5QQk>`_ ; - *LearnOpenCV* 2019 Youtube; - In this demo, you will learn an example of C++ code in Jupyter Notebook using Xeus-Cling kernel. . .. list-table:: Clad:; :widths: 25 25 50; :header-rows: 1; ; * - Link; - Info ; - Description; * - `Clad: Automatic differentiation plugin for C++ <https://clad.readthedocs.io/en/latest/index.html>`_ ; - Read The Docs webpage; - Clad is a plugin for Cling. It allows to perform Automatic Differentiation (AD) on multivariate functions and functor objects. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:6976,adapt,adapted,6976,interpreter/cling/docs/chapters/references.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst,1,['adapt'],['adapted']
Energy Efficiency,"; - TDecompChol: The Cholesky decomposition class, which decomposes a symmetric, positive definite matrix `A = U^T * U` where `U` is a upper triangular matrix.; - TDecompQRH: QR decomposition class.; - TDecompSVD: Single value decomposition class.; - TDecompSparse: Sparse symmetric decomposition class. ### Matrix Eigen analysis. With the `TMatrixDEigen` and `TMatrixDSymEigen` classes, you can compute eigenvalues and; eigenvectors for general dense and symmetric real matrices. ## Additional Notes. The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in %ROOT, they of course; can be stored in a %ROOT database. ### How to efficiently use this package. #### 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:. ~~~ {.cpp}; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; ~~~. runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. #### 2. Use ""two-address instructions"". ~~~ {.cpp}; void TMatrixD::operator += (const TMatrixD &B);; ~~~. as much",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:14781,efficient,efficiently,14781,math/matrix/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md,1,['efficient'],['efficiently']
Energy Efficiency,"; 1) Fisher and LD; -----------------; ""Bugfix"" in Fisher's linear discriminant:; The ""Within-Class"" matrix was before calculated as: ; ; (*fWith)(x, y) = (sumSig[k] + sumBgd[k])/(fSumOfWeightsS + fSumOfWeightsB);; while according to Fisher it should (and now is) be:; (*fWith)(x, y) = sumSig[k]/fSumOfWeightsS + sumBgd[k]/fSumOfWeightsB; . Both results are the same if the number of (weighted) training events for signal; and background are the same, and as this is the recommended setting, the ""bug"" ; had very litte impact. However in order to be a ""correct"" Fisher discriminant, ; the correct calculation has now been adopted. Fisher and LD are the same, ONCE; the events are weighted such that signal and background have the same weight. ; Hence, the LD classifier still gives exactly the same result as the ""old"" Fisher; implementation, while the corrected Fisher implementation allows to ""play"" with; different event weights to perhaps find better discrimination power in certain; regions of the ROC curve. ; 2) BDT. a) Changes to some tuning options . nEventsMin --> MinNodeSize; UseNTrainEvents --> BaggedSampleFraction. have been replaced by options that are now given in terms of the relative; size of the training sample rather than in absulut numbers of events. This; is in order to facilitate the parameter tuning on different sample sizes; (i.e when starting on a smaller data sample to tune the parameter in order; to speed up the training); Furthermore, this option here has been changed name. GradBaggingFraction --> BaggedSampleFraction. in an attempt to consolidate and avoid idential duplicate code; ; The option UseWeightedTrees has been removed and set to ""true"", as was default; anyway, as a measure of further consolidation. Removed the option NNodesMax --> This should be replaced by specifying MaxDepth; instead (limiting the maximum tree depth also limits the number of possible nodes!). b) Added a trial version of a new ""cost sensitive"" boosting algorithem according to; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt:970,power,power,970,documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt,1,['power'],['power']
Energy Efficiency,"; TF1 f(""Sin Function"", ""sin(x)"", 0, TMath::Pi());; ROOT::Math::WrappedTF1 wf1(f);. ROOT::Math::GaussIntegrator ig;. ig.SetFunction(wf1, false);; ig.SetRelTolerance(0.001);. cout << ig.Integral(0, TMath::PiOver2()) << endl;. return 0;; }; ```; #### ROOT::Math::GaussLegendreIntegrator. This class implementes the Gauss-Legendre quadrature formulas. This sort of numerical methods requieres that the user specifies the number of intermediate function points; used in the calculation of the integral. It will automatically determine the coordinates and weights of such points before performing the integration.; We can use the example above, but replacing the creation of a `ROOT::Math::GaussIntegrator` object with `ROOT::Math::GaussLegendreIntegrator`. #### ROOT::Math::GSLIntegrator. This is a wrapper for the *QUADPACK* integrator implemented in the GSL library. It supports several integration methods that can be chosen in construction time.; The default type is adaptive integration with singularity applying a Gauss-Kronrod 21-point integration rule. For a detail description of the GSL methods visit the GSL user guide; This class implements the best algorithms for numerical integration for one dimensional functions. We encourage the use it as the main option, bearing in mind that it uses code from the; GSL library, wich is provided in the *MathMore* library of ROOT. The interface to use is the same as above. We have now the possibility to specify a different integration algorithm in the constructor of the `ROOT::Math::GSLIntegrator` class.; ```{.cpp}; // create the adaptive integrator with the 51 point rule; ROOT::Math::GSLIntegrator ig(ROOT::Math::Integration::kADAPTIVE, ROOT::Math::Integration::kGAUSS51);; ig.SetRelTolerance(1.E-6); // set relative tolerance; ig.SetAbsTolerance(1.E-6); // set absoulte tolerance; ```. The algorithm is controlled by the given absolute and relative tolerance. The iterations are continued until the following condition is satisfied; $$; absErr <=",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:54763,adapt,adaptive,54763,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['adapt'],['adaptive']
Energy Efficiency,"; `MySelector.C`. The example is executed with the following sequence of; commands:. ``` {.cpp}; > TChain *ch=new TChain(""cond_data"", ""Chain for Example N-Tuple"");; > ch->Add(""conductivity_experiment*.root"");; > ch->Process(""MySelector.C+"");; ```. As usual, the ""`+`"" appended to the name of the macro to be executed; initiates the compilation of the `MySelector.C` with the system compiler; in order to improve performance. The code in `MySelector.C`, shown in the listing below, books some; histograms in `SlaveBegin()` and adds them to the instance `fOutput`,; which is of the class `TList` [^6]. The final processing in; `Terminate()` allows to access histograms and store, display or save; them as pictures. This is shown in the example via the `TList`; `fOutput`. See the commented listing below for more details; most of the; text is actually comments generated automatically by; `TTree::MakeSelector`. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/MySelector.C; ```. ### *For power-users:* Multi-core processing with `PROOF lite` ###. The processing of n-tuples via a selector function of type `TSelector`; through `TChain::Process()`, as described at the end of the previous; section, offers an additional advantage in particular for very large; data sets: on distributed systems or multi-core architectures, portions; of data can be processed in parallel, thus significantly reducing the; execution time. On modern computers with multi-core CPUs or; hardware-threading enabled, this allows a much faster turnaround of; analyses, since all the available CPU power is used. On distributed systems, a PROOF server and worker nodes have to be set; up, as described in detail in the ROOT documentation. On a single; computer with multiple cores, `PROOF lite` can be used instead. Try the; following little macro, `RunMySelector.C`, which contains two extra; lines compared to the example above (adjust the number of workers; according to the number of CPU cores):. ``` {.cpp}; {// set up a TChain; TChai",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md:8853,power,power-users,8853,documentation/primer/filio.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md,1,['power'],['power-users']
Energy Efficiency,"; ``-0.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to ``start_value``. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fadd; <int_vector_reduce_fadd>`) for more detail on the semantics of the reduction. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fadd.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float -0.0, float -0.0, float -0.0, float -0.0>; %also.r = call float @llvm.vector.reduce.fadd.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_mul:. '``llvm.vp.reduce.mul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.mul.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.mul.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``MUL`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.mul``' intrinsic performs the integer ``MUL`` reduction; (:ref:`llvm.vector.reduce.mul <int_vector_reduce",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:752620,reduce,reduce,752620,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"; ``R_LARCH_PCALA_{HI20,LO12}`` for function call in medium code model.; * The code model of global variables can now be overridden by means of the newly; added LLVM IR attribute, ``code_model``.; * Added support for the ``llvm.is.fpclass`` intrinsic.; * ``mulodi4`` and ``muloti4`` libcalls were disabled due to absence in libgcc.; * Added initial support for auto vectorization.; * Added initial support for linker relaxation.; * Assorted codegen improvements. Changes to the MIPS Backend; ---------------------------. Changes to the PowerPC Backend; ------------------------------. * LLJIT's JIT linker now defaults to JITLink on 64-bit ELFv2 targets.; * Initial-exec TLS model is supported on AIX.; * Implemented new resource based scheduling model of POWER7 and POWER8.; * ``frexp`` libcall now references correct symbol name for ``fp128``.; * Optimized materialization of 64-bit immediates, code generation of; ``vec_promote`` and atomics.; * Global constant strings are pooled in the TOC under one entry to reduce the; number of entries in the TOC.; * Added a number of missing Power10 extended mnemonics.; * Added the SCV instruction.; * Fixed register class for the paddi instruction.; * Optimize VPERM and fix code order for swapping vector operands on LE.; * Added various bug fixes and code gen improvements. AIX Support/improvements:. * Support for a non-TOC-based access sequence for the local-exec TLS model (called small local-exec).; * XCOFF toc-data peephole optimization and bug fixes.; * Move less often used __ehinfo TOC entries to the end of the TOC section.; * Fixed problems when the AIX libunwind unwinds starting from a signal handler; and the function that raised the signal happens to be a leaf function that; shares the stack frame with its caller or a leaf function that does not store; the stack frame backchain. Changes to the RISC-V Backend; -----------------------------. * The Zfa extension version was upgraded to 1.0 and is no longer experimental.; * Zihintntl ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst:5926,reduce,reduce,5926,interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,1,['reduce'],['reduce']
Energy Efficiency,"; architecture. For instance, by inspecting; ``lib/Target/X86/X86GenRegisterInfo.inc`` we see that the 32-bit register; ``EAX`` is denoted by 43, and the MMX register ``MM0`` is mapped to 65. Some architectures contain registers that share the same physical location. A; notable example is the X86 platform. For instance, in the X86 architecture, the; registers ``EAX``, ``AX`` and ``AL`` share the first eight bits. These physical; registers are marked as *aliased* in LLVM. Given a particular architecture, you; can check which registers are aliased by inspecting its ``RegisterInfo.td``; file. Moreover, the class ``MCRegAliasIterator`` enumerates all the physical; registers aliased to a register. Physical registers, in LLVM, are grouped in *Register Classes*. Elements in the; same register class are functionally equivalent, and can be interchangeably; used. Each virtual register can only be mapped to physical registers of a; particular class. For instance, in the X86 architecture, some virtuals can only; be allocated to 8 bit registers. A register class is described by; ``TargetRegisterClass`` objects. To discover if a virtual register is; compatible with a given physical, this code can be used:. .. code-block:: c++. bool RegMapping_Fer::compatible_class(MachineFunction &mf,; unsigned v_reg,; unsigned p_reg) {; assert(TargetRegisterInfo::isPhysicalRegister(p_reg) &&; ""Target register must be physical"");; const TargetRegisterClass *trc = mf.getRegInfo().getRegClass(v_reg);; return trc->contains(p_reg);; }. Sometimes, mostly for debugging purposes, it is useful to change the number of; physical registers available in the target architecture. This must be done; statically, inside the ``TargetRegisterInfo.td`` file. Just ``grep`` for; ``RegisterClass``, the last parameter of which is a list of registers. Just; commenting some out is one simple way to avoid them being used. A more polite; way is to explicitly exclude some registers from the *allocation order*. See the; defin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:59750,allocate,allocated,59750,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['allocate'],['allocated']
Energy Efficiency,"; behavior as described above. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power,; returning the same values as the libm ``pow`` functions would, and; handles error conditions in the same way. '``llvm.experimental.constrained.powi``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.experimental.constrained.powi(<type> <op1>, i32 <op2>,; metadata <rounding mode>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.experimental.constrained.powi``' intrinsic returns the first operand; raised to the (positive or negative) power specified by the second operand. The; order of evaluation of multiplications is not defined. When a vector of; floating-point type is used, the second argument remains a scalar integer value. Arguments:; """""""""""""""""""". The first argument and the return value are floating-point numbers of the same; type. The second argument is a 32-bit signed integer specifying the power to; which the first argument should be raised. The third and fourth arguments specify the rounding mode and exception; behavior as described above. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power with an; unspecified sequence of rounding operations. '``llvm.experimental.constrained.ldexp``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type0>; @llvm.experimental.constrained.ldexp(<type0> <op1>, <type1> <op2>,; metadata <rounding mode>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.experimental.constrained.ldexp``' performs the ldexp function. Arguments:; """""""""""""""""""". The first argument and the return value are :ref:`floating-point; <t_floating>` or :ref:`vector <t_vector>` of floating-point values of; the same type. The second argument is an integer with the same number; of elements. The third and fourth arguments specify the rounding mode and exception; behavior as ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:892611,power,power,892611,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"; call GCC. Although this makes the driver much more complicated than; might otherwise be necessary, we decided that being very compatible with; the gcc command line interface was worth it in order to allow users to; quickly test clang on their projects. Flexible; --------. The driver was designed to be flexible and easily accommodate new uses; as we grow the clang and LLVM infrastructure. As one example, the driver; can easily support the introduction of tools which have an integrated; assembler; something we hope to add to LLVM in the future. Similarly, most of the driver functionality is kept in a library which; can be used to build other tools which want to implement or accept a gcc; like interface. Low Overhead; ------------. The driver should have as little overhead as possible. In practice, we; found that the gcc driver by itself incurred a small but meaningful; overhead when compiling many small files. The driver doesn't do much; work compared to a compilation, but we have tried to keep it as; efficient as possible by following a few simple principles:. - Avoid memory allocation and string copying when possible.; - Don't parse arguments more than once.; - Provide a few simple interfaces for efficiently searching arguments. Simple; ------. Finally, the driver was designed to be ""as simple as possible"", given; the other goals. Notably, trying to be completely compatible with the; gcc driver adds a significant amount of complexity. However, the design; of the driver attempts to mitigate this complexity by dividing the; process into a number of independent stages instead of a single; monolithic task. Internal Design and Implementation; ==================================. .. contents::; :local:; :depth: 1. Internals Introduction; ----------------------. In order to satisfy the stated goals, the driver was designed to; completely subsume the functionality of the gcc executable; that is, the; driver should not need to delegate to gcc to perform subtasks. On; Darwin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst:1933,efficient,efficient,1933,interpreter/llvm-project/clang/docs/DriverInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst,1,['efficient'],['efficient']
Energy Efficiency,"; extension of the ROOT framework, a C++ based data analysis framework that; provides tools for data storage, analysis, and visualization. RooFit provides; a set of tools/classes to define and evaluate probability density functions; (PDFs), perform maximum likelihood fits, perform statistical tests, etc. ## Proof of Concept: Speeding up RooFit using Automatic Differentiation (AD). RooFit is used to reduce statistical models (functions) to find a set of; parameters that minimize the value of the function. This minimization happens; via one of several methods relying heavily on the computation of derivatives; of the function with respect to its free parameters. Currently, the; computation of Numerical Derivatives is the most time-consuming component of; RooFit [^1]. On the other hand, derivatives computed using the Automatic; Differentiation tool [Clad] have been shown to be far more efficient [^2]. \htmlonly; <div class=""pyrootbox"">; \endhtmlonly. Main Advantage of using AD with RooFit: efficient and more precise; derivatives. It computes derivatives with high precision, avoiding the errors; that may arise from approximating derivatives using finite differences. \htmlonly; </div>; \endhtmlonly. ### AD Support essentially requires Code Generation. As we'll discuss in upcoming sections, *AD support* can be added using *C++; Code generation*.; These two terms may be used interchangeably in this document, since the term; *Code Generation* better helps visualize the transformation that is enabling; AD support. ## Current Status of Code Generation in RooFit. RooFit is an extensive toolkit.; The initiative to add AD support/ Code Generation has been started, but has; not yet achieved full coverage for the models defined/maintained in RooFit. ## How Clad enables AD support using Source Code Transformation. [Clad] is a C++ plugin for Clang. It implements a technique called Source Code; Transformation to enable AD support. Source Code Transformation takes the source code (that ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:1460,efficient,efficient,1460,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['efficient'],['efficient']
Energy Efficiency,"; formatting of the value. For example, to format a floating point value as a percentage,; you can use the style option ``P``. Custom formatting; ^^^^^^^^^^^^^^^^^. There are two ways to customize the formatting behavior for a type. 1. Provide a template specialization of ``llvm::format_provider<T>`` for your; type ``T`` with the appropriate static format method. .. code-block:: c++. namespace llvm {; template<>; struct format_provider<MyFooBar> {; static void format(const MyFooBar &V, raw_ostream &Stream, StringRef Style) {; // Do whatever is necessary to format `V` into `Stream`; }; };; void foo() {; MyFooBar X;; std::string S = formatv(""{0}"", X);; }; }. This is a useful extensibility mechanism for adding support for formatting your own; custom types with your own custom Style options. But it does not help when you want; to extend the mechanism for formatting a type that the library already knows how to; format. For that, we need something else. 2. Provide a **format adapter** inheriting from ``llvm::FormatAdapter<T>``. .. code-block:: c++. namespace anything {; struct format_int_custom : public llvm::FormatAdapter<int> {; explicit format_int_custom(int N) : llvm::FormatAdapter<int>(N) {}; void format(llvm::raw_ostream &Stream, StringRef Style) override {; // Do whatever is necessary to format ``this->Item`` into ``Stream``; }; };; }; namespace llvm {; void foo() {; std::string S = formatv(""{0}"", anything::format_int_custom(42));; }; }. If the type is detected to be derived from ``FormatAdapter<T>``, ``formatv``; will call the; ``format`` method on the argument passing in the specified style. This allows; one to provide custom formatting of any type, including one which already has; a builtin format provider. ``formatv`` Examples; ^^^^^^^^^^^^^^^^^^^^; Below is intended to provide an incomplete set of examples demonstrating; the usage of ``formatv``. More information can be found by reading the; doxygen documentation or by looking at the unit test suite. .. code-bl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:14194,adapt,adapter,14194,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['adapt'],['adapter']
Energy Efficiency,"; free(p);; }. unix.MismatchedDeallocator; (C, C++, ObjC); Check for mismatched deallocators (e.g. passing a pointer allocating; with new to free()). // C, C++; void test() {; int *p = (int *)malloc(sizeof(int));; delete p; // warn; }. // C, C++; void __attribute((ownership_returns(malloc))) *user_malloc(size_t);. void test() {; int *p = (int *)user_malloc(sizeof(int));; delete p; // warn; }. // C, C++; void test() {; int *p = new int;; free(p); // warn; }. // C, C++; void test() {; int *p = new int[1];; realloc(p, sizeof(long)); // warn; }. // C, C++; template <typename T>; struct SimpleSmartPointer {; T *ptr;. explicit SimpleSmartPointer(T *p = 0) : ptr(p) {}; ~SimpleSmartPointer() {; delete ptr; // warn; }; };. void test() {; SimpleSmartPointer<int> a((int *)malloc(4));; }. // C++; void test() {; int *p = (int *)operator new(0);; delete[] p; // warn; }. // Objective-C, C++; void test(NSUInteger dataLength) {; int *p = new int;; NSData *d = [NSData dataWithBytesNoCopy:p; length:sizeof(int) freeWhenDone:1];; // warn +dataWithBytesNoCopy:length:freeWhenDone: cannot take; // ownership of memory allocated by 'new'; }. unix.Vfork; (C); Check for proper usage of vfork. int test(int x) {; pid_t pid = vfork(); // warn; if (pid != 0); return 0;. switch (x) {; case 0:; pid = 1;; execl("""", """", 0);; _exit(1);; break;; case 1:; x = 0; // warn: this assignment is prohibited; break;; case 2:; foo(); // warn: this function call is prohibited; break;; default:; return 0; // warn: return is prohibited; }. while(1);; }. unix.cstring.BadSizeArg; (C); Check the size argument passed to strncat for common erroneous; patterns. Use -Wno-strncat-size compiler option to mute other; strncat-related compiler warnings. void test() {; char dest[3];; strncat(dest, ""***"", sizeof(dest));; // warn: potential buffer overflow; }. unix.cstring.NullArg; (C); Check for null pointers being passed as arguments to C string functions:; strlen; strnlen; strcpy; strncpy; strcat; strncat; strcmp; strncmp; strca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html:26126,allocate,allocated,26126,interpreter/llvm-project/clang/www/analyzer/available_checks.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html,1,['allocate'],['allocated']
Energy Efficiency,"; if the operand is of the specified type, and if so, returns a pointer to it; (this operator does not work with references). If the operand is not of the; correct type, a null pointer is returned. Thus, this works very much like; the ``dynamic_cast<>`` operator in C++, and should be used in the same; circumstances. Typically, the ``dyn_cast<>`` operator is used in an ``if``; statement or some other flow control statement like this:. .. code-block:: c++. if (auto *AI = dyn_cast<AllocationInst>(Val)) {; // ...; }. This form of the ``if`` statement effectively combines together a call to; ``isa<>`` and a call to ``cast<>`` into one statement, which is very; convenient. Note that the ``dyn_cast<>`` operator, like C++'s ``dynamic_cast<>`` or Java's; ``instanceof`` operator, can be abused. In particular, you should not use big; chained ``if/then/else`` blocks to check for lots of different variants of; classes. If you find yourself wanting to do this, it is much cleaner and more; efficient to use the ``InstVisitor`` class to dispatch over the instruction; type directly. ``isa_and_nonnull<>``:; The ``isa_and_nonnull<>`` operator works just like the ``isa<>`` operator,; except that it allows for a null pointer as an argument (which it then; returns false). This can sometimes be useful, allowing you to combine several; null checks into one. ``cast_or_null<>``:; The ``cast_or_null<>`` operator works just like the ``cast<>`` operator,; except that it allows for a null pointer as an argument (which it then; propagates). This can sometimes be useful, allowing you to combine several; null checks into one. ``dyn_cast_or_null<>``:; The ``dyn_cast_or_null<>`` operator works just like the ``dyn_cast<>``; operator, except that it allows for a null pointer as an argument (which it; then propagates). This can sometimes be useful, allowing you to combine; several null checks into one. These five templates can be used with any classes, whether they have a v-table; or not. If you want to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:6401,efficient,efficient,6401,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"; ldr lr, [r1, #+32]; sxth r3, r3; ldr r4, [sp, #+52]; mla r4, r3, lr, r4. can be:. mul lr, r4, lr; mov r4, lr; str lr, [sp, #+52]; ldr lr, [r1, #+32]; sxth r3, r3; mla r4, r3, lr, r4. and then ""merge"" mul and mov:. mul r4, r4, lr; str r4, [sp, #+52]; ldr lr, [r1, #+32]; sxth r3, r3; mla r4, r3, lr, r4. It also increase the likelihood the store may become dead. //===---------------------------------------------------------------------===//. bb27 ...; ...; %reg1037 = ADDri %reg1039, 1; %reg1038 = ADDrs %reg1032, %reg1039, %noreg, 10; Successors according to CFG: 0x8b03bf0 (#5). bb76 (0x8b03bf0, LLVM BB @0x8b032d0, ID#5):; Predecessors according to CFG: 0x8b0c5f0 (#3) 0x8b0a7c0 (#4); %reg1039 = PHI %reg1070, mbb<bb76.outer,0x8b0c5f0>, %reg1037, mbb<bb27,0x8b0a7c0>. Note ADDri is not a two-address instruction. However, its result %reg1037 is an; operand of the PHI node in bb76 and its operand %reg1039 is the result of the; PHI node. We should treat it as a two-address code and make sure the ADDri is; scheduled after any node that reads %reg1039. //===---------------------------------------------------------------------===//. Use local info (i.e. register scavenger) to assign it a free register to allow; reuse:; ldr r3, [sp, #+4]; add r3, r3, #3; ldr r2, [sp, #+8]; add r2, r2, #2; ldr r1, [sp, #+4] <==; add r1, r1, #1; ldr r0, [sp, #+4]; add r0, r0, #2. //===---------------------------------------------------------------------===//. LLVM aggressively lift CSE out of loop. Sometimes this can be negative side-; effects:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; load [i + R1]; ...; load [i + R2]; ...; load [i + R3]. Suppose there is high register pressure, R1, R2, R3, can be spilled. We need; to implement proper re-materialization to handle this:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; R1 = X + 4 @ re-materialized; load [i + R1]; ...; R2 = X + 7 @ re-materialized; load [i + R2]; ...; R3 = X + 15 @ re-materialized; load [i + R3]. Furthermore, with re-association, we ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt:1176,schedul,scheduled,1176,interpreter/llvm-project/llvm/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt,1,['schedul'],['scheduled']
Energy Efficiency,; llvm/tools/llvm-profgen/CSPreInliner.h; llvm/tools/llvm-profgen/llvm-profgen.cpp; llvm/tools/llvm-profgen/PerfReader.cpp; llvm/tools/llvm-profgen/PerfReader.h; llvm/tools/llvm-rc/ResourceScriptCppFilter.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337352,reduce,reduce,337352,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"; memory. In LLVM, no memory locations are in SSA form, which makes things; very simple. This section describes how to read, write, and allocate; memory in LLVM. .. _i_alloca:. '``alloca``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = alloca [inalloca] <type> [, <ty> <NumElements>] [, align <alignment>] [, addrspace(<num>)] ; yields type addrspace(num)*:result. Overview:; """""""""""""""""". The '``alloca``' instruction allocates memory on the stack frame of the; currently executing function, to be automatically released when this; function returns to its caller. If the address space is not explicitly; specified, the object is allocated in the alloca address space from the; :ref:`datalayout string<langref_datalayout>`. Arguments:; """""""""""""""""""". The '``alloca``' instruction allocates ``sizeof(<type>)*NumElements``; bytes of memory on the runtime stack, returning a pointer of the; appropriate type to the program. If ""NumElements"" is specified, it is; the number of elements allocated, otherwise ""NumElements"" is defaulted; to be one. If a constant alignment is specified, the value result of the; allocation is guaranteed to be aligned to at least that boundary. The; alignment may not be greater than ``1 << 32``. The alignment is only optional when parsing textual IR; for in-memory IR,; it is always present. If not specified, the target can choose to align the; allocation on any convenient boundary compatible with the type. '``type``' may be any sized type. Structs containing scalable vectors cannot be used in allocas unless all; fields are the same scalable vector type (e.g. ``{<vscale x 2 x i32>,; <vscale x 2 x i32>}`` contains the same type while ``{<vscale x 2 x i32>,; <vscale x 2 x i64>}`` doesn't). Semantics:; """""""""""""""""""". Memory is allocated; a pointer is returned. The allocated memory is; uninitialized, and loading from uninitialized memory produces an undefined; value. The operation itself is undefined if there is insufficient stack; space for the a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:409674,allocate,allocated,409674,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"; modes depending on the floating-point type. One; controls float, and the other controls both double and; half operations. If both modes are the same, returns; one of the standard return values. If the modes are; different, returns one of :ref:`12 extended values; <amdgpu-rounding-mode-enumeration-values-table>`; describing the two modes. To nearest, ties away from zero is not a supported; mode. The raw rounding mode values in the MODE; register do not exactly match the FLT_ROUNDS values,; so a conversion is performed. llvm.amdgcn.wave.reduce.umin Performs an arithmetic unsigned min reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.wave.reduce.umax Performs an arithmetic unsigned max reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.udot2 Provides direct access to v_dot2_u32_u16 across targets which; support such instructions. This performs unsigned dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output. llvm.amdgcn.udot4 Provides direct access to v_dot4_u32_u8 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.udot8 Pro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:38699,reduce,reduce,38699,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['reduce'],['reduce']
Energy Efficiency,"; not need to be set up. ""HiddenPrintfBuffer""; A global address space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenHostcallBuffer"". ""HiddenHostcallBuffer""; A global address space pointer; to the runtime hostcall buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenPrintfBuffer"". ""HiddenDefaultQueue""; A global address space pointer; to the OpenCL device enqueue; queue that should be used by; the kernel by default is; passed in the kernarg. ""HiddenCompletionAction""; A global address space pointer; to help link enqueued kernels into; the ancestor tree for determining; when the parent kernel has finished. ""HiddenMultiGridSyncArg""; A global address space pointer for; multi-grid synchronization is; passed in the kernarg. ""ValueType"" string Unused and deprecated. This should no longer; be emitted, but is accepted for compatibility. ""PointeeAlign"" integer Alignment in bytes of pointee; type for pointer type kernel; argument. Must be a power; of 2. Only present if; ""ValueKind"" is; ""DynamicSharedPointer"".; ""AddrSpaceQual"" string Kernel argument address space; qualifier. Only present if; ""ValueKind"" is ""GlobalBuffer"" or; ""DynamicSharedPointer"". Values; are:. - ""Private""; - ""Global""; - ""Constant""; - ""Local""; - ""Generic""; - ""Region"". .. TODO::. Is GlobalBuffer only Global; or Constant? Is; DynamicSharedPointer always; Local? Can HCC allow Generic?; How can Private or Region; ever happen?. ""AccQual"" string Kernel argument access; qualifier. Only present if; ""ValueKind"" is ""Image"" or; ""Pipe"". Values; are:. - ""ReadOnly""; - ""WriteOnly""; - ""ReadWrite"". .. TODO::. Does this apply to; GlobalBuffer?. ""ActualAccQual"" string The actual memory accesses; performed by the kernel on the; kernel argument. Only present if; ""ValueKind"" is ""GlobalBuffer"",; ""Image"", or ""Pipe"". This may be; more restrictive than indicated; by ""AccQual"" to reflect what the; kernel actual does. If not; present then the runtime must; assume what is implied by; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:125651,power,power,125651,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['power'],['power']
Energy Efficiency,"; operations that don't dereference it such as; :ref:`getelementptr <i_getelementptr>`, :ref:`ptrtoint <i_ptrtoint>` and; :ref:`icmp <i_icmp>` return a valid result.; This explains code motion of these instructions across operations that; impact the object's lifetime.; A stack object's lifetime can be explicitly specified using; :ref:`llvm.lifetime.start <int_lifestart>` and; :ref:`llvm.lifetime.end <int_lifeend>` intrinsic function calls. .. _pointeraliasing:. Pointer Aliasing Rules; ----------------------. Any memory access must be done through a pointer value associated with; an address range of the memory access, otherwise the behavior is; undefined. Pointer values are associated with address ranges according; to the following rules:. - A pointer value is associated with the addresses associated with any; value it is *based* on.; - An address of a global variable is associated with the address range; of the variable's storage.; - The result value of an allocation instruction is associated with the; address range of the allocated storage.; - A null pointer in the default address-space is associated with no; address.; - An :ref:`undef value <undefvalues>` in *any* address-space is; associated with no address.; - An integer constant other than zero or a pointer value returned from; a function not defined within LLVM may be associated with address; ranges allocated through mechanisms other than those provided by; LLVM. Such ranges shall not overlap with any ranges of addresses; allocated by mechanisms provided by LLVM. A pointer value is *based* on another pointer value according to the; following rules:. - A pointer value formed from a scalar ``getelementptr`` operation is *based* on; the pointer-typed operand of the ``getelementptr``.; - The pointer in lane *l* of the result of a vector ``getelementptr`` operation; is *based* on the pointer in lane *l* of the vector-of-pointers-typed operand; of the ``getelementptr``.; - The result value of a ``bitcast`` is *based*",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:141908,allocate,allocated,141908,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"; small overhead for each allocation. The checksum is computed using a CRC32 (made faster with hardware support); of the global secret, the chunk pointer itself, and the 8 bytes of header with; the checksum field zeroed out. It is not intended to be cryptographically; strong. The header is atomically loaded and stored to prevent races. This is important; as two consecutive chunks could belong to different threads. We work on local; copies and use compare-exchange primitives to update the headers in the heap; memory, and avoid any type of double-fetching. Randomness; ----------; Randomness is a critical factor to the additional security provided by the; allocator. The allocator trusts the memory mapping primitives of the OS to; provide pages at (mostly) non-predictable locations in memory, as well as the; binaries to be compiled with ASLR. In the event one of those assumptions is; incorrect, the security will be greatly reduced. Scudo further randomizes how; blocks are allocated in the Primary, can randomize how caches are assigned to; threads. Memory reclaiming; -----------------; Primary and Secondary allocators have different behaviors with regard to; reclaiming. While Secondary mapped allocations can be unmapped on deallocation,; it isn't the case for the Primary, which could lead to a steady growth of the; RSS of a process. To counteract this, if the underlying OS allows it, pages; that are covered by contiguous free memory blocks in the Primary can be; released: this generally means they won't count towards the RSS of a process and; be zero filled on subsequent accesses). This is done in the deallocation path,; and several options exist to tune this behavior. Usage; =====. Platform; --------; If using Fuchsia or an Android version greater than 11, your memory allocations; are already service by Scudo (note that Android Svelte configurations still use; jemalloc). Library; -------; The allocator static library can be built from the LLVM tree thanks to the; ``scud",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:4812,allocate,allocated,4812,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['allocate'],['allocated']
Energy Efficiency,"; t2.Branch(""vect"",gstep.vect,""vect[7]/F"");; t2.Branch(""getot"",&gstep.getot,""getot/F"");; t2.Branch(""gekin"",&gstep.gekin,""gekin/F"");; t2.Branch(""nmec"",&gstep.nmec,""nmec/I"");; t2.Branch(""lmec"",gstep.lmec,""lmec[nmec]/I"");; t2.Branch(""destep"",&gstep.destep,""destep/F"");; t2.Branch(""pid"",&gstep.pid,""pid/I"");. //Initialize particle parameters at first point; Float_t px,py,pz,p,charge=0;; Float_t vout[7];; Float_t mass = 0.137;; Bool_t newParticle = kTRUE;; gstep.step = 0.1;; gstep.destep = 0;; gstep.nmec = 0;; gstep.pid = 0;. //transport particles; for (Int_t i=0; i<10000; i++) {; //generate a new particle if necessary (Geant3 emulation); if (newParticle) {; px = gRandom->Gaus(0,.02);; py = gRandom->Gaus(0,.02);; pz = gRandom->Gaus(0,.02);; p = TMath::Sqrt(px*px+py*py+pz*pz);; charge = 1;; if (gRandom->Rndm() < 0.5) charge = -1;; gstep.pid += 1;; gstep.vect[0] = 0;; gstep.vect[1] = 0;; gstep.vect[2] = 0;; gstep.vect[3] = px/p;; gstep.vect[4] = py/p;; gstep.vect[5] = pz/p;; gstep.vect[6] = p*charge;; gstep.getot = TMath::Sqrt(p*p + mass*mass);; gstep.gekin = gstep.getot - mass;; newParticle = kFALSE;; }; // fill the Tree with current step parameters; t2.Fill();. //transport particle in magnetic field (Geant3 emulation); helixStep(gstep.step, gstep.vect, vout);; //make one step; //apply energy loss; gstep.destep = gstep.step*gRandom->Gaus(0.0002,0.00001);; gstep.gekin -= gstep.destep;; gstep.getot = gstep.gekin + mass;; gstep.vect[6]= charge*TMath::Sqrt(gstep.getot*gstep.getot; - mass*mass);; gstep.vect[0] = vout[0];; gstep.vect[1] = vout[1];; gstep.vect[2] = vout[2];; gstep.vect[3] = vout[3];; gstep.vect[4] = vout[4];; gstep.vect[5] = vout[5];; gstep.nmec = (Int_t)(5*gRandom->Rndm());; for (Int_t l=0; l<gstep.nmec; l++) gstep.lmec[l] = l;; if (gstep.gekin < 0.001) newParticle = kTRUE;; if (TMath::Abs(gstep.vect[2]) > 30) newParticle = kTRUE;; }; //save the Tree header. The file will be automatically; // closed when going out of the function scope; t2.Write();; }; ```. #### A",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:46764,charge,charge,46764,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['charge'],['charge']
Energy Efficiency,"; these methods should return ``true`` if they modified the program, or ``false``; if they didn't. A ``LoopPass`` subclass which is intended to run as part of the main loop pass; pipeline needs to preserve all of the same *function* analyses that the other; loop passes in its pipeline require. To make that easier,; a ``getLoopAnalysisUsage`` function is provided by ``LoopUtils.h``. It can be; called within the subclass's ``getAnalysisUsage`` override to get consistent; and correct behavior. Analogously, ``INITIALIZE_PASS_DEPENDENCY(LoopPass)``; will initialize this set of function analyses. The ``doInitialization(Loop *, LPPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Loop *, LPPassManager &LPM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``LPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnLoop:. The ``runOnLoop`` method; ^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnLoop(Loop *, LPPassManager &LPM) = 0;. The ``runOnLoop`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. ``LPPassManager`` interface; should be used to update loop nest. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnLoop; <writing-an-llvm-pass-runOnLoop>` for every loop in the program being compiled. .. _writing-an-llvm-pass-RegionPass:. The ``RegionPass`` clas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:21695,schedul,scheduled,21695,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['schedul'],['scheduled']
Energy Efficiency,"; time). You shouldn't need to understand these details if you are just a client of the; AliasSetTracker, but if you look at the code, hopefully this brief description; will help make sense of why things are designed the way they are. Using the ``AliasAnalysis`` interface directly; ----------------------------------------------. If neither of these utility class are what your pass needs, you should use the; interfaces exposed by the ``AliasAnalysis`` class directly. Try to use the; higher-level methods when possible (e.g., use mod/ref information instead of the; `alias`_ method directly if possible) to get the best precision and efficiency. Existing alias analysis implementations and clients; ===================================================. If you're going to be working with the LLVM alias analysis infrastructure, you; should know what clients and implementations of alias analysis are available.; In particular, if you are implementing an alias analysis, you should be aware of; the `the clients`_ that are useful for monitoring and evaluating different; implementations. .. _various alias analysis implementations:. Available ``AliasAnalysis`` implementations; -------------------------------------------. This section lists the various implementations of the ``AliasAnalysis``; interface. All of these :ref:`chain <aliasanalysis-chaining>` to other; alias analysis implementations. The ``-basic-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^^. The ``-basic-aa`` pass is an aggressive local analysis that *knows* many; important facts:. * Distinct globals, stack allocations, and heap allocations can never alias.; * Globals, stack allocations, and heap allocations never alias the null pointer.; * Different fields of a structure do not alias.; * Indexes into arrays with statically differing subscripts cannot alias.; * Many common standard C library functions `never access memory or only read; memory`_.; * Pointers that obviously point to constant globals ""``pointToConstantMemory``"".; * Fun",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:23377,monitor,monitoring,23377,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['monitor'],['monitoring']
Energy Efficiency,"; track of whether or not all of the pointers in the set are Must aliases. The; AliasSetTracker also makes sure that sets are properly folded due to call; instructions, and can provide a list of pointers in each set. As an example user of this, the `Loop Invariant Code Motion; <doxygen/structLICM.html>`_ pass uses ``AliasSetTracker``\s to calculate alias; sets for each loop nest. If an ``AliasSet`` in a loop is not modified, then all; load instructions from that set may be hoisted out of the loop. If any alias; sets are stored to **and** are must alias sets, then the stores may be sunk; to outside of the loop, promoting the memory location to a register for the; duration of the loop nest. Both of these transformations only apply if the; pointer argument is loop-invariant. The AliasSetTracker implementation; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The AliasSetTracker class is implemented to be as efficient as possible. It; uses the union-find algorithm to efficiently merge AliasSets when a pointer is; inserted into the AliasSetTracker that aliases multiple sets. The primary data; structure is a hash table mapping pointers to the AliasSet they are in. The AliasSetTracker class must maintain a list of all of the LLVM ``Value*``\s; that are in each AliasSet. Since the hash table already has entries for each; LLVM ``Value*`` of interest, the AliasesSets thread the linked list through; these hash-table nodes to avoid having to allocate memory unnecessarily, and to; make merging alias sets extremely efficient (the linked list merge is constant; time). You shouldn't need to understand these details if you are just a client of the; AliasSetTracker, but if you look at the code, hopefully this brief description; will help make sense of why things are designed the way they are. Using the ``AliasAnalysis`` interface directly; ----------------------------------------------. If neither of these utility class are what your pass needs, you should use the; interfaces exposed by the ``Ali",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:21749,efficient,efficiently,21749,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['efficient'],['efficiently']
Energy Efficiency,"; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum element magnitude ``0.0`` and containing both ``+0.0`` and; ``-0.0`` elements, the sign of the result is unspecified. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmax.v4f32(float %float, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float QNAN, float QNAN, float QNAN, float QNAN>; %reduction = call float @llvm.vector.reduce.fmax.v4f32(<4 x float> %masked.a); %also.r = call float @llvm.maxnum.f32(float %reduction, float %start). .. _int_vp_reduce_fmin:. '``llvm.vp.reduce.fmin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmin.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmin.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmin``' intrinsic performs the floating-point ``MIN``; reduction (",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:774041,reduce,reduce,774041,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"; values. Defaults to 0, 0, 0. Corresponds to the OpenCL; ``reqd_work_group_size``; attribute.; "".workgroup_size_hint"" sequence of The dispatch work-group size; 3 integers X, Y, Z is likely to be the; specified values. Corresponds to the OpenCL; ``work_group_size_hint``; attribute.; "".vec_type_hint"" string The name of a scalar or vector; type. Corresponds to the OpenCL; ``vec_type_hint`` attribute. "".device_enqueue_symbol"" string The external symbol name; associated with a kernel.; OpenCL runtime allocates a; global buffer for the symbol; and saves the kernel's address; to it, which is used for; device side enqueueing. Only; available for device side; enqueued kernels.; "".kernarg_segment_size"" integer Required The size in bytes of; the kernarg segment; that holds the values; of the arguments to; the kernel.; "".group_segment_fixed_size"" integer Required The amount of group; segment memory; required by a; work-group in; bytes. This does not; include any; dynamically allocated; group segment memory; that may be added; when the kernel is; dispatched.; "".private_segment_fixed_size"" integer Required The amount of fixed; private address space; memory required for a; work-item in; bytes. If the kernel; uses a dynamic call; stack then additional; space must be added; to this value for the; call stack.; "".kernarg_segment_align"" integer Required The maximum byte; alignment of; arguments in the; kernarg segment. Must; be a power of 2.; "".wavefront_size"" integer Required Wavefront size. Must; be a power of 2.; "".sgpr_count"" integer Required Number of scalar; registers required by a; wavefront for; GFX6-GFX9. A register; is required if it is; used explicitly, or; if a higher numbered; register is used; explicitly. This; includes the special; SGPRs for VCC, Flat; Scratch (GFX7-GFX9); and XNACK (for; GFX8-GFX9). It does; not include the 16; SGPR added if a trap; handler is; enabled. It is not; rounded up to the; allocation; granularity.; "".vgpr_count"" integer Required Number of vec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:133839,allocate,allocated,133839,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"; }. Builtin Functions; =================. Clang supports a number of builtin library functions with the same syntax as; GCC, including things like ``__builtin_nan``, ``__builtin_constant_p``,; ``__builtin_choose_expr``, ``__builtin_types_compatible_p``,; ``__builtin_assume_aligned``, ``__sync_fetch_and_add``, etc. In addition to; the GCC builtins, Clang supports a number of builtins that GCC does not, which; are listed here. Please note that Clang does not and will not support all of the GCC builtins; for vector operations. Instead of using builtins, you should use the functions; defined in target-specific header files like ``<xmmintrin.h>``, which define; portable wrappers for these. Many of the Clang versions of these functions are; implemented directly in terms of :ref:`extended vector support; <langext-vectors>` instead of builtins, in order to reduce the number of; builtins that we need to implement. ``__builtin_alloca``; --------------------. ``__builtin_alloca`` is used to dynamically allocate memory on the stack. Memory; is automatically freed upon function termination. **Syntax**:. .. code-block:: c++. __builtin_alloca(size_t n). **Example of Use**:. .. code-block:: c++. void init(float* data, size_t nbelems);; void process(float* data, size_t nbelems);; int foo(size_t n) {; auto mem = (float*)__builtin_alloca(n * sizeof(float));; init(mem, n);; process(mem, n);; /* mem is automatically freed at this point */; }. **Description**:. ``__builtin_alloca`` is meant to be used to allocate a dynamic amount of memory; on the stack. This amount is subject to stack allocation limits. Query for this feature with ``__has_builtin(__builtin_alloca)``. ``__builtin_alloca_with_align``; -------------------------------. ``__builtin_alloca_with_align`` is used to dynamically allocate memory on the; stack while controlling its alignment. Memory is automatically freed upon; function termination. **Syntax**:. .. code-block:: c++. __builtin_alloca_with_align(size_t n, size_t ali",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:96930,allocate,allocate,96930,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['allocate'],['allocate']
Energy Efficiency,";. class A {; A() {}; ~A() { f(); } // warn; };. ctordtor.PlacementSelfCopy; (C++11); For a placement copy or move, it is almost certainly an error if the; constructed object is also the object being copied from. class A {};. void test(A *dst, A *src) {; ::new (dst) A(*dst); // warn (should be 'src'); }. exceptions. Name, DescriptionExampleProgress. exceptions.ThrowSpecButNotThrow; (C++); Function declaration has a throw(type) specifier but the; function do not throw exceptions. void test() throw(int) {; } // warn. exceptions.NoThrowSpecButThrows; (C++); An exception is throw from a function having a throw(); specifier. void test() throw() {; throw(1); // warn; }. exceptions.ThrownTypeDiffersSpec; (C++); The type of a thrown exception differs from those specified in; a throw(type) specifier. struct S{};. void test() throw(int) {; S s;; throw (s); // warn; }. smart pointers. Name, DescriptionExampleProgress. smartptr.SmartPtrInit; (C++); C++03: auto_ptr should store a pointer to an object obtained via; new as allocated memory will be cleaned using delete.; C++11: one should use unique_ptr<type[]> to keep a; pointer to memory allocated by new[].; C++11: to keep a pointer to memory allocated by new[] in; a shared_ptr one should use a custom deleter that calls ; delete[]..; Source: C++03 20.4.5p1; C++11 auto_ptr is deprecated (D.10). #include <stdlib.h>; #include <memory>. void test() {; std::auto_ptr<int> p1(new int); // Ok; std::auto_ptr<int> p2(new int[3]); // warn; }. #include <stdlib.h>; #include <memory>. void test() {; std::auto_ptr<int> p((int *)malloc(sizeof(int))); // warn; }. dead code. Name, DescriptionExampleProgress. deadcode.UnmodifiedVariable; (C, C++); A variable is never modified but was not declared const and is not a; reference.(opt-in checker). extern int computeDelta();. int test(bool cond) {; int i = 0;; if (cond) {; const int delta = computeDelta();; // warn: forgot to modify 'i'; }; return i;; }. PR16890. deadcode.IdempotentOperations; (C); Warn",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:3552,allocate,allocated,3552,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,1,['allocate'],['allocated']
Energy Efficiency,"<< X. One better solution for 1LL << x is:; xorl %eax, %eax; xorl %edx, %edx; testb $32, %cl; sete %al; setne %dl; sall %cl, %eax; sall %cl, %edx. But that requires good 8-bit subreg support. Also, this might be better. It's an extra shift, but it's one instruction; shorter, and doesn't stress 8-bit subreg support.; (From http://gcc.gnu.org/ml/gcc-patches/2004-09/msg01148.html,; but without the unnecessary and.); movl %ecx, %eax; shrl $5, %eax; movl %eax, %edx; xorl $1, %edx; sall %cl, %eax; sall %cl. %edx. 64-bit shifts (in general) expand to really bad code. Instead of using; cmovs, we should expand to a conditional branch like GCC produces. //===---------------------------------------------------------------------===//. Some isel ideas:. 1. Dynamic programming based approach when compile time is not an; issue.; 2. Code duplication (addressing mode) during isel.; 3. Other ideas from ""Register-Sensitive Selection, Duplication, and; Sequencing of Instructions"".; 4. Scheduling for reduced register pressure. E.g. ""Minimum Register; Instruction Sequence Problem: Revisiting Optimal Code Generation for DAGs""; and other related papers.; http://citeseer.ist.psu.edu/govindarajan01minimum.html. //===---------------------------------------------------------------------===//. Should we promote i16 to i32 to avoid partial register update stalls?. //===---------------------------------------------------------------------===//. Leave any_extend as pseudo instruction and hint to register; allocator. Delay codegen until post register allocation.; Note. any_extend is now turned into an INSERT_SUBREG. We still need to teach; the coalescer how to deal with it though. //===---------------------------------------------------------------------===//. It appears icc use push for parameter passing. Need to investigate. //===---------------------------------------------------------------------===//. The instruction selector sometimes misses folding a load into a compare. The; pattern is writ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:1716,reduce,reduced,1716,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['reduce'],['reduced']
Energy Efficiency,"<``, ``>``, ``≤``, or ``≥`` to; ``=`` or ``≠`` if possible.; #. All ``cmp`` instructions on boolean values are replaced with logical; operations.; #. ``add X, X`` is represented as ``mul X, 2`` ⇒ ``shl X, 1``; #. Multiplies with a constant power-of-two argument are transformed into; shifts.; #. … etc. This pass can also simplify calls to specific well-known function calls (e.g.; runtime library functions). For example, a call ``exit(3)`` that occurs within; the ``main()`` function can be transformed into simply ``return 3``. Whether or; not library calls are simplified is controlled by the; :ref:`-function-attrs <passes-function-attrs>` pass and LLVM's knowledge of; library calls on different targets. .. _passes-aggressive-instcombine:. ``aggressive-instcombine``: Combine expression patterns; --------------------------------------------------------. Combine expression patterns to form expressions with fewer, simple instructions. For example, this pass reduce width of expressions post-dominated by TruncInst; into smaller width when applicable. It differs from instcombine pass in that it can modify CFG and contains pattern; optimization that requires higher complexity than the O(1), thus, it should run fewer; times than instcombine pass. ``internalize``: Internalize Global Symbols; -------------------------------------------. This pass loops over all of the functions in the input module, looking for a; main function. If a main function is found, all other functions and all global; variables with initializers are marked as internal. ``ipsccp``: Interprocedural Sparse Conditional Constant Propagation; -------------------------------------------------------------------. An interprocedural variant of :ref:`Sparse Conditional Constant Propagation; <passes-sccp>`. ``jump-threading``: Jump Threading; ----------------------------------. Jump threading tries to find distinct threads of control flow running through a; basic block. This pass looks at blocks that have multiple pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:21062,reduce,reduce,21062,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['reduce'],['reduce']
Energy Efficiency,"<img src=""https://root-forum.cern.ch/uploads/default/original/2X/3/3fb82b650635bc6d61461f3c47f41786afad4548.png"" align=""right"" height=""50""/>. ## About. ROOT is a unified software package for the storage, processing, and analysis of ; scientific data: from its acquisition to the final visualization in form of highly ; customizable, publication-ready plots. It is reliable, performant and well supported,; easy to use and obtain, and strives to maximize the quantity and impact of scientific ; results obtained per unit cost, both of human effort and computing resources. ROOT provides a very efficient storage system for data models, ; that demonstrated to scale at the Large Hadron Collider experiments: Exabytes ; of scientific data are written in columnar ROOT format.; ROOT comes with histogramming capabilities in an arbitrary number of ; dimensions, curve fitting, statistical modelling, minimization, to allow; the easy setup of a data analysis system that can query and process the data; interactively or in batch mode, as well as a general parallel processing; framework, RDataFrame, that can considerably speed up an analysis, taking ; full advantage of multi-core and distributed systems. ROOT is performance critical software written in C++ and enables rapid prototyping ; powered by a unique C++ compliant interpreter called Cling. ; Cling also enables performant C++ type introspection which is a building block of automatic ; interoperability with Python. Thanks to PyROOT, leveraging the cppyy technology, ; ROOT offers efficient, on-demand C++/Python interoperability in a uniform cross-language ; execution environment. ROOT fully embraces open-source, it's made with passion by its community,; for the benefit of its community. [![License: LGPL v2.1+](https://img.shields.io/badge/License-LGPL%20v2.1+-blue.svg)](https://www.gnu.org/licenses/lgpl.html); [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5060/badge)](https://bestpractices.coreinfrastruct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README.md:593,efficient,efficient,593,README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README.md,1,['efficient'],['efficient']
Energy Efficiency,"== =============; Syntax Alternative Syntax (SP3) Note Availability; ===================== ========================= ================================================ =============; shared_base src_shared_base Base address of shared memory region. GFX9+; shared_limit src_shared_limit Address of the end of shared memory region. GFX9+; private_base src_private_base Base address of private memory region. GFX9+; private_limit src_private_limit Address of the end of private memory region. GFX9+; pops_exiting_wave_id src_pops_exiting_wave_id A dedicated counter for POPS. GFX9, GFX10; ===================== ========================= ================================================ =============. .. _amdgpu_synid_literal:. literal; -------. A *literal* is a 64-bit value encoded as a separate; 32-bit dword in the instruction stream. Compare *literals*; with :ref:`inline constants<amdgpu_synid_constant>`. If a number may be encoded as either; a :ref:`literal<amdgpu_synid_literal>` or; an :ref:`inline constant<amdgpu_synid_constant>`,; assembler selects the latter encoding as more efficient. Literals may be specified as; :ref:`integer numbers<amdgpu_synid_integer_number>`,; :ref:`floating-point numbers<amdgpu_synid_floating-point_number>`,; :ref:`absolute expressions<amdgpu_synid_absolute_expression>` or; :ref:`relocatable expressions<amdgpu_synid_relocatable_expression>`. An instruction may use only one literal,; but several operands may refer to the same literal. .. _amdgpu_synid_uimm8:. uimm8; -----. An 8-bit :ref:`integer number<amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`.; The value must be in the range 0..0xFF. .. _amdgpu_synid_uimm32:. uimm32; ------. A 32-bit :ref:`integer number<amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`.; The value must be in the range 0..0xFFFFFFFF. .. _amdgpu_synid_uimm20:. uimm20; ------. A 20-bit :ref:`integer number<amdgpu_synid_integer_numb",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:25521,efficient,efficient,25521,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,1,['efficient'],['efficient']
Energy Efficiency,"==. The global and constant memory spaces both use global virtual addresses, which; are the same virtual address space used by the CPU. However, some virtual; addresses may only be accessible to the CPU, some only accessible by the GPU,; and some by both. Using the constant memory space indicates that the data will not change during; the execution of the kernel. This allows scalar read instructions to be; used. The vector and scalar L1 caches are invalidated of volatile data before; each kernel dispatch execution to allow constant memory to change values between; kernel dispatches. The local memory space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates work-groups of wavefronts, and; freed when all the wavefronts of a work-group have terminated. The data store; (DS) instructions can be used to access it. The private memory space uses the hardware scratch memory support. If the kernel; uses scratch, then the hardware allocates memory that is accessed using; wavefront lane dword (4 byte) interleaving. The mapping used from private; address to physical address is:. ``wavefront-scratch-base +; (private-address * wavefront-size * 4) +; (wavefront-lane-id * 4)``. There are different ways that the wavefront scratch base address is determined; by a wavefront (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). This; memory can be accessed in an interleaved manner using buffer instruction with; the scratch buffer descriptor and per wavefront scratch offset, by the scratch; instructions, or by flat instructions. If each lane of a wavefront accesses the; same private address, the interleaving results in adjacent dwords being accessed; and hence requires fewer cache lines to be fetched. Multi-dword access is not; supported except by flat and scratch instructions in GFX9-GFX11. The generic address space uses the hardware flat address support available in; GFX7-GFX11. This uses two fixed ranges of virtual addresses (the pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:154483,allocate,allocates,154483,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocates']
Energy Efficiency,"==//; In order to have the same logical functionality as the ELF Reader, such; as:. - find scopes contribution to debug info; - sort by its physical location. The logical elements must have an unique offset (similar like the DWARF; DIE offset). //===----------------------------------------------------------------------===//; // Move 'initializeFileAndStringTables' to the COFF Library.; //===----------------------------------------------------------------------===//; There is some code in the CodeView reader that was extracted/adapted; from 'tools/llvm-readobj/COFFDumper.cpp' that can be moved to the COFF; library. We had a similar case with code shared with llvm-pdbutil that was moved; to the PDB library: https://reviews.llvm.org/D122226. //===----------------------------------------------------------------------===//; // Move 'getSymbolKindName'/'formatRegisterId' to the CodeView Library.; //===----------------------------------------------------------------------===//; There is some code in the CodeView reader that was extracted/adapted; from 'lib/DebugInfo/CodeView/SymbolDumper.cpp' that can be used. //===----------------------------------------------------------------------===//; // Use of std::unordered_set instead of std::set.; //===----------------------------------------------------------------------===//; https://reviews.llvm.org/D125784#inline-1221421. Replace the std::set usage for DeducedScopes, UnresolvedScopes and; IdentifiedNamespaces with std::unordered_set and get the benefit; of the O(1) while inserting/searching, as the order is not important. //===----------------------------------------------------------------------===//; // Optimize 'LVNamespaceDeduction::find' funtion.; //===----------------------------------------------------------------------===//; https://reviews.llvm.org/D125784#inline-1296195. Optimize the 'find' method to use the proposed code:. LVStringRefs::iterator Iter = std::find_if(Components.begin(), Components.end(),; [](StringRe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt:6113,adapt,adapted,6113,interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt,1,['adapt'],['adapted']
Energy Efficiency,"====. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libraries,; tools, etc. It is the responsibility of **every** LLVM developer to care for the core tier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc).; * Build infrastructure that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reverted, as per review policy.; * Bit-rot of a component in the core tier will result in that component being; downgraded to the peripheral tier or being removed. Sub-communities can; avoid this by fixing all raised issues in a timely manner. Peripheral Tier; ===============. The peripheral tier encompass the parts of LLVM that cater to a specific; sub-community and which don't usually affect the core components directly. This includes experimental back-ends, disabled-by-default options and; alternative paths (work-in-progress replacements) in the same repository, as; well as separate efforts to integrate LLVM development with local practices. It is the responsibility of each sub-community to care about their own parts; and the intersection of that with the core tier and other peripheral parts. There are three main groups of code that fit in this category:; * Co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:2755,green,green,2755,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst,1,['green'],['green']
Energy Efficiency,"=======; ThinLTO; =======. .. contents::; :local:. Introduction; ============. *ThinLTO* compilation is a new type of LTO that is both scalable and; incremental. *LTO* (Link Time Optimization) achieves better; runtime performance through whole-program analysis and cross-module; optimization. However, monolithic LTO implements this by merging all; input into a single module, which is not scalable; in time or memory, and also prevents fast incremental compiles. In ThinLTO mode, as with regular LTO, clang emits LLVM bitcode after the; compile phase. The ThinLTO bitcode is augmented with a compact summary; of the module. During the link step, only the summaries are read and; merged into a combined summary index, which includes an index of function; locations for later cross-module function importing. Fast and efficient; whole-program analysis is then performed on the combined summary index. However, all transformations, including function importing, occur; later when the modules are optimized in fully parallel backends.; By default, linkers_ that support ThinLTO are set up to launch; the ThinLTO backends in threads. So the usage model is not affected; as the distinction between the fast serial thin link step and the backends; is transparent to the user. For more information on the ThinLTO design and current performance,; see the LLVM blog post `ThinLTO: Scalable and Incremental LTO; <http://blog.llvm.org/2016/06/thinlto-scalable-and-incremental-lto.html>`_.; While tuning is still in progress, results in the blog post show that; ThinLTO already performs well compared to LTO, in many cases matching; the performance improvement. Current Status; ==============. Clang/LLVM; ----------; .. _compiler:. The 3.9 release of clang includes ThinLTO support. However, ThinLTO; is under active development, and new features, improvements and bugfixes; are being added for the next release. For the latest ThinLTO support,; `build a recent version of clang and LLVM; <https://llvm.org/docs/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst:817,efficient,efficient,817,interpreter/llvm-project/clang/docs/ThinLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst,1,['efficient'],['efficient']
Energy Efficiency,"========; GWP-ASan; ========. .. contents::; :local:; :depth: 2. Introduction; ============. GWP-ASan is a sampled allocator framework that assists in finding use-after-free; and heap-buffer-overflow bugs in production environments. It informally is a; recursive acronym, ""**G**\WP-ASan **W**\ill **P**\rovide **A**\llocation; **SAN**\ity"". GWP-ASan is based on the classic; `Electric Fence Malloc Debugger <https://linux.die.net/man/3/efence>`_, with a; key adaptation. Notably, we only choose a very small percentage of allocations; to sample, and apply guard pages to these sampled allocations only. The sampling; is small enough to allow us to have very low performance overhead. There is a small, tunable memory overhead that is fixed for the lifetime of the; process. This is approximately ~40KiB per process using the default settings,; depending on the average size of your allocations. GWP-ASan vs. ASan; =================. Unlike `AddressSanitizer <https://clang.llvm.org/docs/AddressSanitizer.html>`_,; GWP-ASan does not induce a significant performance overhead. ASan often requires; the use of dedicated canaries to be viable in production environments, and as; such is often impractical. GWP-ASan is only capable of finding a subset of the memory issues detected by; ASan. Furthermore, GWP-ASan's bug detection capabilities are only probabilistic.; As such, we recommend using ASan over GWP-ASan in testing, as well as anywhere; else that guaranteed error detection is more valuable than the 2x execution; slowdown/binary size bloat. For the majority of production environments, this; impact is too high, and GWP-ASan proves extremely useful. Design; ======. **Please note:** The implementation of GWP-ASan is largely in-flux, and these; details are subject to change. There are currently other implementations of; GWP-ASan, such as the implementation featured in; `Chromium <https://cs.chromium.org/chromium/src/components/gwp_asan/>`_. The; long-term support goal is to ensure feature-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:459,adapt,adaptation,459,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['adapt'],['adaptation']
Energy Efficiency,"==========. Because changing PSTATE.SM zeroes the FP/vector registers, it is best to emit; the ``smstart`` and ``smstop`` instructions before register allocation, so that; the register allocator can spill/reload registers around the mode change. The compiler should also have sufficient information on which operations are; part of the call/function's arguments/result and which operations are part of; the function's body, so that it can place the mode changes in exactly the right; position. The suitable place to do this seems to be SelectionDAG, where it lowers; the call's arguments/return values to implement the specified calling convention.; SelectionDAG provides Chains and Glue to specify the order of operations and give; preliminary control over the instruction's scheduling. Example of preserving state; ---------------------------. When passing and returning a ``float`` value to/from a function; that has a streaming interface from a function that has a normal interface, the; call-site will need to ensure that the argument/result registers are preserved; and that no other code is scheduled in between the ``smstart/smstop`` and the call. .. code-block:: llvm. define float @foo(float %f) nounwind {; %res = call float @bar(float %f) ""aarch64_pstate_sm_enabled""; ret float %res; }. declare float @bar(float) ""aarch64_pstate_sm_enabled"". The program needs to preserve the value of the floating point argument and; return value in register ``s0``:. .. code-block:: none. foo: // @foo; // %bb.0:; stp d15, d14, [sp, #-80]! // 16-byte Folded Spill; stp d13, d12, [sp, #16] // 16-byte Folded Spill; stp d11, d10, [sp, #32] // 16-byte Folded Spill; stp d9, d8, [sp, #48] // 16-byte Folded Spill; str x30, [sp, #64] // 8-byte Folded Spill; str s0, [sp, #76] // 4-byte Folded Spill; smstart sm; ldr s0, [sp, #76] // 4-byte Folded Reload; bl bar; str s0, [sp, #76] // 4-byte Folded Spill; smstop sm; ldp d9, d8, [sp, #48] // 16-byte Folded Reload; ldp d11, d10, [sp, #32] // 16-byte Folded Re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst:6662,schedul,scheduled,6662,interpreter/llvm-project/llvm/docs/AArch64SME.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst,1,['schedul'],['scheduled']
Energy Efficiency,"===========; Clang-Repl; ===========. **Clang-Repl** is an interactive C++ interpreter that allows for incremental; compilation. It supports interactive programming for C++ in a; read-evaluate-print-loop (REPL) style. It uses Clang as a library to compile the; high level programming language into LLVM IR. Then the LLVM IR is executed by; the LLVM just-in-time (JIT) infrastructure. Clang-Repl is suitable for exploratory programming and in places where time; to insight is important. Clang-Repl is a project inspired by the work in; `Cling <https://github.com/root-project/cling>`_, a LLVM-based C/C++ interpreter; developed by the field of high energy physics and used by the scientific data; analysis framework `ROOT <https://root.cern/>`_. Clang-Repl allows to move parts; of Cling upstream, making them useful and available to a broader audience. Clang-Repl Basic Data Flow; ==========================. .. image:: ClangRepl_design.png; :align: center; :alt: ClangRepl design. Clang-Repl data flow can be divided into roughly 8 phases:. 1. Clang-Repl controls the input infrastructure by an interactive prompt or by; an interface allowing the incremental processing of input. 2. Then it sends the input to the underlying incremental facilities in Clang; infrastructure. 3. Clang compiles the input into an AST representation. 4. When required the AST can be further transformed in order to attach specific; behavior. 5. The AST representation is then lowered to LLVM IR. 6. The LLVM IR is the input format for LLVM’s JIT compilation infrastructure.; The tool will instruct the JIT to run specified functions, translating them; into machine code targeting the underlying device architecture (eg. Intel; x86 or NVPTX). 7. The LLVM JIT lowers the LLVM IR to machine code. 8. The machine code is then executed. Build Instructions:; ===================. .. code-block:: console. $ cd llvm-project; $ mkdir build; $ cd build; $ cmake -DCMAKE_BUILD_TYPE=RelWithDebInfo -DLLVM_ENABLE_PROJECTS=clang -G ""U",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangRepl.rst:648,energy,energy,648,interpreter/llvm-project/clang/docs/ClangRepl.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangRepl.rst,1,['energy'],['energy']
Energy Efficiency,"============; Region Store; ============; The analyzer ""Store"" represents the contents of memory regions. It is an opaque; functional data structure stored in each ``ProgramState``; the only class that; can modify the store is its associated StoreManager. Currently (Feb. 2013), the only StoreManager implementation being used is; ``RegionStoreManager``. This store records bindings to memory regions using a; ""base region + offset"" key. (This allows ``*p`` and ``p[0]`` to map to the same; location, among other benefits.). Regions are grouped into ""clusters"", which roughly correspond to ""regions with; the same base region"". This allows certain operations to be more efficient,; such as invalidation. Regions that do not have a known offset use a special ""symbolic"" offset. These; keys store both the original region, and the ""concrete offset region"" -- the; last region whose offset is entirely concrete. (For example, in the expression; ``foo.bar[1][i].baz``, the concrete offset region is the array ``foo.bar[1]``,; since that has a known offset from the start of the top-level ``foo`` struct.). Binding Invalidation; --------------------. Supporting both concrete and symbolic offsets makes things a bit tricky. Here's; an example:. .. code-block:: cpp. foo[0] = 0;; foo[1] = 1;; foo[i] = i;. After the third assignment, nothing can be said about the value of ``foo[0]``,; because ``foo[i]`` may have overwritten it! Thus, *binding to a region with a; symbolic offset invalidates the entire concrete offset region.* We know; ``foo[i]`` is somewhere within ``foo``, so we don't have to invalidate; anything else, but we do have to be conservative about all other bindings within; ``foo``. Continuing the example:. .. code-block:: cpp. foo[i] = i;; foo[0] = 0;. After this latest assignment, nothing can be said about the value of ``foo[i]``,; because ``foo[0]`` may have overwritten it! *Binding to a region R with a; concrete offset invalidates any symbolic offset bindings whose concrete offse",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/RegionStore.rst:670,efficient,efficient,670,interpreter/llvm-project/clang/docs/analyzer/developer-docs/RegionStore.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/RegionStore.rst,1,['efficient'],['efficient']
Energy Efficiency,"=============; Type Metadata; =============. Type metadata is a mechanism that allows IR modules to co-operatively build; pointer sets corresponding to addresses within a given set of globals. LLVM's; `control flow integrity`_ implementation uses this metadata to efficiently; check (at each call site) that a given address corresponds to either a; valid vtable or function pointer for a given class or function type, and its; whole-program devirtualization pass uses the metadata to identify potential; callees for a given virtual call. To use the mechanism, a client creates metadata nodes with two elements:. 1. a byte offset into the global (generally zero for functions); 2. a metadata object representing an identifier for the type. These metadata nodes are associated with globals by using global object; metadata attachments with the ``!type`` metadata kind. Each type identifier must exclusively identify either global variables; or functions. .. admonition:: Limitation. The current implementation only supports attaching metadata to functions on; the x86-32 and x86-64 architectures. An intrinsic, :ref:`llvm.type.test <type.test>`, is used to test whether a; given pointer is associated with a type identifier. .. _control flow integrity: https://clang.llvm.org/docs/ControlFlowIntegrity.html. Representing Type Information using Type Metadata; =================================================. This section describes how Clang represents C++ type information associated with; virtual tables using type metadata. Consider the following inheritance hierarchy:. .. code-block:: c++. struct A {; virtual void f();; };. struct B : A {; virtual void f();; virtual void g();; };. struct C {; virtual void h();; };. struct D : A, C {; virtual void f();; virtual void h();; };. The virtual table objects for A, B, C and D look like this (under the Itanium ABI):. .. csv-table:: Virtual Table Layout for A, B, C, D; :header: Class, 0, 1, 2, 3, 4, 5, 6. A, A::offset-to-top, &A::rtti, &A::f; B, B::",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:264,efficient,efficiently,264,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst,1,['efficient'],['efficiently']
Energy Efficiency,"=============== ============== ========= =====================; String Key Value Type Required? Description; ============================ ============== ========= =====================; ""KernargSegmentSize"" integer Required The size in bytes of; the kernarg segment; that holds the values; of the arguments to; the kernel.; ""GroupSegmentFixedSize"" integer Required The amount of group; segment memory; required by a; work-group in; bytes. This does not; include any; dynamically allocated; group segment memory; that may be added; when the kernel is; dispatched.; ""PrivateSegmentFixedSize"" integer Required The amount of fixed; private address space; memory required for a; work-item in; bytes. If the kernel; uses a dynamic call; stack then additional; space must be added; to this value for the; call stack.; ""KernargSegmentAlign"" integer Required The maximum byte; alignment of; arguments in the; kernarg segment. Must; be a power of 2.; ""WavefrontSize"" integer Required Wavefront size. Must; be a power of 2.; ""NumSGPRs"" integer Required Number of scalar; registers used by a; wavefront for; GFX6-GFX11. This; includes the special; SGPRs for VCC, Flat; Scratch (GFX7-GFX10); and XNACK (for; GFX8-GFX10). It does; not include the 16; SGPR added if a trap; handler is; enabled. It is not; rounded up to the; allocation; granularity.; ""NumVGPRs"" integer Required Number of vector; registers used by; each work-item for; GFX6-GFX11; ""MaxFlatWorkGroupSize"" integer Required Maximum flat; work-group size; supported by the; kernel in work-items.; Must be >=1 and; consistent with; ReqdWorkGroupSize if; not 0, 0, 0.; ""NumSpilledSGPRs"" integer Number of stores from; a scalar register to; a register allocator; created spill; location.; ""NumSpilledVGPRs"" integer Number of stores from; a vector register to; a register allocator; created spill; location.; ============================ ============== ========= =====================. .. _amdgpu-amdhsa-code-object-metadata-v3:. Code Object V3 Metadata; ++",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:128512,power,power,128512,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['power'],['power']
Energy Efficiency,"===============; ShadowCallStack; ===============. .. contents::; :local:. Introduction; ============. ShadowCallStack is an instrumentation pass, currently only implemented for; aarch64, that protects programs against return address overwrites; (e.g. stack buffer overflows.) It works by saving a function's return address; to a separately allocated 'shadow call stack' in the function prolog in; non-leaf functions and loading the return address from the shadow call stack; in the function epilog. The return address is also stored on the regular stack; for compatibility with unwinders, but is otherwise unused. The aarch64 implementation is considered production ready, and; an `implementation of the runtime`_ has been added to Android's libc; (bionic). An x86_64 implementation was evaluated using Chromium and was found; to have critical performance and security deficiencies--it was removed in; LLVM 9.0. Details on the x86_64 implementation can be found in the; `Clang 7.0.1 documentation`_. .. _`implementation of the runtime`: https://android.googlesource.com/platform/bionic/+/808d176e7e0dd727c7f929622ec017f6e065c582/libc/bionic/pthread_create.cpp#128; .. _`Clang 7.0.1 documentation`: https://releases.llvm.org/7.0.1/tools/clang/docs/ShadowCallStack.html. Comparison; ----------. To optimize for memory consumption and cache locality, the shadow call; stack stores only an array of return addresses. This is in contrast to other; schemes, like :doc:`SafeStack`, that mirror the entire stack and trade-off; consuming more memory for shorter function prologs and epilogs with fewer; memory accesses. `Return Flow Guard`_ is a pure software implementation of shadow call stacks; on x86_64. Like the previous implementation of ShadowCallStack on x86_64, it is; inherently racy due to the architecture's use of the stack for calls and; returns. Intel `Control-flow Enforcement Technology`_ (CET) is a proposed hardware; extension that would add native support to use a shadow stack to store/c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ShadowCallStack.rst:341,allocate,allocated,341,interpreter/llvm-project/clang/docs/ShadowCallStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ShadowCallStack.rst,1,['allocate'],['allocated']
Energy Efficiency,"================; LeakSanitizer; ================. .. contents::; :local:. Introduction; ============. LeakSanitizer is a run-time memory leak detector. It can be combined with; :doc:`AddressSanitizer` to get both memory error and leak detection, or; used in a stand-alone mode. LSan adds almost no performance overhead; until the very end of the process, at which point there is an extra leak; detection phase. Usage; =====. :doc:`AddressSanitizer`: integrates LeakSanitizer and enables it by default on; supported platforms. .. code-block:: console. $ cat memory-leak.c; #include <stdlib.h>; void *p;; int main() {; p = malloc(7);; p = 0; // The memory is leaked here.; return 0;; }; % clang -fsanitize=address -g memory-leak.c ; ASAN_OPTIONS=detect_leaks=1 ./a.out; ==23646==ERROR: LeakSanitizer: detected memory leaks; Direct leak of 7 byte(s) in 1 object(s) allocated from:; #0 0x4af01b in __interceptor_malloc /projects/compiler-rt/lib/asan/asan_malloc_linux.cc:52:3; #1 0x4da26a in main memory-leak.c:4:7; #2 0x7f076fd9cec4 in __libc_start_main libc-start.c:287; SUMMARY: AddressSanitizer: 7 byte(s) leaked in 1 allocation(s). To use LeakSanitizer in stand-alone mode, link your program with; ``-fsanitize=leak`` flag. Make sure to use ``clang`` (not ``ld``) for the; link step, so that it would link in proper LeakSanitizer run-time library; into the final executable. Supported Platforms; ===================. * Android aarch64/i386/x86_64; * Fuchsia aarch64/x86_64; * Linux arm/aarch64/mips64/ppc64/ppc64le/riscv64/s390x/i386/x86\_64; * macOS aarch64/i386/x86\_64; * NetBSD i386/x86_64. More Information; ================. `<https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer>`_; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LeakSanitizer.rst:863,allocate,allocated,863,interpreter/llvm-project/clang/docs/LeakSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LeakSanitizer.rst,1,['allocate'],['allocated']
Energy Efficiency,"=================; TableGen BackEnds; =================. .. contents::; :local:. Introduction; ============. TableGen backends are at the core of TableGen's functionality. The source; files provide the classes and records that are parsed and end up as a; collection of record instances, but it's up to the backend to interpret and; print the records in a way that is meaningful to the user (normally a C++; include file or a textual list of warnings, options, and error messages). TableGen is used by both LLVM, Clang, and MLIR with very different goals.; LLVM uses it as a way to automate the generation of massive amounts of; information regarding instructions, schedules, cores, and architecture; features. Some backends generate output that is consumed by more than one; source file, so they need to be created in a way that makes it is easy for; preprocessor tricks to be used. Some backends can also print C++ code; structures, so that they can be directly included as-is. Clang, on the other hand, uses it mainly for diagnostic messages (errors,; warnings, tips) and attributes, so more on the textual end of the scale. MLIR uses TableGen to define operations, operation dialects, and operation; traits. See the :doc:`TableGen Programmer's Reference <./ProgRef>` for an in-depth; description of TableGen, and the :doc:`TableGen Backend Developer's Guide; <./BackGuide>` for a guide to writing a new backend. LLVM BackEnds; =============. .. warning::; This portion is incomplete. Each section below needs three subsections:; description of its purpose with a list of users, output generated from; generic input, and finally why it needed a new backend (in case there's; something similar). Overall, each backend will take the same TableGen file type and transform into; similar output for different targets/uses. There is an implicit contract between; the TableGen files, the back-ends and their users. For instance, a global contract is that each back-end produces macro-guarded; sections. Bas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst:664,schedul,schedules,664,interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,1,['schedul'],['schedules']
Energy Efficiency,"=================; TableGen Overview; =================. .. contents::; :local:. .. toctree::; :hidden:. BackEnds; BackGuide; ProgRef. Introduction; ============. TableGen's purpose is to help a human develop and maintain records of; domain-specific information. Because there may be a large number of these; records, it is specifically designed to allow writing flexible descriptions and; for common features of these records to be factored out. This reduces the; amount of duplication in the description, reduces the chance of error, and makes; it easier to structure domain specific information. The TableGen front end parses a file, instantiates the declarations, and; hands the result off to a domain-specific `backend`_ for processing. See; the :doc:`TableGen Programmer's Reference <./ProgRef>` for an in-depth; description of TableGen. See :doc:`tblgen - Description to C++ Code; <../CommandGuide/tblgen>` for details on the ``*-tblgen`` commands; that run the various flavors of TableGen. The current major users of TableGen are :doc:`The LLVM Target-Independent; Code Generator <../CodeGenerator>` and the `Clang diagnostics and attributes; <https://clang.llvm.org/docs/UsersManual.html#controlling-errors-and-warnings>`_. Note that if you work with TableGen frequently and use emacs or vim,; you can find an emacs ""TableGen mode"" and a vim language file in the; ``llvm/utils/emacs`` and ``llvm/utils/vim`` directories of your LLVM; distribution, respectively. .. _intro:. The TableGen program; ====================. TableGen files are interpreted by the TableGen program: `llvm-tblgen` available; on your build directory under `bin`. It is not installed in the system (or where; your sysroot is set to), since it has no use beyond LLVM's build process. Running TableGen; ----------------. TableGen runs just like any other LLVM tool. The first (optional) argument; specifies the file to read. If a filename is not specified, ``llvm-tblgen``; reads from standard input. To be useful, one of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/index.rst:452,reduce,reduces,452,interpreter/llvm-project/llvm/docs/TableGen/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/index.rst,2,['reduce'],['reduces']
Energy Efficiency,"======================; Control Flow Integrity; ======================. .. toctree::; :hidden:. ControlFlowIntegrityDesign. .. contents::; :local:. Introduction; ============. Clang includes an implementation of a number of control flow integrity (CFI); schemes, which are designed to abort the program upon detecting certain forms; of undefined behavior that can potentially allow attackers to subvert the; program's control flow. These schemes have been optimized for performance,; allowing developers to enable them in release builds. To enable Clang's available CFI schemes, use the flag ``-fsanitize=cfi``.; You can also enable a subset of available :ref:`schemes <cfi-schemes>`.; As currently implemented, all schemes rely on link-time optimization (LTO);; so it is required to specify ``-flto``, and the linker used must support LTO,; for example via the `gold plugin`_. To allow the checks to be implemented efficiently, the program must; be structured such that certain object files are compiled with CFI; enabled, and are statically linked into the program. This may preclude; the use of shared libraries in some cases. The compiler will only produce CFI checks for a class if it can infer hidden; LTO visibility for that class. LTO visibility is a property of a class that; is inferred from flags and attributes. For more details, see the documentation; for :doc:`LTO visibility <LTOVisibility>`. The ``-fsanitize=cfi-{vcall,nvcall,derived-cast,unrelated-cast}`` flags; require that a ``-fvisibility=`` flag also be specified. This is because the; default visibility setting is ``-fvisibility=default``, which would disable; CFI checks for classes without visibility attributes. Most users will want; to specify ``-fvisibility=hidden``, which enables CFI checks for such classes. Experimental support for :ref:`cross-DSO control flow integrity; <cfi-cross-dso>` exists that does not require classes to have hidden LTO; visibility. This cross-DSO support has unstable ABI at this time. .. _g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst:916,efficient,efficiently,916,interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst,1,['efficient'],['efficiently']
Energy Efficiency,"======================== ================================================================ =========================================; T __builtin_elementwise_abs(T x) return the absolute value of a number x; the absolute value of signed integer and floating point types; the most negative integer remains the most negative integer; T __builtin_elementwise_fma(T x, T y, T z) fused multiply add, (x * y) + z. floating point types; T __builtin_elementwise_ceil(T x) return the smallest integral value greater than or equal to x floating point types; T __builtin_elementwise_sin(T x) return the sine of x interpreted as an angle in radians floating point types; T __builtin_elementwise_cos(T x) return the cosine of x interpreted as an angle in radians floating point types; T __builtin_elementwise_floor(T x) return the largest integral value less than or equal to x floating point types; T __builtin_elementwise_log(T x) return the natural logarithm of x floating point types; T __builtin_elementwise_log2(T x) return the base 2 logarithm of x floating point types; T __builtin_elementwise_log10(T x) return the base 10 logarithm of x floating point types; T __builtin_elementwise_pow(T x, T y) return x raised to the power of y floating point types; T __builtin_elementwise_bitreverse(T x) return the integer represented after reversing the bits of x integer types; T __builtin_elementwise_exp(T x) returns the base-e exponential, e^x, of the specified value floating point types; T __builtin_elementwise_exp2(T x) returns the base-2 exponential, 2^x, of the specified value floating point types. T __builtin_elementwise_sqrt(T x) return the square root of a floating-point number floating point types; T __builtin_elementwise_roundeven(T x) round x to the nearest integer value in floating point format, floating point types; rounding halfway cases to even (that is, to the nearest value; that is an even integer), regardless of the current rounding; direction.; T __builtin_elementwise_round(T x) rou",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:23487,power,power,23487,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['power'],['power']
Energy Efficiency,"========================; Segmented Stacks in LLVM; ========================. .. contents::; :local:. Introduction; ============. Segmented stack allows stack space to be allocated incrementally than as a; monolithic chunk (of some worst case size) at thread initialization. This is; done by allocating stack blocks (henceforth called *stacklets*) and linking them; into a doubly linked list. The function prologue is responsible for checking if; the current stacklet has enough space for the function to execute; and if not,; call into the libgcc runtime to allocate more stack space. Segmented stacks are; enabled with the ``""split-stack""`` attribute on LLVM functions. The runtime functionality is `already there in libgcc; <http://gcc.gnu.org/wiki/SplitStacks>`_. Implementation Details; ======================. .. _allocating stacklets:. Allocating Stacklets; --------------------. As mentioned above, the function prologue checks if the current stacklet has; enough space. The current approach is to use a slot in the TCB to store the; current stack limit (minus the amount of space needed to allocate a new block) -; this slot's offset is again dictated by ``libgcc``. The generated; assembly looks like this on x86-64:. .. code-block:: text. leaq -8(%rsp), %r10; cmpq %fs:112, %r10; jg .LBB0_2. # More stack space needs to be allocated; movabsq $8, %r10 # The amount of space needed; movabsq $0, %r11 # The total size of arguments passed on stack; callq __morestack; ret # The reason for this extra return is explained below; .LBB0_2:; # Usual prologue continues here. The size of function arguments on the stack needs to be passed to; ``__morestack`` (this function is implemented in ``libgcc``) since that number; of bytes has to be copied from the previous stacklet to the current one. This is; so that SP (and FP) relative addressing of function arguments work as expected. The unusual ``ret`` is needed to have the function which made a call to; ``__morestack`` return correctly. ``__more",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst:171,allocate,allocated,171,interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,2,['allocate'],"['allocate', 'allocated']"
Energy Efficiency,"==========================; Sphinx Quickstart Template; ==========================. This article is intended to take someone in the state of “I want to write documentation and get it added to LLVM’s docs” and help them start writing documentation as fast as possible and with as little nonsense as possible. .. contents::; :local:. Overview; ========. LLVM documentation is written in `reStructuredText`_, a markup syntax similar to markdown (but much more powerful). The LLVM documentation site itself uses `Sphinx`_, a documentation generator originally written for Python documentation. .. _`reStructuredText`: http://www.sphinx-doc.org/en/master/usage/restructuredtext/basics.html; .. _`Sphinx`: http://www.sphinx-doc.org. How to use this template; ========================. This article is located in ``docs/SphinxQuickstartTemplate.rst``. To use it as a template, make a copy and open it in a text editor. You can then write your docs, and then send the new article to llvm-commits for review. To view the restructuredText source file for this article, click **Show Source** on the right sidebar. Authoring Guidelines; ====================. Focus on *content*. It is easy to fix the Sphinx (reStructuredText) syntax; later if necessary, although reStructuredText tries to imitate common; plain-text conventions so it should be quite natural. A basic knowledge of; reStructuredText syntax is useful when writing the document, so the last; ~half of this document (starting with `Example Section`_) gives examples; which should cover 99% of use cases. Let me say that again: focus on *content*. But if you really need to verify; Sphinx's output, see ``docs/README.txt`` for information. Once you have finished with the content, please send the ``.rst`` file to; llvm-commits for review. Creating New Articles; ---------------------. Before creating a new article, consider the following questions:. #. Why would I want to read this document?. #. What should I know to be able to follow along with t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst:457,power,powerful,457,interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst,1,['power'],['powerful']
Energy Efficiency,"============================= =========================. Release Process Summary; -----------------------. * Announce release schedule to the LLVM community and update the website. Do; this at least 3 weeks before the -rc1 release. * Create release branch and begin release process. * Send out release candidate sources for first round of testing. Testing lasts; 6 weeks. During the first round of testing, any regressions found should be; fixed. Patches are merged from mainline into the release branch. Also, all; features need to be completed during this time. Any features not completed at; the end of the first round of testing will be removed or disabled for the; release. * Generate and send out the second release candidate sources. Only *critical*; bugs found during this testing phase will be fixed. Any bugs introduced by; merged patches will be fixed. If so a third round of testing is needed. * The release notes are updated. * Finally, release!. * Announce bug fix release schedule to the LLVM community and update the website. * Do bug-fix releases every two weeks until X.1.5 or X.1.6 (if necessary). Release Process; ===============. .. contents::; :local:. Release Administrative Tasks; ----------------------------. This section describes a few administrative tasks that need to be done for the; release process to begin. Specifically, it involves:. * Updating version numbers,. * Creating the release branch, and. * Tagging release candidates for the release team to begin testing. Create Release Branch; ^^^^^^^^^^^^^^^^^^^^^. Branch the Git trunk using the following procedure:. #. Remind developers that the release branching is imminent and to refrain from; committing patches that might break the build. E.g., new features, large; patches for works in progress, an overhaul of the type system, an exciting; new TableGen feature, etc. #. Verify that the current git trunk is in decent shape by; examining nightly tester and buildbot results. #. Bump the version in trunk to N.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:2951,schedul,schedule,2951,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['schedul'],['schedule']
Energy Efficiency,"=============================; How To Validate a New Release; =============================. .. contents::; :local:; :depth: 1. Introduction; ============. This document contains information about testing the release candidates that; will ultimately be the next LLVM release. For more information on how to; manage the actual release, please refer to :doc:`HowToReleaseLLVM`. Overview of the Release Process; -------------------------------. Once the release process starts, the Release Manager will ask for volunteers,; and it'll be the role of each volunteer to:. * Test and benchmark the previous release. * Test and benchmark each release candidate, comparing to the previous release; and candidates. * Identify, reduce and report every regression found during tests and benchmarks. * Make sure the critical bugs get fixed and merged to the next release candidate. Not all bugs or regressions are show-stoppers and it's a bit of a grey area what; should be fixed before the next candidate and what can wait until the next; release. It'll depend on:. * The severity of the bug, how many people it affects and if it's a regression; or a known bug. Known bugs are ""unsupported features"" and some bugs can be; disabled if they have been implemented recently. * The stage in the release. Less critical bugs should be considered to be; fixed between RC1 and RC2, but not so much at the end of it. * If it's a correctness or a performance regression. Performance regression; tends to be taken more lightly than correctness. .. _scripts:. Scripts; =======. The scripts are in the ``utils/release`` directory. test-release.sh; ---------------. This script will check-out, configure and compile LLVM+Clang (+ most add-ons,; like ``compiler-rt``, ``libcxx``, ``libomp`` and ``clang-extra-tools``) in; three stages, and will test the final stage.; It'll have installed the final binaries on the Phase3/Releasei(+Asserts); directory, and that's the one you should use for the test-suite and other; external tes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst:717,reduce,reduce,717,interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,1,['reduce'],['reduce']
Energy Efficiency,"==============================. .. .. table:: AMDHSA Code Object V3 Kernel Argument Metadata Map; :name: amdgpu-amdhsa-code-object-kernel-argument-metadata-map-table-v3. ====================== ============== ========= ================================; String Key Value Type Required? Description; ====================== ============== ========= ================================; "".name"" string Kernel argument name.; "".type_name"" string Kernel argument type name.; "".size"" integer Required Kernel argument size in bytes.; "".offset"" integer Required Kernel argument offset in; bytes. The offset must be a; multiple of the alignment; required by the argument.; "".value_kind"" string Required Kernel argument kind that; specifies how to set up the; corresponding argument.; Values include:. ""by_value""; The argument is copied; directly into the kernarg. ""global_buffer""; A global address space pointer; to the buffer data is passed; in the kernarg. ""dynamic_shared_pointer""; A group address space pointer; to dynamically allocated LDS; is passed in the kernarg. ""sampler""; A global address space; pointer to a S# is passed in; the kernarg. ""image""; A global address space; pointer to a T# is passed in; the kernarg. ""pipe""; A global address space pointer; to an OpenCL pipe is passed in; the kernarg. ""queue""; A global address space pointer; to an OpenCL device enqueue; queue is passed in the; kernarg. ""hidden_global_offset_x""; The OpenCL grid dispatch; global offset for the X; dimension is passed in the; kernarg. ""hidden_global_offset_y""; The OpenCL grid dispatch; global offset for the Y; dimension is passed in the; kernarg. ""hidden_global_offset_z""; The OpenCL grid dispatch; global offset for the Z; dimension is passed in the; kernarg. ""hidden_none""; An argument that is not used; by the kernel. Space needs to; be left for it, but it does; not need to be set up. ""hidden_printf_buffer""; A global address space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive wit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:137141,allocate,allocated,137141,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"==============================; Convergent Operation Semantics; ==============================. .. contents::; :local:; :depth: 4. Overview; ========. Some parallel execution environments execute threads in groups that allow; efficient communication within the group using special primitives called; *convergent* operations. The outcome of a convergent operation is sensitive to; the set of threads that executes it ""together"", i.e., convergently. When control; flow :ref:`diverges <convergence-and-uniformity>`, i.e. threads of the same; group follow different; paths through the CFG, not all threads of the group may be available to; participate in this communication. This is the defining characteristic that; distinguishes convergent operations from other inter-thread communication:. A convergent operation involves inter-thread communication or synchronization; that occurs outside of the memory model, where the set of threads which; participate in communication is implicitly affected by control flow. For example, in the following GPU compute kernel, communication during the; convergent operation is expected to occur precisely among those threads of an; implementation-defined execution scope (such as workgroup or subgroup) for; which ``condition`` is true:. .. code-block:: c++. void example_kernel() {; ...; if (condition); convergent_operation();; ...; }. In structured programming languages, there is often an intuitive and; unambiguous way of determining the threads that are expected to communicate.; However, this is not always the case even in structured programming languages,; and the intuition breaks down entirely in unstructured control flow. This; document describes the formal semantics in LLVM, i.e. how to determine the set; of communicating threads for convergent operations. The definitions in this document leave many details open, such as how groups of; threads are formed in the first place. It focuses on the questions that are; relevant for deciding the correctness",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:226,efficient,efficient,226,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,1,['efficient'],['efficient']
Energy Efficiency,"==============================; LLVM Language Reference Manual; ==============================. .. contents::; :local:; :depth: 3. Abstract; ========. This document is a reference manual for the LLVM assembly language. LLVM; is a Static Single Assignment (SSA) based representation that provides; type safety, low-level operations, flexibility, and the capability of; representing 'all' high-level languages cleanly. It is the common code; representation used throughout all phases of the LLVM compilation; strategy. Introduction; ============. The LLVM code representation is designed to be used in three different; forms: as an in-memory compiler IR, as an on-disk bitcode representation; (suitable for fast loading by a Just-In-Time compiler), and as a human; readable assembly language representation. This allows LLVM to provide a; powerful intermediate representation for efficient compiler; transformations and analysis, while providing a natural means to debug; and visualize the transformations. The three different forms of LLVM are; all equivalent. This document describes the human readable; representation and notation. The LLVM representation aims to be light-weight and low-level while; being expressive, typed, and extensible at the same time. It aims to be; a ""universal IR"" of sorts, by being at a low enough level that; high-level ideas may be cleanly mapped to it (similar to how; microprocessors are ""universal IR's"", allowing many source languages to; be mapped to them). By providing type information, LLVM can be used as; the target of optimizations: for example, through pointer analysis, it; can be proven that a C automatic variable is never accessed outside of; the current function, allowing it to be promoted to a simple SSA value; instead of a memory location. .. _wellformed:. Well-Formedness; ---------------. It is important to note that this document describes 'well formed' LLVM; assembly language. There is a difference between what the parser accepts; and what is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:837,power,powerful,837,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['efficient', 'power']","['efficient', 'powerful']"
Energy Efficiency,"================================; How to submit an LLVM bug report; ================================. Introduction - Got bugs?; ========================. If you're working with LLVM and run into a bug, we definitely want to know; about it. This document describes what you can do to increase the odds of; getting it fixed quickly. 🔒 If you believe that the bug is security related, please follow :ref:`report-security-issue`. 🔒. Basically you have to do two things at a minimum. First, decide whether the; bug `crashes the compiler`_ or if the compiler is `miscompiling`_ the program; (i.e., the compiler successfully produces an executable, but it doesn't run; right). Based on what type of bug it is, follow the instructions in the; linked section to narrow down the bug so that the person who fixes it will be; able to find the problem more easily. Once you have a reduced test-case, go to `the LLVM Bug Tracking System; <https://github.com/llvm/llvm-project/issues>`_ and fill out the form with the; necessary details (note that you don't need to pick a label, just use if you're; not sure). The bug description should contain the following information:. * All information necessary to reproduce the problem.; * The reduced test-case that triggers the bug.; * The location where you obtained LLVM (if not from our Git; repository). Thanks for helping us make LLVM better!. .. _crashes the compiler:. Crashing Bugs; =============. More often than not, bugs in the compiler cause it to crash---often due to; an assertion failure of some sort. The most important piece of the puzzle; is to figure out if it is crashing in the Clang front-end or if it is one of; the LLVM libraries (e.g. the optimizer or code generator) that has; problems. To figure out which component is crashing (the front-end, middle-end; optimizer, or backend code generator), run the ``clang`` command line as you; were when the crash occurred, but with the following extra command line; options:. * ``-emit-llvm -Xclang -disab",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:868,reduce,reduced,868,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduced']
Energy Efficiency,"=================================; How To Release LLVM To The Public; =================================. Introduction; ============. This document contains information about successfully releasing LLVM ---; including sub-projects: e.g., ``clang`` and ``compiler-rt`` --- to the public.; It is the Release Manager's responsibility to ensure that a high quality build; of LLVM is released. If you're looking for the document on how to test the release candidates and; create the binary packages, please refer to the :doc:`ReleaseProcess` instead. .. _timeline:. Release Timeline; ================. LLVM is released on a time based schedule --- with major releases roughly; every 6 months. In between major releases there may be dot releases.; The release manager will determine if and when to make a dot release based; on feedback from the community. Typically, dot releases should be made if; there are large number of bug-fixes in the stable branch or a critical bug; has been discovered that affects a large number of users. Unless otherwise stated, dot releases will follow the same procedure as; major releases. Annual Release Schedule; -----------------------. Here is the annual release schedule for LLVM. This is meant to be a; guide, and release managers are not required to follow this exactly.; Releases should be tagged on Tuesdays. =============================== =========================; Release Approx. Date; =============================== =========================; *release branch: even releases* *4th Tue in January*; *release branch: odd releases* *4th Tue in July*; X.1.0-rc1 3 days after branch.; X.1.0-rc2 2 weeks after branch.; X.1.0-rc3 4 weeks after branch; **X.1.0-final** **6 weeks after branch**; **X.1.1** **8 weeks after branch**; **X.1.2** **10 weeks after branch**; **X.1.3** **12 weeks after branch**; **X.1.4** **14 weeks after branch**; **X.1.5** **16 weeks after branch**; **X.1.6 (if necessary)** **18 weeks after branch**; =============================== =======",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:629,schedul,schedule,629,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['schedul'],['schedule']
Energy Efficiency,"==================================; Benchmarking tips; ==================================. Introduction; ============. For benchmarking a patch we want to reduce all possible sources of; noise as much as possible. How to do that is very OS dependent. Note that low noise is required, but not sufficient. It does not; exclude measurement bias. See; https://www.cis.upenn.edu/~cis501/papers/producing-wrong-data.pdf for; example. General; ================================. * Use a high resolution timer, e.g. perf under linux. * Run the benchmark multiple times to be able to recognize noise. * Disable as many processes or services as possible on the target system. * Disable frequency scaling, turbo boost and address space; randomization (see OS specific section). * Static link if the OS supports it. That avoids any variation that; might be introduced by loading dynamic libraries. This can be done; by passing ``-DLLVM_BUILD_STATIC=ON`` to cmake. * Try to avoid storage. On some systems you can use tmpfs. Putting the; program, inputs and outputs on tmpfs avoids touching a real storage; system, which can have a pretty big variability. To mount it (on linux and freebsd at least)::. mount -t tmpfs -o size=<XX>g none dir_to_mount. Linux; =====. * Disable address space randomization::. echo 0 > /proc/sys/kernel/randomize_va_space. * Set scaling_governor to performance::. for i in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; do; echo performance > /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; done. * Use https://github.com/lpechacek/cpuset to reserve cpus for just the; program you are benchmarking. If using perf, leave at least 2 cores; so that perf runs in one and your program in another::. cset shield -c N1,N2 -k on. This will move all threads out of N1 and N2. The ``-k on`` means; that even kernel threads are moved out. * Disable the SMT pair of the cpus you will use for the benchmark. The; pair of cpu N can be found in; ``/sys/devices/system/cpu/cpuN/topology/t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Benchmarking.rst:155,reduce,reduce,155,interpreter/llvm-project/llvm/docs/Benchmarking.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Benchmarking.rst,1,['reduce'],['reduce']
Energy Efficiency,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:169,allocate,allocated,169,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,1,['allocate'],['allocated']
Energy Efficiency,"====================================; LLVM bugpoint tool: design and usage; ====================================. .. contents::; :local:. Description; ===========. ``bugpoint`` narrows down the source of problems in LLVM tools and passes. It; can be used to debug three types of failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:436,reduce,reduce,436,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,2,['reduce'],['reduce']
Energy Efficiency,"=====================================; How to start LLVM Social in your town; =====================================. Here are several ideas you can take into account when designing your specific; LLVM Social. Before you start, it is essential to make sure that the meetup is as welcoming; as any other event related to LLVM. Therefore you shall follow LLVM's; `Code of Conduct <https://llvm.org/docs/CodeOfConduct.html>`_. Other than that - your mileage may vary. Please adapt your social to what works; best for your specific situation. General suggestions; -------------------. * We highly recommend that you join the official LLVM meetup organization. In; addition to covering the cost of the meetup, all LLVM meetups are advertised; together and easily found by potential attendees. Please contact; arnaud.degrandmaison@llvm.org for more details.; * Beware of cultural differences: what works well in one region may not work in; other part of the world.; * Do not be alone to organize the meetup. Try to work with a couple other; organizers. This is more motivating as an organizer, and this makes the; meetup more resilient over time.; * Each event can have a different form such as a social event, or; a hackathon/workshop, or a 'mini-conference' with one or more talks. You do; not have to stick to one format forever.; * Whatever format you choose, `LLVM Weekly <http://llvmweekly.org/>`_ is an; excellent topic starter: go through the 3-4 recent LLVM Weekly posts and; prepare a list of the most interesting/notable news and discuss them with the; group. Advertisement; -------------. * Try to advertise via similar meetups/user groups; * Advertise your meetup on the mailing lists (llvm-dev, cfe-dev, lldb-dev,; ...). Feel free to post to all of them, or at least to llvm-dev.; But as these mailing lists have high traffic and some LLVM developers are not; very active on them, you may reach more interested people using the mailing; feature from meetup.com.; * Advertise the meetup on Twitt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MeetupGuidelines.rst:471,adapt,adapt,471,interpreter/llvm-project/llvm/docs/MeetupGuidelines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MeetupGuidelines.rst,1,['adapt'],['adapt']
Energy Efficiency,"==========================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of instructions.; From IR to object emission, the major transformations which affect variable; location fidelity are:. 1. Instruction Selection; 2. Register allocation; 3. Block layout. each of which are discussed below. In addition, instruction scheduling can; significantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simple MachineFunction table.; Location changes in the prologue and epilogue of a function are also ignored:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output binary to; describe, and should be stepped over by debuggers anyway. Variable locations in Instruction Selection and MIR; ---------------------------------------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:24863,schedul,scheduling,24863,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['schedul'],['scheduling']
Energy Efficiency,"=============================================; My First Language Frontend with LLVM Tutorial; =============================================. .. toctree::; :hidden:. LangImpl01; LangImpl02; LangImpl03; LangImpl04; LangImpl05; LangImpl06; LangImpl07; LangImpl08; LangImpl09; LangImpl10. **Requirements:** This tutorial assumes you know C++, but no previous; compiler experience is necessary. Welcome to the ""My First Language Frontend with LLVM"" tutorial. Here we; run through the implementation of a simple language, showing; how fun and easy it can be. This tutorial will get you up and running; fast and show a concrete example of something that uses LLVM to generate; code. This tutorial introduces the simple ""Kaleidoscope"" language, building it; iteratively over the course of several chapters, showing how it is built; over time. This lets us cover a range of language design and LLVM-specific; ideas, showing and explaining the code for it all along the way,; and reduces the overwhelming amount of details up front. We strongly; encourage that you *work with this code* - make a copy and hack it up and; experiment. **Warning**: In order to focus on teaching compiler techniques and LLVM; specifically,; this tutorial does *not* show best practices in software engineering; principles. For example, the code uses global variables; pervasively, doesn't use; `visitors <http://en.wikipedia.org/wiki/Visitor_pattern>`_, etc... but; instead keeps things simple and focuses on the topics at hand. This tutorial is structured into chapters covering individual topics,; allowing you to skip ahead as you wish:. - `Chapter #1: Kaleidoscope language and Lexer <LangImpl01.html>`_ -; This shows where we are; going and the basic functionality that we want to build. A lexer; is also the first part of building a parser for a language, and we; use a simple C++ lexer which is easy to understand.; - `Chapter #2: Implementing a Parser and AST <LangImpl02.html>`_ -; With the lexer in place, we can talk abo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/index.rst:970,reduce,reduces,970,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/index.rst,1,['reduce'],['reduces']
Energy Efficiency,"==============================================; Kaleidoscope: Adding JIT and Optimizer Support; ==============================================. .. contents::; :local:. Chapter 4 Introduction; ======================. Welcome to Chapter 4 of the ""`Implementing a language with; LLVM <index.html>`_"" tutorial. Chapters 1-3 described the implementation; of a simple language and added support for generating LLVM IR. This; chapter describes two new techniques: adding optimizer support to your; language, and adding JIT compiler support. These additions will; demonstrate how to get nice, efficient code for the Kaleidoscope; language. Trivial Constant Folding; ========================. Our demonstration for Chapter 3 is elegant and easy to extend.; Unfortunately, it does not produce wonderful code. The IRBuilder,; however, does give us obvious optimizations when compiling simple code:. ::. ready> def test(x) 1+2+x;; Read function definition:; define double @test(double %x) {; entry:; %addtmp = fadd double 3.000000e+00, %x; ret double %addtmp; }. This code is not a literal transcription of the AST built by parsing the; input. That would be:. ::. ready> def test(x) 1+2+x;; Read function definition:; define double @test(double %x) {; entry:; %addtmp = fadd double 2.000000e+00, 1.000000e+00; %addtmp1 = fadd double %addtmp, %x; ret double %addtmp1; }. Constant folding, as seen above, in particular, is a very common and; very important optimization: so much so that many language implementors; implement constant folding support in their AST representation. With LLVM, you don't need this support in the AST. Since all calls to; build LLVM IR go through the LLVM IR builder, the builder itself checked; to see if there was a constant folding opportunity when you call it. If; so, it just does the constant fold and return the constant instead of; creating an instruction. Well, that was easy :). In practice, we recommend always using; ``IRBuilder`` when generating code like this. It has no ""s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:585,efficient,efficient,585,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['efficient'],['efficient']
Energy Efficiency,"=================================================; Choosing the Right Interface for Your Application; =================================================. Clang provides infrastructure to write tools that need syntactic and semantic; information about a program. This document will give a short introduction of; the different ways to write clang tools, and their pros and cons. LibClang; --------. `LibClang <https://clang.llvm.org/doxygen/group__CINDEX.html>`_ is a stable high; level C interface to clang. When in doubt LibClang is probably the interface; you want to use. Consider the other interfaces only when you have a good; reason not to use LibClang. Canonical examples of when to use LibClang:. * Xcode; * Clang Python Bindings. Use LibClang when you...:. * want to interface with clang from other languages than C++; * need a stable interface that takes care to be backwards compatible; * want powerful high-level abstractions, like iterating through an AST with a; cursor, and don't want to learn all the nitty gritty details of Clang's AST. Do not use LibClang when you...:. * want full control over the Clang AST. Clang Plugins; -------------. :doc:`Clang Plugins <ClangPlugins>` allow you to run additional actions on the; AST as part of a compilation. Plugins are dynamic libraries that are loaded at; runtime by the compiler, and they're easy to integrate into your build; environment. Canonical examples of when to use Clang Plugins:. * special lint-style warnings or errors for your project; * creating additional build artifacts from a single compile step. Use Clang Plugins when you...:. * need your tool to rerun if any of the dependencies change; * want your tool to make or break a build; * need full control over the Clang AST. Do not use Clang Plugins when you...:. * want to run tools outside of your build environment; * want full control on how Clang is set up, including mapping of in-memory; virtual files; * need to run over a specific subset of files in your project whi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Tooling.rst:903,power,powerful,903,interpreter/llvm-project/clang/docs/Tooling.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Tooling.rst,1,['power'],['powerful']
Energy Efficiency,"==================================================; Kaleidoscope: Extending the Language: Control Flow; ==================================================. .. contents::; :local:. Chapter 5 Introduction; ======================. Welcome to Chapter 5 of the ""`Implementing a language with; LLVM <index.html>`_"" tutorial. Parts 1-4 described the implementation of; the simple Kaleidoscope language and included support for generating; LLVM IR, followed by optimizations and a JIT compiler. Unfortunately, as; presented, Kaleidoscope is mostly useless: it has no control flow other; than call and return. This means that you can't have conditional; branches in the code, significantly limiting its power. In this episode; of ""build that compiler"", we'll extend Kaleidoscope to have an; if/then/else expression plus a simple 'for' loop. If/Then/Else; ============. Extending Kaleidoscope to support if/then/else is quite straightforward.; It basically requires adding support for this ""new"" concept to the; lexer, parser, AST, and LLVM code emitter. This example is nice, because; it shows how easy it is to ""grow"" a language over time, incrementally; extending it as new ideas are discovered. Before we get going on ""how"" we add this extension, let's talk about; ""what"" we want. The basic idea is that we want to be able to write this; sort of thing:. ::. def fib(x); if x < 3 then; 1; else; fib(x-1)+fib(x-2);. In Kaleidoscope, every construct is an expression: there are no; statements. As such, the if/then/else expression needs to return a value; like any other. Since we're using a mostly functional form, we'll have; it evaluate its conditional, then return the 'then' or 'else' value; based on how the condition was resolved. This is very similar to the C; ""?:"" expression. The semantics of the if/then/else expression is that it evaluates the; condition to a boolean equality value: 0.0 is considered to be false and; everything else is considered to be true. If the condition is true, the; first ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl05.rst:694,power,power,694,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl05.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl05.rst,1,['power'],['power']
Energy Efficiency,"======================================================; How to set up LLVM-style RTTI for your class hierarchy; ======================================================. .. contents::. Background; ==========. LLVM avoids using C++'s built in RTTI. Instead, it pervasively uses its; own hand-rolled form of RTTI which is much more efficient and flexible,; although it requires a bit more work from you as a class author. A description of how to use LLVM-style RTTI from a client's perspective is; given in the `Programmer's Manual <ProgrammersManual.html#isa>`_. This; document, in contrast, discusses the steps you need to take as a class; hierarchy author to make LLVM-style RTTI available to your clients. Before diving in, make sure that you are familiar with the Object Oriented; Programming concept of ""`is-a`_"". .. _is-a: http://en.wikipedia.org/wiki/Is-a. Basic Setup; ===========. This section describes how to set up the most basic form of LLVM-style RTTI; (which is sufficient for 99.9% of the cases). We will set up LLVM-style; RTTI for this class hierarchy:. .. code-block:: c++. class Shape {; public:; Shape() {}; virtual double computeArea() = 0;; };. class Square : public Shape {; double SideLength;; public:; Square(double S) : SideLength(S) {}; double computeArea() override;; };. class Circle : public Shape {; double Radius;; public:; Circle(double R) : Radius(R) {}; double computeArea() override;; };. The most basic working setup for LLVM-style RTTI requires the following; steps:. #. In the header where you declare ``Shape``, you will want to ``#include; ""llvm/Support/Casting.h""``, which declares LLVM's RTTI templates. That; way your clients don't even have to think about it. .. code-block:: c++. #include ""llvm/Support/Casting.h"". #. In the base class, introduce an enum which discriminates all of the; different concrete classes in the hierarchy, and stash the enum value; somewhere in the base class. Here is the code after introducing this change:. .. code-block:: c++. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst:328,efficient,efficient,328,interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,1,['efficient'],['efficient']
Energy Efficiency,"======================================================; LLVM Link Time Optimization: Design and Implementation; ======================================================. .. contents::; :local:. Description; ===========. LLVM features powerful intermodular optimizations which can be used at link; time. Link Time Optimization (LTO) is another name for intermodular; optimization when performed during the link stage. This document describes the; interface and design between the LTO optimizer and the linker. Design Philosophy; =================. The LLVM Link Time Optimizer provides complete transparency, while doing; intermodular optimization, in the compiler tool chain. Its main goal is to let; the developer take advantage of intermodular optimizations without making any; significant changes to the developer's makefiles or build system. This is; achieved through tight integration with the linker. In this model, the linker; treats LLVM bitcode files like native object files and allows mixing and; matching among them. The linker uses `libLTO`_, a shared object, to handle LLVM; bitcode files. This tight integration between the linker and LLVM optimizer; helps to do optimizations that are not possible in other models. The linker; input allows the optimizer to avoid relying on conservative escape analysis. .. _libLTO-example:. Example of link time optimization; ---------------------------------. The following example illustrates the advantages of LTO's integrated approach; and clean interface. This example requires a system linker which supports LTO; through the interface described in this document. Here, clang transparently; invokes system linker. * Input source file ``a.c`` is compiled into LLVM bitcode form.; * Input source file ``main.c`` is compiled into native object code. .. code-block:: c++. --- a.h ---; extern int foo1(void);; extern void foo2(void);; extern void foo4(void);. --- a.c ---; #include ""a.h"". static signed int i = 0;. void foo2(void) {; i = -1;; }. static ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:232,power,powerful,232,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['power'],['powerful']
Energy Efficiency,"============================================================; Kaleidoscope: Extending the Language: User-defined Operators; ============================================================. .. contents::; :local:. Chapter 6 Introduction; ======================. Welcome to Chapter 6 of the ""`Implementing a language with; LLVM <index.html>`_"" tutorial. At this point in our tutorial, we now; have a fully functional language that is fairly minimal, but also; useful. There is still one big problem with it, however. Our language; doesn't have many useful operators (like division, logical negation, or; even any comparisons besides less-than). This chapter of the tutorial takes a wild digression into adding; user-defined operators to the simple and beautiful Kaleidoscope; language. This digression now gives us a simple and ugly language in; some ways, but also a powerful one at the same time. One of the great; things about creating your own language is that you get to decide what; is good or bad. In this tutorial we'll assume that it is okay to use; this as a way to show some interesting parsing techniques. At the end of this tutorial, we'll run through an example Kaleidoscope; application that `renders the Mandelbrot set <#kicking-the-tires>`_. This gives an; example of what you can build with Kaleidoscope and its feature set. User-defined Operators: the Idea; ================================. The ""operator overloading"" that we will add to Kaleidoscope is more; general than in languages like C++. In C++, you are only allowed to; redefine existing operators: you can't programmatically change the; grammar, introduce new operators, change precedence levels, etc. In this; chapter, we will add this capability to Kaleidoscope, which will let the; user round out the set of operators that are supported. The point of going into user-defined operators in a tutorial like this; is to show the power and flexibility of using a hand-written parser.; Thus far, the parser we have been implement",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst:863,power,powerful,863,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst,1,['power'],['powerful']
Energy Efficiency,"===================================================================; How to Cross Compile Compiler-rt Builtins For Arm; ===================================================================. Introduction; ============. This document contains information about building and testing the builtins part; of compiler-rt for an Arm target, from an x86_64 Linux machine. While this document concentrates on Arm and Linux the general principles should; apply to other targets supported by compiler-rt. Further contributions for other; targets are welcome. The instructions in this document depend on libraries and programs external to; LLVM, there are many ways to install and configure these dependencies so you; may need to adapt the instructions here to fit your own local situation. Prerequisites; =============. In this use case we'll be using cmake on a Debian-based Linux system,; cross-compiling from an x86_64 host to a hard-float Armv7-A target. We'll be; using as many of the LLVM tools as we can, but it is possible to use GNU; equivalents. * ``A build of LLVM/clang for the llvm-tools and llvm-config``; * ``A clang executable with support for the ARM target``; * ``compiler-rt sources``; * ``The qemu-arm user mode emulator``; * ``An arm-linux-gnueabihf sysroot``. In this example we will be using ninja. See https://compiler-rt.llvm.org/ for more information about the dependencies; on clang and LLVM. See https://llvm.org/docs/GettingStarted.html for information about obtaining; the source for LLVM and compiler-rt. Note that the getting started guide; places compiler-rt in the projects subdirectory, but this is not essential and; if you are using the BaremetalARM.cmake cache for v6-M, v7-M and v7-EM then; compiler-rt must be placed in the runtimes directory. ``qemu-arm`` should be available as a package for your Linux distribution. The most complicated of the prerequisites to satisfy is the arm-linux-gnueabihf; sysroot. In theory it is possible to use the Linux distributions multiarch",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToCrossCompileBuiltinsOnArm.rst:716,adapt,adapt,716,interpreter/llvm-project/llvm/docs/HowToCrossCompileBuiltinsOnArm.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToCrossCompileBuiltinsOnArm.rst,1,['adapt'],['adapt']
Energy Efficiency,"=======================================================================; Building a JIT: Extreme Laziness - Using LazyReexports to JIT from ASTs; =======================================================================. .. contents::; :local:. **This tutorial is under active development. It is incomplete and details may; change frequently.** Nonetheless we invite you to try it out as it stands, and; we welcome any feedback. Chapter 4 Introduction; ======================. Welcome to Chapter 4 of the ""Building an ORC-based JIT in LLVM"" tutorial. This; chapter introduces custom MaterializationUnits and Layers, and the lazy; reexports API. Together these will be used to replace the CompileOnDemandLayer; from `Chapter 3 <BuildingAJIT3.html>`_ with a custom lazy-JITing scheme that JITs; directly from Kaleidoscope ASTs. **To be done:**. **(1) Describe the drawbacks of JITing from IR (have to compile to IR first,; which reduces the benefits of laziness).**. **(2) Describe CompileCallbackManagers and IndirectStubManagers in detail.**. **(3) Run through the implementation of addFunctionAST.**. Full Code Listing; =================. Here is the complete code listing for our running example that JITs lazily from; Kaleidoscope ASTS. To build this example, use:. .. code-block:: bash. # Compile; clang++ -g toy.cpp `llvm-config --cxxflags --ldflags --system-libs --libs core orcjit native` -O3 -o toy; # Run; ./toy. Here is the code:. .. literalinclude:: ../../examples/Kaleidoscope/BuildingAJIT/Chapter4/KaleidoscopeJIT.h; :language: c++. `Next: Remote-JITing -- Process-isolation and laziness-at-a-distance <BuildingAJIT5.html>`_; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT4.rst:925,reduce,reduces,925,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT4.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT4.rst,1,['reduce'],['reduces']
Energy Efficiency,"==============================================================================; Cling Release License; ==============================================================================; Copyright (c) 2007-2014 by the Authors.; All rights reserved. Developed by:. The ROOT Team; CERN and Fermilab; http://cern.ch/cling. You may license this software under one of the following licenses, marked; ""UI/NCSAOSL"" and ""LGPL"". ==============================================================================; UI/NCSAOSL; ==============================================================================; University of Illinois/NCSA; Open Source License. Permission is hereby granted, free of charge, to any person obtaining a copy of; this software and associated documentation files (the ""Software""), to deal with; the Software without restriction, including without limitation the rights to; use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies; of the Software, and to permit persons to whom the Software is furnished to do; so, subject to the following conditions:. * Redistributions of source code must retain the above copyright notice,; this list of conditions and the following disclaimers. * Redistributions in binary form must reproduce the above copyright notice,; this list of conditions and the following disclaimers in the; documentation and/or other materials provided with the distribution. * Neither the names of the LLVM Team, University of Illinois at; Urbana-Champaign, nor the names of its contributors may be used to; endorse or promote products derived from this Software without specific; prior written permission. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS; FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/LICENSE.TXT:676,charge,charge,676,interpreter/cling/LICENSE.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/LICENSE.TXT,1,['charge'],['charge']
Energy Efficiency,"==============================================================================; LLVM Release License; ==============================================================================; University of Illinois/NCSA; Open Source License. Copyright (c) 2003-2010 University of Illinois at Urbana-Champaign.; All rights reserved. Developed by:. LLVM Team. University of Illinois at Urbana-Champaign. http://llvm.org. Permission is hereby granted, free of charge, to any person obtaining a copy of; this software and associated documentation files (the ""Software""), to deal with; the Software without restriction, including without limitation the rights to; use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies; of the Software, and to permit persons to whom the Software is furnished to do; so, subject to the following conditions:. * Redistributions of source code must retain the above copyright notice,; this list of conditions and the following disclaimers. * Redistributions in binary form must reproduce the above copyright notice,; this list of conditions and the following disclaimers in the; documentation and/or other materials provided with the distribution. * Neither the names of the LLVM Team, University of Illinois at; Urbana-Champaign, nor the names of its contributors may be used to; endorse or promote products derived from this Software without specific; prior written permission. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS; FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE; SOFTWARE. ==============================================================================; Copyrights and Licenses for ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/textinput/src/textinput/LICENSE.TXT:447,charge,charge,447,core/textinput/src/textinput/LICENSE.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/textinput/src/textinput/LICENSE.TXT,1,['charge'],['charge']
Energy Efficiency,"==============================================================================; The LLVM Project is under the Apache License v2.0 with LLVM Exceptions:; ==============================================================================. Apache License; Version 2.0, January 2004; http://www.apache.org/licenses/. TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION. 1. Definitions. ""License"" shall mean the terms and conditions for use, reproduction,; and distribution as defined by Sections 1 through 9 of this document. ""Licensor"" shall mean the copyright owner or entity authorized by; the copyright owner that is granting the License. ""Legal Entity"" shall mean the union of the acting entity and all; other entities that control, are controlled by, or are under common; control with that entity. For the purposes of this definition,; ""control"" means (i) the power, direct or indirect, to cause the; direction or management of such entity, whether by contract or; otherwise, or (ii) ownership of fifty percent (50%) or more of the; outstanding shares, or (iii) beneficial ownership of such entity. ""You"" (or ""Your"") shall mean an individual or Legal Entity; exercising permissions granted by this License. ""Source"" form shall mean the preferred form for making modifications,; including but not limited to software source code, documentation; source, and configuration files. ""Object"" form shall mean any form resulting from mechanical; transformation or translation of a Source form, including but; not limited to compiled object code, generated documentation,; and conversions to other media types. ""Work"" shall mean the work of authorship, whether in Source or; Object form, made available under the License, as indicated by a; copyright notice that is included in or attached to the work; (an example is provided in the Appendix below). ""Derivative Works"" shall mean any work, whether in Source or Object; form, that is based on (or derived from) the Work and for which the; editorial revi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT:867,power,power,867,interpreter/llvm-project/clang/LICENSE.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT,4,['power'],['power']
Energy Efficiency,"=init; src:bad/init/files/*=init. Suppressing memory leaks; ------------------------. Memory leak reports produced by :doc:`LeakSanitizer` (if it is run as a part; of AddressSanitizer) can be suppressed by a separate file passed as. .. code-block:: bash. LSAN_OPTIONS=suppressions=MyLSan.supp. which contains lines of the form `leak:<pattern>`. Memory leak will be; suppressed if pattern matches any function name, source file name, or; library name in the symbolized stack trace of the leak report. See; `full documentation; <https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer#suppressions>`_; for more details. Code generation control; =======================. Instrumentation code outlining; ------------------------------. By default AddressSanitizer inlines the instrumentation code to improve the; run-time performance, which leads to increased binary size. Using the; (clang flag ``-fsanitize-address-outline-instrumentation` default: ``false``); flag forces all code instrumentation to be outlined, which reduces the size; of the generated code, but also reduces the run-time performance. Limitations; ===========. * AddressSanitizer uses more real memory than a native run. Exact overhead; depends on the allocations sizes. The smaller the allocations you make the; bigger the overhead is.; * AddressSanitizer uses more stack memory. We have seen up to 3x increase.; * On 64-bit platforms AddressSanitizer maps (but not reserves) 16+ Terabytes of; virtual address space. This means that tools like ``ulimit`` may not work as; usually expected.; * Static linking of executables is not supported. Supported Platforms; ===================. AddressSanitizer is supported on:. * Linux i386/x86\_64 (tested on Ubuntu 12.04); * macOS 10.7 - 10.11 (i386/x86\_64); * iOS Simulator; * Android ARM; * NetBSD i386/x86\_64; * FreeBSD i386/x86\_64 (tested on FreeBSD 11-current); * Windows 8.1+ (i386/x86\_64). Ports to various other platforms are in progress. Current Status; ========",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:12117,reduce,reduces,12117,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,2,['reduce'],['reduces']
Energy Efficiency,"=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; git -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release bran",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:34968,green,greened,34968,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['green'],['greened']
Energy Efficiency,">SetPoint(2, 0.01150, 30.00);; graph->Draw(""AL*"");; graph->GetXaxis()->SetTitle(""foo"") ;; gPad->SetLogx(1) ;; }; . New method IsInside(x,y). TMultiGraph. New method IsInside(x,y). THStack. The color index used to erase the background while drawing a stack of 1D; histogram was wrong. TF1. Bug fixed in TF1 zooming on Y axis. To reproduce it do:; ; root [0] TF1 f1( ""f1"", ""-x"", 1,3); root [1] f1.Draw(); ; now selecting some range on the y-axis with the mouse; jumped to the range (0, 1) instead of chosen range.; ; Add in TF1::GetX and TF1::GetMaximum, TF1::GetMinimum and; TF1::GetMaximumX, TF1::GetMinimumX the tolerance and max number; of iterations as extra parameters with default values of; tolerance=10E-10 and max iterations=100; . TH1. Implement a faster version of TH1::FillRandom(TH1*,int); when the passed histogram has the same bins. In this case generate; the flactuations bin by bins using Multinomial statistics; . THnSparse. Shrink THnSparse on disk by 70% in an arbitrary example case;; also reduce memory usage, especially when not filling.; ; IMPORTANT NOTE: while new THnSparse objects can be read and e.g. projected from in old ROOT versions, filling a new THnSparse object in old ROOT versions does NOT WORK!. Add SetBinContent(), AddBinContent(), SetBinError() taking the; linear bin index. Use it in Projection() for a considerable; speed-up. TSpectrum2Painter. New parameter bf() in the SPEC option to define the buffer size; used by TSpectrum2Painter. It is needed in case of very; large canvases like 8000x5000. New TEfficiency class. This new class from Christian Gumpert (CERN summer student 2010) handles the calculation of efficiencies and their uncertainties. It; provides several statistical methods for calculating frequentist and bayesian; confidence intervals as well as a function for combining several efficiencies.; Example of usage: Creating a TEfficiency object; ; If you start a new analysis, it is highly recommended to use the TEfficiency class; from the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v528/index.html:7572,reduce,reduce,7572,hist/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v528/index.html,1,['reduce'],['reduce']
Energy Efficiency,">`_. * `Run-time ABI for the ARM Architecture <http://infocenter.arm.com/help/topic/com.arm.doc.ihi0043d/IHI0043D_rtabi.pdf>`_ This documents the __aeabi_* helper functions. Itanium (ia64); --------------. * `Itanium documentation <http://developer.intel.com/design/itanium2/documentation.htm>`_. Lanai; -----. * `Lanai Instruction Set Architecture <http://g.co/lanai/isa>`_. MIPS; ----. * `MIPS Processor Architecture <https://www.mips.com/products/>`_. * `MIPS 64-bit ELF Object File Specification <https://www.linux-mips.org/pub/linux/mips/doc/ABI/elf64-2.4.pdf>`_. PowerPC; -------. IBM - Official manuals and docs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `Power Instruction Set Architecture, Version 3.0B <https://openpowerfoundation.org/?resource_lib=power-isa-version-3-0>`_. * `POWER9 Processor User's Manual <https://openpowerfoundation.org/?resource_lib=power9-processor-users-manual>`_. * `Power Instruction Set Architecture, Version 2.07B <https://openpowerfoundation.org/?resource_lib=ibm-power-isa-version-2-07-b>`_. * `POWER8 Processor User's Manual <https://openpowerfoundation.org/?resource_lib=power8-processor-users-manual>`_. * `Power Instruction Set Architecture, Versions 2.03 through 2.06 (Internet Archive) <https://web.archive.org/web/20121124005736/https://www.power.org/technology-introduction/standards-specifications>`_. * `IBM AIX 7.2 POWER Assembly Reference <https://www.ibm.com/support/knowledgecenter/en/ssw_aix_72/assembler/alangref_kickoff.html>`_. * `IBM AIX/5L for POWER Assembly Reference <http://publibn.boulder.ibm.com/doc_link/en_US/a_doc_lib/aixassem/alangref/alangreftfrm.htm>`_. Embedded PowerPC Processors manuals and docs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `Book E: Enhanced PowerPC Architecture <https://www.nxp.com/docs/en/user-guide/BOOK_EUM.pdf>`_. * `EREF: A Programmer's Reference Manual for Freescale Embedded Processors (EREFRM) <https://www.nxp.com/files-static/32bit/doc/ref_manual/EREF_RM.pdf>`_. * `Signal Processing Engine (SPE) Pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:2448,power,power-isa-version-,2448,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,1,['power'],['power-isa-version-']
Energy Efficiency,">fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric int",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5267,adapt,adaptive,5267,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,2,['adapt'],['adaptive']
Energy Efficiency,"@llvm.vector.reduce.or.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scalar. The return type matches the; element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_xor:. '``llvm.vector.reduce.xor.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.xor.*``' intrinsics do a bitwise ``XOR``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smax:. '``llvm.vector.reduce.smax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smax.*``' intrinsics do a signed integer; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smin:. '``llvm.vector.reduce.smin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smin.*``' intrinsics do a signed integer; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umax:. '``llvm.vector.reduce.umax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:656581,reduce,reduce,656581,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"AG_dwarf_procedure[; DW_AT_name = ""__divergent_lane_pc_1_else"";; DW_AT_location = DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_addrx &lex_1_end;; DW_OP_stack_value;; DW_OP_LLVM_extend 64, 64;; DW_OP_call_ref %__lex_1_save_exec;; DW_OP_deref_type 64, %__uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc, DIExpression[; DW_OP_call_ref %__divergent_lane_pc_1_else;; DW_OP_call_ref %__active_lane_pc;; ];; f;; EXEC = %1;; $lex_1_end:; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; g;; $lex_end:. The DWARF procedure ``%__active_lane_pc`` is used to update the lane pc elements; that are active, with the current program location. Artificial variables %__lex_1_save_exec and %__lex_1_1_save_exec are created for; the execution masks saved on entry to a region. Using the ``DBG_VALUE`` pseudo; instruction, location list entries will be created that describe where the; artificial variables are allocated at any given program location. The compiler; may allocate them to registers or spill them to memory. The DWARF procedures for each region use the values of the saved execution mask; artificial variables to only update the lanes that are active on entry to the; region. All other lanes retain the value of the enclosing region where they were; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:108154,allocate,allocated,108154,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"ALL LICENSES; =====. This document includes several copyright licenses for different; aspects of the software. Not all licenses may apply depending; on the features chosen. Civetweb License; -----. ### Included with all features. > Copyright (c) 2013-2021 The CivetWeb developers ([CREDITS.md](https://github.com/civetweb/civetweb/blob/master/CREDITS.md)); >; > Copyright (c) 2004-2013 Sergey Lyubka; >; > Copyright (c) 2013 No Face Press, LLC (Thomas Davis); >; > Copyright (c) 2013 F-Secure Corporation; >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, publish, distribute, sublicense, and/or sell; > copies of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. Lua License; ------. ### Included only if built with Lua support. http://www.lua.org/license.html. > Copyright (C) 1994-2020 Lua.org, PUC-Rio.; >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, pu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:549,charge,charge,549,net/http/civetweb/LICENSE.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md,1,['charge'],['charge']
Energy Efficiency,AMLOutputStyle.h; llvm/tools/llvm-profgen/CallContext.h; llvm/tools/llvm-profgen/CSPreInliner.cpp; llvm/tools/llvm-profgen/CSPreInliner.h; llvm/tools/llvm-profgen/llvm-profgen.cpp; llvm/tools/llvm-profgen/PerfReader.cpp; llvm/tools/llvm-profgen/PerfReader.h; llvm/tools/llvm-rc/ResourceScriptCppFilter.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-redu,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337256,reduce,reduce,337256,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"A_KERNEL. .amd_kernel_code_t; ++++++++++++++++++. This directive marks the beginning of a list of key / value pairs that are used; to specify the amd_kernel_code_t object that will be emitted by the assembler.; The list must be terminated by the *.end_amd_kernel_code_t* directive. For any; amd_kernel_code_t values that are unspecified a default value will be used. The; default value for all keys is 0, with the following exceptions:. - *amd_code_version_major* defaults to 1.; - *amd_kernel_code_version_minor* defaults to 2.; - *amd_machine_kind* defaults to 1.; - *amd_machine_version_major*, *machine_version_minor*, and; *amd_machine_version_stepping* are derived from the value of the -mcpu option; that is passed to the assembler.; - *kernel_code_entry_byte_offset* defaults to 256.; - *wavefront_size* defaults 6 for all targets before GFX10. For GFX10 onwards; defaults to 6 if target feature ``wavefrontsize64`` is enabled, otherwise 5.; Note that wavefront size is specified as a power of two, so a value of **n**; means a size of 2^ **n**.; - *call_convention* defaults to -1.; - *kernarg_segment_alignment*, *group_segment_alignment*, and; *private_segment_alignment* default to 4. Note that alignments are specified; as a power of 2, so a value of **n** means an alignment of 2^ **n**.; - *enable_tg_split* defaults to 1 if target feature ``tgsplit`` is enabled for; GFX90A onwards.; - *enable_wgp_mode* defaults to 1 if target feature ``cumode`` is disabled for; GFX10 onwards.; - *enable_mem_ordered* defaults to 1 for GFX10 onwards. The *.amd_kernel_code_t* directive must be placed immediately after the; function label and before any instructions. For a full list of amd_kernel_code_t keys, refer to AMDGPU ABI document,; comments in lib/Target/AMDGPU/AmdKernelCodeT.h and test/CodeGen/AMDGPU/hsa.s. .. _amdgpu-amdhsa-assembler-example-v2:. Code Object V2 Example Source Code; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .. warning::; Code object V2 generation is no longer supported by t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:434502,power,power,434502,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['power'],['power']
Energy Efficiency,"Access and Addressing Operations; ---------------------------------------. A key design point of an SSA-based representation is how it represents; memory. In LLVM, no memory locations are in SSA form, which makes things; very simple. This section describes how to read, write, and allocate; memory in LLVM. .. _i_alloca:. '``alloca``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = alloca [inalloca] <type> [, <ty> <NumElements>] [, align <alignment>] [, addrspace(<num>)] ; yields type addrspace(num)*:result. Overview:; """""""""""""""""". The '``alloca``' instruction allocates memory on the stack frame of the; currently executing function, to be automatically released when this; function returns to its caller. If the address space is not explicitly; specified, the object is allocated in the alloca address space from the; :ref:`datalayout string<langref_datalayout>`. Arguments:; """""""""""""""""""". The '``alloca``' instruction allocates ``sizeof(<type>)*NumElements``; bytes of memory on the runtime stack, returning a pointer of the; appropriate type to the program. If ""NumElements"" is specified, it is; the number of elements allocated, otherwise ""NumElements"" is defaulted; to be one. If a constant alignment is specified, the value result of the; allocation is guaranteed to be aligned to at least that boundary. The; alignment may not be greater than ``1 << 32``. The alignment is only optional when parsing textual IR; for in-memory IR,; it is always present. If not specified, the target can choose to align the; allocation on any convenient boundary compatible with the type. '``type``' may be any sized type. Structs containing scalable vectors cannot be used in allocas unless all; fields are the same scalable vector type (e.g. ``{<vscale x 2 x i32>,; <vscale x 2 x i32>}`` contains the same type while ``{<vscale x 2 x i32>,; <vscale x 2 x i64>}`` doesn't). Semantics:; """""""""""""""""""". Memory is allocated; a pointer is returned. The allocated memory is; uninitialized, and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:409472,allocate,allocates,409472,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocates']
Energy Efficiency,"Add ``/lldsavetemps`` to the linker flags.; * When linking from the compiler driver, add ``/link /lldsavetemps`` in order to forward that flag to the linker. Using the specified flags will generate four intermediate bytecode files:. #. a.out.0.0.preopt.bc (Before any link-time optimizations (LTO) are applied); #. a.out.0.2.internalize.bc (After initial optimizations are applied); #. a.out.0.4.opt.bc (After an extensive set of optimizations); #. a.out.0.5.precodegen.bc (After LTO but before translating into machine code). Execute one of the following commands to identify the source of the problem:. #. ``opt ""-passes=lto<O3>"" a.out.0.2.internalize.bc``; #. ``llc a.out.0.5.precodegen.bc``. If one of these do crash, you should be able to reduce; this with :program:`llvm-reduce`; command line (use the bc file corresponding to the command above that failed):. .. code-block:: bash. llvm-reduce --test reduce.sh a.out.0.2.internalize.bc. Example of reduce.sh script. .. code-block:: bash. $ cat reduce.sh; #!/bin/bash -e. path/to/not --crash path/to/opt ""-passes=lto<O3>"" $1 -o temp.bc 2> err.log; grep -q ""It->second == &Insn"" err.log. Here we have grepped the failed assert message. Please run this, then file a bug with the instructions and reduced .bc file; that llvm-reduce emits. .. _miscompiling:. Miscompilations; ===============. If clang successfully produces an executable, but that executable doesn't run; right, this is either a bug in the code or a bug in the compiler. The first; thing to check is to make sure it is not using undefined behavior (e.g.; reading a variable before it is defined). In particular, check to see if the; program is clean under various `sanitizers; <https://github.com/google/sanitizers>`_ (e.g. ``clang; -fsanitize=undefined,address``) and `valgrind <http://valgrind.org/>`_. Many; ""LLVM bugs"" that we have chased down ended up being bugs in the program being; compiled, not LLVM. Once you determine that the program itself is not buggy, you should choo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:7633,reduce,reduce,7633,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduce']
Energy Efficiency,ArmNeon; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/lib/Target/LLVMIR/Dialect/ArmSVE; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/lib/Target/LLVMIR/Dialect/LLVMIR; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/lib/Target/LLVMIR/Dialect/NVVM; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/lib/Target/LLVMIR/Dialect/OpenACC; - `1`; - `0`; - `1`; - :none:`0%`; * - mlir/lib/Target/LLVMIR/Dialect/OpenMP; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/lib/Target/LLVMIR/Dialect/ROCDL; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/lib/Target/LLVMIR/Dialect/X86Vector; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/lib/Target/SPIRV; - `2`; - `2`; - `0`; - :good:`100%`; * - mlir/lib/Target/SPIRV/Deserialization; - `4`; - `3`; - `1`; - :part:`75%`; * - mlir/lib/Target/SPIRV/Serialization; - `4`; - `3`; - `1`; - :part:`75%`; * - mlir/lib/Tools/mlir-lsp-server; - `5`; - `4`; - `1`; - :part:`80%`; * - mlir/lib/Tools/mlir-lsp-server/lsp; - `6`; - `4`; - `2`; - :part:`66%`; * - mlir/lib/Tools/mlir-reduce; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/lib/Tools/PDLL/AST; - `6`; - `5`; - `1`; - :part:`83%`; * - mlir/lib/Tools/PDLL/CodeGen; - `2`; - `1`; - `1`; - :part:`50%`; * - mlir/lib/Tools/PDLL/ODS; - `3`; - `3`; - `0`; - :good:`100%`; * - mlir/lib/Tools/PDLL/Parser; - `3`; - `1`; - `2`; - :part:`33%`; * - mlir/lib/Transforms; - `13`; - `11`; - `2`; - :part:`84%`; * - mlir/lib/Transforms/Utils; - `6`; - `6`; - `0`; - :good:`100%`; * - mlir/lib/Translation; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-cpu-runner; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-linalg-ods-gen; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-lsp-server; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-opt; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-pdll; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-reduce; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-shlib; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-spirv-cpu-ru,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst:119144,reduce,reduce,119144,interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,1,['reduce'],['reduce']
Energy Efficiency,"By Chris:. LLVM has been designed with two primary goals in mind. First we strive to ; enable the best possible division of labor between static and dynamic ; compilers, and second, we need a flexible and powerful interface ; between these two complementary stages of compilation. We feel that ; providing a solution to these two goals will yield an excellent solution ; to the performance problem faced by modern architectures and programming ; languages. A key insight into current compiler and runtime systems is that a ; compiler may fall in anywhere in a ""continuum of compilation"" to do its ; job. On one side, scripting languages statically compile nothing and ; dynamically compile (or equivalently, interpret) everything. On the far ; other side, traditional static compilers process everything statically and ; nothing dynamically. These approaches have typically been seen as a ; tradeoff between performance and portability. On a deeper level, however, ; there are two reasons that optimal system performance may be obtained by a; system somewhere in between these two extremes: Dynamic application ; behavior and social constraints. From a technical perspective, pure static compilation cannot ever give ; optimal performance in all cases, because applications have varying dynamic; behavior that the static compiler cannot take into consideration. Even ; compilers that support profile guided optimization generate poor code in ; the real world, because using such optimization tunes that application ; to one particular usage pattern, whereas real programs (as opposed to ; benchmarks) often have several different usage patterns. On a social level, static compilation is a very shortsighted solution to ; the performance problem. Instruction set architectures (ISAs) continuously ; evolve, and each implementation of an ISA (a processor) must choose a set ; of tradeoffs that make sense in the market context that it is designed for. ; With every new processor introduced, the vendor f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-04-16-DynamicCompilation.txt:205,power,powerful,205,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-04-16-DynamicCompilation.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-04-16-DynamicCompilation.txt,1,['power'],['powerful']
Energy Efficiency,"Cling is (also, but not only) REPL; -----------------------------------. A `read-eval-print-loop <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) is an interactive programming environment that takes user inputs,; executes them, and returns the result to the user. In order to enable; interactivity in C++, Cling provides several extensions to the C++ language:. 1. **Defining functions in the global scope:** Cling redefines expressions at a; global level. C++ provides limited support for this, Cling possesses the; necessary semantics to re-define code while the program is running,; minimizing the impedance mismatch between the **REPL** and the C++ codebase,; and allowing for a seamlessly interactive programing experience. 2. **Allows for implementation of commands** that provide information about the; current state of the environment. e.g., has an `Application Programming; Interface <https://en.wikipedia.org/wiki/API>`_ (**API**) to provide; information about the current state of the environment. 3. **Error recovery:** Cling has an efficient error recovery system which allows; it to handle the errors made by the user without restarting or having to redo; everything from the beginning. 4. **Tight feedback loop:** It provides feedback about the results of the; developer’s choices that is both accurate and fast. 5. **Facilitates debugging:** The programmer can inspect the printed result; before deciding what expression to provide for the next line of code.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst:1079,efficient,efficient,1079,interpreter/cling/docs/chapters/REPL.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst,1,['efficient'],['efficient']
Energy Efficiency,"Code Generation Notes for MSA; =============================. Intrinsics are lowered to SelectionDAG nodes where possible in order to enable; optimisation, reduce the size of the ISel matcher, and reduce repetition in; the implementation. In a small number of cases, this can cause different; (semantically equivalent) instructions to be used in place of the requested; instruction, even when no optimisation has taken place. Instructions; ============. This section describes any quirks of instruction selection for MSA. For; example, two instructions might be equally valid for some given IR and one is; chosen in preference to the other. bclri.b:; It is not possible to emit bclri.b since andi.b covers exactly the; same cases. andi.b should use fractionally less power than bclri.b in; most hardware implementations so it is used in preference to bclri.b. vshf.w:; It is not possible to emit vshf.w when the shuffle description is; constant since shf.w covers exactly the same cases. shf.w is used; instead. It is also impossible for the shuffle description to be; unknown at compile-time due to the definition of shufflevector in; LLVM IR. vshf.[bhwd]; When the shuffle description describes a splat operation, splat.[bhwd]; instructions will be selected instead of vshf.[bhwd]. Unlike the ilv*,; and pck* instructions, this is matched from MipsISD::VSHF instead of; a special-case MipsISD node. ilvl.d, pckev.d:; It is not possible to emit ilvl.d, or pckev.d since ilvev.d covers the; same shuffle. ilvev.d will be emitted instead. ilvr.d, ilvod.d, pckod.d:; It is not possible to emit ilvr.d, or pckod.d since ilvod.d covers the; same shuffle. ilvod.d will be emitted instead. splat.[bhwd]; The intrinsic will work as expected. However, unlike other intrinsics; it lowers directly to MipsISD::VSHF instead of using common IR. splati.w:; It is not possible to emit splati.w since shf.w covers the same cases.; shf.w will be emitted instead. copy_s.w:; On MIPS32, the copy_u.d intrinsic will emit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MSA.txt:156,reduce,reduce,156,interpreter/llvm-project/llvm/lib/Target/Mips/MSA.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/MSA.txt,3,"['power', 'reduce']","['power', 'reduce']"
Energy Efficiency,"ColFields', one for; // each column in the relation table. These are the instructions a key; // instruction will be transformed into.; list<list<string> > ValueCols = [];; }. Sample Example; --------------. Let's say that we want to have a function; ``int getPredOpcode(uint16_t Opcode, enum PredSense inPredSense)`` which; takes a non-predicated instruction and returns its predicated true or false form; depending on some input flag, ``inPredSense``. The first step in the process is; to define a relationship model that relates predicated instructions to their; non-predicated form by assigning appropriate values to the ``InstrMapping``; fields. For this relationship, non-predicated instructions are treated as key; instruction since they are the one used to query the interface function. .. code-block:: text. def getPredOpcode : InstrMapping {; // Choose a FilterClass that is used as a base class for all the; // instructions modeling this relationship. This is done to reduce the; // search space only to these set of instructions.; let FilterClass = ""PredRel"";. // Instructions with same values for all the fields in RowFields form a; // row in the resulting relation table.; // For example, if we want to relate 'ADD' (non-predicated) with 'Add_pt'; // (predicated true) and 'Add_pf' (predicated false), then all 3; // instructions need to have same value for BaseOpcode field. It can be any; // unique value (Ex: XYZ) and should not be shared with any other; // instruction not related to 'add'.; let RowFields = [""BaseOpcode""];. // List of attributes that can be used to define key and column instructions; // for a relation. Key instruction is passed as an argument; // to the function used for querying relation tables. Column instructions; // are the instructions they (key) can transform into.; //; // Here, we choose 'PredSense' as ColFields since this is the unique; // attribute of the key (non-predicated) and column (true/false); // instructions involved in this relationship mod",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUseInstrMappings.rst:3284,reduce,reduce,3284,interpreter/llvm-project/llvm/docs/HowToUseInstrMappings.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUseInstrMappings.rst,1,['reduce'],['reduce']
Energy Efficiency,"Conclusion; ----------. Cling is not just an interpreter, and is not just a REPL: it is a C/C++; JIT-compiler that can be embedded to your software for efficient incremental; execution of C++. Cling allows you to decide how much you want to compile; statically and how much to defer for the target platform. Cling enables; reflection and introspection information in high-performance systems such as; ROOT, or Xeus Jupyter, where it provides efficient code for performance-critical; tasks where hot-spot regions can be annotated with specific optimization; levels. You ca find more information regarding Cling's internal architecture,; functionment, user-cases, and Cling's based project into the References Chapter.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/conclusion.rst:152,efficient,efficient,152,interpreter/cling/docs/chapters/conclusion.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/conclusion.rst,2,['efficient'],['efficient']
Energy Efficiency,"Core.js provide central function, which handles different kinds; of XMLHttpRequest. Use only async requests, also when getting file header.; 4. Fully reorganize data management in file/tree/directory/collection hierarchical; display. Now complete description collected in HPainter class and decoupled from; visualization, performed with dTree.js.; 5. Remove all global variables from the code.; 6. Automatic scripts/style loading handled via JSROOT.loadScript() function.; One can specify arbitrary scripts list, which asynchronously loaded by browser.; 7. Method to build simple GUI changed and more simplified :). The example in index.htm.; While loadScript and AssertPrerequisites functions moved to JSROOT, one; can easily build many different kinds of GUIs, reusing provided JSRootCore.js functions.; 8. In example.htm also use AssertPrerequisites to load necessary scripts.; This helps to keep code up-to-date even by big changes in JavaScript code.; 9. Provide monitoring of online THttpServer with similar interface as for ROOT files.; 10. Fix several errors in TKey Streamer, use member names as in ROOT itself.; 11. Keep the only version identifier JSROOT.version for JS code; 12. One can specify in JSROOT.AssertPrerequisites functionality which is required.; One could specify '2d', 'io' (default) or '3d'.; 13. Use new AssertPrerequisites functionality to load only required functionality.; 14. When displaying single element, one could specify draw options and monitor property like:; <http://localhost:8080/Files/job1.root/hpxpy/draw.htm?opt=col&monitor=2000>; Such link is best possibility to integrate display into different HTML pages,; using `<iframe/>` tag like:; `<iframe src=""http://localhost:8080/Files/job1.root/hpx/draw.htm""`; `style=""width: 800px; height:600px""></iframe>`; 15. Remove 'JSROOTIO.' prefix from _typename. Now real class name is used.; 16. Use in all scripts JSROOT as central 'namespace'; 17. Introduce context menu in 3D, use it for switch between 2D/3D modes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:74944,monitor,monitoring,74944,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['monitor'],['monitoring']
Energy Efficiency,"CustomBehaviour; class is only a part of the in-order pipeline, but there are plans to add it; to the out-of-order pipeline in the future. CustomBehaviour's main method is `checkCustomHazard()` which uses the; current instruction and a list of all instructions still executing within; the pipeline to determine if the current instruction should be dispatched.; As output, the method returns an integer representing the number of cycles; that the current instruction must stall for (this can be an underestimate; if you don't know the exact number and a value of 0 represents no stall). If you'd like to add a CustomBehaviour class for a target that doesn't; already have one, refer to an existing implementation to see how to set it; up. The classes are implemented within the target specific backend (for; example `/llvm/lib/Target/AMDGPU/MCA/`) so that they can access backend symbols. Instrument Manager; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; On certain architectures, scheduling information for certain instructions; do not contain all of the information required to identify the most precise; schedule class. For example, data that can have an impact on scheduling can; be stored in CSR registers. One example of this is on RISCV, where values in registers such as `vtype`; and `vl` change the scheduling behaviour of vector instructions. Since MCA; does not keep track of the values in registers, instrument comments can; be used to specify these values. InstrumentManager's main function is `getSchedClassID()` which has access; to the MCInst and all of the instruments that are active for that MCInst.; This function can use the instruments to override the schedule class of; the MCInst. On RISCV, instrument comments containing LMUL information are used; by `getSchedClassID()` to map a vector instruction and the active; LMUL to the scheduling class of the pseudo-instruction that describes; that base instruction and the active LMUL. Custom Views; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; :pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:45732,schedul,scheduling,45732,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['schedul'],"['schedule', 'scheduling']"
Energy Efficiency,"DataFlowSanitizer Design Document; =================================. This document sets out the design for DataFlowSanitizer, a general; dynamic data flow analysis. Unlike other Sanitizer tools, this tool is; not designed to detect a specific class of bugs on its own. Instead,; it provides a generic dynamic data flow analysis framework to be used; by clients to help detect application-specific issues within their; own code. DataFlowSanitizer is a program instrumentation which can associate; a number of taint labels with any data stored in any memory region; accessible by the program. The analysis is dynamic, which means that; it operates on a running program, and tracks how the labels propagate; through that program. Use Cases; ---------. This instrumentation can be used as a tool to help monitor how data; flows from a program's inputs (sources) to its outputs (sinks).; This has applications from a privacy/security perspective in that; one can audit how a sensitive data item is used within a program and; ensure it isn't exiting the program anywhere it shouldn't be. Interface; ---------. A number of functions are provided which will attach taint labels to; memory regions and extract the set of labels associated with a; specific memory region. These functions are declared in the header; file ``sanitizer/dfsan_interface.h``. .. code-block:: c. /// Sets the label for each address in [addr,addr+size) to \c label.; void dfsan_set_label(dfsan_label label, void *addr, size_t size);. /// Sets the label for each address in [addr,addr+size) to the union of the; /// current label for that address and \c label.; void dfsan_add_label(dfsan_label label, void *addr, size_t size);. /// Retrieves the label associated with the given data.; ///; /// The type of 'data' is arbitrary. The function accepts a value of any type,; /// which can be truncated or extended (implicitly or explicitly) as necessary.; /// The truncation/extension operations will preserve the label of the original; //",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst:801,monitor,monitor,801,interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,1,['monitor'],['monitor']
Energy Efficiency,"Date: Fri, 1 Jun 2001 16:38:17 -0500 (CDT); From: Chris Lattner <sabre@nondot.org>; To: Vikram S. Adve <vadve@cs.uiuc.edu>; Subject: Interesting: GCC passes. Take a look at this document (which describes the order of optimizations; that GCC performs):. http://gcc.gnu.org/onlinedocs/gcc_17.html. The rundown is that after RTL generation, the following happens:. 1 . [t] jump optimization (jumps to jumps, etc); 2 . [t] Delete unreachable code; 3 . Compute live ranges for CSE; 4 . [t] Jump threading (jumps to jumps with identical or inverse conditions); 5 . [t] CSE; 6 . *** Conversion to SSA ; 7 . [t] SSA Based DCE; 8 . *** Conversion to LLVM; 9 . UnSSA; 10. GCSE; 11. LICM; 12. Strength Reduction; 13. Loop unrolling; 14. [t] CSE; 15. [t] DCE; 16. Instruction combination, register movement, scheduling... etc. I've marked optimizations with a [t] to indicate things that I believe to; be relatively trivial to implement in LLVM itself. The time consuming; things to reimplement would be SSA based PRE, Strength reduction & loop; unrolling... these would be the major things we would miss out on if we; did LLVM creation from tree code [inlining and other high level; optimizations are done on the tree representation]. Given the lack of ""strong"" optimizations that would take a long time to; reimplement, I am leaning a bit more towards creating LLVM from the tree; code. Especially given that SGI has GPL'd their compiler, including many; SSA based optimizations that could be adapted (besides the fact that their; code looks MUCH nicer than GCC :). Even if we choose to do LLVM code emission from RTL, we will almost; certainly want to move LLVM emission from step 8 down until at least CSE; has been rerun... which causes me to wonder if the SSA generation code; will still work (due to global variable dependencies and stuff). I assume; that it can be made to work, but might be a little more involved than we; would like. I'm continuing to look at the Tree -> RTL code. It is pretty gross; b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations.txt:796,schedul,scheduling,796,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations.txt,1,['schedul'],['scheduling']
Energy Efficiency,"Date: Tue, 18 Sep 2001 00:38:37 -0500 (CDT); From: Chris Lattner <sabre@nondot.org>; To: Vikram S. Adve <vadve@cs.uiuc.edu>; Subject: Idea for a simple, useful link time optimization. In C++ programs, exceptions suck, and here's why:. 1. In virtually all function calls, you must assume that the function; throws an exception, unless it is defined as 'nothrow'. This means; that every function call has to have code to invoke dtors on objects; locally if one is thrown by the function. Most functions don't throw; exceptions, so this code is dead [with all the bad effects of dead; code, including icache pollution].; 2. Declaring a function nothrow causes catch blocks to be added to every; call that isnot provably nothrow. This makes them very slow.; 3. Extra extraneous exception edges reduce the opportunity for code; motion.; 4. EH is typically implemented with large lookup tables. Ours is going to; be much smaller (than the ""standard"" way of doing it) to start with,; but eliminating it entirely would be nice. :); 5. It is physically impossible to correctly put (accurate, correct); exception specifications on generic, templated code. But it is trivial; to analyze instantiations of said code.; 6. Most large C++ programs throw few exceptions. Most well designed; programs only throw exceptions in specific planned portions of the; code. Given our _planned_ model of handling exceptions, all of this would be; pretty trivial to eliminate through some pretty simplistic interprocedural; analysis. The DCE factor alone could probably be pretty significant. The; extra code motion opportunities could also be exploited though... Additionally, this optimization can be implemented in a straight forward; conservative manner, allowing libraries to be optimized or individual; files even (if there are leaf functions visible in the translation unit; that are called). I think it's a reasonable optimization that hasn't really been addressed; (because assembly is way too low level for this), and ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-09-18-OptimizeExceptions.txt:790,reduce,reduce,790,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-09-18-OptimizeExceptions.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-09-18-OptimizeExceptions.txt,1,['reduce'],['reduce']
Energy Efficiency,"Delay codegen until post register allocation.; Note. any_extend is now turned into an INSERT_SUBREG. We still need to teach; the coalescer how to deal with it though. //===---------------------------------------------------------------------===//. It appears icc use push for parameter passing. Need to investigate. //===---------------------------------------------------------------------===//. The instruction selector sometimes misses folding a load into a compare. The; pattern is written as (cmp reg, (load p)). Because the compare isn't; commutative, it is not matched with the load on both sides. The dag combiner; should be made smart enough to canonicalize the load into the RHS of a compare; when it can invert the result of the compare for free. //===---------------------------------------------------------------------===//. In many cases, LLVM generates code like this:. _test:; movl 8(%esp), %eax; cmpl %eax, 4(%esp); setl %al; movzbl %al, %eax; ret. on some processors (which ones?), it is more efficient to do this:. _test:; movl 8(%esp), %ebx; xor %eax, %eax; cmpl %ebx, 4(%esp); setl %al; ret. Doing this correctly is tricky though, as the xor clobbers the flags. //===---------------------------------------------------------------------===//. We should generate bts/btr/etc instructions on targets where they are cheap or; when codesize is important. e.g., for:. void setbit(int *target, int bit) {; *target |= (1 << bit);; }; void clearbit(int *target, int bit) {; *target &= ~(1 << bit);; }. //===---------------------------------------------------------------------===//. Instead of the following for memset char*, 1, 10:. 	movl $16843009, 4(%edx); 	movl $16843009, (%edx); 	movw $257, 8(%edx). It might be better to generate. 	movl $16843009, %eax; 	movl %eax, 4(%edx); 	movl %eax, (%edx); 	movw al, 8(%edx); 	; when we can spare a register. It reduces code size. //===---------------------------------------------------------------------===//. Evaluate what the best way to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:3243,efficient,efficient,3243,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['efficient'],['efficient']
Energy Efficiency,"F. New functionality. PROOF-Lite2-tier; realization of PROOF intended for multi-core machines; the client; starts directly the workers; no daemon is required. To start a session; just use TProof::Open("""") or TProof::Open(""lite""). From there on; everything should be as in normal PROOF, though some functionality may; not have been ported yet. To start a standard PROOF; session (i.e. via daemons) on the localhost use; TProof::Open(""localhost"").XrdProofd plug-in. Possibility to define the list worker directly in the; xrootd config file (new directive xpd.worker, see Wiki reference pages); Support for automatic reconnections in the case xrootd; is restarted; Dedicated admin area (under <xrd.admin>/.xproofd.<port>) to; keep information about active and terminated sessions, and active; clients. This is used to reguraly check the client and session; activity, to cleanup orphalin sessions and to shutdown inactive client; connections. ; domain + level control of printout message. Dynamic ""per-query"" scheduling. Dynamic worker startup. It can be enabled by the cluster; administrator with the 'xpd.putrc Proof.DynamicStartup 1' directive; in the config file. The effect is that a session starts only on; the master. When a query is submitted (call to TProof::Process),; the session master contacts the scheduler.; In response it receives a list of workers and starts the worker; processes. The environment is copied from the master to the workers.; It consist of: the include and library paths, the set of enabled; packages as well as the macros loaded by the user. . Flexible and fault-tolerant workers. A packet resubmitting mechanism. When a worker dies all the; packets that it processed are resubmitted.; Added the possibility to handle dynamically removed workers and partly processed; packets (when a worker is stopped while processing a packet it finishes; the current event and the rest of the packet is reassigned to another workers).; It's done by a new method TPacketizerAdaptive::Ad",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:1032,schedul,scheduling,1032,proof/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html,1,['schedul'],['scheduling']
Energy Efficiency,"FTrigger.h ATLFTriggerMaker.h; LinkDef.h MAKE MyProject.so MyProjectProjectDict.h; MyProjectProjectDict.cxx MyProjectProjectDict.o; ```. Now you can load the shared library in any consecutive root session to; use the `atlfast` classes. ``` {.cpp}; root[]gSystem->Load(""MyProject/MyProject""); root[]ATLFMuon muon; ```. This is an example of a generated header file:. ``` {.cpp}; //////////////////////////////////////////////////////////; // This class has been generated by TFile::MakeProject; // (Thu Apr 5 10:18:37 2001 by ROOT version 3.00/06); // from the TStreamerInfo in file atlfast.root; //////////////////////////////////////////////////////////; #ifndef ATLFMuon_h; #define ATLFMuon_h; #include ""TObject.h""; #include ""TAtt3D.h""; class ATLFMuon : public TObject , public TAtt3D {; public:; Int_t m_KFcode; //Muon KF-code; Int_t m_MCParticle; //Muon position in MCParticles list; Int_t m_KFmother; //Muon mother KF-code; Int_t m_UseFlag; //Muon energy usage flag; Int_t m_Isolated; //Muon isolation (1 for isolated); Float_t m_Eta; //Eta coordinate; Float_t m_Phi; //Phi coordinate; Float_t m_PT; //Transverse energy; Int_t m_Trigger; //Result of trigger; ATLFMuon() {;}; virtual ~ATLFMuon() {;}; ClassDef(ATLFMuon,1) //; };; ClassImp(ATLFMuon); #endif; ```. ## Compression and Performance. ROOT uses a compression algorithm based on the well-known `gzip`; algorithm. It supports nine levels of compression. The default for ROOT; is one. The compression level can be set with the method; `TFile::SetCompressionLevel`. The experience with this algorithm shows; that a compression level of 1.3 for raw data files and around two on; most DST files is the optimum. The choice of one for the default is a; compromise between the time it takes to read and write the object vs.; the disk space savings. To specify no compression, set the level to zero. We recommend using compression when the time spent in I/O is small; compared to the total processing time. If the I/O operation is increased; by a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:91125,energy,energy,91125,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,2,['energy'],['energy']
Energy Efficiency,FunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llvm/tools/llvm-tapi-diff/llvm-tapi-diff.cpp; llvm/tools,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338675,reduce,reduce,338675,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"Histograms. Fitting a histogram with a Python function is no more difficult than; plotting: instantiate a **`TF1`** with the Python callable and supply; that **`TF1`** as a parameter to the `Fit()` member function of the; histogram. After the fit, you can retrieve the fit parameters from the; **`TF1`** instance. For example:. ``` {.cpp}; from ROOT import TF1, TH1F, TCanvas. class Linear:; def __call__( self, x, par ):; return par[0] + x[0]*par[1]. # create a linear function for fitting; f = TF1('pyf3',Linear(),-1.,1.,2). # create and fill a histogram; h = TH1F('h','test',100,-1.,1.); f2 = TF1('cf2','6.+x*4.5',-1.,1.); h.FillRandom('cf2',10000). # fit the histo with the python 'linear' function; h.Fit(f). # print results; par = f.GetParameters(); print('fit results: const =', par[0], ',pitch =', par[1]); ```. ### Working with Trees. Next to making histograms, working with trees is probably the most; common part of any analysis. The **`TTree`** implementation uses; pointers and dedicated buffers to reduce the memory usage and to speed; up access. Consequently, mapping **`TTree`** functionality to Python is; not straightforward, and most of the following features are implemented; in ROOT release 4.01/04 and later only, whereas you will need 5.02 if; you require all of them. #### Accessing an Existing Tree. Let us assume that you have a file containing **`TTrees`**,; **`TChains`**, or **`TNtuples`** and want to read the contents for use; in your analysis code. This is commonly the case when you work with the; result of the reconstruction software of your experiment (e.g. the; combined ntuple in ATLAS). The following example code outlines the main; steps (you can run it on the result of the `tree1.C` macro):. ``` {.cpp}; from ROOT import TFile. # open the file; myfile = TFile('tree1.root'). # retrieve the ntuple of interest; mychain = myfile.Get('t1'); entries = mychain.GetEntriesFast(). for jentry in xrange(entries):; # get the next tree in the chain and verify; ientry ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:28394,reduce,reduce,28394,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['reduce'],['reduce']
Energy Efficiency,"However, when given only a ``void*`` or ``intptr_t`` type on return, a cast; is required to turn it into something usable. * **bind_object**: This is the preferred method to proxy a C++ address,; and lives in ``cppyy``, not ``cppyy.ll``, as it is not a low-level C++; cast, but a ``cppyy`` API that is also used internally.; It thus plays well with object identity, references, etc.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... struct MyStruct { int fInt; };; ... void* create_mystruct() { return new MyStruct{42}; }; ... """"""); ... ; >>> s = cppyy.gbl.create_mystruct(); >>> print(s); <cppyy.LowLevelView object at 0x10559d430>; >>> sobj = cppyy.bind_object(s, 'MyStruct'); >>> print(sobj); <cppyy.gbl.MyStruct object at 0x7ff25e28eb20>; >>> print(sobj.fInt); 42; >>>. Instead of the type name as a string, ``bind_object`` can also take the; actual class (here: ``cppyy.gbl.MyStruct``). * **Typed nullptr**: A Python side proxy can pass through a pointer to; pointer function argument, but if the C++ side allocates memory and; stores it in the pointer, the result is a memory leak.; In that case, use ``bind_object`` to bind ``cppyy.nullptr`` instead, to; get a typed nullptr to pass to the function.; Example (continuing from the example above):. .. code-block:: python. >>> cppyy.cppdef(""""""; ... void create_mystruct(MyStruct** ptr) { *ptr = new MyStruct{42}; }; ... """"""); ...; >>> s = cppyy.bind_object(cppyy.nullptr, 'MyStruct'); >>> print(s); <cppyy.gbl.MyStruct object at 0x0>; >>> cppyy.gbl.create_mystruct(s); >>> print(s); <cppyy.gbl.MyStruct object at 0x7fc7d85b91c0>; >>> print(s.fInt); 42; >>>. * **C-style cast**: This is the simplest option for builtin types.; The syntax is ""template-style"", example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... void* get_data(int sz) {; ... int* iptr = (int*)malloc(sizeof(int)*sz);; ... for (int i=0; i<sz; ++i) iptr[i] = i;; ... return iptr;; ... }""""""); ...; >>> NDATA = 4; >>> d = cppyy.gbl.get_data(NDATA); >>> print(d); <c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:3026,allocate,allocates,3026,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,1,['allocate'],['allocates']
Energy Efficiency,"Hx $$; $$ H^T=H^THx $$; $$ y^{'} = H^{'}x $$; $$x_{i}^{(k+1)}=\frac{y_{i}^{'}}{\sum_{m=0}^{N-1}H_{im}^{'}x_{m}^{(k)}}x_{i}^{(k)}, i=0,1,...,N-1, $$; where:; $$ k=1,2,3,...,I $$; $$ x^{(0)} = [1,1,...,1]^T $$. The basic function has the form of. ```{.cpp}; char *Deconvolution1(float *source,; const float *resp,; int size,; int number_of_iterations);; ```. This function calculates deconvolution from the source spectrum according to the response spectrum. Function parameters:. - **`source`**: pointer to the vector of the source spectrum; - **`resp`**: pointer to the vector of the response spectrum; - **`size`**: length of source and the response spectra; - **`number_of_iterations`**: for details see [8]. As an illustration of the method, let us introduce a small example. In; Figure 4.1 we present original 1-dimensional spectrum. It contains; multiplets that cannot be directly analyzed. The response function (one; peak) is given in Figure 4.2. We assume the same response function (not; changing the shape) along the entire energy scale. So the response; matrix is composed of mutually shifted response functions by one; channel, however of the same shape. ![Original 1-dimensional spectrum](figures/image086.png). ![Response function (one peak)](figures/image088.png). The result after deconvolution is given in Figure 4.3. It substantially; improves the resolution in the spectrum. ![Result after deconvolution](figures/image090.png). We have developed a new high resolution deconvolution algorithm. We have; observed that the Gold deconvolution converges to its stable state; (solution). It is useless to increase the number of iterations, the; result obtained does not change. To continue decreasing the width of; peaks, we have found that when the solution reaches its stable state, it; is necessary to stop iterations, then to change the vector in a way and; repeat again the Gold deconvolution. We have found that in order to change the; particular solution we need to apply a non-li",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:26920,energy,energy,26920,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['energy'],['energy']
Energy Efficiency,"I'm not trying to suggest actual solutions here,; but just various directions we can pursue:. a. A single-assignment VM, which we've both already been thinking about. b. A strongly-typed VM. One question is do we need the types to be; explicitly declared or should they be inferred by the dynamic compiler?. c. How do we get more high-level information into the VM while keeping; to a low-level VM design?. o Explicit array references as operands? An alternative is; to have just an array type, and let the index computations be; separate 3-operand instructions. o Explicit instructions to handle aliasing, e.g.s:; -- an instruction to say ""I speculate that these two values are not; aliased, but check at runtime"", like speculative execution in; EPIC?; -- or an instruction to check whether two values are aliased and; execute different code depending on the answer, somewhat like; predicated code in EPIC. o (This one is a difficult but powerful idea.); A ""thread-id"" field on every instruction that allows the static; compiler to generate a set of parallel threads, and then have; the runtime compiler and hardware do what they please with it.; This has very powerful uses, but thread-id on every instruction; is expensive in terms of instruction size and code size.; We would need to compactly encode it somehow. Also, this will require some reading on at least two other; projects:; -- Multiscalar architecture from Wisconsin; -- Simultaneous multithreading architecture from Washington. o Or forget all this and stick to a traditional instruction set?. BTW, on an unrelated note, after the meeting yesterday, I did remember; that you had suggested doing instruction scheduling on SSA form instead; of a dependence DAG earlier in the semester. When we talked about; it yesterday, I didn't remember where the idea had come from but I; remembered later. Just giving credit where its due... Perhaps you can save the above as a file under RCS so you and I can; continue to expand on this. --Vikram. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeas.txt:2206,power,powerful,2206,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeas.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeas.txt,2,"['power', 'schedul']","['powerful', 'scheduling']"
Energy Efficiency,"I; might let you click on typedefs to expand them. This application would want to; pass significantly more information about types through to the GUI than a; simple flat string. The interface allows this to happen. .. _internals-diag-translation:. Adding Translations to Clang; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Not possible yet! Diagnostic strings should be written in UTF-8, the client can; translate to the relevant code page if needed. Each translation completely; replaces the format string for the diagnostic. .. _SourceLocation:; .. _SourceManager:. The ``SourceLocation`` and ``SourceManager`` classes; ----------------------------------------------------. Strangely enough, the ``SourceLocation`` class represents a location within the; source code of the program. Important design points include:. #. ``sizeof(SourceLocation)`` must be extremely small, as these are embedded; into many AST nodes and are passed around often. Currently it is 32 bits.; #. ``SourceLocation`` must be a simple value object that can be efficiently; copied.; #. We should be able to represent a source location for any byte of any input; file. This includes in the middle of tokens, in whitespace, in trigraphs,; etc.; #. A ``SourceLocation`` must encode the current ``#include`` stack that was; active when the location was processed. For example, if the location; corresponds to a token, it should contain the set of ``#include``\ s active; when the token was lexed. This allows us to print the ``#include`` stack; for a diagnostic.; #. ``SourceLocation`` must be able to describe macro expansions, capturing both; the ultimate instantiation point and the source of the original character; data. In practice, the ``SourceLocation`` works together with the ``SourceManager``; class to encode two pieces of information about a location: its spelling; location and its expansion location. For most tokens, these will be the; same. However, for a macro expansion (or tokens that came from a ``_Pragma``; directive) the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:23538,efficient,efficiently,23538,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['efficient'],['efficiently']
Energy Efficiency,"Int_t col_lwb,Int_t col_upb,` | `row_lwb:row_upb` x |; | | `col_lwb:col_upb` |; | `Int_t nr_nonzeros=-1)` | |; +-----------------------------------------+----------------------------------+; | `SetRowIndexArray` `(Int_t *data)` | for sparse matrices, set the row |; | | index. The array data should |; | | contains at least` fNrows+1` |; | | entries column lower-bound index |; +-----------------------------------------+----------------------------------+; | `SetColIndexArray` `(Int_t *data)` | for sparse matrices, set the |; | | column index. The array data |; | | should contains at least |; | | `fNelems` entries |; +-----------------------------------------+----------------------------------+; | `SetSparseIndex` `(Int_t nelems new)` | allocate memory for a sparse map |; | | of `nelems_new` elements and |; | | copy (if exists) at most |; | | `nelems_new` matrix elements |; | | over to the new structure |; +-----------------------------------------+----------------------------------+; | `SetSparseIndex` | copy the sparse map from matrix |; | `(const TMatrixDBase &a)` | `a` Note that this can be a |; | | dense matrix! |; +-----------------------------------------+----------------------------------+; | `SetSparseIndexAB` | set the sparse map to the same |; | `(const TMatrixDSparse &a,` ` | of the map of matrix `a` and `b` |; | const TMatrixDSparse &b)` | |; +-----------------------------------------+----------------------------------+. The second half of the table is only relevant for sparse matrices. These; methods define the sparse structure. It should be clear that a call to; any of these methods has to be followed by a **`SetMatrixArray`** (...); which will supply the matrix data, see the next chapter ""Creating and; Filling a Matrix"". ## Creating and Filling a Matrix. The matrix constructors are listed in the next table. In the simplest; ones, only the number of rows and columns is given. In a slightly more; elaborate version, one can define the row and column index ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md:8542,allocate,allocate,8542,documentation/users-guide/LinearAlgebra.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md,1,['allocate'],['allocate']
Energy Efficiency,"Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umax.*``' intrinsics do an unsigned; integer ``MAX`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umin:. '``llvm.vector.reduce.umin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umin.*``' intrinsics do an unsigned; integer ``MIN`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmax:. '``llvm.vector.reduce.fmax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmax.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmax.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmax.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maxnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with maximum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:658485,reduce,reduce,658485,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"LLVM Command Guide; ------------------. The following documents are command descriptions for all of the LLVM tools.; These pages describe how to use the LLVM commands and what their options are.; Note that these pages do not describe all of the options available for all; tools. To get a complete listing, pass the ``--help`` (general options) or; ``--help-hidden`` (general and debugging options) arguments to the tool you are; interested in. Basic Commands; ~~~~~~~~~~~~~~. .. toctree::; :maxdepth: 1. dsymutil; llc; lli; llvm-as; llvm-config; llvm-cov; llvm-cxxmap; llvm-debuginfo-analyzer; llvm-diff; llvm-dis; llvm-dwarfdump; llvm-dwarfutil; llvm-lib; llvm-libtool-darwin; llvm-link; llvm-lipo; llvm-mc; llvm-mca; llvm-opt-report; llvm-otool; llvm-profdata; llvm-readobj; llvm-reduce; llvm-stress; llvm-symbolizer; opt. GNU binutils replacements; ~~~~~~~~~~~~~~~~~~~~~~~~~. .. toctree::; :maxdepth: 1. llvm-addr2line; llvm-ar; llvm-cxxfilt; llvm-install-name-tool; llvm-nm; llvm-objcopy; llvm-objdump; llvm-ranlib; llvm-readelf; llvm-size; llvm-strings; llvm-strip. Debugging Tools; ~~~~~~~~~~~~~~~. .. toctree::; :maxdepth: 1. bugpoint; llvm-extract; llvm-bcanalyzer. Developer Tools; ~~~~~~~~~~~~~~~. .. toctree::; :maxdepth: 1. FileCheck; tblgen; clang-tblgen; lldb-tblgen; llvm-tblgen; mlir-tblgen; lit; llvm-exegesis; llvm-ifs; llvm-locstats; llvm-pdbutil; llvm-profgen; llvm-tli-checker. Remarks Tools; ~~~~~~~~~~~~~~. .. toctree::; :maxdepth: 1. llvm-remarkutil; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/index.rst:782,reduce,reduce,782,interpreter/llvm-project/llvm/docs/CommandGuide/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/index.rst,1,['reduce'],['reduce']
Energy Efficiency,"LLs provided with Windows. Each frame on the stack has an assigned EH; personality routine, which decides what actions to take to handle the exception.; There are a few major personalities for C and C++ code: the C++ personality; (``__CxxFrameHandler3``) and the SEH personalities (``_except_handler3``,; ``_except_handler4``, and ``__C_specific_handler``). All of them implement; cleanups by calling back into a ""funclet"" contained in the parent function. Funclets, in this context, are regions of the parent function that can be called; as though they were a function pointer with a very special calling convention.; The frame pointer of the parent frame is passed into the funclet either using; the standard EBP register or as the first parameter register, depending on the; architecture. The funclet implements the EH action by accessing local variables; in memory through the frame pointer, and returning some appropriate value,; continuing the EH process. No variables live in to or out of the funclet can be; allocated in registers. The C++ personality also uses funclets to contain the code for catch blocks; (i.e. all user code between the braces in ``catch (Type obj) { ... }``). The; runtime must use funclets for catch bodies because the C++ exception object is; allocated in a child stack frame of the function handling the exception. If the; runtime rewound the stack back to frame of the catch, the memory holding the; exception would be overwritten quickly by subsequent function calls. The use of; funclets also allows ``__CxxFrameHandler3`` to implement rethrow without; resorting to TLS. Instead, the runtime throws a special exception, and then uses; SEH (``__try / __except``) to resume execution with new information in the child; frame. In other words, the successive unwinding approach is incompatible with Visual; C++ exceptions and general purpose Windows exception handling. Because the C++; exception object lives in stack memory, LLVM cannot provide a custom personality;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:22606,allocate,allocated,22606,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,1,['allocate'],['allocated']
Energy Efficiency,"Label. It doesn't use anymore the `TGX11` function `RequestString`.; Now the text appears directly as it will show and it is possible to; enter several text string. The input is not block in the `RequestString` event loop.; - The toolbar methods now work without XOR mode (useful for OpenGL()).; - A new ""vertex compression"" algorithm added to deal with complex histograms; (thousands/millions of bins - polygons with thousands/millions of vertices) -; optimization/fix for X11 crashes. ### TGaxis and TAxis. - The time axis behavior should now be correct along time zone and; summer saving time. A fix has been done with the of Philippe Gras; (CEA Saclay. IRFU/SEDI) and Julian Sitarek (IFAE). Time axis; transported from a time zone to an other in a ROOT file are correct; too. A new example test have been introduced to test the time axis; (timeonaxis3.C); - In some case the format use to build the axis labels was incorrect.; (cf: Jira report ROOT-5635).; - New static function to change the position of the ""power of 10""; near the axis. A static function is used instead of data members; in `TAxis` in order to keep the `TAxis` class small. Adding two; floating point numbers in that class (in fact in `TAttAxis`) would; have a none negligible effect on the Root files' sizes as there is; at least two axis per histogram and that there is often 1000th; histograms in a single file.; So we choose to follow the same mechanism as for the `SetMaxDigits`; static method. The new function is: `SetExponentOffset`.; Example:. ``` {.cpp}; ...; TGaxis::SetMaxDigits(2);; TGaxis::SetExponentOffset(-0.01, 0.01, ""y""); // X and Y offset for Y axis; TGaxis::SetExponentOffset(-0.05, 0.01, ""x""); // Y and Y offset for X axis; ...; hist->Draw();; ```. - `TGaxis::SetMaxDigits()` was not acitve on standalone `TGaxis`. ### TLegend. - The line attribute of objects in the legend were not taken into; account with the option ""e"".; - In case of automatic computation of the legend items' size, the; text size was ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md:3073,power,power,3073,graf2d/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v600/index.md,1,['power'],['power']
Energy Efficiency,"Live Intervals; --------------. Live Intervals are the ranges (intervals) where a variable is *live*. They are; used by some `register allocator`_ passes to determine if two or more virtual; registers which require the same physical register are live at the same point in; the program (i.e., they conflict). When this situation occurs, one virtual; register must be *spilled*. Live Variable Analysis; ^^^^^^^^^^^^^^^^^^^^^^. The first step in determining the live intervals of variables is to calculate; the set of registers that are immediately dead after the instruction (i.e., the; instruction calculates the value, but it is never used) and the set of registers; that are used by the instruction, but are never used after the instruction; (i.e., they are killed). Live variable information is computed for; each *virtual* register and *register allocatable* physical register; in the function. This is done in a very efficient manner because it uses SSA to; sparsely compute lifetime information for virtual registers (which are in SSA; form) and only has to track physical registers within a block. Before register; allocation, LLVM can assume that physical registers are only live within a; single basic block. This allows it to do a single, local analysis to resolve; physical register lifetimes within each basic block. If a physical register is; not register allocatable (e.g., a stack pointer or condition codes), it is not; tracked. Physical registers may be live in to or out of a function. Live in values are; typically arguments in registers. Live out values are typically return values in; registers. Live in values are marked as such, and are given a dummy ""defining""; instruction during live intervals analysis. If the last basic block of a; function is a ``return``, then it's marked as using all live out values in the; function. ``PHI`` nodes need to be handled specially, because the calculation of the live; variable information from a depth first traversal of the CFG of the fu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:55363,efficient,efficient,55363,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['efficient'],['efficient']
Energy Efficiency,"M welcomes contributions of all kinds. To get started, please review the following topics:. .. contents::; :local:. .. toctree::; :hidden:. Contributing; DeveloperPolicy; CodeReview; SupportPolicy; SphinxQuickstartTemplate; HowToSubmitABug; BugLifeCycle; CodingStandards; GitHub; GitBisecting; GitRepositoryPolicy. :doc:`Contributing`; An overview on how to contribute to LLVM. :doc:`DeveloperPolicy`; The LLVM project's policy towards developers and their contributions. :doc:`CodeReview`; The LLVM project's code-review process. :doc:`SupportPolicy`; The LLVM support policy for core and non-core components. :doc:`SphinxQuickstartTemplate`; A template + tutorial for writing new Sphinx documentation. It is meant; to be read in source form. :doc:`HowToSubmitABug`; Instructions for properly submitting information about any bugs you run into; in the LLVM system. :doc:`BugLifeCycle`; Describes how bugs are reported, triaged and closed. :doc:`CodingStandards`; Details the LLVM coding standards and provides useful information on writing; efficient C++ code. :doc:`GitHub`; Describes how to use the llvm-project repository and code reviews on GitHub. :doc:`GitBisecting`; Describes how to use ``git bisect`` on LLVM's repository. :doc:`GitRepositoryPolicy`; Collection of policies around the git repositories. .. _development-process:. Development Process; -------------------. Information about LLVM's development process. .. toctree::; :hidden:. Projects; HowToReleaseLLVM; Packaging; ReleaseProcess; HowToAddABuilder; ReleaseNotes. :doc:`Projects`; How-to guide and templates for new projects that *use* the LLVM; infrastructure. The templates (directory organization, Makefiles, and test; tree) allow the project code to be located outside (or inside) the ``llvm/``; tree, while using LLVM header files and libraries. :doc:`HowToReleaseLLVM`; This is a guide to preparing LLVM releases. Most developers can ignore it. :doc:`ReleaseProcess`; This is a guide to validate a new release, during th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingInvolved.rst:1081,efficient,efficient,1081,interpreter/llvm-project/llvm/docs/GettingInvolved.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingInvolved.rst,1,['efficient'],['efficient']
Energy Efficiency,"MC layer, emitting; directives through MCStreamer. On the implementation side of MCStreamer, there are two major implementations:; one for writing out a .s file (MCAsmStreamer), and one for writing out a .o; file (MCObjectStreamer). MCAsmStreamer is a straightforward implementation; that prints out a directive for each method (e.g. ``EmitValue -> .byte``), but; MCObjectStreamer implements a full assembler. For target specific directives, the MCStreamer has a MCTargetStreamer instance.; Each target that needs it defines a class that inherits from it and is a lot; like MCStreamer itself: It has one method per directive and two classes that; inherit from it, a target object streamer and a target asm streamer. The target; asm streamer just prints it (``emitFnStart -> .fnstart``), and the object; streamer implement the assembler logic for it. To make llvm use these classes, the target initialization must call; TargetRegistry::RegisterAsmStreamer and TargetRegistry::RegisterMCObjectStreamer; passing callbacks that allocate the corresponding target streamer and pass it; to createAsmStreamer or to the appropriate object streamer constructor. The ``MCContext`` class; -----------------------. The MCContext class is the owner of a variety of uniqued data structures at the; MC layer, including symbols, sections, etc. As such, this is the class that you; interact with to create symbols and sections. This class can not be subclassed. The ``MCSymbol`` class; ----------------------. The MCSymbol class represents a symbol (aka label) in the assembly file. There; are two interesting kinds of symbols: assembler temporary symbols, and normal; symbols. Assembler temporary symbols are used and processed by the assembler; but are discarded when the object file is produced. The distinction is usually; represented by adding a prefix to the label, for example ""L"" labels are; assembler temporary labels in MachO. MCSymbols are created by MCContext and uniqued there. This means that MCSymbols; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:28666,allocate,allocate,28666,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['allocate'],['allocate']
Energy Efficiency,"MDGPU is defined in; :ref:`amdgpu-dwarf-memory-space-mapping-table`. .. table:: AMDGPU DWARF Memory Space Mapping; :name: amdgpu-dwarf-memory-space-mapping-table. =========================== ====== =================; DWARF AMDGPU; ---------------------------------- -----------------; Memory Space Name Value Memory Space; =========================== ====== =================; ``DW_MSPACE_LLVM_none`` 0x0000 Generic (Flat); ``DW_MSPACE_LLVM_global`` 0x0001 Global; ``DW_MSPACE_LLVM_constant`` 0x0002 Global; ``DW_MSPACE_LLVM_group`` 0x0003 Local (group/LDS); ``DW_MSPACE_LLVM_private`` 0x0004 Private (Scratch); ``DW_MSPACE_AMDGPU_region`` 0x8000 Region (GDS); =========================== ====== =================. The DWARF memory space values defined in the *DWARF Extensions For Heterogeneous; Debugging* section :ref:`amdgpu-dwarf-memory-spaces` are used. In addition, ``DW_ADDR_AMDGPU_region`` is encoded as a vendor extension. This is; available for use for the AMD extension for access to the hardware GDS memory; which is scratchpad memory allocated per device. For AMDGPU if no ``DW_AT_LLVM_memory_space`` attribute is present, then the; default memory space of ``DW_MSPACE_LLVM_none`` is used. See :ref:`amdgpu-dwarf-address-space-identifier` for information on the AMDGPU; mapping of DWARF memory spaces to DWARF address spaces, including address size; and NULL value. .. _amdgpu-dwarf-address-space-identifier:. Address Space Identifier; ------------------------. DWARF address spaces correspond to target architecture specific linear; addressable memory areas. See DWARF Version 5 section 2.12 and *DWARF Extensions; For Heterogeneous Debugging* section :ref:`amdgpu-dwarf-address-spaces`. The DWARF address space mapping used for AMDGPU is defined in; :ref:`amdgpu-dwarf-address-space-mapping-table`. .. table:: AMDGPU DWARF Address Space Mapping; :name: amdgpu-dwarf-address-space-mapping-table. ======================================= ===== ======= ======== ===================== =====",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:92218,allocate,allocated,92218,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"ND_BLOCK`_ --- This abbrev ID marks the end of the current block. * 1 - `ENTER_SUBBLOCK`_ --- This abbrev ID marks the beginning of a new; block. * 2 - `DEFINE_ABBREV`_ --- This defines a new abbreviation. * 3 - `UNABBREV_RECORD`_ --- This ID specifies the definition of an; unabbreviated record. Abbreviation IDs 4 and above are defined by the stream itself, and specify an; `abbreviated record encoding`_. .. _Blocks:. Blocks; ------. Blocks in a bitstream denote nested regions of the stream, and are identified by; a content-specific id number (for example, LLVM IR uses an ID of 12 to represent; function bodies). Block IDs 0-7 are reserved for `standard blocks`_ whose; meaning is defined by Bitcode; block IDs 8 and greater are application; specific. Nested blocks capture the hierarchical structure of the data encoded; in it, and various properties are associated with blocks as the file is parsed.; Block definitions allow the reader to efficiently skip blocks in constant time; if the reader wants a summary of blocks, or if it wants to efficiently skip data; it does not understand. The LLVM IR reader uses this mechanism to skip function; bodies, lazily reading them on demand. When reading and encoding the stream, several properties are maintained for the; block. In particular, each block maintains:. #. A current abbrev id width. This value starts at 2 at the beginning of the; stream, and is set every time a block record is entered. The block entry; specifies the abbrev id width for the body of the block. #. A set of abbreviations. Abbreviations may be defined within a block, in; which case they are only defined in that block (neither subblocks nor; enclosing blocks see the abbreviation). Abbreviations can also be defined; inside a `BLOCKINFO`_ block, in which case they are defined in all blocks; that match the ID that the ``BLOCKINFO`` block is describing. As sub blocks are entered, these properties are saved and the new sub-block has; its own set of abbreviations, and i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:6242,efficient,efficiently,6242,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,2,['efficient'],['efficiently']
Energy Efficiency,"Negative values were not painted with option ""TEXT"" for TH2Poly. ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ### Jupyter Notebook Integration; - When starting Jupyter server with `root --notebook arg1 arg2 ...`, extra arguments can be provided.; All these arguments delivered as is to jupyter executable and can be used for configuration.; Like server binding to specific host `root --notebook --ip=hostname`; - Remove `c.NotebookApp.ip = '*'` from default jupyter config. One has to provide ip address for server; binding using `root --notebook --ip=<hostaddr>` arguments; - Now Jupyter Notebooks will use JSROOT provided with ROOT installation. This allows to use notebooks; without internet connection (offline). ## JavaScript ROOT; - Provide monitoring capabilities for TGeoManager object. Now geomtry with some tracks can be displayed and; updated in web browser, using THttpServer monitoring capability like histogram objects. ## Tutorials; - Add the ""Legacy"" category collecting the old tutorials which do not represent any more best practices. ## Class Reference Guide; - Images in tutorials can now be displayed à JavaScript thanks to the (js) option; added next to the directive `\macro_image`; - As the tutorial `palettes.C` is often hit when searching the keyword `palette`; in the reference guide, a direct link from this example to the full list of; predefined palettes given in `TColor` has been added.; - Revisited the TSpectrum2 documentation. All the static images have been replaced; by macros generating images at reference guide build time. These macros have; been added in the tutorial section of the reference guide.; - The Reference Guide can now be accessed directly from the ROOT prompt thanks to; a great extension (implemented by Desislava Kalaydjieva) of the `.help` command.; For example to access the Reference Guide for `TTree` it ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md:6676,monitor,monitoring,6676,README/ReleaseNotes/v620/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md,1,['monitor'],['monitoring']
Energy Efficiency,"NonNilReturnValue:. osx.cocoa.NonNilReturnValue; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Models the APIs that are guaranteed to return a non-nil value. .. _osx-cocoa-ObjCGenerics:. osx.cocoa.ObjCGenerics (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for type errors when using Objective-C generics. .. code-block:: objc. NSMutableArray *names = [NSMutableArray array];; NSMutableArray *birthDates = names;. // Warning: Conversion from value of type 'NSDate *'; // to incompatible type 'NSString *'; [birthDates addObject: [NSDate date]];. .. _osx-cocoa-RetainCount:. osx.cocoa.RetainCount (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for leaks and improper reference count management. .. code-block:: objc. void test() {; NSString *s = [[NSString alloc] init]; // warn; }. CFStringRef test(char *bytes) {; return CFStringCreateWithCStringNoCopy(; 0, bytes, NSNEXTSTEPStringEncoding, 0); // warn; }. .. _osx-cocoa-RunLoopAutoreleaseLeak:. osx.cocoa.RunLoopAutoreleaseLeak; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for leaked memory in autorelease pools that will never be drained. .. _osx-cocoa-SelfInit:. osx.cocoa.SelfInit (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""; Check that 'self' is properly initialized inside an initializer method. .. code-block:: objc. @interface MyObj : NSObject {; id x;; }; - (id)init;; @end. @implementation MyObj; - (id)init {; [super init];; x = 0; // warn: instance variable used while 'self' is not; // initialized; return 0;; }; @end. @interface MyObj : NSObject; - (id)init;; @end. @implementation MyObj; - (id)init {; [super init];; return self; // warn: returning uninitialized 'self'; }; @end. .. _osx-cocoa-SuperDealloc:. osx.cocoa.SuperDealloc (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; Warn about improper use of '[super dealloc]' in Objective-C. .. code-block:: objc. @interface SuperDeallocThenReleaseIvarClass : NSObject {; NSObject *_ivar;; }; @end. @implementation SuperDeallocThenReleaseIvarClass; - (void)dealloc {; [super dealloc];; [_ivar release]; // warn; }; @end. .. _osx-c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:40435,drain,drained,40435,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['drain'],['drained']
Energy Efficiency,"OOT->SetStyle(""Plain""); // set plain TStyle; gStyle->SetOptStat(111111); // draw statistics on plots,; // (0) for no output; gStyle->SetOptFit(1111); // draw fit results on plot,; // (0) for no ouput; gStyle->SetPalette(57); // set color map; gStyle->SetOptTitle(0); // suppress title box; ...; ```. Next, you should create a canvas for graphical output, with size,; subdivisions and format suitable to your needs, see documentation of; class `TCanvas`:. ``` {.cpp}; TCanvas c1(""c1"",""<Title>"",0,0,400,300); // create a canvas, specify position and size in pixels; c1.Divide(2,2); //set subdivisions, called pads; c1.cd(1); //change to pad 1 of canvas c1; ```. These parts of a well-written macro are pretty standard, and you should; remember to include pieces of code like in the examples above to make; sure your plots always look as you had intended. Below, in section [Interpretation and Compilation](#interpretation-and-compilation), some more code fragments; will be shown, allowing you to use the system compiler to compile macros for; more efficient execution, or turn macros into stand-alone applications linked; against the ROOT libraries. ## A more complete example ##. Let us now look at a rather complete example of a typical task in data; analysis, a macro that constructs a graph with errors, fits a (linear); model to it and saves it as an image. To run this macro, simply type in; the shell:. ``` {.cpp}; > root macro1.C; ```. The code is built around the ROOT class `TGraphErrors`, which was; already introduced previously. Have a look at it in the class reference; guide, where you will also find further examples. The macro shown below; uses additional classes, `TF1` to define a function, `TCanvas` to define; size and properties of the window used for our plot, and `TLegend` to; add a nice legend. For the moment, ignore the commented include; statements for header files, they will only become important at the end; in section [Interpretation and Compilation](#interpretation-a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/your_first_ROOT_macro.md:2425,efficient,efficient,2425,documentation/primer/your_first_ROOT_macro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/your_first_ROOT_macro.md,1,['efficient'],['efficient']
Energy Efficiency,"OOTMutex``` and ```gInterpreterMutex``` are deprecated and may be removed in future releases.; - Added ```TReadLockGuard```,```TWriteLockGuard```, ```R__READ_LOCKGUARD``` and```R__WRITE_LOCKGUARD``` to take advantage of the new lock. The legacy ```TLockGuard``` and ```R__LOCKGUARD``` use the write lock.; - Improved scaling of TROOT::RecursiveRemove in the case of large collection.; - Added a thread safe mode for the following ROOT collections: THashList, THashTable, TList and TObjArray. When ROOT's thread safe mode is enabled and the collection is set to use internal locks by calling:; ```; collection->UseRWLock();; ```; all operations on the collection will take the read or write lock when needed, currently they shared the global lock (ROOT::gCoreMutex). ### Interpreter. - cling's LLVM is upgraded to version 5.0; - All of cling's patches to llvm have been upstreamed.; - The interpreter-related lock is now locking only the compilation step, not the execution step. This reduces the scope for lock contention. Most significantly, it enables the use of concurrency on the prompt!. ## I/O Libraries. - Introduce TKey::ReadObject<typeName>. This is a user friendly wrapper around ReadObjectAny. For example; ```; auto h1 = key->ReadObject<TH1>; ```; after which h1 will either be null if the key contains something that is not a TH1 (or derived class); or will be set to the address of the histogram read from the file.; - Add the ability to store the 'same' object several time (assumingly with different data) in a single buffer. Instead of. ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer << arr;; }; ```; which would only really stream the array at the first iteration because it will be detected has having the same address and thus assumed to be the same object. We can now do:; ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer.WriteObject(&arr, kFALSE);; }; ```; where the last argument of WriteObject tells the buffer do *not* re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:6252,reduce,reduces,6252,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['reduce'],['reduces']
Energy Efficiency,"OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. Duktape License; ------. ### Included only if built with Duktape support. https://github.com/svaarala/duktape/blob/master/LICENSE.txt. > ===============; > Duktape license; > ===============; >; > (http://opensource.org/licenses/MIT); >; > Copyright (c) 2013-2017 by Duktape authors (see AUTHORS.rst); >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, publish, distribute, sublicense, and/or sell; > copies of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. zlib License; ------. ### Included only if built with zlib support. https://www.zlib.net/zlib_license.html. > zlib.h -- interface of the 'zlib' general purpose compression library; > version 1.2.11, January 15th, 2017",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:7873,charge,charge,7873,net/http/civetweb/LICENSE.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md,1,['charge'],['charge']
Energy Efficiency,"OT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonethe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9568,reduce,reduce,9568,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['reduce'],['reduce']
Energy Efficiency,"OrCreateFoo"" method for a; complex object (for example, a node in the code generator). The client has a; description of **what** it wants to generate (it knows the opcode and all the; operands), but we don't want to 'new' a node, then try inserting it into a set; only to find out it already exists, at which point we would have to delete it; and return the node that already exists. To support this style of client, FoldingSet perform a query with a; FoldingSetNodeID (which wraps SmallVector) that can be used to describe the; element that we want to query for. The query either returns the element; matching the ID or it returns an opaque ID that indicates where insertion should; take place. Construction of the ID usually does not require heap traffic. Because FoldingSet uses intrusive links, it can support polymorphic objects in; the set (for example, you can have SDNode instances mixed with LoadSDNodes).; Because the elements are individually allocated, pointers to the elements are; stable: inserting or removing elements does not invalidate any pointers to other; elements. .. _dss_set:. <set>; ^^^^^. ``std::set`` is a reasonable all-around set class, which is decent at many; things but great at nothing. std::set allocates memory for each element; inserted (thus it is very malloc intensive) and typically stores three pointers; per element in the set (thus adding a large amount of per-element space; overhead). It offers guaranteed log(n) performance, which is not particularly; fast from a complexity standpoint (particularly if the elements of the set are; expensive to compare, like strings), and has extremely high constant factors for; lookup, insertion and removal. The advantages of std::set are that its iterators are stable (deleting or; inserting an element from the set does not affect iterators or pointers to other; elements) and that iteration over the set is guaranteed to be in sorted order.; If the elements in the set are large, then the relative overhead of the p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:83056,allocate,allocated,83056,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocated']
Energy Efficiency,"Other options you can use are:. .. code-block:: bash. Use Ninja instead of Make: ""-G Ninja""; Build with assertions on: ""-DLLVM_ENABLE_ASSERTIONS=True""; Local (non-sudo) install path: ""-DCMAKE_INSTALL_PREFIX=$HOME/llvm/install""; CPU flags: ""DCMAKE_C_FLAGS=-mcpu=cortex-a15"" (same for CXX_FLAGS). After that, just typing ``make -jN`` or ``ninja`` will build everything.; ``make -jN check-all`` or ``ninja check-all`` will run all compiler tests. For; running the test suite, please refer to :doc:`TestingGuide`. #. If you are building LLVM/Clang on an ARM board with 1G of memory or less,; please use ``gold`` rather then GNU ``ld``. In any case it is probably a good; idea to set up a swap partition, too. .. code-block:: bash. $ sudo ln -sf /usr/bin/ld /usr/bin/ld.gold. #. ARM development boards can be unstable and you may experience that cores; are disappearing, caches being flushed on every big.LITTLE switch, and; other similar issues. To help ease the effect of this, set the Linux; scheduler to ""performance"" on **all** cores using this little script:. .. code-block:: bash. # The code below requires the package 'cpufrequtils' to be installed.; for ((cpu=0; cpu<`grep -c proc /proc/cpuinfo`; cpu++)); do; sudo cpufreq-set -c $cpu -g performance; done. Remember to turn that off after the build, or you may risk burning your; CPU. Most modern kernels don't need that, so only use it if you have; problems. #. Running the build on SD cards is ok, but they are more prone to failures; than good quality USB sticks, and those are more prone to failures than; external hard-drives (those are also a lot faster). So, at least, you; should consider to buy a fast USB stick. On systems with a fast eMMC,; that's a good option too. #. Make sure you have a decent power supply (dozens of dollars worth) that can; provide *at least* 4 amperes, this is especially important if you use USB; devices with your board. Externally powered USB/SATA harddrives are even; better than having a good power supply.;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildOnARM.rst:2537,schedul,scheduler,2537,interpreter/llvm-project/llvm/docs/HowToBuildOnARM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildOnARM.rst,1,['schedul'],['scheduler']
Energy Efficiency,"P uses the value provided by the; runtime. It is used, together with Scratch Wavefront Offset as an offset, to; access the private memory space using a segment address. See; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`. The scratch V# is a four-aligned SGPR and always selected for the kernel as; follows:. - If it is known during instruction selection that there is stack usage,; SGPR0-3 is reserved for use as the scratch V#. Stack usage is assumed if; optimizations are disabled (``-O0``), if stack objects already exist (for; locals, etc.), or if there are any function calls. - Otherwise, four high numbered SGPRs beginning at a four-aligned SGPR index; are reserved for the tentative scratch V#. These will be used if it is; determined that spilling is needed. - If no use is made of the tentative scratch V#, then it is unreserved,; and the register count is determined ignoring it.; - If use is made of the tentative scratch V#, then its register numbers; are shifted to the first four-aligned SGPR index after the highest one; allocated by the register allocator, and all uses are updated. The; register count includes them in the shifted location.; - In either case, if the processor has the SGPR allocation bug, the; tentative allocation is not shifted or unreserved in order to ensure; the register count is higher to workaround the bug. .. note::. This approach of using a tentative scratch V# and shifting the register; numbers if used avoids having to perform register allocation a second; time if the tentative V# is eliminated. This is more efficient and; avoids the problem that the second register allocation may perform; spilling which will fail as there is no longer a scratch V#. When the kernel prolog code is being emitted it is known whether the scratch V#; described above is actually used. If it is, the prolog code must set it up by; copying the Private Segment Buffer to the scratch V# registers and then adding; the Private Segment Wavefront Offset to the queue ba",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:199487,allocate,allocated,199487,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"PLE``, and the values of the record are the ASCII codes for the; characters in the string. .. _UNABBREV_RECORD:. UNABBREV_RECORD Encoding; ^^^^^^^^^^^^^^^^^^^^^^^^. :raw-html:`<tt>`; [UNABBREV_RECORD, code\ :sub:`vbr6`, numops\ :sub:`vbr6`, op0\ :sub:`vbr6`, op1\ :sub:`vbr6`, ...]; :raw-html:`</tt>`. An ``UNABBREV_RECORD`` provides a default fallback encoding, which is both; completely general and extremely inefficient. It can describe an arbitrary; record by emitting the code and operands as VBRs. For example, emitting an LLVM IR target triple as an unabbreviated record; requires emitting the ``UNABBREV_RECORD`` abbrevid, a vbr6 for the; ``MODULE_CODE_TRIPLE`` code, a vbr6 for the length of the string, which is equal; to the number of operands, and a vbr6 for each character. Because there are no; letters with values less than 32, each letter would need to be emitted as at; least a two-part VBR, which means that each letter would require at least 12; bits. This is not an efficient encoding, but it is fully general. .. _abbreviated record encoding:. Abbreviated Record Encoding; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``[<abbrevid>, fields...]``. An abbreviated record is an abbreviation id followed by a set of fields that are; encoded according to the `abbreviation definition`_. This allows records to be; encoded significantly more densely than records encoded with the; `UNABBREV_RECORD`_ type, and allows the abbreviation types to be specified in; the stream itself, which allows the files to be completely self describing. The; actual encoding of abbreviations is defined below. The record code, which is the first field of an abbreviated record, may be; encoded in the abbreviation definition (as a literal operand) or supplied in the; abbreviated record (as a Fixed or VBR operand value). .. _abbreviation definition:. Abbreviations; -------------. Abbreviations are an important form of compression for bitstreams. The idea is; to specify a dense encoding for a class of records once, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:9834,efficient,efficient,9834,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,1,['efficient'],['efficient']
Energy Efficiency,Parser/Parser.cpp; mlir/lib/Transforms/Canonicalizer.cpp; mlir/lib/Transforms/ControlFlowSink.cpp; mlir/lib/Transforms/CSE.cpp; mlir/lib/Transforms/Inliner.cpp; mlir/lib/Transforms/LocationSnapshot.cpp; mlir/lib/Transforms/LoopInvariantCodeMotion.cpp; mlir/lib/Transforms/PassDetail.h; mlir/lib/Transforms/SCCP.cpp; mlir/lib/Transforms/StripDebugInfo.cpp; mlir/lib/Transforms/SymbolDCE.cpp; mlir/lib/Transforms/SymbolPrivatize.cpp; mlir/lib/Transforms/Utils/ControlFlowSinkUtils.cpp; mlir/lib/Transforms/Utils/DialectConversion.cpp; mlir/lib/Transforms/Utils/FoldUtils.cpp; mlir/lib/Transforms/Utils/GreedyPatternRewriteDriver.cpp; mlir/lib/Transforms/Utils/InliningUtils.cpp; mlir/lib/Transforms/Utils/RegionUtils.cpp; mlir/lib/Translation/Translation.cpp; mlir/tools/mlir-cpu-runner/mlir-cpu-runner.cpp; mlir/tools/mlir-linalg-ods-gen/mlir-linalg-ods-yaml-gen.cpp; mlir/tools/mlir-lsp-server/mlir-lsp-server.cpp; mlir/tools/mlir-opt/mlir-opt.cpp; mlir/tools/mlir-pdll/mlir-pdll.cpp; mlir/tools/mlir-reduce/mlir-reduce.cpp; mlir/tools/mlir-shlib/mlir-shlib.cpp; mlir/tools/mlir-spirv-cpu-runner/mlir-spirv-cpu-runner.cpp; mlir/tools/mlir-tblgen/AttrOrTypeDefGen.cpp; mlir/tools/mlir-tblgen/AttrOrTypeFormatGen.cpp; mlir/tools/mlir-tblgen/AttrOrTypeFormatGen.h; mlir/tools/mlir-tblgen/CodeGenHelpers.cpp; mlir/tools/mlir-tblgen/DialectGen.cpp; mlir/tools/mlir-tblgen/DirectiveCommonGen.cpp; mlir/tools/mlir-tblgen/DocGenUtilities.h; mlir/tools/mlir-tblgen/EnumsGen.cpp; mlir/tools/mlir-tblgen/FormatGen.cpp; mlir/tools/mlir-tblgen/FormatGen.h; mlir/tools/mlir-tblgen/LLVMIRConversionGen.cpp; mlir/tools/mlir-tblgen/LLVMIRIntrinsicGen.cpp; mlir/tools/mlir-tblgen/mlir-tblgen.cpp; mlir/tools/mlir-tblgen/OpClass.cpp; mlir/tools/mlir-tblgen/OpClass.h; mlir/tools/mlir-tblgen/OpDefinitionsGen.cpp; mlir/tools/mlir-tblgen/OpDocGen.cpp; mlir/tools/mlir-tblgen/OpFormatGen.h; mlir/tools/mlir-tblgen/OpGenHelpers.cpp; mlir/tools/mlir-tblgen/OpGenHelpers.h; mlir/tools/mlir-tblgen/OpInterfacesGen.cpp; mlir/to,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:401730,reduce,reduce,401730,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,2,['reduce'],['reduce']
Energy Efficiency,"QualType`` class is designed as a trivial value class that is small,; passed by-value and is efficient to query. The idea of ``QualType`` is that it; stores the type qualifiers (``const``, ``volatile``, ``restrict``, plus some; extended qualifiers required by language extensions) separately from the types; themselves. ``QualType`` is conceptually a pair of ""``Type*``"" and the bits; for these type qualifiers. By storing the type qualifiers as bits in the conceptual pair, it is extremely; efficient to get the set of qualifiers on a ``QualType`` (just return the field; of the pair), add a type qualifier (which is a trivial constant-time operation; that sets a bit), and remove one or more type qualifiers (just return a; ``QualType`` with the bitfield set to empty). Further, because the bits are stored outside of the type itself, we do not need; to create duplicates of types with different sets of qualifiers (i.e. there is; only a single heap allocated ""``int``"" type: ""``const int``"" and ""``volatile; const int``"" both point to the same heap allocated ""``int``"" type). This; reduces the heap size used to represent bits and also means we do not have to; consider qualifiers when uniquing types (:ref:`Type <Type>` does not even; contain qualifiers). In practice, the two most common type qualifiers (``const`` and ``restrict``); are stored in the low bits of the pointer to the ``Type`` object, together with; a flag indicating whether extended qualifiers are present (which must be; heap-allocated). This means that ``QualType`` is exactly the same size as a; pointer. .. _DeclarationName:. Declaration names; -----------------. The ``DeclarationName`` class represents the name of a declaration in Clang.; Declarations in the C family of languages can take several different forms.; Most declarations are named by simple identifiers, e.g., ""``f``"" and ""``x``"" in; the function declaration ``f(int x)``. In C++, declaration names can also name; class constructors (""``Class``"" in ``struct ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:67469,allocate,allocated,67469,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,2,['allocate'],['allocated']
Energy Efficiency,"RNTupleParallelWriter` class has been added, providing (initial) support for parallel writing of RNTuples.; - A new static method `RFieldBase::Check()` has been added, which produces a support status report of a type with regards to RNTuple I/O.; - A new internal `RNTupleMerger` class has been added, enabling the merging of different page sources into one page sink. This also means that RNTuples can be merged through `hadd`.; - Zero-copy bulk reading has been added, with extra optimizations for `ROOT::RVec` fields.; - It is now possible to use the `RNTupleView` with an external address with type erasure, e.g.:; ```cpp; std::shared_ptr<void> data{new float()};; auto view = reader->GetView(""pt"", data);; ```; This enables use cases such as reading one specific entry of one specific field into a previously allocated memory location.; - Further integration with [RDataFrame](#rdataframe): it is now possible to create RDataFrame for chains of RNTuples. This addition also comes with improvements to the multi-threaded work scheduling.; - Many additional bug fixes and improvements. Please, report any issues regarding the above mentioned features should you encounter them. RNTuple is still in pre-production. The on-disk format is scheduled to be finalized by the end of 2024. Thus, we appreciate feedback and suggestions for improvement. ## Histogram Libraries. - Implement the FLT_MAX mechanism for `THStack::GetMaximum()` and `THStack::GetMiniumum()`.; - Print a warning when the range given to `TAxis::SetRange` is invalid.; - Fix projection name in `TH3` as requested [here](https://root-forum.cern.ch/t/project3d-letter-d-in-name-option/57612). ## Parallelism; - The ROOT::Experimental::TFuture template has been removed. ## RooFit Libraries. ### New CPU likelihood evaluation backend by default. The new vectorizing CPU evaluation backend is not the default for RooFit likelihoods.; Likelihood minimization is now up to 10x faster on a single CPU core. If you experience unexpected pro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:6282,schedul,scheduling,6282,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['schedul'],['scheduling']
Energy Efficiency,"ROFDATA_FILE """" CACHE FILEPATH; ""Profiling data file to use when compiling in order to improve runtime performance.""). if(LLVM_INCLUDE_TESTS); # Lit test suite requires at least python 3.6; set(LLVM_MINIMUM_PYTHON_VERSION 3.6); else(); # FIXME: it is unknown if this is the actual minimum bound; set(LLVM_MINIMUM_PYTHON_VERSION 3.0); endif(). # Find python before including config-ix, since it needs to be able to search; # for python modules.; find_package(Python3 ${LLVM_MINIMUM_PYTHON_VERSION} REQUIRED; COMPONENTS Interpreter). # All options referred to from HandleLLVMOptions have to be specified; # BEFORE this include, otherwise options will not be correctly set on; # first cmake run; include(config-ix). # By default, we target the host, but this can be overridden at CMake; # invocation time. Except on 64-bit AIX, where the system toolchain; # expect 32-bit objects by default.; if(""${LLVM_HOST_TRIPLE}"" MATCHES ""^powerpc64-ibm-aix""); string(REGEX REPLACE ""^powerpc64"" ""powerpc"" LLVM_DEFAULT_TARGET_TRIPLE_DEFAULT ""${LLVM_HOST_TRIPLE}""); else(); # Only set default triple when native target is enabled.; if (LLVM_NATIVE_TARGET); set(LLVM_DEFAULT_TARGET_TRIPLE_DEFAULT ""${LLVM_HOST_TRIPLE}""); endif(); endif(). set(LLVM_DEFAULT_TARGET_TRIPLE ""${LLVM_DEFAULT_TARGET_TRIPLE_DEFAULT}"" CACHE STRING; ""Default target for which LLVM will generate code."" ); message(STATUS ""LLVM default target triple: ${LLVM_DEFAULT_TARGET_TRIPLE}""). set(LLVM_TARGET_TRIPLE ""${LLVM_DEFAULT_TARGET_TRIPLE}""). if(WIN32 OR CYGWIN); if(BUILD_SHARED_LIBS OR LLVM_BUILD_LLVM_DYLIB); set(LLVM_ENABLE_PLUGINS_default ON); else(); set(LLVM_ENABLE_PLUGINS_default OFF); endif(); else(); set(LLVM_ENABLE_PLUGINS_default ${LLVM_ENABLE_PIC}); endif(); option(LLVM_ENABLE_PLUGINS ""Enable plugin support"" ${LLVM_ENABLE_PLUGINS_default}). set(LLVM_ENABLE_NEW_PASS_MANAGER TRUE CACHE BOOL; ""Enable the new pass manager by default.""); if(NOT LLVM_ENABLE_NEW_PASS_MANAGER); message(FATAL_ERROR ""Enabling the legacy pass manager on th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:38188,power,powerpc,38188,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['power'],['powerpc']
Energy Efficiency,"ROOT (and thus not; interfere with the system's shared linker).; The final ""Dynamic Path"" is now composed of these sources in order:; 1. `ROOT_LIBRARY_PATH` environment variable; 2. System specific shared linker environment variables like; `LD_LIBRARY_PATH`, `LIBPATH`, or `PATH`.; 3. Setting from rootrc; 4. ROOT's builtin library directory. ### Interpreter. - cling's LLVM is upgraded to version 9.0; - New interface to enable/disable optional cling features. Currently, it can be used to enable/disable support for redefinitions. See [this](https://github.com/root-project/cling/issues/360) issue for more information. ### Multithreading. - Fix an uninitialized variable in global read-write lock which could have caused deadlocks or crashes in some rare cases.; - Default global read-write lock transitioned to new implementation based on TBB thread local storage when TBB is available on supported platforms (all except Windows). This gives an O(10%) performance improvement for some typical RDataFrame scenarios with 256 threads due to reduced lock contention. ## I/O Libraries. - Exclusive use of the global lock is reduced or migrated to finer grained read and write locks in a few hotspots that occur during file opening/closing or task initialization in RDataFrame. This can lead to O(100x) improvements for some typical RDataFrame scenarios with 256 threads due to massively reduced lock contention. ## TTree Libraries. - `TTree` now supports the inclusion of leaves of types `long` and `unsigned long` (and therefore also `std::size_t` on most systems) also for branches in ""leaflist mode"". The corresponding leaflist letters are 'G' and 'g'.; - when looping over a `TTree` with a friend with a larger number of entries, `TTreeReader` now ends the event loop when the entries in the _main_ `TTree` are exhausted, consistently with other interfaces. See [#6518](https://github.com/root-project/root/issues/6518) for more details.; - `TTreeProcessorMT::SetMaxTasksPerFilePerWorker` is now d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:4252,reduce,reduced,4252,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['reduce'],['reduced']
Energy Efficiency,Reader.h; llvm/tools/llvm-rc/ResourceScriptCppFilter.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; l,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337503,reduce,reduce,337503,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"Region will be; automatically ended, and a new InstrumentRegion will begin. If there are comments containing the different `INSTRUMENT_TYPE`,; then both data sets remain available. In contrast with an AnalysisRegion,; an InstrumentRegion does not need a comment to end the region. Comments that are prefixed with `LLVM-MCA-` but do not correspond to; a valid `INSTRUMENT_TYPE` for the target cause an error, except for; `BEGIN` and `END`, since those correspond to AnalysisRegions. Comments; that do not start with `LLVM-MCA-` are ignored by :program `llvm-mca`. An instruction (a MCInst) is added to an InstrumentRegion R only; if its location is in range [R.RangeStart, R.RangeEnd]. On RISCV targets, vector instructions have different behaviour depending; on the LMUL. Code can be instrumented with a comment that takes the; following form:. .. code-block:: none. # LLVM-MCA-RISCV-LMUL <M1|M2|M4|M8|MF2|MF4|MF8>. The RISCV InstrumentManager will override the schedule class for vector; instructions to use the scheduling behaviour of its pseudo-instruction; which is LMUL dependent. It makes sense to place RISCV instrument; comments directly after `vset{i}vl{i}` instructions, although; they can be placed anywhere in the program. Example of program with no call to `vset{i}vl{i}`:. .. code-block:: none. # LLVM-MCA-RISCV-LMUL M2; vadd.vv v2, v2, v2. Example of program with call to `vset{i}vl{i}`:. .. code-block:: none. vsetvli zero, a0, e8, m1, tu, mu; # LLVM-MCA-RISCV-LMUL M1; vadd.vv v2, v2, v2. Example of program with multiple calls to `vset{i}vl{i}`:. .. code-block:: none. vsetvli zero, a0, e8, m1, tu, mu; # LLVM-MCA-RISCV-LMUL M1; vadd.vv v2, v2, v2; vsetvli zero, a0, e8, m8, tu, mu; # LLVM-MCA-RISCV-LMUL M8; vadd.vv v2, v2, v2. Example of program with call to `vsetvl`:. .. code-block:: none. vsetvl rd, rs1, rs2; # LLVM-MCA-RISCV-LMUL M1; vadd.vv v12, v12, v12; vsetvl rd, rs1, rs2; # LLVM-MCA-RISCV-LMUL M4; vadd.vv v12, v12, v12. HOW LLVM-MCA WORKS; ------------------. :program",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:12279,schedul,schedule,12279,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['schedul'],"['schedule', 'scheduling']"
Energy Efficiency,"SC S If PSTATE.SM before call is 0, If PSTATE.SM before call is 0, If PSTATE.SM before call is 1,; then SMSTART then SMSTOP then SMSTART; SC SC If PSTATE.SM before call is 1,; then SMSTART; ==== ==== =============================== ============================== ==============================. Because changing PSTATE.SM zeroes the FP/vector registers, it is best to emit; the ``smstart`` and ``smstop`` instructions before register allocation, so that; the register allocator can spill/reload registers around the mode change. The compiler should also have sufficient information on which operations are; part of the call/function's arguments/result and which operations are part of; the function's body, so that it can place the mode changes in exactly the right; position. The suitable place to do this seems to be SelectionDAG, where it lowers; the call's arguments/return values to implement the specified calling convention.; SelectionDAG provides Chains and Glue to specify the order of operations and give; preliminary control over the instruction's scheduling. Example of preserving state; ---------------------------. When passing and returning a ``float`` value to/from a function; that has a streaming interface from a function that has a normal interface, the; call-site will need to ensure that the argument/result registers are preserved; and that no other code is scheduled in between the ``smstart/smstop`` and the call. .. code-block:: llvm. define float @foo(float %f) nounwind {; %res = call float @bar(float %f) ""aarch64_pstate_sm_enabled""; ret float %res; }. declare float @bar(float) ""aarch64_pstate_sm_enabled"". The program needs to preserve the value of the floating point argument and; return value in register ``s0``:. .. code-block:: none. foo: // @foo; // %bb.0:; stp d15, d14, [sp, #-80]! // 16-byte Folded Spill; stp d13, d12, [sp, #16] // 16-byte Folded Spill; stp d11, d10, [sp, #32] // 16-byte Folded Spill; stp d9, d8, [sp, #48] // 16-byte Folded Spill; str x30, [s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst:6340,schedul,scheduling,6340,interpreter/llvm-project/llvm/docs/AArch64SME.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst,1,['schedul'],['scheduling']
Energy Efficiency,"START/SMSTOP`` nodes take ``CurrentState`` and ``ExpectedState`` operand for; the case of a conditional SMSTART/SMSTOP. The instruction will only be executed; if CurrentState != ExpectedState. When ``CurrentState`` and ``ExpectedState`` can be evaluated at compile-time; (i.e. they are both constants) then an unconditional ``smstart/smstop``; instruction is emitted. Otherwise the node is matched to a Pseudo instruction; which expands to a compare/branch and a ``smstart/smstop``. This is necessary to; implement transitions from ``SC -> N`` and ``SC -> S``. Unchained Function calls; ------------------------; When a function with ""``aarch64_pstate_sm_enabled``"" calls a function that is not; streaming compatible, the compiler has to insert a SMSTOP before the call and; insert a SMSTOP after the call. If the function that is called is an intrinsic with no side-effects which in; turn is lowered to a function call (e.g. ``@llvm.cos()``), then the call to; ``@llvm.cos()`` is not part of any Chain; it can be scheduled freely. Lowering of a Callsite creates a small chain of nodes which:. - starts a call sequence. - copies input values from virtual registers to physical registers specified by; the ABI. - executes a branch-and-link. - stops the call sequence. - copies the output values from their physical registers to virtual registers. When the callsite's Chain is not used, only the result value from the chained; sequence is used, but the Chain itself is discarded. The ``SMSTART`` and ``SMSTOP`` ISD nodes return a Chain, but no real; values, so when the ``SMSTART/SMSTOP`` nodes are part of a Chain that isn't; used, these nodes are not considered for scheduling and are; removed from the DAG. In order to prevent these nodes; from being removed, we need a way to ensure the results from the; ``CopyFromReg`` can only be **used after** the ``SMSTART/SMSTOP`` has been; executed. We can use a CopyToReg -> CopyFromReg sequence for this, which moves the; value to/from a virtual register a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst:9173,schedul,scheduled,9173,interpreter/llvm-project/llvm/docs/AArch64SME.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst,1,['schedul'],['scheduled']
Energy Efficiency,"SetSeed(520);; for (Int_t i = 0; i < n; i++) {; x1[i] = rg.Uniform(0, 1);; y1[i] = TMath::Power(x1[i], 3) + rg.Gaus() * 0.06;; }. TGraph *gr1 = new TGraph(n,x1,y1);; gr1->SetMarkerColor(kBlue);; gr1->SetMarkerStyle(8);; gr1->SetMarkerSize(1);; mg->Add(gr1);. // create the second graph; TF1 *f_known=new TF1(""f_known"",""pow(x,3)"",0,1);; TGraph *gr2 = new TGraph(f_known);; gr2->SetMarkerColor(kRed);; gr2->SetMarkerStyle(8);; gr2->SetMarkerSize(1);; mg->Add(gr2);; //passing data to Rfot fitting; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; r[""x""]<<TVectorD(n, x1);; r[""y""]<<TVectorD(n, y1);; //creating a R data frame; r<<""ds<-data.frame(x=x,y=y)"";; //fitting x and y to X^power using Nonlinear Least Squares; r<<""m <- nls(y ~ I(x^power),data = ds, start = list(power = 1),trace = T)"";; //getting the exponent; Double_t power;; r[""summary(m)$coefficients[1]""]>>power;. TF1 *f_fitted=new TF1(""f_fitted"",""pow(x,[0])"",0,1);; f_fitted->SetParameter(0,power);; //plotting the fitted function; TGraph *gr3 = new TGraph(f_fitted);; gr3->SetMarkerColor(kGreen);; gr3->SetMarkerStyle(8);; gr3->SetMarkerSize(1);. mg->Add(gr3);; mg->Draw(""ap"");. //displaying basic results; TPaveText *pt = new TPaveText(0.1,0.6,0.5,0.9,""brNDC"");; pt->SetFillColor(18);; pt->SetTextAlign(12);; pt->AddText(""Fitting x^power "");; pt->AddText("" \""Blue\"" Points with gaussian noise to be fitted"");; pt->AddText("" \""Red\"" Known function x^3"");; TString fmsg;; fmsg.Form("" \""Green\"" Fitted function with power=%.4lf"",power);; pt->AddText(fmsg);; pt->Draw();; c1->Update();; return c1;; }; ~~~; In the first image you can see the blue dots which are the function `x^3` with gaussian noise, the red dots correspond to; the original function and the green ones correspond to the fitted function. \image html R_image1.png. ## Global Minimization in R using the package DEoptim; DEoptim is a R package for Differential Evolution Minimization that lets you do global; Minimization.; To install this package you just need to r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:16161,power,power,16161,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['power'],['power']
Energy Efficiency,"Setup a static PROOF cluster with PROOF on Demand; =================================================. Introduction; ------------. Using PROOF on Demand is our current recommended way of running a PROOF; cluster. The usage of PoD is in particular helpful for the following; reasons:. - **Sandboxing.** Each user get their own personal PROOF cluster,; separated from the others: a problem occurring on one personal; cluster does not affect the workflow of other users. - **Easier administration and self-servicing.** A user can restart their; personal PROOF cluster in case of troubles without waiting for a; system administrator's intervention. - **Efficient multiuser scheduling.** PROOF on Demand makes PROOF run on; top of an existing resource management system, moving the problem of; scheduling many concurrent users outside of PROOF. This guide particularly refers to the setup of a static PROOF cluster; running on physical hosts: the recommended setup is in practice the same; as the ready-to-go Virtual Analysis Facility. If you want to use PROOF; on the clouds there is no configuration to go through. Setup a resource management system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:668,schedul,scheduling,668,proof/doc/confman/ConfigProofPoD.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md,2,['schedul'],['scheduling']
Energy Efficiency,"Spaces; --------------------------------------. AMDGPU needs to be able to describe addresses that are in different kinds of; memory. Optimized code may need to describe a variable that resides in pieces; that are in different kinds of storage which may include parts of registers,; memory that is in a mixture of memory kinds, implicit values, or be undefined. DWARF has the concept of segment addresses. However, the segment cannot be; specified within a DWARF expression, which is only able to specify the offset; portion of a segment address. The segment index is only provided by the entity; that specifies the DWARF expression. Therefore, the segment index is a property; that can only be put on complete objects, such as a variable. That makes it only; suitable for describing an entity (such as variable or subprogram code) that is; in a single kind of memory. AMDGPU uses multiple address spaces. For example, a variable may be allocated in; a register that is partially spilled to the call stack which is in the private; address space, and partially spilled to the local address space. DWARF mentions; address spaces, for example as an argument to the ``DW_OP_xderef*`` operations.; A new section that defines address spaces is added (see; :ref:`amdgpu-dwarf-address-spaces`). A new attribute ``DW_AT_LLVM_address_space`` is added to pointer and reference; types (see :ref:`amdgpu-dwarf-type-modifier-entries`). This allows the compiler; to specify which address space is being used to represent the pointer or; reference type. DWARF uses the concept of an address in many expression operations but does not; define how it relates to address spaces. For example,; ``DW_OP_push_object_address`` pushes the address of an object. Other contexts; implicitly push an address on the stack before evaluating an expression. For; example, the ``DW_AT_use_location`` attribute of the; ``DW_TAG_ptr_to_member_type``. The expression belongs to a source language type; which may apply to objects allocat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:17748,allocate,allocated,17748,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['allocate'],['allocated']
Energy Efficiency,"Submit"" at the bottom of the; page. Updating your change; ~~~~~~~~~~~~~~~~~~~~. If you make changes in response to a reviewer's comments, simply update; your branch with more commits and push to your fork. It may be a good; idea to answer the comments from the reviewer explicitly. Accepting a revision; ~~~~~~~~~~~~~~~~~~~~. When the reviewer is happy with the change, they will **Accept** the; revision. They may leave some more minor comments that you should; address, but at this point the review is complete. It's time to get it; merged!. Commit by proxy; ---------------. As this is your first change, you won't have access to merge it; yourself yet. The reviewer **doesn't know this**, so you need to tell; them! Leave a message on the review like:. Thanks @somellvmdev. I don't have commit access, can you land this; patch for me?. The pull-request will be closed and you will be notified by GitHub. Review expectations; -------------------. In order to make LLVM a long-term sustainable effort, code needs to be; maintainable and well tested. Code reviews help to achieve that goal.; Especially for new contributors, that often means many rounds of reviews; and push-back on design decisions that do not fit well within the; overall architecture of the project. For your first patches, this means:. - be kind, and expect reviewers to be kind in return - LLVM has a `Code; of Conduct <https://llvm.org/docs/CodeOfConduct.html>`__;. - be patient - understanding how a new feature fits into the; architecture of the project is often a time consuming effort, and; people have to juggle this with other responsibilities in their; lives; **ping the review once a week** when there is no response;. - if you can't agree, generally the best way is to do what the reviewer; asks; we optimize for readability of the code, which the reviewer is; in a better position to judge; if this feels like it's not the right; option, you can contact the cfe-dev mailing list to get more feedback; on the directio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst:11627,sustainab,sustainable,11627,interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst,1,['sustainab'],['sustainable']
Energy Efficiency,"Switch lowering refactoring. N: Sumant Kowshik; E: kowshik@uiuc.edu; D: Author of the original C backend. N: Benjamin Kramer; E: benny.kra@gmail.com; D: Miscellaneous bug fixes. N: Michael Kuperstein; E: mkuper@google.com; D: Loop Vectorizer. N: Sundeep Kushwaha; E: sundeepk@codeaurora.org; D: Implemented DFA-based target independent VLIW packetizer. N: Christopher Lamb; E: christopher.lamb@gmail.com; D: aligned load/store support, parts of noalias and restrict support; D: vreg subreg infrastructure, X86 codegen improvements based on subregs; D: address spaces. N: Jim Laskey; E: jlaskey@apple.com; D: Improvements to the PPC backend, instruction scheduling; D: Debug and Dwarf implementation; D: Auto upgrade mangler; D: llvm-gcc4 svn wrangler. N: Chris Lattner; E: sabre@nondot.org; W: http://nondot.org/~sabre/; D: Primary architect of LLVM. N: Tanya Lattner (Tanya Brethour); E: tonic@nondot.org; W: http://nondot.org/~tonic/; D: The initial llvm-ar tool, converted regression testsuite to dejagnu; D: Modulo scheduling in the SparcV9 backend; D: Release manager (1.7+). N: Sylvestre Ledru; E: sylvestre@debian.org; W: http://sylvestre.ledru.info/; W: https://apt.llvm.org/; D: Debian and Ubuntu packaging; D: Continuous integration with jenkins. N: Andrew Lenharth; E: alenhar2@cs.uiuc.edu; W: http://www.lenharth.org/~andrewl/; D: Alpha backend; D: Sampling based profiling. N: Nick Lewycky; E: nicholas@mxc.ca; D: PredicateSimplifier pass. N: Tony Linthicum, et. al.; E: tlinth@codeaurora.org; D: Backend for Qualcomm's Hexagon VLIW processor. N: Bruno Cardoso Lopes; E: bruno.cardoso@gmail.com; I: bruno; W: http://brunocardoso.cc; D: Mips backend; D: Random ARM integrated assembler and assembly parser improvements; D: General X86 AVX1 support. N: Weining Lu; E: luweining@loongson.cn; D: LoongArch backend. N: Duraid Madina; E: duraid@octopus.com.au; W: http://kinoko.c.u-tokyo.ac.jp/~duraid/; D: IA64 backend, BigBlock register allocator. N: John McCall; E: rjmccall@apple.com; D: C",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT:7523,schedul,scheduling,7523,interpreter/llvm-project/llvm/CREDITS.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT,1,['schedul'],['scheduling']
Energy Efficiency,"TO. With gold, if you see an error during the link of the form:. .. code-block:: console. /usr/bin/ld: error: /path/to/clang/bin/../lib/LLVMgold.so: could not load plugin library: /path/to/clang/bin/../lib/LLVMgold.so: cannot open shared object file: No such file or directory. Then either gold was not configured with plugins enabled, or clang; was not built with ``-DLLVM_BINUTILS_INCDIR`` set properly. See; the instructions for the; `LLVM gold plugin <https://llvm.org/docs/GoldPlugin.html#how-to-build-it>`_. Controlling Backend Parallelism; -------------------------------; .. _parallelism:. By default, the ThinLTO link step will launch as many; threads in parallel as there are cores. If the number of; cores can't be computed for the architecture, then it will launch; ``std::thread::hardware_concurrency`` number of threads in parallel.; For machines with hyper-threading, this is the total number of; virtual cores. For some applications and machine configurations this; may be too aggressive, in which case the amount of parallelism can; be reduced to ``N`` via:. - gold:; ``-Wl,-plugin-opt,jobs=N``; - ld64:; ``-Wl,-mllvm,-threads=N``; - ld.lld, ld64.lld:; ``-Wl,--thinlto-jobs=N``; - lld-link:; ``/opt:lldltojobs=N``. Other possible values for ``N`` are:. - 0:; Use one thread per physical core (default); - 1:; Use a single thread only (disable multi-threading); - all:; Use one thread per logical core (uses all hyper-threads). Incremental; -----------; .. _incremental:. ThinLTO supports fast incremental builds through the use of a cache,; which currently must be enabled through a linker option. - gold (as of LLVM 4.0):; ``-Wl,-plugin-opt,cache-dir=/path/to/cache``; - ld64 (supported since clang 3.9 and Xcode 8) and Mach-O ld64.lld (as of LLVM; 15.0):; ``-Wl,-cache_path_lto,/path/to/cache``; - ELF ld.lld (as of LLVM 5.0):; ``-Wl,--thinlto-cache-dir=/path/to/cache``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocache:/path/to/cache``. Cache Pruning; -------------. To help keep",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst:4137,reduce,reduced,4137,interpreter/llvm-project/clang/docs/ThinLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst,1,['reduce'],['reduced']
Energy Efficiency,"The '``llvm.vector.reduce.and.*``' intrinsics do a bitwise ``AND``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_or:. '``llvm.vector.reduce.or.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scalar. The return type matches the; element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_xor:. '``llvm.vector.reduce.xor.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.xor.*``' intrinsics do a bitwise ``XOR``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smax:. '``llvm.vector.reduce.smax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smax.*``' intrinsics do a signed integer; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smin:. '``llvm.vector.reduce.smin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.redu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:656159,reduce,reduce,656159,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"The '``llvm.vector.reduce.fmax.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maxnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with maximum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmin:. '``llvm.vector.reduce.fmin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmin.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmin.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmin.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with minimum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmaximum:. '``llvm.vector.reduce.fmaximum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:659723,reduce,reduce,659723,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"The '``llvm.vp.fmuladd``' intrinsic performs floating-point multiply-add (:ref:`llvm.fuladd <int_fmuladd>`); of the first, second, and third vector operand on each enabled lane. The result; on disabled lanes is a :ref:`poison value <poisonvalues>`. The operation is; performed in the default floating-point environment. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.fmuladd.v4f32(<4 x float> %a, <4 x float> %b, <4 x float> %c, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.fmuladd(<4 x float> %a, <4 x float> %b, <4 x float> %c); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_reduce_add:. '``llvm.vp.reduce.add.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.add.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.add.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``ADD`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.add``' intrinsic performs the integer ``ADD`` reduction; (:ref:`llvm.vector.reduce.add <int_vector_reduce_add>`) of the vector operand; ``val`` on each enabled lane, adding it to the scalar ``start_value``. Disabled; l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:748530,reduce,reduce,748530,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"The algorithm in use is simple and is based on the object-oriented; relationship and communication. When the user activates the editor,; according to the selected object **`<obj>`** in the canvas it looks for; a class name **`<obj>Editor`**. For that reason, the correct naming is; very important. If a class with this name is found, the editor verifies; that this class derives from the base editor class **`TGedFrame`**. If; all checks are satisfied, the editor makes an instance of the object; editor. Then, it scans all object base classes searching the; corresponding object editors. When it finds one, it makes an instance of; the base class editor too. Once the object editor is in place, it sets the user interface elements; according to the object's status. After that, it is ready to interact; with the object following the user actions. The graphics editor gives an intuitive way to edit objects in a canvas; with immediate feedback. Complexity of some object editors is reduced by; hiding GUI elements and revealing them only on users' requests. An object in the canvas is selected by clicking on it with the left; mouse button. Its name is displayed on the top of the editor frame in; red color. If the editor frame needs more space than the canvas window,; a vertical scroll bar appears for easy navigation. ![Histogram, pad and axis editors](pictures/03000222.png). ### Editor Design Elements. The next rules describe the path to follow when creating your own object; editor that will be recognized and loaded by the graphics editor in; ROOT, i.e. it will be included as a part of it. (a) Derive the code of your object editor from the base editor class; **`TGedFrame`**. (b) Keep the correct naming convention: the name of the object editor; should be the object class name concatenated with the word `‘Editor'`. (c) Provide a default constructor. (d) Use the signals/slots communication mechanism for event processing. (e) Implement the virtual method `SetModel(TObject *obj)` where a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md:103895,reduce,reduced,103895,documentation/users-guide/WritingGUI.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md,1,['reduce'],['reduced']
Energy Efficiency,"The algorithm in use is simple and is based on the object-oriented; relationship and communication. When the user activates the editor,; according to the selected object **`<obj>`** in the canvas it looks for; a class name **`<obj>Editor`**. For that reason, the correct naming is; very important. If a class with this name is found, the editor verifies; that this class derives from the base editor class **`TGedFrame`**. If; all checks are satisfied, the editor makes an instance of the object; editor. Then, it scans all object base classes searching the; corresponding object editors. When it finds one, it makes an instance of; the base class editor too. Once the object editor is in place, it sets the user interface elements; according to the object's status. After that, it is ready to interact; with the object following the user actions. The graphics editor gives an intuitive way to edit objects in a canvas; with immediate feedback. Complexity of some object editors is reduced by; hiding GUI elements and revealing them only on users' requests. An object in the canvas is selected by clicking on it with the left; mouse button. Its name is displayed on the top of the editor frame in; red color. If the editor frame needs more space than the canvas window,; a vertical scroll bar appears for easy navigation. \image html ged.png width=800px. **Histogram, pad and axis editors**. ### Editor Design Elements. The next rules describe the path to follow when creating your own object; editor that will be recognized and loaded by the graphics editor in; ROOT, i.e. it will be included as a part of it. (a) Derive the code of your object editor from the base editor class; **`TGedFrame`**. (b) Keep the correct naming convention: the name of the object editor; should be the object class name concatenated with the word `‘Editor'`. (c) Provide a default constructor. (d) Use the signals/slots communication mechanism for event processing. (e) Implement the virtual method `SetModel(TObject *ob",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:2925,reduce,reduced,2925,gui/ged/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md,1,['reduce'],['reduced']
Energy Efficiency,"The base of all folders is `//root`. It is visible at; the top of the left panel in the browser. The browser shows several; folders under `//root`. New folders can be added and removed to/from a folder. ## Why Use Folders?. One reason to use folders is to reduce class dependencies and improve; modularity. Each set of data has a producer class and one or many; consumer classes. When using folders, the producer class places a; pointer to the data into a folder, and the consumer class retrieves a; reference to the folder. The consumer can access the objects in a folder by specifying the path; name of the folder. Here is an example of a folder's path name:. `//root/Event/Hits/TCP`. One does not have to specify the full path name. If the partial path; name is unique, it will find it; otherwise it will return the first; occurrence of the path. The first diagram shows a system without folders. The objects have; pointers to each other to access each other's data. Pointers are an; efficient way to share data between classes. However, a direct pointer; creates a direct coupling between classes. This design can become a very; tangled web of dependencies in a system with a large number of classes. ![](pictures/020000E2.jpg). In the second diagram, a reference to the data is in the folder and the; consumers refer to the folder rather than each other to access the data.; The naming and search service provided by the ROOT folders hierarchy; provides an alternative. It loosely couples the classes and greatly; enhances I/O operations. In this way, folders separate the data from the; algorithms and greatly improve the modularity of an application by; minimizing the class dependencies. ![](pictures/020000E3.jpg). In addition, the folder hierarchy creates a picture of the data; organization. This is useful when discussing data design issues or when; learning the data organization. The example below illustrates this; point. ## How to Use Folders. Using folders means to build a hierarchy",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FoldersTasks.md:1257,efficient,efficient,1257,documentation/users-guide/FoldersTasks.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FoldersTasks.md,1,['efficient'],['efficient']
Energy Efficiency,"The cache; policy must be specified with a linker option. - gold (as of LLVM 6.0):; ``-Wl,-plugin-opt,cache-policy=POLICY``; - ELF ld.lld (as of LLVM 5.0), Mach-O ld64.lld (as of LLVM 15.0):; ``-Wl,--thinlto-cache-policy=POLICY``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocachepolicy:POLICY``. A policy string is a series of key-value pairs separated by ``:`` characters.; Possible key-value pairs are:. - ``cache_size=X%``: The maximum size for the cache directory is ``X`` percent; of the available space on the disk. Set to 100 to indicate no limit,; 50 to indicate that the cache size will not be left over half the available; disk space. A value over 100 is invalid. A value of 0 disables the percentage; size-based pruning. The default is 75%. - ``cache_size_bytes=X``, ``cache_size_bytes=Xk``, ``cache_size_bytes=Xm``,; ``cache_size_bytes=Xg``:; Sets the maximum size for the cache directory to ``X`` bytes (or KB, MB,; GB respectively). A value over the amount of available space on the disk; will be reduced to the amount of available space. A value of 0 disables; the byte size-based pruning. The default is no byte size-based pruning. Note that ThinLTO will apply both size-based pruning policies simultaneously,; and changing one does not affect the other. For example, a policy of; ``cache_size_bytes=1g`` on its own will cause both the 1GB and default 75%; policies to be applied unless the default ``cache_size`` is overridden. - ``cache_size_files=X``:; Set the maximum number of files in the cache directory. Set to 0 to indicate; no limit. The default is 1000000 files. - ``prune_after=Xs``, ``prune_after=Xm``, ``prune_after=Xh``: Sets the; expiration time for cache files to ``X`` seconds (or minutes, hours; respectively). When a file hasn't been accessed for ``prune_after`` seconds,; it is removed from the cache. A value of 0 disables the expiration-based; pruning. The default is 1 week. - ``prune_interval=Xs``, ``prune_interval=Xm``, ``prune_interval=Xh``:; Sets the pru",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst:6308,reduce,reduced,6308,interpreter/llvm-project/clang/docs/ThinLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst,1,['reduce'],['reduced']
Energy Efficiency,"The external symbol name; associated with a kernel.; OpenCL runtime allocates a; global buffer for the symbol; and saves the kernel's address; to it, which is used for; device side enqueueing. Only; available for device side; enqueued kernels.; "".kernarg_segment_size"" integer Required The size in bytes of; the kernarg segment; that holds the values; of the arguments to; the kernel.; "".group_segment_fixed_size"" integer Required The amount of group; segment memory; required by a; work-group in; bytes. This does not; include any; dynamically allocated; group segment memory; that may be added; when the kernel is; dispatched.; "".private_segment_fixed_size"" integer Required The amount of fixed; private address space; memory required for a; work-item in; bytes. If the kernel; uses a dynamic call; stack then additional; space must be added; to this value for the; call stack.; "".kernarg_segment_align"" integer Required The maximum byte; alignment of; arguments in the; kernarg segment. Must; be a power of 2.; "".wavefront_size"" integer Required Wavefront size. Must; be a power of 2.; "".sgpr_count"" integer Required Number of scalar; registers required by a; wavefront for; GFX6-GFX9. A register; is required if it is; used explicitly, or; if a higher numbered; register is used; explicitly. This; includes the special; SGPRs for VCC, Flat; Scratch (GFX7-GFX9); and XNACK (for; GFX8-GFX9). It does; not include the 16; SGPR added if a trap; handler is; enabled. It is not; rounded up to the; allocation; granularity.; "".vgpr_count"" integer Required Number of vector; registers required by; each work-item for; GFX6-GFX9. A register; is required if it is; used explicitly, or; if a higher numbered; register is used; explicitly.; "".agpr_count"" integer Required Number of accumulator; registers required by; each work-item for; GFX90A, GFX908.; "".max_flat_workgroup_size"" integer Required Maximum flat; work-group size; supported by the; kernel in work-items.; Must be >=1 and; consistent with; Reqd",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:134295,power,power,134295,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['power'],['power']
Energy Efficiency,"The first two lines here are now familiar: the first adds the ""merge""; block to the Function object (it was previously floating, like the else; block above). The second changes the insertion point so that newly; created code will go into the ""merge"" block. Once that is done, we need; to create the PHI node and set up the block/value pairs for the PHI. Finally, the CodeGen function returns the phi node as the value computed; by the if/then/else expression. In our example above, this returned; value will feed into the code for the top-level function, which will; create the return instruction. Overall, we now have the ability to execute conditional code in; Kaleidoscope. With this extension, Kaleidoscope is a fairly complete; language that can calculate a wide variety of numeric functions. Next up; we'll add another useful expression that is familiar from non-functional; languages... 'for' Loop Expression; =====================. Now that we know how to add basic control flow constructs to the; language, we have the tools to add more powerful things. Let's add; something more aggressive, a 'for' expression:. ::. extern putchard(char);; def printstar(n); for i = 1, i < n, 1.0 in; putchard(42); # ascii 42 = '*'. # print 100 '*' characters; printstar(100);. This expression defines a new variable (""i"" in this case) which iterates; from a starting value, while the condition (""i < n"" in this case) is; true, incrementing by an optional step value (""1.0"" in this case). If; the step value is omitted, it defaults to 1.0. While the loop is true,; it executes its body expression. Because we don't have anything better; to return, we'll just define the loop as always returning 0.0. In the; future when we have mutable variables, it will get more useful. As before, let's talk about the changes that we need to Kaleidoscope to; support this. Lexer Extensions for the 'for' Loop; -----------------------------------. The lexer extensions are the same sort of thing as for if/then/else:. .. co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl05.rst:15282,power,powerful,15282,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl05.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl05.rst,1,['power'],['powerful']
Energy Efficiency,"The term ""static analysis"" is conflated, but here we use it to mean; a collection of algorithms and techniques used to analyze source code in order; to automatically find bugs. The idea is similar in spirit to compiler warnings; (which can be useful for finding coding errors) but to take that idea a step; further and find bugs that are traditionally found using run-time debugging; techniques such as testing.; Static analysis bug-finding tools have evolved over the last several decades; from basic syntactic checkers to those that find deep bugs by reasoning about; the semantics of code. The goal of the Clang Static Analyzer is to provide a; industrial-quality static analysis framework for analyzing C, C++, and; Objective-C programs that is freely available, extensible, and has a high quality of implementation.; Part of Clang and LLVM; As its name implies, the Clang Static Analyzer is built on top of Clang and LLVM.; Strictly speaking, the analyzer is part of Clang, as Clang consists of a set of; reusable C++ libraries for building powerful source-level tools. The static; analysis engine used by the Clang Static Analyzer is a Clang library, and has; the capability to be reused in different contexts and by different clients.; Important Points to Consider; While we believe that the static analyzer is already very useful for finding; bugs, we ask you to bear in mind a few points when using it.; Work-in-Progress; The analyzer is a continuous work-in-progress. There are many planned; enhancements to improve both the precision and scope of its analysis algorithms; as well as the kinds of bugs it will find. While there are fundamental; limitations to what static analysis can do, we have a long way to go before; hitting that wall.; Slower than Compilation; Operationally, using static analysis to; automatically find deep program bugs is about trading CPU time for the hardening; of code. Because of the deep analysis performed by state-of-the-art static; analysis tools, static an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/index.html:1977,power,powerful,1977,interpreter/llvm-project/clang/www/analyzer/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/index.html,1,['power'],['powerful']
Energy Efficiency,"The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by setting it to zero; ```. - Added an experimental feature that allows the IO libraries to skip writing out redundant information for some split classes, resulting in disk space savings. This is disabled by default and may be enabled by setting:. ```; ROOT::TIOFeatures features;; features.Set(ROOT::Experimental::EIOFeatures::kGenerateOffsetMap);; ttree_ref.SetIOFeatures(features);; ```; - Added `GetAutoSave()` and `SetAutoSave()` methods to `TBufferMerger`, to allow; it to accumulate several buffers in memory before merging, to reduce the; amount of compression work done due to `TTree` metadata. - Added a non-blocking callback mechanism to `TBufferMerger` to allow users to; control the rate at which data is pushed into the merging queue. The callback; mechanism can be used, for example, to launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolved O(N^2) scaling problem in ```TTree::Draw()``` observed when a branch that contains a; large TClonesArray where each element contains another small vector container.; - `TTree::TTree()` now takes the `TDirectory*` that the tree should be constructed in.; Defaults to `gDirectory`, i.e. the default behavior did not change.; - To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced.; This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters wi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:9157,reduce,reduce,9157,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['reduce'],['reduce']
Energy Efficiency,"There are few key implications of the definitions given above which; are important for working successfully with this interface. * LoopInfo does not contain information about non-loop cycles. As a; result, it is not suitable for any algorithm which requires complete; cycle detection for correctness. * LoopInfo provides an interface for enumerating all top level loops; (e.g. those not contained in any other loop). From there, you may; walk the tree of sub-loops rooted in that top level loop. * Loops which become statically unreachable during optimization *must*; be removed from LoopInfo. If this can not be done for some reason,; then the optimization is *required* to preserve the static; reachability of the loop. .. _loop-terminology-loop-simplify:. Loop Simplify Form; ==================. The Loop Simplify Form is a canonical form that makes; several analyses and transformations simpler and more effective.; It is ensured by the LoopSimplify; (:ref:`-loop-simplify <passes-loop-simplify>`) pass and is automatically; added by the pass managers when scheduling a LoopPass.; This pass is implemented in; `LoopSimplify.h <https://llvm.org/doxygen/LoopSimplify_8h_source.html>`_.; When it is successful, the loop has:. * A preheader.; * A single backedge (which implies that there is a single latch).; * Dedicated exits. That is, no exit block for the loop; has a predecessor that is outside the loop. This implies; that all exit blocks are dominated by the loop header. .. _loop-terminology-lcssa:. Loop Closed SSA (LCSSA); =======================. A program is in Loop Closed SSA Form if it is in SSA form; and all values that are defined in a loop are used only inside; this loop. Programs written in LLVM IR are always in SSA form but not necessarily; in LCSSA. To achieve the latter, for each value that is live across the; loop boundary, single entry PHI nodes are inserted to each of the exit blocks; [#lcssa-construction]_ in order to ""close"" these values inside the loop.; In particul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst:10241,schedul,scheduling,10241,interpreter/llvm-project/llvm/docs/LoopTerminology.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst,1,['schedul'],['scheduling']
Energy Efficiency,"Thu Jun 26 14:43:04 CDT 2003. Information about BinInterface; ------------------------------. Take in a set of instructions with some particular register; allocation. It allows you to add, modify, or delete some instructions,; in SSA form (kind of like LLVM's MachineInstrs.) Then re-allocate; registers. It assumes that the transformations you are doing are safe.; It does not update the mapping information or the LLVM representation; for the modified trace (so it would not, for instance, support; multiple optimization passes; passes have to be aware of and update; manually the mapping information.). The way you use it is you take the original code and provide it to; BinInterface; then you do optimizations to it, then you put it in the; trace cache. The BinInterface tries to find live-outs for traces so that it can do; register allocation on just the trace, and stitch the trace back into; the original code. It has to preserve the live-ins and live-outs when; it does its register allocation. (On exits from the trace we have; epilogues that copy live-outs back into the right registers, but; live-ins have to be in the right registers.). Limitations of BinInterface; ---------------------------. It does copy insertions for PHIs, which it infers from the machine; code. The mapping info inserted by LLC is not sufficient to determine; the PHIs. It does not handle integer or floating-point condition codes and it; does not handle floating-point register allocation. It is not aggressively able to use lots of registers. There is a problem with alloca: we cannot find our spill space for; spilling registers, normally allocated on the stack, if the trace; follows an alloca(). What might be an acceptable solution would be to; disable trace generation on functions that have variable-sized; alloca()s. Variable-sized allocas in the trace would also probably; screw things up. Because of the FP and alloca limitations, the BinInterface is; completely disabled right now. Demo; ----. This is ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-26-Reoptimizer2.txt:284,allocate,allocate,284,interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-26-Reoptimizer2.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-26-Reoptimizer2.txt,1,['allocate'],['allocate']
Energy Efficiency,"To-do; -----. * Keep the address of the constant pool in a register instead of forming its; address all of the time.; * We can fold small constant offsets into the %hi/%lo references to constant; pool addresses as well.; * When in V9 mode, register allocate %icc[0-3].; * Add support for isel'ing UMUL_LOHI instead of marking it as Expand.; * Emit the 'Branch on Integer Register with Prediction' instructions. It's; not clear how to write a pattern for this though:. float %t1(int %a, int* %p) {; %C = seteq int %a, 0; br bool %C, label %T, label %F; T:; store int 123, int* %p; br label %F; F:; ret float undef; }. codegens to this:. t1:; save -96, %o6, %o6; 1) subcc %i0, 0, %l0; 1) bne .LBBt1_2 ! F; nop; .LBBt1_1: ! T; or %g0, 123, %l0; st %l0, [%i1]; .LBBt1_2: ! F; restore %g0, %g0, %g0; retl; nop. 1) should be replaced with a brz in V9 mode. * Same as above, but emit conditional move on register zero (p192) in V9; mode. Testcase:. int %t1(int %a, int %b) {; %C = seteq int %a, 0; %D = select bool %C, int %a, int %b; ret int %D; }. * Emit MULX/[SU]DIVX instructions in V9 mode instead of fiddling; with the Y register, if they are faster. * Codegen bswap(load)/store(bswap) -> load/store ASI. * Implement frame pointer elimination, e.g. eliminate save/restore for; leaf fns.; * Fill delay slots. * Use %g0 directly to materialize 0. No instruction is required.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Sparc/README.txt:249,allocate,allocate,249,interpreter/llvm-project/llvm/lib/Target/Sparc/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Sparc/README.txt,1,['allocate'],['allocate']
Energy Efficiency,"Used Technology; ---------------. `LLVM <https://llvm.org/>`_ is a free, open-source compiler infrastructure under; the `Apache License 2.0 <https://www.apache.org/licenses/LICENSE-2.0>`_. It is; designed as a collection of tools including Front Ends parsers, Middle Ends; optimizers, and Back Ends to produce machine code out of those programs. `Clang <https://clang.llvm.org/>`_ is a front-end that uses a LLVM; license. Clang works by taking the source language (e.g. C++) and translating it; into an intermediate representation that is then received by the compiler back; end (i.e., the LLVM backend). Its library-based architecture makes it relatively; easy to adapt Clang and build new tools based on it. Cling inherits a number of; features from LLVM and Clang, such as: fast compiling and low memory use,; efficient C++ parsing, extremely clear and concise diagnostics, Just-In-Time; compilation, pluggable optimizers, and support for `GCC <https://gcc.gnu.org/>`_; extensions. Interpreters allow for exploration of software development at the rate of human; thought. Nevertheless, interpreter code can be slower than compiled code due to; the fact that translating code at run time adds to the overhead and therefore; causes the execution speed to be slower. This issue is overcome by exploiting; the *Just-In-Time* (`JIT; <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_) compilation method,; which allows an efficient memory management (for example, by evaluating whether; a certain part of the source code is executed often, and then compile this part,; therefore reducing the overall execution time). With the JIT approach, the developer types the code in Cling's command; prompt. The input code is then lowered to Clang, where is compiled and; eventually transformed in order to attach specific behavior. Clang compiles then; the input into an AST representation, that is then lowered to LLVM IR, an; `intermediate language; <https://en.wikipedia.org/wiki/Common_Intermediate_L",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst:666,adapt,adapt,666,interpreter/cling/docs/chapters/implementation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst,2,"['adapt', 'efficient']","['adapt', 'efficient']"
Energy Efficiency,"Used in This Book. We tried to follow a style convention for the sake of clarity. The; styles in used are described below. To show source code in scripts or source files:. ``` {.cpp}; {; cout << "" Hello"" << endl;; float x = 3.;; float y = 5.;; int i = 101;; cout <<"" x = ""<<x<<"" y = ""<<y<<"" i = ""<<i<< endl;; }; ```. To show the ROOT command line, we show the ROOT prompt without numbers.; In the interactive system, the ROOT prompt has a line number; (`root[12]`); for the sake of simplicity, the line numbers are left; off. ``` {.cpp}; root[] TLine l; root[] l.Print(); TLine X1=0.000000 Y1=0.000000 X2=0.000000 Y2=0.000000; ```. Italic bold monotype font indicates a global variable, for example; ***`gDirectory`***. When a variable term is used, it is shown between angled brackets. In; the example below the variable term \<library\> can be replaced with; any library in the `$ROOTSYS` directory: `$ROOTSYS/<library>/inc.`. ## The Framework. ROOT is an object-oriented framework aimed at solving the data; analysis challenges of high-energy physics. There are two key words in; this definition, object oriented and framework. First, we explain what; we mean by a framework and then why it is an object-oriented; framework. ### What Is a Framework?. Programming inside a framework is a little like living in a city.; Plumbing, electricity, telephone, and transportation are services; provided by the city. In your house, you have interfaces to the; services such as light switches, electrical outlets, and telephones.; The details, for example, the routing algorithm of the phone switching; system, are transparent to you as the user. You do not care; you are; only interested in using the phone to communicate with your; collaborators to solve your domain specific problems. Programming outside of a framework may be compared to living in the; country. In order to have transportation and water, you will have to; build a road and dig a well. To have services like telephone and; electricity you",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:4643,energy,energy,4643,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['energy'],['energy']
Energy Efficiency,"W the twenty-year-old FORTRAN libraries had reached their; limits. Although still very popular, these tools could not scale up to; the challenges offered by the Large Hadron Collider, where the data is; a few orders of magnitude larger than anything seen before. At the same time, computer science had made leaps of progress; especially in the area of Object Oriented Design, and René and Fons; were ready to take advantage of it. ROOT was developed in the context of the NA49 experiment at CERN. NA49; has generated an impressive amount of data, around 10 Terabytes per; run. This rate provided the ideal environment to develop and test the; next generation data analysis. ROOT was, and still is, developed in the ""Bazaar style"", a term from; the book ""The Cathedral and the Bazaar"" by Eric S. Raymond. It means a; liberal, informal development style that heavily relies on the diverse; and deep talent of the user community. The result is that physicists; developed ROOT for themselves; this made it specific, appropriate,; useful, and over time refined and very powerful. The development of; ROOT is a continuous conversation between users and developers with; the line between the two blurring at times and the users becoming; co-developers. When it comes to storing and mining large amount of data, physics; plows the way with its Terabytes, but other fields and industry follow; close behind as they acquiring more and more data over time. They are; ready to use the true and tested technologies physics has invented. In; this way, other fields and industries have found ROOT useful and they; have started to use it also. In the bazaar view, software is released early and frequently to; expose it to thousands of eager co-developers to pound on, report; bugs, and contribute possible fixes. More users find more bugs,; because they stress the program in different ways. By now, after ten; years, the age of ROOT is quite mature. Most likely, you will find the; features you are looking for, an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:1296,power,powerful,1296,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['power'],['powerful']
Energy Efficiency,"When and why was Cling developed?; ---------------------------------. Cling was first released in 2014 as the interactive, C++ interpreter in; ROOT. `ROOT <https://root.cern/>`_ is an open-source program written primarily; in C++, developed by research groups in high-energy physics including `CERN; <https://home.cern/>`_, `FERMILAB <https://www.fnal.gov/>`_ and `Princeton; <https://www.princeton.edu/>`_. ROOT is nowadays used by most high-energy; physics experiments. CERN is an European research organization that operates the; largest particle physics laboratory in the world. Its experiments collect; petabytes of data per year to be serialized, analyzed, and visualized as C++; objects. In this framework, Cling was developed with the aim to facilitate the; processing of scientific data in the field of high-energy physics . Cling is a; core component of ROOT: it provides essential functionality for the analysis of; vast amounts of very complex data produced by the experimental high-energy; physics community by enabling (1) interactive exploration in C++, (2) dynamic; interoperability (see `cppyy <https://cppyy.readthedocs.io/en/latest/>`_, an; automatic, runtime Python/C++ binder), and (3) rapid prototyping capabilities.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/background.rst:268,energy,energy,268,interpreter/cling/docs/chapters/background.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/background.rst,4,['energy'],['energy']
Energy Efficiency,"Why interpreting C++ with Cling?; -----------------------------------. 1. **Learning C++:**; ; One use case of Cling is to aid the C++ learning process. Offering imediate; feedback the user can easily get familiar with the structures and spelling of; the language. 2. **Creating scripts:**; ; The power of an interpreter lays as well in the compactness and ease of; repeatedly running a small snippet of code - aka a script. This can be done in; Cling by inserting the bash-like style line:. .. code:: bash; ; #!/usr/bin/cling; ; 3. **Rapid Application Development (RAD):**. Cling can be used successfully for Rapid Application Development allowing for; prototyping and proofs of concept taking advantage of dynamicity and feedback; during the implementation process. 4. **Runtime-Generated Code**. Sometime it's convenient to create code as a reaction to input; (user/network/configuration). Runtime-generated code can interface with C++; libraries. 5. **Embedding Cling:**. The functionality of an application can be enriched by embedding Cling. To embed; Cling, the main program has to be provided. One of the things this main program; has to do is initialize the Cling interpreter. There are optional calls to pass; command line arguments to Cling. Afterwards, you can call the interpreter from; any anywhere within the application. For compilation and linkage the application needs the path to the Clang and LLVM; libraries and the invocation is order dependent since the linker cannot do; backward searches. .. code:: bash. g++ embedcling.cxx -std=c++11 -L/usr/local/lib; -lclingInterpreter -lclingUtils ; -lclangFrontend -lclangSerialization -lclangParse -lclangSema ; -lclangAnalysis -lclangEdit -lclangLex -lclangDriver -lclangCodeGen ; -lclangBasic -lclangAST ; `llvm-config ; --libs bitwriter mcjit orcjit native option ; ipo profiledata instrumentation objcarcopts` ; -lz -pthread -ldl -ltinfo ; -o embedcling; . Embedding Cling requires the creation of the interpreter. Optionally compile",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst:297,power,power,297,interpreter/cling/docs/chapters/why_interpreting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst,1,['power'],['power']
Energy Efficiency,"Windows, you should be using lld-link as the linker. Adjust your compilation ; flags as follows:; * Add ``/lldsavetemps`` to the linker flags.; * When linking from the compiler driver, add ``/link /lldsavetemps`` in order to forward that flag to the linker. Using the specified flags will generate four intermediate bytecode files:. #. a.out.0.0.preopt.bc (Before any link-time optimizations (LTO) are applied); #. a.out.0.2.internalize.bc (After initial optimizations are applied); #. a.out.0.4.opt.bc (After an extensive set of optimizations); #. a.out.0.5.precodegen.bc (After LTO but before translating into machine code). Execute one of the following commands to identify the source of the problem:. #. ``opt ""-passes=lto<O3>"" a.out.0.2.internalize.bc``; #. ``llc a.out.0.5.precodegen.bc``. If one of these do crash, you should be able to reduce; this with :program:`llvm-reduce`; command line (use the bc file corresponding to the command above that failed):. .. code-block:: bash. llvm-reduce --test reduce.sh a.out.0.2.internalize.bc. Example of reduce.sh script. .. code-block:: bash. $ cat reduce.sh; #!/bin/bash -e. path/to/not --crash path/to/opt ""-passes=lto<O3>"" $1 -o temp.bc 2> err.log; grep -q ""It->second == &Insn"" err.log. Here we have grepped the failed assert message. Please run this, then file a bug with the instructions and reduced .bc file; that llvm-reduce emits. .. _miscompiling:. Miscompilations; ===============. If clang successfully produces an executable, but that executable doesn't run; right, this is either a bug in the code or a bug in the compiler. The first; thing to check is to make sure it is not using undefined behavior (e.g.; reading a variable before it is defined). In particular, check to see if the; program is clean under various `sanitizers; <https://github.com/google/sanitizers>`_ (e.g. ``clang; -fsanitize=undefined,address``) and `valgrind <http://valgrind.org/>`_. Many; ""LLVM bugs"" that we have chased down ended up being bugs in the program ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:7526,reduce,reduce,7526,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,2,['reduce'],['reduce']
Energy Efficiency,"X90A, GFX940; - vgprs_used 0..512; - vgprs_used = align(arch_vgprs, 4); + acc_vgprs; - max(0, ceil(vgprs_used / 8) - 1); GFX10-GFX11 (wavefront size 64); - max_vgpr 1..256; - max(0, ceil(vgprs_used / 4) - 1); GFX10-GFX11 (wavefront size 32); - max_vgpr 1..256; - max(0, ceil(vgprs_used / 8) - 1). Where vgprs_used is defined; as the highest VGPR number; explicitly referenced plus; one. Used by CP to set up; ``COMPUTE_PGM_RSRC1.VGPRS``. The; :ref:`amdgpu-assembler`; calculates this; automatically for the; selected processor from; values provided to the; `.amdhsa_kernel` directive; by the; `.amdhsa_next_free_vgpr`; nested directive (see; :ref:`amdhsa-kernel-directives-table`).; 9:6 4 bits GRANULATED_WAVEFRONT_SGPR_COUNT Number of scalar register; blocks used by a wavefront;; granularity is device; specific:. GFX6-GFX8; - sgprs_used 0..112; - max(0, ceil(sgprs_used / 8) - 1); GFX9; - sgprs_used 0..112; - 2 * max(0, ceil(sgprs_used / 16) - 1); GFX10-GFX11; Reserved, must be 0.; (128 SGPRs always; allocated.). Where sgprs_used is; defined as the highest; SGPR number explicitly; referenced plus one, plus; a target specific number; of additional special; SGPRs for VCC,; FLAT_SCRATCH (GFX7+) and; XNACK_MASK (GFX8+), and; any additional; target specific; limitations. It does not; include the 16 SGPRs added; if a trap handler is; enabled. The target specific; limitations and special; SGPR layout are defined in; the hardware; documentation, which can; be found in the; :ref:`amdgpu-processors`; table. Used by CP to set up; ``COMPUTE_PGM_RSRC1.SGPRS``. The; :ref:`amdgpu-assembler`; calculates this; automatically for the; selected processor from; values provided to the; `.amdhsa_kernel` directive; by the; `.amdhsa_next_free_sgpr`; and `.amdhsa_reserve_*`; nested directives (see; :ref:`amdhsa-kernel-directives-table`).; 11:10 2 bits PRIORITY Must be 0. Start executing wavefront; at the specified priority. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.PRIORITY``.; 13:12 2 bit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:164732,allocate,allocated,164732,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"YAML for should be in x,y coordinates. That; is, you want the yaml to look like:. .. code-block:: yaml. x: 10.3; y: -4.7. You can support this by defining a MappingTraits that normalizes the polar; coordinates to x,y coordinates when writing YAML and denormalizes x,y; coordinates into polar when reading YAML. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct MappingTraits<Polar> {. class NormalizedPolar {; public:; NormalizedPolar(IO &io); : x(0.0), y(0.0) {; }; NormalizedPolar(IO &, Polar &polar); : x(polar.distance * cos(polar.angle)),; y(polar.distance * sin(polar.angle)) {; }; Polar denormalize(IO &) {; return Polar(sqrt(x*x+y*y), arctan(x,y));; }. float x;; float y;; };. static void mapping(IO &io, Polar &polar) {; MappingNormalization<NormalizedPolar, Polar> keys(io, polar);. io.mapRequired(""x"", keys->x);; io.mapRequired(""y"", keys->y);; }; };. When writing YAML, the local variable ""keys"" will be a stack allocated; instance of NormalizedPolar, constructed from the supplied polar object which; initializes it x and y fields. The mapRequired() methods then write out the x; and y values as key/value pairs. When reading YAML, the local variable ""keys"" will be a stack allocated instance; of NormalizedPolar, constructed by the empty constructor. The mapRequired; methods will find the matching key in the YAML document and fill in the x and y; fields of the NormalizedPolar object keys. At the end of the mapping() method; when the local keys variable goes out of scope, the denormalize() method will; automatically be called to convert the read values back to polar coordinates,; and then assigned back to the second parameter to mapping(). In some cases, the normalized class may be a subclass of the native type and; could be returned by the denormalize() method, except that the temporary; normalized instance is stack allocated. In these cases, the utility template; MappingNormalizationHeap<> can be used instead. It just like; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:18665,allocate,allocated,18665,interpreter/llvm-project/llvm/docs/YamlIO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst,1,['allocate'],['allocated']
Energy Efficiency,"[0]; // returns 'Both'.; }. .. _dss_ilist_traits:. ilist_traits; ^^^^^^^^^^^^. ``ilist_traits<T>`` is ``ilist<T>``'s customization mechanism. ``ilist<T>``; publicly derives from this traits class. .. _dss_ilist_node:. llvm/ADT/ilist_node.h; ^^^^^^^^^^^^^^^^^^^^^. ``ilist_node<T>`` implements the forward and backward links that are expected; by the ``ilist<T>`` (and analogous containers) in the default manner. ``ilist_node<T>``\ s are meant to be embedded in the node type ``T``, usually; ``T`` publicly derives from ``ilist_node<T>``. .. _dss_ilist_sentinel:. Sentinels; ^^^^^^^^^. ``ilist``\ s have another specialty that must be considered. To be a good; citizen in the C++ ecosystem, it needs to support the standard container; operations, such as ``begin`` and ``end`` iterators, etc. Also, the; ``operator--`` must work correctly on the ``end`` iterator in the case of; non-empty ``ilist``\ s. The only sensible solution to this problem is to allocate a so-called *sentinel*; along with the intrusive list, which serves as the ``end`` iterator, providing; the back-link to the last element. However conforming to the C++ convention it; is illegal to ``operator++`` beyond the sentinel and it also must not be; dereferenced. These constraints allow for some implementation freedom to the ``ilist`` how to; allocate and store the sentinel. The corresponding policy is dictated by; ``ilist_traits<T>``. By default a ``T`` gets heap-allocated whenever the need; for a sentinel arises. While the default policy is sufficient in most cases, it may break down when; ``T`` does not provide a default constructor. Also, in the case of many; instances of ``ilist``\ s, the memory overhead of the associated sentinels is; wasted. To alleviate the situation with numerous and voluminous; ``T``-sentinels, sometimes a trick is employed, leading to *ghostly sentinels*. Ghostly sentinels are obtained by specially-crafted ``ilist_traits<T>`` which; superpose the sentinel with the ``ilist`` instance in mem",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:69195,allocate,allocate,69195,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocate']
Energy Efficiency,"[ROOT-6996]. A similar problem was affecting `TClonesArray::operator=`, `TClonesArray::Expand` and `TClonesArray::ExpandCreate` and was also solved. `TClonesArray` reliance on global state during the destruction of the elements was decreased (removing use of `TObject::SetDtorOnly`). ### Global resources. Several tweaks to if and when, resources held by the global ROOT object (TROOT, TApplication) are deleted. When the default TApplication is replaced by a user provide TApplication, do not call EndOfProcessCleanups and co. and thus do not delete TFiles, TSockets or TColors that have already been created. In EndOfProcessCleanups, we now delete the objects held in TROOT's TDirectory part. If the libCling library is unloaded, this now induces an immediate tear down of the ROOT resources; consequently objects might be deleted sooner in the process tear down process on some platforms. TObject instances allocated as part of an array and made part of a collection, as for example the TCanvas instances into the global list of instances, are not longer deleted if the content of the collection is deleted. Technically the element of the array are now treated by collections as if they have been allocated on the stack. This fixes the issue described at [ROOT-7846]. ### Code Cleanups. Several definition where moved from the global or ROOT namespace to the ROOT::Internal namespace as they are not intended to be used outside of ROOT, including: `gROOTLocal` and related functions, `TSchemaHelper`, `TSchemaMatch`, `TSchemaType`, `RStl`, `ROOT::TROOTAllocator`, `TSchemaRuleProcessor`, `TStdBitsetHelper`, `TInitBehavior`, `TDefaultInitBehavior`, `DefineBehavior`, `THnBaseBrowsable`, `THnBaseBinIter`, `GenericShowMembers`, `TOperatorNewHelper` and `BranchProxy` implementations classes. Several definition where moved from the global or ROOT namespace to the ROOT::Details namespace as they are intended to be used in 'expert' level code and have a lower level of backward compatibility require",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:4941,allocate,allocated,4941,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['allocate'],['allocated']
Energy Efficiency,"[TBufferJSON](https://root.cern/doc/master/classTBufferJSON.html) class,; which is capable to convert any (beside TTree) ROOT object into JSON. Any ROOT application can use such class to; create JSON files for selected objects and write such files in a directory,; which can be accessed via web server. Then one can use JSROOT to read such files and display objects in a web browser. There is a demonstration page showing such functionality: <https://root.cern/js/latest/demo/update_draw.htm>.; This demo page reads in cycle 20 json files and displays them. If one has a web server which already provides such JSON file, one could specify the URL to this file like:. <https://root.cern/js/latest/demo/update_draw.htm?addr=../httpserver.C/Canvases/c1/root.json.gz>. Here the same problem with [Cross-Origin Request](https://developer.mozilla.org/en/http_access_control) can appear. If the web server configuration cannot be changed, just copy JSROOT to the web server itself. ### Binary file-based monitoring (not recommended). Theoretically, one could use binary ROOT files to implement monitoring.; With such approach, a ROOT-based application creates and regularly updates content of a ROOT file, which can be accessed via normal web server. From the browser side, JSROOT could regularly read the specified objects and update their drawings. But such solution has three major caveats. First of all, one need to store the data of all objects, which only potentially could be displayed in the browser. In case of 10 objects it does not matter, but for 1000 or 100000 objects this will be a major performance penalty. With such big amount of data one will never achieve higher update rate. The second problem is I/O. To read the first object from the ROOT file, one need to perform several (about 5) file-reading operations via http protocol.; There is no http file locking mechanism (at least not for standard web servers),; therefore there is no guarantee that the file content is not changed/replac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:32167,monitor,monitoring,32167,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['monitor'],['monitoring']
Energy Efficiency,"\defgroup ged ROOT Graphics Editor; \ingroup gui; \brief Classes forming the Graphics Editor (GED) of ROOT and the basic classes of so-called object editors. ## The ROOT Graphics Editor (GED). Everything drawn in a ROOT canvas is an object. There are classes for; all objects, and they fall into hierarchies. In addition, the ROOT has; fully cross-platform GUI classes and provides all standard components; for an application environment with common ‘look and feel'. The; object-oriented, event-driven programming model supports the modern; signals/slots communication mechanism. It handles user interface actions; and allows total independence of interacting objects and classes. This; mechanism uses the ROOT dictionary information and the Cling the C++; Interpreter to connect signals to slots methods. Therefore, all necessary elements for an object-oriented editor design; are in place. The editor complexity can be reduced by splitting it into; discrete units of so-called *`object`* *`editors`*. Any object editor; provides an object specific GUI. The main purpose of the ROOT graphics; editor is the organization of the object editors' appearance and the; task sequence between them. ### Object Editors. Every object editor follows a simple naming convention: to have as a; name the object class name concatenated with ‘*`Editor`*' (e.g. for; **`TGraph`** objects the object editor is **`TGraphEditor`**). Thanks to; the signals/slots communication mechanism and to the method; `DistancetoPrimitive()` that computes a ‘‘distance'' to an object from; the mouse position, it was possible to implement a signal method of the; canvas that says which is the selected object and to which pad it; belongs. Having this information the graphics editor loads the; corresponding object editor and the user interface is ready for use.; This way after a click on ‘axis'—the axis editor is active; a click on a; ‘pad' activates the pad editor, etc. The algorithm in use is simple and is based on the object-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md:921,reduce,reduced,921,gui/ged/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/ged/doc/index.md,1,['reduce'],['reduced']
Energy Efficiency,"\defgroup roofit_dev_docs_ad How to extend the use of Automatic Differentiation in RooFit; \ingroup roofit_dev_docs; \date October 2023; \brief Developer guide on how to add support for Automatic Differentiation via code generation. # How to extend the use of Automatic Differentiation in RooFit. ## What is RooFit?. [RooFit] is a statistical data analysis tool, widely used in scientific; research, especially in the high-energy physics (HEP) field. It is an; extension of the ROOT framework, a C++ based data analysis framework that; provides tools for data storage, analysis, and visualization. RooFit provides; a set of tools/classes to define and evaluate probability density functions; (PDFs), perform maximum likelihood fits, perform statistical tests, etc. ## Proof of Concept: Speeding up RooFit using Automatic Differentiation (AD). RooFit is used to reduce statistical models (functions) to find a set of; parameters that minimize the value of the function. This minimization happens; via one of several methods relying heavily on the computation of derivatives; of the function with respect to its free parameters. Currently, the; computation of Numerical Derivatives is the most time-consuming component of; RooFit [^1]. On the other hand, derivatives computed using the Automatic; Differentiation tool [Clad] have been shown to be far more efficient [^2]. \htmlonly; <div class=""pyrootbox"">; \endhtmlonly. Main Advantage of using AD with RooFit: efficient and more precise; derivatives. It computes derivatives with high precision, avoiding the errors; that may arise from approximating derivatives using finite differences. \htmlonly; </div>; \endhtmlonly. ### AD Support essentially requires Code Generation. As we'll discuss in upcoming sections, *AD support* can be added using *C++; Code generation*.; These two terms may be used interchangeably in this document, since the term; *Code Generation* better helps visualize the transformation that is enabling; AD support. ## Current S",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:423,energy,energy,423,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,2,"['energy', 'reduce']","['energy', 'reduce']"
Energy Efficiency,"\defgroup roofit_dev_docs_batchcompute RooBatchCompute library guide; \ingroup roofit_dev_docs; \date September 2021; \author Emmanouil Michalainas; \brief Overview of the RooBatchCompute library. ## RooBatchCompute Library; _Contains optimized computation functions for PDFs that enable significantly faster fittings._; #### Note: This library is still at an experimental stage. Tests are being conducted continuously to ensure correctness of the results, but the interfaces and the instructions on how to use might change. ### Purpose; While fitting, a significant amount of time and processing power is spent on computing the probability function for every event and PDF involved in the fitting model. To speed up this process, roofit can use the computation functions provided in this library. The functions provided here process whole data arrays (batches) instead of a single event at a time, as in the legacy evaluate() function in roofit. In addition, the code is written in a manner that allows for compiler optimizations, notably auto-vectorization. This library is compiled multiple times for different [vector instruction set architectures](https://en.wikipedia.org/wiki/SIMD) and the optimal code is executed during runtime, as a result of an automatic hardware detection mechanism that this library contains. **As a result, fits can benefit by a speedup of 3x-16x.**. As of ROOT v6.26, RooBatchComputes also provides multithread and [CUDA](https://en.wikipedia.org/wiki/CUDA) instances of the computation functions, resulting in even greater improvements for fitting times. ### How to use; This library is an internal component of RooFit, so users are not supposed to actively interact with it. Instead, they can benefit from significantly faster times for fitting by calling `fitTo()` and providing a `BatchMode(""cpu"")` or a `BatchMode(""cuda"")` option.; ``` {.cpp}; // fit using the most efficient library that the computer's CPU can support; RooMyPDF.fitTo(data, BatchMode(""cpu""));. //",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md:597,power,power,597,roofit/doc/developers/batchcompute.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md,1,['power'],['power']
Energy Efficiency,"]; ldrb r12, [r1, #+7]; ldrh r1, [r1, #+4]; str r2, [r0]; strh r1, [r0, #+4]; strb r3, [r0, #+6]; strb r12, [r0, #+7]; gcc code (-O2); ldmia r1, {r1-r2}; stmia r0, {r1-r2}. In this benchmark poor handling of aggregate copies has shown up as; having a large effect on size, and possibly speed as well (we don't have; a good way to measure on ARM). //===---------------------------------------------------------------------===//. * Consider this silly example:. double bar(double x) {; double r = foo(3.1);; return x+r;; }. _bar:; stmfd sp!, {r4, r5, r7, lr}; add r7, sp, #8; mov r4, r0; mov r5, r1; fldd d0, LCPI1_0; fmrrd r0, r1, d0; bl _foo; fmdrr d0, r4, r5; fmsr s2, r0; fsitod d1, s2; faddd d0, d1, d0; fmrrd r0, r1, d0; ldmfd sp!, {r4, r5, r7, pc}. Ignore the prologue and epilogue stuff for a second. Note; 	mov r4, r0; 	mov r5, r1; the copys to callee-save registers and the fact they are only being used by the; fmdrr instruction. It would have been better had the fmdrr been scheduled; before the call and place the result in a callee-save DPR register. The two; mov ops would not have been necessary. //===---------------------------------------------------------------------===//. Calling convention related stuff:. * gcc's parameter passing implementation is terrible and we suffer as a result:. e.g.; struct s {; double d1;; int s1;; };. void foo(struct s S) {; printf(""%g, %d\n"", S.d1, S.s1);; }. 'S' is passed via registers r0, r1, r2. But gcc stores them to the stack, and; then reload them to r1, r2, and r3 before issuing the call (r0 contains the; address of the format string):. 	stmfd	sp!, {r7, lr}; 	add	r7, sp, #0; 	sub	sp, sp, #12; 	stmia	sp, {r0, r1, r2}; 	ldmia	sp, {r1-r2}; 	ldr	r0, L5; 	ldr	r3, [sp, #8]; L2:; 	add	r0, pc, r0; 	bl	L_printf$stub. Instead of a stmia, ldmia, and a ldr, wouldn't it be better to do three moves?. * Return an aggregate type is even worse:. e.g.; struct s foo(void) {; struct s S = {1.1, 2};; return S;; }. 	mov	ip, r0; 	ldr	r0, L5; 	sub	sp, sp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:4904,schedul,scheduled,4904,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,1,['schedul'],['scheduled']
Energy Efficiency,"^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmin.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmin.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmin.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with minimum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmaximum:. '``llvm.vector.reduce.fmaximum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmaximum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmaximum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmaximum.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maximum.*``'; intrinsic. That is, this intrinsic propagates NaNs and +0.0 is considered; greater than -0.0. If any element of the vector is a NaN, the result is NaN. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fminimum:. '``llvm.vector.reduce.fminimum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. de",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:660566,reduce,reduce,660566,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"^^^^^^^^^^^. Create a vector from multiple scalar registers. No implicit; conversion is performed (i.e. the result element type must be the; same as all source operands). The _TRUNC version truncates the larger operand types to fit the; destination vector elt type. G_INSERT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^. Insert an element into a vector. G_EXTRACT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^^. Extract an element from a vector. G_SHUFFLE_VECTOR; ^^^^^^^^^^^^^^^^. Concatenate two vectors and shuffle the elements according to the mask operand.; The mask operand should be an IR Constant which exactly matches the; corresponding mask for the IR shufflevector instruction. Vector Reduction Operations; ---------------------------. These operations represent horizontal vector reduction, producing a scalar result. G_VECREDUCE_SEQ_FADD, G_VECREDUCE_SEQ_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SEQ variants perform reductions in sequential order. The first operand is; an initial scalar accumulator value, and the second operand is the vector to reduce. G_VECREDUCE_FADD, G_VECREDUCE_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These reductions are relaxed variants which may reduce the elements in any order. G_VECREDUCE_FMAX, G_VECREDUCE_FMIN, G_VECREDUCE_FMAXIMUM, G_VECREDUCE_FMINIMUM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. FMIN/FMAX/FMINIMUM/FMAXIMUM nodes can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. * G_VECREDUCE_ADD; * G_VECREDUCE_MUL; * G_VECREDUCE_AND; * G_VECREDUCE_OR; * G_VECREDUCE_XOR; * G_VECREDUCE_SMAX; * G_VECREDUCE_SMIN; * G_VECREDUCE_UMAX; * G_VECREDUCE_UMIN. Integer reductions may have a result type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:14579,reduce,reduce,14579,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,1,['reduce'],['reduce']
Energy Efficiency,"^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The loaded data is a vector of any integer, floating-point or pointer data type. ::. declare <16 x float> @llvm.masked.load.v16f32.p0(ptr <ptr>, i32 <alignment>, <16 x i1> <mask>, <16 x float> <passthru>); declare <2 x double> @llvm.masked.load.v2f64.p0(ptr <ptr>, i32 <alignment>, <2 x i1> <mask>, <2 x double> <passthru>); ;; The data is a vector of pointers; declare <8 x ptr> @llvm.masked.load.v8p0.p0(ptr <ptr>, i32 <alignment>, <8 x i1> <mask>, <8 x ptr> <passthru>). Overview:; """""""""""""""""". Reads a vector from memory according to the provided mask. The mask holds a bit for each vector lane, and is used to prevent memory accesses to the masked-off lanes. The masked-off lanes in the result vector are taken from the corresponding lanes of the '``passthru``' operand. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is the alignment of the source location. It must be a power of two constant integer value. The third operand, mask, is a vector of boolean values with the same number of elements as the return type. The fourth is a pass-through value that is used to fill the masked-off lanes of the result. The return type, underlying type of the base pointer and the type of the '``passthru``' operand are the same vector types. Semantics:; """""""""""""""""""". The '``llvm.masked.load``' intrinsic is designed for conditional reading of selected vector elements in a single IR operation. It is useful for targets that support vector masked loads and allows vectorizing predicated basic blocks on these targets. Other targets may support this intrinsic differently, for example by lowering it into a sequence of branches that guard scalar load operations.; The result of this operation is equivalent to a regular vector load instruction followed by a 'select' between the loaded and the passthru values, predicated on the same mask. However, using this intrinsic prevents exceptions on mem",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:844178,power,power,844178,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umax``' intrinsic performs the unsigned-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.umax <int_vector_reduce_umax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``0`` (i.e. having no effect on the reduction operation). If the; vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umax.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umax.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_um",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:767914,reduce,reduce,767914,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umin``' intrinsic performs the unsigned-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.umin <int_vector_reduce_umin>`) of the; vector operand ``val`` on each enabled lane, taking the minimum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umin.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umin.i32(i32 %reduction, i32 %start). ..",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:769982,reduce,reduce,769982,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smax``' intrinsic performs the signed-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.smax <int_vector_reduce_smax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MIN`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smax.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 -128, i8 -128, i8 -128, i8 -128>; %reduction = call i8 @llvm.vector.reduce.smax.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smax.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_smi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:763786,reduce,reduce,763786,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smin``' intrinsic performs the signed-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.smin <int_vector_reduce_smin>`) of the; vector operand ``val`` on each enabled lane, and taking the minimum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MAX`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smin.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 127, i8 127, i8 127, i8 127>; %reduction = call i8 @llvm.vector.reduce.smin.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smin.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_umax:. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:765851,reduce,reduce,765851,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.ctlz`` on any; integer bit width, or any vector whose elements are integers. Not all; targets support all bit widths or vector types, however. ::. declare i8 @llvm.ctlz.i8 (i8 <src>, i1 <is_zero_poison>); declare <2 x i37> @llvm.ctlz.v2i37(<2 x i37> <src>, i1 <is_zero_poison>). Overview:; """""""""""""""""". The '``llvm.ctlz``' family of intrinsic functions counts the number of; leading zeros in a variable. Arguments:; """""""""""""""""""". The first argument is the value to be counted. This argument may be of; any integer type, or a vector with integer element type. The return; type must match the first argument type. The second argument is a constant flag that indicates whether the intrinsic; returns a valid result if the first argument is zero. If the first; argument is zero and the second argument is true, the result is poison.; Historically some architectures did not provide a defined result for zero; values as efficiently, and many algorithms are now predicated on avoiding; zero-value inputs. Semantics:; """""""""""""""""""". The '``llvm.ctlz``' intrinsic counts the leading (most significant); zeros in a variable, or within each element of the vector. If; ``src == 0`` then the result is the size in bits of the type of ``src``; if ``is_zero_poison == 0`` and ``poison`` otherwise. For example,; ``llvm.ctlz(i32 2) = 30``. .. _int_cttz:. '``llvm.cttz.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.cttz`` on any; integer bit width, or any vector of integer elements. Not all targets; support all bit widths or vector types, however. ::. declare i42 @llvm.cttz.i42 (i42 <src>, i1 <is_zero_poison>); declare <2 x i32> @llvm.cttz.v2i32(<2 x i32> <src>, i1 <is_zero_poison>). Overview:; """""""""""""""""". The '``llvm.cttz``' family of intrinsic functions counts the number of; trailing zeros. Arguments:; """""""""""""""""""". The first argument is the value to be co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:594466,efficient,efficiently,594466,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['efficient'],['efficiently']
Energy Efficiency,"^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The data stored in memory is a vector of any integer, floating-point or pointer data type. ::. declare void @llvm.masked.store.v8i32.p0 (<8 x i32> <value>, ptr <ptr>, i32 <alignment>, <8 x i1> <mask>); declare void @llvm.masked.store.v16f32.p0(<16 x float> <value>, ptr <ptr>, i32 <alignment>, <16 x i1> <mask>); ;; The data is a vector of pointers; declare void @llvm.masked.store.v8p0.p0 (<8 x ptr> <value>, ptr <ptr>, i32 <alignment>, <8 x i1> <mask>). Overview:; """""""""""""""""". Writes a vector to memory according to the provided mask. The mask holds a bit for each vector lane, and is used to prevent memory accesses to the masked-off lanes. Arguments:; """""""""""""""""""". The first operand is the vector value to be written to memory. The second operand is the base pointer for the store, it has the same underlying type as the value operand. The third operand is the alignment of the destination location. It must be a power of two constant integer value. The fourth operand, mask, is a vector of boolean values. The types of the mask and the value operand must have the same number of vector elements. Semantics:; """""""""""""""""""". The '``llvm.masked.store``' intrinsics is designed for conditional writing of selected vector elements in a single IR operation. It is useful for targets that support vector masked store and allows vectorizing predicated basic blocks on these targets. Other targets may support this intrinsic differently, for example by lowering it into a sequence of branches that guard scalar store operations.; The result of this operation is equivalent to a load-modify-store sequence. However, using this intrinsic prevents exceptions and data races on memory access to masked-off lanes. ::. call void @llvm.masked.store.v16f32.p0(<16 x float> %value, ptr %ptr, i32 4, <16 x i1> %mask). ;; The result of the following instructions is identical aside from potential data races and memory access exceptions; %oldval ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:846629,power,power,846629,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.add.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.add.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``ADD`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.add``' intrinsic performs the integer ``ADD`` reduction; (:ref:`llvm.vector.reduce.add <int_vector_reduce_add>`) of the vector operand; ``val`` on each enabled lane, adding it to the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``0`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is equal; to ``start_value``. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.add.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> zeroinitializer; %reduction = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %masked.a); %also.r = add i32 %reduction, %start. .. _int_vp_reduce_fadd:. '``llvm.vp.reduce.fadd.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:749309,reduce,reduce,749309,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.and.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.and.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``AND`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.and``' intrinsic performs the integer ``AND`` reduction; (:ref:`llvm.vector.reduce.and <int_vector_reduce_and>`) of the vector operand; ``val`` on each enabled lane, performing an '``and``' of that with with the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.and.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %masked.a); %also.r = and i32 %reduction, %start. .. _int_vp_reduce_or:. '``llvm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:757709,reduce,reduce,757709,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.mul.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.mul.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``MUL`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.mul``' intrinsic performs the integer ``MUL`` reduction; (:ref:`llvm.vector.reduce.mul <int_vector_reduce_mul>`) of the vector operand ``val``; on each enabled lane, multiplying it by the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``1`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is the; start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.mul.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 1, i32 1, i32 1, i32 1>; %reduction = call i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %masked.a); %also.r = mul i32 %reduction, %start. .. _int_vp_reduce_fmul:. '``llvm.vp.reduce.fmul.*``' Intrinsics; ^^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:753512,reduce,reduce,753512,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.xor.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.xor.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``XOR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.xor``' intrinsic performs the integer ``XOR`` reduction; (:ref:`llvm.vector.reduce.xor <int_vector_reduce_xor>`) of the vector operand; ``val`` on each enabled lane, performing an '``xor``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.xor.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %masked.a); %also.r = xor i32 %reduction, %start. .. _int_vp_reduce_smax:. '``llvm.vp.reduce.smax.*``' Intr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:761757,reduce,reduce,761757,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.or.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.or.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``OR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.or``' intrinsic performs the integer ``OR`` reduction; (:ref:`llvm.vector.reduce.or <int_vector_reduce_or>`) of the vector operand; ``val`` on each enabled lane, performing an '``or``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.or.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %masked.a); %also.r = or i32 %reduction, %start. .. _int_vp_reduce_xor:. '``llvm.vp.reduce.xor.*``' Intrinsics; ^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:759748,reduce,reduce,759748,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.thread.pointer(). Overview:; """""""""""""""""". The '``llvm.thread.pointer``' intrinsic returns the value of the thread; pointer. Semantics:; """""""""""""""""""". The '``llvm.thread.pointer``' intrinsic returns a pointer to the TLS area; for the current thread. The exact semantics of this value are target; specific: it may point to the start of TLS area, to the end, or somewhere; in the middle. Depending on the target, this intrinsic may read a register,; call a helper function, read from an alternate memory space, or perform; other operations necessary to locate the TLS area. Not all targets support; this intrinsic. '``llvm.call.preallocated.setup``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare token @llvm.call.preallocated.setup(i32 %num_args). Overview:; """""""""""""""""". The '``llvm.call.preallocated.setup``' intrinsic returns a token which can; be used with a call's ``""preallocated""`` operand bundle to indicate that; certain arguments are allocated and initialized before the call. Semantics:; """""""""""""""""""". The '``llvm.call.preallocated.setup``' intrinsic returns a token which is; associated with at most one call. The token can be passed to; '``@llvm.call.preallocated.arg``' to get a pointer to get that; corresponding argument. The token must be the parameter to a; ``""preallocated""`` operand bundle for the corresponding call. Nested calls to '``llvm.call.preallocated.setup``' are allowed, but must; be properly nested. e.g. :: code-block:: llvm. %t1 = call token @llvm.call.preallocated.setup(i32 0); %t2 = call token @llvm.call.preallocated.setup(i32 0); call void foo() [""preallocated""(token %t2)]; call void foo() [""preallocated""(token %t1)]. is allowed, but not. :: code-block:: llvm. %t1 = call token @llvm.call.preallocated.setup(i32 0); %t2 = call token @llvm.call.preallocated.setup(i32 0); call void foo() [""preallocated""(token %t1)]; call void foo() [""preallocated""(token %",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:537782,allocate,allocated,537782,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmaximum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmaximum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmaximum.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maximum.*``'; intrinsic. That is, this intrinsic propagates NaNs and +0.0 is considered; greater than -0.0. If any element of the vector is a NaN, the result is NaN. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fminimum:. '``llvm.vector.reduce.fminimum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fminimum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fminimum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fminimum.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minimum.*``'; intrinsic. That is, this intrinsic propagates NaNs and -0.0 is considered less; than +0.0. If any element of the vector is a NaN, the result is NaN. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. '``llvm.vector.insert``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. ; Insert fixed type into scalable type; declare <vscale x 4 x float> @llvm.vector.insert.nxv4f32.v4f32(<vscale x 4 x float> %vec, <4 x float> %subvec, i64 <idx>); declare <vscale x 2 x double> @llvm.vector.insert.nxv2f64.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:661595,reduce,reduce,661595,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"_' identifier in item name, one can easily draw or superimpose; similar items from different files. Could be used in URL like:; `...&files=[file1.root,file2.root]&items=[file1.root/hpx, file2.root/_same_]`; `...&files=[file1.root,file2.root]&item=file1.root/hpx+file2.root/_same_`; Main limitation - file names should have similar length.; - When 'autozoom' specified in draw options, histogram zoomed into; non-empty content. Same command available via context menu.; - Item of 'Text' kind can be created. It is displayed as; lain text in the browser. If property 'mathjax' specified,; MathJax.js library will be loaded and used for rendering.; See tutorials/http/httpcontrol.C macro for example.; - When using foreignObject, provide workaround for absolute positioning; problem in Chrome/Safari, see <http://bit.ly/1wjqCQ9>; - Support usage of minimized versions of .js and .css files.; Minimized scripts used by default on web servers.; - Implement JSROOT.extend instead of jQuery.extend, reduce; usage of jquery.js in core JSROOT classes; - Implement main graphics without jquery at all,; such mode used in `nobrowser` mode.; - Provide optional latex drawing with MathJax SVG.; TMathText always drawn with MathJax,; other classes require `mathjax` option in URL; - Improve drawing of different text classes, correctly handle; their alignment and scaling, special handling for IE. ## TTree Libraries. ### TTree Behavior change. #### Merging. Added fast cloning support to TTree::MergeTrees and TTree::Merge(TCollection*,Option_t*). #### TTreeCache. The TTreeCache is now enabled by default. The default size of the TTreeCache; is the estimated size of a cluster size for the TTree. The TTreeCache; prefilling is also enabled by default; when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:11989,reduce,reduce,11989,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['reduce'],['reduce']
Energy Efficiency,_3.bench.cpp; libcxx/include/__algorithm/adjacent_find.h; libcxx/include/__algorithm/all_of.h; libcxx/include/__algorithm/any_of.h; libcxx/include/__algorithm/count.h; libcxx/include/__algorithm/count_if.h; libcxx/include/__algorithm/find.h; libcxx/include/__algorithm/find_first_of.h; libcxx/include/__algorithm/find_if.h; libcxx/include/__algorithm/find_if_not.h; libcxx/include/__algorithm/for_each.h; libcxx/include/__algorithm/for_each_n.h; libcxx/include/__algorithm/iter_swap.h; libcxx/include/__algorithm/mismatch.h; libcxx/include/__algorithm/none_of.h; libcxx/include/__algorithm/swap_ranges.h; libcxx/include/__compare/is_eq.h; libcxx/include/__filesystem/file_time_type.h; libcxx/include/__filesystem/file_type.h; libcxx/include/__filesystem/space_info.h; libcxx/include/__format/formatter_floating_point.h; libcxx/include/__format/formatter_pointer.h; libcxx/include/__memory/voidify.h; libcxx/include/__numeric/exclusive_scan.h; libcxx/include/__numeric/inclusive_scan.h; libcxx/include/__numeric/reduce.h; libcxx/include/__numeric/transform_reduce.h; libcxx/include/__random/default_random_engine.h; libcxx/include/__random/knuth_b.h; libcxx/include/__ranges/dangling.h; libcxx/include/__ranges/enable_borrowed_range.h; libcxx/include/__support/ibm/gettod_zos.h; libcxx/include/__support/ibm/nanosleep.h; libcxx/include/__support/openbsd/xlocale.h; libcxx/include/__support/solaris/floatingpoint.h; libcxx/include/__support/solaris/wchar.h; libcxx/include/__utility/auto_cast.h; libcxx/include/__utility/declval.h; libcxx/include/__utility/forward.h; libcxx/include/__utility/move.h; libcxx/include/__utility/swap.h; libcxx/src/chrono_system_time_init.h; libcxx/src/format.cpp; libcxx/src/ios.instantiations.cpp; libcxx/src/iostream_init.h; libcxx/src/legacy_pointer_safety.cpp; libcxx/src/utility.cpp; libcxx/src/experimental/memory_resource_init_helper.h; libcxx/src/include/to_chars_floating_point.h; libcxx/src/include/ryu/common.h; libcxx/src/include/ryu/d2fixed.h; libcxx/src/incl,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:160840,reduce,reduce,160840,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"_; * `The XMOS XS2 Architecture (ISA) <https://www.xmos.ai/download/xCORE-200:-The-XMOS-XS2-Architecture-%28ISA%29%281.1%29.pdf>`_; * `Tools Development Guide (includes ABI) <https://www.xmos.ai/download/Tools-Development-Guide%282.1%29.pdf>`_. Hexagon; -------. * `Hexagon Programmer's Reference Manuals and Hexagon ABI Specification (registration required, free sign-up) <https://developer.qualcomm.com/software/hexagon-dsp-sdk/tools>`_. Other relevant lists; --------------------. * `GCC reading list <http://gcc.gnu.org/readings.html>`_. ABI; ===. * `System V Application Binary Interface <http://www.sco.com/developers/gabi/latest/contents.html>`_; * `Itanium C++ ABI <http://itanium-cxx-abi.github.io/cxx-abi/>`_ (This is used for all non-Windows targets.). Linux; -----. * `Linux extensions to gabi <https://github.com/hjl-tools/linux-abi/wiki/Linux-Extensions-to-gABI>`_; * `64-Bit ELF V2 ABI Specification: Power Architecture <https://openpowerfoundation.org/?resource_lib=64-bit-elf-v2-abi-specification-power-architecture>`_. * `OpenPOWER ELFv2 Errata: ELFv2 ABI Version 1.4 <https://openpowerfoundation.org/?resource_lib=openpower-elfv2-errata-elfv2-abi-version-1-4>`_; * `PowerPC 64-bit ELF ABI Supplement <http://www.linuxbase.org/spec/ELF/ppc64/>`_; * `Procedure Call Standard for the AArch64 Architecture <http://infocenter.arm.com/help/topic/com.arm.doc.ihi0055a/IHI0055A_aapcs64.pdf>`_; * `Procedure Call Standard for the ARM Architecture <https://developer.arm.com/docs/ihi0042/latest>`_; * `ELF for the ARM Architecture <http://infocenter.arm.com/help/topic/com.arm.doc.ihi0044e/IHI0044E_aaelf.pdf>`_; * `ELF for the ARM 64-bit Architecture (AArch64) <http://infocenter.arm.com/help/topic/com.arm.doc.ihi0056a/IHI0056A_aaelf64.pdf>`_; * `System z ELF ABI Supplement <http://legacy.redhat.com/pub/redhat/linux/7.1/es/os/s390x/doc/lzsabi0.pdf>`_. macOS; -----. * `Mach-O Runtime Architecture <http://developer.apple.com/documentation/Darwin/RuntimeArchitecture-date.html>`_; * `Note",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:7502,power,power-architecture,7502,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,1,['power'],['power-architecture']
Energy Efficiency,"_Legalizer:. SelectionDAG Legalize Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the operations; that are natively supported by the target. Targets often have weird constraints, such as not supporting every operation on; every supported datatype (e.g. X86 does not support byte conditional moves and; PowerPC does not support sign-extending loads from a 16-bit memory location).; Legalize takes care of this by open-coding another sequence of operations to; emulate the operation (""expansion""), by promoting one type to a larger type that; supports the operation (""promotion""), or by using a target-specific hook to; implement the legalization (""custom""). A target implementation tells the legalizer which operations are not supported; (and which of the above three actions to take) by calling the; ``setOperationAction`` method in its ``TargetLowering`` constructor. If a target has legal vector types, it is expected to produce efficient machine; code for common forms of the shufflevector IR instruction using those types.; This may require custom legalization for SelectionDAG vector operations that; are created from the shufflevector IR. The shufflevector forms that should be; handled include:. * Vector select --- Each element of the vector is chosen from either of the; corresponding elements of the 2 input vectors. This operation may also be; known as a ""blend"" or ""bitwise select"" in target assembly. This type of shuffle; maps directly to the ``shuffle_vector`` SelectionDAG node. * Insert subvector --- A vector is placed into a longer vector type starting; at index 0. This type of shuffle maps directly to the ``insert_subvector``; SelectionDAG node with the ``index`` operand set to 0. * Extract subvector --- A vector is pulled from a longer vector type starting; at index 0. This type of shuffle maps directly to the ``extract_subvector``; SelectionDAG node with the ``index`` operand set to 0. * Splat --- All elements of the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:43307,efficient,efficient,43307,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['efficient'],['efficient']
Energy Efficiency,"_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umin.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umin.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_fmax:. '``llvm.vp.reduce.fmax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmax.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmax.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmax``' intrinsic performs the floating-point ``MAX``; reduction (:ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>`) of the; vector operand ``val`` on each enabled lane, taking the ma",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:771290,reduce,reduce,771290,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"_SELF __attribute__((ns_consumes_self)); #else; #define NS_CONSUMES_SELF; #endif; #endif. @interface MyClass : NSObject; - initWith:(MyClass *)x;; - nonstandardInitWith:(MyClass *)x NS_CONSUMES_SELF NS_RETURNS_RETAINED;; @end. In this example, -nonstandardInitWith: has the same ownership; semantics as the init method -initWith:. The static analyzer will; observe that the method consumes the receiver, and then returns an object with; a +1 retain count.; The Foundation framework defines a macro NS_REPLACES_RECEIVER; which is functionally equivalent to the combination of NS_CONSUMES_SELF; and NS_RETURNS_RETAINED shown above.; Libkern Memory Management Annotations; Libkern; requires developers to inherit all heap allocated objects from OSObject; and to perform manual reference counting.; The reference counting model is very similar to MRR (manual retain-release) mode in; Objective-C; or to CoreFoundation reference counting.; Freshly-allocated objects start with a reference count of 1,; and calls to retain increment it,; while calls to release decrement it.; The object is deallocated whenever its reference count reaches zero.; Manually incrementing and decrementing reference counts is error-prone:; over-retains lead to leaks, and over-releases lead to uses-after-free.; The analyzer can help the programmer to check for unbalanced; retain/release calls.; The reference count checking is based on the principle of; locality: it should be possible to establish correctness; (lack of leaks/uses after free) by looking at each function body,; and the declarations (not the definitions) of all the functions it interacts; with.; In order to support such reasoning, it should be possible to summarize; the behavior of each function, with respect to reference count; of its returned values and attributes.; By default, the following summaries are assumed:. All functions starting with get or Get,; unless they are returning subclasses of OSIterator,; are assumed to be returning at +0.; That i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html:13959,allocate,allocated,13959,interpreter/llvm-project/clang/www/analyzer/annotations.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html,1,['allocate'],['allocated']
Energy Efficiency,"__counted_by; count--; // may violate the invariant of __counted_by if count was 0.; count = g; // may violate the invariant of __counted_by; // depending on the value of `g`.; }. The requirement to annotate all pointers with explicit bounds information could; present a significant adoption burden. To tackle this issue, the model; incorporates the concept of a ""wide pointer"" (a.k.a. fat pointer) – a larger; pointer that carries bounds information alongside the pointer value. Utilizing; wide pointers can potentially reduce the adoption burden, as it contains bounds; information internally and eliminates the need for explicit bounds annotations.; However, wide pointers differ from standard C pointers in their data layout,; which may result in incompatibilities with the application binary interface; (ABI). Breaking the ABI complicates interoperability with external code that has; not adopted the same programming model. ``-fbounds-safety`` harmonizes the wide pointer and the bounds annotation; approaches to reduce the adoption burden while maintaining the ABI. In this; model, local variables of pointer type are implicitly treated as wide pointers,; allowing them to carry bounds information without requiring explicit bounds; annotations. Please note that this approach doesn't apply to function parameters; which are considered ABI-visible. As local variables are typically hidden from; the ABI, this approach has a marginal impact on it. In addition,; ``-fbounds-safety`` employs compile-time restrictions to prevent implicit wide; pointers from silently breaking the ABI (see `ABI implications of default bounds; annotations`_). Pointers associated with any other variables, including function; parameters, are treated as single object pointers (i.e., ``__single``), ensuring; that they always have the tightest bounds by default and offering a strong; bounds safety guarantee. By implementing default bounds annotations based on ABI visibility, a; considerable portion of C code can ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:5839,reduce,reduce,5839,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['reduce'],['reduce']
Energy Efficiency,"_middleend-crash:. Middle-end optimization bugs; ----------------------------. If you find that a bug crashes in the optimizer, compile your test-case to a; ``.bc`` file by passing ""``-emit-llvm -O1 -Xclang -disable-llvm-passes -c -o; foo.bc``"". The ``-O1`` is important because ``-O0`` adds the ``optnone``; function attribute to all functions and many passes don't run on ``optnone``; functions. Then run:. .. code-block:: bash. opt -O3 foo.bc -disable-output. If this doesn't crash, please follow the instructions for a :ref:`front-end; bug <frontend-crash>`. If this does crash, then you should be able to debug this with the following; :doc:`bugpoint <Bugpoint>` command:. .. code-block:: bash. bugpoint foo.bc -O3. Run this, then file a bug with the instructions and reduced .bc; files that bugpoint emits. If bugpoint doesn't reproduce the crash, ``llvm-reduce`` is an alternative; way to reduce LLVM IR. Create a script that repros the crash and run:. .. code-block:: bash. llvm-reduce --test=path/to/script foo.bc. which should produce reduced IR that reproduces the crash. Be warned the; ``llvm-reduce`` is still fairly immature and may crash. If none of the above work, you can get the IR before a crash by running the; ``opt`` command with the ``--print-before-all --print-module-scope`` flags to; dump the IR before every pass. Be warned that this is very verbose. .. _backend-crash:. Backend code generator bugs; ---------------------------. If you find a bug that crashes clang in the code generator, compile your; source file to a .bc file by passing ""``-emit-llvm -c -o foo.bc``"" to; clang (in addition to the options you already pass). Once your have; foo.bc, one of the following commands should fail:. #. ``llc foo.bc``; #. ``llc foo.bc -relocation-model=pic``; #. ``llc foo.bc -relocation-model=static``. If none of these crash, please follow the instructions for a :ref:`front-end; bug<frontend-crash>`. If one of these do crash, you should be able to reduce; this with one of th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:4469,reduce,reduce,4469,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduce']
Energy Efficiency,"_reduce_add>`) of the vector operand; ``val`` on each enabled lane, adding it to the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``0`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is equal; to ``start_value``. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.add.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> zeroinitializer; %reduction = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %masked.a); %also.r = add i32 %reduction, %start. .. _int_vp_reduce_fadd:. '``llvm.vp.reduce.fadd.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fadd.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fadd.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``ADD`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fadd``' intrinsic performs the floating-point ``ADD``; reduction (:r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:750411,reduce,reduce,750411,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"_start_main ??:0; ... Note that on macOS you may need to run ``dsymutil`` on your binary to have the; file\:line info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; -----------------------------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6113,reduce,reduce,6113,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,1,['reduce'],['reduce']
Energy Efficiency,"_value; for i = 0 to length(input_vector); result = result + input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, negative zero (``-0.0``) can be used, as it is; the neutral value of floating point addition. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fadd.v4f32(float -0.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_mul:. '``llvm.vector.reduce.mul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.mul.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.mul.*``' intrinsics do an integer ``MUL``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmul:. '``llvm.vector.reduce.fmul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fmul.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmul.*``' intrinsics do a floating-point; ``MUL`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. Otherwise; the reduction will be *sequential*, thus implying that the oper",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:652945,reduce,reduce,652945,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"` and containing both ``+0.0`` and; ``-0.0`` elements, the sign of the result is unspecified. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmax.v4f32(float %float, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float QNAN, float QNAN, float QNAN, float QNAN>; %reduction = call float @llvm.vector.reduce.fmax.v4f32(<4 x float> %masked.a); %also.r = call float @llvm.maxnum.f32(float %reduction, float %start). .. _int_vp_reduce_fmin:. '``llvm.vp.reduce.fmin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmin.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmin.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmin``' intrinsic performs the floating-point ``MIN``; reduction (:ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>`) of the; vector operand ``val`` on each enabled lane, taking the mi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:774164,reduce,reduce,774164,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"` using; the ``str`` member function. See ``llvm/ADT/StringRef.h`` (`doxygen; <https://llvm.org/doxygen/StringRef_8h_source.html>`__) for more; information. You should rarely use the ``StringRef`` class directly, because it contains; pointers to external memory it is not generally safe to store an instance of the; class (unless you know that the external storage will not be freed).; ``StringRef`` is small and pervasive enough in LLVM that it should always be; passed by value. The ``Twine`` class; ^^^^^^^^^^^^^^^^^^^. The ``Twine`` (`doxygen <https://llvm.org/doxygen/classllvm_1_1Twine.html>`__); class is an efficient way for APIs to accept concatenated strings. For example,; a common LLVM paradigm is to name one instruction based on the name of another; instruction with a suffix, for example:. .. code-block:: c++. New = CmpInst::Create(..., SO->getName() + "".cmp"");. The ``Twine`` class is effectively a lightweight `rope; <http://en.wikipedia.org/wiki/Rope_(computer_science)>`_ which points to; temporary (stack allocated) objects. Twines can be implicitly constructed as; the result of the plus operator applied to strings (i.e., a C strings, an; ``std::string``, or a ``StringRef``). The twine delays the actual concatenation; of strings until it is actually required, at which point it can be efficiently; rendered directly into a character array. This avoids unnecessary heap; allocation involved in constructing the temporary results of string; concatenation. See ``llvm/ADT/Twine.h`` (`doxygen; <https://llvm.org/doxygen/Twine_8h_source.html>`__) and :ref:`here <dss_twine>`; for more information. As with a ``StringRef``, ``Twine`` objects point to external memory and should; almost never be stored or mentioned directly. They are intended solely for use; when defining a function which should be able to efficiently accept concatenated; strings. .. _formatting_strings:. Formatting strings (the ``formatv`` function); ---------------------------------------------; While LLVM do",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:10268,allocate,allocated,10268,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocated']
Energy Efficiency,"`' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smin.*``' intrinsics do a signed integer; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umax:. '``llvm.vector.reduce.umax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umax.*``' intrinsics do an unsigned; integer ``MAX`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umin:. '``llvm.vector.reduce.umin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umin.*``' intrinsics do an unsigned; integer ``MIN`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmax:. '``llvm.vector.reduce.fmax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmax.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmax.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmax.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:657978,reduce,reduce,657978,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"`' intrinsic performs the integer ``AND`` reduction; (:ref:`llvm.vector.reduce.and <int_vector_reduce_and>`) of the vector operand; ``val`` on each enabled lane, performing an '``and``' of that with with the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.and.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %masked.a); %also.r = and i32 %reduction, %start. .. _int_vp_reduce_or:. '``llvm.vp.reduce.or.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.or.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.or.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``OR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:758717,reduce,reduce,758717,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"`' intrinsics do a signed integer; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umax:. '``llvm.vector.reduce.umax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umax.*``' intrinsics do an unsigned; integer ``MAX`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umin:. '``llvm.vector.reduce.umin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umin.*``' intrinsics do an unsigned; integer ``MIN`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmax:. '``llvm.vector.reduce.fmax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmax.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmax.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmax.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maxnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with maximum element magnitude 0.0 and; containing both +0.0 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:658170,reduce,reduce,658170,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,`5`; - `4`; - `1`; - :part:`80%`; * - mlir/lib/Tools/mlir-lsp-server/lsp; - `6`; - `4`; - `2`; - :part:`66%`; * - mlir/lib/Tools/mlir-reduce; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/lib/Tools/PDLL/AST; - `6`; - `5`; - `1`; - :part:`83%`; * - mlir/lib/Tools/PDLL/CodeGen; - `2`; - `1`; - `1`; - :part:`50%`; * - mlir/lib/Tools/PDLL/ODS; - `3`; - `3`; - `0`; - :good:`100%`; * - mlir/lib/Tools/PDLL/Parser; - `3`; - `1`; - `2`; - :part:`33%`; * - mlir/lib/Transforms; - `13`; - `11`; - `2`; - :part:`84%`; * - mlir/lib/Transforms/Utils; - `6`; - `6`; - `0`; - :good:`100%`; * - mlir/lib/Translation; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-cpu-runner; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-linalg-ods-gen; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-lsp-server; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-opt; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-pdll; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-reduce; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-shlib; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-spirv-cpu-runner; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-tblgen; - `29`; - `28`; - `1`; - :part:`96%`; * - mlir/tools/mlir-translate; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/tools/mlir-vulkan-runner; - `4`; - `4`; - `0`; - :good:`100%`; * - mlir/unittests/Analysis/Presburger; - `8`; - `8`; - `0`; - :good:`100%`; * - mlir/unittests/Conversion/PDLToPDLInterp; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/unittests/Dialect; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/unittests/Dialect/Affine/Analysis; - `3`; - `3`; - `0`; - :good:`100%`; * - mlir/unittests/Dialect/Quant; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/unittests/Dialect/SparseTensor; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/unittests/Dialect/SPIRV; - `2`; - `2`; - `0`; - :good:`100%`; * - mlir/unittests/Dialect/Utils; - `1`; - `1`; - `0`; - :good:`100%`; * - mlir/unittest,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst:120007,reduce,reduce,120007,interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,1,['reduce'],['reduce']
Energy Efficiency,"`; are used, or for the reasons defined in ``SIFrameLowering``.; 2. Runtime stack alignment is supported. SGPR34 is used as a base pointer (BP); to access the incoming stack arguments in the function. The BP is needed; only when the function requires the runtime stack alignment. 3. Allocating SGPR arguments on the stack are not supported. 4. No CFI is currently generated. See; :ref:`amdgpu-dwarf-call-frame-information`. .. note::. CFI will be generated that defines the CFA as the unswizzled address; relative to the wave scratch base in the unswizzled private address space; of the lowest address stack allocated local variable. ``DW_AT_frame_base`` will be defined as the swizzled address in the; swizzled private address space by dividing the CFA by the wavefront size; (since CFA is always at least dword aligned which matches the scratch; swizzle element size). If no dynamic stack alignment was performed, the stack allocated arguments; are accessed as negative offsets relative to ``DW_AT_frame_base``, and the; local variables and register spill slots are accessed as positive offsets; relative to ``DW_AT_frame_base``. 5. Function argument passing is implemented by copying the input physical; registers to virtual registers on entry. The register allocator can spill if; necessary. These are copied back to physical registers at call sites. The; net effect is that each function call can have these values in entirely; distinct locations. The IPRA can help avoid shuffling argument registers.; 6. Call sites are implemented by setting up the arguments at positive offsets; from SP. Then SP is incremented to account for the known frame size before; the call and decremented after the call. .. note::. The CFI will reflect the changed calculation needed to compute the CFA; from SP. 7. 4 byte spill slots are used in the stack frame. One slot is allocated for an; emergency spill slot. Buffer instructions are used for stack accesses and; not the ``flat_scratch`` instruction. .. TODO::. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:398991,allocate,allocated,398991,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"`TMath`** at; [<http://root.cern.ch/root/htmldoc/TMath.html>](https://root.cern/doc/master/namespaceTMath.html). ### Numerical Constants. `TMath` offers a wide range of constants in the form of inline functions. Notice that they are not defined as C/C++ preprocessor macros. This set of functions includes one or more definitions for the following constants:. * Pi.; * Base of natural logarithm.; * Velocity of light.; * Gravitational constant (G).; * Standard acceleration of gravity (g).; * Standard acceleration of Gravity.; * Plank's contant.; * Boltzmann's and Steffan-Boltzmann's constants.; * Avogadro's number.; * Universal gas constant.; * Molecular weight of dry air.; * Dry air gas constant.; * Euler-Mascheroni Constant.; * Elementary charge. ### Elementary Functions. A set of miscellaneous elementary mathematical functions is provided along with a set of basic trigonometrical functions. Some of this functions refer to basic mathematical functions like the square root, the power to a number of the calculus of a logarithm, while others are used for number treatment, like rounding. Although there are some functions that are not in the standard C math library (like `Factorial`), most of the functionality offered here is just a wrapper of the first ones. Nevertheless, some of the them also offer some security checks or a better precision, like the trigonometrical functions `ASin(x)`, `ACos(x)` or `ATan(x)`. ```{.cpp}; // Generate a vector with 10 random numbers; vector<double> v(10);; std::generate(v.begin(), v.end(), rand);. // Find the minimum value of the vector (iterator version); vector<double>::iterator it;; it = TMath::LocMin(v.begin(), v.end());; std::cout << *it << std::endl;. // The same with the old-style version; int i;; i = TMath::LocMin(10, &v[0]);; std::cout << v[i] << std::endl;; ```. Another example of these functions can be found in $ROOTSYS/tutorials/permute.C. ### Statistic Functions Operating on Arrays. This set of functions processes arrays to ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:7476,power,power,7476,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['power'],['power']
Energy Efficiency,"`` call may still; be an inlining candidate, provided that the call is not; duplicated by inlining. That implies that the function has; internal linkage and only has one call site, so the original; call is dead after inlining.; ``nofree``; This function attribute indicates that the function does not, directly or; transitively, call a memory-deallocation function (``free``, for example); on a memory allocation which existed before the call. As a result, uncaptured pointers that are known to be dereferenceable; prior to a call to a function with the ``nofree`` attribute are still; known to be dereferenceable after the call. The capturing condition is; necessary in environments where the function might communicate the; pointer to another thread which then deallocates the memory. Alternatively,; ``nosync`` would ensure such communication cannot happen and even captured; pointers cannot be freed by the function. A ``nofree`` function is explicitly allowed to free memory which it; allocated or (if not ``nosync``) arrange for another thread to free; memory on it's behalf. As a result, perhaps surprisingly, a ``nofree``; function can return a pointer to a previously deallocated memory object.; ``noimplicitfloat``; Disallows implicit floating-point code. This inhibits optimizations that; use floating-point code and floating-point registers for operations that are; not nominally floating-point. LLVM instructions that perform floating-point; operations or require access to floating-point registers may still cause; floating-point code to be generated. Also inhibits optimizations that create SIMD/vector code and registers from; scalar code such as vectorization or memcpy/memset optimization. This; includes integer vectors. Vector instructions present in IR may still cause; vector code to be generated.; ``noinline``; This attribute indicates that the inliner should never inline this; function in any situation. This attribute may not be used together; with the ``alwaysinline`` attr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:89873,allocate,allocated,89873,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"``-DLLVM_USE_LINKER=gold``. **LLVM_USE_OPROFILE**:BOOL; Enable building OProfile JIT support. Defaults to OFF. **LLVM_USE_PERF**:BOOL; Enable building support for Perf (linux profiling tool) JIT support. Defaults to OFF. **LLVM_USE_RELATIVE_PATHS_IN_FILES**:BOOL; Rewrite absolute source paths in sources and debug info to relative ones. The; source prefix can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_RELATIVE_PATHS_IN_DEBUG_INFO**:BOOL; Rewrite absolute source paths in debug info to relative ones. The source prefix; can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_SANITIZER**:STRING; Define the sanitizer used to build LLVM binaries and tests. Possible values; are ``Address``, ``Memory``, ``MemoryWithOrigins``, ``Undefined``, ``Thread``,; ``DataFlow``, and ``Address;Undefined``. Defaults to empty string. **LLVM_USE_SPLIT_DWARF**:BOOL; If enabled CMake will pass ``-gsplit-dwarf`` to the compiler. This option; reduces link-time memory usage by reducing the amount of debug information that; the linker needs to resolve. It is recommended for platforms using the ELF object; format, like Linux systems when linker memory usage is too high. **SPHINX_EXECUTABLE**:STRING; The path to the ``sphinx-build`` executable detected by CMake.; For installation instructions, see; https://www.sphinx-doc.org/en/master/usage/installation.html. **SPHINX_OUTPUT_HTML**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) then the targets for; building the documentation as html are added (but not built by default unless; ``LLVM_BUILD_DOCS`` is enabled). There is a target for each project in the; source tree that uses sphinx (e.g. ``docs-llvm-html``, ``docs-clang-html``; and ``docs-lld-html``). Defaults to ON. **SPHINX_OUTPUT_MAN**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) the targets for building; the man pages are added (but not built by default unless ``LLVM_BUILD_DOCS``; is enabled). Currently the only target added is ``docs-llvm-man``. Defa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:36603,reduce,reduces,36603,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['reduce'],['reduces']
Energy Efficiency,"``clang-check``; ---------------. :doc:`ClangCheck` combines the LibTooling framework for running a; Clang tool with the basic Clang diagnostics by syntax checking specific files; in a fast, command line interface. It can also accept flags to re-display the; diagnostics in different formats with different flags, suitable for use driving; an IDE or editor. Furthermore, it can be used in fixit-mode to directly apply; fixit-hints offered by clang. See :doc:`HowToSetupToolingForLLVM` for; instructions on how to setup and used `clang-check`. ``clang-format``; ----------------. Clang-format is both a :doc:`library <LibFormat>` and a :doc:`stand-alone tool; <ClangFormat>` with the goal of automatically reformatting C++ sources files; according to configurable style guides. To do so, clang-format uses Clang's; ``Lexer`` to transform an input file into a token stream and then changes all; the whitespace around those tokens. The goal is for clang-format to serve both; as a user tool (ideally with powerful IDE integrations) and as part of other; refactoring tools, e.g. to do a reformatting of all the lines changed during a; renaming. Extra Clang Tools; =================. As various categories of Clang Tools are added to the extra repository,; they'll be tracked here. The focus of this documentation is on the scope; and features of the tools for other tool developers; each tool should; provide its own user-focused documentation. ``clang-tidy``; --------------. `clang-tidy <https://clang.llvm.org/extra/clang-tidy/>`_ is a clang-based C++; linter tool. It provides an extensible framework for building compiler-based; static analyses detecting and fixing bug-prone patterns, performance,; portability and maintainability issues. Ideas for new Tools; ===================. * C++ cast conversion tool. Will convert C-style casts (``(type) value``) to; appropriate C++ cast (``static_cast``, ``const_cast`` or; ``reinterpret_cast``).; * Non-member ``begin()`` and ``end()`` conversion tool. W",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangTools.rst:3673,power,powerful,3673,interpreter/llvm-project/clang/docs/ClangTools.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangTools.rst,1,['power'],['powerful']
Energy Efficiency,"`llvm.lifetime.start <int_lifestart>` and; :ref:`llvm.lifetime.end <int_lifeend>` intrinsic function calls. .. _pointeraliasing:. Pointer Aliasing Rules; ----------------------. Any memory access must be done through a pointer value associated with; an address range of the memory access, otherwise the behavior is; undefined. Pointer values are associated with address ranges according; to the following rules:. - A pointer value is associated with the addresses associated with any; value it is *based* on.; - An address of a global variable is associated with the address range; of the variable's storage.; - The result value of an allocation instruction is associated with the; address range of the allocated storage.; - A null pointer in the default address-space is associated with no; address.; - An :ref:`undef value <undefvalues>` in *any* address-space is; associated with no address.; - An integer constant other than zero or a pointer value returned from; a function not defined within LLVM may be associated with address; ranges allocated through mechanisms other than those provided by; LLVM. Such ranges shall not overlap with any ranges of addresses; allocated by mechanisms provided by LLVM. A pointer value is *based* on another pointer value according to the; following rules:. - A pointer value formed from a scalar ``getelementptr`` operation is *based* on; the pointer-typed operand of the ``getelementptr``.; - The pointer in lane *l* of the result of a vector ``getelementptr`` operation; is *based* on the pointer in lane *l* of the vector-of-pointers-typed operand; of the ``getelementptr``.; - The result value of a ``bitcast`` is *based* on the operand of the; ``bitcast``.; - A pointer value formed by an ``inttoptr`` is *based* on all pointer; values that contribute (directly or indirectly) to the computation of; the pointer's value.; - The ""*based* on"" relationship is transitive. Note that this definition of *""based""* is intentionally similar to the; definition of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:142247,allocate,allocated,142247,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"`operator *` has been implemented in a way that follows the; mathematical notation of a product of the two matrices which describe; the two consecutive rotations. Therefore, the second rotation should be; placed first:. ``` {.cpp}; r = r2 * r1;; ```. ### Rotation of TVector3. The **`TRotation`** class provides an `operator *` which allows; expressing a rotation of a **`TVector3`** analog to the mathematical; notation:. $$; \left|; \begin{array}{c}; x' \\; y' \\; z'; \end{array}; \right|; =; \left|; \begin{array}{ccc}; xx & xy & xz \\; yx & yy & yz \\; zx & zy & zz; \end{array}; \right|; \times; \left|; \begin{array}{c}; x \\; y \\; z; \end{array}; \right|; $$. ``` {.cpp}; TRotation r;; TVector3 v(1,1,1);; v = r * v;; ```. You can also use the `Transform()` method or the `operator *=` of the; **`TVector3`** class:. ``` {.cpp}; TVector3 v;; TRotation r;; v.Transform(r);; ```. ## TLorentzVector. **`TLorentzVector`** is a general four-vector class, which can be used; either for the description of position and time (`x`, `y`, `z`, `t`) or; momentum and energy (`px`, `py`, `pz`, `E`). ### Declaration. **`TLorentzVector`** has been implemented as a set a **`TVector3`** and; a `Double_t` variable. By default, all components are initialized by; zero. ``` {.cpp}; TLorentzVector v1; // initialized by (0.,0.,0.,0.); TLorentzVector v2(1.,1.,1.,1.);; TLorentzVector v3(v1);; TLorentzVector v4(TVector3(1.,2.,3.),4.);; ```. For backward compatibility there are two constructors from a `Double_t`; and `Float_t` array. ### Access to Components. There are two sets of access functions to the components of a; **`TLorentzVector`**: `X()`, `Y()`, `Z()`, `T()` and `Px()`, `Py()`,; `Pz()` and `E()`. Both sets return the same values but the first set is; more relevant for use where **`TLorentzVector`** describes a combination; of position and time and the second set is more relevant where; **`TLorentzVector`** describes momentum and energy:. ``` {.cpp}; Double_t xx =v.X();; ...; Double_t tt = ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md:9540,energy,energy,9540,documentation/users-guide/PhysicsVectors.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md,1,['energy'],['energy']
Energy Efficiency,"`ungetc``, ``fflush``,; ``getdelim``, ``getline`` and no not recognize alternative; ``fopen`` and ``tmpfile`` implementations.; (`#78693 <https://github.com/llvm/llvm-project/pull/78693>`_,; `#76776 <https://github.com/llvm/llvm-project/pull/76776>`_,; `#74296 <https://github.com/llvm/llvm-project/pull/74296>`_,; `#73335 <https://github.com/llvm/llvm-project/pull/73335>`_,; `#72627 <https://github.com/llvm/llvm-project/pull/72627>`_,; `#71518 <https://github.com/llvm/llvm-project/pull/71518>`_,; `#72016 <https://github.com/llvm/llvm-project/pull/72016>`_,; `#70540 <https://github.com/llvm/llvm-project/pull/70540>`_,; `#73638 <https://github.com/llvm/llvm-project/pull/73638>`_,; `#77331 <https://github.com/llvm/llvm-project/pull/77331>`_). - The ``alpha.security.taint.TaintPropagation`` checker no longer propagates; taint on ``strlen`` and ``strnlen`` calls, unless these are marked; explicitly propagators in the user-provided taint configuration file.; This removal empirically reduces the number of false positive reports.; Read the PR for the details.; (`#66086 <https://github.com/llvm/llvm-project/pull/66086>`_). - Other taint-related improvements.; (`#66358 <https://github.com/llvm/llvm-project/pull/66358>`_,; `#66074 <https://github.com/llvm/llvm-project/pull/66074>`_,; `#66358 <https://github.com/llvm/llvm-project/pull/66358>`_). - Checkers can query constraint bounds to improve diagnostic messages.; (`#74141 <https://github.com/llvm/llvm-project/pull/74141>`_). - Improved the generated initializers for modules. Now the calls to initialize; functions from imported module units can be omitted if the initialize; function is known to be empty.; (`#56794 <https://github.com/llvm/llvm-project/issues/56794>`_). - Clang now allow to export declarations within linkage-specification.; (`#71347 <https://github.com/llvm/llvm-project/issues/71347>`_). Moved checkers; ^^^^^^^^^^^^^^. - Move checker ``alpha.unix.Errno`` out of the ``alpha`` package; to ``unix.Errno``.; `Docume",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:75648,reduce,reduces,75648,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['reduce'],['reduces']
Energy Efficiency,"a concern. This flag is only compatible with :doc:`control flow integrity; <ControlFlowIntegrity>` schemes and :doc:`UndefinedBehaviorSanitizer`; checks other than ``vptr``. This flag is enabled by default for sanitizers in the ``cfi`` group. .. option:: -fsanitize-ignorelist=/path/to/ignorelist/file. Disable or modify sanitizer checks for objects (source files, functions,; variables, types) listed in the file. See; :doc:`SanitizerSpecialCaseList` for file format description. .. option:: -fno-sanitize-ignorelist. Don't use ignorelist file, if it was specified earlier in the command line. .. option:: -f[no-]sanitize-coverage=[type,features,...]. Enable simple code coverage in addition to certain sanitizers.; See :doc:`SanitizerCoverage` for more details. .. option:: -f[no-]sanitize-address-outline-instrumentation. Controls how address sanitizer code is generated. If enabled will always use; a function call instead of inlining the code. Turning this option on could; reduce the binary size, but might result in a worse run-time performance. See :doc: `AddressSanitizer` for more details. .. option:: -f[no-]sanitize-stats. Enable simple statistics gathering for the enabled sanitizers.; See :doc:`SanitizerStats` for more details. .. option:: -fsanitize-undefined-trap-on-error. Deprecated alias for ``-fsanitize-trap=undefined``. .. option:: -fsanitize-cfi-cross-dso. Enable cross-DSO control flow integrity checks. This flag modifies; the behavior of sanitizers in the ``cfi`` group to allow checking; of cross-DSO virtual and indirect calls. .. option:: -fsanitize-cfi-icall-generalize-pointers. Generalize pointers in return and argument types in function type signatures; checked by Control Flow Integrity indirect call checking. See; :doc:`ControlFlowIntegrity` for more details. .. option:: -fsanitize-cfi-icall-experimental-normalize-integers. Normalize integers in return and argument types in function type signatures; checked by Control Flow Integrity indirect call checking. S",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:79094,reduce,reduce,79094,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['reduce'],['reduce']
Energy Efficiency,"a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmul``' intrinsic performs the floating-point ``MUL``; reduction (:ref:`llvm.vector.reduce.fmul <int_vector_reduce_fmul>`) of the; vector operand ``val`` on each enabled lane, multiplying it by the scalar; `start_value``. Disabled lanes are treated as containing the neutral value; ``1.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to the starting value. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fmul; <int_vector_reduce_fmul>`) for more detail on the semantics. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmul.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float 1.0, float 1.0, float 1.0, float 1.0>; %also.r = call float @llvm.vector.reduce.fmul.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_and:. '``llvm.vp.reduce.and.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.and.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.and.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``AND`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:756233,reduce,reduce,756233,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"a-code-object-kernel-code-properties-metadata-map-v2-table. ============================ ============== ========= =====================; String Key Value Type Required? Description; ============================ ============== ========= =====================; ""KernargSegmentSize"" integer Required The size in bytes of; the kernarg segment; that holds the values; of the arguments to; the kernel.; ""GroupSegmentFixedSize"" integer Required The amount of group; segment memory; required by a; work-group in; bytes. This does not; include any; dynamically allocated; group segment memory; that may be added; when the kernel is; dispatched.; ""PrivateSegmentFixedSize"" integer Required The amount of fixed; private address space; memory required for a; work-item in; bytes. If the kernel; uses a dynamic call; stack then additional; space must be added; to this value for the; call stack.; ""KernargSegmentAlign"" integer Required The maximum byte; alignment of; arguments in the; kernarg segment. Must; be a power of 2.; ""WavefrontSize"" integer Required Wavefront size. Must; be a power of 2.; ""NumSGPRs"" integer Required Number of scalar; registers used by a; wavefront for; GFX6-GFX11. This; includes the special; SGPRs for VCC, Flat; Scratch (GFX7-GFX10); and XNACK (for; GFX8-GFX10). It does; not include the 16; SGPR added if a trap; handler is; enabled. It is not; rounded up to the; allocation; granularity.; ""NumVGPRs"" integer Required Number of vector; registers used by; each work-item for; GFX6-GFX11; ""MaxFlatWorkGroupSize"" integer Required Maximum flat; work-group size; supported by the; kernel in work-items.; Must be >=1 and; consistent with; ReqdWorkGroupSize if; not 0, 0, 0.; ""NumSpilledSGPRs"" integer Number of stores from; a scalar register to; a register allocator; created spill; location.; ""NumSpilledVGPRs"" integer Number of stores from; a vector register to; a register allocator; created spill; location.; ============================ ============== ========= =====================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:128439,power,power,128439,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['power'],['power']
Energy Efficiency,"a; declaration context. The source-centric view accurately represents the; program source code as written, including multiple declarations of entities; where present (see the section :ref:`Redeclarations and Overloads; <Redeclarations>`), while the semantics-centric view represents the program; semantics. The two views are kept synchronized by semantic analysis while; the ASTs are being constructed. Storage of declarations within that context. Every declaration context can contain some number of declarations. For; example, a C++ class (represented by ``RecordDecl``) contains various member; functions, fields, nested types, and so on. All of these declarations will; be stored within the ``DeclContext``, and one can iterate over the; declarations via [``DeclContext::decls_begin()``,; ``DeclContext::decls_end()``). This mechanism provides the source-centric; view of declarations in the context. Lookup of declarations within that context. The ``DeclContext`` structure provides efficient name lookup for names within; that declaration context. For example, if ``N`` is a namespace we can look; for the name ``N::f`` using ``DeclContext::lookup``. The lookup itself is; based on a lazily-constructed array (for declaration contexts with a small; number of declarations) or hash table (for declaration contexts with more; declarations). The lookup operation provides the semantics-centric view of; the declarations in the context. Ownership of declarations. The ``DeclContext`` owns all of the declarations that were declared within; its declaration context, and is responsible for the management of their; memory as well as their (de-)serialization. All declarations are stored within a declaration context, and one can query; information about the context in which each declaration lives. One can; retrieve the ``DeclContext`` that contains a particular ``Decl`` using; ``Decl::getDeclContext``. However, see the section; :ref:`LexicalAndSemanticContexts` for more information about how to i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:74670,efficient,efficient,74670,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"a; system somewhere in between these two extremes: Dynamic application ; behavior and social constraints. From a technical perspective, pure static compilation cannot ever give ; optimal performance in all cases, because applications have varying dynamic; behavior that the static compiler cannot take into consideration. Even ; compilers that support profile guided optimization generate poor code in ; the real world, because using such optimization tunes that application ; to one particular usage pattern, whereas real programs (as opposed to ; benchmarks) often have several different usage patterns. On a social level, static compilation is a very shortsighted solution to ; the performance problem. Instruction set architectures (ISAs) continuously ; evolve, and each implementation of an ISA (a processor) must choose a set ; of tradeoffs that make sense in the market context that it is designed for. ; With every new processor introduced, the vendor faces two fundamental ; problems: First, there is a lag time between when a processor is introduced ; to when compilers generate quality code for the architecture. Secondly, ; even when compilers catch up to the new architecture there is often a large ; body of legacy code that was compiled for previous generations and will ; not or can not be upgraded. Thus a large percentage of code running on a ; processor may be compiled quite sub-optimally for the current ; characteristics of the dynamic execution environment. For these reasons, LLVM has been designed from the beginning as a long-term ; solution to these problems. Its design allows the large body of platform ; independent, static, program optimizations currently in compilers to be ; reused unchanged in their current form. It also provides important static ; type information to enable powerful dynamic and link time optimizations ; to be performed quickly and efficiently. This combination enables an ; increase in effective system performance for real world environments.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-04-16-DynamicCompilation.txt:2851,power,powerful,2851,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-04-16-DynamicCompilation.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-04-16-DynamicCompilation.txt,2,"['efficient', 'power']","['efficiently', 'powerful']"
Energy Efficiency,"ableGen ``Operand`` class, which represent branch target; operands:. .. code-block:: text. def brtarget : Operand<OtherVT>;; def brtarget8 : Operand<OtherVT>;. This results in:. .. code-block:: c++. namespace X86 {; namespace OpTypes {; enum OperandType {; ...; brtarget,; brtarget8,; ...; i32imm,; i64imm,; ...; OPERAND_TYPE_LIST_END; } // End namespace OpTypes; } // End namespace X86. In typical TableGen fashion, to use the enum, you will need to define a; preprocessor macro:. .. code-block:: c++. #define GET_INSTRINFO_OPERAND_TYPES_ENUM // For OpTypes enum; #include ""XXXGenInstrInfo.inc"". Instruction Scheduling; ----------------------. Instruction itineraries can be queried using MCDesc::getSchedClass(). The; value can be named by an enumeration in llvm::XXX::Sched namespace generated; by TableGen in XXXGenInstrInfo.inc. The name of the schedule classes are; the same as provided in XXXSchedule.td plus a default NoItinerary class. The schedule models are generated by TableGen by the SubtargetEmitter,; using the ``CodeGenSchedModels`` class. This is distinct from the itinerary; method of specifying machine resource use. The tool ``utils/schedcover.py``; can be used to determine which instructions have been covered by the; schedule model description and which haven't. The first step is to use the; instructions below to create an output file. Then run ``schedcover.py`` on the; output file:. .. code-block:: shell. $ <src>/utils/schedcover.py <build>/lib/Target/AArch64/tblGenSubtarget.with; instruction, default, CortexA53Model, CortexA57Model, CycloneModel, ExynosM3Model, FalkorModel, KryoModel, ThunderX2T99Model, ThunderXT8XModel; ABSv16i8, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_2VXVY_2cyc, KryoWrite_2cyc_XY_XY_150ln, ,; ABSv1i64, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_1VXVY_2cyc, KryoWrite_2cyc_XY_noRSV_67ln, ,; ... To capture the debug output from generating a schedule model, change to the; appropriate target directory and use the following command:; c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:43034,schedul,schedule,43034,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['schedul'],['schedule']
Energy Efficiency,"ace uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates the wavefronts of a; work-group, and freed when all the wavefronts of a work-group have; terminated. All wavefronts belonging to the same work-group will access the; same memory for any given local address. However, the same local address; accessed by wavefronts belonging to different work-groups will access; different memory. It is higher performance than global memory. The data store; (DS) instructions can be used to access it. **Private**; The private address space uses the hardware scratch memory support which; automatically allocates memory when it creates a wavefront and frees it when; a wavefronts terminates. The memory accessed by a lane of a wavefront for any; given private address will be different to the memory accessed by another lane; of the same or different wavefront for the same private address. If a kernel dispatch uses scratch, then the hardware allocates memory from a; pool of backing memory allocated by the runtime for each wavefront. The lanes; of the wavefront access this using dword (4 byte) interleaving. The mapping; used from private address to backing memory address is:. ``wavefront-scratch-base +; ((private-address / 4) * wavefront-size * 4) +; (wavefront-lane-id * 4) + (private-address % 4)``. If each lane of a wavefront accesses the same private address, the; interleaving results in adjacent dwords being accessed and hence requires; fewer cache lines to be fetched. There are different ways that the wavefront scratch base address is; determined by a wavefront (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Scratch memory can be accessed in an interleaved manner using buffer; instructions with the scratch buffer descriptor and per wavefront scratch; offset, by the scratch instructions, or by flat instructions. Multi-dword; access is not supported except by flat and scratch instructions in; GFX9-GFX11. Code that manipulates t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:26940,allocate,allocates,26940,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['allocate'],"['allocated', 'allocates']"
Energy Efficiency,"ack=4 }. ; Target-dependent attributes:; attributes #1 = { ""no-sse"" }. ; Function @f has attributes: alwaysinline, alignstack=4, and ""no-sse"".; define void @f() #0 #1 { ... }. .. _fnattrs:. Function Attributes; -------------------. Function attributes are set to communicate additional information about; a function. Function attributes are considered to be part of the; function, not of the function type, so functions with different function; attributes can have the same function type. Function attributes are simple keywords that follow the type specified.; If multiple attributes are needed, they are space separated. For; example:. .. code-block:: llvm. define void @f() noinline { ... }; define void @f() alwaysinline { ... }; define void @f() alwaysinline optsize { ... }; define void @f() optsize { ... }. ``alignstack(<n>)``; This attribute indicates that, when emitting the prologue and; epilogue, the backend should forcibly align the stack pointer.; Specify the desired alignment, which must be a power of two, in; parentheses.; ``""alloc-family""=""FAMILY""``; This indicates which ""family"" an allocator function is part of. To avoid; collisions, the family name should match the mangled name of the primary; allocator function, that is ""malloc"" for malloc/calloc/realloc/free,; ""_Znwm"" for ``::operator::new`` and ``::operator::delete``, and; ""_ZnwmSt11align_val_t"" for aligned ``::operator::new`` and; ``::operator::delete``. Matching malloc/realloc/free calls within a family; can be optimized, but mismatched ones will be left alone.; ``allockind(""KIND"")``; Describes the behavior of an allocation function. The KIND string contains comma; separated entries from the following options:. * ""alloc"": the function returns a new block of memory or null.; * ""realloc"": the function returns a new block of memory or null. If the; result is non-null the memory contents from the start of the block up to; the smaller of the original allocation size and the new allocation size; will match that ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:77639,power,power,77639,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"ackward-incompatible way between v6.24 and v6.26.; Because of this, we now print a warning if an application is reading or writing a `ROOT::RVec` object from/to a ROOT file. We assume this is an; exceedingly rare case, as the ROOT interface typically used to manipulate `RVec`s is `RDataFrame`, and `RDataFrame` performs an on-the-fly; `RVec <-> std::vector` conversion rather than writing `RVec`s to disk. Note that, currently, `RVecs` written e.g. in a `TTree` cannot be read back; using certain ROOT interfaces (e.g. `TTreeReaderArray`, `RDataFrame` and the experimental `RNTuple`). All these limitations will be lifted in v6.26.; - Portable implementation of the RANLUX++ generator, see [RanluxppEngine](https://root.cern/doc/master/classROOT_1_1Math_1_1RanluxppEngine.html) and [our blog post](https://root.cern/blog/ranluxpp/). ## TMVA. - Introducing TMVA PyTorch Interface, a method to use PyTorch internally with TMVA for deep learning. This can be used as an alternative to PyKeras Interface for complex models providing more flexibility and power. ## RooFit Libraries. - Extension / updates of the doxygen reference guide.; - Allow for removing RooPlot from global directory management, see [RooPlot::AddDirectory](https://root.cern/doc/v624/classRooPlot.html#a47f7ba71dcaca30ad9ee295dee89c9b8); and [RooPlot::SetDirectory](https://root.cern/doc/v624/classRooPlot.html#a5938bc6d5c47d94c2f04fdcc10c1c026); - Hash-assisted finding of elements in RooWorkspace. Large RooWorkspace objects were slow in finding elements.; This was improved using a hash map.; - Stabilise RooStats::HypoTestInverter. It can now tolerate a few failed fits when conducting hypothesis tests.; This is relevant when a few points in a parameter scan don't converge due to numerical or model instabilities.; These points will be skipped, and HypoTestInverter can continue.; - Tweak pull / residual plots. ROOT automatically zoomed out a bit when a pull / residual plot is created. Now, the; axis range of the original pl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:13834,power,power,13834,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['power'],['power']
Energy Efficiency,"act lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the; :ref:`FunctionPasses <writing-an-llvm-pass-FunctionPass>` on the second; function, etc... until the entire program has been run through the passes. This improves the cache behavior of the compiler, because it is only; touching the LLVM program representation for a single function at a time,; instead of traversing the entire program. It reduces the memory consumption; of compiler, because, for example, only one `DominatorSet; <https://llvm.org/doxygen/classllvm_1_1DominatorSet.html>`_ needs to be; calculated at a time. The effectiveness of the ``PassManager`` is influenced directly by how much; information it has about the behaviors of the passes it is scheduling. For; example, the ""preserved"" set is intentionally conservative in the face of an; unimplemented :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. Not implementing when it should be implemented will have the effect of; not allowing any analysis results to live across the execution of your pass. The ``PassManager`` class exposes a ``--debug-pass`` command line options that; is useful for debugging pass execution, seeing how things work, and diagnosing; when you should be preserving more analyses than you currently are. (To get; information about all of the variants of the ``--debug-pass`` option, just type; ""``opt -help-hidden``""). By using the --debug-pass=Structure option, for example",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:42485,reduce,reduces,42485,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,2,"['consumption', 'reduce']","['consumption', 'reduces']"
Energy Efficiency,"add two lines to transfer the newly defined function to; the JIT and open a new module. In HandleExtern, we just need to add one line to; add the prototype to FunctionProtos. .. warning::; Duplication of symbols in separate modules is not allowed since LLVM-9. That means you can not redefine function in your Kaleidoscope as its shown below. Just skip this part. The reason is that the newer OrcV2 JIT APIs are trying to stay very close to the static and dynamic linker rules, including rejecting duplicate symbols. Requiring symbol names to be unique allows us to support concurrent compilation for symbols using the (unique) symbol names as keys for tracking. With these changes made, let's try our REPL again (I removed the dump of the; anonymous functions this time, you should get the idea by now :) :. ::. ready> def foo(x) x + 1;; ready> foo(2);; Evaluated to 3.000000. ready> def foo(x) x + 2;; ready> foo(2);; Evaluated to 4.000000. It works!. Even with this simple code, we get some surprisingly powerful capabilities -; check this out:. ::. ready> extern sin(x);; Read extern:; declare double @sin(double). ready> extern cos(x);; Read extern:; declare double @cos(double). ready> sin(1.0);; Read top-level expression:; define double @2() {; entry:; ret double 0x3FEAED548F090CEE; }. Evaluated to 0.841471. ready> def foo(x) sin(x)*sin(x) + cos(x)*cos(x);; Read function definition:; define double @foo(double %x) {; entry:; %calltmp = call double @sin(double %x); %multmp = fmul double %calltmp, %calltmp; %calltmp2 = call double @cos(double %x); %multmp4 = fmul double %calltmp2, %calltmp2; %addtmp = fadd double %multmp, %multmp4; ret double %addtmp; }. ready> foo(4.0);; Read top-level expression:; define double @3() {; entry:; %calltmp = call double @foo(double 4.000000e+00); ret double %calltmp; }. Evaluated to 1.000000. Whoa, how does the JIT know about sin and cos? The answer is surprisingly; simple: The KaleidoscopeJIT has a straightforward symbol resolution rule that; it use",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:21733,power,powerful,21733,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['power'],['powerful']
Energy Efficiency,"address of outgoing stack arguments. An ``inalloca`` argument must; be a pointer to stack memory produced by an ``alloca`` instruction.; The alloca, or argument allocation, must also be tagged with the; inalloca keyword. Only the last argument may have the ``inalloca``; attribute, and that argument is guaranteed to be passed in memory. An argument allocation may be used by a call at most once because; the call may deallocate it. The ``inalloca`` attribute cannot be; used in conjunction with other attributes that affect argument; storage, like ``inreg``, ``nest``, ``sret``, or ``byval``. The; ``inalloca`` attribute also disables LLVM's implicit lowering of; large aggregate return values, which means that frontend authors; must lower them with ``sret`` pointers. When the call site is reached, the argument allocation must have; been the most recent stack allocation that is still live, or the; behavior is undefined. It is possible to allocate additional stack; space after an argument allocation and before its call site, but it; must be cleared off with :ref:`llvm.stackrestore; <int_stackrestore>`. The inalloca attribute requires a type argument, which must be the; same as the pointee type of the argument. See :doc:`InAlloca` for more information on how to use this; attribute. ``sret(<ty>)``; This indicates that the pointer parameter specifies the address of a; structure that is the return value of the function in the source; program. This pointer must be guaranteed by the caller to be valid:; loads and stores to the structure may be assumed by the callee not; to trap and to be properly aligned. This is not a valid attribute; for return values. The sret type argument specifies the in memory type, which must be; the same as the pointee type of the argument. .. _attr_elementtype:. ``elementtype(<ty>)``. The ``elementtype`` argument attribute can be used to specify a pointer; element type in a way that is compatible with `opaque pointers; <OpaquePointers.html>`__. The ``elem",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:55535,allocate,allocate,55535,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocate']
Energy Efficiency,"ade three.js to r121:; - SoftwareRenderer deprecated and removed; - let use WebGL for browser, batch and node.js (via headless-gl); - support r3d_gl, r3d_img, r3d_svg rendering options for TGeo and histograms; - keep support of SVGRendered as backup solution; 10. Upgrade MathJax.js to version 3.1.1; - reliably works in browser and node.js!; - all latex/mathjax related methods moved to special JSRoot.latex.js script, loaded on demand; 11. Update jquery to 3.5.1, openui5 to 1.82.2; 12. Use JS classes only in few places - performance is not good enough compared to Object.prototype; 13. Deprecate IE support; 14. Deprecate bower package manager; 15. Add support of ZSTD compression - works only on https://root.cern/js/ website; 16. Add support of log2 scale for axes drawing, v7 can have arbitrary log base; 17. Improve TH2 col drawings for large number of bins - up to factor 5 faster; 18. Allow to move axis title to opposite position; 19. Fix zooming in color palette; 20. Implement monitoring of object inspector. ## Changes in 5.9.1; 1. Fix zooming in color palette; 2. Fix interactive update of TGraph painting on time scale; 3. Fix I/O error in reading std::map (#204); 4. Fix functionality of ""open all"" / ""close all"" GUI buttons. ## Changes in 5.9.0; 1. Support RX and RY drawing option together with COL of TH2; 2. Add support of #overline, #underline, #strike into TLatex parsing (#196); 3. Add support of TGeoTessellated shape; 4. Major changes in v7 drawing: RFrame, RPalette, RColor, RStatBox, ...; 5. Fix in reading std::map member-wise; 6. Better handling of context menu position; 7. Support TASImage class - both PNG and binary content, including palette; 8. Let change TH2 values range via context menu; 9. Fix problem with TH2 col drawing when bins size too small. ## Changes in 5.8.2; 1. Fix - tooltip handling for TH2 Error draw; 2. Fix - use proper ""fixed"" position for enlarged drawing; 3. Fix - correctly extract TF1 parameter names; 4. Fix - keep stat box when update hi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:26850,monitor,monitoring,26850,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['monitor'],['monitoring']
Energy Efficiency,"ady been called or if the; preallocated call corresponding to the '``llvm.call.preallocated.setup``'; has already been called. .. _int_call_preallocated_teardown:. '``llvm.call.preallocated.teardown``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.call.preallocated.teardown(token %setup_token). Overview:; """""""""""""""""". The '``llvm.call.preallocated.teardown``' intrinsic cleans up the stack; created by a '``llvm.call.preallocated.setup``'. Semantics:; """""""""""""""""""". The token argument must be a '``llvm.call.preallocated.setup``'. The '``llvm.call.preallocated.teardown``' intrinsic cleans up the stack; allocated by the corresponding '``llvm.call.preallocated.setup``'. Exactly; one of this or the preallocated call must be called to prevent stack leaks.; It is undefined behavior to call both a '``llvm.call.preallocated.teardown``'; and the preallocated call for a given '``llvm.call.preallocated.setup``'. For example, if the stack is allocated for a preallocated call by a; '``llvm.call.preallocated.setup``', then an initializer function called on an; allocated argument throws an exception, there should be a; '``llvm.call.preallocated.teardown``' in the exception handler to prevent; stack leaks. Following the nesting rules in '``llvm.call.preallocated.setup``', nested; calls to '``llvm.call.preallocated.setup``' and; '``llvm.call.preallocated.teardown``' are allowed but must be properly; nested. Example:; """""""""""""""". .. code-block:: llvm. %cs = call token @llvm.call.preallocated.setup(i32 1); %x = call ptr @llvm.call.preallocated.arg(token %cs, i32 0) preallocated(i32); invoke void @constructor(ptr %x) to label %conta unwind label %contb; conta:; call void @foo1(ptr preallocated(i32) %x) [""preallocated""(token %cs)]; ret void; contb:; %s = catchswitch within none [label %catch] unwind to caller; catch:; %p = catchpad within %s []; call void @llvm.call.preallocated.teardown(token %cs); ret void. Standard C/C++ Library Intrinsics",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:540970,allocate,allocated,540970,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"age information and exit. .. option:: -version. Display the version of this program. .. option:: -verify_arch <architecture 1> [<architecture 2> ...]. Take a single input file and verify the specified architectures are present in the file.; If so then exit with a status of 0 else exit with a status of 1. .. option:: -archs. Take a single input file and display the architectures present in the file.; Each architecture is separated by a single whitespace.; Unknown architectures are displayed as unknown(CPUtype,CPUsubtype). .. option:: -info. Take at least one input file and display the descriptions of each file.; The descriptions include the filename and architecture types separated by whitespace.; Universal binaries are grouped together first, followed by thin files.; Architectures in the fat file: <filename> are: <architectures>; Non-fat file: <filename> is architecture: <architecture>. .. option:: -thin. Take a single universal binary input file and the thin flag followed by an architecture type.; Require the output flag to be specified, and output a thin binary of the specified architecture. .. option:: -create. Take at least one input file and require the output flag to be specified.; Output a universal binary combining the input files. .. option:: -replace. Take a single universal binary input file and require the output flag to be specified.; The replace flag is followed by an architecture type, and a thin input file.; Output a universal binary with the specified architecture slice in the; universal binary input replaced with the contents of the thin input file. .. option:: -segalign. Additional flag that can be specified with create and replace.; The segalign flag is followed by an architecture type, and an alignment.; The alignment is a hexadecimal number that is a power of 2.; Output a file in which the slice with the specified architecture has the specified alignment. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/issues/>.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-lipo.rst:2370,power,power,2370,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-lipo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-lipo.rst,1,['power'],['power']
Energy Efficiency,ags-index-name. Generate Clang diagnostic name index. .. option:: -gen-clang-basic-reader. Generate Clang BasicReader classes. .. option:: -gen-clang-basic-writer. Generate Clang BasicWriter classes. .. option:: -gen-clang-comment-nodes. Generate Clang AST comment nodes. .. option:: -gen-clang-decl-nodes. Generate Clang AST declaration nodes. .. option:: -gen-clang-stmt-nodes. Generate Clang AST statement nodes. .. option:: -gen-clang-type-nodes. Generate Clang AST type nodes. .. option:: -gen-clang-type-reader. Generate Clang AbstractTypeReader class. .. option:: -gen-clang-type-writer. Generate Clang AbstractTypeWriter class. .. option:: -gen-clang-opcodes. Generate Clang constexpr interpreter opcodes. .. option:: -gen-clang-sa-checkers. Generate Clang static analyzer checkers. .. option:: -gen-clang-comment-html-tags. Generate efficient matchers for HTML tag names that are used in; documentation comments. .. option:: -gen-clang-comment-html-tags-properties. Generate efficient matchers for HTML tag properties. .. option:: -gen-clang-comment-html-named-character-references. Generate function to translate named character references to UTF-8 sequences. .. option:: -gen-clang-comment-command-info. Generate command properties for commands that are used in documentation comments. .. option:: -gen-clang-comment-command-list. Generate list of commands that are used in documentation comments. .. option:: -gen-clang-opencl-builtins. Generate OpenCL builtin declaration handlers. .. option:: -gen-arm-neon. Generate ``arm_neon.h`` for Clang. .. option:: -gen-arm-fp16. Generate ``arm_fp16.h`` for Clang. .. option:: -gen-arm-bf16. Generate ``arm_bf16.h`` for Clang. .. option:: -gen-arm-neon-sema. Generate ARM NEON sema support for Clang. .. option:: -gen-arm-neon-test. Generate ARM NEON tests for Clang. .. option:: -gen-arm-sve-header. Generate ``arm_sve.h`` for Clang. .. option:: -gen-arm-sve-builtins. Generate ``arm_sve_builtins.inc`` for Clang. .. option:: -gen-arm-sve-builtin,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:5380,efficient,efficient,5380,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,1,['efficient'],['efficient']
Energy Efficiency,"ain page coming from THttpServer is very similar to normal JSROOT page.; One could browse existing items and display them. A snapshot of running; server can be seen on the [demo page](https://root.cern/js/latest/httpserver.C/). One could also specify similar URL parameters to configure the displayed items and drawing options. It is also possible to display one single item from the THttpServer server like:. <https://root.cern/js/latest/httpserver.C/Files/job1.root/hpxpy/draw.htm?opt=colz>. ## Data monitoring with JSROOT. ### Monitoring with http server. The best possibility to organize the monitoring of data from a running application; is to use THttpServer. In such case the client can always access the latest; changes and request only the items currently displayed in the browser.; To enable monitoring, one should activate the appropriate checkbox or; provide __monitoring__ parameter in the URL string like:. <https://root.cern/js/latest/httpserver.C/Files/job1.root/hprof/draw.htm?monitoring=1000>. The parameter value is the update interval in milliseconds. ### JSON file-based monitoring. Solid file-based monitoring (without integration of THttpServer into application) can be; implemented in JSON format. There is the [TBufferJSON](https://root.cern/doc/master/classTBufferJSON.html) class,; which is capable to convert any (beside TTree) ROOT object into JSON. Any ROOT application can use such class to; create JSON files for selected objects and write such files in a directory,; which can be accessed via web server. Then one can use JSROOT to read such files and display objects in a web browser. There is a demonstration page showing such functionality: <https://root.cern/js/latest/demo/update_draw.htm>.; This demo page reads in cycle 20 json files and displays them. If one has a web server which already provides such JSON file, one could specify the URL to this file like:. <https://root.cern/js/latest/demo/update_draw.htm?addr=../httpserver.C/Canvases/c1/root.json.gz>. H",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:30929,monitor,monitoring,30929,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['monitor'],['monitoring']
Energy Efficiency,"ain the upper and lower bounds of the array, with the; equivalent of ``&arr[0]`` serving as the lower bound and ``&arr[array_size]``; (or one past the last element) serving as the upper bound. This applies to all; types of arrays including constant-length arrays, variable-length arrays (VLAs),; and flexible array members annotated with `__counted_by`. In the following example, reference to ``vla`` promotes to ``int; *__bidi_indexable``, with ``&vla[n]`` as the upper bound and ``&vla[0]`` as the; lower bound. Then, it's copied to ``int *p``, which is implicitly ``int; *__bidi_indexable p``. Please note that value of ``n`` used to create the upper; bound is ``10``, not ``100``, in this case because ``10`` is the actual length; of ``vla``, the value of ``n`` at the time when the array is being allocated. .. code-block:: c. void foo(void) {; int n = 10;; int vla[n];; n = 100;; int *p = vla; // { .ptr: &vla[0], .upper: &vla[10], .lower: &vla[0] }; // it's `&vla[10]` because the value of `n` was 10 at the; // time when the array is actually allocated.; // ...; }. By promoting array references to ``__bidi_indexable``, all array accesses are; bounds checked in ``-fbounds-safety``, just as ``__bidi_indexable`` pointers; are. Maintaining correctness of bounds annotations; ---------------------------------------------. ``-fbounds-safety`` maintains correctness of bounds annotations by performing; additional checks when a pointer object and/or its related value containing the; bounds information is updated. For example, ``__single`` expresses an invariant that the pointer must either; point to a single valid object or be a null pointer. To maintain this invariant,; the compiler inserts checks when initializing a ``__single`` pointer, as shown; in the following example:. .. code-block:: c. void foo(void *__sized_by(size) vp, size_t size) {; // Inserted check:; // if ((int*)upper_bound(vp) - (int*)vp < sizeof(int) && !!vp) trap();; int *__single ip = (int *)vp;; }. Additionally, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:34920,allocate,allocated,34920,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['allocate'],['allocated']
Energy Efficiency,"aining the; neutral value ``INT_MIN`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smax.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 -128, i8 -128, i8 -128, i8 -128>; %reduction = call i8 @llvm.vector.reduce.smax.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smax.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_smin:. '``llvm.vp.reduce.smin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smin``' intrinsic performs the signed-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.smin <int_vector_reduce_smin>`) of the; vector operand ``val`` on each enabled lane, and taking the minimum of that and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:765064,reduce,reduce,765064,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"aint. //===----------------------------------------------------------------------===//. We currently codegen SCALAR_TO_VECTOR as a store of the scalar to a 16-byte; aligned stack slot, followed by a load/vperm. We should probably just store it; to a scalar stack slot, then use lvsl/vperm to load it. If the value is already; in memory this is a big win. //===----------------------------------------------------------------------===//. extract_vector_elt of an arbitrary constant vector can be done with the ; following instructions:. vTemp = vec_splat(v0,2); // 2 is the element the src is in.; vec_ste(&destloc,0,vTemp);. We can do an arbitrary non-constant value by using lvsr/perm/ste. //===----------------------------------------------------------------------===//. If we want to tie instruction selection into the scheduler, we can do some; constant formation with different instructions. For example, we can generate; ""vsplti -1"" with ""vcmpequw R,R"" and 1,1,1,1 with ""vsubcuw R,R"", and 0,0,0,0 with; ""vsplti 0"" or ""vxor"", each of which use different execution units, thus could; help scheduling. This is probably only reasonable for a post-pass scheduler. //===----------------------------------------------------------------------===//. For this function:. void test(vector float *A, vector float *B) {; vector float C = (vector float)vec_cmpeq(*A, *B);; if (!vec_any_eq(*A, *B)); *B = (vector float){0,0,0,0};; *A = C;; }. we get the following basic block:. 	...; lvx v2, 0, r4; lvx v3, 0, r3; vcmpeqfp v4, v3, v2; vcmpeqfp. v2, v3, v2; bne cr6, LBB1_2 ; cond_next. The vcmpeqfp/vcmpeqfp. instructions currently cannot be merged when the; vcmpeqfp. result is used by a branch. This can be improved. //===----------------------------------------------------------------------===//. The code generated for this is truly aweful:. vector float test(float a, float b) {; return (vector float){ 0.0, a, 0.0, 0.0}; ; }. LCPI1_0: ; float; .space 4; .text; .globl _test; .align 4; _test:; mfspr r2,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt:2884,schedul,scheduling,2884,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,1,['schedul'],['scheduling']
Energy Efficiency,"ake incorrect assumptions (most notably, that X == X; is always true, since it does not hold for NaN).; (Difficulty: Medium). Improved loop execution modeling.; The analyzer simply unrolls each loop N times before; dropping the path, for a fixed constant N.; However, that results in lost coverage in cases where the loop always; executes more than N times.; A Google Summer Of Code; project; was completed to make the loop bound parameterizable,; but the widening; problem still remains open. (Difficulty: Hard). Basic function summarization support; The analyzer performs inter-procedural analysis using; either inlining or ""conservative evaluation"" (invalidating all data; passed to the function).; Often, a very simple summary; (e.g. ""this function is pure"") would be; enough to be a large improvement over conservative evaluation.; Such summaries could be obtained either syntactically,; or using a dataflow framework.; (Difficulty: Hard). Implement a dataflow flamework.; The analyzer core; implements a symbolic execution; engine, which performs checks; (use-after-free, uninitialized value read, etc.); over a single program path.; However, many useful properties; (dead code, check-after-use, etc.) require; reasoning over all possible in a program.; Such reasoning requires a; dataflow analysis framework.; Clang already implements; a few dataflow analyses (most notably, liveness),; but they implemented in an ad-hoc fashion.; A proper framework would enable us writing many more useful checkers.; (Difficulty: Hard) . Track type information through casts more precisely.; The DynamicTypePropagation; checker is in charge of inferring a region's; dynamic type based on what operations the code is performing.; Casts are a rich source of type information that the analyzer currently ignores.; (Difficulty: Medium). Fixing miscellaneous bugs; Apart from the open projects listed above,; contributors are welcome to fix any of the outstanding; bugs; in the Bugzilla.; (Difficulty: Anything). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html:8416,charge,charge,8416,interpreter/llvm-project/clang/www/analyzer/open_projects.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html,1,['charge'],['charge']
Energy Efficiency,"al; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``-QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the smallest floating-point value for the; result type. If only ``nnan`` is set then the neutral value is ``-Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>` intrinsic (and thus the; '``llvm.maxnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum element magnitude ``0.0`` and containing both ``+0.0`` and; ``-0.0`` elements, the sign of the result is unspecified. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmax.v4f32(float %float, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float QNAN, float QNAN, float QNAN, float QNAN>; %reduction = call float @llvm.vector.reduce.fmax.v4f32(<4 x float> %masked.a); %also.r = call float @llvm.maxnum.f32(float %reduction, float %start). .. _int_vp_reduce_fmin:. '``llvm.vp.reduce.fmin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmin.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmin.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MIN`` reduction of a vector and a scalar starting; value, r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:773388,reduce,reduce,773388,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,alTypeDumper.h; llvm/tools/llvm-pdbutil/PrettyBuiltinDumper.cpp; llvm/tools/llvm-pdbutil/PrettyEnumDumper.cpp; llvm/tools/llvm-pdbutil/PrettyExternalSymbolDumper.cpp; llvm/tools/llvm-pdbutil/PrettyTypeDumper.cpp; llvm/tools/llvm-pdbutil/TypeReferenceTracker.h; llvm/tools/llvm-pdbutil/YAMLOutputStyle.h; llvm/tools/llvm-profgen/CallContext.h; llvm/tools/llvm-profgen/CSPreInliner.cpp; llvm/tools/llvm-profgen/CSPreInliner.h; llvm/tools/llvm-profgen/llvm-profgen.cpp; llvm/tools/llvm-profgen/PerfReader.cpp; llvm/tools/llvm-profgen/PerfReader.h; llvm/tools/llvm-rc/ResourceScriptCppFilter.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/l,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:336975,reduce,reduce,336975,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"alifiers (``const``, ``volatile``, ``restrict``, plus some; extended qualifiers required by language extensions) separately from the types; themselves. ``QualType`` is conceptually a pair of ""``Type*``"" and the bits; for these type qualifiers. By storing the type qualifiers as bits in the conceptual pair, it is extremely; efficient to get the set of qualifiers on a ``QualType`` (just return the field; of the pair), add a type qualifier (which is a trivial constant-time operation; that sets a bit), and remove one or more type qualifiers (just return a; ``QualType`` with the bitfield set to empty). Further, because the bits are stored outside of the type itself, we do not need; to create duplicates of types with different sets of qualifiers (i.e. there is; only a single heap allocated ""``int``"" type: ""``const int``"" and ""``volatile; const int``"" both point to the same heap allocated ""``int``"" type). This; reduces the heap size used to represent bits and also means we do not have to; consider qualifiers when uniquing types (:ref:`Type <Type>` does not even; contain qualifiers). In practice, the two most common type qualifiers (``const`` and ``restrict``); are stored in the low bits of the pointer to the ``Type`` object, together with; a flag indicating whether extended qualifiers are present (which must be; heap-allocated). This means that ``QualType`` is exactly the same size as a; pointer. .. _DeclarationName:. Declaration names; -----------------. The ``DeclarationName`` class represents the name of a declaration in Clang.; Declarations in the C family of languages can take several different forms.; Most declarations are named by simple identifiers, e.g., ""``f``"" and ""``x``"" in; the function declaration ``f(int x)``. In C++, declaration names can also name; class constructors (""``Class``"" in ``struct Class { Class(); }``), class; destructors (""``~Class``""), overloaded operator names (""``operator+``""), and; conversion functions (""``operator void const *``""). In Object",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:67602,reduce,reduces,67602,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['reduce'],['reduces']
Energy Efficiency,"alizedPolar, Polar> keys(io, polar);. io.mapRequired(""x"", keys->x);; io.mapRequired(""y"", keys->y);; }; };. When writing YAML, the local variable ""keys"" will be a stack allocated; instance of NormalizedPolar, constructed from the supplied polar object which; initializes it x and y fields. The mapRequired() methods then write out the x; and y values as key/value pairs. When reading YAML, the local variable ""keys"" will be a stack allocated instance; of NormalizedPolar, constructed by the empty constructor. The mapRequired; methods will find the matching key in the YAML document and fill in the x and y; fields of the NormalizedPolar object keys. At the end of the mapping() method; when the local keys variable goes out of scope, the denormalize() method will; automatically be called to convert the read values back to polar coordinates,; and then assigned back to the second parameter to mapping(). In some cases, the normalized class may be a subclass of the native type and; could be returned by the denormalize() method, except that the temporary; normalized instance is stack allocated. In these cases, the utility template; MappingNormalizationHeap<> can be used instead. It just like; MappingNormalization<> except that it heap allocates the normalized object; when reading YAML. It never destroys the normalized object. The denormalize(); method can this return ""this"". Default values; --------------; Within a mapping() method, calls to io.mapRequired() mean that that key is; required to exist when parsing YAML documents, otherwise YAML I/O will issue an; error. On the other hand, keys registered with io.mapOptional() are allowed to not; exist in the YAML document being read. So what value is put in the field; for those optional keys?; There are two steps to how those optional fields are filled in. First, the; second parameter to the mapping() method is a reference to a native class. That; native class must have a default constructor. Whatever value the default; constructor i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:19583,allocate,allocated,19583,interpreter/llvm-project/llvm/docs/YamlIO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst,1,['allocate'],['allocated']
Energy Efficiency,"all cell contents are scaled to `ncolors`.; The current color palette does not have a class or global object of its; own. It is defined in the current style as an array of color numbers.; The current palette can be changed with:. ``` {.cpp}; TStyle::SetPalette(Int_t ncolors,Int_t*color_indexes).; ```. By default, or if `ncolors <= 0`, a default palette (see above) of 50; colors is defined. The colors defined in this palette are good for; coloring pads, labels, and other graphic objects. If `ncolors > 0` and; `colors = 0`, the default palette is used with a maximum of `ncolors`.; If `ncolors == 1 && colors == 0`, then a pretty palette with a spectrum; `Violet->Red` is created. It is recommended to use this pretty palette; when drawing lego(s), surfaces or contours. For example, to set the; current palette to the ""`pretty`"" one, do:. ``` {.cpp}; root[] gStyle->SetPalette(1); ```. A more complete example is shown below. It illustrates the definition of; a custom palette. You can adapt it to suit your needs. In case you use; it for contour coloring, with the current color/contour algorithm,; always define two more colors than the number of contours. ``` {.cpp}; void palette() {; // Example of creating new colors (purples); const Int_t colNum = 10; // and defining of a new palette; Int_t palette[colNum];; for (Int_t i=0; i<colNum; i++) {; // get the color and if it does not exist create it; if (! gROOT->GetColor(230+i) ){; TColor *color =; new TColor(230+i,1-(i/((colNum)*1.0)),0.3,0.5,"""");; } else {; TColor *color = gROOT->GetColor(230+i);; color->SetRGB(1-(i/((colNum)*1.0)),0.3,0.5);; }; palette[i] = 230+i;; }; gStyle->SetPalette(colNum,palette);; TF2 *f2 = new TF2(""f2"",""exp(-(x^2)-(y^2))"",-3,3,-3,3);; // two contours less than the number of colors in palette; f2->SetContour(colNum-2);; f2->Draw(""cont"");; }; ```. Since ROOT 6.26, you can also define a palette based on an ASCII text; file, using `TColor::CreateColorTableFromFile(""filename.txt"")` or; `gStyle->SetPalette(""f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:82739,adapt,adapt,82739,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['adapt'],['adapt']
Energy Efficiency,"all. The type is used in the case that an; ``llvm.call.preallocated.setup`` does not have a corresponding call (e.g. due; to DCE), where otherwise we cannot know how large the arguments are. It is undefined behavior if this is called with a token from an; '``llvm.call.preallocated.setup``' if another; '``llvm.call.preallocated.setup``' has already been called or if the; preallocated call corresponding to the '``llvm.call.preallocated.setup``'; has already been called. .. _int_call_preallocated_teardown:. '``llvm.call.preallocated.teardown``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.call.preallocated.teardown(token %setup_token). Overview:; """""""""""""""""". The '``llvm.call.preallocated.teardown``' intrinsic cleans up the stack; created by a '``llvm.call.preallocated.setup``'. Semantics:; """""""""""""""""""". The token argument must be a '``llvm.call.preallocated.setup``'. The '``llvm.call.preallocated.teardown``' intrinsic cleans up the stack; allocated by the corresponding '``llvm.call.preallocated.setup``'. Exactly; one of this or the preallocated call must be called to prevent stack leaks.; It is undefined behavior to call both a '``llvm.call.preallocated.teardown``'; and the preallocated call for a given '``llvm.call.preallocated.setup``'. For example, if the stack is allocated for a preallocated call by a; '``llvm.call.preallocated.setup``', then an initializer function called on an; allocated argument throws an exception, there should be a; '``llvm.call.preallocated.teardown``' in the exception handler to prevent; stack leaks. Following the nesting rules in '``llvm.call.preallocated.setup``', nested; calls to '``llvm.call.preallocated.setup``' and; '``llvm.call.preallocated.teardown``' are allowed but must be properly; nested. Example:; """""""""""""""". .. code-block:: llvm. %cs = call token @llvm.call.preallocated.setup(i32 1); %x = call ptr @llvm.call.preallocated.arg(token %cs, i32 0) preallocated(i32); invoke void @cons",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:540635,allocate,allocated,540635,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"allocation. This allows the context to track/hold memory allocations and; react to the newly emitted definitions. In ORC this is used to update the; ``ExecutionSession`` instance's dependence graph, which may result in; these symbols (and possibly others) becoming *Ready* if all of their; dependencies have also been emitted. .. _passes:. Passes; ------. JITLink passes are ``std::function<Error(LinkGraph&)>`` instances. They are free; to inspect and modify the given ``LinkGraph`` subject to the constraints of; whatever phase they are running in (see :ref:`generic_link_algorithm`). If a; pass returns ``Error::success()`` then linking continues. If a pass returns; a failure value then linking is stopped and the ``JITLinkContext`` is notified; that the link failed. Passes may be used by both JITLink backends (e.g. MachO/x86-64 implements GOT; and PLT construction as a pass), and external clients like; ``ObjectLinkingLayer::Plugin``. In combination with the open ``LinkGraph`` API, JITLink passes enable the; implementation of powerful new features. For example:. * Relaxation optimizations -- A pre-fixup pass can inspect GOT accesses and PLT; calls and identify situations where the addresses of the entry target and the; access are close enough to be accessed directly. In this case the pass can; rewrite the instruction stream of the containing block and update the fixup; edges to make the access direct. Code for this looks like:. .. code-block:: c++. Error relaxGOTEdges(LinkGraph &G) {; for (auto *B : G.blocks()); for (auto &E : B->edges()); if (E.getKind() == x86_64::GOTLoad) {; auto &GOTTarget = getGOTEntryTarget(E.getTarget());; if (isInRange(B.getFixupAddress(E), GOTTarget)) {; // Rewrite B.getContent() at fixup address from; // MOVQ to LEAQ. // Update edge target and kind.; E.setTarget(GOTTarget);; E.setKind(x86_64::PCRel32);; }; }. return Error::success();; }. * Metadata registration -- Post allocation passes can be used to record the; address range of sections in the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:23480,power,powerful,23480,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['power'],['powerful']
Energy Efficiency,"allow const; use of C++ objects, pointers, or references held in automatic storage. As usual, within the block, references to captured variables become; const-qualified, as if they were references to members of a const; object. Note that this does not change the type of a variable of; reference type. For example, given a class Foo:. .. code-block:: c. Foo foo;; Foo &fooRef = foo;; Foo *fooPtr = &foo;. A Block that referenced these variables would import the variables as; const variations:. .. code-block:: c. const Foo block_foo = foo;; Foo &block_fooRef = fooRef;; Foo *const block_fooPtr = fooPtr;. Captured variables are copied into the Block at the instant of; evaluating the Block literal expression. They are also copied when; calling ``Block_copy()`` on a Block allocated on the stack. In both; cases, they are copied as if the variable were const-qualified, and; it's an error if there's no such constructor. Captured variables in Blocks on the stack are destroyed when control; leaves the compound statement that contains the Block literal; expression. Captured variables in Blocks on the heap are destroyed; when the reference count of the Block drops to zero. Variables declared as residing in ``__block`` storage may be initially; allocated in the heap or may first appear on the stack and be copied; to the heap as a result of a ``Block_copy()`` operation. When copied; from the stack, ``__block`` variables are copied using their normal; qualification (i.e. without adding const). In C++11, ``__block``; variables are copied as x-values if that is possible, then as l-values; if not; if both fail, it's an error. The destructor for any initial; stack-based version is called at the variable's normal end of scope. References to ``this``, as well as references to non-static members of; any enclosing class, are evaluated by capturing ``this`` just like a; normal variable of C pointer type. Member variables that are Blocks may not be overloaded by the types of; their arguments.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:12317,allocate,allocated,12317,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['allocate'],['allocated']
Energy Efficiency,"ally supports a fully fine grained mapping mechanism that allows; you to map almost any diagnostic to the output level that you want. The only; diagnostics that cannot be mapped are ``NOTE``\ s, which always follow the; severity of the previously emitted diagnostic and ``ERROR``\ s, which can only; be mapped to ``Fatal`` (it is not possible to turn an error into a warning, for; example). Diagnostic mappings are used in many ways. For example, if the user specifies; ``-pedantic``, ``EXTENSION`` maps to ``Warning``, if they specify; ``-pedantic-errors``, it turns into ``Error``. This is used to implement; options like ``-Wunused_macros``, ``-Wundef`` etc. Mapping to ``Fatal`` should only be used for diagnostics that are considered so; severe that error recovery won't be able to recover sensibly from them (thus; spewing a ton of bogus errors). One example of this class of error are failure; to ``#include`` a file. The Format String; ^^^^^^^^^^^^^^^^^. The format string for the diagnostic is very simple, but it has some power. It; takes the form of a string in English with markers that indicate where and how; arguments to the diagnostic are inserted and formatted. For example, here are; some simple format strings:. .. code-block:: c++. ""binary integer literals are an extension""; ""format string contains '\\0' within the string body""; ""more '%%' conversions than data arguments""; ""invalid operands to binary expression (%0 and %1)""; ""overloaded '%0' must be a %select{unary|binary|unary or binary}2 operator""; "" (has %1 parameter%s1)"". These examples show some important points of format strings. You can use any; plain ASCII character in the diagnostic string except ""``%``"" without a; problem, but these are C strings, so you have to use and be aware of all the C; escape sequences (as in the second example). If you want to produce a ""``%``""; in the output, use the ""``%%``"" escape sequence, like the third diagnostic.; Finally, Clang uses the ""``%...[digit]``"" sequences to specif",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:6293,power,power,6293,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['power'],['power']
Energy Efficiency,"alues for the OpenCL language are:. | ``cl1.0``. OpenCL 1.0. | ``cl1.1``. OpenCL 1.1. | ``cl1.2``. OpenCL 1.2. | ``cl2.0``. OpenCL 2.0. The default OpenCL language standard is ``cl1.0``. Supported values for the CUDA language are:. | ``cuda``. NVIDIA CUDA(tm). .. option:: -stdlib=<library>. Specify the C++ standard library to use; supported options are libstdc++ and; libc++. If not specified, platform default will be used. .. option:: -rtlib=<library>. Specify the compiler runtime library to use; supported options are libgcc and; compiler-rt. If not specified, platform default will be used. .. option:: -ansi. Same as -std=c89. .. option:: -ObjC, -ObjC++. Treat source input files as Objective-C and Object-C++ inputs respectively. .. option:: -trigraphs. Enable trigraphs. .. option:: -ffreestanding. Indicate that the file should be compiled for a freestanding, not a hosted,; environment. Note that it is assumed that a freestanding environment will; additionally provide `memcpy`, `memmove`, `memset` and `memcmp`; implementations, as these are needed for efficient codegen for many programs. .. option:: -fno-builtin. Disable special handling and optimizations of well-known library functions,; like :c:func:`strlen` and :c:func:`malloc`. .. option:: -fno-builtin-<function>. Disable special handling and optimizations for the specific library function.; For example, ``-fno-builtin-strlen`` removes any special handling for the; :c:func:`strlen` library function. .. option:: -fno-builtin-std-<function>. Disable special handling and optimizations for the specific C++ standard; library function in namespace ``std``. For example,; ``-fno-builtin-std-move_if_noexcept`` removes any special handling for the; :cpp:func:`std::move_if_noexcept` library function. For C standard library functions that the C++ standard library also provides; in namespace ``std``, use :option:`-fno-builtin-\<function\>` instead. .. option:: -fmath-errno. Indicate that math functions should be treated as upd",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:6182,efficient,efficient,6182,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['efficient'],['efficient']
Energy Efficiency,"amdhsa-kernel-descriptor:. Kernel Descriptor; ~~~~~~~~~~~~~~~~~. A kernel descriptor consists of the information needed by CP to initiate the; execution of a kernel, including the entry point address of the machine code; that implements the kernel. Code Object V3 Kernel Descriptor; ++++++++++++++++++++++++++++++++. CP microcode requires the Kernel descriptor to be allocated on 64-byte; alignment. The fields used by CP for code objects before V3 also match those specified in; :ref:`amdgpu-amdhsa-kernel-descriptor-v3-table`. .. table:: Code Object V3 Kernel Descriptor; :name: amdgpu-amdhsa-kernel-descriptor-v3-table. ======= ======= =============================== ============================; Bits Size Field Name Description; ======= ======= =============================== ============================; 31:0 4 bytes GROUP_SEGMENT_FIXED_SIZE The amount of fixed local; address space memory; required for a work-group; in bytes. This does not; include any dynamically; allocated local address; space memory that may be; added when the kernel is; dispatched.; 63:32 4 bytes PRIVATE_SEGMENT_FIXED_SIZE The amount of fixed; private address space; memory required for a; work-item in bytes. When; this cannot be predicted,; code object v4 and older; sets this value to be; higher than the minimum; requirement.; 95:64 4 bytes KERNARG_SIZE The size of the kernarg; memory pointed to by the; AQL dispatch packet. The; kernarg memory is used to; pass arguments to the; kernel. * If the kernarg pointer in; the dispatch packet is NULL; then there are no kernel; arguments.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is 0 then the kernarg; memory size is; unspecified.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is not 0 then the value; specifies the kernarg; memory size in bytes. It; is recommended to provide; a value as it may be used; by CP to optimize making; the kernarg memory; visible to the kernel; code. 127:96 4 bytes ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:158888,allocate,allocated,158888,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"ampling, Fourier transforms, etc. �The following concrete implementation; of the TestStatSampler interface are currently available. ToyMCSamplerUses a Toy Monte Carlo approach to build the; sampling distribution. �The pdf's generate method to generate is used to; generate toy data, and then the test statistic is evaluated at the; requested parameter point. ; DebuggingSampler Simply returns a uniform distribution; between 0,1. �Useful for debugging. NeymanConstruction and FeldmanCousins; A flexible framework for the Neyman Construction was added in this; release. The NeymanConstruction is a concrete implementation of the; IntervalCalculator interface, but it needs several; additional components�to be specified before use. The design; factorizes the choice of the parameter points to be tested,�the choice of; the test statistic, and the generation of sampling distribution into; separate parts (described above). �Finally, the NeymanConstruction class; is simply in charge of using these parts (strategies) and constructing; the confidence belt and confidence intervals. �The ConfidenceBelt class; is still under development, but the current version works fine for; producing ConfidenceIntervals. �We are also working to make this class; work with parallelization approaches, which is not yet complete.; The FeldmanCousins class is a separate concrete implementation of the; IntervalCalculator interface. �It uses the NeymanConstruction internally,; and�enforces�specific choices of the test statistic and ordering; principle to realize the Unified intervals described by Feldman and; Cousins in their paper�Phys.Rev.D57:3873-3889,1998. In an extension to the technique discussed in Feldman and Cousins paper,; the FeldmanCousins class also performs a ""profile construction"" if their are nuisance parameters.; In this case, the parameters of interest are scanned in a regular grid. For each point in the grid; the calculator finds the best fit value of the nuisance parameters (given the dat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:28193,charge,charge,28193,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,1,['charge'],['charge']
Energy Efficiency,"analyzer includes new checks for:; ; Improper instance cleanup up in Objective-C -dealloc methods under manual retain/release.; Inadvertent comparisons of NSNumber, CFNumberRef, and other number object pointers against scalar values.; Unsafe usage of dispatch_once_t predicates stored in Objective-C instance variables and other heap-allocated memory.; Issues resulting from self-assignment in C++.; Incorrect usage of MPI APIs in C and C++. This check can be enabled by passing the following command to scan-build: ;   -enable-checker optin.mpi.MPI-Checker. The scan-build tool now supports a --force-analyze-debug-code flag that forces projects to analyze in debug mode. This flag leaves in assertions and so typically results in fewer false positives.; Additional miscellaneous improvements.; Now requires macOS 10.8 or later. checker-278; built: February 5, 2016; download: checker-278.tar.bz2; highlights:. Greatly improves analysis of C++ lambdas, including interprocedural analysis of lambda applications and reduced 'dead store'; false positives for variables captured by reference.; The analyzer now checks for misuse of 'vfork()'. This check is enabled by default.; The analyzer can now detect excessively-padded structs. This check can be enabled by passing the following; command to scan-build:;   -enable-checker optin.performance.Padding ; The checks to detect misuse of _Nonnull are now enabled by default.; The checks to detect misuse of Objective-C generics are now enabled by default.; Many miscellaneous improvements. checker-277; built: October 28, 2015; download: checker-277.tar.bz2; highlights:. Includes about 20 months of change to Clang itself.; New checker for C++ leaks is turned on by default.; Added various small checks and bug fixes.; Added experimental checkers for Objective-C:. New localizability checks:; ; Checker warning about uses of non-localized NSStrings passed to UI methods expecting localized strings.; Checker warning when the comment argument is missing ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:1181,reduce,reduced,1181,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,1,['reduce'],['reduced']
Energy Efficiency,"and difficult; to describe using ordinary DWARF location descriptions. Instead of forcing; complex thread-local storage calculations into the DWARF expressions, the*; ``DW_OP_form_tls_address`` *allows the consumer to perform the computation; based on the target architecture specific run-time environment.*. 5. ``DW_OP_call_frame_cfa``. ``DW_OP_call_frame_cfa`` pushes the location description L of the Canonical; Frame Address (CFA) of the current subprogram, obtained from the call frame; information on the stack. See :ref:`amdgpu-dwarf-call-frame-information`. *Although the value of the* ``DW_AT_frame_base`` *attribute of the debugger; information entry corresponding to the current subprogram can be computed; using a location list expression, in some cases this would require an; extensive location list because the values of the registers used in; computing the CFA change during a subprogram execution. If the call frame; information is present, then it already encodes such changes, and it is; space efficient to reference that using the* ``DW_OP_call_frame_cfa``; *operation.*. 6. ``DW_OP_fbreg``. ``DW_OP_fbreg`` has a single signed LEB128 integer operand that represents a; byte displacement B. The location description L for the *frame base* of the current subprogram is; obtained from the ``DW_AT_frame_base`` attribute of the debugger information; entry corresponding to the current subprogram as described in; :ref:`amdgpu-dwarf-low-level-information`. The location description L is updated as if the ``DW_OP_LLVM_offset_uconst; B`` operation was applied. The updated L is pushed on the stack. 7. ``DW_OP_breg0``, ``DW_OP_breg1``, ..., ``DW_OP_breg31``. The ``DW_OP_breg<N>`` operations encode the numbers of up to 32 registers,; numbered from 0 through 31, inclusive. The register number R corresponds to; the N in the operation name. They have a single signed LEB128 integer operand that represents a byte; displacement B. The address space identifier AS is defined as the one cor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:114632,efficient,efficient,114632,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['efficient'],['efficient']
Energy Efficiency,"and to convert this address to a flat address by adding the flat; scratch aperture base address. The swizzled SP value is always 4 bytes aligned for the ``r600``; architecture and 16 byte aligned for the ``amdgcn`` architecture. .. note::. The ``amdgcn`` value is selected to avoid dynamic stack alignment for the; OpenCL language which has the largest base type defined as 16 bytes. On entry, the swizzled SP value is the address of the first function; argument passed on the stack. Other stack passed arguments are positive; offsets from the entry swizzled SP value. The function may use positive offsets beyond the last stack passed argument; for stack allocated local variables and register spill slots. If necessary,; the function may align these to greater alignment than 16 bytes. After these; the function may dynamically allocate space for such things as runtime sized; ``alloca`` local allocations. If the function calls another function, it will place any stack allocated; arguments after the last local allocation and adjust SGPR32 to the address; after the last local allocation. 9. All other registers are unspecified.; 10. Any necessary ``s_waitcnt`` has been performed to ensure memory is available; to the function.; 11. Use pass-by-reference (byref) in stead of pass-by-value (byval) for struct; arguments in C ABI. Callee is responsible for allocating stack memory and; copying the value of the struct if modified. Note that the backend still; supports byval for struct arguments. On exit from a function:. 1. VGPR0-31 and SGPR4-29 are used to pass function result arguments as; described below. Any registers used are considered clobbered registers.; 2. The following registers are preserved and have the same value as on entry:. * FLAT_SCRATCH; * EXEC; * GFX6-GFX8: M0; * All SGPR registers except the clobbered registers of SGPR4-31.; * VGPR40-47; * VGPR56-63; * VGPR72-79; * VGPR88-95; * VGPR104-111; * VGPR120-127; * VGPR136-143; * VGPR152-159; * VGPR168-175; * VGPR184-191; *",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:389679,allocate,allocated,389679,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"and. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smax``' intrinsic performs the signed-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.smax <int_vector_reduce_smax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MIN`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smax.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 -128, i8 -128, i8 -128, i8 -128>; %reduction = call i8 @llvm.vector.reduce.smax.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smax.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_smin:. '``llvm.vp.reduce.smin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:764672,reduce,reduce,764672,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,ang/lib/Parser/parse-tree.cpp; flang/lib/Parser/parsing.cpp; flang/lib/Parser/preprocessor.cpp; flang/lib/Parser/preprocessor.h; flang/lib/Parser/prescan.cpp; flang/lib/Parser/prescan.h; flang/lib/Parser/program-parsers.cpp; flang/lib/Parser/provenance.cpp; flang/lib/Parser/source.cpp; flang/lib/Parser/stmt-parser.h; flang/lib/Parser/token-parsers.h; flang/lib/Parser/token-sequence.cpp; flang/lib/Parser/token-sequence.h; flang/lib/Parser/tools.cpp; flang/lib/Parser/type-parser-implementation.h; flang/lib/Parser/type-parsers.h; flang/lib/Parser/unparse.cpp; flang/lib/Parser/user-state.cpp; flang/lib/Semantics/assignment.cpp; flang/lib/Semantics/assignment.h; flang/lib/Semantics/attr.cpp; flang/lib/Semantics/canonicalize-acc.cpp; flang/lib/Semantics/canonicalize-acc.h; flang/lib/Semantics/canonicalize-do.cpp; flang/lib/Semantics/canonicalize-do.h; flang/lib/Semantics/canonicalize-omp.cpp; flang/lib/Semantics/canonicalize-omp.h; flang/lib/Semantics/check-acc-structure.cpp; flang/lib/Semantics/check-allocate.cpp; flang/lib/Semantics/check-allocate.h; flang/lib/Semantics/check-arithmeticif.cpp; flang/lib/Semantics/check-arithmeticif.h; flang/lib/Semantics/check-call.h; flang/lib/Semantics/check-case.cpp; flang/lib/Semantics/check-case.h; flang/lib/Semantics/check-coarray.cpp; flang/lib/Semantics/check-coarray.h; flang/lib/Semantics/check-data.cpp; flang/lib/Semantics/check-data.h; flang/lib/Semantics/check-deallocate.cpp; flang/lib/Semantics/check-deallocate.h; flang/lib/Semantics/check-declarations.h; flang/lib/Semantics/check-directive-structure.h; flang/lib/Semantics/check-do-forall.cpp; flang/lib/Semantics/check-do-forall.h; flang/lib/Semantics/check-if-stmt.cpp; flang/lib/Semantics/check-if-stmt.h; flang/lib/Semantics/check-io.cpp; flang/lib/Semantics/check-io.h; flang/lib/Semantics/check-namelist.cpp; flang/lib/Semantics/check-namelist.h; flang/lib/Semantics/check-nullify.cpp; flang/lib/Semantics/check-nullify.h; flang/lib/Semantics/check-omp-structure.cpp; flang/l,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:121848,allocate,allocate,121848,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['allocate'],['allocate']
Energy Efficiency,"anges to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ; RUN: split-file %s %t; ; RUN: llvm-link -S %t/a.ll %t/b.ll | FileCheck %s. ; CHECK: ... ;--- a.ll; ...; ;--- b.ll; ... The parts are separated by the regex ``^(.|//)--- ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:14053,reduce,reduce,14053,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['reduce'],['reduce']
Energy Efficiency,"any convenient boundary compatible with the type. '``type``' may be any sized type. Structs containing scalable vectors cannot be used in allocas unless all; fields are the same scalable vector type (e.g. ``{<vscale x 2 x i32>,; <vscale x 2 x i32>}`` contains the same type while ``{<vscale x 2 x i32>,; <vscale x 2 x i64>}`` doesn't). Semantics:; """""""""""""""""""". Memory is allocated; a pointer is returned. The allocated memory is; uninitialized, and loading from uninitialized memory produces an undefined; value. The operation itself is undefined if there is insufficient stack; space for the allocation.'``alloca``'d memory is automatically released; when the function returns. The '``alloca``' instruction is commonly used; to represent automatic variables that must have an address available. When; the function returns (either with the ``ret`` or ``resume`` instructions),; the memory is reclaimed. Allocating zero bytes is legal, but the returned; pointer may not be unique. The order in which memory is allocated (ie.,; which way the stack grows) is not specified. Note that '``alloca``' outside of the alloca address space from the; :ref:`datalayout string<langref_datalayout>` is meaningful only if the; target has assigned it a semantics. If the returned pointer is used by :ref:`llvm.lifetime.start <int_lifestart>`,; the returned object is initially dead.; See :ref:`llvm.lifetime.start <int_lifestart>` and; :ref:`llvm.lifetime.end <int_lifeend>` for the precise semantics of; lifetime-manipulating intrinsics. Example:; """""""""""""""". .. code-block:: llvm. %ptr = alloca i32 ; yields ptr; %ptr = alloca i32, i32 4 ; yields ptr; %ptr = alloca i32, i32 4, align 1024 ; yields ptr; %ptr = alloca i32, align 1024 ; yields ptr. .. _i_load:. '``load``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = load [volatile] <ty>, ptr <pointer>[, align <alignment>][, !nontemporal !<nontemp_node>][, !invariant.load !<empty_node>][, !invariant.group !<empty_node>][, !nonnull !<empty_n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:411088,allocate,allocated,411088,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"apRecord will be empty for a statepoint; record. Safepoint Semantics & Verification; ==================================. The fundamental correctness property for the compiled code's; correctness w.r.t. the garbage collector is a dynamic one. It must be; the case that there is no dynamic trace such that an operation; involving a potentially relocated pointer is observably-after a; safepoint which could relocate it. 'observably-after' is this usage; means that an outside observer could observe this sequence of events; in a way which precludes the operation being performed before the; safepoint. To understand why this 'observable-after' property is required,; consider a null comparison performed on the original copy of a; relocated pointer. Assuming that control flow follows the safepoint,; there is no way to observe externally whether the null comparison is; performed before or after the safepoint. (Remember, the original; Value is unmodified by the safepoint.) The compiler is free to make; either scheduling choice. The actual correctness property implemented is slightly stronger than; this. We require that there be no *static path* on which a; potentially relocated pointer is 'observably-after' it may have been; relocated. This is slightly stronger than is strictly necessary (and; thus may disallow some otherwise valid programs), but greatly; simplifies reasoning about correctness of the compiled code. By construction, this property will be upheld by the optimizer if; correctly established in the source IR. This is a key invariant of; the design. The existing IR Verifier pass has been extended to check most of the; local restrictions on the intrinsics mentioned in their respective; documentation. The current implementation in LLVM does not check the; key relocation invariant, but this is ongoing work on developing such; a verifier. Please ask on llvm-dev if you're interested in; experimenting with the current version. .. _statepoint-utilities:. Utility Passes for Safe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:24225,schedul,scheduling,24225,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['schedul'],['scheduling']
Energy Efficiency,"arameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43375,schedul,scheduled,43375,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency,"are defined in; :ref:`amdgpu-amdhsa-floating-point-denorm-mode-enumeration-values-table`. Used by CP to set up; ``COMPUTE_PGM_RSRC1.FLOAT_MODE``.; 19:18 2 bits FLOAT_DENORM_MODE_16_64 Wavefront starts execution; with specified denorm mode; for half/double (16; and 64-bit) floating point; precision floating point; operations. Floating point denorm mode; values are defined in; :ref:`amdgpu-amdhsa-floating-point-denorm-mode-enumeration-values-table`. Used by CP to set up; ``COMPUTE_PGM_RSRC1.FLOAT_MODE``.; 20 1 bit PRIV Must be 0. Start executing wavefront; in privilege trap handler; mode. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.PRIV``.; 21 1 bit ENABLE_DX10_CLAMP GFX9-GFX11; Wavefront starts execution; with DX10 clamp mode; enabled. Used by the vector; ALU to force DX10 style; treatment of NaN's (when; set, clamp NaN to zero,; otherwise pass NaN; through). Used by CP to set up; ``COMPUTE_PGM_RSRC1.DX10_CLAMP``.; WG_RR_EN GFX12; If 1, wavefronts are scheduled; in a round-robin fashion with; respect to the other wavefronts; of the SIMD. Otherwise, wavefronts; are scheduled in oldest age order. CP is responsible for filling in; ``COMPUTE_PGM_RSRC1.WG_RR_EN``.; 22 1 bit DEBUG_MODE Must be 0. Start executing wavefront; in single step mode. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.DEBUG_MODE``.; 23 1 bit ENABLE_IEEE_MODE GFX9-GFX11; Wavefront starts execution; with IEEE mode; enabled. Floating point; opcodes that support; exception flag gathering; will quiet and propagate; signaling-NaN inputs per; IEEE 754-2008. Min_dx10 and; max_dx10 become IEEE; 754-2008 compliant due to; signaling-NaN propagation; and quieting. Used by CP to set up; ``COMPUTE_PGM_RSRC1.IEEE_MODE``.; DISABLE_PERF GFX12; Reserved. Must be 0.; 24 1 bit BULKY Must be 0. Only one work-group allowed; to execute on a compute; unit. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.BULKY``.; 25 1 bit CDBG_USER Must be 0. Flag that can be used to; control debugging code. CP is r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:167618,schedul,scheduled,167618,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency,"are exhausted, consistently with other interfaces. See [#6518](https://github.com/root-project/root/issues/6518) for more details.; - `TTreeProcessorMT::SetMaxTasksPerFilePerWorker` is now deprecated in favor of the more flexible and newly introduced `TTreeProcessorMT::SetTasksPerWorkerHint`. See the relevant entries in our reference guide for more information.; - The name of the sub-branches of a split collection no longer have 2 consecutive dots if the top level branche name has a trailing dot. The name of the collection's index leaf also no longer include the dot. For example for ""t."" the names where ""t._"" and ""t..fValue"" and are now ""t_"" and ""t.fValue"". . ## RDataFrame. ### New features. - Introduce `ROOT::RDF::RunGraphs`, which allows to compute the results of multiple `RDataFrame`s (or better, multiple independent computation graphs) concurrently while sharing the same thread pool. The computation may be more efficient than running the `RDataFrame`s sequentially if an analysis consists of several computation graphs that individually do not fully utilize the available resources. See e.g. [this tutorial](https://root.cern/doc/master/df104__HiggsToTwoPhotons_8py.html) for an example usage.; - `RDataFrame` now supports reading friend `TTree`s with a `TTreeIndex`, aka ""indexed friends"". More details at [ROOT-9559](https://sft.its.cern.ch/jira/browse/ROOT-9559).; - Experimental logging capabilities have been added to `RDataFrame`. To activate logging, define the following variable before creating the `RDataFrame` object: `auto verbosity = ROOT::Experimental::RLogScopedVerbosity(ROOT::Detail::RDF::RDFLogChannel(), ROOT::Experimental::ELogLevel.kInfo);`.; - With [ROOT-10023](https://sft.its.cern.ch/jira/browse/ROOT-10023) fixed, `RDataFrame` can now read and write certain branches containing unsplit objects, i.e. `TBranchObjects`. More information is available at [ROOT-10022](https://sft.its.cern.ch/jira/browse/ROOT-10022).; - CSV files can now be opened and processed",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:5949,efficient,efficient,5949,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['efficient'],['efficient']
Energy Efficiency,"are treated as containing the neutral value ``1`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is the; start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.mul.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 1, i32 1, i32 1, i32 1>; %reduction = call i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %masked.a); %also.r = mul i32 %reduction, %start. .. _int_vp_reduce_fmul:. '``llvm.vp.reduce.fmul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmul.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fmul.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MUL`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmul``' intrinsic performs the floating-point ``MUL``; reduction (:ref:`llvm.vector.reduce.fmul <int_vector_reduce_fmul>`) of the; vector operand ``val`` on each enabled lane, multiplying i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:754744,reduce,reduce,754744,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"art of the **--args** option, not as; options to **bugpoint** itself. **--tool-args** *tool args*. Pass all arguments specified after **--tool-args** to the LLVM tool under test; (**llc**, **lli**, etc.) whenever it runs. You should use this option in the; following way:. .. code-block:: bash. bugpoint [bugpoint args] --tool-args -- [tool args]. The ""``--``"" right after the **--tool-args** option tells **bugpoint** to; consider any options starting with ""``-``"" to be part of the **--tool-args**; option, not as options to **bugpoint** itself. (See **--args**, above.). **--safe-tool-args** *tool args*. Pass all arguments specified after **--safe-tool-args** to the ""safe"" execution; tool. **--gcc-tool-args** *gcc tool args*. Pass all arguments specified after **--gcc-tool-args** to the invocation of; **gcc**. **--opt-args** *opt args*. Pass all arguments specified after **--opt-args** to the invocation of **opt**. **--disable-{dce,simplifycfg}**. Do not run the specified passes to clean up and reduce the size of the test; program. By default, **bugpoint** uses these passes internally when attempting to; reduce test programs. If you're trying to find a bug in one of these passes,; **bugpoint** may crash. **--enable-valgrind**. Use valgrind to find faults in the optimization phase. This will allow; bugpoint to find otherwise asymptomatic problems caused by memory; mis-management. **-find-bugs**. Continually randomize the specified passes and run them on the test program; until a bug is found or the user kills **bugpoint**. **-help**. Print a summary of command line options. **--input** *filename*. Open *filename* and redirect the standard input of the test program, whenever; it runs, to come from that file. **--load** *plugin*. Load the dynamic object *plugin* into **bugpoint** itself. This object should; register new optimization passes. Once loaded, the object will add new command; line options to enable various optimizations. To see the new complete list of; optimizat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst:2566,reduce,reduce,2566,interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,1,['reduce'],['reduce']
Energy Efficiency,"art. Otherwise; the reduction will be *sequential*, thus implying that the operation respects; the associativity of a scalarized reduction. That is, the reduction begins with; the start value and performs an fmul operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fmul(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result * input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, one (``1.0``) can be used, as it is the neutral; value of floating point multiplication. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fmul.v4f32(float 1.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_and:. '``llvm.vector.reduce.and.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.and.*``' intrinsics do a bitwise ``AND``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_or:. '``llvm.vector.reduce.or.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scalar. The return type matches the; element-type of the vector input. Arguments:; """"""""""""""""""""; The argumen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:654867,reduce,reduce,654867,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ary's; complete source code as you receive it, in any medium, provided that; you conspicuously and appropriately publish on each copy an; appropriate copyright notice and disclaimer of warranty; keep intact; all the notices that refer to this License and to the absence of any; warranty; and distribute a copy of this License along with the; Library. You may charge a fee for the physical act of transferring a copy,; and you may at your option offer warranty protection in exchange for a; fee. 2. You may modify your copy or copies of the Library or any portion; of it, thus forming a work based on the Library, and copy and; distribute such modifications or work under the terms of Section 1; above, provided that you also meet all of these conditions:. a) The modified work must itself be a software library. b) You must cause the files modified to carry prominent notices; stating that you changed the files and the date of any change. c) You must cause the whole of the work to be licensed at no; charge to all third parties under the terms of this License. d) If a facility in the modified Library refers to a function or a; table of data to be supplied by an application program that uses; the facility, other than as an argument passed when the facility; is invoked, then you must make a good faith effort to ensure that,; in the event an application does not supply such function or; table, the facility still operates, and performs whatever part of; its purpose remains meaningful. (For example, a function in a library to compute square roots has; a purpose that is entirely well-defined independent of the; application. Therefore, Subsection 2d requires that any; application-supplied function or table used by this function must; be optional: if the application does not supply it, the square; root function must still compute square roots.). These requirements apply to the modified work as a whole. If; identifiable sections of that work are not derived from the Library,; and can be re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/LICENSE.TXT:11142,charge,charge,11142,interpreter/cling/LICENSE.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/LICENSE.TXT,1,['charge'],['charge']
Energy Efficiency,as < /dev/null | llc -march=xyz -mattr=help**. FLOATING POINT OPTIONS; ----------------------. .. option:: -disable-excess-fp-precision. Disable optimizations that may increase floating point precision. .. option:: -enable-no-infs-fp-math. Enable optimizations that assume no Inf values. .. option:: -enable-no-nans-fp-math. Enable optimizations that assume no NAN values. .. option:: -enable-unsafe-fp-math. Causes :program:`lli` to enable optimizations that may decrease floating point; precision. .. option:: -soft-float. Causes :program:`lli` to generate software floating point library calls instead of; equivalent hardware instructions. CODE GENERATION OPTIONS; -----------------------. .. option:: -code-model=model. Choose the code model from:. .. code-block:: text. default: Target default code model; tiny: Tiny code model; small: Small code model; kernel: Kernel code model; medium: Medium code model; large: Large code model. .. option:: -disable-post-RA-scheduler. Disable scheduling after register allocation. .. option:: -disable-spill-fusing. Disable fusing of spill code into instructions. .. option:: -jit-enable-eh. Exception handling should be enabled in the just-in-time compiler. .. option:: -join-liveintervals. Coalesce copies (default=true). .. option:: -nozero-initialized-in-bss. Don't place zero-initialized symbols into the BSS section. .. option:: -pre-RA-sched=scheduler. Instruction schedulers available (before register allocation):. .. code-block:: text. =default: Best scheduler for the target; =none: No scheduling: breadth first sequencing; =simple: Simple two pass scheduling: minimize critical path and maximize processor utilization; =simple-noitin: Simple two pass scheduling: Same as simple except using generic latency; =list-burr: Bottom-up register reduction list scheduling; =list-tdrr: Top-down register reduction list scheduling; =list-td: Top-down list scheduler. .. option:: -regalloc=allocator. Register allocator to use (default=linearscan). .. cod,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst:3850,schedul,scheduling,3850,interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,1,['schedul'],['scheduling']
Energy Efficiency,"as a; warning of an arbitrary expression using the function above. Example usage::. void foo() {; int x = 1;; clang_analyzer_hashDump(x); // expected-warning{{hashed string for x}}; }. - ``void clang_analyzer_denote(int, const char *);``. Denotes symbols with strings. A subsequent call to clang_analyzer_express(); will expresses another symbol in terms of these string. Useful for testing; relationships between different symbols. Example usage::. void foo(int x) {; clang_analyzer_denote(x, ""$x"");; clang_analyzer_express(x + 1); // expected-warning{{$x + 1}}; }. - ``void clang_analyzer_express(int);``. See clang_analyzer_denote(). - ``void clang_analyzer_isTainted(a single argument of any type);``. Queries the analyzer whether the expression used as argument is tainted or not.; This is useful in tests, where we don't want to issue warning for all tainted; expressions but only check for certain expressions.; This would help to reduce the *noise* that the `TaintTest` debug checker would; introduce and let you focus on the `expected-warning`'s that you really care; about. Example usage::. int read_integer() {; int n;; clang_analyzer_isTainted(n); // expected-warning{{NO}}; scanf(""%d"", &n);; clang_analyzer_isTainted(n); // expected-warning{{YES}}; clang_analyzer_isTainted(n + 2); // expected-warning{{YES}}; clang_analyzer_isTainted(n > 0); // expected-warning{{YES}}; int next_tainted_value = n; // no-warning; return n;; }. - ``clang_analyzer_dumpExtent(a single argument of any type)``; - ``clang_analyzer_dumpElementCount(a single argument of any type)``. Dumps out the extent and the element count of the argument. Example usage::. void array() {; int a[] = {1, 3};; clang_analyzer_dumpExtent(a); // expected-warning {{8 S64b}}; clang_analyzer_dumpElementCount(a); // expected-warning {{2 S64b}}; }. - ``clang_analyzer_value(a single argument of integer or pointer type)``. Prints an associated value for the given argument.; Supported argument types are integers, enums and point",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/DebugChecks.rst:9876,reduce,reduce,9876,interpreter/llvm-project/clang/docs/analyzer/developer-docs/DebugChecks.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/DebugChecks.rst,1,['reduce'],['reduce']
Energy Efficiency,"as been performed to ensure memory is available; to the function.; 11. Use pass-by-reference (byref) in stead of pass-by-value (byval) for struct; arguments in C ABI. Callee is responsible for allocating stack memory and; copying the value of the struct if modified. Note that the backend still; supports byval for struct arguments. On exit from a function:. 1. VGPR0-31 and SGPR4-29 are used to pass function result arguments as; described below. Any registers used are considered clobbered registers.; 2. The following registers are preserved and have the same value as on entry:. * FLAT_SCRATCH; * EXEC; * GFX6-GFX8: M0; * All SGPR registers except the clobbered registers of SGPR4-31.; * VGPR40-47; * VGPR56-63; * VGPR72-79; * VGPR88-95; * VGPR104-111; * VGPR120-127; * VGPR136-143; * VGPR152-159; * VGPR168-175; * VGPR184-191; * VGPR200-207; * VGPR216-223; * VGPR232-239; * VGPR248-255. .. note::. Except the argument registers, the VGPRs clobbered and the preserved; registers are intermixed at regular intervals in order to keep a; similar ratio independent of the number of allocated VGPRs. * GFX90A: All AGPR registers except the clobbered registers AGPR0-31.; * Lanes of all VGPRs that are inactive at the call site. For the AMDGPU backend, an inter-procedural register allocation (IPRA); optimization may mark some of clobbered SGPR and VGPR registers as; preserved if it can be determined that the called function does not change; their value. 2. The PC is set to the RA provided on entry.; 3. MODE register: *TBD*.; 4. All other registers are clobbered.; 5. Any necessary ``s_waitcnt`` has been performed to ensure memory accessed by; function is available to the caller. .. TODO::. - How are function results returned? The address of structured types is passed; by reference, but what about other types?. The function input arguments are made up of the formal arguments explicitly; declared by the source language function plus the implicit input arguments used; by the implementation. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:390955,allocate,allocated,390955,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"as libHist, have a direct dependency on the Mathcore library.; Linking with libMathCore is therefore required for running any major ROOT application. It has been added to the list of libraries obtained when doing root-config --libs. N.B.: users building ROOT applications and not using root-config MUST add libMathCore to their list of linking libraries. Together with the libraries merge, many changes have been applied to both TMath and the other mathcore classes.; TMath; A major clean-up and re-structuring has been done for the functions present in TMath. Some functions have been implemented using the STL algorithms, which have better performances in term of CPU time and a template interface has been also added.; Some of the basic special mathematical functions of TMath, like the error function or the gamma and beta functions use now the Cephes implementation from Stephen L. Moshier, which is used as well by the ROOT::Math functions. This implementation has been found to be more accurate and in some cases more efficient in term of CPU time. More detailed information on the new mathematical functions can be found in this presentation from M. Slawinska at a ROOT team meeting. define the functions as template functions instead of having the same re-definition for all the various basic types. This is done for TMath::Mean,TMath::GeomMean, TMath::Median, TMath::KOrdStat; Use STL to implement the following algorithms:; ; TMath::Sort is re-implemented using std::sort.; TMath::BinarySearch is re-implemented using the STL algorithm std::lower_bound. The STL algorithms have been found for these cases to be perform better in term of CPU time. For some other algorithms like TMath::LocMin, TMath::LocMax or TMath::Permute the original implementation is faster than STL and has been maintained.; ; Add a generic iterator interface, similar to the STL algorithm interface, to the following TMath functions:; MinElement, MaxElement, LocMin, LocMax, Mean, GeomMean, RMS,; BinarySearch. The i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v520/index.html:1341,efficient,efficient,1341,math/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v520/index.html,1,['efficient'],['efficient']
Energy Efficiency,"ased. The key part of the **`TKey`** is kept. ![A diagram of a streamed TH1F in the buffer](pictures/020000EB.jpg). The key consumes about 60 bytes, whereas the buffer, since it contains; the object data, can be very large. ### Ignore Object Streamers. Your class can ignore the **`TObject`** `Streamer `with the; `MyClass->Class::IgnoreObjectStreamer()` method. When the class; `kIgnoreTObjectStreamer `bit is set (by calling the; `IgnoreTObjectStreamer `method`)`, the automatically generated; `Streamer `will not call `TObject::Streamer`, and the **`TObject`** part; of the class is not streamed to the file. This is useful in case you do; not use the **`TObject`** `fBits` and `fUniqueID `data members. You gain; space on the file, and you do not loose functionality if you do not use; the `fBits` and `fUniqueID. `See ""The Role of TObject"" on the use of; `fBits` and `fUniqueID`. ### Streaming a TClonesArray. When writing a **`TClonesArray`** it bypasses by default the; `Streamer `of the member class and uses a more efficient internal; mechanism to write the members to the file. You can override the default; and specify that the member class `Streamer `is used by setting the; `TClonesArray::BypassStreamer` bit to false:. ``` {.cpp}; TClonesArray *fTracks;; fTracks->BypassStreamer(kFALSE); // use the member Streamer; ```. When the `kBypassStreamer` bit is set, the automatically generated; `Streamer `can call directly the method **`TClass::WriteBuffer`**.; Bypassing the `Streamer` improves the performance when writing/reading; the objects in the **`TClonesArray`**. However, the drawback is when a; **`TClonesArray`** is written with `split=0` bypassing the `Streamer`,; the `StreamerInfo `of the class in the array being optimized, one cannot; later use the **`TClonesArray`** with `split > 0`. For example, there is; a problem with the following scenario: a class `Foo` has a; **`TClonesArray`** of `Bar` objects the `Foo` object is written with; `split=0` to `Tree` `T1`. In this ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:53545,efficient,efficient,53545,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['efficient'],['efficient']
Energy Efficiency,"asing; vector element indices. See the following pseudocode:. ::. float sequential_fadd(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result + input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, negative zero (``-0.0``) can be used, as it is; the neutral value of floating point addition. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fadd.v4f32(float -0.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_mul:. '``llvm.vector.reduce.mul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.mul.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.mul.*``' intrinsics do an integer ``MUL``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmul:. '``llvm.vector.reduce.fmul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fmul.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmul.*``' intrinsics do a floating-point; ``MUL`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:652815,reduce,reduce,652815,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"asses are called on the graph before it is pruned. At this stage; ``LinkGraph`` nodes still have their original vmaddrs. A mark-live pass; (supplied by the ``JITLinkContext``) will be run at the end of this; sequence to mark the initial set of live symbols. Notable use cases: marking nodes live, accessing/copying graph data that; will be pruned (e.g. metadata that's important for the JIT, but not needed; for the link process). #. Prune (dead-strip) the ``LinkGraph``. Removes all symbols and blocks not reachable from the initial set of live; symbols. This allows JITLink to remove unreachable symbols / content, including; overridden weak and redundant ODR definitions. #. Run post-prune passes. These passes are run on the graph after dead-stripping, but before memory; is allocated or nodes assigned their final target vmaddrs. Passes run at this stage benefit from pruning, as dead functions and data; have been stripped from the graph. However new content can still be added; to the graph, as target and working memory have not been allocated yet. Notable use cases: Building Global Offset Table (GOT), Procedure Linkage; Table (PLT), and Thread Local Variable (TLV) entries. #. Asynchronously allocate memory. Calls the ``JITLinkContext``'s ``JITLinkMemoryManager`` to allocate both; working and target memory for the graph. As part of this process the; ``JITLinkMemoryManager`` will update the addresses of all nodes; defined in the graph to their assigned target address. Note: This step only updates the addresses of nodes defined in this graph.; External symbols will still have null addresses. #. Phase 2. #. Run post-allocation passes. These passes are run on the graph after working and target memory have; been allocated, but before the ``JITLinkContext`` is notified of the; final addresses of the symbols in the graph. This gives these passes a; chance to set up data structures associated with target addresses before; any JITLink clients (especially ORC queries for symbol resol",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:19070,allocate,allocated,19070,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['allocate'],['allocated']
Energy Efficiency,"asses you will encounter in this tutorial; have such graphical interfaces. We will not comment further on this,; just be aware of the existence of ROOT's interactive features and use; them if you find them convenient. Some trial-and-error is certainly necessary; to find your way through the huge number of menus and parameter; settings. ## ROOT Beginners' FAQ ##. At this point of the guide, some basic questions could have already come; to your mind. We will try to clarify some of them with further; explanations in the following. ### ROOT type declarations for basic data types ###. In the official ROOT documentation, you find special data types; replacing the normal ones, e.g. `Double_t`, `Float_t` or `Int_t`; replacing the standard `double`, `float` or `int` types. Using the ROOT; types makes it easier to port code between platforms (64/32 bit) or; operating systems (windows/Linux), as these types are mapped to suitable; ones in the ROOT header files. If you want adaptive code of this type,; use the ROOT type declarations. However, usually you do not need such; adaptive code, and you can safely use the standard C type declarations; for your private code, as we did and will do throughout this guide. If; you intend to become a ROOT developer, however, you better stick to the; official coding rules!. ### Configure ROOT at start-up ###. The behaviour of a ROOT session can be tailored with the options in the; `.rootrc` file. Examples of the tunable parameters are the ones related; to the operating and window system, to the fonts to be used, to the; location of start-up files. At start-up, ROOT looks for a `.rootrc` file; in the following order:. - `./.rootrc //local directory`. - `$HOME/.rootrc //user directory`. - `$ROOTSYS/etc/system.rootrc //global ROOT directory`. If more than one `.rootrc` files are found in the search paths above,; the options are merged, with precedence local, user, global. The parsing; and interpretation of this file is handled by the ROOT class `T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md:17533,adapt,adaptive,17533,documentation/primer/ROOT_as_calculator.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md,1,['adapt'],['adaptive']
Energy Efficiency,"at @llvm.vector.reduce.fadd.v4f32(float -0.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_mul:. '``llvm.vector.reduce.mul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.mul.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.mul.*``' intrinsics do an integer ``MUL``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmul:. '``llvm.vector.reduce.fmul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fmul.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmul.*``' intrinsics do a floating-point; ``MUL`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. Otherwise; the reduction will be *sequential*, thus implying that the operation respects; the associativity of a scalarized reduction. That is, the reduction begins with; the start value and performs an fmul operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fmul(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result * input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:653453,reduce,reduce,653453,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"at least) one heap allocation and free per iteration of the; loop. .. _dss_deque:. <deque>; ^^^^^^^. ``std::deque`` is, in some senses, a generalized version of ``std::vector``.; Like ``std::vector``, it provides constant time random access and other similar; properties, but it also provides efficient access to the front of the list. It; does not guarantee continuity of elements within memory. In exchange for this extra flexibility, ``std::deque`` has significantly higher; constant factor costs than ``std::vector``. If possible, use ``std::vector`` or; something cheaper. .. _dss_list:. <list>; ^^^^^^. ``std::list`` is an extremely inefficient class that is rarely useful. It; performs a heap allocation for every element inserted into it, thus having an; extremely high constant factor, particularly for small data types.; ``std::list`` also only supports bidirectional iteration, not random access; iteration. In exchange for this high cost, std::list supports efficient access to both ends; of the list (like ``std::deque``, but unlike ``std::vector`` or; ``SmallVector``). In addition, the iterator invalidation characteristics of; std::list are stronger than that of a vector class: inserting or removing an; element into the list does not invalidate iterator or pointers to other elements; in the list. .. _dss_ilist:. llvm/ADT/ilist.h; ^^^^^^^^^^^^^^^^. ``ilist<T>`` implements an 'intrusive' doubly-linked list. It is intrusive,; because it requires the element to store and provide access to the prev/next; pointers for the list. ``ilist`` has the same drawbacks as ``std::list``, and additionally requires an; ``ilist_traits`` implementation for the element type, but it provides some novel; characteristics. In particular, it can efficiently store polymorphic objects,; the traits class is informed when an element is inserted or removed from the; list, and ``ilist``\ s are guaranteed to support a constant-time splice; operation. An ``ilist`` and an ``iplist`` are ``using`` aliase",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:66217,efficient,efficient,66217,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"at mimic STL classes can have member names in STL's; style of lower-case words separated by underscores (e.g. ``begin()``,; ``push_back()``, and ``empty()``). Classes that provide multiple; iterators should add a singular prefix to ``begin()`` and ``end()``; (e.g. ``global_begin()`` and ``use_begin()``). Here are some examples:. .. code-block:: c++. class VehicleMaker {; ...; Factory<Tire> F; // Avoid: a non-descriptive abbreviation.; Factory<Tire> Factory; // Better: more descriptive.; Factory<Tire> TireFactory; // Even better: if VehicleMaker has more than one; // kind of factories.; };. Vehicle makeVehicle(VehicleType Type) {; VehicleMaker M; // Might be OK if scope is small.; Tire Tmp1 = M.makeTire(); // Avoid: 'Tmp1' provides no information.; Light Headlight = M.makeLight(""head""); // Good: descriptive.; ...; }. Assert Liberally; ^^^^^^^^^^^^^^^^. Use the ""``assert``"" macro to its fullest. Check all of your preconditions and; assumptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:45170,reduce,reduces,45170,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['reduce'],['reduces']
Energy Efficiency,"at sigma,; int threshold,; bool markov,; int aver_window);; ```. This function searches for peaks in the source spectrum. The number of found; peaks and their positions are written into the structure pointed by the; `one_dim_peak` structure pointer. Function parameters:. - **`spectrum`**: pointer to the vector of the source spectrum. This source spectrum is replaced by the new spectrum calculated using Markov chains method.; - **`size`**: length of the source spectrum; - **`sigma`**: sigma of searched peaks; - **`threshold`**: threshold value for peaks selection; - **`markov`**: logical variable. If it is set to `true`, then the source spectrum is first replaced by the new spectrum calculated using Markov chains method; - **`aver_window`**: averaging window used in the calculation of Markov spectrum, applies only if the `markov` variable was set to `true`. The methods of peak searching are sensitive to the `sigma`. Usually the; `sigma` value is known beforehand. It also changes only slightly with the; energy. We have investigated as well the robustness of the proposed; algorithms to the spectrum with the peaks with `sigma` changing from 1 to; 10 (see Figure 3.6). ![Robustness of the proposed algorithms to the spectrum with the peaks with sigma changing from 1 to 10](figures/image068.png). We applied peak searching algorithm based on Markov approach. We changed; `sigma` in the interval from 1 to 10. The spectra for averaging windows 3,; 5, 10 are shown in Figure 3.7. ![Spectra for averaging windows 3, 5, 10](figures/image070.png). When we applied peak searching function to the Markov spectrum averaged; with the `window=10`, we obtained correct estimate of all 10 peak; positions for `sigma=2,3,4,5,6,7,8`. It was not the case when we made the; same experiment with the original spectrum. For all sigmas some peaks; were not discovered. ## 2-DIMENSIONAL SPECTRA. The basic function of the 2-dimensional peak searching is described in; details in [4]. It automatically identi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:20415,energy,energy,20415,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['energy'],['energy']
Energy Efficiency,"at(""Hello "", Hello:_msg);; }; ------------- Defs -----------------; def HelloWorld { // Hello; string msg = ""Hello world!"";; }; ```; [Try this example on Compiler Explorer.](https://godbolt.org/z/13xo1P5oz). The internalized records are passed on to various backends, which extract; information from a subset of the records and generate one or more output files. These output files are typically .inc files for C++, but may be any type of file; that the backend developer needs. Resources for learning the language:; * [TableGen Overview](https://llvm.org/docs/TableGen/index.html); * [Programmer's reference guide](https://llvm.org/docs/TableGen/ProgRef.html); * [Tutorial](jupyter/tablegen_tutorial_part_1.ipynb); * [Tools for Learning LLVM TableGen](https://blog.llvm.org/posts/2023-12-07-tools-for-learning-llvm-tablegen/); * [Lessons in TableGen](https://www.youtube.com/watch?v=45gmF77JFBY) (video),; [slides](https://archive.fosdem.org/2019/schedule/event/llvm_tablegen/attachments/slides/3304/export/events/attachments/llvm_tablegen/slides/3304/tablegen.pdf); * [Improving Your TableGen Descriptions](https://www.youtube.com/watch?v=dIEVUlsiktQ); (video), [slides](https://llvm.org/devmtg/2019-10/slides/Absar-ImprovingYourTableGenDescription.pdf). Writing TableGen backends:; * [TableGen Backend Developer's Guide](https://llvm.org/docs/TableGen/BackGuide.html); * [How to write a TableGen backend](https://www.youtube.com/watch?v=UP-LBRbvI_U); (video), [slides](https://llvm.org/devmtg/2021-11/slides/2021-how-to-write-a-tablegen-backend.pdf), also available as a; 	[notebook](jupyter/sql_query_backend.ipynb). TableGen in MLIR:; * [Operation Definition Specification](https://mlir.llvm.org/docs/DefiningDialects/Operations/); * [Defining Dialect Attributes and Types](https://mlir.llvm.org/docs/DefiningDialects/AttributesAndTypes/). Useful tools:; * [TableGen Jupyter Kernel](jupyter/); * [TableGen LSP Language Server](https://mlir.llvm.org/docs/Tools/MLIRLSP/#tablegen-lsp-language-serve",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/README.md:1528,schedul,schedule,1528,interpreter/llvm-project/llvm/utils/TableGen/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/README.md,1,['schedul'],['schedule']
Energy Efficiency,"at; all i64 values be expanded into pairs of i32 values. These changes can insert; sign and zero extensions as needed to make sure that the final code has the same; behavior as the input. There are two main ways of converting values of unsupported vector types to; value of supported types: splitting vector types, multiple times if necessary,; until a legal type is found, and extending vector types by adding elements to; the end to round them out to legal types (""widening""). If a vector gets split; all the way down to single-element parts with no supported vector type being; found, the elements are converted to scalars (""scalarizing""). A target implementation tells the legalizer which types are supported (and which; register class to use for them) by calling the ``addRegisterClass`` method in; its ``TargetLowering`` constructor. .. _legalize operations:; .. _Legalizer:. SelectionDAG Legalize Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the operations; that are natively supported by the target. Targets often have weird constraints, such as not supporting every operation on; every supported datatype (e.g. X86 does not support byte conditional moves and; PowerPC does not support sign-extending loads from a 16-bit memory location).; Legalize takes care of this by open-coding another sequence of operations to; emulate the operation (""expansion""), by promoting one type to a larger type that; supports the operation (""promotion""), or by using a target-specific hook to; implement the legalization (""custom""). A target implementation tells the legalizer which operations are not supported; (and which of the above three actions to take) by calling the; ``setOperationAction`` method in its ``TargetLowering`` constructor. If a target has legal vector types, it is expected to produce efficient machine; code for common forms of the shufflevector IR instruction using those types.; This may require custom legalization for SelectionD",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:42419,charge,charge,42419,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['charge'],['charge']
Energy Efficiency,"ate if; it does not interact with the environment in an observable way, and; terminating loops without side-effects can be removed. If a `mustprogress`; function does not satisfy this contract, the behavior is undefined. This; attribute does not apply transitively to callees, but does apply to call; sites within the function. Note that `willreturn` implies `mustprogress`.; ``""warn-stack-size""=""<threshold>""``; This attribute sets a threshold to emit diagnostics once the frame size is; known should the frame size exceed the specified value. It takes one; required integer value, which should be a non-negative integer, and less; than `UINT_MAX`. It's unspecified which threshold will be used when; duplicate definitions are linked together with differing values.; ``vscale_range(<min>[, <max>])``; This function attribute indicates `vscale` is a power-of-two within a; specified range. `min` must be a power-of-two that is greater than 0. When; specified, `max` must be a power-of-two greater-than-or-equal to `min` or 0; to signify an unbounded maximum. The syntax `vscale_range(<val>)` can be; used to set both `min` and `max` to the same value. Functions that don't; include this attribute make no assumptions about the value of `vscale`.; ``""nooutline""``; This attribute indicates that outlining passes should not modify the; function. Call Site Attributes; ----------------------. In addition to function attributes the following call site only; attributes are supported:. ``vector-function-abi-variant``; This attribute can be attached to a :ref:`call <i_call>` to list; the vector functions associated to the function. Notice that the; attribute cannot be attached to a :ref:`invoke <i_invoke>` or a; :ref:`callbr <i_callbr>` instruction. The attribute consists of a; comma separated list of mangled names. The order of the list does; not imply preference (it is logically a set). The compiler is free; to pick any listed vector function of its choosing. The syntax for the mangled names i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:111216,power,power-of-two,111216,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power-of-two']
Energy Efficiency,"ate running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsReal* cdf = pdf.createCdf(x,y) ;. ; As with the similarly styled function createIntegral running integrals and c.d.f. can be created; over any number of observables, e.g createCdf(RooArgSet(x,y,z)) will create a three-dimensional; cumulative distribution function. C.d.f and running integrals that are calculated from p.d.fs that have; support for analytical integration are constructed from an appropriately reconnected RooRealIntegral.; If numeric integration is required, the c.d.f or running integral is calculated by a dedicated class; RooRunningIntegral that precalculates results for all observable values, which is more efficient; in most use cases. Cumulative distributions functions that are calculated numerically are handled slightly differently; that standard running integrals: their values is constructed to converge to exactly zero at the lower bound; and exactly 1 at the upper bound so that algorithms that make use of that property of c.d.f can do so reliably. Constraints management. New tools have been added to simplify studies with fits involving (external) constraints on parameters.; The general philosophy is that constraints on parameters can be represented as probability density functions; and can thus be modeled by RooAbsPdf classes (e.g. a RooGaussian for a simple Gaussian constraint on a parameter).; There are two modes of operation: you can add parameter constraints to your problem definition by multiplying; the constraint p.d.f.s with your 'master' p.d.f. or you specify them externally in each operation. The; first mode of operat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:6227,efficient,efficient,6227,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,1,['efficient'],['efficient']
Energy Efficiency,"ate() function in roofit. In addition, the code is written in a manner that allows for compiler optimizations, notably auto-vectorization. This library is compiled multiple times for different [vector instruction set architectures](https://en.wikipedia.org/wiki/SIMD) and the optimal code is executed during runtime, as a result of an automatic hardware detection mechanism that this library contains. **As a result, fits can benefit by a speedup of 3x-16x.**. As of ROOT v6.26, RooBatchComputes also provides multithread and [CUDA](https://en.wikipedia.org/wiki/CUDA) instances of the computation functions, resulting in even greater improvements for fitting times. ### How to use; This library is an internal component of RooFit, so users are not supposed to actively interact with it. Instead, they can benefit from significantly faster times for fitting by calling `fitTo()` and providing a `BatchMode(""cpu"")` or a `BatchMode(""cuda"")` option.; ``` {.cpp}; // fit using the most efficient library that the computer's CPU can support; RooMyPDF.fitTo(data, BatchMode(""cpu""));. // fit using the CUDA library along with the most efficient library that the computer's CPU can support; RooMyPDF.fitTo(data, BatchMode(""cuda""));; ```; **Note: In case the system does not support vector instructions, the `RooBatchCompute::Cpu` option is guaranteed to work properly by using a generic CPU library. In contrast, users must first make sure that their system supports CUDA in order to use the `RooBatchCompute::Cuda` option. If this is not the case, an exception will be thrown.**. If `""cuda""` is selected, RooFit will launch CUDA kernels for computing likelihoods and potentially other intense computations. At the same time, the most efficient CPU library loaded will also handle parts of the computations in parallel with the GPU (or potentially, if it's faster, all of them), thus gaining full advantage of the available hardware. For this purpose `RooFitDriver`, a newly created RooFit class (in roofitco",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md:1903,efficient,efficient,1903,roofit/doc/developers/batchcompute.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md,1,['efficient'],['efficient']
Energy Efficiency,"ate, and then simulate transitions by analyzing; individual expressions. The analysis of an expression can cause the; state to change, resulting in a new node in the ExplodedGraph with an; updated program point and an updated state. A bug is found by hitting; a node that satisfies some ""bug condition"" (basically a violation of a; checking invariant). The analyzer traces out multiple paths by reasoning about branches and; then bifurcating the state: on the true branch the conditions of the; branch are assumed to be true and on the false branch the conditions; of the branch are assumed to be false. Such ""assumptions"" create; constraints on the values of the program, and those constraints are; recorded in the ProgramState object (and are manipulated by the; ConstraintManager). If assuming the conditions of a branch would; cause the constraints to be unsatisfiable, the branch is considered; infeasible and that path is not taken. This is how we get; path-sensitivity. We reduce exponential blow-up by caching nodes. If; a new node with the same state and program point as an existing node; would get generated, the path ""caches out"" and we simply reuse the; existing node. Thus the ExplodedGraph is not a DAG; it can contain; cycles as paths loop back onto each other and cache out. ProgramState and ExplodedNodes are basically immutable once created. Once; one creates a ProgramState, you need to create a new one to get a new; ProgramState. This immutability is key since the ExplodedGraph represents; the behavior of the analyzed program from the entry point. To; represent these efficiently, we use functional data structures (e.g.,; ImmutableMaps) which share data between instances. Finally, individual Checkers work by also manipulating the analysis; state. The analyzer engine talks to them via a visitor interface.; For example, the PreVisitCallExpr() method is called by ExprEngine; to tell the Checker that we are about to analyze a CallExpr, and the; checker is asked to check fo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt:2404,reduce,reduce,2404,interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt,1,['reduce'],['reduce']
Energy Efficiency,"ates; two files similar to `TTree::MakeClass`. In the resulting files is a class that is a descendent of; **`TSelector`** and implements the following methods:. - `TSelector::Begin()` `-` this method is called every time a loop; over the tree starts. This is a convenient place to create your; histograms. - `TSelector::Notify()` `-` it is called at the first entry of a new; tree in a chain. - `TSelector::Process()` `-` it is called to process an event. It is; the user's responsibility to read the corresponding entry in memory; (may be just a partial read). Once the entry is in memory one can; apply a selection and if the event is selected histograms can be; filled. Processing stops when this function returns `kFALSE`. It; combines the methods **`TSelector::ProcessCut()` and; `TSelector`**`::ProcessFill()` in one, avoiding the necessity to; maintain the state in the class to communicate between these two; functions. It reduces the information that needs to be shared; between them and promotes a more granular data access by reading; branches as they are needed. - `TSelector::Terminate() -` it is called at the end of a loop on a; **`TTree`**. This is a convenient place to draw and fit your; histograms. - `TSelector::Version()` `-` this function provides backward; compatibility for old versions and support for the future upgrades. - The **`TSelector`**, unlike the resulting class from `MakeClass`,; separates the processing into a `ProcessCut()` and `ProcessFill()`,; so we can limit reading of branches to the ones we need. - When a selector is used with a **`TChain`** in methods `Process()`,; `ProcessFill()`, `ProcessCut()`, you must use the pointer to the; current **`TTree`** to call the method `GetEntry(entry)`. The; parameter `entry` is always the local entry number in the current; tree. Assuming that `fChain` is the pointer to the **`TChain`**; being processed, use. ``` {.cpp}; fChain->GetTree()->GetEntry(entry);; ```. To create a selector call:. ``` {.cpp}; root[] T->",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:132486,reduce,reduces,132486,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['reduce'],['reduces']
Energy Efficiency,"ation has completed.; using OnDeallocatedFunction = unique_function<void(Error)>;. /// Call to allocate memory.; virtual void allocate(const JITLinkDylib *JD, LinkGraph &G,; OnAllocatedFunction OnAllocated) = 0;. /// Call to deallocate memory.; virtual void deallocate(std::vector<FinalizedAlloc> Allocs,; OnDeallocatedFunction OnDeallocated) = 0;. The ``allocate`` method takes a ``JITLinkDylib*`` representing the target; simulated dylib, a reference to the ``LinkGraph`` that must be allocated for,; and a callback to run once an ``InFlightAlloc`` has been constructed.; ``JITLinkMemoryManager`` implementations can (optionally) use the ``JD``; argument to manage a per-simulated-dylib memory pool (since code model; constraints are typically imposed on a per-dylib basis, and not across; dylibs) [2]_. The ``LinkGraph`` describes the object file that we need to; allocate memory for. The allocator must allocate working memory for all of; the Blocks defined in the graph, assign address space for each Block within the; executing processes memory, and update the Blocks' addresses to reflect this; assignment. Block content should be copied to working memory, but does not need; to be transferred to executor memory yet (that will be done once the content is; fixed up). ``JITLinkMemoryManager`` implementations can take full; responsibility for these steps, or use the ``BasicLayout`` utility to reduce; the task to allocating working and executor memory for *segments*: chunks of; memory defined by permissions, alignments, content sizes, and zero-fill sizes.; Once the allocation step is complete the memory manager should construct an; ``InFlightAlloc`` object to represent the allocation, and then pass this object; to the ``OnAllocated`` callback. The ``InFlightAlloc`` object has two virtual methods:. .. code-block:: c++. using OnFinalizedFunction = unique_function<void(Expected<FinalizedAlloc>)>;; using OnAbandonedFunction = unique_function<void(Error)>;. /// Called prior to finalizat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:27874,allocate,allocate,27874,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['allocate'],['allocate']
Energy Efficiency,"ation, see ""`llvm/Target/TargetRegistry.h; </doxygen/TargetRegistry_8h-source.html>`_"". Register Set and Register Classes; =================================. You should describe a concrete target-specific class that represents the; register file of a target machine. This class is called ``XXXRegisterInfo``; (where ``XXX`` identifies the target) and represents the class register file; data that is used for register allocation. It also describes the interactions; between registers. You also need to define register classes to categorize related registers. A; register class should be added for groups of registers that are all treated the; same way for some instruction. Typical examples are register classes for; integer, floating-point, or vector registers. A register allocator allows an; instruction to use any register in a specified register class to perform the; instruction in a similar manner. Register classes allocate virtual registers; to instructions from these sets, and register classes let the; target-independent register allocator automatically choose the actual; registers. Much of the code for registers, including register definition, register; aliases, and register classes, is generated by TableGen from; ``XXXRegisterInfo.td`` input files and placed in ``XXXGenRegisterInfo.h.inc``; and ``XXXGenRegisterInfo.inc`` output files. Some of the code in the; implementation of ``XXXRegisterInfo`` requires hand-coding. Defining a Register; -------------------. The ``XXXRegisterInfo.td`` file typically starts with register definitions for; a target machine. The ``Register`` class (specified in ``Target.td``) is used; to define an object for each register. The specified string ``n`` becomes the; ``Name`` of the register. The basic ``Register`` object does not have any; subregisters and does not specify any aliases. .. code-block:: text. class Register<string n> {; string Namespace = """";; string AsmName = n;; string Name = n;; int SpillSize = 0;; int SpillAlignment = 0;; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:14837,allocate,allocate,14837,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['allocate'],['allocate']
Energy Efficiency,"ation: anonymous types are ignored.; For example, the X86 backend defines ``brtarget`` and ``brtarget8``, both; instances of the TableGen ``Operand`` class, which represent branch target; operands:. .. code-block:: text. def brtarget : Operand<OtherVT>;; def brtarget8 : Operand<OtherVT>;. This results in:. .. code-block:: c++. namespace X86 {; namespace OpTypes {; enum OperandType {; ...; brtarget,; brtarget8,; ...; i32imm,; i64imm,; ...; OPERAND_TYPE_LIST_END; } // End namespace OpTypes; } // End namespace X86. In typical TableGen fashion, to use the enum, you will need to define a; preprocessor macro:. .. code-block:: c++. #define GET_INSTRINFO_OPERAND_TYPES_ENUM // For OpTypes enum; #include ""XXXGenInstrInfo.inc"". Instruction Scheduling; ----------------------. Instruction itineraries can be queried using MCDesc::getSchedClass(). The; value can be named by an enumeration in llvm::XXX::Sched namespace generated; by TableGen in XXXGenInstrInfo.inc. The name of the schedule classes are; the same as provided in XXXSchedule.td plus a default NoItinerary class. The schedule models are generated by TableGen by the SubtargetEmitter,; using the ``CodeGenSchedModels`` class. This is distinct from the itinerary; method of specifying machine resource use. The tool ``utils/schedcover.py``; can be used to determine which instructions have been covered by the; schedule model description and which haven't. The first step is to use the; instructions below to create an output file. Then run ``schedcover.py`` on the; output file:. .. code-block:: shell. $ <src>/utils/schedcover.py <build>/lib/Target/AArch64/tblGenSubtarget.with; instruction, default, CortexA53Model, CortexA57Model, CycloneModel, ExynosM3Model, FalkorModel, KryoModel, ThunderX2T99Model, ThunderXT8XModel; ABSv16i8, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_2VXVY_2cyc, KryoWrite_2cyc_XY_XY_150ln, ,; ABSv1i64, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_1VXVY_2cyc, KryoWrite_2cyc_XY_noRSV_67ln, ,; ... To capture",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:42935,schedul,schedule,42935,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['schedul'],['schedule']
Energy Efficiency,"ation; ==================================. .. contents::; :local:; :depth: 1. Internals Introduction; ----------------------. In order to satisfy the stated goals, the driver was designed to; completely subsume the functionality of the gcc executable; that is, the; driver should not need to delegate to gcc to perform subtasks. On; Darwin, this implies that the Clang driver also subsumes the gcc; driver-driver, which is used to implement support for building universal; images (binaries and object files). This also implies that the driver; should be able to call the language specific compilers (e.g. cc1); directly, which means that it must have enough information to forward; command line arguments to child processes correctly. Design Overview; ---------------. The diagram below shows the significant components of the driver; architecture and how they relate to one another. The orange components; represent concrete data structures built by the driver, the green; components indicate conceptually distinct stages which manipulate these; data structures, and the blue components are important helper classes. .. image:: DriverArchitecture.png; :align: center; :alt: Driver Architecture Diagram. Driver Stages; -------------. The driver functionality is conceptually divided into five stages:. #. **Parse: Option Parsing**. The command line argument strings are decomposed into arguments; (``Arg`` instances). The driver expects to understand all available; options, although there is some facility for just passing certain; classes of options through (like ``-Wl,``). Each argument corresponds to exactly one abstract ``Option``; definition, which describes how the option is parsed along with some; additional metadata. The Arg instances themselves are lightweight and; merely contain enough information for clients to determine which; option they correspond to and their values (if they have additional; parameters). For example, a command line like ""-Ifoo -I foo"" would parse to two; Arg ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst:3544,green,green,3544,interpreter/llvm-project/clang/docs/DriverInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst,1,['green'],['green']
Energy Efficiency,"atisfy all cases, ``cppyy`` aims to maximize; functionality and minimum surprises based on common use.; Thus, for example, ``std::vector`` grows a pythonistic ``__len__`` method,; but does not lose its C++ ``size`` method.; Passing a Python container through a const reference to a ``std::vector``; will trigger automatic conversion, but such an attempt through a non-const; reference will fail since a non-temporary C++ object is required [#f1]_ to; return any updates/changes. ``std::string`` is almost always converted to Python's ``str`` on function; returns (the exception is return-by-reference when assigning), but not when; its direct use is more likely such as in the case of (global) variables or; when iterating over a ``std::vector<std::string>``. The rest of this section shows examples of how STL containers can be used in; a natural, pythonistic, way. `std::vector`; -------------. A ``std::vector`` is the most commonly used C++ container type because it is; more efficient and performant than specialized types such as ``list`` and; ``map``, unless the number of elements gets very large.; Python has several similar types, from the builtin ``tuple`` and ``list``,; the ``array`` from builtin module ``array``, to ""as-good-as-builtin""; ``numpy.ndarray``.; A vector is more like the latter two in that it can contain only one type,; but more like the former two in that it can contain objects.; In practice, it can interplay well with all these containers, but e.g.; efficiency and performance can differ significantly. A vector can be instantiated from any sequence, including generators, and; vectors of objects can be recursively constructed.; If the template type is to be inferred from the argument to the constructor,; the first element needs to be accessible, which precludes generators. .. code-block:: python. >>> from cppyy.gbl.std import vector, pair; >>> v = vector[int](range(10)) # from generator; >>> len(v); 10; >>> v = vector([x for x in range(10)]) # type inferred; >",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:2105,efficient,efficient,2105,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,1,['efficient'],['efficient']
Energy Efficiency,"attributes <http://www.graphviz.org/doc/info/attrs.html>`_.); If you want to restart and clear all the current graph attributes, then you can; ``call DAG.clearGraphAttrs()``. Note that graph visualization features are compiled out of Release builds to; reduce file size. This means that you need a Debug+Asserts or Release+Asserts; build to use these features. .. _datastructure:. Picking the Right Data Structure for a Task; ===========================================. LLVM has a plethora of data structures in the ``llvm/ADT/`` directory, and we; commonly use STL data structures. This section describes the trade-offs you; should consider when you pick one. The first step is a choose your own adventure: do you want a sequential; container, a set-like container, or a map-like container? The most important; thing when choosing a container is the algorithmic properties of how you plan to; access the container. Based on that, you should use:. * a :ref:`map-like <ds_map>` container if you need efficient look-up of a; value based on another value. Map-like containers also support efficient; queries for containment (whether a key is in the map). Map-like containers; generally do not support efficient reverse mapping (values to keys). If you; need that, use two maps. Some map-like containers also support efficient; iteration through the keys in sorted order. Map-like containers are the most; expensive sort, only use them if you need one of these capabilities. * a :ref:`set-like <ds_set>` container if you need to put a bunch of stuff into; a container that automatically eliminates duplicates. Some set-like; containers support efficient iteration through the elements in sorted order.; Set-like containers are more expensive than sequential containers. * a :ref:`sequential <ds_sequential>` container provides the most efficient way; to add elements and keeps track of the order they are added to the collection.; They permit duplicates and support efficient iteration, but do not suppor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:55393,efficient,efficient,55393,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"augmented by an extra pointer, which serves; as the back-link of the sentinel. This is the only field in the ghostly; sentinel which can be legally accessed. .. _dss_other:. Other Sequential Container options; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Other STL containers are available, such as ``std::string``. There are also various STL adapter classes such as ``std::queue``,; ``std::priority_queue``, ``std::stack``, etc. These provide simplified access; to an underlying container but don't affect the cost of the container itself. .. _ds_string:. String-like containers; ----------------------. There are a variety of ways to pass around and use strings in C and C++, and; LLVM adds a few new options to choose from. Pick the first option on this list; that will do what you need, they are ordered according to their relative cost. Note that it is generally preferred to *not* pass strings around as ``const; char*``'s. These have a number of problems, including the fact that they; cannot represent embedded nul (""\0"") characters, and do not have a length; available efficiently. The general replacement for '``const char*``' is; StringRef. For more information on choosing string containers for APIs, please see; :ref:`Passing Strings <string_apis>`. .. _dss_stringref:. llvm/ADT/StringRef.h; ^^^^^^^^^^^^^^^^^^^^. The StringRef class is a simple value class that contains a pointer to a; character and a length, and is quite related to the :ref:`ArrayRef; <dss_arrayref>` class (but specialized for arrays of characters). Because; StringRef carries a length with it, it safely handles strings with embedded nul; characters in it, getting the length does not require a strlen call, and it even; has very convenient APIs for slicing and dicing the character range that it; represents. StringRef is ideal for passing simple strings around that are known to be live,; either because they are C string literals, std::string, a C array, or a; SmallVector. Each of these cases has an efficient implicit c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:71443,efficient,efficiently,71443,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficiently']
Energy Efficiency,"aussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). VolumeRangeMode No Adaptive Unscaled, MinMax, RMS, Adaptive, kNN Method to determine volume size. KernelEstimator No Box Box, Sphere, Teepee, Gauss, Sinc3, Sinc5, Sinc7, Sinc9, Sinc11, Lanczos2, Lanczos3, Lanczos5, Lanczos8, Trim Kernel estimation function. DeltaFrac No 3 − nEventsMin/Max for minmax and rms volume range. NEventsMin No 100 − nEventsMin for adaptive volume range. NEventsMax No 200 − nEventsMax for adaptive volume range. MaxVIterations No 150 − MaxVIterations for adaptive volume range. InitialScale No 0.99 − InitialScale for adaptive volume range. GaussSigma No 0.1 − Width (wrt volume size) of Gaussian kernel estimator. NormTree No False − Normalize binary search tree. Configuration options for MVA method :. Configuration options reference for MVA method: FDA. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:4912,adapt,adaptive,4912,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,1,['adapt'],['adaptive']
Energy Efficiency,"ave been run. - Introduce [`ProgressBar`](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#progressbar) feature that can be added to any RDataFrame program. - The `RDatasetSpec` class and its users now employ the concept of 'sample' rather than the original naming 'group' for groups of files with associated metadata. - `df106_HiggsToFourLeptons` tutorials (both python and C++) now showcase the `ProgressBar`. They now use `FromSpec` to define multiple samples and `Vary` for systematic variations. ### Distributed RDataFrame. - Vastly improve runtime performance when using an RDataFrame with simulated dataset, i.e. `RDataFrame(nentries)`, by removing usage of `Range` operation to define the per-task entry range. - Explicitly error out when trying to process a TTree with a TTreeIndex in distributed mode. The feature is currently not supported. - JITting the RDataFrame computation graph now only happens once per worker process, not once per task. This greatly reduces memory usage and runtime overhead at of each task. ## TTree Libraries. ## RNTuple; ROOT's experimental successor of TTree has seen a large number of updates during the last few months. Specifically, v6.30 includes the following changes:. - Support for custom ROOT I/O rules that target transient members of a user-defined class (see PR [#11944](https://github.com/root-project/root/pull/11944)). If a rule only targets transient members and it was working in TTree, it should work unmodified in RNTuple. - Improved support for user-defined classes that behave as a collection. Specifically, RNTuple now relies on the iterator interface defined in `TVirtualCollectionProxy` (see PR [#12380](https://github.com/root-project/root/pull/12380) for details).; Note that associative collections are not yet supported. - Support for new field types: `std::bitset<N>`, `std::unique_ptr<T>`, `std::set<T>`, `Double32_t`, scoped and unscoped enums with dictionary. - Full support for late model extension, which allows the RN",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:5951,reduce,reduces,5951,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,1,['reduce'],['reduces']
Energy Efficiency,"ave to juggle this with other responsibilities in their; lives; **ping the review once a week** when there is no response;. - if you can't agree, generally the best way is to do what the reviewer; asks; we optimize for readability of the code, which the reviewer is; in a better position to judge; if this feels like it's not the right; option, you can contact the cfe-dev mailing list to get more feedback; on the direction;. Commit access; =============. Once you've contributed a handful of patches to LLVM, start to think; about getting commit access yourself. It's probably a good idea if:. - you've landed 3-5 patches of larger scope than ""fix a typo"". - you'd be willing to review changes that are closely related to yours. - you'd like to keep contributing to LLVM. Getting commit access; ---------------------. LLVM uses Git for committing changes. The details are in the `developer; policy; document <https://llvm.org/docs/DeveloperPolicy.html#obtaining-commit-access>`__. With great power; ----------------. Actually, this would be a great time to read the rest of the `developer; policy <https://llvm.org/docs/DeveloperPolicy.html>`__, too. At minimum,; you need to be subscribed to the relevant commits list before landing; changes (e.g. llvm-commits@lists.llvm.org), as discussion often happens; there if a new patch causes problems. Post-commit errors; ------------------. Once your change is submitted it will be picked up by automated build; bots that will build and test your patch in a variety of configurations. You can see all configurations and their current state in a waterfall; view at http://lab.llvm.org/buildbot/#/waterfall. The waterfall view is good; to get a general overview over the tested configurations and to see; which configuration have been broken for a while. The console view at http://lab.llvm.org/buildbot/#/console helps to get a; better understanding of the build results of a specific patch. If you; want to follow along how your change is affecting the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst:13214,power,power,13214,interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst,1,['power'],['power']
Energy Efficiency,"ax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argument and; return value:. .. code-block:: none. Stack Map: ID=78, Loc0=%r9 Loc1=%r8. The patch code sequence may now use the argument that happened to be; allocated in %r8 and return a value allocated in %r9:. .. code-block:: none. 0x00 movslq 4(%r8) %r9 <--- patched code at patch point address; 0x03 nop; ...; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %r9; 0x10 movl %r9, 8(%rsp). .. _stackmap-format:. Stack Map Format; ================. The existence of a stack map or patch point intrinsic within an LLVM; Module forces code emission to create a :ref:`stackmap-section`. The; format of this section follows:. .. code-block:: none. Header {; uint8 : Stack Map Version (current version is 3); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; uint32 : NumConstants; uint32 : NumRecords; StkSizeRecord[NumFunctions] {; uint64 : Function Address; uint64 : Stack Size (or UINT64_MAX if not statically known); uint64 : Record Count; }; Constants[NumConstants] {; uint64 : LargeConstant; }; StkMapRecord[NumRecords] {; uint64 : PatchPoint ID; uint32 : Instruction Offset; uint16 : Res",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:11608,allocate,allocated,11608,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,2,['allocate'],['allocated']
Energy Efficiency,"axes* (which generally pass through the middle of the; 3D scene) are not depth clipped - so always visible. A single orange sphere of fixed view port (window) size can be shown at; any arbitrary position. Enable / disable the drawing with ‘*Show'*; checkbox. Enter X/Y/Z position in the edit boxes to set position.; Initial position is at the center of the scene. Set the guides using `TGLViewer::SetGuideState` e.g. to enable edge; axes, and enable a reference marker at world position 50, 60, 100:. ``` {.cpp}; Double_t refPos[3] = {50.0,60.0,100.0};; v->SetGuideState(TGLUtil::kAxesEdge, kTRUE, refPos);; ```. #### Selecting Scene Shapes. You can select a single shape from your scene by pressing ‘Shift' key,; pointing and left clicking anywhere on the shape in the viewer.; Selection is currently shown by drawing the shape-bounding box (not; depth clipped) in white (polygon or wire frame render styles) or red; (outline render style). Manipulators supported by the shape are drawn in; red, green and blue while the non-supported ones are drawn in grey. To; deselect a shape, either select another, or shift/click anywhere on the; background (empty space) in the viewer. You cannot select Manipulators; or Guides (Axes / Reference Marker). #### Editing Shapes. When a shape is selected, the viewer's control pane shows the user; interface that allows you to review and adjust the color and geometry; properties of the shape. Note: At present modifications to the shapes are local to the viewer -; they are not propagated back to external objects/client that published; to the viewer. The changes are preserved only until the viewer is; closed. In some cases, this will never be feasible as there is not a; one-to-one correspondence between a shape in the viewer and a single; external object in which the modification could be stored. #### Colors / Style. Viewer Controls Pane ‘Style' tab. A full description of OpenGL materials, colors and lighting is beyond; the scope of this document. You s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:118832,green,green,118832,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['green'],['green']
Energy Efficiency,"ay comparison requiring strong ordering for floating-point types; Unknown. 2540; CD6; Unspecified interpretation of numeric-escape-sequence; Unknown. 2541; open; Linkage specifications, module purview, and module attachment; Not resolved. 2542; DRWP; Is a closure type a structural type?; Unknown. 2543; C++23; constinit and optimized dynamic initialization; Unknown. 2544; open; Address of past-the-end of a potentially-overlapping subobject; Not resolved. 2545; open; Transparently replacing objects in constant expressions; Not resolved. 2546; tentatively ready; Defaulted secondary comparison operators defined as deleted; Unknown. 2547; tentatively ready; Defaulted comparison operator function for non-classes; Unknown. 2548; NAD; Array prvalues and additive operators; Unknown. 2549; review; Implicitly moving the operand of a throw-expression in unevaluated contexts; Not resolved. 2550; DRWP; Type ""reference to cv void"" outside of a declarator; Unknown. 2551; review; ""Refers to allocated storage"" has no meaning; Not resolved. 2552; DRWP; Constant evaluation of non-defining variable declarations; Unknown. 2553; review; Restrictions on explicit object member functions; Clang 18. 2554; review; Overriding virtual functions, also with explicit object parameters; Clang 18. 2555; drafting; Ineffective redeclaration prevention for using-declarators; Not resolved. 2556; DR; Unusable promise::return_void; Unknown. 2557; drafting; Class member access referring to an unrelated class; Not resolved. 2558; C++23; Uninitialized subobjects as a result of an immediate invocation; Unknown. 2559; open; Defaulted consteval functions; Not resolved. 2560; tentatively ready; Parameter type determination in a requirement-parameter-list; Unknown. 2561; review; Conversion to function pointer for lambda with explicit object parameter; Clang 18. 2562; open; Exceptions thrown during coroutine startup; Not resolved. 2563; drafting; Initialization of coroutine result object; Not resolved. 2564; drafti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:175231,allocate,allocated,175231,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,1,['allocate'],['allocated']
Energy Efficiency,"be computed when; calling `GetEntryWithIndex()`. To build an index with only `majorname`,; specify `minorname=""0""` (default). Note that once the index is built, it can be saved with the **`TTree`**; object with:. ``` {.cpp}; tree.Write(); //if the file has been open in ""update"" mode; ```. The most convenient place to create the index is at the end of the; filling process just before saving the tree header. If a previous index; was computed, it is redefined by this new call. Note that this function can also be applied to a **`TChain`**. The; return value is the number of entries in the Index (\< 0 indicates; failure). ## Branches. The organization of branches allows the designer to optimize the data; for the anticipated use. The class for a branch is called **`TBranch`**.; If two variables are independent, and the designer knows the variables; will not be used together, they should be placed on separate branches.; If, however, the variables are related, such as the coordinates of a; point, it is most efficient to create one branch with both coordinates; on it. A variable on a **`TBranch`** is called a leaf (yes -; **`TLeaf`**). Another point to keep in mind when designing trees is that; branches of the same **`TTree`** can be written to separate files. To; add a **`TBranch`** to a **`TTree`** we call the; method **`TTree::Branch()`**. Note that we DO NOT use the `TBranch`; constructor. The `TTree::Branch` method has several signatures. The branch type; differs by what is stored in it. A branch can hold an entire object, a; list of simple variables, contents of a folder, contents of a; **`TList`**, or an array of objects. Let's see some examples. To follow; along you will need the shared library `libEvent.so`. First, check if it; is in `$ROOTSYS/test`. If it is, copy it to your own area. If it is not; there, you have to build it by typing make in `$ROOTSYS/test`. ## Adding a Branch to Hold a List of Variables. As in the very first example (`cernstaff.root.root`); the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:18385,efficient,efficient,18385,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['efficient'],['efficient']
Energy Efficiency,"ber of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.mul``' intrinsic performs the integer ``MUL`` reduction; (:ref:`llvm.vector.reduce.mul <int_vector_reduce_mul>`) of the vector operand ``val``; on each enabled lane, multiplying it by the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``1`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is the; start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.mul.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 1, i32 1, i32 1, i32 1>; %reduction = call i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %masked.a); %also.r = mul i32 %reduction, %start. .. _int_vp_reduce_fmul:. '``llvm.vp.reduce.fmul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmul.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fmul.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MUL`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:754363,reduce,reduce,754363,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"between argument allocations and the call site; avoids this problem, but it creates a cleanup problem. Cleanup and; lifetime is handled explicitly with stack save and restore calls. In; the future, we may want to introduce a new construct such as ``freea``; or ``afree`` to make it clear that this stack adjusting cleanup is less; powerful than a full stack save and restore. Nested Calls and Copy Elision; -----------------------------. We also want to be able to support copy elision into these argument; slots. This means we have to support multiple live argument; allocations. Consider the evaluation of:. .. code-block:: c++. // Foo is non-trivial.; struct Foo { int a; Foo(); Foo(const &Foo); ~Foo(); };; Foo bar(Foo b);; int main() {; bar(bar(Foo()));; }. In this case, we want to be able to elide copies into ``bar``'s argument; slots. That means we need to have more than one set of argument frames; active at the same time. First, we need to allocate the frame for the; outer call so we can pass it in as the hidden struct return pointer to; the middle call. Then we do the same for the middle call, allocating a; frame and passing its address to ``Foo``'s default constructor. By; wrapping the evaluation of the inner ``bar`` with stack save and; restore, we can have multiple overlapping active call frames. Callee-cleanup Calling Conventions; ----------------------------------. Another wrinkle is the existence of callee-cleanup conventions. On; Windows, all methods and many other functions adjust the stack to clear; the memory used to pass their arguments. In some sense, this means that; the allocas are automatically cleared by the call. However, LLVM; instead models this as a write of undef to all of the inalloca values; passed to the call instead of a stack adjustment. Frontends should; still restore the stack pointer to avoid a stack leak. Exceptions; ----------. There is also the possibility of an exception. If argument evaluation; or copy construction throws an exception",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst:4485,allocate,allocate,4485,interpreter/llvm-project/llvm/docs/InAlloca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst,1,['allocate'],['allocate']
Energy Efficiency,"bjective-C.; Numerous bug fixes and heuristics to reduce false positives reported; 			over checker-268. checker-268; built: September 11, 2012; highlights:. Adds initial interprocedural analysis support for C++ and Objective-C. This will greatly improve analysis coverage and find deeper bugs in Objective-C and C++ code.; Contains a static analyzer newer than Xcode 4.4. NOTE: this checker build includes a huge number of changes. It has the potential to find many more bugs, but may report new kinds of false positives. We'd like to know about; these, and any other problems you encounter. When you encounter an issue, please file a bug report.; checker-267; built: June 1, 2012; highlights:; Adds basic interprocedural analysis support for blocks.; checker-266; built: May 23, 2012; highlights:; Contains numerous stability fixes over checker-266, especially when analyzing C++11 code.; checker-265; built: May 8, 2012; highlights:; This release contains a fix for a major crasher introduced in checker-264, and various refinements to; improve the precision and reduce the false positive rate of the analyzer. It also enables a new unix.MallocSizeof check, which reports; inconsistencies between the casted type of the return value of a 'malloc/calloc/realloc' call and the operand; of sizeof expressions contained within its argument(s).; checker-264; built: April 26, 2012; highlights:; This release contains misc. bug fixes and performance enhancements over checker-263, including; a reduction of some kinds of false positives related to the malloc() checker.; checker-263; built: March 22, 2012; highlights:. Fixes several serious bugs with inter-procedural analysis, including a case where retain/releases would be ""double-counted"". checker-262; built: March 15, 2012; highlights:. Enables experimental interprocedural analysis (within a file), which greatly amplifies the analyzer's ability to find issues.; Many bug fixes to the malloc/free checker.; Support for new Objective-C NSArray/NSD",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:7547,reduce,reduce,7547,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,1,['reduce'],['reduce']
Energy Efficiency,"ble. Only at that point, does the instruction becomes eligible for; execution and may be issued (potentially out-of-order) for execution.; Instruction latencies are computed by :program:`llvm-mca` with the help of the; scheduling model. :program:`llvm-mca`'s scheduler is designed to simulate multiple processor; schedulers. The scheduler is responsible for tracking data dependencies, and; dynamically selecting which processor resources are consumed by instructions.; It delegates the management of processor resource units and resource groups to a; resource manager. The resource manager is responsible for selecting resource; units that are consumed by instructions. For example, if an instruction; consumes 1cy of a resource group, the resource manager selects one of the; available units from the group; by default, the resource manager uses a; round-robin selector to guarantee that resource usage is uniformly distributed; between all units of a group. :program:`llvm-mca`'s scheduler internally groups instructions into three sets:. * WaitSet: a set of instructions whose operands are not ready.; * ReadySet: a set of instructions ready to execute.; * IssuedSet: a set of instructions executing. Depending on the operands availability, instructions that are dispatched to the; scheduler are either placed into the WaitSet or into the ReadySet. Every cycle, the scheduler checks if instructions can be moved from the WaitSet; to the ReadySet, and if instructions from the ReadySet can be issued to the; underlying pipelines. The algorithm prioritizes older instructions over younger; instructions. Write-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions ar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:37970,schedul,scheduler,37970,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,"bles at global or local static scope. The Invoke Operator; ===================. Blocks are :block-term:`invoked` using function call syntax with a; list of expression parameters of types corresponding to the; declaration and returning a result type also according to the; declaration. Given:. .. code-block:: c. int (^x)(char);; void (^z)(void);; int (^(*y))(char) = &x;. the following are all legal Block invocations:. .. code-block:: c. x('a');; (*y)('a');; (true ? x : *y)('a'). The Copy and Release Operations; ===============================. The compiler and runtime provide :block-term:`copy` and; :block-term:`release` operations for Block references that create and,; in matched use, release allocated storage for referenced Blocks. The copy operation ``Block_copy()`` is styled as a function that takes; an arbitrary Block reference and returns a Block reference of the same; type. The release operation, ``Block_release()``, is styled as a; function that takes an arbitrary Block reference and, if dynamically; matched to a Block copy operation, allows recovery of the referenced; allocated memory. The ``__block`` Storage Qualifier; =================================. In addition to the new Block type we also introduce a new storage; qualifier, :block-term:`__block`, for local variables. [testme: a; __block declaration within a block literal] The ``__block`` storage; qualifier is mutually exclusive to the existing local storage; qualifiers auto, register, and static. [testme] Variables qualified by; ``__block`` act as if they were in allocated storage and this storage; is automatically recovered after last use of said variable. An; implementation may choose an optimization where the storage is; initially automatic and only ""moved"" to allocated (heap) storage upon; a Block_copy of a referencing Block. Such variables may be mutated as; normal variables are. In the case where a ``__block`` variable is a Block one must assume; that the ``__block`` variable resides in allocated",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:6834,allocate,allocated,6834,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['allocate'],['allocated']
Energy Efficiency,"brackets create variables (discrete and continuous). ""m[-10,10]"" - Creates a RooRealVar named 'm' with range [-10,10]; ""m[5,-10,10]"" - Idem, but with initial value 5; ""m[5]"" - Creates a constant RooRealVar with name 'm' and value 5. ""tagCat[Lep,Kao,NT1,NT2]"" -- Creates a RooCategory with name tagCat and labeled states Lep,Kao,NT1,NT2; ""b0flav[B0=1,B0bar=-1]"" -- Creates a RooCategory with name b0flav and states B0 and B0bar with explicit index assignments. Expressions with parentheses create RooAbsArg function objects of any type. ""RooGaussian::g(x,m,s)"" -- Create a RooGaussian named g with variables x,m,s; This expression maps 1-1 to a createArg() call. ""Gaussian::g(x,m,s)"" -- Idem. The 'Roo' prefix on any class may be omitted. ""Gaussian(x,m,s)"" -- Create a RooGaussian with an automatically assigned name with variables x,m,s. Expressions with curly brackets creates RooArgSets or RooArgLists ""{x,y,z}"". Compound expressions; The real power of this language is that all these expressions may be nested to result in a compact; and readable expression that creates an entire p.d.f. and its components. ""Gaussian::g(x[-10,10],m[-10,10],3)"". Creates a RooGaussian named 'g', its observables 'x' with range [-10,10],; its parameter 'm' with range [-10,10]' and a constant width of 3. ""SUM::model( f[0.5,0,1] * Gaussian( x[-10,10], m[0], 3] ),; Chebychev( x, {a0[0.1],a1[0.2],a2[-0.3]}))"". Create a RooAddPdf model of a RooGaussian and a RooChebychev (which; are implicitly named model_0 and model_1), its observable x and its; parameters m,a0,a1,a2,Nsig and Nbkg; Note that each object may be created only once (with [] or () brackets) but may be referenced multiple; times in the expression by just giving the name. Here is a much more complicated example:. ""PROD::sig(BMixDecay::sig_t( dt[-20,20], mixState[mixed=1,unmix=-1], tagFlav[B0=1,B0bar=-1],; tau[1.54], dm[0.472], w[0.05], dw[0],; AddModel({GaussModel(dt,biasC[-10,10],sigmaC[0.1,3],dterr[0.01,0.2]),; GaussModel(dt,0,sigmaT[3,10]),;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:19769,power,power,19769,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,1,['power'],['power']
Energy Efficiency,"branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1->Clone(0);; for (Int_t i = 0; i < 10; ++i) {; t1->GetEntry(i);; t2->Fill();; }; t2->Write(); delete f2;; f2 = 0;; delete f1;; f1 = 0;. An example of a branch with an object allocated by us,; but owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = 0;; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. Notice that the only difference between this example; and the following example is that the event pointer; is zero when the branch is created. An example of a branch with an object allocated and; owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:1934,allocate,allocated,1934,tree/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html,1,['allocate'],['allocated']
Energy Efficiency,"bregister indices are target specific, and are typically; defined in the target's ``*RegisterInfo.td`` file. Constant Pool Indices; ^^^^^^^^^^^^^^^^^^^^^. A constant pool index (CPI) operand is printed using its index in the; function's ``MachineConstantPool`` and an offset. For example, a CPI with the index 1 and offset 8:. .. code-block:: text. %1:gr64 = MOV64ri %const.1 + 8. For a CPI with the index 0 and offset -12:. .. code-block:: text. %1:gr64 = MOV64ri %const.0 - 12. A constant pool entry is bound to a LLVM IR ``Constant`` or a target-specific; ``MachineConstantPoolValue``. When serializing all the function's constants the; following format is used:. .. code-block:: text. constants:; - id: <index>; value: <value>; alignment: <alignment>; isTargetSpecific: <target-specific>. where:; - ``<index>`` is a 32-bit unsigned integer;; - ``<value>`` is a `LLVM IR Constant; <https://www.llvm.org/docs/LangRef.html#constants>`_;; - ``<alignment>`` is a 32-bit unsigned integer specified in bytes, and must be; power of two;; - ``<target-specific>`` is either true or false. Example:. .. code-block:: text. constants:; - id: 0; value: 'double 3.250000e+00'; alignment: 8; - id: 1; value: 'g-(LPC0+8)'; alignment: 4; isTargetSpecific: true. Global Value Operands; ^^^^^^^^^^^^^^^^^^^^^. The global value machine operands reference the global values from the; :ref:`embedded LLVM IR module <embedded-module>`.; The example below shows an instance of the X86 ``MOV64rm`` instruction that has; a global value operand named ``G``:. .. code-block:: text. $rax = MOV64rm $rip, 1, _, @G, _. The named global values are represented using an identifier with the '@' prefix.; If the identifier doesn't match the regular expression; `[-a-zA-Z$._][-a-zA-Z$._0-9]*`, then this identifier must be quoted. The unnamed global values are represented using an unsigned numeric value with; the '@' prefix, like in the following examples: ``@0``, ``@989``. Target-dependent Index Operands; ^^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MIRLangRef.rst:17740,power,power,17740,interpreter/llvm-project/llvm/docs/MIRLangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MIRLangRef.rst,1,['power'],['power']
Energy Efficiency,"bug type\n"");; #undef DEBUG_TYPE. Then you can run your pass like this:. .. code-block:: none. $ opt < a.bc > /dev/null -mypass; <no output>; $ opt < a.bc > /dev/null -mypass -debug; 'foo' debug type; 'bar' debug type; $ opt < a.bc > /dev/null -mypass -debug-only=foo; 'foo' debug type; $ opt < a.bc > /dev/null -mypass -debug-only=bar; 'bar' debug type; $ opt < a.bc > /dev/null -mypass -debug-only=foo,bar; 'foo' debug type; 'bar' debug type. Of course, in practice, you should only set ``DEBUG_TYPE`` at the top of a file,; to specify the debug type for the entire module. Be careful that you only do; this after including Debug.h and not around any #include of headers. Also, you; should use names more meaningful than ""foo"" and ""bar"", because there is no; system in place to ensure that names do not conflict. If two different modules; use the same string, they will all be turned on when the name is specified.; This allows, for example, all debug information for instruction scheduling to be; enabled with ``-debug-only=InstrSched``, even if the source lives in multiple; files. The name must not include a comma (,) as that is used to separate the; arguments of the ``-debug-only`` option. For performance reasons, -debug-only is not available in optimized build; (``--enable-optimized``) of LLVM. The ``DEBUG_WITH_TYPE`` macro is also available for situations where you would; like to set ``DEBUG_TYPE``, but only for one specific ``DEBUG`` statement. It; takes an additional first parameter, which is the type to use. For example, the; preceding example could be written as:. .. code-block:: c++. DEBUG_WITH_TYPE(""foo"", dbgs() << ""'foo' debug type\n"");; DEBUG_WITH_TYPE(""bar"", dbgs() << ""'bar' debug type\n"");. .. _Statistic:. The ``Statistic`` class & ``-stats`` option; -------------------------------------------. The ``llvm/ADT/Statistic.h`` (`doxygen; <https://llvm.org/doxygen/Statistic_8h_source.html>`__) file provides a class; named ``Statistic`` that is used as a unified way to ke",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:45470,schedul,scheduling,45470,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['schedul'],['scheduling']
Energy Efficiency,"bugpoint - automatic test case reduction tool; =============================================. .. program:: bugpoint. SYNOPSIS; --------. **bugpoint** [*options*] [*input LLVM ll/bc files*] [*LLVM passes*] **--args**; *program arguments*. DESCRIPTION; -----------. **bugpoint** narrows down the source of problems in LLVM tools and passes. It; can be used to debug three types of failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For more information on the design and inner workings of **bugpoint**, as well as; advice for using bugpoint, see :doc:`/Bugpoint` in the LLVM; distribution. OPTIONS; -------. **--additional-so** *library*. Load the dynamic shared object *library* into the test program whenever it is; run. This is useful if you are debugging programs which depend on non-LLVM; libraries (such as the X or curses libraries) to run. **--append-exit-code**\ =\ *{true,false}*. Append the test programs exit code to the output file so that a change in exit; code is considered a test failure. Defaults to false. **--args** *program args*. Pass all arguments specified after **--args** to the test program whenever it runs.; Note that if any of the *program args* start with a ""``-``"", you should use:. .. code-block:: bash. bugpoint [bugpoint args] --args -- [program args]. The ""``--``"" right after the **--args** option tells **bugpoint** to consider; any options starting with ""``-``"" to be part of the **--args** option, not as; options to **bugpoint** itself. **--tool-args** *tool args*. Pass all arguments specified after **--tool-args** to the LLVM tool under test; (**llc**, **lli**, etc.) whenever it runs. You should use this option in the; following way:. .. code-block:: bash. bugpoint [bugpoint args] --tool-args -- [tool args]. The ""``--``"" right after the **--tool-args** option tells **bugpoint** to; consider any optio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst:536,reduce,reduce,536,interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,1,['reduce'],['reduce']
Energy Efficiency,"bvious data dependency (e.g., when comparing strings, ignore the fact; that the output of the comparison might be implicit data-dependent on the; content of the strings). This applies only to functions with ``custom`` category; in ABI list. Its default value is true.; * ``origin_history_size`` -- The limit of origin chain length. Non-positive values; mean unlimited. Its default value is 16.; * ``origin_history_per_stack_limit`` -- The limit of origin node's references count.; Non-positive values mean unlimited. Its default value is 20000.; * ``store_context_size`` -- The depth limit of origin tracking stack traces. Its; default value is 20.; * ``zero_in_malloc`` -- Whether to zero shadow space of new allocated memory. Its; default value is true.; * ``zero_in_free`` --- Whether to zero shadow space of deallocated memory. Its; default value is true. Example; =======. DataFlowSanitizer supports up to 8 labels, to achieve low CPU and code; size overhead. Base labels are simply 8-bit unsigned integers that are; powers of 2 (i.e. 1, 2, 4, 8, ..., 128), and union labels are created; by ORing base labels. The following program demonstrates label propagation by checking that; the correct labels are propagated. .. code-block:: c++. #include <sanitizer/dfsan_interface.h>; #include <assert.h>. int main(void) {; int i = 100;; int j = 200;; int k = 300;; dfsan_label i_label = 1;; dfsan_label j_label = 2;; dfsan_label k_label = 4;; dfsan_set_label(i_label, &i, sizeof(i));; dfsan_set_label(j_label, &j, sizeof(j));; dfsan_set_label(k_label, &k, sizeof(k));. dfsan_label ij_label = dfsan_get_label(i + j);. assert(ij_label & i_label); // ij_label has i_label; assert(ij_label & j_label); // ij_label has j_label; assert(!(ij_label & k_label)); // ij_label doesn't have k_label; assert(ij_label == 3); // Verifies all of the above. // Or, equivalently:; assert(dfsan_has_label(ij_label, i_label));; assert(dfsan_has_label(ij_label, j_label));; assert(!dfsan_has_label(ij_label, k_label));. dfsa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizer.rst:10808,power,powers,10808,interpreter/llvm-project/clang/docs/DataFlowSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizer.rst,1,['power'],['powers']
Energy Efficiency,"by using the command option; ``-register-file-size``. A value of zero for this option means *unbounded*. By; knowing how many registers are available for renaming, the tool can predict; dispatch stalls caused by the lack of physical registers. The number of reorder buffer entries consumed by an instruction depends on the; number of micro-opcodes specified for that instruction by the target scheduling; model. The reorder buffer is responsible for tracking the progress of; instructions that are ""in-flight"", and retiring them in program order. The; number of entries in the reorder buffer defaults to the value specified by field; `MicroOpBufferSize` in the target scheduling model. Instructions that are dispatched to the schedulers consume scheduler buffer; entries. :program:`llvm-mca` queries the scheduling model to determine the set; of buffered resources consumed by an instruction. Buffered resources are; treated like scheduler resources. Instruction Issue; """"""""""""""""""""""""""""""""""; Each processor scheduler implements a buffer of instructions. An instruction; has to wait in the scheduler's buffer until input register operands become; available. Only at that point, does the instruction becomes eligible for; execution and may be issued (potentially out-of-order) for execution.; Instruction latencies are computed by :program:`llvm-mca` with the help of the; scheduling model. :program:`llvm-mca`'s scheduler is designed to simulate multiple processor; schedulers. The scheduler is responsible for tracking data dependencies, and; dynamically selecting which processor resources are consumed by instructions.; It delegates the management of processor resource units and resource groups to a; resource manager. The resource manager is responsible for selecting resource; units that are consumed by instructions. For example, if an instruction; consumes 1cy of a resource group, the resource manager selects one of the; available units from the group; by default, the resource manager uses a; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:36842,schedul,scheduler,36842,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,"c amount of memory; on the stack. This amount is subject to stack allocation limits. Query for this feature with ``__has_builtin(__builtin_alloca)``. ``__builtin_alloca_with_align``; -------------------------------. ``__builtin_alloca_with_align`` is used to dynamically allocate memory on the; stack while controlling its alignment. Memory is automatically freed upon; function termination. **Syntax**:. .. code-block:: c++. __builtin_alloca_with_align(size_t n, size_t align). **Example of Use**:. .. code-block:: c++. void init(float* data, size_t nbelems);; void process(float* data, size_t nbelems);; int foo(size_t n) {; auto mem = (float*)__builtin_alloca_with_align(; n * sizeof(float),; CHAR_BIT * alignof(float));; init(mem, n);; process(mem, n);; /* mem is automatically freed at this point */; }. **Description**:. ``__builtin_alloca_with_align`` is meant to be used to allocate a dynamic amount of memory; on the stack. It is similar to ``__builtin_alloca`` but accepts a second; argument whose value is the alignment constraint, as a power of 2 in *bits*. Query for this feature with ``__has_builtin(__builtin_alloca_with_align)``. .. _langext-__builtin_assume:. ``__builtin_assume``; --------------------. ``__builtin_assume`` is used to provide the optimizer with a boolean; invariant that is defined to be true. **Syntax**:. .. code-block:: c++. __builtin_assume(bool). **Example of Use**:. .. code-block:: c++. int foo(int x) {; __builtin_assume(x != 0);; // The optimizer may short-circuit this check using the invariant.; if (x == 0); return do_something();; return do_something_else();; }. **Description**:. The boolean argument to this function is defined to be true. The optimizer may; analyze the form of the expression provided as the argument and deduce from; that information used to optimize the program. If the condition is violated; during execution, the behavior is undefined. The argument itself is never; evaluated, so any side effects of the expression will be discar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:98496,power,power,98496,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['power'],['power']
Energy Efficiency,"c array type are valid. There is no problem with out of; bounds indices in this sense. Indexing into an array only depends on the size of; the array element, not the number of elements. A common example of how this is used is arrays where the size is not known.; It's common to use array types with zero length to represent these. The fact; that the static type says there are zero elements is irrelevant; it's perfectly; valid to compute arbitrary element indices, as the computation only depends on; the size of the array element, not the number of elements. Note that zero-sized; arrays are not a special case here. This sense is unconnected with ``inbounds`` keyword. The ``inbounds`` keyword is; designed to describe low-level pointer arithmetic overflow conditions, rather; than high-level array indexing rules. Analysis passes which wish to understand array indexing should not assume that; the static array type bounds are respected. The second sense of being out of bounds is computing an address that's beyond; the actual underlying allocated object. With the ``inbounds`` keyword, the result value of the GEP is ``poison`` if the; address is outside the actual underlying allocated object and not the address; one-past-the-end. Without the ``inbounds`` keyword, there are no restrictions on computing; out-of-bounds addresses. Obviously, performing a load or a store requires an; address of allocated and sufficiently aligned memory. But the GEP itself is only; concerned with computing addresses. Can array indices be negative?; ------------------------------. Yes. This is basically a special case of array indices being out of bounds. Can I compare two values computed with GEPs?; --------------------------------------------. Yes. If both addresses are within the same allocated object, or; one-past-the-end, you'll get the comparison result you expect. If either is; outside of it, integer arithmetic wrapping may occur, so the comparison may not; be meaningful. Can I do GEP with a di",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:13727,allocate,allocated,13727,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['allocate'],['allocated']
Energy Efficiency,"c performs the unsigned-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.umax <int_vector_reduce_umax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``0`` (i.e. having no effect on the reduction operation). If the; vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umax.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umax.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_umin:. '``llvm.vp.reduce.umin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:768934,reduce,reduce,768934,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"c(..) {; #ifdef INSTALL_GWP_ASAN_STUBS; if (GWPASanAllocator.shouldSample(..)); return GWPASanAllocator.allocate(..);; #endif. // ... the rest of your allocator code here.; }. Then, all the supporting allocator needs to do is compile with; ``-DINSTALL_GWP_ASAN_STUBS`` and link against the GWP-ASan library! For; performance reasons, we strongly recommend static linkage of the GWP-ASan; library. Guarded Allocation Pool; -----------------------. The core of GWP-ASan is the guarded allocation pool. Each sampled allocation is; backed using its own *guarded* slot, which may consist of one or more accessible; pages. Each guarded slot is surrounded by two *guard* pages, which are mapped as; inaccessible. The collection of all guarded slots makes up the *guarded; allocation pool*. Buffer Underflow/Overflow Detection; -----------------------------------. We gain buffer-overflow and buffer-underflow detection through these guard; pages. When a memory access overruns the allocated buffer, it will touch the; inaccessible guard page, causing memory exception. This exception is caught and; handled by the internal crash handler. Because each allocation is recorded with; metadata about where (and by what thread) it was allocated and deallocated, we; can provide information that will help identify the root cause of the bug. Allocations are randomly selected to be either left- or right-aligned to provide; equal detection of both underflows and overflows. Use after Free Detection; ------------------------. The guarded allocation pool also provides use-after-free detection. Whenever a; sampled allocation is deallocated, we map its guarded slot as inaccessible. Any; memory accesses after deallocation will thus trigger the crash handler, and we; can provide useful information about the source of the error. Please note that the use-after-free detection for a sampled allocation is; transient. To keep memory overhead fixed while still detecting bugs, deallocated; slots are randomly reused to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:3714,allocate,allocated,3714,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['allocate'],['allocated']
Energy Efficiency,"c. which should produce reduced IR that reproduces the crash. Be warned the; ``llvm-reduce`` is still fairly immature and may crash. If none of the above work, you can get the IR before a crash by running the; ``opt`` command with the ``--print-before-all --print-module-scope`` flags to; dump the IR before every pass. Be warned that this is very verbose. .. _backend-crash:. Backend code generator bugs; ---------------------------. If you find a bug that crashes clang in the code generator, compile your; source file to a .bc file by passing ""``-emit-llvm -c -o foo.bc``"" to; clang (in addition to the options you already pass). Once your have; foo.bc, one of the following commands should fail:. #. ``llc foo.bc``; #. ``llc foo.bc -relocation-model=pic``; #. ``llc foo.bc -relocation-model=static``. If none of these crash, please follow the instructions for a :ref:`front-end; bug<frontend-crash>`. If one of these do crash, you should be able to reduce; this with one of the following :doc:`bugpoint <Bugpoint>` command lines (use; the one corresponding to the command above that failed):. #. ``bugpoint -run-llc foo.bc``; #. ``bugpoint -run-llc foo.bc --tool-args -relocation-model=pic``; #. ``bugpoint -run-llc foo.bc --tool-args -relocation-model=static``. Please run this, then file a bug with the instructions and reduced .bc file; that bugpoint emits. If something goes wrong with bugpoint, please submit; the ""foo.bc"" file and the option that llc crashes with. LTO bugs; ---------------------------. If you encounter a bug that leads to crashes in the LLVM LTO phase when using; the ``-flto`` option, follow these steps to diagnose and report the issue:. Compile your source file to a ``.bc`` (Bitcode) file with the following options,; in addition to your existing compilation options:. .. code-block:: bash. export CFLAGS=""-flto -fuse-ld=lld"" CXXFLAGS=""-flto -fuse-ld=lld"" LDFLAGS=""-Wl,-plugin-opt=save-temps"". These options enable LTO and save temporary files generated during compil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:5456,reduce,reduce,5456,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduce']
Energy Efficiency,"c; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmax.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmax.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmax.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maxnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with maximum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmin:. '``llvm.vector.reduce.fmin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmin.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmin.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmin.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with minimum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:659507,reduce,reduce,659507,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"c_fp128 %Val). Overview:; """""""""""""""""". The '``llvm.sqrt``' intrinsics return the square root of the specified value. Arguments:; """""""""""""""""""". The argument and return value are floating-point numbers of the same type. Semantics:; """""""""""""""""""". Return the same value as a corresponding libm '``sqrt``' function but without; trapping or setting ``errno``. For types specified by IEEE-754, the result; matches a conforming libm implementation. When specified with the fast-math-flag 'afn', the result may be approximated; using a less accurate calculation. '``llvm.powi.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.powi`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. Generally, the only supported type for the exponent is the one matching; with the C type ``int``. ::. declare float @llvm.powi.f32.i32(float %Val, i32 %power); declare double @llvm.powi.f64.i16(double %Val, i16 %power); declare x86_fp80 @llvm.powi.f80.i32(x86_fp80 %Val, i32 %power); declare fp128 @llvm.powi.f128.i32(fp128 %Val, i32 %power); declare ppc_fp128 @llvm.powi.ppcf128.i32(ppc_fp128 %Val, i32 %power). Overview:; """""""""""""""""". The '``llvm.powi.*``' intrinsics return the first operand raised to the; specified (positive or negative) power. The order of evaluation of; multiplications is not defined. When a vector of floating-point type is; used, the second argument remains a scalar integer value. Arguments:; """""""""""""""""""". The second argument is an integer power, and the first is a value to; raise to that power. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power with an; unspecified sequence of rounding operations. '``llvm.sin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.sin`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:558066,power,power,558066,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"ca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target assembler format or in machine; code. The code generator is based on the assumption that the instruction selector will; use an optimal pattern matching selector to create high-quality sequences of; native instructions. Alternative code generator designs based on pattern; expansion and aggressive iterative peephole optimization are much slower. This; design permits efficient compilation (important for JIT environments) and; aggressive optimization (used when generating code offline) by allowing; components of varying levels of sophistication to be used for any step of; compilation. In addition to these stages, target implementations can insert arbitrary; target-specific passes into the flow. For example, the X86 target uses a; special pass to handle the 80x87 floating point stack architecture. Other; targets with unusual requirements can be supported with custom passes as needed. Using TableGen for target description; -------------------------------------. The target description classes require a detailed description of the target; architecture. These target descriptions often have a large amount of common; information (e.g., an ``add`` instruction is almost identical to a ``sub``; instruction). In order to allow the maximum amount of commonality to be; factored out, the LLVM code generator uses the; :doc:`TableGen/index` tool to describe big chunks of the; target machine, which allows the use of domain-specific and target-specific; abstractio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:7607,efficient,efficient,7607,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['efficient'],['efficient']
Energy Efficiency,"calar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX90A are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table`. .. table:: AMDHSA Memory Model Code Sequences GFX90A; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table. ============ ===",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:241120,allocate,allocated,241120,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"calar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX940, GFX941, GFX942; are defined in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx940-gfx941-gfx942-table`. .. table:: AMDHSA Memory Model Code Sequences GFX940, GFX941, GFX942; :name: amdgpu-amdhsa-memory-model",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:291138,allocate,allocated,291138,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"calling convention; is specified) matches the target C calling conventions. This calling; convention supports varargs function calls and tolerates some; mismatch in the declared prototype and implemented declaration of; the function (as does normal C).; ""``fastcc``"" - The fast calling convention; This calling convention attempts to make calls as fast as possible; (e.g. by passing things in registers). This calling convention; allows the target to use whatever tricks it wants to produce fast; code for the target, without having to conform to an externally; specified ABI (Application Binary Interface). `Tail calls can only; be optimized when this, the tailcc, the GHC or the HiPE convention is; used. <CodeGenerator.html#tail-call-optimization>`_ This calling; convention does not support varargs and requires the prototype of all; callees to exactly match the prototype of the function definition.; ""``coldcc``"" - The cold calling convention; This calling convention attempts to make code in the caller as; efficient as possible under the assumption that the call is not; commonly executed. As such, these calls often preserve all registers; so that the call does not break any live ranges in the caller side.; This calling convention does not support varargs and requires the; prototype of all callees to exactly match the prototype of the; function definition. Furthermore the inliner doesn't consider such function; calls for inlining.; ""``ghccc``"" - GHC convention; This calling convention has been implemented specifically for use by; the `Glasgow Haskell Compiler (GHC) <http://www.haskell.org/ghc>`_.; It passes everything in registers, going to extremes to achieve this; by disabling callee save registers. This calling convention should; not be used lightly but only for specific situations such as an; alternative to the *register pinning* performance technique often; used when implementing functional programming languages. At the; moment only X86, AArch64, and RISCV support this c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:13184,efficient,efficient,13184,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['efficient'],['efficient']
Energy Efficiency,"case of *read write* access, ``1`` is to be used. ``locality``; indicates the expected persistence of data in cache, from ``0`` which means that; data can be discarded from cache after its next use to ``3`` which means that; data is going to be reused a lot once in cache. ``1`` and ``2`` provide; intermediate behavior between these two extremes. Query for this feature with ``__has_builtin(__builtin_prefetch)``. ``__sync_swap``; ---------------. ``__sync_swap`` is used to atomically swap integers or pointers in memory. **Syntax**:. .. code-block:: c++. type __sync_swap(type *ptr, type value, ...). **Example of Use**:. .. code-block:: c++. int old_value = __sync_swap(&value, new_value);. **Description**:. The ``__sync_swap()`` builtin extends the existing ``__sync_*()`` family of; atomic intrinsics to allow code to atomically swap the current value with the; new value. More importantly, it helps developers write more efficient and; correct code by avoiding expensive loops around; ``__sync_bool_compare_and_swap()`` or relying on the platform specific; implementation details of ``__sync_lock_test_and_set()``. The; ``__sync_swap()`` builtin is a full barrier. ``__builtin_addressof``; -----------------------. ``__builtin_addressof`` performs the functionality of the built-in ``&``; operator, ignoring any ``operator&`` overload. This is useful in constant; expressions in C++11, where there is no other way to take the address of an; object that overloads ``operator&``. Clang automatically adds; ``[[clang::lifetimebound]]`` to the parameter of ``__builtin_addressof``. **Example of use**:. .. code-block:: c++. template<typename T> constexpr T *addressof(T &value) {; return __builtin_addressof(value);; }. ``__builtin_function_start``; -----------------------------. ``__builtin_function_start`` returns the address of a function body. **Syntax**:. .. code-block:: c++. void *__builtin_function_start(function). **Example of use**:. .. code-block:: c++. void a() {}; void *p = __buil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:117088,efficient,efficient,117088,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['efficient'],['efficient']
Energy Efficiency,"case, we want to be able to elide copies into ``bar``'s argument; slots. That means we need to have more than one set of argument frames; active at the same time. First, we need to allocate the frame for the; outer call so we can pass it in as the hidden struct return pointer to; the middle call. Then we do the same for the middle call, allocating a; frame and passing its address to ``Foo``'s default constructor. By; wrapping the evaluation of the inner ``bar`` with stack save and; restore, we can have multiple overlapping active call frames. Callee-cleanup Calling Conventions; ----------------------------------. Another wrinkle is the existence of callee-cleanup conventions. On; Windows, all methods and many other functions adjust the stack to clear; the memory used to pass their arguments. In some sense, this means that; the allocas are automatically cleared by the call. However, LLVM; instead models this as a write of undef to all of the inalloca values; passed to the call instead of a stack adjustment. Frontends should; still restore the stack pointer to avoid a stack leak. Exceptions; ----------. There is also the possibility of an exception. If argument evaluation; or copy construction throws an exception, the landing pad must do; cleanup, which includes adjusting the stack pointer to avoid a stack; leak. This means the cleanup of the stack memory cannot be tied to the; call itself. There needs to be a separate IR-level instruction that can; perform independent cleanup of arguments. Efficiency; ----------. Eventually, it should be possible to generate efficient code for this; construct. In particular, using inalloca should not require a base; pointer. If the backend can prove that all points in the CFG only have; one possible stack level, then it can address the stack directly from; the stack pointer. While this is not yet implemented, the plan is that; the inalloca attribute should not change much, but the frontend IR; generation recommendations may change.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst:5888,efficient,efficient,5888,interpreter/llvm-project/llvm/docs/InAlloca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst,1,['efficient'],['efficient']
Energy Efficiency,ce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338094,reduce,reduce,338094,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,ceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llvm/tools/llvm-tapi-diff/llvm-tapi-diff.cpp; llvm/tools/llvm-undname/llvm-undname.cpp; llvm/tools/llvm-xray/func-id-helper.cpp; llvm/tools/llvm-xray/func-id-helper.h; llvm/tools/llvm-xray/llvm-xray.cpp; llvm/tools/llvm-xray/trie-node.h; llvm/tools/llvm-xray/xray,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338883,reduce,reduce,338883,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,ceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llvm/tools/llvm-tapi-diff/llvm-tapi-diff.cpp; llvm/tools/llvm-undname/llvm-undname.cpp; llvm/tools/llvm-xray/func-id-helper.cpp; llvm/tools/llvm-xray/func-id-helper.h; llvm/tools/llvm-xray/llvm-xray.cpp; llvm/tools/llvm-xray/trie-node.h; llvm/tools/llvm-xray/xray-account.h; llvm/tools/llvm-xray/xray-color-helper.cp,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338937,reduce,reduce,338937,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,ceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llvm/tools/llvm-tapi-diff/llvm-tapi-diff.cpp; llvm/tools/llvm-undname/llvm-undname.cpp; llvm/tools/llvm-xray/func-id-helper.cpp; llvm/tools/llvm-xray/func-id-helper.h; llvm/tools/llvm-xray/llvm-xray.cpp; llvm/tools/llvm-xray/trie-node.h; llvm/tools/llvm-xray/xray-account.h; llvm/tools/llvm-xray/xray-color-helper.cpp; llvm/tools/llvm-xray/xray-color-helper.h; llvm/tool,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338989,reduce,reduce,338989,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"cern.ch/doc/v628/classRooAbsPdf.html) with an option string was removed. This way of configuring the fit was deprecated since at least since ROOT 5.02.; Subsequently, the `RooMinimizer::fit(const char*)` function and the [RooMCStudy](https://root.cern.ch/doc/v628/classRooMCStudy.html) constructor that takes an option string were removed as well.; - The overload of `RooAbsData::createHistogram` that takes integer parameters for the bin numbers is now deprecated and will be removed in ROOT 6.30.; This was done to avoid confusion with inconsistent behavior when compared to other `createHistogram` overloads.; Please use the verson of `createHistogram` that takes RooFit command arguments.; - The `RooAbsData::valid()` method to cache valid entries in the variable range; was removed. It was not implemented in RooDataSet, so it never worked as; intended. Related to it was the `RooDataHist::cacheValidEntries()` function, which is removed as well.; The preferred way to reduce RooFit datasets to subranges is [RooAbsData::reduce()](https://root.cern.ch/doc/v628/classRooAbsData.html#acfa7b31e5cd751eec1bc4e95d2796390).; - The longtime-deprecated `RooStats::HistFactory::EstimateSummary` class is removed, including the functions that use it. The information that it was meant to store is managed by the `RooStats::HistFactory::Measurement` object since many years.; - The `RooSuperCategory::MakeIterator()` function that was deprecated since 6.22 is now removed. Please use range-based loops to iterate over the category states.; - The `HybridCalculatorOriginal` and `HypoTestInverterOriginal` classes in RooStats that were deprecated for a very long time aleady are removed. Please use `HybridCalculator` and `HypoTestInverter`.; - The `RooSimPdfBuilder` that was deprecated in ROOT 5.20 and replaced by the `RooSimWSTool` is removed.; - The RDataFrame factory functions `MakeNumpyDataFrame`, `MakeCsvDataFrame`, `MakeArrowDataFrame`, `MakeNTupleDataFrame` and `MakeSqliteDataFrame` are now depr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:3512,reduce,reduce,3512,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,2,['reduce'],['reduce']
Energy Efficiency,"ces are generally available. For these, all the type; indices considered together must match all the types in one of the tuples. So; ``.legalFor({{s16, s32}, {s32, s64}})`` will only accept ``{s16, s32}``, or; ``{s32, s64}`` but will not accept ``{s16, s64}``. * ``legalForTypesWithMemSize()``, ``narrowScalarForTypesWithMemSize()``, etc. are; similar to ``legalFor()``, ``narrowScalarFor()``, etc. but additionally require a; MachineMemOperand to have a given size in each tuple. * ``legalForCartesianProduct()``, ``narrowScalarForCartesianProduct()``, etc. are; satisfied if each type index matches one element in each of the independent; sets. So ``.legalForCartesianProduct({s16, s32}, {s32, s64})`` will accept; ``{s16, s32}``, ``{s16, s64}``, ``{s32, s32}``, and ``{s32, s64}``. Composite Rules; """""""""""""""""""""""""""""". There are some composite rules for common situations built out of the above facilities:. * ``widenScalarToNextPow2()`` is like ``widenScalarIf()`` but is satisfied iff the type; size in bits is not a power of 2 and selects a target type that is the next; largest power of 2. .. _clampscalar:. * ``minScalar()`` is like ``widenScalarIf()`` but is satisfied iff the type; size in bits is smaller than the given minimum and selects the minimum as the; target type. Similarly, there is also a ``maxScalar()`` for the maximum and a; ``clampScalar()`` to do both at once. * ``minScalarSameAs()`` is like ``minScalar()`` but the minimum is taken from another; type index. * ``moreElementsToNextMultiple()`` is like ``moreElementsToNextPow2()`` but is based on; multiples of X rather than powers of 2. .. _min-legalizerinfo:. Minimum Rule Set; ^^^^^^^^^^^^^^^^. GlobalISel's legalizer has a great deal of flexibility in how a given target; shapes the GMIR that the rest of the backend must handle. However, there are; a small number of requirements that all targets must meet. Before discussing the minimum requirements, we'll need some terminology:. Producer Type Set; The set of types wh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:10118,power,power,10118,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,2,['power'],['power']
Energy Efficiency,"cess to the pointer. To avoid this, the compiler employs; compile-time restrictions and emits run-time checks as necessary to ensure the; new count value doesn't exceed the actual length of the buffer. Section; `Maintaining correctness of bounds annotations`_ provides more details about; this programming model. .. code-block:: c. int g;. void foo(int *__counted_by(count) p, size_t count) {; count++; // may violate the invariant of __counted_by; count--; // may violate the invariant of __counted_by if count was 0.; count = g; // may violate the invariant of __counted_by; // depending on the value of `g`.; }. The requirement to annotate all pointers with explicit bounds information could; present a significant adoption burden. To tackle this issue, the model; incorporates the concept of a ""wide pointer"" (a.k.a. fat pointer) – a larger; pointer that carries bounds information alongside the pointer value. Utilizing; wide pointers can potentially reduce the adoption burden, as it contains bounds; information internally and eliminates the need for explicit bounds annotations.; However, wide pointers differ from standard C pointers in their data layout,; which may result in incompatibilities with the application binary interface; (ABI). Breaking the ABI complicates interoperability with external code that has; not adopted the same programming model. ``-fbounds-safety`` harmonizes the wide pointer and the bounds annotation; approaches to reduce the adoption burden while maintaining the ABI. In this; model, local variables of pointer type are implicitly treated as wide pointers,; allowing them to carry bounds information without requiring explicit bounds; annotations. Please note that this approach doesn't apply to function parameters; which are considered ABI-visible. As local variables are typically hidden from; the ABI, this approach has a marginal impact on it. In addition,; ``-fbounds-safety`` employs compile-time restrictions to prevent implicit wide; pointers from sil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:5341,reduce,reduce,5341,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['reduce'],['reduce']
Energy Efficiency,"ch ""assumptions"" create; constraints on the values of the program, and those constraints are; recorded in the ProgramState object (and are manipulated by the; ConstraintManager). If assuming the conditions of a branch would; cause the constraints to be unsatisfiable, the branch is considered; infeasible and that path is not taken. This is how we get; path-sensitivity. We reduce exponential blow-up by caching nodes. If; a new node with the same state and program point as an existing node; would get generated, the path ""caches out"" and we simply reuse the; existing node. Thus the ExplodedGraph is not a DAG; it can contain; cycles as paths loop back onto each other and cache out. ProgramState and ExplodedNodes are basically immutable once created. Once; one creates a ProgramState, you need to create a new one to get a new; ProgramState. This immutability is key since the ExplodedGraph represents; the behavior of the analyzed program from the entry point. To; represent these efficiently, we use functional data structures (e.g.,; ImmutableMaps) which share data between instances. Finally, individual Checkers work by also manipulating the analysis; state. The analyzer engine talks to them via a visitor interface.; For example, the PreVisitCallExpr() method is called by ExprEngine; to tell the Checker that we are about to analyze a CallExpr, and the; checker is asked to check for any preconditions that might not be; satisfied. The checker can do nothing, or it can generate a new; ProgramState and ExplodedNode which contains updated checker state. If it; finds a bug, it can tell the BugReporter object about the bug,; providing it an ExplodedNode which is the last node in the path that; triggered the problem. = Notes about C++ =. Since now constructors are seen before the variable that is constructed; in the CFG, we create a temporary object as the destination region that; is constructed into. See ExprEngine::VisitCXXConstructExpr(). In ExprEngine::processCallExit(), we alway",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt:3016,efficient,efficiently,3016,interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt,1,['efficient'],['efficiently']
Energy Efficiency,"ch enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``0`` (i.e. having no effect on the reduction operation). If the; vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umax.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umax.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_umin:. '``llvm.vp.reduce.umin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umin``' intrinsic performs the unsigned-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:769079,reduce,reduce,769079,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ch must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fadd``' intrinsic performs the floating-point ``ADD``; reduction (:ref:`llvm.vector.reduce.fadd <int_vector_reduce_fadd>`) of the; vector operand ``val`` on each enabled lane, adding it to the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``-0.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to ``start_value``. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fadd; <int_vector_reduce_fadd>`) for more detail on the semantics of the reduction. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fadd.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float -0.0, float -0.0, float -0.0, float -0.0>; %also.r = call float @llvm.vector.reduce.fadd.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_mul:. '``llvm.vp.reduce.mul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.mul.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.mul.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicate",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:751872,reduce,reduce,751872,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"che; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option.  The merger was reading each; key in memory and deleted the object at the end, but the container is; not owner by default, so all objects inside leaked. PROOF-Lite. Fix a couple of memory leaks showing up when running; repeate",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:6043,adapt,adapting,6043,proof/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html,1,['adapt'],['adapting']
Energy Efficiency,"chitecture. Other; targets with unusual requirements can be supported with custom passes as needed. Using TableGen for target description; -------------------------------------. The target description classes require a detailed description of the target; architecture. These target descriptions often have a large amount of common; information (e.g., an ``add`` instruction is almost identical to a ``sub``; instruction). In order to allow the maximum amount of commonality to be; factored out, the LLVM code generator uses the; :doc:`TableGen/index` tool to describe big chunks of the; target machine, which allows the use of domain-specific and target-specific; abstractions to reduce the amount of repetition. As LLVM continues to be developed and refined, we plan to move more and more of; the target description to the ``.td`` form. Doing so gives us a number of; advantages. The most important is that it makes it easier to port LLVM because; it reduces the amount of C++ code that has to be written, and the surface area; of the code generator that needs to be understood before someone can get; something working. Second, it makes it easier to change things. In particular,; if tables and other things are all emitted by ``tblgen``, we only need a change; in one place (``tblgen``) to update all of the targets to a new interface. .. _Abstract target description:; .. _target description:. Target description classes; ==========================. The LLVM target description classes (located in the ``include/llvm/Target``; directory) provide an abstract description of the target machine independent of; any particular client. These classes are designed to capture the *abstract*; properties of the target (such as the instructions and registers it has), and do; not incorporate any particular pieces of code generation algorithms. All of the target description classes (except the :raw-html:`<tt>` `DataLayout`_; :raw-html:`</tt>` class) are designed to be subclassed by the concrete target; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:8984,reduce,reduces,8984,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['reduce'],['reduces']
Energy Efficiency,"ck:: text. DBG_VALUE_LIST !123, !DIExpression(DW_OP_LLVM_arg, 0, DW_OP_LLVM_arg, 1, DW_OP_plus), %1, %2. And has the following operands:; * The first operand is the Variable field of the original debug intrinsic.; * The second operand is the Expression field of the original debug intrinsic.; * Any number of operands, from the 3rd onwards, record a sequence of variable; location operands, which may take any of the same values as the first; operand of the ``DBG_VALUE`` instruction above. These variable location; operands are inserted into the final DWARF Expression in positions indicated; by the DW_OP_LLVM_arg operator in the `DIExpression; <LangRef.html#diexpression>`_. The position at which the DBG_VALUEs are inserted should correspond to the; positions of their matching ``llvm.dbg.value`` intrinsics in the IR block. As; with optimization, LLVM aims to preserve the order in which variable; assignments occurred in the source program. However SelectionDAG performs some; instruction scheduling, which can reorder assignments (discussed below).; Function parameter locations are moved to the beginning of the function if; they're not already, to ensure they're immediately available on function entry. To demonstrate variable locations during instruction selection, consider; the following example:. .. code-block:: llvm. define i32 @foo(i32* %addr) {; entry:; call void @llvm.dbg.value(metadata i32 0, metadata !3, metadata !DIExpression()), !dbg !5; br label %bb1, !dbg !5. bb1: ; preds = %bb1, %entry; %bar.0 = phi i32 [ 0, %entry ], [ %add, %bb1 ]; call void @llvm.dbg.value(metadata i32 %bar.0, metadata !3, metadata !DIExpression()), !dbg !5; %addr1 = getelementptr i32, i32 *%addr, i32 1, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr1, metadata !3, metadata !DIExpression()), !dbg !5; %loaded1 = load i32, i32* %addr1, !dbg !5; %addr2 = getelementptr i32, i32 *%addr, i32 %bar.0, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr2, metadata !3, metadata !DIExpression(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:29061,schedul,scheduling,29061,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['schedul'],['scheduling']
Energy Efficiency,"ckground,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). VolumeRangeMode No Adaptive Unscaled, MinMax, RMS, Adaptive, kNN Method to determine volume size. KernelEstimator No Box Box, Sphere, Teepee, Gauss, Sinc3, Sinc5, Sinc7, Sinc9, Sinc11, Lanczos2, Lanczos3, Lanczos5, Lanczos8, Trim Kernel estimation function. DeltaFrac No 3 − nEventsMin/Max for minmax and rms volume range. NEventsMin No 100 − nEventsMin for adaptive volume range. NEventsMax No 200 − nEventsMax for adaptive volume range. MaxVIterations No 150 − MaxVIterations for adaptive volume range. InitialScale No 0.99 − InitialScale for adaptive volume range. GaussSigma No 0.1 − Width (wrt volume size) of Gaussian kernel estimator. NormTree No False − Normalize binary search tree. Configuration options for MVA method :. Configuration options reference for MVA method: FDA. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:4849,adapt,adaptive,4849,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,1,['adapt'],['adaptive']
Energy Efficiency,"cks) ... somefunc(42);; assert(3 != 4 && ""laws of math are failing me"");. A = foo(42, 92) + bar(X);. The reason for doing this is not completely arbitrary. This style makes control; flow operators stand out more, and makes expressions flow better. Prefer Preincrement; ^^^^^^^^^^^^^^^^^^^. Hard fast rule: Preincrement (``++X``) may be no slower than postincrement; (``X++``) and could very well be a lot faster than it. Use preincrementation; whenever possible. The semantics of postincrement include making a copy of the value being; incremented, returning it, and then preincrementing the ""work value"". For; primitive types, this isn't a big deal. But for iterators, it can be a huge; issue (for example, some iterators contains stack and set objects in them...; copying an iterator could invoke the copy ctor's of these as well). In general,; get in the habit of always using preincrement, and you won't have a problem. Namespace Indentation; ^^^^^^^^^^^^^^^^^^^^^. In general, we strive to reduce indentation wherever possible. This is useful; because we want code to `fit into 80 columns`_ without excessive wrapping, but; also because it makes it easier to understand the code. To facilitate this and; avoid some insanely deep nesting on occasion, don't indent namespaces. If it; helps readability, feel free to add a comment indicating what namespace is; being closed by a ``}``. For example:. .. code-block:: c++. namespace llvm {; namespace knowledge {. /// This class represents things that Smith can have an intimate; /// understanding of and contains the data associated with it.; class Grokable {; ...; public:; explicit Grokable() { ... }; virtual ~Grokable() = 0;. ... };. } // namespace knowledge; } // namespace llvm. Feel free to skip the closing comment when the namespace being closed is; obvious for any reason. For example, the outer-most namespace in a header file; is rarely a source of confusion. But namespaces both anonymous and named in; source files that are being closed",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:58507,reduce,reduce,58507,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['reduce'],['reduce']
Energy Efficiency,"clang were updated to r227800. This includes everything from the clang 3.6 release. ### Dictionary Generation. Detect usage of #pragma once for inlined headers. Turn on verbosity of genreflex if the VERBOSE environment variable is defined. Optimise forward declarations in rootmap files in order to make their interpretation faster. Propagate attributes specified in xml selection files to selected classes even when selected through typedefs. Optimise selection procedure caching selected declarations in the selection rules, therewith avoiding to query the AST twice. Include in the PCH all the STL and C headers to guarantee portability of binaries from SLC6 to CC7. ## I/O Libraries. ### I/O New functionalities. - Support for forward_list and I/O of unordered stl containers.; - Support for std::complex. ### I/O Behavior change. - The I/O now properly skip the content of base class onfile that have been removed from the in-memory class layout. - The scheduling the I/O customization rules within a StreamerInfo is now as soon as possible, i.e. after all sources have been read. One significant consequence is that now when an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest cycle for a TFile being written since v5.34/11. ## Networking Libraries. ### HTTP Server. ##### Command Interface; One can now register an arbitrary command to the server, which become visible in the web browser. Then, when the item is clicked by the user, the command ends-up in a gROOT->ProcessLineSync() call. ##### Custom Properties ; Custom properties can be configured for any item in the server. For example, one could configure an icon for each item visible in the browser. Or one could ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:8729,schedul,scheduling,8729,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['schedul'],['scheduling']
Energy Efficiency,"class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ~~~. One can make materials or mixtures from radionuclides:. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""C14"", c14, 2.0);; ~~~. The following properties of radionuclides can be currently accessed via; getters in the TGeoElementRN class:. Atomic number and charge (from the base class TGeoElement). - Isomeric number (`ISO`); - ENDF code - following the convention: `ENDF=10000*Z+100*A+ISO`; - Isomeric energy level [`MeV`]; - Mass excess [`MeV`]; - Half life [`s`]; - Spin/Parity - can be retrieved with: `TGeoElementRN::GetTitle()`; - Hynalation and ingestion toxicities; - List of decays - `TGeoElementRN::GetDecays()`. The radioactive decays of a radionuclide are represented by the class; TGeoDecayChannel and they are stored in a TObjArray. Decay; provides:. - Decay mode; - Variation of isomeric number; - `Q` value for the decay [`GeV`]; - Parent element; - Daughter element. Radionuclides are linked one to each other via their decays, until the; last element in the decay chain which must be stable. One can iterate; decay chains using the iterator TGeoElemIter:. ~~~{.cpp}; root[] TGeoElemIter next(c14);; root[] TGeoElementRN *elem;; root[] while ((elem=next())) next.Print();; 6-C-014 (100% BetaMinus) T1/2=1.81e+11; 7-N-014 stable; ~~~. To create a radioactive material based on a radionuclide, one should; use the constructor:. ~~~{.cpp}; TGeoMaterial(const char *name, TGeoElement *elem, Double_t density); ~~~. To create a radioactive mixture,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:6113,energy,energy,6113,geom/geom/doc/materials.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md,1,['energy'],['energy']
Energy Efficiency,"cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class loader (see below). .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:1209,reduce,reduce,1209,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,1,['reduce'],['reduce']
Energy Efficiency,"cling/${lib_path}/*.h; ${CLING_SOURCE_DIR}/include/cling/${lib_path}/*.def; ); set_source_files_properties(${headers} PROPERTIES HEADER_FILE_ONLY ON). file( GLOB_RECURSE tds; ${CLING_SOURCE_DIR}/include/cling/${lib_path}/*.td; ); source_group(""TableGen descriptions"" FILES ${tds}); set_source_files_properties(${tds}} PROPERTIES HEADER_FILE_ONLY ON). if(headers OR tds); set(srcs ${headers} ${tds}); endif(); endif(); endif(MSVC_IDE OR XCODE); if(srcs OR ARG_ADDITIONAL_HEADERS); set(srcs; ADDITIONAL_HEADERS; ${srcs}; ${ARG_ADDITIONAL_HEADERS} # It may contain unparsed unknown args.; ); endif(); if(ARG_SHARED); set(ARG_ENABLE_SHARED SHARED); endif(). if (MSVC); # On Windows exceptions aren’t as generic as an x64 ABI.; # Stack unwinding code must be generated for every function between the; # throw and catch blocks.; if (${name} STREQUAL ""clingInterpreter""); # All of libClingInterpreter is compiled with exceptions, mostly because; # llvm_unreachable throws an exception. Otherwise it could be reduced:; # Exception.cpp, Interpreter.cpp, IncrementalParser.cpp,; # IncrementalExecutor.cpp; set(cling_ex_file_match "".cpp$""); elseif(${name} STREQUAL ""clingUserInterface""); # For libClingUserInterface, only UserInterface.cpp uses exceptions.; set(cling_ex_file_match ""^UserInterface.cpp$""); endif(); if(cling_ex_file_match); # needs to be on before llvm_add_library so flags can be set below; set(LLVM_REQUIRES_EH ON); set(LLVM_REQUIRES_RTTI ON); endif(); endif(). # Set DISABLE_LLVM_LINK_LLVM_DYLIB to disable linking against shared LLVM; llvm_add_library(${name} ${ARG_ENABLE_SHARED} DISABLE_LLVM_LINK_LLVM_DYLIB ${ARG_UNPARSED_ARGUMENTS} ${srcs}). if (MSVC AND cling_ex_file_match); # /EHs because cling_runtime_internal_throwIfInvalidPointer is extern “C”; if (cling_ex_file_match); foreach(file_var ${ARGN}); if (file_var MATCHES ${cling_ex_file_match}); set_property(SOURCE ${file_var} APPEND_STRING PROPERTY COMPILE_FLAGS; "" /D _HAS_EXCEPTIONS=1 /EHs /GR /wd4714 ""); elseif (file_var MATCHE",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/CMakeLists.txt:12924,reduce,reduced,12924,interpreter/cling/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/CMakeLists.txt,1,['reduce'],['reduced']
Energy Efficiency,clude/mlir/Target/LLVMIR/TypeToLLVM.h; mlir/include/mlir/Target/LLVMIR/Dialect/All.h; mlir/include/mlir/Target/LLVMIR/Dialect/AMX/AMXToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/ArmNeon/ArmNeonToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/ArmSVE/ArmSVEToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/LLVMIR/LLVMToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/NVVM/NVVMToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/OpenACC/OpenACCToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/OpenMP/OpenMPToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/ROCDL/ROCDLToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/X86Vector/X86VectorToLLVMIRTranslation.h; mlir/include/mlir/Target/SPIRV/Deserialization.h; mlir/include/mlir/Target/SPIRV/Serialization.h; mlir/include/mlir/Target/SPIRV/SPIRVBinaryUtils.h; mlir/include/mlir/Tools/mlir-lsp-server/MlirLspServerMain.h; mlir/include/mlir/Tools/mlir-reduce/MlirReduceMain.h; mlir/include/mlir/Tools/PDLL/AST/Context.h; mlir/include/mlir/Tools/PDLL/AST/Diagnostic.h; mlir/include/mlir/Tools/PDLL/CodeGen/CPPGen.h; mlir/include/mlir/Tools/PDLL/CodeGen/MLIRGen.h; mlir/include/mlir/Tools/PDLL/ODS/Constraint.h; mlir/include/mlir/Tools/PDLL/ODS/Context.h; mlir/include/mlir/Tools/PDLL/ODS/Dialect.h; mlir/include/mlir/Tools/PDLL/ODS/Operation.h; mlir/include/mlir/Tools/PDLL/Parser/Parser.h; mlir/include/mlir/Transforms/ControlFlowSinkUtils.h; mlir/include/mlir/Transforms/DialectConversion.h; mlir/include/mlir/Transforms/GreedyPatternRewriteDriver.h; mlir/include/mlir/Transforms/InliningUtils.h; mlir/include/mlir/Transforms/LocationSnapshot.h; mlir/include/mlir/Transforms/Passes.h; mlir/include/mlir/Transforms/RegionUtils.h; mlir/include/mlir-c/AffineExpr.h; mlir/include/mlir-c/AffineMap.h; mlir/include/mlir-c/BuiltinAttributes.h; mlir/include/mlir-c/BuiltinTypes.h; mlir/include/mlir-c/Conversion.h; mlir/include/mlir-c/Debug.h; mlir/inclu,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:374735,reduce,reduce,374735,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"column names in the RDataFrame object is now also; usable from a node of a distributed computation graph. This makes the generation of said computation graph slightly; less lazy than before. Notably, it used to be the case that a distributed computation graph could be defined with; code that was not yet available on the user's local application, but that would only become available in the; distributed worker. Now a call such as `df.Define(""mycol"", ""return run_my_fun();"")` needs to be at least declarable; to the interpreter also locally so that the column can be properly tracked. ## Histogram Libraries. ### Upgrade TUnfold to version 17.9. The [TUnfold package](https://www.desy.de/~sschmitt/tunfold.html) inside ROOT is upgraded from version 17.6 to version 17.9. ## Math Libraries. ### Usage of `std::span<const double>` in Minuit 2 interfaces. To avoid forcing the user to do manual memory allocations via `std::vector`, the interfaces of Minuit 2 function adapter classes like `ROOT::Minuit2::FCNBase` or `ROOT::Minuit2::FCNGradientBase` were changed to accept `std::span<const double>` arguments instead of `std::vector<double> const&`.; This should have minimal impact on users, since one should usual use Minuit 2 via the `ROOT::Math::Minimizer` interface, which is unchanged. ## RooFit Libraries. ### Miscellaneous. * Setting `useHashMapForFind(true)` is not supported for RooArgLists anymore, since hash-assisted finding by name hash can be ambiguous: a RooArgList is allowed to have different elements with the same name. If you want to do fast lookups by name, convert your RooArgList to a RooArgSet. * The function `RooFit::bindFunction()` now supports arbitrary many input variables when binding a Python function. * The `ExportOnly()` attribute of the `RooStats::HistFactory::Measurement` object is now switched on by default, and the associated getter and setter functions are deprecated. They will be removed in ROOT 6.36. If you want to fit the model as well instead of just ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v634/index.md:4374,adapt,adapter,4374,README/ReleaseNotes/v634/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v634/index.md,1,['adapt'],['adapter']
Energy Efficiency,"column. For example, leaf `""l""` under branch `""b""` might now be mentioned as `""l""` as well as `""b.l""`, while only one of the two spellings might have been recognized before.; - Certain RDF-related types in the `ROOT::Detail` and `ROOT::Internal` namespaces have been renamed, most notably `RCustomColumn` is now `RDefine`. This does not impact code that only makes use of entities in the public ROOT namespace, and should not impact downstream code unless it was patching or reusing internal `RDataFrame` types. ### Notable bug fixes and improvements. - A critical issue has been fixed that could potentially result in wrong data being silently read in multi-thread runs when an input `TChain` contained more than one `TTree` coming from the _same_ input file. More details are available at [#7143](https://github.com/root-project/root/issues/7143).; - The start-up time of event loops with large computation graphs with many just-in-time-compiled expressions (e.g. thousands of string `Filter`s and `Define`s) has been greatly reduced. See [the corresponding pull request](https://github.com/root-project/root/pull/7651) for more details. The full list of bug fixes for this release is available below. ### Distributed computing with RDataFrame; ROOT 6.24 introduces `ROOT.RDF.Experimental.Distributed`, an experimental python package that enhances RDataFrame with distributed computing capabilities. The new package allows distributing RDataFrame applications through one of the supported distributed backends. The package was designed so that different backends can be easily plugged in. Currently the [Apache Spark](http://spark.apache.org/) backend is supported and support for [Dask](https://dask.org/) is coming soon. The backend submodules of this package expose their own `RDataFrame` objects. The only needed change in user code is to substitute `ROOT.RDataFrame` calls with such backend-specific `RDataFrame`s. For example:. ```python; import ROOT. # Point RDataFrame calls to the Spark spe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:9848,reduce,reduced,9848,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['reduce'],['reduced']
Energy Efficiency,"constructor and; destructors will be run for every element in the array (re-sizable vectors only; construct those elements actually used). .. _dss_tinyptrvector:. llvm/ADT/TinyPtrVector.h; ^^^^^^^^^^^^^^^^^^^^^^^^. ``TinyPtrVector<Type>`` is a highly specialized collection class that is; optimized to avoid allocation in the case when a vector has zero or one; elements. It has two major restrictions: 1) it can only hold values of pointer; type, and 2) it cannot hold a null pointer. Since this container is highly specialized, it is rarely used. .. _dss_smallvector:. llvm/ADT/SmallVector.h; ^^^^^^^^^^^^^^^^^^^^^^. ``SmallVector<Type, N>`` is a simple class that looks and smells just like; ``vector<Type>``: it supports efficient iteration, lays out elements in memory; order (so you can do pointer arithmetic between elements), supports efficient; push_back/pop_back operations, supports efficient random access to its elements,; etc. The main advantage of SmallVector is that it allocates space for some number of; elements (N) **in the object itself**. Because of this, if the SmallVector is; dynamically smaller than N, no malloc is performed. This can be a big win in; cases where the malloc/free call is far more expensive than the code that; fiddles around with the elements. This is good for vectors that are ""usually small"" (e.g. the number of; predecessors/successors of a block is usually less than 8). On the other hand,; this makes the size of the SmallVector itself large, so you don't want to; allocate lots of them (doing so will waste a lot of space). As such,; SmallVectors are most useful when on the stack. In the absence of a well-motivated choice for the number of; inlined elements ``N``, it is recommended to use ``SmallVector<T>`` (that is,; omitting the ``N``). This will choose a default number of; inlined elements reasonable for allocation on the stack (for example, trying; to keep ``sizeof(SmallVector<T>)`` around 64 bytes). SmallVector also provides a nice porta",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:59787,allocate,allocates,59787,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocates']
Energy Efficiency,"contain the; address of each function, along with the relative offset of each basic block. .. option:: --demangle, -C. Display demangled symbol names in the output. .. option:: --dependent-libraries. Display the dependent libraries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms, --dt. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output (the default) is an expanded and; structured format. ``GNU`` output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --section-groups, -g. Display section groups. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various dynamic entries, decoded global descriptor sections, and decoded; Android-specific ELF notes. .. option:: --notes, -n. Display all notes. .. option:: --pretty-print. When used with :option:`--elf-output-style`, JSON output will be formatted in; a more readable format. .. option:: --program-headers, --segments, -l. Display the program headers. .. option:: --raw-relr. Do not decode relocations in RELR relocation sections when displaying them. .. option:: --section-mapping. Display the section to segment mapping. .. option:: --stack-sizes. Display the contents ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:5750,consumption,consumption,5750,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,1,['consumption'],['consumption']
Energy Efficiency,"containing the; neutral value ``INT_MAX`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smin.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 127, i8 127, i8 127, i8 127>; %reduction = call i8 @llvm.vector.reduce.smin.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smin.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_umax:. '``llvm.vp.reduce.umax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umax``' intrinsic performs the unsigned-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.umax <int_vector_reduce_umax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:767125,reduce,reduce,767125,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"contributions. This policy covers all llvm.org subprojects, including Clang,; LLDB, libc++, etc. This policy is also designed to accomplish the following objectives:. #. Attract both users and developers to the LLVM project. #. Make life as simple and easy for contributors as possible. #. Keep the top of tree as stable as possible. #. Establish awareness of the project's :ref:`copyright, license, and patent; policies <copyright-license-patents>` with contributors to the project. This policy is aimed at frequent contributors to LLVM. People interested in; contributing one-off patches can do so in an informal way by sending them to the; `llvm-commits mailing list; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_ and engaging another; developer to see it through the process. Developer Policies; ==================. This section contains policies that pertain to frequent LLVM developers. We; always welcome `one-off patches`_ from people who do not routinely contribute to; LLVM, but we expect more from frequent contributors to keep the system as; efficient as possible for everyone. Frequent LLVM contributors are expected to; meet the following requirements in order for LLVM to maintain a high standard of; quality. Stay Informed; -------------. Developers should stay informed by reading the `LLVM Discourse forums`_ and subscribing; to the categories of interest for notifications. Paying attention to changes being made by others is a good way to see what other people; are interested in and watching the flow of the project as a whole. Contibutions to the project are made through :ref:`GitHub Pull Requests <github-reviews>`.; You can subscribe to notification for areas of the codebase by joining; one of the `pr-subscribers-* <https://github.com/orgs/llvm/teams?query=pr-subscribers>`_; GitHub teams. This `mapping <https://github.com/llvm/llvm-project/blob/main/.github/new-prs-labeler.yml>`_; indicates which team is associated with a particular paths in the repository. Yo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:1584,efficient,efficient,1584,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['efficient'],['efficient']
Energy Efficiency,"controlled with an option. Arguments:; """""""""""""""""""". The integer argument is the loop decrement value used to decrement the loop; iteration counter. Semantics:; """""""""""""""""""". The '``llvm.loop.decrement.*``' intrinsics do a ``SUB`` of the loop iteration; counter with the given loop decrement value, and return false if the loop; should exit, this ``SUB`` is not allowed to wrap. The result is a condition; that is used by the conditional branch controlling the loop. Vector Reduction Intrinsics; ---------------------------. Horizontal reductions of vectors can be expressed using the following; intrinsics. Each one takes a vector operand as an input and applies its; respective operation across all elements of the vector, returning a single; scalar result of the same element type. .. _int_vector_reduce_add:. '``llvm.vector.reduce.add.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.add.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.add.*``' intrinsics do an integer ``ADD``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fadd:. '``llvm.vector.reduce.fadd.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fadd.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fadd.*``' intrinsics do a floating-point; ``ADD`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. O",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:650573,reduce,reduce,650573,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"corresponds; to the level 0 in the stored array, while the last node will correspond; to level `n`. For each level, the node, volume and global matrix can be; retrieved using corresponding getters:. ``` {.cpp}; TGeoHMatrix *GetMatrix(Int_t level=-1) const; TGeoNode *GetNode(Int_t level=-1) const; TGeoShape *GetShape(Int_t level=-1) const; TGeoVolume *GetVolume(Int_t level=-1) const; ```. By default the object at level n is retrieved (the align-able object). Once created, a physical node can be misaligned, meaning that its; positioning matrix or even the shape.:. ``` {.cpp}; void Align(TGeoMatrix* newmat=0, TGeoShape* newshape=0,; Bool_t check=kFALSE); ```. The convention used is that newmat represents the new local matrix of; the last node in the branch with respect to its mother volume. The; `Align()` method will actually duplicate the corresponding branch within; the logical hierarchy, creating new volumes and nodes. This is mandatory; in order to avoid problems due to replicated volumes and can create; exhaustive memory consumption if used abusively. Once aligned, a physical node is ready to be tracked. The operation can; be done only after the geometry was closed. Important NOTE: Calling the `Align()` method for a physical node changes; the node pointers for the stored node branch in the active geometry, Due; to this the other defined physical nodes containing elements of this; path will be invalid. Example:. ``` {.cpp}; TGeoPhysicalNode *pn1 =; gGeoManager->MakePhysicalNode(""/A_1/B_1/C_2"");; TGeoPhysicalNode *pn2 =; gGeoManager->MakePhysicalNode(""/A_1/B_1/C_3"");; ...; pn1->Align(...);; ```. The call to `pn1->Align()` will invalidate the pointer to the node `B_1`; in `pn2` object.. The way out is to either call `pn1->Align()` before; the creation of `pn2`, either to use a global method that will correct; all existing physical nodes:. ``` {.cpp}; void RefreshPhysicalNodes(Bool_t lock = kTRUE); ```. The method above will optionally lock the possibility of doing any",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:149066,consumption,consumption,149066,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['consumption'],['consumption']
Energy Efficiency,"counter is incremented every time the dispatch; logic is unable to dispatch a full group because the scheduler's queue is full. Looking at the *Dispatch Logic* table, we see that the pipeline was only able to; dispatch two micro opcodes 51.5% of the time. The dispatch group was limited to; one micro opcode 44.6% of the cycles, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycle",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31544,schedul,schedulers,31544,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['schedulers']
Energy Efficiency,"cpp}; enum EObjBits {; kCanDelete = BIT(0), // if can be deleted; kMustCleanup = BIT(3), // if destructor must call RecursiveRemove(); kObjInCanvas = BIT(3), // for backward compatibility only; kIsReferenced = BIT(4), // if referenced by TRef or TRefArray; kHasUUID = BIT(5), // if has a TUUID, fUniqueID=UUIDNumber; kCannotPick = BIT(6), // if cannot be picked in a pad; kNoContextMenu = BIT(8), // if does not want a context menu; kInvalidObject = BIT(13) // object ctor succeeded but the object should not be used; };; ```. For example, the bits `kMustCleanup` and `kCanDelete` are used in; **`TObject`**. See ""The kCanDelete Bit"" and ""The kMustCleanup Bit"". They; can be set by any object and should not be reused. Make sure not; to overlap them in any given hierarchy. The bit 13 (`kInvalidObject`) is; set when an object could not be read from a ROOT file. It will check; this bit and will skip to the next object on the file. The **`TObject`** constructor initializes the `fBits` to zero depending; if the object is created on the stack or allocated on the heap. When the; object is created on the stack, the `kCanDelete` bit is set to false to; protect from deleting objects on the stack. The high 8 bits are reserved; for the system usage; the low 24 bits are user settable. `fUniqueID` is; a data member used to give a unique identification number to an object.; It is initialized to zero by the **`TObject`** constructor. ROOT does; not use this data member. The two data members (`fBits` and `fUniqueID`); are streamed out when writing an object to disk. If you do not use them,; you can save some space and time by specifying:. ``` {.cpp}; MyClass::Class()->IgnoreTObjectStreamer();; ```. This sets a bit in the **`TClass`** object. If the file is compressed,; the savings are minimal since most values are zero; however, it saves; some space when the file is not compressed. A call; to` IgnoreTObjectStreamer` also prevents the creation of two additional; branches when splitting the obj",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md:6702,allocate,allocated,6702,documentation/users-guide/AddingaClass.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md,1,['allocate'],['allocated']
Energy Efficiency,cross-dso; Disable control flow integrity (CFI) checks for cross-DSO calls.; -fno-sanitize-coverage=<value>; Disable specified features of coverage instrumentation for Sanitizers; -fno-sanitize-memory-track-origins; Disable origins tracking in MemorySanitizer; -fno-sanitize-memory-use-after-dtor; Disable use-after-destroy detection in MemorySanitizer; -fno-sanitize-recover=<value>; Disable recovery for specified sanitizers; -fno-sanitize-stats Disable sanitizer statistics gathering.; -fno-sanitize-thread-atomics; Disable atomic operations instrumentation in ThreadSanitizer; -fno-sanitize-thread-func-entry-exit; Disable function entry/exit instrumentation in ThreadSanitizer; -fno-sanitize-thread-memory-access; Disable memory access instrumentation in ThreadSanitizer; -fno-sanitize-trap=<value>; Disable trapping for specified sanitizers; -fno-standalone-debug Limit debug information produced to reduce size of debug binary; -fno-strict-aliasing Disable optimizations based on strict aliasing rules (default); -fobjc-runtime=<value> Specify the target Objective-C runtime kind and version; -fprofile-exclude-files=<value>; Instrument only functions from files where names don't match all the regexes separated by a semi-colon; -fprofile-filter-files=<value>; Instrument only functions from files where names match any regex separated by a semi-colon; -fprofile-generate=<dirname>; Generate instrumented code to collect execution counts into a raw profile file in the directory specified by the argument. The filename uses default_%m.profraw pattern; (overridden by LLVM_PROFILE_FILE env var); -fprofile-generate; Generate instrumented code to collect execution counts into default_%m.profraw file; (overridden by '=' form of option or LLVM_PROFILE_FILE env var); -fprofile-instr-generate=<file_name_pattern>; Generate instrumented code to collect execution counts into the file whose name pattern is specified as the argument; (overridden by LLVM_PROFILE_FILE env var); -fprofile-instr-gene,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:181243,reduce,reduce,181243,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['reduce'],['reduce']
Energy Efficiency,"ction(no-op-function),no-op-module' /tmp/a.ll -S. A more complete example, and ``-debug-pass-manager`` to show the execution; order:. .. code-block:: shell. $ opt -passes='no-op-module,cgscc(no-op-cgscc,function(no-op-function,loop(no-op-loop))),function(no-op-function,loop(no-op-loop))' /tmp/a.ll -S -debug-pass-manager. Improper nesting can lead to error messages such as. .. code-block:: shell. $ opt -passes='no-op-function,no-op-module' /tmp/a.ll -S; opt: unknown function pass 'no-op-module'. The nesting is: module (-> cgscc) -> function -> loop, where the CGSCC nesting is optional. There are a couple of special cases for easier typing:. * If the first pass is not a module pass, a pass manager of the first pass is; implicitly created. * For example, the following are equivalent. .. code-block:: shell. $ opt -passes='no-op-function,no-op-function' /tmp/a.ll -S; $ opt -passes='function(no-op-function,no-op-function)' /tmp/a.ll -S. * If there is an adaptor for a pass that lets it fit in the previous pass; manager, that is implicitly created. * For example, the following are equivalent. .. code-block:: shell. $ opt -passes='no-op-function,no-op-loop' /tmp/a.ll -S; $ opt -passes='no-op-function,loop(no-op-loop)' /tmp/a.ll -S. For a list of available passes and analyses, including the IR unit (module,; CGSCC, function, loop) they operate on, run. .. code-block:: shell. $ opt --print-passes. or take a look at ``PassRegistry.def``. To make sure an analysis named ``foo`` is available before a pass, add; ``require<foo>`` to the pass pipeline. This adds a pass that simply requests; that the analysis is run. This pass is also subject to proper nesting. For; example, to make sure some function analysis is already computed for all; functions before a module pass:. .. code-block:: shell. $ opt -passes='function(require<my-function-analysis>),my-module-pass' /tmp/a.ll -S. Status of the New and Legacy Pass Managers; ==========================================. LLVM currently contai",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:19654,adapt,adaptor,19654,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['adapt'],['adaptor']
Energy Efficiency,ctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llv,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338625,reduce,reduce,338625,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"ctionDAG based; instruction selector. Portions of the DAG instruction selector are generated from the target; description (``*.td``) files. Our goal is for the entire instruction selector; to be generated from these ``.td`` files, though currently there are still; things that require custom C++ code. `GlobalISel <https://llvm.org/docs/GlobalISel/index.html>`_ is another; instruction selection framework. .. _SelectionDAG:. Introduction to SelectionDAGs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG provides an abstraction for code representation in a way that; is amenable to instruction selection using automatic techniques; (e.g. dynamic-programming based optimal pattern matching selectors). It is also; well-suited to other phases of code generation; in particular, instruction; scheduling (SelectionDAG's are very close to scheduling DAGs post-selection).; Additionally, the SelectionDAG provides a host representation where a large; variety of very-low-level (but target-independent) `optimizations`_ may be; performed; ones which require extensive information about the instructions; efficiently supported by the target. The SelectionDAG is a Directed-Acyclic-Graph whose nodes are instances of the; ``SDNode`` class. The primary payload of the ``SDNode`` is its operation code; (Opcode) that indicates what operation the node performs and the operands to the; operation. The various operation node types are described at the top of the; ``include/llvm/CodeGen/ISDOpcodes.h`` file. Although most operations define a single value, each node in the graph may; define multiple values. For example, a combined div/rem operation will define; both the dividend and the remainder. Many other situations require multiple; values as well. Each node also has some number of operands, which are edges to; the node defining the used value. Because nodes may define multiple values,; edges are represented by instances of the ``SDValue`` class, which is a; ``<SDNode, unsigned>`` pair, indicating the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:34152,efficient,efficiently,34152,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['efficient'],['efficiently']
Energy Efficiency,"ctions are provided to check origin tracking status and results. .. code-block:: c. /// Retrieves the immediate origin associated with the given data. The returned; /// origin may point to another origin.; ///; /// The type of 'data' is arbitrary. The function accepts a value of any type,; /// which can be truncated or extended (implicitly or explicitly) as necessary.; /// The truncation/extension operations will preserve the label of the original; /// value.; dfsan_origin dfsan_get_origin(long data);. /// Retrieves the very first origin associated with the data at the given; /// address.; dfsan_origin dfsan_get_init_origin(const void *addr);. /// Prints the origin trace of the label at the address `addr` to stderr. It also; /// prints description at the beginning of the trace. If origin tracking is not; /// on, or the address is not labeled, it prints nothing.; void dfsan_print_origin_trace(const void *addr, const char *description);. /// Prints the origin trace of the label at the address `addr` to a pre-allocated; /// output buffer. If origin tracking is not on, or the address is`; /// not labeled, it prints nothing.; ///; /// `addr` is the tainted memory address whose origin we are printing.; /// `description` is a description printed at the beginning of the trace.; /// `out_buf` is the output buffer to write the results to. `out_buf_size` is; /// the size of `out_buf`. The function returns the number of symbols that; /// should have been written to `out_buf` (not including trailing null byte '\0').; /// Thus, the string is truncated iff return value is not less than `out_buf_size`.; size_t dfsan_sprint_origin_trace(const void *addr, const char *description,; char *out_buf, size_t out_buf_size);. /// Returns the value of `-dfsan-track-origins`.; int dfsan_get_track_origins(void);. The following functions are provided to register hooks called by custom wrappers. .. code-block:: c. /// Sets a callback to be invoked on calls to `write`. The callback is invoked; ///",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst:3841,allocate,allocated,3841,interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,1,['allocate'],['allocated']
Energy Efficiency,"ctor of floating-point values. To ignore the start value, negative zero (``-0.0``) can be used, as it is; the neutral value of floating point addition. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fadd.v4f32(float -0.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_mul:. '``llvm.vector.reduce.mul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.mul.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.mul.*``' intrinsics do an integer ``MUL``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmul:. '``llvm.vector.reduce.fmul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fmul.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmul.*``' intrinsics do a floating-point; ``MUL`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. Otherwise; the reduction will be *sequential*, thus implying that the operation respects; the associativity of a scalarized reduction. That is, the reduction begins with; the start value and performs an fmul operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fmul(start_value, input_vector); result = start_value;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:653250,reduce,reduce,653250,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ctor operand ``val`` on each enabled lane, adding it to the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``-0.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to ``start_value``. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fadd; <int_vector_reduce_fadd>`) for more detail on the semantics of the reduction. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fadd.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float -0.0, float -0.0, float -0.0, float -0.0>; %also.r = call float @llvm.vector.reduce.fadd.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_mul:. '``llvm.vp.reduce.mul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.mul.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.mul.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``MUL`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:752477,reduce,reduce,752477,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ctor.reduce.fmax.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmax.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maxnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with maximum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmin:. '``llvm.vector.reduce.fmin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmin.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmin.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmin.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with minimum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmaximum:. '``llvm.vector.reduce.fmaximum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:659660,reduce,reduce,659660,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"cts, which only potentially could be displayed in the browser. In case of 10 objects it does not matter, but for 1000 or 100000 objects this will be a major performance penalty. With such big amount of data one will never achieve higher update rate. The second problem is I/O. To read the first object from the ROOT file, one need to perform several (about 5) file-reading operations via http protocol.; There is no http file locking mechanism (at least not for standard web servers),; therefore there is no guarantee that the file content is not changed/replaced between consequent read operations. Therefore, one should expect frequent I/O failures while trying to monitor data from ROOT binary files. There is a workaround for the problem - one could load the file completely and exclude many partial I/O operations by this. To achieve this with JSROOT, one should add ""+"" sign at the end of the file name. Of course, it only could work for small files. If somebody still wants to use monitoring of data from ROOT files, could try link like:. - <https://root.cern/js/latest/?nobrowser&file=../files/hsimple.root+&item=hpx;1&monitoring=2000>. In this particular case, the histogram is not changing. ## JSROOT API. JSROOT can be used in arbitrary HTML pages to display data, produced with or without ROOT-based applications. Many different examples of JSROOT API usage can be found on [JSROOT API examples](https://root.cern/js/latest/api.htm) page. ### Import JSROOT functionality. Major JSROOT functions are located in `main.mjs` module and can be imported like:. ```javascript; <script type='module'>; import { openFile, draw } from 'https://root.cern/js/latest/modules/main.mjs';; let filename = ""https://root.cern/js/files/hsimple.root"";; let file = await openFile(filename);; let obj = await file.readObject(""hpxpy;1"");; await draw(""drawing"", obj, ""colz"");; </script>; ```. Here the default location `https://root.cern/js/latest/` is specified. One always can install JSROOT on private web serv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:33597,monitor,monitoring,33597,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['monitor'],['monitoring']
Energy Efficiency,"culator with a Poisson problem, reproduces; results from table IV and V of the original; paper�Phys.Rev.D57:3873-3889,1998.; rs401d_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with the neutrino oscillation toy; example described in the original paper�Phys.Rev.D57:3873-3889,1998.; Reproduces figure 12.; rs_bernsteinCorrection.C Demonstrates use of; BernsteinCorrection class, which corrects a nominal PDF with a polynomial; to agree with observed or simulated data. TestStatistic interface and implementations; We added a new interface class called TestStatistic. It defines the; method Evaluate(data, parameterPoint), which returns a double. �This; class can be used in�conjunction�with the ToyMCSampler class to generate; sampling distributions for a user-defined test statistic. �; The following concrete implementations of the TestStatistic interface; are currently available. ProfileLikelihoodTestStatReturns the log of profile; likelihood ratio. �Generally a powerful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. �Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. �Useful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. �The following concrete implementation; of the Te",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:26296,power,powerful,26296,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,1,['power'],['powerful']
Energy Efficiency,"cuted, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers that are; globally available for register renaming by using the command option; ``-register-file-size``. A value of zero for this option means *unbounded*. By; knowing how many registers are available for renaming, the tool can predict; dispatch stalls caused by the lack of physical registers. The number of reorder buffer entries consumed by an instruction depends on the; number of micro-opcodes specified for that instruction by the target scheduling; mo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:35279,schedul,scheduling,35279,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency,"cution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the; :ref:`FunctionPasses <writing-an-llvm-pass-FunctionPass>` on the second; function, etc... until the entire program has been run through the passes. This improves the cache behavior of the compiler, because it is only; touching the LLVM program representation for a single function at a time,; instead of traversing the entire program. It reduces the memory consumption; of compiler, because, for example, only one `DominatorSet; <https://llvm.org/doxygen/classllvm_1_1DominatorSet.html>`_ needs to be; calculated at a time. The effectiveness of the ``PassManager`` is influenced directly by how much; information it has about the behaviors of the passes it is scheduling. For; example, the ""preserved"" set is intentionally conservative in the face of an; unimplemented :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. Not implementing when it should be implemented will have the effect of; not allowing any analysis results to live across the execution of your pass. The ``PassManager`` class exposes a ``--debug-pass`` command line options that; is useful for debugging pass execution, seeing how things work, and diagnosing; when you should be preserving more analyses than you currently are. (To get; information about all of the variants of the ``--debug-pass`` option, just type; ""``opt -help-hidden``""). By using the --debug-pass=Structure option, for example, we can see how our; :ref:`Hello World <writing-an-llvm-pass-basiccode>` pass interacts with other; passes. Lets try it out with the gvn and licm passes:. .. code-block:: console. $ opt -load lib/LLVMHello.s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:42807,schedul,scheduling,42807,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['schedul'],['scheduling']
Energy Efficiency,"d 'hide' any item from the user (but keep access with normal http requests). With such properties one could specify which item is drawn when web page is loaded, or configure monitoring. See tutorials/http/httpcontrol.C macro for more details. ##### Method Calls; Implement exe.json requests to be able to execute any method of registered objects. This request is used to provide remote TTree::Draw() functionality. ##### Misc; Correctly set 'Cache-Control' headers when replying to http requests.; Better support of STL containers when converting objects into json with TBufferJSON class. ## JavaScript ROOT. - Several files can now be loaded simultaneously; - Use d3.time.scale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (via url parameter); - One could monitor simultaneously objects from server and root files; - Implement 'autocol' draw option - when superimposing histograms,; their line colors will be automatically assigned; - Implement 'nostat' draw option - disabled stat drawing; - Using '_same_' identifier in item name, one can easily draw or superimpose; similar items from different files. Could be used in URL like:; `...&files=[file1.root,file2.root]&items=[file1.root/hpx, file2.root/_same_]`; `...&files=[file1.root,file2.root]&item=file1.root/hpx+file2.root/_same_`; Main limitation - file names should have similar length.; - When 'autozoom' specified in draw options, histogram zoomed into; non-empty content. Same command available via context menu.; - Item of 'Text' kind can be created. It is displayed as; lain text in the browser. If property 'mathjax' specified,; MathJax.js library will be loaded and used for rendering.; See tutorials/http/httpcontrol.C macro for example.; - When using foreignObject, provide workaround for absolute positioning; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:10748,monitor,monitor,10748,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['monitor'],['monitor']
Energy Efficiency,"d RDICT. The ROOT precompiled header (PCH) reduces the CPU and memory cost for ROOT's; most used libraries. The precompiled header technology is well-understood since; decades [[4]]. It is an efficient on-disk representation of the state of the; compiler after parsing a set of headers. It can be loaded before starting the; next instance to avoid doing redundant work. At build time, rootcling (ROOT's; dictionary generator) creates such PCH file which is attached at ROOT startup; time. Its major drawback is the fact that if third-party users want to include; their libraries, they have to recompile it every time there is a change. RDICT files store some useful information (in particular about class offsets) in; ROOT files to avoid the potentially expensive call to the interpreter if the; information is not the PCH. For example, ROOT's libGeom and other third-party; code. This is done to circumvent the costly call to `ShowMembers` which will; require parsing. ROOTMAP files reduce parsing for code which is not in the PCH. Consider; `foo::bar` and `S` are defined in `libFoo`'s `Foo.h`:; ```cpp; // Foo.h; namespace foo { struct bar{}; }; struct S{};; ```. ```bash; # libFoo.rootmap; { decls }; namespace foo { }; struct S;; ; [ libFoo.so ]; # List of selected classes; class bar; struct S; ```. ```cpp; // G__Foo.cxx (aka libFoo dictionary); namespace {; void TriggerDictionaryInitialization_libFoo_Impl() {; static const char* headers[] = {""Foo.h""}; // More scaffolding; extern int __Cling_AutoLoading_Map;; namespace foo{struct __attribute__((annotate(""$clingAutoload$Foo.h""))) bar;}; struct __attribute__((annotate(""$clingAutoload$Foo.h""))) S;; // More initialization scaffolding.; }; ```. The code snippet bellow demonstrates the efforts which ROOT does to; avoid parsing redundant code. ```cpp; // ROOT prompt; root [] S *s; // #1: does not require a definition.; root [] foo::bar *baz1; // #2: does not require a definition.; root [] foo::bar baz2; // #3: requires a definition.; ```.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:6843,reduce,reduce,6843,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['reduce'],['reduce']
Energy Efficiency,"d add some more. For example,; by browsing the `LLVM language reference <../../LangRef.html>`_ you'll find; several other interesting instructions that are really easy to plug into; our basic framework. Function Code Generation; ========================. Code generation for prototypes and functions must handle a number of; details, which make their code less beautiful than expression code; generation, but allows us to illustrate some important points. First,; let's talk about code generation for prototypes: they are used both for; function bodies and external function declarations. The code starts; with:. .. code-block:: c++. Function *PrototypeAST::codegen() {; // Make the function type: double(double,double) etc.; std::vector<Type*> Doubles(Args.size(),; Type::getDoubleTy(*TheContext));; FunctionType *FT =; FunctionType::get(Type::getDoubleTy(*TheContext), Doubles, false);. Function *F =; Function::Create(FT, Function::ExternalLinkage, Name, TheModule.get());. This code packs a lot of power into a few lines. Note first that this; function returns a ""Function\*"" instead of a ""Value\*"". Because a; ""prototype"" really talks about the external interface for a function; (not the value computed by an expression), it makes sense for it to; return the LLVM Function it corresponds to when codegen'd. The call to ``FunctionType::get`` creates the ``FunctionType`` that; should be used for a given Prototype. Since all function arguments in; Kaleidoscope are of type double, the first line creates a vector of ""N""; LLVM double types. It then uses the ``Functiontype::get`` method to; create a function type that takes ""N"" doubles as arguments, returns one; double as a result, and that is not vararg (the false parameter; indicates this). Note that Types in LLVM are uniqued just like Constants; are, so you don't ""new"" a type, you ""get"" it. The final line above actually creates the IR Function corresponding to; the Prototype. This indicates the type, linkage and name to use, as; well as",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl03.rst:11403,power,power,11403,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl03.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl03.rst,1,['power'],['power']
Energy Efficiency,"d and if no type is given, the same type as the; previous variable is assumed. This leaf list has three integers called; `ntrack`, `nseg`, and `nvtex`. ``` {.cpp}; ""ntrack/I:nseg:nvtex""; ```. There is one more rule: when no type is given for the very first leaf,; it becomes a `float` (F). This leaf list has three floats called `temp`,; `mass`, and `px`. ``` {.cpp}; ""temp:mass:px""; ```. The symbols used for the type are:. - `C`: a character string terminated by the 0 character; - `B`: an 8 bit signed integer; - `b`: an 8 bit unsigned integer; - `S`: a 16 bit signed integer; - `s`: a 16 bit unsigned integer; - `I`: a 32 bit signed integer; - `i`: a 32 bit unsigned integer; - `L`: a 64 bit signed integer; - `l`: a 64 bit unsigned integer; - `G`: a long signed integer, stored as 64 bit; - `g`: a long unsigned integer, stored as 64 bit; - `F`: a 32 bit floating point; - `D`: a 64 bit floating point; - `O`: [the letter 'o', not a zero] a boolean (Bool\_t). The type is used for a byte count to decide how much space to allocate.; The variable written is simply the block of bytes starting at the; starting address given in the second parameter. It may or may not match; the leaf list depending on whether or not the programmer is being; careful when choosing the leaf address, name, and type. By default, a variable will be copied with the number of bytes specified; in the type descriptor symbol. However, if the type consists of two; characters, the number specifies the number of bytes to be used when; copying the variable to the output buffer. The line below describes; `ntrack` to be written as a 16-bit integer (rather than a 32-bit; integer). ``` {.cpp}; ""ntrack/I2""; ```. With this Branch method, you can also add a leaf that holds an entire; array of variables. To add an array of floats use the `f[n]` notation; when describing the leaf. ``` {.cpp}; Float_t f[10];; tree->Branch(""fBranch"",f,""f[10]/F"");; ```. You can also add an array of variable length:. ``` {.cpp}; {; TFile *f =",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:21747,allocate,allocate,21747,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['allocate'],['allocate']
Energy Efficiency,"d backtraces with inlining information, but does not; include any information about variables, their locations or types. :option:`-gmodules` Generate debug information that contains external; references to types defined in Clang modules or precompiled headers instead; of emitting redundant debug type information into every object file. This; option transparently switches the Clang module format to object file; containers that hold the Clang module together with the debug information.; When compiling a program that uses Clang modules or precompiled headers,; this option produces complete debug information with faster compile; times and much smaller object files. This option should not be used when building static libraries for; distribution to other machines because the debug info will contain; references to the module cache on the machine the object files in the; library were built on. .. option:: -fstandalone-debug -fno-standalone-debug. Clang supports a number of optimizations to reduce the size of debug; information in the binary. They work based on the assumption that the; debug type information can be spread out over multiple compilation units.; For instance, Clang will not emit type definitions for types that are not; needed by a module and could be replaced with a forward declaration.; Further, Clang will only emit type info for a dynamic C++ class in the; module that contains the vtable for the class. The :option:`-fstandalone-debug` option turns off these optimizations.; This is useful when working with 3rd-party libraries that don't come with; debug information. This is the default on Darwin. Note that Clang will; never emit type information for types that are not referenced at all by the; program. .. option:: -feliminate-unused-debug-types. By default, Clang does not emit type information for types that are defined; but not used in a program. To retain the debug info for these unused types,; the negation **-fno-eliminate-unused-debug-types** can be used. .",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:12901,reduce,reduce,12901,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['reduce'],['reduce']
Energy Efficiency,"d barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mca` isn't always able to simulate them; perfectly. Modifying the scheduling model isn't always a viable; option though (maybe because the instruction is modeled incorrectly on; purpose or the instruction's behaviour is quite complex). The; CustomBehaviour class can be used in these cases to enforce proper; instruction modeling (often by customizing data dependencies and detecting; hazards that :program:`llvm-mca` has no way of knowing about). :program:`llvm-mca` comes w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:43543,schedul,scheduling,43543,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency,"d execution one could automatically reload hierarchy (_hreload property) or; update view of displayed object (_update_item property); 5. Use HierarchyPainter for implementing draw.htm. This let us handle; all different kinds of extra attributes in central place; 6. Fix problem in tabs layout - new tab should be add to direct child; 7. When drawing several tabs, activate frame before drawing - only then; real frame size will be set; 8. Fix problem with GetBBox - it only can be used for visible elements in mozilla.; 9. Support drawing of fit parameters in stat box, use (as far as possible) stat and; fit format for statistic display; 10. Implement 'g' formatting kind for stat box output - one need to checks; significant digits when producing output.; 11. Support new draw options for TGraph: 'C', 'B1', '0', '2', '3', '4', '[]'; 12. Primary support for STL containers in IO part. Allows to read ROOT6 TF1.; 13. Full support of TGraphBentErrors; 14. Support objects drawing from JSON files in default user interface, including; monitoring. One could open file from link like: https://root.cern.ch/js/dev/?json=demo/canvas_tf1.json; 15. Introduce JSROOT.FFormat function to convert numeric values into string according; format like 6.4g or 5.7e. Used for statistic display. ## Changes in 3.5; 1. Fix error in vertical text alignment; 2. Many improvements in TPaletteAxis drawing - draw label, avoid too large ticks.; 3. Fix error with col drawing - bin with maximum value got wrong color; 4. Test for existing jquery.js, jquery-ui.js and d3.js libraries, reuse when provided; 5. Fix several I/O problems; now one could read files, produced in Geant4; 6. Implement 'e2' drawing option for TH1 class,; use by default 'e' option when TH1 has non-empty fSumw2; 7. Reuse statistic from histogram itself, when no axis selection done; 8. Support log/lin z scale for color drawing; 9. Implement interactive z-scale selection on TPaletteAxis; 10. Allow to redraw item with other draw options (before one ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:65135,monitor,monitoring,65135,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['monitor'],['monitoring']
Energy Efficiency,"d many; different ways of classifying them: flow-sensitive vs. flow-insensitive,; context-sensitive vs. context-insensitive, field-sensitive; vs. field-insensitive, unification-based vs. subset-based, etc. Traditionally,; alias analyses respond to a query with a `Must, May, or No`_ alias response,; indicating that two pointers always point to the same object, might point to the; same object, or are known to never point to the same object. The LLVM `AliasAnalysis; <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`__ class is the; primary interface used by clients and implementations of alias analyses in the; LLVM system. This class is the common interface between clients of alias; analysis information and the implementations providing it, and is designed to; support a wide range of implementations and clients (but currently all clients; are assumed to be flow-insensitive). In addition to simple alias analysis; information, this class exposes Mod/Ref information from those implementations; which can provide it, allowing for powerful analyses and transformations to work; well together. This document contains information necessary to successfully implement this; interface, use it, and to test both sides. It also explains some of the finer; points about what exactly results mean. ``AliasAnalysis`` Class Overview; ================================. The `AliasAnalysis <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`__; class defines the interface that the various alias analysis implementations; should support. This class exports two important enums: ``AliasResult`` and; ``ModRefResult`` which represent the result of an alias query or a mod/ref; query, respectively. The ``AliasAnalysis`` interface exposes information about memory, represented in; several different ways. In particular, memory objects are represented as a; starting address and size, and function calls are represented as the actual; ``call`` or ``invoke`` instructions that performs the call. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:1429,power,powerful,1429,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['power'],['powerful']
Energy Efficiency,"d polar object which; initializes it x and y fields. The mapRequired() methods then write out the x; and y values as key/value pairs. When reading YAML, the local variable ""keys"" will be a stack allocated instance; of NormalizedPolar, constructed by the empty constructor. The mapRequired; methods will find the matching key in the YAML document and fill in the x and y; fields of the NormalizedPolar object keys. At the end of the mapping() method; when the local keys variable goes out of scope, the denormalize() method will; automatically be called to convert the read values back to polar coordinates,; and then assigned back to the second parameter to mapping(). In some cases, the normalized class may be a subclass of the native type and; could be returned by the denormalize() method, except that the temporary; normalized instance is stack allocated. In these cases, the utility template; MappingNormalizationHeap<> can be used instead. It just like; MappingNormalization<> except that it heap allocates the normalized object; when reading YAML. It never destroys the normalized object. The denormalize(); method can this return ""this"". Default values; --------------; Within a mapping() method, calls to io.mapRequired() mean that that key is; required to exist when parsing YAML documents, otherwise YAML I/O will issue an; error. On the other hand, keys registered with io.mapOptional() are allowed to not; exist in the YAML document being read. So what value is put in the field; for those optional keys?; There are two steps to how those optional fields are filled in. First, the; second parameter to the mapping() method is a reference to a native class. That; native class must have a default constructor. Whatever value the default; constructor initially sets for an optional field will be that field's value.; Second, the mapOptional() method has an optional third parameter. If provided; it is the value that mapOptional() should set that field to if the YAML document; does not ha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:19737,allocate,allocates,19737,interpreter/llvm-project/llvm/docs/YamlIO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst,1,['allocate'],['allocates']
Energy Efficiency,"d prepend `button;`; string to the icon name to let browser show command as extra button. In last case one could hide command element from elements list:. ```cpp; serv->Hide(""/DoSomething"");; ```. One can find example of command interface usage in [tutorials/http/httpcontrol.C](https://github.com/root-project/root/blob/master/tutorials/http/httpcontrol.C) macro. ## Customize user interface. JSROOT is used to implement UI for the THttpServer. Default webpage shows list of registered objects on the left side and drawing area on the right side - [see example](https://root.cern/js/latest/httpserver.C/). JSROOT allows to configure different parameters via URL - like monitoring interval or name of displayed items [item=Files/job1.root/hpxpy&opt=colz&monitoring=1000](https://root.cern/js/latest/httpserver.C/?item=Files/job1.root/hpxpy&opt=colz&monitoring=1000). Some of such parameters can be configured already on the server:. ```cpp; serv->SetItemField(""/"", ""_monitoring"", ""1000""); // monitoring interval in ms; serv->SetItemField(""/"", ""_drawitem"", ""Files/job1.root/hpxpy""); // item to draw; serv->SetItemField(""/"", ""_drawopt"", ""colz"");; ```. In such case URL parameters are not required - specified item will be displayed automatically when web page is opened.; One also can configure to display several items at once. For that one also can configure layout of the drawing area:. ```cpp; serv->SetItemField(""/"", ""_layout"", ""grid2x2""); // layout for drawing area; serv->SetItemField(""/"", ""_drawitem"", ""[Files/job1.root/hpxpy,Files/job1.root/hpx]""); // items; serv->SetItemField(""/"", ""_drawopt"", ""[colz,hist]""); // options; ```. One also can change appearance of hierarchy browser on the left side of the web page:. ```cpp; serv->SetItemField(""/"", ""_browser"", ""off""); // allowed ""fix"" (default), ""float"", ""no"", ""off""; serv->SetItemField(""/"", ""_toptitle"", ""Custom title""); // title of web page, shown when browser off; ```. If necessary, one also can automatically open ROOT file when web page i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:6970,monitor,monitoring,6970,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['monitor'],['monitoring']
Energy Efficiency,"d*. By; knowing how many registers are available for renaming, the tool can predict; dispatch stalls caused by the lack of physical registers. The number of reorder buffer entries consumed by an instruction depends on the; number of micro-opcodes specified for that instruction by the target scheduling; model. The reorder buffer is responsible for tracking the progress of; instructions that are ""in-flight"", and retiring them in program order. The; number of entries in the reorder buffer defaults to the value specified by field; `MicroOpBufferSize` in the target scheduling model. Instructions that are dispatched to the schedulers consume scheduler buffer; entries. :program:`llvm-mca` queries the scheduling model to determine the set; of buffered resources consumed by an instruction. Buffered resources are; treated like scheduler resources. Instruction Issue; """"""""""""""""""""""""""""""""""; Each processor scheduler implements a buffer of instructions. An instruction; has to wait in the scheduler's buffer until input register operands become; available. Only at that point, does the instruction becomes eligible for; execution and may be issued (potentially out-of-order) for execution.; Instruction latencies are computed by :program:`llvm-mca` with the help of the; scheduling model. :program:`llvm-mca`'s scheduler is designed to simulate multiple processor; schedulers. The scheduler is responsible for tracking data dependencies, and; dynamically selecting which processor resources are consumed by instructions.; It delegates the management of processor resource units and resource groups to a; resource manager. The resource manager is responsible for selecting resource; units that are consumed by instructions. For example, if an instruction; consumes 1cy of a resource group, the resource manager selects one of the; available units from the group; by default, the resource manager uses a; round-robin selector to guarantee that resource usage is uniformly distributed; between all units of a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:36924,schedul,scheduler,36924,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,"d, but mismatched ones will be left alone.; ``allockind(""KIND"")``; Describes the behavior of an allocation function. The KIND string contains comma; separated entries from the following options:. * ""alloc"": the function returns a new block of memory or null.; * ""realloc"": the function returns a new block of memory or null. If the; result is non-null the memory contents from the start of the block up to; the smaller of the original allocation size and the new allocation size; will match that of the ``allocptr`` argument and the ``allocptr``; argument is invalidated, even if the function returns the same address.; * ""free"": the function frees the block of memory specified by ``allocptr``.; Functions marked as ""free"" ``allockind`` must return void.; * ""uninitialized"": Any newly-allocated memory (either a new block from; a ""alloc"" function or the enlarged capacity from a ""realloc"" function); will be uninitialized.; * ""zeroed"": Any newly-allocated memory (either a new block from a ""alloc""; function or the enlarged capacity from a ""realloc"" function) will be; zeroed.; * ""aligned"": the function returns memory aligned according to the; ``allocalign`` parameter. The first three options are mutually exclusive, and the remaining options; describe more details of how the function behaves. The remaining options; are invalid for ""free""-type functions.; ``allocsize(<EltSizeParam>[, <NumEltsParam>])``; This attribute indicates that the annotated function will always return at; least a given number of bytes (or null). Its arguments are zero-indexed; parameter numbers; if one argument is provided, then it's assumed that at; least ``CallSite.Args[EltSizeParam]`` bytes will be available at the; returned pointer. If two are provided, then it's assumed that; ``CallSite.Args[EltSizeParam] * CallSite.Args[NumEltsParam]`` bytes are; available. The referenced parameters must be integer types. No assumptions; are made about the contents of the returned block of memory.; ``alwaysinline``; This",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:79081,allocate,allocated,79081,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"d-stripping, but before memory; is allocated or nodes assigned their final target vmaddrs. Passes run at this stage benefit from pruning, as dead functions and data; have been stripped from the graph. However new content can still be added; to the graph, as target and working memory have not been allocated yet. Notable use cases: Building Global Offset Table (GOT), Procedure Linkage; Table (PLT), and Thread Local Variable (TLV) entries. #. Asynchronously allocate memory. Calls the ``JITLinkContext``'s ``JITLinkMemoryManager`` to allocate both; working and target memory for the graph. As part of this process the; ``JITLinkMemoryManager`` will update the addresses of all nodes; defined in the graph to their assigned target address. Note: This step only updates the addresses of nodes defined in this graph.; External symbols will still have null addresses. #. Phase 2. #. Run post-allocation passes. These passes are run on the graph after working and target memory have; been allocated, but before the ``JITLinkContext`` is notified of the; final addresses of the symbols in the graph. This gives these passes a; chance to set up data structures associated with target addresses before; any JITLink clients (especially ORC queries for symbol resolution) can; attempt to access them. Notable use cases: Setting up mappings between target addresses and; JIT data structures, such as a mapping between ``__dso_handle`` and; ``JITDylib*``. #. Notify the ``JITLinkContext`` of the assigned symbol addresses. Calls ``JITLinkContext::notifyResolved`` on the link graph, allowing; clients to react to the symbol address assignments made for this graph.; In ORC this is used to notify any pending queries for *resolved* symbols,; including pending queries from concurrently running JITLink instances that; have reached the next step and are waiting on the address of a symbol in; this graph to proceed with their link. #. Identify external symbols and resolve their addresses asynchronously. Calls the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:19757,allocate,allocated,19757,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['allocate'],['allocated']
Energy Efficiency,"d/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. option:: -dispatch-stats. Enable extra dispatch statistics. This view collects and analyzes instruction; dispatch events, as well as static/dynamic dispatch stall events. This view; is disabled by default. .. option:: -scheduler-stats. Enable extra scheduler statistics. This view collects and analyzes instruction; issue events. This view is disabled by default. .. option:: -retire-stats. Enable extra retire control unit statistics. This view is disabled by default. .. option:: -instruction-info. Enable the instruction info view. This is enabled by default. .. option:: -show-encoding. Enable the printing of instruction encodings within the instruction info view. .. option:: -show-barriers. Enable the printing of LoadBarrier and StoreBarrier flags within the; instruction info view. .. option:: -all-stats. Print all hardware statistics. This enables extra statistics related to the; dispatch logic, the hardware schedulers, the register file(s), and the retire; control unit. This option is disabled by default. .. option:: -all-views. Enable all the view. .. option:: -instruction-tables. Prints resource pressure information based on the static information; available from the processor model. This differs from",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:5481,schedul,scheduler-stats,5481,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler-stats']
Energy Efficiency,"d1 + d.get_field2(); ... return total; ...; >>> print(tsdcm(a, d)); 155; >>>. Demo: Numba physics example; ---------------------------. Motivating example taken from:; `numba_scalar_impl.py <https://github.com/numba/numba-examples/blob/master/examples/physics/lennard_jones/numba_scalar_impl.py>`_. .. code-block:: python. >>> import numba; >>> import cppyy; >>> import cppyy.numba_ext; ...; >>> cppyy.cppdef(""""""; ... #include <vector>; ... struct Atom {; ... float x;; ... float y;; ... float z;; ... };; ...; ... std::vector<Atom> atoms = {{1, 2, 3}, {2, 3, 4}, {3, 4, 5}, {4, 5, 6}, {5, 6, 7}};; ... """"""); ...; >>> @numba.njit; >>> def lj_numba_scalar(r):; ... sr6 = (1./r)**6; ... pot = 4.*(sr6*sr6 - sr6); ... return pot. >>> @numba.njit; >>> def distance_numba_scalar(atom1, atom2):; ... dx = atom2.x - atom1.x; ... dy = atom2.y - atom1.y; ... dz = atom2.z - atom1.z; ...; ... r = (dx * dx + dy * dy + dz * dz) ** 0.5; ...; ... return r; ...; >>> def potential_numba_scalar(cluster):; ... energy = 0.0; ... for i in range(cluster.size() - 1):; ... for j in range(i + 1, cluster.size()):; ... r = distance_numba_scalar(cluster[i], cluster[j]); ... e = lj_numba_scalar(r); ... energy += e; ...; ... return energy; ...; >>> print(""Total lennard jones potential ="", potential_numba_scalar(cppyy.gbl.atoms)); Total lennard jones potential = -0.5780277345740283. Overhead; --------. The main overhead of JITing Numba traces is in the type annotation in Numba; itself, optimization of the IR and assembly by the backend less so.; (There is also a non-negligible cost to Numba initialization, which is why; ``cppyy`` does not provide automatic extension hooks.); The use of ``cppyy`` bound C++, which relies on the same Numba machinery,; does not change that, since the reflection-based lookups are in C++ and; comparatively very fast.; For example, there is no appreciable difference in wall clock time to JIT a; trace using Numba's included math functions (from module ``math`` or; ``numpy``) or one ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:8866,energy,energy,8866,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,1,['energy'],['energy']
Energy Efficiency,"d:. '``llvm.vector.reduce.and.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.and.*``' intrinsics do a bitwise ``AND``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_or:. '``llvm.vector.reduce.or.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scalar. The return type matches the; element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_xor:. '``llvm.vector.reduce.xor.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.xor.*``' intrinsics do a bitwise ``XOR``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smax:. '``llvm.vector.reduce.smax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smax.*``' intrinsics do a signed integer; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smin:. '``llvm.vector.reduce.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:655970,reduce,reduce,655970,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"d:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output binary to; describe, and should be stepped over by debuggers anyway. Variable locations in Instruction Selection and MIR; ---------------------------------------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there can be different types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optimized out:; in IR the location would be assigned ``undef`` by a debug intrinsic, and in MIR; the equivalent location is used. After MIR locations are assigned to each variable, machine pseudo-instructions; corresponding to each ``llvm.dbg.value`` intrinsic are inserted. There are two; forms of this type of instruction. The first form, ``DBG_VALUE``, appears thus:. .. code-block:: text. DBG_VAL",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:26342,allocate,allocated,26342,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['allocate'],['allocated']
Energy Efficiency,"ddition to; all the simple types. When using a **`TTree`**, we fill its branch buffers with leaf data and; the buffers are written to disk when it is full. Branches, buffers, and; leafs, are explained a little later in this chapter, but for now, it is; important to realize that each object is not written individually, but; rather collected and written a bunch at a time. This is where the **`TTree`** takes advantage of compression and will; produce a much smaller file than if the objects were written; individually. Since the unit to be compressed is a buffer, and the; **`TTree`** contains many same-class objects, the header of the objects; can be compressed. The **`TTree`** reduces the header of each object, but it still contains; the class name. Using compression, the class name of each same-class; object has a good chance of being compressed, since the compression; algorithm recognizes the bit pattern representing the class name. Using; a **`TTree`** and compression the header is reduced to about 4 bytes; compared to the original 60 bytes. However, if compression is turned; off, you will not see these large savings. The **`TTree`** is also used to optimize the data access. A tree uses a; hierarchy of branches, and each branch can be read independently from; any other branch. Now, assume that `Px` and `Py` are data members of the; event, and we would like to compute `Px2 + Py2` for every event; and histogram the result. If we had saved the million events without a **`TTree`** we would have; to:. - read each event in its entirety into memory; - extract the `Px` and `Py` from the event; - compute the sum of the squares; - fill a histogram. We would have to do that a million times! This is very time consuming,; and we really do not need to read the entire event, every time. All we; need are two little data members (`Px` and `Py`). On the other hand, if; we use a tree with one branch containing `Px` and another branch; containing `Py`, we can read all values of `Px` and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:1534,reduce,reduced,1534,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['reduce'],['reduced']
Energy Efficiency,"de:. ::. float sequential_fadd(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result + input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, negative zero (``-0.0``) can be used, as it is; the neutral value of floating point addition. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fadd.v4f32(float -0.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_mul:. '``llvm.vector.reduce.mul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.mul.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.mul.*``' intrinsics do an integer ``MUL``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmul:. '``llvm.vector.reduce.fmul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fmul.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmul.*``' intrinsics do a floating-point; ``MUL`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. O",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:652872,reduce,reduce,652872,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"de:. alpha.deadcode.UnreachableCode (C, C++); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check unreachable code. .. code-block:: cpp. // C; int test() {; int x = 1;; while(x);; return x; // warn; }. // C++; void test() {; int a = 2;. while (a > 1); a--;. if (a > 1); a++; // warn; }. // Objective-C; void test(id x) {; return;; [x retain]; // warn; }. alpha.fuchsia; ^^^^^^^^^^^^^. .. _alpha-fuchsia-lock:. alpha.fuchsia.Lock; """"""""""""""""""""""""""""""""""""; Similarly to :ref:`alpha.unix.PthreadLock <alpha-unix-PthreadLock>`, checks for; the locking/unlocking of fuchsia mutexes. .. code-block:: cpp. spin_lock_t mtx1;. void bad1(void); {; spin_lock(&mtx1);; spin_lock(&mtx1);	// warn: This lock has already been acquired; }. alpha.llvm; ^^^^^^^^^^. .. _alpha-llvm-Conventions:. alpha.llvm.Conventions; """""""""""""""""""""""""""""""""""""""""""". Check code for LLVM codebase conventions:. * A StringRef should not be bound to a temporary std::string whose lifetime is shorter than the StringRef's.; * Clang AST nodes should not have fields that can allocate memory. alpha.osx; ^^^^^^^^^. .. _alpha-osx-cocoa-DirectIvarAssignment:. alpha.osx.cocoa.DirectIvarAssignment (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for direct assignments to instance variables. .. code-block:: objc. @interface MyClass : NSObject {}; @property (readonly) id A;; - (void) foo;; @end. @implementation MyClass; - (void) foo {; _A = 0; // warn; }; @end. .. _alpha-osx-cocoa-DirectIvarAssignmentForAnnotatedFunctions:. alpha.osx.cocoa.DirectIvarAssignmentForAnnotatedFunctions (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for direct assignments to instance variables in; the methods annotated with ``objc_no_direct_instance_variable_assignment``. .. code-block:: objc. @interface MyClass : NSObject {}; @property (readonly) id A;; - (void) fAnnotated __attribute__((; annotate(""objc_no_direct_instance_variable_assignment"")));; - (void) fNotAnnotated;; @end. @implementation MyClass; - (void) fAnnotated {;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:57022,allocate,allocate,57022,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['allocate'],['allocate']
Energy Efficiency,deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llvm/tools/llvm-tapi-diff/llvm-tapi-diff.cpp; llvm/tools/llvm-undname/llvm-undname.cpp; llvm/tools/llvm-xray/func-id-helper.cpp; llvm/tools/llvm-xray/func-id-helper.h; llvm/tools/llvm-xray/llvm-xray.cpp; llvm/tools/llvm-xray/trie-node.h; llvm/tools/llvm-xray/xray-account.h; llvm/tools/llvm-xray/xray-color-helper.cpp; llvm/tools/llvm-xray/xray-color-helper.h; llvm/tools/llvm-xray/xray-converter.cpp; llvm/tools/llvm-xray/xray-converter.h; llvm/tools/llvm-xray/xray-fdr-dump.cpp; llvm/tools/llvm-xray/xray-graph-diff.cpp; llvm/tools/l,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:339155,reduce,reduce,339155,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"described with combination of planes, can; be rendered in this fashion - e.g. a clipping tube is not possible. - Each additional clipping plane requires an additional render pass -; so the more active planes the more time the render will take. Set the current clip object with **`TGLClipSet::SetClipType`**. ``` {.cpp}; v->GetClipSet()->SetClipType(TGLClipSet::kClipPlane);; ```. Configure the clip object with **`TGLClipSet::SetClipState`**. ``` {.cpp}; Double_t planeEq[4] = {0.5,1.0,-1.0, 2.0};; v->GetClipSet()->SetClipState(TGLClipSet::kClipPlane, planeEq);; ```. As with cameras, any clip can be configured at any time, but you must; set the clip current to see the effect. #### Manipulators. *Manipulators* are GUI ‘widgets' or controls attached to a 3D object in; the viewer, allowing a direct manipulation of the object's geometry.; There are three manipulators for the three basic geometries; transformations. In each case, the *manipulator* consists of three; components, one for each local axis of the object, shown in standard; colors: red (X), green (Y) and blue (Z). ![GL Viewer object manipulators](pictures/030000DE.png). Activate the *manipulator* by moving the mouse over one of these; components (which turns yellow to indicate active state). Click with; left mouse and drag this active component to perform the manipulation.; Toggle between the *manipulator* types using the ‘x', ‘c', ‘v' keys; while the mouse cursor is above the manipulator. Note: Manipulators; cannot be controlled via the API at present. #### Guides. Guides are visual aids drawn into the viewer world. Controls for these; are under the ""Guides"" tab:. Viewer Controls Pane Guides Tab. Axes show the world (global) frame *coordinate*directions: X (red), Y; (green) and Z (blue). The negative portion of the *axis* line is shown; in dark color, the positive in bright. The *axis* name and minimum /; maximum values are labeled in the same color. There are three options; for *axes* drawing - selected by radio ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:116490,green,green,116490,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['green'],['green']
Energy Efficiency,"design; principle that semantically important behavior should be explicit. A simple; fix is to clear the instance variable manually during ``dealloc``; a more; holistic solution is to move semantically important side-effects out of; ``dealloc`` and into a separate teardown phase which can rely on working with; well-formed objects. .. _arc.misc.autoreleasepool:. ``@autoreleasepool``; --------------------. To simplify the use of autorelease pools, and to bring them under the control; of the compiler, a new kind of statement is available in Objective-C. It is; written ``@autoreleasepool`` followed by a *compound-statement*, i.e. by a new; scope delimited by curly braces. Upon entry to this block, the current state; of the autorelease pool is captured. When the block is exited normally,; whether by fallthrough or directed control flow (such as ``return`` or; ``break``), the autorelease pool is restored to the saved state, releasing all; the objects in it. When the block is exited with an exception, the pool is not; drained. ``@autoreleasepool`` may be used in non-ARC translation units, with equivalent; semantics. A program is ill-formed if it refers to the ``NSAutoreleasePool`` class. .. admonition:: Rationale. Autorelease pools are clearly important for the compiler to reason about, but; it is far too much to expect the compiler to accurately reason about control; dependencies between two calls. It is also very easy to accidentally forget; to drain an autorelease pool when using the manual API, and this can; significantly inflate the process's high-water-mark. The introduction of a; new scope is unfortunate but basically required for sane interaction with the; rest of the language. Not draining the pool during an unwind is apparently; required by the Objective-C exceptions implementation. .. _arc.misc.externally_retained:. Externally-Retained Variables; -----------------------------. In some situations, variables with strong ownership are considered; externally-retaine",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:91125,drain,drained,91125,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['drain'],['drained']
Energy Efficiency,"detailed in; `OpenCL C v3.0 6.7.8 <https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_C.html#addr-spaces-inference>`_. The default address space is ""generic-memory"", which is a virtual address space; that overlaps the global, local, and private address spaces. SYCL mode enables; following conversions:. - explicit conversions to/from the default address space from/to the address; space-attributed type; - implicit conversions from the address space-attributed type to the default; address space; - explicit conversions to/from the global address space from/to the; ``__attribute__((opencl_global_device))`` or; ``__attribute__((opencl_global_host))`` address space-attributed type; - implicit conversions from the ``__attribute__((opencl_global_device))`` or; ``__attribute__((opencl_global_host))`` address space-attributed type to the; global address space. All named address spaces are disjoint and sub-sets of default address space. The SPIR target allocates SYCL namespace scope variables in the global address; space. Pointers to default address space should get lowered into a pointer to a generic; address space (or flat to reuse more general terminology). But depending on the; allocation context, the default address space of a non-pointer type is assigned; to a specific address space. This is described in; `common address space deduction rules <https://www.khronos.org/registry/SYCL/specs/sycl-2020/html/sycl-2020.html#subsec:commonAddressSpace>`_; section. This is also in line with the behaviour of CUDA (`small example; <https://godbolt.org/z/veqTfo9PK>`_). ``multi_ptr`` class implementation example:. .. code-block:: C++. // check that SYCL mode is ON and we can use non-standard decorations; #if defined(__SYCL_DEVICE_ONLY__); // GPU/accelerator implementation; template <typename T, address_space AS> class multi_ptr {; // DecoratedType applies corresponding address space attribute to the type T; // DecoratedType<T, global_space>::type == ""__attribute__((ope",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SYCLSupport.rst:2539,allocate,allocates,2539,interpreter/llvm-project/clang/docs/SYCLSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SYCLSupport.rst,1,['allocate'],['allocates']
Energy Efficiency,"dicated rep as part of it's dynamic; complication phase. Also, if a basic block contains ONLY a move, then; that can be trivally translated into a conditional move... > I agree that we need a static data space. Otherwise, emulating global; > data gets unnecessarily complex. Definitely. Also a later item though. :). > We once talked about adding a symbolic thread-id field to each; > ..; > Instead, it could a great topic for a separate study. Agreed. :). > What is the semantics of the IA64 stop bit?. Basically, the IA64 writes instructions like this:; mov ...; add ...; sub ...; op xxx; op xxx; ;;; mov ...; add ...; sub ...; op xxx; op xxx; ;;. Where the ;; delimits a group of instruction with no dependencies between; them, which can all be executed concurrently (to the limits of the; available functional units). The ;; gets translated into a bit set in one; of the opcodes. The advantages of this representation is that you don't have to do some; kind of 'thread id scheduling' pass by having to specify ahead of time how; many threads to use, and the representation doesn't have a per instruction; overhead... > And finally, another thought about the syntax for arrays :-); > Although this syntax:; > array <dimension-list> of <type>; > is verbose, it will be used only in the human-readable assembly code so; > size should not matter. I think we should consider it because I find it; > to be the clearest syntax. It could even make arrays of function; > pointers somewhat readable. My only comment will be to give you an example of why this is a bad; idea. :). Here is an example of using the switch statement (with my recommended; syntax):. switch uint %val, label %otherwise, ; [%3 x {uint, label}] [ { uint %57, label %l1 }, ; { uint %20, label %l2 }, ; { uint %14, label %l3 } ]. Here it is with the syntax you are proposing:. switch uint %val, label %otherwise, ; array %3 of {uint, label} ; array of {uint, label}; { uint %57, label %l1 },; { uint %20, label %l2 },; { uint %14, labe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt:7659,schedul,scheduling,7659,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,1,['schedul'],['scheduling']
Energy Efficiency,"dif(). if(${t} IN_LIST need_network); list(APPEND labels needs_network); endif(). # These tests on ARM64 need much more than 20 minutes - increase the timeout; if(ROOT_ARCHITECTURE MATCHES arm64 OR ROOT_ARCHITECTURE MATCHES ppc64); set(thisTestTimeout 3000) # 50m; else(); set(thisTestTimeout 1200) # 20m; endif(). ROOT_ADD_TEST(tutorial-${tname}; COMMAND ${ROOT_root_CMD} -b -l -q ${createThreadPool} ${CMAKE_CURRENT_SOURCE_DIR}/${t}${${tname}-aclic}; PASSRC ${rc} FAILREGEX ""Error in <"" "": error:"" ""segmentation violation"" ""FROM HESSE STATUS=FAILED"" ""warning: Failed to call""; LABELS ${labels}; DEPENDS tutorial-hsimple ${${tname}-depends}; ENVIRONMENT ${TUTORIAL_ENV}; TIMEOUT ${thisTestTimeout}). if(${t} IN_LIST multithreaded); # Makes sure that this doesn't run in parallel with other multithreaded tutorials, and that cmake doesn't start too; # many other tests. That we use 4 processors is actually a lie, because IMT takes whatever it finds.; # However, even this poor indication of MT behaviour is a good hint for cmake to reduce congestion.; set_tests_properties(tutorial-${tname} PROPERTIES RESOURCE_LOCK multithreaded PROCESSORS ${NProcessors}); endif(); endforeach(). #---Loop over all MPI tutorials and define the corresponding test---------; foreach(t ${mpi_tutorials}); list(FIND returncode_1 ${t} index); if(index EQUAL -1); set(rc 0); else(); set(rc 255); endif(); string(REPLACE "".C"" """" tname ${t}); string(REPLACE ""/"" ""-"" tname ${tname}). # These tests on ARM64 need much more than 20 minutes - increase the timeout; if(ROOT_ARCHITECTURE MATCHES arm64 OR ROOT_ARCHITECTURE MATCHES ppc64); set(thisTestTimeout 3000) # 50m; else(); set(thisTestTimeout 1200) # 20m; endif(). ROOT_ADD_TEST(tutorial-${tname}; COMMAND ${MPIEXEC_EXECUTABLE} ${MPIEXEC_NUMPROC_FLAG} 4 ${ROOT_root_CMD} -b -l -q ${CMAKE_CURRENT_SOURCE_DIR}/${t}${${tname}-aclic}; PASSRC ${rc} FAILREGEX ""Error in <"" "": error:"" ""segmentation violation"" ""FROM HESSE STATUS=FAILED"" ""warning: Failed to call""; LABELS tutorial;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/CMakeLists.txt:24971,reduce,reduce,24971,tutorials/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/CMakeLists.txt,1,['reduce'],['reduce']
Energy Efficiency,"ding class as is the case in `EventHeader` and; `Event`. ``` {.cpp}; class EventHeader {; private:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;; // ... list of methods; ClassDef(EventHeader,1) //Event Header; };; ```. ### The Track Class. The `Track` class descends from **`TObject`** since tracks are in a; **`TClonesArray`** (i.e. a ROOT collection class) and contains a; selection of basic types and an array of vertices. Its **`TObject`**; inheritance enables `Track` to be in a collection and in `Event` is a; **`TClonesArray`** of `Tracks`. ``` {.cpp}; class Track : public TObject {; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Float_t fCharge; //Charge of this track; Float_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion. // method definitions ...; ClassDef(Track,1) //A track segment; };; ```. ### Writing the Tree. We create a simple tree with two branches both holding `Event` objects.; One is split and the other is not. We also create a pointer to an; `Event` object (`event`). ``` {.cpp}; void tree4w() {; // check to see if the event class is in the dictionary; // if it is not load the definition in libEvent.so; if (!TClassTable::GetDict(""Event"")) {; gSystem->Load(""$ROOTSYS/test/libEvent.so"");; }; // create a Tree file tree4.root; TFile f(""tree4.root"",""RECREATE",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:61465,charge,charge,61465,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['charge'],['charge']
Energy Efficiency,discourse category. You **must** have a Discourse account associated with the email address you are sending from or the email will be rejected. <table border=1>; <tr><th>Discourse Category</th><th>Email Address</th></tr>; <tr><td>Beginner</td><td>beginners@discourse.llvm.org</td></tr>; <tr><td>LLVM Project</td><td>llvmproject@discourse.llvm.org</td></tr>; <tr><td>IR & Optimizations</td><td>IR.Optimizations@discourse.llvm.org</td></tr>; <tr><td>IR & Optimizations - Loop Optimizations</td><td>IR.Optimizations-Loops@discourse.llvm.org</td></tr>; <tr><td>Code Generation</td><td>codegen@discourse.llvm.org</td></tr>; <tr><td>Code Generation - AMDGPU</td><td>codegen-amdgpu@discourse.llvm.org</td></tr>; <tr><td>Code Generation - Common Infrastructure</td><td>codegen-common@discourse.llvm.org</td></tr>; <tr><td>Code Generation - AArch64</td><td>codegen-aarch64@discourse.llvm.org</td></tr>; <tr><td>Code Generation - Arm</td><td>codegen-arm@discourse.llvm.org</td></tr>; <tr><td>Code Generation - PowerPC</td><td>codegen-powerpc@discourse.llvm.org</td></tr>; <tr><td>Code Generation - RISCV</td><td>codegen-riscv@discourse.llvm.org</td></tr>; <tr><td>Code Generation - WebAssembly</td><td>codegen-webassembly@discourse.llvm.org</td></tr>; <tr><td>Code Generation - X86</td><td>codegen-x86@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend</td><td>clang@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - Using Clang</td><td>clang-users@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - clangd</td><td>clangd@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - Building Clang</td><td>clang-build@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - Static Analyzer</td><td>clang-staticanalyzer@discourse.llvm.org</td></tr>; <tr><td>Runtimes</td><td>runtimes@discourse.llvm.org</td></tr>; <tr><td>Runtimes - C++</td><td>runtimes-cxx@discourse.llvm.org</td></tr>; <tr><td>Runtimes - Sanitizers</td><td>runtimes-sanitizers@discourse.llvm.org</td></tr>; <tr><td>Runtimes - C</td><td>run,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:3288,power,powerpc,3288,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,1,['power'],['powerpc']
Energy Efficiency,"duce.xor.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.xor.*``' intrinsics do a bitwise ``XOR``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smax:. '``llvm.vector.reduce.smax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smax.*``' intrinsics do a signed integer; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smin:. '``llvm.vector.reduce.smin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smin.*``' intrinsics do a signed integer; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umax:. '``llvm.vector.reduce.umax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umax.*``' intrinsics do an unsigned; integer ``MAX`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umin:. '``llvm.vector.reduce.umin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:657085,reduce,reduce,657085,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"duction. That is, the reduction begins with; the start value and performs an fadd operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fadd(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result + input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, negative zero (``-0.0``) can be used, as it is; the neutral value of floating point addition. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fadd.v4f32(float -0.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_mul:. '``llvm.vector.reduce.mul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.mul.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.mul.*``' intrinsics do an integer ``MUL``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmul:. '``llvm.vector.reduce.fmul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fmul.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmul.*``' intrinsics do a floating-point; ``MUL`` reduction of a vector, returning the result as a scalar. The return type; matches the element-t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:652699,reduce,reduce,652699,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"duled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llvm.amdgcn.iglp_opt An **experimental** intrinsic for instruction group level parallelism. The intrinsic; implements predefined intruction sche",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43729,schedul,schedule,43729,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['schedule']
Energy Efficiency,"e (by avoid the fast merge technique). The equivalent in TFileMerger is to call; merger->SetFastMethod(kFALSE); To make sure that the class emulation layer of ROOT does not double delete an object,; tell the StreamerElement representing one of the pointers pointing to the object; to never delete the object. For example:. TClass::AddRule(""HepMC::GenVertex m_event attributes=NotOwner"");. The handling of memory by the collection proxy has been improved in the case of a; collection of pointers which can now become owner of its content. The default, for backward compatibility reasons and to avoid double delete (at the expense; of memory leaks), the container of pointers are still not owning their content; unless they are a free standing container (i.e. itself not contained in another; object).; To make a container of pointers become owner of its content do something like:. TClass::AddRule(""ObjectVector<LHCb::MCRichDigitSummary> m_vector options=Owner"");. Added TKey::Reset and TKey::WriteFileKeepBuffer to allow derived classes (TBasket) to be re-use as key rather than always recreated.; TH1::Streamer and TGraph2D::Streamer no longer reset the kCanDelete bit directly so that the user can give; ownership of the object to the canvas they are stored with. However, if they are saved on their own, the mechanism; that associates them to the current directory (DirectoryAutoAdd) will now reset the bit to avoid any possible; ownsership confusion.; Added TFile::SetOffset and TFile::ReadBuffer(char *buf, Long64_t pos, Int_t len); to drastically reduce; the number of fseek done on the physical file when using the TTreeCache.; To support future changes in the API of the CollectionProxy, we added the new #define:; ROOT_COLLECTIONPROXY_VERSION and REFLEX_COLLECTIONPROXY_VERSION. Reduce possible confusions and conflicts by always using in TClass and TStreamerInfo the version of template instance names with ULong64_t and Long64_t rather than [unsigned] long long.; new Hadoop TFile plugin. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html:12504,reduce,reduce,12504,io/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html,1,['reduce'],['reduce']
Energy Efficiency,"e `LinkDef.h` file tells `rootcling` which classes should; be added to the dictionary. ``` {.cpp}; #ifdef __CLING__; #pragma link C++ class SClass;; #endif; ```. Three options can trail the class name:. - `-` : tells `rootcling` **not** to generate the `Streamer` method for; this class. This is necessary for those classes that need a; customized `Streamer` method. ``` {.cpp}; #pragma link C++ class SClass-; // no streamer; ```. - **`!`** : tells `rootcling` **not** to generate the; `operator>>(`**`TBuffer`** `&b,MyClass *&obj)` method for this; class. This is necessary to be able to write pointers to objects of; classes not inheriting from **`TObject`**. ``` {.cpp}; #pragma link C++ class SClass!; // no >> operator; // or; #pragma link C++ class SClass-!; // no streamer, no >> operator; ```. - **+** : in ROOT version 1 and 2 tells `rootcling` to generate a; `Streamer` with extra byte count information. This adds an integer; to each object in the output buffer, but it allows for powerful; error correction in case a `Streamer` method is out of sync with; data in the file. The `+` option is mutual exclusive with both the; `-` and `!` options. IMPORTANT NOTE: In ROOT Version 3 and later, a ""+"" after the class name; tells `rootcling` to use the new I/O system. The byte count check is; always added. The new I/O system has many advantages including support; automatic schema evolution, full support for STL collections and better; run-time performance. We strongly recommend using it. ``` {.cpp}; #pragma link C++ class SClass+; // add byte count; ```. For information on `Streamers` see ""Input/Output"". To get help on; `rootcling` type on the UNIX command line: **`rootcling -h`**. #### The Order Matters. When using template classes, the order of the pragma statements matters.; For example, here is a template class `Tmpl` and a normal class `Norm`,; which holds a specialized instance of a `Tmpl`:. ``` {.cpp}; class Norm {; private:; Tmpl<int>* fIntTmpl;; public:; ...; };; ```. Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md:22117,power,powerful,22117,documentation/users-guide/AddingaClass.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md,1,['power'],['powerful']
Energy Efficiency,"e algorithm is controlled by the given absolute and relative tolerance. The iterations are continued until the following condition is satisfied; $$; absErr <= max ( epsAbs, epsRel * Integral); $$; Where *absErr* is an estimate of the absolute error (it can be retrieved with `GSLIntegrator::Error()`) and *Integral* is the estimate of the function integral; (it can be obtained with `GSLIntegrator::Result()`). The possible integration algorithm types to use with the GSLIntegrator are the following. More information is provided in the `GSL` users documentation.; * `ROOT::Math::Integration::kNONADAPTIVE` : based on `gsl_integration_qng`. It is a non-adaptive procedure which uses fixed Gauss-Kronrod-Patterson abscissae; to sample the integrand at a maximum of 87 points. It is provided for fast integration of smooth functions.; * `ROOT::Math::Integration::kADAPTIVE`: based on `gsl_integration_qag`. It is an adaptiva Gauss-Kronrod integration algorithm, the integration region is divided into subintervals, and on each; iteration the subinterval with the largest estimated error is bisected. It is possible to specify the integration rule as an extra enumeration parameter. The possible rules are; * `Integration::kGAUSS15` : 15 points Gauss-Konrod rule (value = 1); * `Integration::kGAUSS21` : 21 points Gauss-Konrod rule (value = 2); * `Integration::kGAUSS31` : 31 points Gauss-Konrod rule (value = 3); * `Integration::kGAUSS41` : 41 points Gauss-Konrod rule (value = 4); * `Integration::kGAUSS51` : 51 points Gauss-Konrod rule (value = 5); * `Integration::kGAUSS61` : 61 points Gauss-Konrod rule (value = 6); 	 The higher-order rules give better accuracy for smooth functions, while lower-order rules save time when the function contains local difficulties, such as discontinuities. If no integration rule; 	 is passed, the 31 points rule is used as default. * 	 `ROOT::Math::Integration::kADAPTIVESINGULAR`: based on `gsl_integration_qags`. It is an integration type which can be used in the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:56553,adapt,adaptiva,56553,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['adapt'],['adaptiva']
Energy Efficiency,"e are a lot of different ways to do this. :). .. _dss_sortedvectormap:. A sorted 'vector'; ^^^^^^^^^^^^^^^^^. If your usage pattern follows a strict insert-then-query approach, you can; trivially use the same approach as :ref:`sorted vectors for set-like containers; <dss_sortedvectorset>`. The only difference is that your query function (which; uses std::lower_bound to get efficient log(n) lookup) should only compare the; key, not both the key and value. This yields the same advantages as sorted; vectors for sets. .. _dss_stringmap:. llvm/ADT/StringMap.h; ^^^^^^^^^^^^^^^^^^^^. Strings are commonly used as keys in maps, and they are difficult to support; efficiently: they are variable length, inefficient to hash and compare when; long, expensive to copy, etc. StringMap is a specialized container designed to; cope with these issues. It supports mapping an arbitrary range of bytes to an; arbitrary other object. The StringMap implementation uses a quadratically-probed hash table, where the; buckets store a pointer to the heap allocated entries (and some other stuff).; The entries in the map must be heap allocated because the strings are variable; length. The string data (key) and the element object (value) are stored in the; same allocation with the string data immediately after the element object.; This container guarantees the ""``(char*)(&Value+1)``"" points to the key string; for a value. The StringMap is very fast for several reasons: quadratic probing is very cache; efficient for lookups, the hash value of strings in buckets is not recomputed; when looking up an element, StringMap rarely has to touch the memory for; unrelated objects when looking up a value (even when hash collisions happen),; hash table growth does not recompute the hash values for strings already in the; table, and each pair in the map is store in a single allocation (the string data; is stored in the same allocation as the Value of a pair). StringMap also provides query methods that take byte ran",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:88924,allocate,allocated,88924,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocated']
Energy Efficiency,"e corresponds; to the level 0 in the stored array, while the last node will correspond; to level `n`. For each level, the node, volume and global matrix can be; retrieved using corresponding getters:. ~~~{.cpp}; TGeoHMatrix *GetMatrix(Int_t level=-1) const; TGeoNode *GetNode(Int_t level=-1) const; TGeoShape *GetShape(Int_t level=-1) const; TGeoVolume *GetVolume(Int_t level=-1) const; ~~~. By default the object at level n is retrieved (the align-able object). Once created, a physical node can be misaligned, meaning that its; positioning matrix or even the shape.:. ~~~{.cpp}; void Align(TGeoMatrix* newmat=0, TGeoShape* newshape=0,; Bool_t check=kFALSE); ~~~. The convention used is that newmat represents the new local matrix of; the last node in the branch with respect to its mother volume. The; `Align()` method will actually duplicate the corresponding branch within; the logical hierarchy, creating new volumes and nodes. This is mandatory; in order to avoid problems due to replicated volumes and can create; exhaustive memory consumption if used abusively. Once aligned, a physical node is ready to be tracked. The operation can; be done only after the geometry was closed. Important NOTE: Calling the `Align()` method for a physical node changes; the node pointers for the stored node branch in the active geometry, Due; to this the other defined physical nodes containing elements of this; path will be invalid. Example:. ~~~{.cpp}; TGeoPhysicalNode *pn1 =; gGeoManager->MakePhysicalNode(""/A_1/B_1/C_2"");; TGeoPhysicalNode *pn2 =; gGeoManager->MakePhysicalNode(""/A_1/B_1/C_3"");; ...; pn1->Align(...);; ~~~. The call to `pn1->Align()` will invalidate the pointer to the node `B_1`; in `pn2` object.. The way out is to either call `pn1->Align()` before; the creation of `pn2`, either to use a global method that will correct; all existing physical nodes:. ~~~{.cpp}; void RefreshPhysicalNodes(Bool_t lock = kTRUE); ~~~. The method above will optionally lock the possibility of doing any; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:109606,consumption,consumption,109606,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['consumption'],['consumption']
Energy Efficiency,"e creating the volume; itself, so we will describe the bits and pieces needed for making the; geometry before moving to an architectural point of view. As far as materials are concerned, they represent the physical; properties of the solid from which a volume is made. Materials are just; a support for the data that has to be provided to the tracking engine; that uses this geometry package. Due to this fact, the; **`TGeoMaterial`** class is more like a thin data structure needed for; building the corresponding native materials of the Monte-Carlo tracking; code that uses **`TGeo`**. ### Elements, Materials and Mixtures. In order to make easier material and mixture creation, one can use the; pre-built table of elements owned by **`TGeoManager`** class:. ``` {.cpp}; TGeoElementTable *table = gGeoManager->GetElementTable();; TGeoElement *element1 = table->GetElement(Int_t Z);; TGeoElement *element2 = table->FindElement(""Copper"");; ```. Materials made of single elements can be defined by their atomic mass; (`A`), charge (`Z`) and density (`rh`o). One can also create a material; by specifying the element that it is made of. Optionally the radiation; and absorption lengths can be also provided; otherwise they can be; computed on-demand [`G3`]. The class representing them is; **`TGeoMaterial`**:. ``` {.cpp}; TGeoMaterial(const char *name,Double_t a,Double_t z,; Double_t density, Double_t radlen=0,Double_t intlen=0);; TGeoMaterial(const char *name, TGeoElement *elem,; Double_t density);; TGeoMaterial(const char* name, Double_t a, Double_t z,; Double_t rho,; TGeoMaterial::EGeoMaterialState state,; Double_t temperature = STP_temperature,; Double_t pressure = STP_pressure); ```. Any material or derived class is automatically indexed after creation.; The assigned index is corresponding to the last entry in the list of; materials owned by **`TGeoManager`** class. This can be changed using; the **`TGeoMaterial`**`::SetIndex()` method, however it is not; recommended while using the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:14140,charge,charge,14140,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['charge'],['charge']
Energy Efficiency,"e definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProofd plugin. Add automatically the line 'Path.ForceRemote 1' to the; session rootrc file if the ROOT version is < 5.24/00 ; this acts; as a workaround for the wrong TTreeCache initialization at the; transition between local and remote files fixed in 5.24/00 . Enable mass storage domain settings when working with; TChain's; in multi-master mode. The Mass Storage Domain must be specified as; option in the URL.              ; chain.AddFile(""root:// .....?msd=CERN"").  and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of the processing time:. Instantaneous processing rate, which is now better; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:5033,monitor,monitor,5033,proof/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html,1,['monitor'],['monitor']
Energy Efficiency,"e done |; +------------+-------------+------------------------+---------------------------------+. .. _coro.end.results:. 'llvm.coro.end.results' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.end.results(...). Overview:; """""""""""""""""". The '``llvm.coro.end.results``' intrinsic captures values to be returned from; unique-suspend returned-continuation coroutines. Arguments:; """""""""""""""""""". The number of arguments must match the return type of the continuation function:. - if the return type of the continuation function is ``void`` there must be no; arguments. - if the return type of the continuation function is a ``struct``, the arguments; will be of element types of that ``struct`` in order;. - otherwise, it is just the return value of the continuation function. .. code-block:: llvm. define {ptr, ptr} @g(ptr %buffer, ptr %ptr, i8 %val) presplitcoroutine {; entry:; %id = call token @llvm.coro.id.retcon.once(i32 8, i32 8, ptr %buffer,; ptr @prototype,; ptr @allocate, ptr @deallocate); %hdl = call ptr @llvm.coro.begin(token %id, ptr null). ... cleanup:; %tok = call token (...) @llvm.coro.end.results(i8 %val); call i1 @llvm.coro.end(ptr %hdl, i1 0, token %tok); unreachable. ... declare i8 @prototype(ptr, i1 zeroext); . 'llvm.coro.end.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i1 @llvm.coro.end.async(ptr <handle>, i1 <unwind>, ...). Overview:; """""""""""""""""". The '``llvm.coro.end.async``' marks the point where execution of the resume part; of the coroutine should end and control should return to the caller. As part of; its variable tail arguments this instruction allows to specify a function and; the function's arguments that are to be tail called as the last action before; returning. Arguments:; """""""""""""""""""". The first argument should refer to the coroutine handle of the enclosing; coroutine. A frontend is allowed to supply null as the first parameter, in this; case `coro-early` pass will replace the null with a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:48047,allocate,allocate,48047,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['allocate'],['allocate']
Energy Efficiency,"e embedded in the node type ``T``, usually; ``T`` publicly derives from ``ilist_node<T>``. .. _dss_ilist_sentinel:. Sentinels; ^^^^^^^^^. ``ilist``\ s have another specialty that must be considered. To be a good; citizen in the C++ ecosystem, it needs to support the standard container; operations, such as ``begin`` and ``end`` iterators, etc. Also, the; ``operator--`` must work correctly on the ``end`` iterator in the case of; non-empty ``ilist``\ s. The only sensible solution to this problem is to allocate a so-called *sentinel*; along with the intrusive list, which serves as the ``end`` iterator, providing; the back-link to the last element. However conforming to the C++ convention it; is illegal to ``operator++`` beyond the sentinel and it also must not be; dereferenced. These constraints allow for some implementation freedom to the ``ilist`` how to; allocate and store the sentinel. The corresponding policy is dictated by; ``ilist_traits<T>``. By default a ``T`` gets heap-allocated whenever the need; for a sentinel arises. While the default policy is sufficient in most cases, it may break down when; ``T`` does not provide a default constructor. Also, in the case of many; instances of ``ilist``\ s, the memory overhead of the associated sentinels is; wasted. To alleviate the situation with numerous and voluminous; ``T``-sentinels, sometimes a trick is employed, leading to *ghostly sentinels*. Ghostly sentinels are obtained by specially-crafted ``ilist_traits<T>`` which; superpose the sentinel with the ``ilist`` instance in memory. Pointer; arithmetic is used to obtain the sentinel, which is relative to the ``ilist``'s; ``this`` pointer. The ``ilist`` is augmented by an extra pointer, which serves; as the back-link of the sentinel. This is the only field in the ghostly; sentinel which can be legally accessed. .. _dss_other:. Other Sequential Container options; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Other STL containers are available, such as ``std::string``. There are a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:69681,allocate,allocated,69681,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocated']
Energy Efficiency,"e files 1.000000; Info in <TCanvas::Print>:; file ResistanceDistribution.png has been created; *==* ----- End of Job ----- Date/Time = Wed Feb 15 23:00:08 2012; Lite-0: all output objects have been merged; ```. Log files of the whole processing chain are kept in the directory; `~.proof` for each worker node. This is very helpful for debugging or if; something goes wrong. As the method described here also works without; using PROOF, the development work on an analysis script can be done in; the standard way on a small subset of the data, and only for the full; processing one would use parallelism via PROOF. It is worth to remind the reader that the speed of typical data analysis; programs limited by the I/O speed (for example the latencies implied by; reading data from a hard drive). It is therefore expected that this; limitation cannot be eliminated with the usage of any parallel analysis; toolkit. ### Optimisation Regarding N-tuples ###. ROOT automatically applies compression algorithms on n-tuples to reduce; the memory consumption. A value that is in most cases the same will; consume only small space on your disk (but it has to be decompressed on; reading). Nevertheless, you should think about the design of your; n-tuples and your analyses as soon as the processing time exceeds some; minutes. - Try to keep your n-tuples simple and use appropriate variable types.; If your measurement has only a limited precision, it is needless to; store it with double precision. - Experimental conditions that do not change with every single; measurement should be stored in a separate tree. Although the; compression can handle redundant values, the processing time; increase with every variable that has to be filled. - The function `SetCacheSize(long)` specifies the size of the cache; for reading a `TTree` object from a file. The default value is 30MB.; A manual increase may help in certain situations. Please note that; the caching mechanism can cover only one `TTree` object per `TFi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md:13338,reduce,reduce,13338,documentation/primer/filio.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md,2,"['consumption', 'reduce']","['consumption', 'reduce']"
Energy Efficiency,"e files:. #. a.out.0.0.preopt.bc (Before any link-time optimizations (LTO) are applied); #. a.out.0.2.internalize.bc (After initial optimizations are applied); #. a.out.0.4.opt.bc (After an extensive set of optimizations); #. a.out.0.5.precodegen.bc (After LTO but before translating into machine code). Execute one of the following commands to identify the source of the problem:. #. ``opt ""-passes=lto<O3>"" a.out.0.2.internalize.bc``; #. ``llc a.out.0.5.precodegen.bc``. If one of these do crash, you should be able to reduce; this with :program:`llvm-reduce`; command line (use the bc file corresponding to the command above that failed):. .. code-block:: bash. llvm-reduce --test reduce.sh a.out.0.2.internalize.bc. Example of reduce.sh script. .. code-block:: bash. $ cat reduce.sh; #!/bin/bash -e. path/to/not --crash path/to/opt ""-passes=lto<O3>"" $1 -o temp.bc 2> err.log; grep -q ""It->second == &Insn"" err.log. Here we have grepped the failed assert message. Please run this, then file a bug with the instructions and reduced .bc file; that llvm-reduce emits. .. _miscompiling:. Miscompilations; ===============. If clang successfully produces an executable, but that executable doesn't run; right, this is either a bug in the code or a bug in the compiler. The first; thing to check is to make sure it is not using undefined behavior (e.g.; reading a variable before it is defined). In particular, check to see if the; program is clean under various `sanitizers; <https://github.com/google/sanitizers>`_ (e.g. ``clang; -fsanitize=undefined,address``) and `valgrind <http://valgrind.org/>`_. Many; ""LLVM bugs"" that we have chased down ended up being bugs in the program being; compiled, not LLVM. Once you determine that the program itself is not buggy, you should choose; which code generator you wish to compile the program with (e.g. LLC or the JIT); and optionally a series of LLVM passes to run. For example:. .. code-block:: bash. bugpoint -run-llc [... optzn passes ...] file-to-test.bc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:7882,reduce,reduced,7882,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduced']
Energy Efficiency,"e goal of this tutorial is to introduce you to LLVM's ORC JIT APIs, show how; these APIs interact with other parts of LLVM, and to teach you how to recombine; them to build a custom JIT that is suited to your use-case. The structure of the tutorial is:. - Chapter #1: Investigate the simple KaleidoscopeJIT class. This will; introduce some of the basic concepts of the ORC JIT APIs, including the; idea of an ORC *Layer*. - `Chapter #2 <BuildingAJIT2.html>`_: Extend the basic KaleidoscopeJIT by adding; a new layer that will optimize IR and generated code. - `Chapter #3 <BuildingAJIT3.html>`_: Further extend the JIT by adding a; Compile-On-Demand layer to lazily compile IR. - `Chapter #4 <BuildingAJIT4.html>`_: Improve the laziness of our JIT by; replacing the Compile-On-Demand layer with a custom layer that uses the ORC; Compile Callbacks API directly to defer IR-generation until functions are; called. - `Chapter #5 <BuildingAJIT5.html>`_: Add process isolation by JITing code into; a remote process with reduced privileges using the JIT Remote APIs. To provide input for our JIT we will use a lightly modified version of the; Kaleidoscope REPL from `Chapter 7 <LangImpl07.html>`_ of the ""Implementing a; language in LLVM tutorial"". Finally, a word on API generations: ORC is the 3rd generation of LLVM JIT API.; It was preceded by MCJIT, and before that by the (now deleted) legacy JIT.; These tutorials don't assume any experience with these earlier APIs, but; readers acquainted with them will see many familiar elements. Where appropriate; we will make this connection with the earlier APIs explicit to help people who; are transitioning from them to ORC. JIT API Basics; ==============. The purpose of a JIT compiler is to compile code ""on-the-fly"" as it is needed,; rather than compiling whole programs to disk ahead of time as a traditional; compiler does. To support that aim our initial, bare-bones JIT API will have; just two functions:. 1. ``Error addModule(std::unique_ptr<Module",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst:1916,reduce,reduced,1916,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst,1,['reduce'],['reduced']
Energy Efficiency,"e handling of ACLiC options on the command line (for example a.C+g).; In TClass::BuildEmulatedRealData properly handle the case of TNamed member that are not base class.; On the command line:; ; Fix the tab-completion of filenames in the sub-directories.; Prevent the unadvertent replacement of an arrow with a dot when the left side is actually a pointer. More user friendly stacktrace in case of a crash, with hints where; the problem might be. On Linux and MacOS X these stacktraces are generated; by the script $ROOTSYS/etc/gdb-backtrace.sh. Using the Root.StackTraceMessage; resource one can customize the message printed by the script. The entire; script can be replaced using the Root.StacktraceScript resource.; Numerous minor bug fixes... New module editline ; The new module editline enhances the prompt, giving type and syntax feedback using e.g. colors.; Class names are highlighted blue when typed, indicating that it is known to ROOT.; Matching parenthesis pairs are highlighted green when typed, or when the cursor is moved to a bracket. This works for () {} and [] brackets.; Any mismatched brackets (those without a matching partner) will be highlighted red when typed or when the cursor is moved to the bracket.; Tab completion output is colored magenta to differentiate between tab completion output and user input.; All of the colors are configurable in the .rootrc file.; They can be specified as #rgb or #rrggbb or color names:; black, red, green, yellow, blue, magenta, cyan or white.; They can be followed by an optional bold (alias light) or underlined.; Rint.ReverseColor allows to quickly toggle between the default ""light on dark"" (yes) instead of ""dark on light"" (no), depending on the terminal background.; An example configuration would be:. Rint.TypeColor: blue; Rint.BracketColor: bold green; Rint.BadBracketColor: underlined red; Rint.TabColor: magenta; Rint.PromptColor: black; Rint.ReverseColor: no. The enhanced prompt is available on all platforms with [n]curses",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v526/index.html:1714,green,green,1714,core/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v526/index.html,1,['green'],['green']
Energy Efficiency,"e i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intri",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43129,schedul,scheduled,43129,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency,"e i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.and.*``' intrinsics do a bitwise ``AND``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_or:. '``llvm.vector.reduce.or.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scalar. The return type matches the; element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_xor:. '``llvm.vector.reduce.xor.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.xor.*``' intrinsics do a bitwise ``XOR``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smax:. '``llvm.vector.reduce.smax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smax.*``' intrinsics do a signed integer; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smin:. '``llvm.vector.reduce.smin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:656086,reduce,reduce,656086,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"e implementation featured in; `Chromium <https://cs.chromium.org/chromium/src/components/gwp_asan/>`_. The; long-term support goal is to ensure feature-parity where reasonable, and to; support compiler-rt as the reference implementation. Allocator Support; -----------------. GWP-ASan is not a replacement for a traditional allocator. Instead, it works by; inserting stubs into a supporting allocator to redirect allocations to GWP-ASan; when they're chosen to be sampled. These stubs are generally implemented in the; implementation of ``malloc()``, ``free()`` and ``realloc()``. The stubs are; extremely small, which makes using GWP-ASan in most allocators fairly trivial.; The stubs follow the same general pattern (example ``malloc()`` pseudocode; below):. .. code:: cpp. #ifdef INSTALL_GWP_ASAN_STUBS; gwp_asan::GuardedPoolAllocator GWPASanAllocator;; #endif. void* YourAllocator::malloc(..) {; #ifdef INSTALL_GWP_ASAN_STUBS; if (GWPASanAllocator.shouldSample(..)); return GWPASanAllocator.allocate(..);; #endif. // ... the rest of your allocator code here.; }. Then, all the supporting allocator needs to do is compile with; ``-DINSTALL_GWP_ASAN_STUBS`` and link against the GWP-ASan library! For; performance reasons, we strongly recommend static linkage of the GWP-ASan; library. Guarded Allocation Pool; -----------------------. The core of GWP-ASan is the guarded allocation pool. Each sampled allocation is; backed using its own *guarded* slot, which may consist of one or more accessible; pages. Each guarded slot is surrounded by two *guard* pages, which are mapped as; inaccessible. The collection of all guarded slots makes up the *guarded; allocation pool*. Buffer Underflow/Overflow Detection; -----------------------------------. We gain buffer-overflow and buffer-underflow detection through these guard; pages. When a memory access overruns the allocated buffer, it will touch the; inaccessible guard page, causing memory exception. This exception is caught and; handled by the in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:2844,allocate,allocate,2844,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['allocate'],['allocate']
Energy Efficiency,"e integer constant.; - ``M``: Print as a register set suitable for ldm/stm. Also prints *all*; register operands subsequent to the specified one (!), so use carefully.; - ``Q``: Print the low-order register of a register-pair, or the low-order; register of a two-register operand.; - ``R``: Print the high-order register of a register-pair, or the high-order; register of a two-register operand.; - ``H``: Print the second register of a register-pair. (On a big-endian system,; ``H`` is equivalent to ``Q``, and on little-endian system, ``H`` is equivalent; to ``R``.). .. FIXME: H doesn't currently support printing the second register; of a two-register operand. - ``e``: Print the low doubleword register of a NEON quad register.; - ``f``: Print the high doubleword register of a NEON quad register.; - ``m``: Print the base register of a memory operand without the ``[`` and ``]``; adornment. Hexagon:. - ``L``: Print the second register of a two-register operand. Requires that it; has been allocated consecutively to the first. .. FIXME: why is it restricted to consecutive ones? And there's; nothing that ensures that happens, is there?. - ``I``: Print the letter 'i' if the operand is an integer constant, otherwise; nothing. Used to print 'addi' vs 'add' instructions. LoongArch:. - ``z``: Print $zero register if operand is zero, otherwise print it normally. MSP430:. No additional modifiers. MIPS:. - ``X``: Print an immediate integer as hexadecimal; - ``x``: Print the low 16 bits of an immediate integer as hexadecimal.; - ``d``: Print an immediate integer as decimal.; - ``m``: Subtract one and print an immediate integer as decimal.; - ``z``: Print $0 if an immediate zero, otherwise print normally.; - ``L``: Print the low-order register of a two-register operand, or prints the; address of the low-order word of a double-word memory operand. .. FIXME: L seems to be missing memory operand support. - ``M``: Print the high-order register of a two-register operand, or prints the; addre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:237322,allocate,allocated,237322,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"e is incompatible with the ``minsize``, ``optsize``, and; ``optnone`` attributes.; ``optforfuzzing``; This attribute indicates that this function should be optimized; for maximum fuzzing signal.; ``optnone``; This function attribute indicates that most optimization passes will skip; this function, with the exception of interprocedural optimization passes.; Code generation defaults to the ""fast"" instruction selector.; This attribute cannot be used together with the ``alwaysinline``; attribute; this attribute is also incompatible; with the ``minsize``, ``optsize``, and ``optdebug`` attributes. This attribute requires the ``noinline`` attribute to be specified on; the function as well, so the function is never inlined into any caller.; Only functions with the ``alwaysinline`` attribute are valid; candidates for inlining into the body of this function.; ``optsize``; This attribute suggests that optimization passes and code generator; passes make choices that keep the code size of this function low,; and otherwise do optimizations specifically to reduce code size as; long as they do not significantly impact runtime performance.; This attribute is incompatible with the ``optdebug`` and ``optnone``; attributes.; ``""patchable-function""``; This attribute tells the code generator that the code; generated for this function needs to follow certain conventions that; make it possible for a runtime function to patch over it later.; The exact effect of this attribute depends on its string value,; for which there currently is one legal possibility:. * ``""prologue-short-redirect""`` - This style of patchable; function is intended to support patching a function prologue to; redirect control away from the function in a thread safe; manner. It guarantees that the first instruction of the; function will be large enough to accommodate a short jump; instruction, and will be sufficiently aligned to allow being; fully changed via an atomic compare-and-swap instruction.; While the first requir",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:96600,reduce,reduce,96600,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"e models are generated by TableGen by the SubtargetEmitter,; using the ``CodeGenSchedModels`` class. This is distinct from the itinerary; method of specifying machine resource use. The tool ``utils/schedcover.py``; can be used to determine which instructions have been covered by the; schedule model description and which haven't. The first step is to use the; instructions below to create an output file. Then run ``schedcover.py`` on the; output file:. .. code-block:: shell. $ <src>/utils/schedcover.py <build>/lib/Target/AArch64/tblGenSubtarget.with; instruction, default, CortexA53Model, CortexA57Model, CycloneModel, ExynosM3Model, FalkorModel, KryoModel, ThunderX2T99Model, ThunderXT8XModel; ABSv16i8, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_2VXVY_2cyc, KryoWrite_2cyc_XY_XY_150ln, ,; ABSv1i64, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_1VXVY_2cyc, KryoWrite_2cyc_XY_noRSV_67ln, ,; ... To capture the debug output from generating a schedule model, change to the; appropriate target directory and use the following command:; command with the ``subtarget-emitter`` debug option:. .. code-block:: shell. $ <build>/bin/llvm-tblgen -debug-only=subtarget-emitter -gen-subtarget \; -I <src>/lib/Target/<target> -I <src>/include \; -I <src>/lib/Target <src>/lib/Target/<target>/<target>.td \; -o <build>/lib/Target/<target>/<target>GenSubtargetInfo.inc.tmp \; > tblGenSubtarget.dbg 2>&1. Where ``<build>`` is the build directory, ``src`` is the source directory,; and ``<target>`` is the name of the target.; To double check that the above command is what is needed, one can capture the; exact TableGen command from a build by using:. .. code-block:: shell. $ VERBOSE=1 make ... and search for ``llvm-tblgen`` commands in the output. Instruction Relation Mapping; ----------------------------. This TableGen feature is used to relate instructions with each other. It is; particularly useful when you have multiple instruction formats and need to; switch between them after instruction sele",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:43992,schedul,schedule,43992,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['schedul'],['schedule']
Energy Efficiency,"e of the basic block; that you are interested to visualize and filters all the previous; ``view-*-dags`` options. .. _Build initial DAG:. Initial SelectionDAG Construction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The initial SelectionDAG is na\ :raw-html:`&iuml;`\ vely peephole expanded from; the LLVM input by the ``SelectionDAGBuilder`` class. The intent of this pass; is to expose as much low-level, target-specific details to the SelectionDAG as; possible. This pass is mostly hard-coded (e.g. an LLVM ``add`` turns into an; ``SDNode add`` while a ``getelementptr`` is expanded into the obvious; arithmetic). This pass requires target-specific hooks to lower calls, returns,; varargs, etc. For these features, the :raw-html:`<tt>` `TargetLowering`_; :raw-html:`</tt>` interface is used. .. _legalize types:; .. _Legalize SelectionDAG Types:; .. _Legalize SelectionDAG Ops:. SelectionDAG LegalizeTypes Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the types that; are natively supported by the target. There are two main ways of converting values of unsupported scalar types to; values of supported types: converting small types to larger types (""promoting""),; and breaking up large integer types into smaller ones (""expanding""). For; example, a target might require that all f32 values are promoted to f64 and that; all i1/i8/i16 values are promoted to i32. The same target might require that; all i64 values be expanded into pairs of i32 values. These changes can insert; sign and zero extensions as needed to make sure that the final code has the same; behavior as the input. There are two main ways of converting values of unsupported vector types to; value of supported types: splitting vector types, multiple times if necessary,; until a legal type is found, and extending vector types by adding elements to; the end to round them out to legal types (""widening""). If a vector gets split; all the way down to single-element parts with no",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:40972,charge,charge,40972,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['charge'],['charge']
Energy Efficiency,"e or @protocol; declaration. Clang does not allow variable declarations to appear; within these declarations unless they are marked extern.; Variables may still be declared in an @implementation. @interface XX; int a; // not allowed in clang; int b = 1; // not allowed in clang; extern int c; // allowed; @end. C++ compatibility. Variable-length arrays. GCC and C99 allow an array's size to be determined at run; time. This extension is not permitted in standard C++. However, Clang; supports such variable length arrays for compatibility with GNU C and; C99 programs.; If you would prefer not to use this extension, you can disable it with; -Werror=vla. There are several ways to fix your code:. replace the variable length array with a fixed-size array if you can; determine a reasonable upper bound at compile time; sometimes this is as; simple as changing int size = ...; to const int size; = ...; (if the initializer is a compile-time constant);; use std::vector or some other suitable container type;; or; allocate the array on the heap instead using new Type[] -; just remember to delete[] it. Unqualified lookup in templates. Some versions of GCC accept the following invalid code:. template <typename T> T Squared(T x) {; return Multiply(x, x);; }. int Multiply(int x, int y) {; return x * y;; }. int main() {; Squared(5);; }. Clang complains:. my_file.cpp:2:10: error: call to function 'Multiply' that is neither visible in the template definition nor found by argument-dependent lookup; return Multiply(x, x);; ^; my_file.cpp:10:3: note: in instantiation of function template specialization 'Squared<int>' requested here; Squared(5);; ^; my_file.cpp:5:5: note: 'Multiply' should be declared prior to the call site; int Multiply(int x, int y) {; ^. The C++ standard says that unqualified names like Multiply; are looked up in two ways. First, the compiler does unqualified lookup in the scope; where the name was written. For a template, this means the lookup is; done at the point where th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/compatibility.html:11652,allocate,allocate,11652,interpreter/llvm-project/clang/www/compatibility.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/compatibility.html,1,['allocate'],['allocate']
Energy Efficiency,"e recorded in the history; file `$HOME/.root_hist`. It is a text file, and you can edit, cut, and; paste from it. You can specify the history file in the `system.rootrc`; file, by setting the `Rint.History `option. You can also turn off the; command logging in the `system.rootrc` file with the option:; `Rint.History: -`. The number of history lines to be kept can be set also in `.rootrc`; by:. ```; Rint.HistSize: 500; Rint.HistSave: 400; ```. The first value defines the maximum of lines kept; once it is reached; all, the last `HistSave` lines will be removed. One can set `HistSize`; to 0 to disable history line management. There is also implemented an; environment variable called `ROOT_HIST`. By setting; `ROOT_HIST=300:200` the above values can be overriden - the first; value corresponds to `HistSize`, the (optional) second one to; `HistSave`. You can set `ROOT_HIST=0` to disable the history. ### Tracking Memory Leaks. You can track memory usage and detect leaks by monitoring the number; of objects that are created and deleted (see **`TObjectTable`**). To; use this facility, edit the file `$ROOTSYS/etc/system.rootrc` or; `.rootrc` if you have this file and add the two following lines:. ```; Root.ObjectStat: 1; ```. In your code or on the command line you can type the line:. ``` {.cpp}; gObjectTable->Print();; ```. This line will print the list of all active classes and the number of; instances for each class. By comparing consecutive print outs, you can; see objects that you forgot to delete. Note that this method cannot; show leaks coming from the allocation of non-objects or classes; unknown to ROOT. ## Converting from PAW to ROOT. The web page at:; <http://root.cern.ch/root/HowtoConvertFromPAW.html#TABLE> gives the; ""translation"" table of some commonly used PAW commands into ROOT. If; you move the mouse cursor over the picture at:; <http://root.cern.ch/root/HowtoConvertFromPAW.html#SET>, you will get; the corresponding ROOT commands as tooltips. ### Converting HB",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md:39510,monitor,monitoring,39510,documentation/users-guide/GettingStarted.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md,1,['monitor'],['monitoring']
Energy Efficiency,"e reduction strategy to obtain much smaller test; cases that still have the same property as the original one. This will be done; via classic delta debugging and by adding some IR-specific reductions (e.g.; replacing globals, removing unused instructions, etc), similar to what; already exists, but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpoint’s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test that’s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpoint’s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isn’t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. It’s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduce’s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the tool’s beha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:1396,reduce,reduce,1396,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md,1,['reduce'],['reduce']
Energy Efficiency,"e result vector type. The fifth operand is the explicit vector length of; the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.fmuladd``' intrinsic performs floating-point multiply-add (:ref:`llvm.fuladd <int_fmuladd>`); of the first, second, and third vector operand on each enabled lane. The result; on disabled lanes is a :ref:`poison value <poisonvalues>`. The operation is; performed in the default floating-point environment. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.fmuladd.v4f32(<4 x float> %a, <4 x float> %b, <4 x float> %c, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.fmuladd(<4 x float> %a, <4 x float> %b, <4 x float> %c); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_reduce_add:. '``llvm.vp.reduce.add.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.add.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.add.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``ADD`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.add``' intrinsic performs the integer ``ADD`` reduction; (:ref:`llvm.vector.reduce.add <int_vector_reduce",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:748417,reduce,reduce,748417,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"e shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. Lua License; ------. ### Included only if built with Lua support. http://www.lua.org/license.html. > Copyright (C) 1994-2020 Lua.org, PUC-Rio.; >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, publish, distribute, sublicense, and/or sell; > copies of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. SQLite3 License; ------. ### Included only if built with Lua and SQLite support. http://www.sqlite.org/copyright.html. > 2001-09-15; >; > The author disclaims copyright to this source code. In place of; > a legal notice",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:1767,charge,charge,1767,net/http/civetweb/LICENSE.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md,1,['charge'],['charge']
Energy Efficiency,"e signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sudot4 Provides direct access to v_dot4_i32_iu8 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific propert",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42485,schedul,scheduled,42485,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency,"e the default policy is sufficient in most cases, it may break down when; ``T`` does not provide a default constructor. Also, in the case of many; instances of ``ilist``\ s, the memory overhead of the associated sentinels is; wasted. To alleviate the situation with numerous and voluminous; ``T``-sentinels, sometimes a trick is employed, leading to *ghostly sentinels*. Ghostly sentinels are obtained by specially-crafted ``ilist_traits<T>`` which; superpose the sentinel with the ``ilist`` instance in memory. Pointer; arithmetic is used to obtain the sentinel, which is relative to the ``ilist``'s; ``this`` pointer. The ``ilist`` is augmented by an extra pointer, which serves; as the back-link of the sentinel. This is the only field in the ghostly; sentinel which can be legally accessed. .. _dss_other:. Other Sequential Container options; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Other STL containers are available, such as ``std::string``. There are also various STL adapter classes such as ``std::queue``,; ``std::priority_queue``, ``std::stack``, etc. These provide simplified access; to an underlying container but don't affect the cost of the container itself. .. _ds_string:. String-like containers; ----------------------. There are a variety of ways to pass around and use strings in C and C++, and; LLVM adds a few new options to choose from. Pick the first option on this list; that will do what you need, they are ordered according to their relative cost. Note that it is generally preferred to *not* pass strings around as ``const; char*``'s. These have a number of problems, including the fact that they; cannot represent embedded nul (""\0"") characters, and do not have a length; available efficiently. The general replacement for '``const char*``' is; StringRef. For more information on choosing string containers for APIs, please see; :ref:`Passing Strings <string_apis>`. .. _dss_stringref:. llvm/ADT/StringRef.h; ^^^^^^^^^^^^^^^^^^^^. The StringRef class is a simple value class t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:70708,adapt,adapter,70708,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['adapt'],['adapter']
Energy Efficiency,"e type system in all sorts of interesting ways. Simple; arrays are very easy and are quite useful for many different; applications. Adding them is mostly an exercise in learning how the; LLVM `getelementptr <../../LangRef.html#getelementptr-instruction>`_ instruction; works: it is so nifty/unconventional, it `has its own; FAQ <../../GetElementPtr.html>`_!; - **standard runtime** - Our current language allows the user to access; arbitrary external functions, and we use it for things like ""printd""; and ""putchard"". As you extend the language to add higher-level; constructs, often these constructs make the most sense if they are; lowered to calls into a language-supplied runtime. For example, if; you add hash tables to the language, it would probably make sense to; add the routines to a runtime, instead of inlining them all the way.; - **memory management** - Currently we can only access the stack in; Kaleidoscope. It would also be useful to be able to allocate heap; memory, either with calls to the standard libc malloc/free interface; or with a garbage collector. If you would like to use garbage; collection, note that LLVM fully supports `Accurate Garbage; Collection <../../GarbageCollection.html>`_ including algorithms that; move objects and need to scan/update the stack.; - **exception handling support** - LLVM supports generation of `zero; cost exceptions <../../ExceptionHandling.html>`_ which interoperate with; code compiled in other languages. You could also generate code by; implicitly making every function return an error value and checking; it. You could also make explicit use of setjmp/longjmp. There are; many different ways to go here.; - **object orientation, generics, database access, complex numbers,; geometric programming, ...** - Really, there is no end of crazy; features that you can add to the language.; - **unusual domains** - We've been talking about applying LLVM to a; domain that many people are interested in: building a compiler for a; specific la",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst:3336,allocate,allocate,3336,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,1,['allocate'],['allocate']
Energy Efficiency,"e used directly as; boxed literals (this avoids conflicts with future ``'@'``-prefixed; Objective-C keywords). Instead, an enum value must be placed inside a; boxed expression. The following example demonstrates configuring an; ``AVAudioRecorder`` using a dictionary that contains a boxed enumeration; value:. .. code-block:: objc. enum {; AVAudioQualityMin = 0,; AVAudioQualityLow = 0x20,; AVAudioQualityMedium = 0x40,; AVAudioQualityHigh = 0x60,; AVAudioQualityMax = 0x7F; };. - (AVAudioRecorder *)recordToFile:(NSURL *)fileURL {; NSDictionary *settings = @{ AVEncoderAudioQualityKey : @(AVAudioQualityMax) };; return [[AVAudioRecorder alloc] initWithURL:fileURL settings:settings error:NULL];; }. The expression ``@(AVAudioQualityMax)`` converts ``AVAudioQualityMax``; to an integer type, and boxes the value accordingly. If the enum has a; :ref:`fixed underlying type <objc-fixed-enum>` as in:. .. code-block:: objc. typedef enum : unsigned char { Red, Green, Blue } Color;; NSNumber *red = @(Red), *green = @(Green), *blue = @(Blue); // => [NSNumber numberWithUnsignedChar:]. then the fixed underlying type will be used to select the correct; ``NSNumber`` creation method. Boxing a value of enum type will result in a ``NSNumber`` pointer with a; creation method according to the underlying type of the enum, which can; be a :ref:`fixed underlying type <objc-fixed-enum>`; or a compiler-defined integer type capable of representing the values of; all the members of the enumeration:. .. code-block:: objc. typedef enum : unsigned char { Red, Green, Blue } Color;; Color col = Red;; NSNumber *nsCol = @(col); // => [NSNumber numberWithUnsignedChar:]. Boxed C Strings; ---------------. A C string literal prefixed by the ``'@'`` token denotes an ``NSString``; literal in the same way a numeric literal prefixed by the ``'@'`` token; denotes an ``NSNumber`` literal. When the type of the parenthesized; expression is ``(char *)`` or ``(const char *)``, the result of the; boxed expression is a poin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ObjectiveCLiterals.rst:6343,green,green,6343,interpreter/llvm-project/clang/docs/ObjectiveCLiterals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ObjectiveCLiterals.rst,1,['green'],['green']
Energy Efficiency,"e used to identify the derived class.; * **IsActive**: indicates if the field is the active field of a union.; * **IsMutable**: indicates if the field is marked as mutable. Inline descriptors are filled in by the `CtorFn` of blocks, which leaves storage; in an uninitialised, but valid state. Descriptors; -----------. Descriptors are generated at bytecode compilation time and contain information; required to determine if a particular memory access is allowed in constexpr.; They also carry all the information required to emit a diagnostic involving; a memory access, such as the declaration which originates the block.; Currently there is a single kind of descriptor encoding information for all; block types. Pointers; --------. Pointers, implemented in ``Pointer.h`` are represented as a tagged union.; Some of these may not yet be available in upstream ``clang``. * **BlockPointer**: used to reference memory allocated and managed by the; interpreter, being the only pointer kind which allows dereferencing in the; interpreter; * **ExternPointer**: points to memory which can be addressed, but not read by; the interpreter. It is equivalent to APValue, tracking a declaration and a path; of fields and indices into that allocation.; * **TargetPointer**: represents a target address derived from a base address; through pointer arithmetic, such as ``((int *)0x100)[20]``. Null pointers are; target pointers with a zero offset.; * **TypeInfoPointer**: tracks information for the opaque type returned by; ``typeid``; * **InvalidPointer**: is dummy pointer created by an invalid operation which; allows the interpreter to continue execution. Does not allow pointer; arithmetic or dereferencing. Besides the previously mentioned union, a number of other pointer-like types; have their own type:. * **ObjCBlockPointer** tracks Objective-C blocks; * **FnPointer** tracks functions and lazily caches their compiled version; * **MemberPointer** tracks C++ object members. Void pointers, which can be bu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst:8859,allocate,allocated,8859,interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,1,['allocate'],['allocated']
Energy Efficiency,"e vectorizer may decide to fall back on fixed width; vectorization if the target does not support scalable vectors. The interleave count is specified by ``interleave_count(_value_)``, where; _value_ is a positive integer. This is useful for specifying the optimal; width/count of the set of target architectures supported by your application. .. code-block:: c++. #pragma clang loop vectorize_width(2); #pragma clang loop interleave_count(2); for(...) {; ...; }. Specifying a width/count of 1 disables the optimization, and is equivalent to; ``vectorize(disable)`` or ``interleave(disable)``. Vector predication is enabled by ``vectorize_predicate(enable)``, for example:. .. code-block:: c++. #pragma clang loop vectorize(enable); #pragma clang loop vectorize_predicate(enable); for(...) {; ...; }. This predicates (masks) all instructions in the loop, which allows the scalar; remainder loop (the tail) to be folded into the main vectorized loop. This; might be more efficient when vector predication is efficiently supported by the; target platform. Loop Unrolling; --------------. Unrolling a loop reduces the loop control overhead and exposes more; opportunities for ILP. Loops can be fully or partially unrolled. Full unrolling; eliminates the loop and replaces it with an enumerated sequence of loop; iterations. Full unrolling is only possible if the loop trip count is known at; compile time. Partial unrolling replicates the loop body within the loop and; reduces the trip count. If ``unroll(enable)`` is specified the unroller will attempt to fully unroll the; loop if the trip count is known at compile time. If the fully unrolled code size; is greater than an internal limit the loop will be partially unrolled up to this; limit. If the trip count is not known at compile time the loop will be partially; unrolled with a heuristically chosen unroll factor. .. code-block:: c++. #pragma clang loop unroll(enable); for(...) {; ...; }. If ``unroll(full)`` is specified the unroller will att",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:165920,efficient,efficient,165920,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,2,['efficient'],"['efficient', 'efficiently']"
Energy Efficiency,"e+Asserts; build to use these features. .. _datastructure:. Picking the Right Data Structure for a Task; ===========================================. LLVM has a plethora of data structures in the ``llvm/ADT/`` directory, and we; commonly use STL data structures. This section describes the trade-offs you; should consider when you pick one. The first step is a choose your own adventure: do you want a sequential; container, a set-like container, or a map-like container? The most important; thing when choosing a container is the algorithmic properties of how you plan to; access the container. Based on that, you should use:. * a :ref:`map-like <ds_map>` container if you need efficient look-up of a; value based on another value. Map-like containers also support efficient; queries for containment (whether a key is in the map). Map-like containers; generally do not support efficient reverse mapping (values to keys). If you; need that, use two maps. Some map-like containers also support efficient; iteration through the keys in sorted order. Map-like containers are the most; expensive sort, only use them if you need one of these capabilities. * a :ref:`set-like <ds_set>` container if you need to put a bunch of stuff into; a container that automatically eliminates duplicates. Some set-like; containers support efficient iteration through the elements in sorted order.; Set-like containers are more expensive than sequential containers. * a :ref:`sequential <ds_sequential>` container provides the most efficient way; to add elements and keeps track of the order they are added to the collection.; They permit duplicates and support efficient iteration, but do not support; efficient look-up based on a key. * a :ref:`string <ds_string>` container is a specialized sequential container or; reference structure that is used for character or byte arrays. * a :ref:`bit <ds_bit>` container provides an efficient way to store and; perform set operations on sets of numeric id's, while automatical",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:55707,efficient,efficient,55707,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"e, version 2, hence; the version number 2.1.]. Preamble. The licenses for most software are designed to take away your; freedom to share and change it. By contrast, the GNU General Public; Licenses are intended to guarantee your freedom to share and change; free software--to make sure the software is free for all its users. This license, the Lesser General Public License, applies to some; specially designated software packages--typically libraries--of the; Free Software Foundation and other authors who decide to use it. You; can use it too, but we suggest you first think carefully about whether; this license or the ordinary General Public License is the better; strategy to use in any particular case, based on the explanations below. When we speak of free software, we are referring to freedom of use,; not price. Our General Public Licenses are designed to make sure that; you have the freedom to distribute copies of free software (and charge; for this service if you wish); that you receive source code or can get; it if you want it; that you can change the software and use pieces of; it in new free programs; and that you are informed that you can do; these things. To protect your rights, we need to make restrictions that forbid; distributors to deny you these rights or to ask you to surrender these; rights. These restrictions translate to certain responsibilities for; you if you distribute copies of the library or if you modify it. For example, if you distribute copies of the library, whether gratis; or for a fee, you must give the recipients all the rights that we gave; you. You must make sure that they, too, receive or can get the source; code. If you link other code with the library, you must provide; complete object files to the recipients, so that they can relink them; with the library after making changes to the library and recompiling; it. And you must show them these terms so they know their rights. We protect your rights with a two-step method: (1) we copyright",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/LGPL2_1.txt:1364,charge,charge,1364,LGPL2_1.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/LGPL2_1.txt,2,['charge'],['charge']
Energy Efficiency,"e-1294211. LLVM has a StringMap class that is advertised as more efficient than; std::map<std::string, ValueType>. Mainly it does fewer allocations; because the key is not a std::string. Replace the use of std::map<std::string, ValueType> with String Map.; One specific case is the LVSymbolNames definitions. //===----------------------------------------------------------------------===//; // Calculate unique offset for CodeView elements.; //===----------------------------------------------------------------------===//; In order to have the same logical functionality as the ELF Reader, such; as:. - find scopes contribution to debug info; - sort by its physical location. The logical elements must have an unique offset (similar like the DWARF; DIE offset). //===----------------------------------------------------------------------===//; // Move 'initializeFileAndStringTables' to the COFF Library.; //===----------------------------------------------------------------------===//; There is some code in the CodeView reader that was extracted/adapted; from 'tools/llvm-readobj/COFFDumper.cpp' that can be moved to the COFF; library. We had a similar case with code shared with llvm-pdbutil that was moved; to the PDB library: https://reviews.llvm.org/D122226. //===----------------------------------------------------------------------===//; // Move 'getSymbolKindName'/'formatRegisterId' to the CodeView Library.; //===----------------------------------------------------------------------===//; There is some code in the CodeView reader that was extracted/adapted; from 'lib/DebugInfo/CodeView/SymbolDumper.cpp' that can be used. //===----------------------------------------------------------------------===//; // Use of std::unordered_set instead of std::set.; //===----------------------------------------------------------------------===//; https://reviews.llvm.org/D125784#inline-1221421. Replace the std::set usage for DeducedScopes, UnresolvedScopes and; IdentifiedNamespaces with std",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt:5598,adapt,adapted,5598,interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt,1,['adapt'],['adapted']
Energy Efficiency,"e. Variants of the intrinsic with non-void return; type also return a value according to calling convention. On PowerPC, note that ``<target>`` must be the ABI function pointer for the; intended target of the indirect call. Specifically, when compiling for the; ELF V1 ABI, ``<target>`` is the function-descriptor address normally used as; the C/C++ function-pointer representation. Requesting zero patch point arguments is valid. In this case, all; variable operands are handled just like; ``llvm.experimental.stackmap.*``. The difference is that space will; still be reserved for patching, a call will be emitted, and a return; value is allowed. The location of the arguments are not normally recorded in the stack; map because they are already fixed by the calling convention. The; remaining ``live values`` will have their location recorded, which; could be a register, stack location, or constant. A special calling; convention has been introduced for use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:9695,allocate,allocated,9695,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['allocate'],['allocated']
Energy Efficiency,"e090.png). We have developed a new high resolution deconvolution algorithm. We have; observed that the Gold deconvolution converges to its stable state; (solution). It is useless to increase the number of iterations, the; result obtained does not change. To continue decreasing the width of; peaks, we have found that when the solution reaches its stable state, it; is necessary to stop iterations, then to change the vector in a way and; repeat again the Gold deconvolution. We have found that in order to change the; particular solution we need to apply a non-linear boosting function to it.; The power function proved to give the best results. At the beginning the; function calculates exact solution of the Toeplitz system of linear; equations. $$ x^{(0)} = [x_e^2(0),x_e^2(1),...,x_e^2(N-1),]^T$$; where; $$ x_e=H^{'-1}y^{'}$$. Then it applies the Gold deconvolution algorithm to the solution and; carries out preset number of iterations. Then the power function with; the exponent equal to the boosting coefficient is applied to the; deconvolved data. These data are then used as initial estimate of the; solution of linear system of equations and again the Gold algorithm is; employed. The whole procedure is repeated `number_of_repetitions` times. The form of the high-resolution deconvolution function is. ```{.cpp}; char *Deconvolution1HighResolution(float *source,; const float *resp,; int size,; int number_of_iterations,; int number_of_repetitions,; double boost);; ```. This function calculates deconvolution from the source spectrum according; to the response spectrum. The result is placed in the vector pointed by the source pointer. Function parameters:. - **`source`**: pointer to the vector of the source spectrum; - **`resp`**: pointer to the vector of the response spectrum; - **`size`**: length of source and the response spectra; - **`number_of_iterations`**: for details we refer to manual; - **`number_of_repetitions`**: for details we refer to manual; - **`boost`**: boosti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:28275,power,power,28275,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['power'],['power']
Energy Efficiency,"e; (named *Average Wait times*) reports useful timing statistics, which should; help diagnose performance bottlenecks caused by long data dependencies and; sub-optimal usage of hardware resources. An instruction in the timeline view is identified by a pair of indices, where; the first index identifies an iteration, and the second index is the; instruction index (i.e., where it appears in the code sequence). Since this; example was generated using 3 iterations: ``-iterations=3``, the iteration; indices range from 0-2 inclusively. Excluding the first and last column, the remaining columns are in cycles.; Cycles are numbered sequentially starting from 0. From the example output above, we know the following:. * Instruction [1,0] was dispatched at cycle 1.; * Instruction [1,0] started executing at cycle 2.; * Instruction [1,0] reached the write back stage at cycle 4.; * Instruction [1,0] was retired at cycle 10. Instruction [1,0] (i.e., vmulps from iteration #1) does not have to wait in the; scheduler's queue for the operands to become available. By the time vmulps is; dispatched, operands are already available, and pipeline JFPU1 is ready to; serve another instruction. So the instruction can be immediately issued on the; JFPU1 pipeline. That is demonstrated by the fact that the instruction only; spent 1cy in the scheduler's queue. There is a gap of 5 cycles between the write-back stage and the retire event.; That is because instructions must retire in program order, so [1,0] has to wait; for [0,2] to be retired first (i.e., it has to wait until cycle 10). In the example, all instructions are in a RAW (Read After Write) dependency; chain. Register %xmm2 written by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:24268,schedul,scheduler,24268,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,"e; result type. If only ``nnan`` is set then the neutral value is ``+Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>` intrinsic (and thus the; '``llvm.minnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum element magnitude ``0.0`` and containing both ``+0.0`` and; ``-0.0`` elements, the sign of the result is unspecified. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmin.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float QNAN, float QNAN, float QNAN, float QNAN>; %reduction = call float @llvm.vector.reduce.fmin.v4f32(<4 x float> %masked.a); %also.r = call float @llvm.minnum.f32(float %reduction, float %start). .. _int_get_active_lane_mask:. '``llvm.get.active.lane.mask.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <4 x i1> @llvm.get.active.lane.mask.v4i1.i32(i32 %base, i32 %n); declare <8 x i1> @llvm.get.active.lane.mask.v8i1.i64(i64 %base, i64 %n); declare <16 x i1> @llvm.get.active.lane.mask.v16i1.i64(i64 %base, i64 %n); declare <vscale x 16 x i1> @llvm.get.active.lane.mask.nxv16i1.i64(i64 %base, i64 %n). Overview:; """""""""""""""""". Create a mask representing active and inactive vector lanes. Arguments:; """""""""""""""""""". Both operands have the same scalar integer type. The result is a vector with; the i1 element type. Semantics:; """""""""""""""""""". The '``llvm.get.active.lane.mask.*``' intrinsics are semantically equivalent; to:. ::. %m[i] = icmp ult (%base + i), %n. where ``%m`` is a vector (mask) of active/inactive lane",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:776618,reduce,reduce,776618,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"e; result type. If only ``nnan`` is set then the neutral value is ``-Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>` intrinsic (and thus the; '``llvm.maxnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum element magnitude ``0.0`` and containing both ``+0.0`` and; ``-0.0`` elements, the sign of the result is unspecified. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmax.v4f32(float %float, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float QNAN, float QNAN, float QNAN, float QNAN>; %reduction = call float @llvm.vector.reduce.fmax.v4f32(<4 x float> %masked.a); %also.r = call float @llvm.maxnum.f32(float %reduction, float %start). .. _int_vp_reduce_fmin:. '``llvm.vp.reduce.fmin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmin.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmin.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third ope",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:773745,reduce,reduce,773745,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,eArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/ll,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338363,reduce,reduce,338363,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"e``, and; ""_ZnwmSt11align_val_t"" for aligned ``::operator::new`` and; ``::operator::delete``. Matching malloc/realloc/free calls within a family; can be optimized, but mismatched ones will be left alone.; ``allockind(""KIND"")``; Describes the behavior of an allocation function. The KIND string contains comma; separated entries from the following options:. * ""alloc"": the function returns a new block of memory or null.; * ""realloc"": the function returns a new block of memory or null. If the; result is non-null the memory contents from the start of the block up to; the smaller of the original allocation size and the new allocation size; will match that of the ``allocptr`` argument and the ``allocptr``; argument is invalidated, even if the function returns the same address.; * ""free"": the function frees the block of memory specified by ``allocptr``.; Functions marked as ""free"" ``allockind`` must return void.; * ""uninitialized"": Any newly-allocated memory (either a new block from; a ""alloc"" function or the enlarged capacity from a ""realloc"" function); will be uninitialized.; * ""zeroed"": Any newly-allocated memory (either a new block from a ""alloc""; function or the enlarged capacity from a ""realloc"" function) will be; zeroed.; * ""aligned"": the function returns memory aligned according to the; ``allocalign`` parameter. The first three options are mutually exclusive, and the remaining options; describe more details of how the function behaves. The remaining options; are invalid for ""free""-type functions.; ``allocsize(<EltSizeParam>[, <NumEltsParam>])``; This attribute indicates that the annotated function will always return at; least a given number of bytes (or null). Its arguments are zero-indexed; parameter numbers; if one argument is provided, then it's assumed that at; least ``CallSite.Args[EltSizeParam]`` bytes will be available at the; returned pointer. If two are provided, then it's assumed that; ``CallSite.Args[EltSizeParam] * CallSite.Args[NumEltsParam]`` bytes are;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:78920,allocate,allocated,78920,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"ease file bugs when you see issues of any kind so we can assess; where development on C++ analysis support needs to be focused.; To try out C++ analysis support, it should work out of the box using scan-build. If you are using this checker build; as a replacement to the analyzer bundled with Xcode, first use the set-xcode-analyzer script to change Xcode to use; your version of the analyzer. You will then need to modify one configuration file in Xcode to enable C++ analysis support. This can; be done with the following steps:. Find the clang .xcspec file:; $ cd /Developer/Library; $ find . | grep xcspec | grep Clang; ./Xcode/<SNIP>/Clang LLVM 1.0.xcplugin/Contents/Resources/Clang LLVM 1.0.xcspec. The exact location of the file may vary depending on your installation of Xcode. Edit that file, and look for the string ""--analyze"":. SourceFileOption = ""--analyze"";; FileTypes = (; ""sourcecode.c.c"",; ""sourcecode.c.objc"",; );; ... Change the ""FileTypes"" entry to:. FileTypes = (; ""sourcecode.c.c"",; ""sourcecode.c.objc"",; ""sourcecode.cpp.cpp"",; ""sourcecode.cpp.objcpp"",; );. Restart Xcode. checker-255; built: February 11, 2011; highlights:. Mac OS X builds are now Intel i386 and x86_64 only (no ppc support); Turns on new -init method checker by default; Reduces memory usage of analyzer by 10%; Misc. fixes to reduce false positives on dead stores and idempotent operations. checker-254; built: January 27, 2011; highlights:. Introduces new -init method checker to check if a super class's init method is properly called.; Objective-C retain/release checker now reasons about calls to property accessor methods (setter/getter).; Introduces new attribute ns_consumes_self to educate the Objective-C retain/release checker about custom ""init-like"" methods that do not follow the standard Cocoa naming conventions.; Introduces new attributes ns_consumed and cf_consumed to educate the Objective-C retain/release checker about methods/functions that decrement the reference count of a parameter. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:12955,reduce,reduce,12955,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,1,['reduce'],['reduce']
Energy Efficiency,"eated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.and.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %masked.a); %also.r = and i32 %reduction, %start. .. _int_vp_reduce_or:. '``llvm.vp.reduce.or.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.or.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.or.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``OR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.or``' intrinsic performs the integer ``OR`` reduction; (:ref:`llvm.vector.reduce.or <int_vector_reduce_or>`) of the vector operand; ``val`` on each enabled lane, performing an '``or``' of that with the scalar; ``start_va",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:758971,reduce,reduce,758971,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ecay`, `Delta`; and `Epsilon`. #### Steepest Descent Algorithm. Weights are set to the minimum along the line defined by the gradient.; The only parameter for this method is `Tau`. Lower `Tau` = higher; precision = slower search. A value `Tau=3` seems reasonable. #### Conjugate Gradients With the Polak-Ribiere Updating Formula. Weights are set to the minimum along the line defined by the conjugate; gradient. Parameters are `Tau` and `Reset`, which defines the epochs; where the direction is reset to the steepest descent (estimated by; using the Polak-Ribiere formula). #### Conjugate Gradients With the Fletcher-Reeves Updating Formula. Weights are set to the minimum along the line defined by the conjugate; gradient. Parameters are `Tau` and `Reset`, which defines the epochs; where the direction is reset to the steepest descent (estimated by; using the Fletcher-Reeves formula). #### The Broyden, Fletcher, Goldfarb, Shanno (BFGS) Method. It implies the computation of a `NxN` matrix, but seems more powerful; at least for less than 300 weights. Parameters are `Tau` and `Reset`,; which defines the epochs where the direction is reset to the steepest; descent. ### Using the Network. Neural network are build from a set of ""samples"". A sample is a set of; values defining the inputs and the corresponding output that the; network should ideally provide. In ROOT this is a **`TTree`** entry.; The first thing to be decided is the network layout. This layout is; described in a string where the layers are separated by semicolons.; The input/output layers are defined by giving the expression for each; neuron, separated by comas. Hidden layers are just described by the; number of neurons. In addition, input and output layer formulas can be preceded by '@'; (e.g. ""@out"") if one wants to normalize the corresponding value. Also,; if the string ends with '`!`', output neurons are set up for; classification, i.e. with a sigmoid (1 neuron) or softmax (more; neurons) activation function. Many ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:73903,power,powerful,73903,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['power'],['powerful']
Energy Efficiency,"ecial semantics of this; type mean that no arithmetic is ever performed directly on ``__fp16`` values;; see below. * ``_Float16`` is supported on the following targets:. * 32-bit ARM (natively on some architecture versions); * 64-bit ARM (AArch64) (natively on ARMv8.2a and above); * AMDGPU (natively); * SPIR (natively); * X86 (if SSE2 is available; natively if AVX512-FP16 is also available); * RISC-V (natively if Zfh or Zhinx is available). * ``__bf16`` is supported on the following targets (currently never natively):. * 32-bit ARM; * 64-bit ARM (AArch64); * RISC-V; * X86 (when SSE2 is available). (For X86, SSE2 is available on 64-bit and all recent 32-bit processors.). ``__fp16`` and ``_Float16`` both use the binary16 format from IEEE; 754-2008, which provides a 5-bit exponent and an 11-bit significand; (counting the implicit leading 1). ``__bf16`` uses the `bfloat16; <https://en.wikipedia.org/wiki/Bfloat16_floating-point_format>`_ format,; which provides an 8-bit exponent and an 8-bit significand; this is the same; exponent range as `float`, just with greatly reduced precision. ``_Float16`` and ``__bf16`` follow the usual rules for arithmetic; floating-point types. Most importantly, this means that arithmetic operations; on operands of these types are formally performed in the type and produce; values of the type. ``__fp16`` does not follow those rules: most operations; immediately promote operands of type ``__fp16`` to ``float``, and so; arithmetic operations are defined to be performed in ``float`` and so result in; a value of type ``float`` (unless further promoted because of other operands).; See below for more information on the exact specifications of these types. When compiling arithmetic on ``_Float16`` and ``__bf16`` for a target without; native support, Clang will perform the arithmetic in ``float``, inserting; extensions and truncations as necessary. This can be done in a way that; exactly matches the operation-by-operation behavior of native support,; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:31588,reduce,reduced,31588,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['reduce'],['reduced']
Energy Efficiency,"ecific files in a build, without affecting the main compilation flags; used for the other files in the project. In these cases, you can use the flag ``-fno-profile-instr-generate`` (or; ``-fno-profile-generate``) to disable profile generation, and; ``-fno-profile-instr-use`` (or ``-fno-profile-use``) to disable profile use. Note that these flags should appear after the corresponding profile; flags to have an effect. .. note::. When none of the translation units inside a binary is instrumented, in the; case of Fuchsia the profile runtime will not be linked into the binary and; no profile will be produced, while on other platforms the profile runtime; will be linked and profile will be produced but there will not be any; counters. Instrumenting only selected files or functions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Sometimes it's useful to only instrument certain files or functions. For; example in automated testing infrastructure, it may be desirable to only; instrument files or functions that were modified by a patch to reduce the; overhead of instrumenting a full system. This can be done using the ``-fprofile-list`` option. .. option:: -fprofile-list=<pathname>. This option can be used to apply profile instrumentation only to selected; files or functions. ``pathname`` should point to a file in the; :doc:`SanitizerSpecialCaseList` format which selects which files and; functions to instrument. .. code-block:: console. $ clang++ -O2 -fprofile-instr-generate -fprofile-list=fun.list code.cc -o code. The option can be specified multiple times to pass multiple files. .. code-block:: console. $ clang++ -O2 -fprofile-instr-generate -fcoverage-mapping -fprofile-list=fun.list -fprofile-list=code.list code.cc -o code. Supported sections are ``[clang]``, ``[llvm]``, and ``[csllvm]`` representing; clang PGO, IRPGO, and CSIRPGO, respectively. Supported prefixes are ``function``; and ``source``. Supported categories are ``allow``, ``skip``, and ``forbid``.; ``skip`` adds ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:116113,reduce,reduce,116113,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['reduce'],['reduce']
Energy Efficiency,"ecifically; for that purpose. The **`TTree`** class is optimized to reduce disk; space and enhance access speed. A **`TNtuple`** is a **`TTree`** that is; limited to only hold floating-point numbers; a **`TTree`** on the other; hand can hold all kind of data, such as objects or arrays in addition to; all the simple types. When using a **`TTree`**, we fill its branch buffers with leaf data and; the buffers are written to disk when it is full. Branches, buffers, and; leafs, are explained a little later in this chapter, but for now, it is; important to realize that each object is not written individually, but; rather collected and written a bunch at a time. This is where the **`TTree`** takes advantage of compression and will; produce a much smaller file than if the objects were written; individually. Since the unit to be compressed is a buffer, and the; **`TTree`** contains many same-class objects, the header of the objects; can be compressed. The **`TTree`** reduces the header of each object, but it still contains; the class name. Using compression, the class name of each same-class; object has a good chance of being compressed, since the compression; algorithm recognizes the bit pattern representing the class name. Using; a **`TTree`** and compression the header is reduced to about 4 bytes; compared to the original 60 bytes. However, if compression is turned; off, you will not see these large savings. The **`TTree`** is also used to optimize the data access. A tree uses a; hierarchy of branches, and each branch can be read independently from; any other branch. Now, assume that `Px` and `Py` are data members of the; event, and we would like to compute `Px2 + Py2` for every event; and histogram the result. If we had saved the million events without a **`TTree`** we would have; to:. - read each event in its entirety into memory; - extract the `Px` and `Py` from the event; - compute the sum of the squares; - fill a histogram. We would have to do that a million times! Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:1220,reduce,reduces,1220,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['reduce'],['reduces']
Energy Efficiency,"ecified section. If the; definition is located in a different section, the behavior is undefined. LLVM allows an explicit code model to be specified for globals. If the; target supports it, it will emit globals in the code model specified,; overriding the code model used to compile the translation unit.; The allowed values are ""tiny"", ""small"", ""kernel"", ""medium"", ""large"".; This may be extended in the future to specify global data layout that; doesn't cleanly fit into a specific code model. By default, global initializers are optimized by assuming that global; variables defined within the module are not modified from their; initial values before the start of the global initializer. This is; true even for variables potentially accessible from outside the; module, including those with external linkage or appearing in; ``@llvm.used`` or dllexported variables. This assumption may be suppressed; by marking the variable with ``externally_initialized``. An explicit alignment may be specified for a global, which must be a; power of 2. If not present, or if the alignment is set to zero, the; alignment of the global is set by the target to whatever it feels; convenient. If an explicit alignment is specified, the global is forced; to have exactly that alignment. Targets and optimizers are not allowed; to over-align the global if the global has an assigned section. In this; case, the extra alignment could be observable: for example, code could; assume that the globals are densely packed in their section and try to; iterate over them as an array, alignment padding would break this; iteration. For TLS variables, the module flag ``MaxTLSAlign``, if present,; limits the alignment to the given value. Optimizers are not allowed to; impose a stronger alignment on these variables. The maximum alignment; is ``1 << 32``. For global variable declarations, as well as definitions that may be; replaced at link time (``linkonce``, ``weak``, ``extern_weak`` and ``common``; linkage types), the a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:34454,power,power,34454,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"eclare { float, i32 } @llvm.frexp.f32.i32(float %Val); declare { double, i32 } @llvm.frexp.f64.i32(double %Val); declare { x86_fp80, i32 } @llvm.frexp.f80.i32(x86_fp80 %Val); declare { fp128, i32 } @llvm.frexp.f128.i32(fp128 %Val); declare { ppc_fp128, i32 } @llvm.frexp.ppcf128.i32(ppc_fp128 %Val); declare { <2 x float>, <2 x i32> } @llvm.frexp.v2f32.v2i32(<2 x float> %Val). Overview:; """""""""""""""""". The '``llvm.frexp.*``' intrinsics perform the frexp function. Arguments:; """""""""""""""""""". The argument is a :ref:`floating-point <t_floating>` or; :ref:`vector <t_vector>` of floating-point values. Returns two values; in a struct. The first struct field matches the argument type, and the; second field is an integer or a vector of integer values with the same; number of elements as the argument. Semantics:; """""""""""""""""""". This intrinsic splits a floating point value into a normalized; fractional component and integral exponent. For a non-zero argument, returns the argument multiplied by some power; of two such that the absolute value of the returned value is in the; range [0.5, 1.0), with the same sign as the argument. The second; result is an integer such that the first result raised to the power of; the second result is the input argument. If the argument is a zero, returns a zero with the same sign and a 0; exponent. If the argument is a NaN, a NaN is returned and the returned exponent; is unspecified. If the argument is an infinity, returns an infinity with the same sign; and an unspecified exponent. .. _int_log:. '``llvm.log.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.log`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @llvm.log.f32(float %Val); declare double @llvm.log.f64(double %Val); declare x86_fp80 @llvm.log.f80(x86_fp80 %Val); declare fp128 @llvm.log.f128(fp128 %Val); declare ppc_fp128 @llvm.log.ppcf128(ppc_fp128 %Val). Overview:;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:566988,power,power,566988,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"ector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instructi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43204,schedul,scheduled,43204,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency,"ector read from a TTreeReaderArray from root prompt; * [[ROOT-9261](https://its.cern.ch/jira/browse/ROOT-9261)] - TMatrixTSparse fails to transpose non-square matrices; * [[ROOT-9284](https://its.cern.ch/jira/browse/ROOT-9284)] - BUG (See description note) PyDoubleBuffer tolist and numpy array cause segfault.; * [[ROOT-9313](https://its.cern.ch/jira/browse/ROOT-9313)] - Crash in TFile::Close on Fedora, ROOT v6.10; * [[ROOT-9320](https://its.cern.ch/jira/browse/ROOT-9320)] - Make GenVector data structures constexpr; * [[ROOT-9321](https://its.cern.ch/jira/browse/ROOT-9321)] - Dictionary generation: type normalization issue in pcm file; * [[ROOT-9448](https://its.cern.ch/jira/browse/ROOT-9448)] - libNew returns nullptr instead of implementing operator new, has many warnings; * [[ROOT-9983](https://its.cern.ch/jira/browse/ROOT-9983)] - [DOC] hadd --help does not show description and epilogue; * [[ROOT-10033](https://its.cern.ch/jira/browse/ROOT-10033)] - ROOT::EnableImplicitMT: Number of threads in scheduling environments; * [[ROOT-10231](https://its.cern.ch/jira/browse/ROOT-10231)] - TMatrixD(a,TMatrixD::kInvMult,b) requires b.GetNcols() = a.GetNcols(); * [[ROOT-10320](https://its.cern.ch/jira/browse/ROOT-10320)] - ROOT/meta does not support anonymous unions/structs; * [[ROOT-10425](https://its.cern.ch/jira/browse/ROOT-10425)] - Missing symbols not reported as missing anymore; * [[ROOT-10546](https://its.cern.ch/jira/browse/ROOT-10546)] - RDataFrame cannot be interrupted from PyROOT; * [[ROOT-10593](https://its.cern.ch/jira/browse/ROOT-10593)] - Segmentation fault when calling a not-yet-defined function from ROOT interpreter; * [[ROOT-10607](https://its.cern.ch/jira/browse/ROOT-10607)] - Several ROOT 7 tests fail when assertions are enabled; * [[ROOT-10613](https://its.cern.ch/jira/browse/ROOT-10613)] - Configuration does not fail when fail-on-missing is ON and cudnn is not found; * [[ROOT-10621](https://its.cern.ch/jira/browse/ROOT-10621)] - Segfault if TFile is used",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:54202,schedul,scheduling,54202,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['schedul'],['scheduling']
Energy Efficiency,"ectory and to activate it use cmake -Dr=ON .. ~~~{.sh}; mkdir compile; cd compile; cmake -Dr=ON ..; make -j 5; ~~~. ### Compiling ROOTR on Gnu/Linux with CMake:; **NOTE:** Tested on Gnu/Linux Debian Jessie with gcc 4.9. **Prerequisities**; install; (For debian-based distros). ~~~{.sh}; apt-get install r-base r-base-dev; ~~~; Install needed R packages, open R and in the prompt type. ~~~{.sh}; install.packages(c('Rcpp','RInside')); ~~~; select a mirror and install. Install the next additional packages for R TMVA interface. ~~~{.sh}; install.packages(c('C50','RSNNS','e1071','xgboost')); ~~~. Download code from git repo. ~~~{.sh}; git clone http://root.cern.ch/git/root.git; ~~~. To compile ROOTR lets to create a compilation directory and to activate it use cmake -Dr=ON .. ~~~{.sh}; mkdir compile; cd compile; cmake -Dr=ON ..; make -j 5; ~~~. ## How does it work ?; There is a class called TRInterface which is located at the header TRInterface.h and uses the namespace `ROOT::R`, it is in charge; of making calls to R to give and obtain data. This class has a series of overcharged operators which ease the passing and obtaining of data; and code from R to C++ and vice versa. To create an object of this class the user must use the static methods `ROOT::R::TRInterface::Instance`; and `ROOT::R::TRInterface::InstancePtr` which return a reference object and a pointer object respectively. ~~~{.cxx}; #include<TRInterface.h>; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; ~~~. ## Running R code and passing/getting variables.; We have different ways to run R code and pass/obtain data to/from R environment: using the methods Execute(code) and; Eval(code). ~~~{.cxx}; #include<TRInterface.h>. //creating an instance; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; //executing simple r commands with the operator <<; r<<""print('hello ROOTR')"";; r<<""vec=c(1,2,3)""<<""print(vec)"";. //executing R's code using the method Execute that doesn't return anything; r.Execute(""prin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:3231,charge,charge,3231,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['charge'],['charge']
Energy Efficiency,"ects; (""shapes"") - filled /added by negotiation with viewer via; **`TVirtualViewer3D`**. A typical interaction between viewer and client using these, taken from; **`TGeoPainter`** is:. ``` {.cpp}; TVirtualViewer3D * viewer = gPad->GetViewer3D();; // Does viewer prefer local frame positions?; Bool_t localFrame = viewer->PreferLocalFrame();; // Perform first fetch of buffer from the shape and try adding it to the viewer; const TBuffer3D &buffer = shape.GetBuffer3D(TBuffer3D::kCore |; TBuffer3D::kBoundingBox |; TBuffer3D::kShapeSpecific,; localFrame);; Int_t reqSections = viewer->AddObject(buffer, &addDaughters);. // If the viewer requires additional sections fetch from the shape; // (if possible) and add again; if (reqSections != TBuffer3D::kNone); shape.GetBuffer3D(reqSections, localFrame);; ```. Together these allow clients to publish objects to any one of the 3D; viewers free of viewer specific drawing code. They allow our simple x3d; viewer, and considerably more sophisticated OpenGL one to both work with; both geometry libraries (`g3d` and `geom`) efficiently. In addition to external viewers, created in separate windows, this; architecture is also used by internal **`TPad`** drawing when it; requires 3D projections. Publishing to a viewer consists of the; following steps:. 1- Create / obtain viewer handle. 2- Begin scene on viewer. 3- Fill mandatory parts of TBuffer3D describing object. 4- Add to viewer. 5- Fill optional parts of TBuffer3D as requested by viewer. [ .... repeat 3/4/5 as required for other/child objects]. 6- End scene on viewer. You should attach the top-level node of your external geometry (or the; manager) to a **`TPad`** object using **`TObject::Draw()`, and perform; the publishing to the viewer in your object's `TObject::Paint()`; overloaded method. See ""Scene Rebuilds"", and example scripts, for more; details.**. #### Creating / Obtaining Viewer Handle. External viewers are bound to a **`TPad`** object (this may be removed; as a requirement in t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:123904,efficient,efficiently,123904,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['efficient'],['efficiently']
Energy Efficiency,"ed by CP to set up; ``COMPUTE_PGM_RSRC1.FLOAT_MODE``.; 19:18 2 bits FLOAT_DENORM_MODE_16_64 Wavefront starts execution; with specified denorm mode; for half/double (16; and 64-bit) floating point; precision floating point; operations. Floating point denorm mode; values are defined in; :ref:`amdgpu-amdhsa-floating-point-denorm-mode-enumeration-values-table`. Used by CP to set up; ``COMPUTE_PGM_RSRC1.FLOAT_MODE``.; 20 1 bit PRIV Must be 0. Start executing wavefront; in privilege trap handler; mode. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.PRIV``.; 21 1 bit ENABLE_DX10_CLAMP GFX9-GFX11; Wavefront starts execution; with DX10 clamp mode; enabled. Used by the vector; ALU to force DX10 style; treatment of NaN's (when; set, clamp NaN to zero,; otherwise pass NaN; through). Used by CP to set up; ``COMPUTE_PGM_RSRC1.DX10_CLAMP``.; WG_RR_EN GFX12; If 1, wavefronts are scheduled; in a round-robin fashion with; respect to the other wavefronts; of the SIMD. Otherwise, wavefronts; are scheduled in oldest age order. CP is responsible for filling in; ``COMPUTE_PGM_RSRC1.WG_RR_EN``.; 22 1 bit DEBUG_MODE Must be 0. Start executing wavefront; in single step mode. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.DEBUG_MODE``.; 23 1 bit ENABLE_IEEE_MODE GFX9-GFX11; Wavefront starts execution; with IEEE mode; enabled. Floating point; opcodes that support; exception flag gathering; will quiet and propagate; signaling-NaN inputs per; IEEE 754-2008. Min_dx10 and; max_dx10 become IEEE; 754-2008 compliant due to; signaling-NaN propagation; and quieting. Used by CP to set up; ``COMPUTE_PGM_RSRC1.IEEE_MODE``.; DISABLE_PERF GFX12; Reserved. Must be 0.; 24 1 bit BULKY Must be 0. Only one work-group allowed; to execute on a compute; unit. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.BULKY``.; 25 1 bit CDBG_USER Must be 0. Flag that can be used to; control debugging code. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.CDBG_USER``.; 26 1 bit FP16_OVFL GFX6-GFX8; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:167733,schedul,scheduled,167733,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency,"ed clearly using at least one of two; mechanisms:; 1) It will be in a separate directory tree with its own `LICENSE.txt` or; `LICENSE` file at the top containing the specific license and restrictions; which apply to that software, or; 2) It will contain specific license and restriction terms at the top of every; file. ==============================================================================; Legacy LLVM License (https://llvm.org/docs/DeveloperPolicy.html#legacy):; ==============================================================================; University of Illinois/NCSA; Open Source License. Copyright (c) 2003-2019 University of Illinois at Urbana-Champaign.; All rights reserved. Developed by:. LLVM Team. University of Illinois at Urbana-Champaign. http://llvm.org. Permission is hereby granted, free of charge, to any person obtaining a copy of; this software and associated documentation files (the ""Software""), to deal with; the Software without restriction, including without limitation the rights to; use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies; of the Software, and to permit persons to whom the Software is furnished to do; so, subject to the following conditions:. * Redistributions of source code must retain the above copyright notice,; this list of conditions and the following disclaimers. * Redistributions in binary form must reproduce the above copyright notice,; this list of conditions and the following disclaimers in the; documentation and/or other materials provided with the distribution. * Neither the names of the LLVM Team, University of Illinois at; Urbana-Champaign, nor the names of its contributors may be used to; endorse or promote products derived from this Software without specific; prior written permission. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS; FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/LICENSE.TXT:12650,charge,charge,12650,interpreter/llvm-project/llvm/LICENSE.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/LICENSE.TXT,2,['charge'],['charge']
Energy Efficiency,"ed clearly using at least one of two; mechanisms:; 1) It will be in a separate directory tree with its own `LICENSE.txt` or; `LICENSE` file at the top containing the specific license and restrictions; which apply to that software, or; 2) It will contain specific license and restriction terms at the top of every; file. ==============================================================================; Legacy LLVM License (https://llvm.org/docs/DeveloperPolicy.html#legacy):; ==============================================================================; University of Illinois/NCSA; Open Source License. Copyright (c) 2007-2019 University of Illinois at Urbana-Champaign.; All rights reserved. Developed by:. LLVM Team. University of Illinois at Urbana-Champaign. http://llvm.org. Permission is hereby granted, free of charge, to any person obtaining a copy of; this software and associated documentation files (the ""Software""), to deal with; the Software without restriction, including without limitation the rights to; use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies; of the Software, and to permit persons to whom the Software is furnished to do; so, subject to the following conditions:. * Redistributions of source code must retain the above copyright notice,; this list of conditions and the following disclaimers. * Redistributions in binary form must reproduce the above copyright notice,; this list of conditions and the following disclaimers in the; documentation and/or other materials provided with the distribution. * Neither the names of the LLVM Team, University of Illinois at; Urbana-Champaign, nor the names of its contributors may be used to; endorse or promote products derived from this Software without specific; prior written permission. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS; FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT:12650,charge,charge,12650,interpreter/llvm-project/clang/LICENSE.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT,1,['charge'],['charge']
Energy Efficiency,"ed is generated.; ``-runs``; Number of individual test runs, -1 (the default) to run indefinitely.; ``-max_len``; Maximum length of a test input. If 0 (the default), libFuzzer tries to guess; a good value based on the corpus (and reports it).; ``-len_control``; Try generating small inputs first, then try larger inputs over time.; Specifies the rate at which the length limit is increased (smaller == faster).; Default is 100. If 0, immediately try inputs with size up to max_len.; ``-timeout``; Timeout in seconds, default 1200. If an input takes longer than this timeout,; the process is treated as a failure case.; ``-rss_limit_mb``; Memory usage limit in Mb, default 2048. Use 0 to disable the limit.; If an input requires more than this amount of RSS memory to execute,; the process is treated as a failure case.; The limit is checked in a separate thread every second.; If running w/o ASAN/MSAN, you may use 'ulimit -v' instead.; ``-malloc_limit_mb``; If non-zero, the fuzzer will exit if the target tries to allocate this; number of Mb with one malloc call.; If zero (default) same limit as rss_limit_mb is applied.; ``-timeout_exitcode``; Exit code (default 77) used if libFuzzer reports a timeout.; ``-error_exitcode``; Exit code (default 77) used if libFuzzer itself (not a sanitizer) reports a bug (leak, OOM, etc).; ``-max_total_time``; If positive, indicates the maximum total time in seconds to run the fuzzer.; If 0 (the default), run indefinitely.; ``-merge``; If set to 1, any corpus inputs from the 2nd, 3rd etc. corpus directories; that trigger new code coverage will be merged into the first corpus; directory. Defaults to 0. This flag can be used to minimize a corpus.; ``-merge_control_file``; Specify a control file used for the merge process.; If a merge process gets killed it tries to leave this file in a state; suitable for resuming the merge. By default a temporary file will be used.; ``-minimize_crash``; If 1, minimizes the provided crash input.; Use with -runs=N or ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:11228,allocate,allocate,11228,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['allocate'],['allocate']
Energy Efficiency,"ed lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.xor.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %masked.a); %also.r = xor i32 %reduction, %start. .. _int_vp_reduce_smax:. '``llvm.vp.reduce.smax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smax``' intrinsic performs the signed-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.smax <int_vector_reduce_smax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:762999,reduce,reduce,762999,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ed to simulate multiple processor; schedulers. The scheduler is responsible for tracking data dependencies, and; dynamically selecting which processor resources are consumed by instructions.; It delegates the management of processor resource units and resource groups to a; resource manager. The resource manager is responsible for selecting resource; units that are consumed by instructions. For example, if an instruction; consumes 1cy of a resource group, the resource manager selects one of the; available units from the group; by default, the resource manager uses a; round-robin selector to guarantee that resource usage is uniformly distributed; between all units of a group. :program:`llvm-mca`'s scheduler internally groups instructions into three sets:. * WaitSet: a set of instructions whose operands are not ready.; * ReadySet: a set of instructions ready to execute.; * IssuedSet: a set of instructions executing. Depending on the operands availability, instructions that are dispatched to the; scheduler are either placed into the WaitSet or into the ReadySet. Every cycle, the scheduler checks if instructions can be moved from the WaitSet; to the ReadySet, and if instructions from the ReadySet can be issued to the; underlying pipelines. The algorithm prioritizes older instructions over younger; instructions. Write-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:38273,schedul,scheduler,38273,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,"ed versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store the data efficiently so we have used some of the DWARF features; that enable efficient data storage to define exactly what kind of data we store; for each name. The ``HeaderData`` contains a definition of the contents of each HashData chunk.; We might want to store an offset to all of the debug information entries (DIEs); for each name. To keep things extensible, we create a list of items, or; Atoms, that are contained in the data for each name. First comes the type of; the data in each atom:. .. code-block:: c. enum AtomType; {; eAtomTypeNULL = 0u,; eAtomTypeDIEOffset = 1u, // DIE offset, check form for encoding; eAtomTypeCUOffset = 2u, // DIE offset of the compiler unit header that contains the item in question; eAtomTypeTag = 3u, // DW_TAG_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:71455,efficient,efficient,71455,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['efficient'],['efficient']
Energy Efficiency,"ed with [TBufferJSON](https://root.cern/doc/master/classTBufferJSON.html) class. TBufferJSON generates such object representation, which could be directly used in [JSROOT](https://root.cern/js/) for drawing. `root.json` request returns either complete object or just object member like:. ```bash; [shell] wget http://localhost:8080/Objects/subfolder/obj/fTitle/root.json; ```. The result will be: `""title""`. For the `root.json` request one could specify the 'compact' parameter, which allow to reduce the number of spaces and new lines without data lost. This parameter can have values from '0' (no compression) till '3' (no spaces and new lines at all).; In addition, one can use simple compression algorithm for big arrays. If compact='10', zero values in the begin and at the end; of the array will be excluded. If compact='20', similar values or large zero gaps in-between will be compressed. Such array; compression support in JSROOT from version 4.8.2. Usage of `root.json` request is about as efficient as binary `root.bin` request. Comparison of different request methods with TH2 histogram from hsimple.C shown in the table:. | Request | Size |; | :---------------------- | :--------- |; | root.bin | 7672 bytes |; | root.bin.gz | 1582 bytes |; | root.json | 8570 bytes |; | root.json?compact=3 | 6004 bytes |; | root.json?compact=23 | 5216 bytes |; | root.json.gz?compact=23 | 1855 bytes |. One should remember that JSON representation always includes names of the data fields which are not present in the binary representation. Even then the size difference is negligible. `root.json` used in JSROOT to request objects from THttpServer. ### Generating images out of objects. For the ROOT classes which are implementing Draw method (like [TH1](https://root.cern/doc/master/classTH1.html) or [TGraph](https://root.cern/doc/master/classTGraph.html)) one could produce images with requests: `root.png`, `root.gif`, `root.jpeg`. For example:. ```bash; [shell] wget ""http://localhost:8080/Files/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:17537,efficient,efficient,17537,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['efficient'],['efficient']
Energy Efficiency,"ed; previously.; - Facilitate using Normalized sums of TF1 objects and convolutions, by adding the `NSUM` and `CONV` operators for TF1 objects built with formula expressions; - `TF1(""model"", ""NSUM(gaus , expo)"", xmin, xmax)` will create a function composed of a normalized sum of a gaussian and an exponential.; - `TF1(""voigt"", ""CONV(breitwigner, gausn) , -15, 15)` will create a TF1 object made of a convolution between a Breit-Wigner and a Gaussian. ; - `TFormula` supports vectorization. All the `TF1` objected created with a formula expression can have a vectorized signature using `ROOT::Double_v`: `TF1::EvalPar( ROOT::Double_v * x,; double * p)`. The vectorization can then be used to speed-up fitting. It is not enabled by default, but it can be enabled by callig `TF1::SetVectorized(true)` or using the `""VEC""` option in the; constructor of TF1, when ROOT has been built with VecCore and one vectorization library such as Vc. ; - Added new auto-binning algorithm, referred to as `power-2`, which uses power of 2 bin widths to create bins; that are mergeable. The target use-case is support for auto-binning in multi-process or multi-thread execution,; e.g. `TDataFrame`, without the need of a synchronization point.; The new `power-2` algorithm is activated by setting the new `TH1::kAutoBinPTwo` status bit on the histogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats class",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:17661,power,power-,17661,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,2,['power'],"['power', 'power-']"
Energy Efficiency,"eduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maxnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with maximum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmin:. '``llvm.vector.reduce.fmin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmin.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmin.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmin.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with minimum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmaximum:. '``llvm.vector.reduce.fmaximum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmaximum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fma",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:659800,reduce,reduce,659800,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ee::TClusterIterator (i.e. this replaces += fAutoFlush):. TTree::TClusterIterator clusterIter = tree->GetClusterIterator(which_entry_to_start_from);; Long64_t clusterStart;; while( (clusterStart = clusterIter()) < tree-<GetEntries()) {; printf(""The cluster starts at %lld and ends at %lld\n"",clusterStart,clusterIter.GetNextEntry()-1);; }; See TTreeCache::FillBuffer for a concrete usage example. Significant improvement of the performance of SetBranchAddress/SetAddress (by a factor 3 to 10 depending on the length/complexity of the classname).; Prevent the unlimited growth of the TBasket's buffer even if the basket is reused.; When the basket is Reset (this happens when it is written and will be reused),; if the TBuffer size is greater than. - twice the data in the current basket; and - twice the average data in each basket (of this branch); and - twice the requeste basket size (TBranch::GetBasketSize).; the size of the buffer is reduced to the max of; 'the data in the current basket' and 'the average' and the requested; buffer size and aligned to next highest multiple of 512.; In TBranchRef distinguish between the entry we need (now called RequestedEntry) and the; entry we have read (fReadEntry) so that we can avoid re-reading the same entry too many; times when executing TRef::GetObject.; Reduce by 40% the time taken GetEntry for a branch created using a leaflist (exclusive of the decompression time).; Introduce TVirtualPerfStats::FileUnzipEvent to be able to keep track of the cost of unzipping and use this in TTreePerfStats and TBasket ... This give a good picture of where the time in unzip or in unstreaming; Add more clusters to the TTreeCache buffer until fBufferMinSize is hit to avoid severely underfilled buffer when; a low number of branches is selected/used.; When reading backwards, make sure to load a full (new) cluster and several other fixes to TTreeCache.; Reduce the memory used by a TTree in half. Refactor the code reading and writing the TBasket data.; A si",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:1111,reduce,reduced,1111,tree/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html,1,['reduce'],['reduced']
Energy Efficiency,"ee; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. 8. Work-Group ID Z (1 SGPR). The value comes from the initial kernel execution state. See; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. 9. Implicit Argument Ptr (2 SGPRs). The value is computed by adding an offset to Kernarg Segment Ptr to get the; global address space pointer to the first kernarg implicit argument. The input and result arguments are assigned in order in the following manner:. .. note::. There are likely some errors and omissions in the following description that; need correction. .. TODO::. Check the Clang source code to decipher how function arguments and return; results are handled. Also see the AMDGPU specific values used. * VGPR arguments are assigned to consecutive VGPRs starting at VGPR0 up to; VGPR31. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. .. TODO::. How are overly aligned structures allocated on the stack?. * SGPR arguments are assigned to consecutive SGPRs starting at SGPR0 up to; SGPR29. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. Note that decomposed struct type arguments may have some fields passed in; registers and some in memory. .. TODO::. So, a struct which can pass some fields as decomposed register arguments, will; pass the rest as decomposed stack elements? But an argument that will not start; in registers will not be decomposed and will be passed as a non-decomposed; stack value?. The following is not part of the AMDGPU function calling convention but; describes how the AMDGPU implements function calls:. 1. SGPR33 is used as a frame pointer (FP) if necessary. Like the SP it is an; unswizzled scratch address. It is only needed if runtime sized ``alloca``; are used, or for the reasons defined in ``SIFrameLowering``.; 2. Runtime stack align",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:397157,allocate,allocated,397157,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"eeded to allocate a new block) -; this slot's offset is again dictated by ``libgcc``. The generated; assembly looks like this on x86-64:. .. code-block:: text. leaq -8(%rsp), %r10; cmpq %fs:112, %r10; jg .LBB0_2. # More stack space needs to be allocated; movabsq $8, %r10 # The amount of space needed; movabsq $0, %r11 # The total size of arguments passed on stack; callq __morestack; ret # The reason for this extra return is explained below; .LBB0_2:; # Usual prologue continues here. The size of function arguments on the stack needs to be passed to; ``__morestack`` (this function is implemented in ``libgcc``) since that number; of bytes has to be copied from the previous stacklet to the current one. This is; so that SP (and FP) relative addressing of function arguments work as expected. The unusual ``ret`` is needed to have the function which made a call to; ``__morestack`` return correctly. ``__morestack``, instead of returning, calls; into ``.LBB0_2``. This is possible since both, the size of the ``ret``; instruction and the PC of call to ``__morestack`` are known. When the function; body returns, control is transferred back to ``__morestack``. ``__morestack``; then de-allocates the new stacklet, restores the correct SP value, and does a; second return, which returns control to the correct caller. Variable Sized Allocas; ----------------------. The section on `allocating stacklets`_ automatically assumes that every stack; frame will be of fixed size. However, LLVM allows the use of the ``llvm.alloca``; intrinsic to allocate dynamically sized blocks of memory on the stack. When; faced with such a variable-sized alloca, code is generated to:. * Check if the current stacklet has enough space. If yes, just bump the SP, like; in the normal case.; * If not, generate a call to ``libgcc``, which allocates the memory from the; heap. The memory allocated from the heap is linked into a list in the current; stacklet, and freed along with the same. This prevents a memory leak.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst:2278,allocate,allocates,2278,interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,4,['allocate'],"['allocate', 'allocated', 'allocates']"
Energy Efficiency,"eeded. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1->Clone(0);; for (Int_t i = 0; i < 10; ++i) {; t1->GetEntry(i);; t2->Fill();; }; t2->Write(); delete f2;; f2 = 0;; delete f1;; f1 = 0;. An example of a branch with an object allocated by us,; but owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = 0;; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. Notice that the only difference between this example; and the following example is that the event pointer; is zero when the branch is created. An example of a branch with an object allocated and; owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = new Event();; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. TTreeFormula (TTree::Draw, TTree::Scan). Fix CollectionTree->Scan(""reco_ee_et[][2]:reco_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:2295,allocate,allocated,2295,tree/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html,1,['allocate'],['allocated']
Energy Efficiency,"eference manual has been moved into Doxygen. Still some work and; polish has to be done but the reference guide in this new format is now online; and can be seen from the [ROOT home page](https://root.cern.ch/doc/master/index.html). ## Core Libraries. ### Dictionary generation. Fixed the dictionary generation in the case of class inside a namespace; marked inlined. Added mechanisms to stop the dictionary generation while parsing the XML and while selecting in presence of duplicates. Fix [ROOT-7760] : fully allow the usage of the dylib extension on OSx. Fix [ROOT-7723] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter packs in class name involved in the I/O. ### Thread safety and thread awareness. We added the function `TMethodCall::GetCallFunc` to allow direct access to the function wrapper. We reduced thread serialization in `TClass::GetCheckSum`, `TClass::GetBaseClassOffset` and `TClass::Property`. `TObjArray::Delete` was updated to allow its caller to explicitly avoid costly checks (extra RecursiveRemove and lock). We removed the need to create a TThread object per thread in a multi-threaded application. Now ROOT can be used with any threading model (e.g. OpenMP, STL threads, TBB) transparently. All the internal synchronisation mechanisms of ROOT are activated by a single call: `ROOT::EnableThreadSafety()` which is the successor of the existing `TThread::Initialize`. This call must take place if ROOT needs to be used in a thread safe manner. The implementation of TSemaphore was redone based on C++11 thread primitive in order to prevent cases where some of request post were lost. ### TDirectory::TContext. We added a default constructor to `TDirectory::TContext` which record the current directory; and will restore it at destruction time and does not change the current directory. The constructor for `TDirectory::TContext` that",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:2180,reduce,reduced,2180,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['reduce'],['reduced']
Energy Efficiency,eferenceTracker.h; llvm/tools/llvm-pdbutil/YAMLOutputStyle.h; llvm/tools/llvm-profgen/CallContext.h; llvm/tools/llvm-profgen/CSPreInliner.cpp; llvm/tools/llvm-profgen/CSPreInliner.h; llvm/tools/llvm-profgen/llvm-profgen.cpp; llvm/tools/llvm-profgen/PerfReader.cpp; llvm/tools/llvm-profgen/PerfReader.h; llvm/tools/llvm-rc/ResourceScriptCppFilter.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/del,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337217,reduce,reduce,337217,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"eferences; ^^^^^^^^^^^^^^^^. In C, similar to arrays on the function prototypes, a reference to array is; automatically promoted (or ""decayed"") to a pointer to its first element (e.g.,; ``&arr[0]``). In `-fbounds-safety`, array references are promoted to ``__bidi_indexable``; pointers which contain the upper and lower bounds of the array, with the; equivalent of ``&arr[0]`` serving as the lower bound and ``&arr[array_size]``; (or one past the last element) serving as the upper bound. This applies to all; types of arrays including constant-length arrays, variable-length arrays (VLAs),; and flexible array members annotated with `__counted_by`. In the following example, reference to ``vla`` promotes to ``int; *__bidi_indexable``, with ``&vla[n]`` as the upper bound and ``&vla[0]`` as the; lower bound. Then, it's copied to ``int *p``, which is implicitly ``int; *__bidi_indexable p``. Please note that value of ``n`` used to create the upper; bound is ``10``, not ``100``, in this case because ``10`` is the actual length; of ``vla``, the value of ``n`` at the time when the array is being allocated. .. code-block:: c. void foo(void) {; int n = 10;; int vla[n];; n = 100;; int *p = vla; // { .ptr: &vla[0], .upper: &vla[10], .lower: &vla[0] }; // it's `&vla[10]` because the value of `n` was 10 at the; // time when the array is actually allocated.; // ...; }. By promoting array references to ``__bidi_indexable``, all array accesses are; bounds checked in ``-fbounds-safety``, just as ``__bidi_indexable`` pointers; are. Maintaining correctness of bounds annotations; ---------------------------------------------. ``-fbounds-safety`` maintains correctness of bounds annotations by performing; additional checks when a pointer object and/or its related value containing the; bounds information is updated. For example, ``__single`` expresses an invariant that the pointer must either; point to a single valid object or be a null pointer. To maintain this invariant,; the compiler inserts c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:34671,allocate,allocated,34671,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['allocate'],['allocated']
Energy Efficiency,"efine; - Fill; - Filter; - Graph; - Histo[1,2,3]D; - Max; - Mean; - Min; - Profile[1,2,3]D; - Snapshot; - Sum. with support for more operations coming in the future. Any distributed RDataFrame backend inherits the dependencies of the underlying software needed to distribute the applications. The Spark backend for example has the following runtime dependencies (ROOT will build just fine without, but the feature will be unavailable without these packages):. - [pyspark](https://spark.apache.org/docs/latest/api/python/index.html), that in turn has its own set of dependencies:; - [Java](https://www.java.com/en/); - [py4j](https://www.py4j.org/). Tests for the Spark backend can be turned ON/OFF with the new build option `test_distrdf_pyspark` (OFF by default). ## Histogram Libraries. ## Math Libraries. - Update the definitions of the physical constants using the recommended 2018 values from NIST.; - Use also the new SI definition of base units from 2019, where the Planck constant, the Boltzmann constant, the elementary electric charge and the Avogadro constant are exact numerical values. See <https://en.wikipedia.org/wiki/2019_redefinition_of_the_SI_base_units>. Note that with this new definition the functions `TMath::HUncertainty()`, `TMath::KUncertainty()`, `TMath::QeUncertainty()` and `TMath::NaUncertainty()` all return a `0.0` value.; - Due to some planned major improvements to `RVec`, the layout of `RVec` objects will change in a backward-incompatible way between v6.24 and v6.26.; Because of this, we now print a warning if an application is reading or writing a `ROOT::RVec` object from/to a ROOT file. We assume this is an; exceedingly rare case, as the ROOT interface typically used to manipulate `RVec`s is `RDataFrame`, and `RDataFrame` performs an on-the-fly; `RVec <-> std::vector` conversion rather than writing `RVec`s to disk. Note that, currently, `RVecs` written e.g. in a `TTree` cannot be read back; using certain ROOT interfaces (e.g. `TTreeReaderArray`, `RDataF",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:12367,charge,charge,12367,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['charge'],['charge']
Energy Efficiency,"efining very small bits of functionality; only. The other difference between CMake functions and macros is how arguments are; passed. Arguments to macros are not set as variables, instead dereferences to; the parameters are resolved across the macro before executing it. This can; result in some unexpected behavior if using unreferenced variables. For example:. .. code-block:: cmake. macro(print_list my_list); foreach(var IN LISTS my_list); message(""${var}""); endforeach(); endmacro(). set(my_list a b c d); set(my_list_of_numbers 1 2 3 4); print_list(my_list_of_numbers); # prints:; # a; # b; # c; # d. Generally speaking this issue is uncommon because it requires using; non-dereferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake built-in commands.; We use these wrappers to provide consistent behaviors across LLVM components; and to reduce code duplication. We generally (but not always) follow the convention that commands prefaced with; ``llvm_`` are intended to be used only as building blocks for other commands.; Wrapper commands that are intended for direct use are generally named following; with the project in the middle of the command name (i.e. ``add_llvm_executable``; is the wrapper for ``add_executable``). The LLVM ``add_*`` wrapper functions are; all defined in ``AddLLVM.cmake`` which is installed as part of the LLVM; distribution. It can be included and used by any LLVM sub-project that requires; LLVM. .. note::. Not all LLVM projects require LLVM for all use cases. For example compiler-rt; can be built without LLVM, and the compiler-rt sanitizer libraries are used; with GCC. Useful Built-in Commands; ========================. CMake has a bunch of useful built-in commands. This document isn't going to; go into details about them because The CMake project has excellent; docum",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:13297,reduce,reduce,13297,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,1,['reduce'],['reduce']
Energy Efficiency,"efore creating the volume; itself, so we will describe the bits and pieces needed for making the; geometry before moving to an architectural point of view. As far as materials are concerned, they represent the physical; properties of the solid from which a volume is made. Materials are just; a support for the data that has to be provided to the tracking engine; that uses this geometry package. Due to this fact, the; TGeoMaterial class is more like a thin data structure needed for; building the corresponding native materials of the Monte-Carlo tracking; code that uses TGeo. \anchor GM00a; ### Elements, Materials and Mixtures. In order to make easier material and mixture creation, one can use the; pre-built table of elements owned by TGeoManager class:. ~~~{.cpp}; TGeoElementTable *table = gGeoManager->GetElementTable();; TGeoElement *element1 = table->GetElement(Int_t Z);; TGeoElement *element2 = table->FindElement(""Copper"");; ~~~. Materials made of single elements can be defined by their atomic mass; (`A`), charge (`Z`) and density (`rho`). One can also create a material; by specifying the element that it is made of. Optionally the radiation; and absorption lengths can be also provided; otherwise they can be; computed on-demand [`G3`]. The class representing them is; TGeoMaterial:. ~~~{.cpp}; TGeoMaterial(const char *name,Double_t a,Double_t z,; Double_t density, Double_t radlen=0,Double_t intlen=0);; TGeoMaterial(const char *name, TGeoElement *elem,; Double_t density);; TGeoMaterial(const char* name, Double_t a, Double_t z,; Double_t rho,; TGeoMaterial::EGeoMaterialState state,; Double_t temperature = STP_temperature,; Double_t pressure = STP_pressure); ~~~. Any material or derived class is automatically indexed after creation.; The assigned index is corresponding to the last entry in the list of; materials owned by TGeoManager class. This can be changed using; the `TGeoMaterial::SetIndex()` method, however it is not; recommended while using the geometry package in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:1612,charge,charge,1612,geom/geom/doc/materials.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md,1,['charge'],['charge']
Energy Efficiency,"eful for finding; bugs, we ask you to bear in mind a few points when using it.; Work-in-Progress; The analyzer is a continuous work-in-progress. There are many planned; enhancements to improve both the precision and scope of its analysis algorithms; as well as the kinds of bugs it will find. While there are fundamental; limitations to what static analysis can do, we have a long way to go before; hitting that wall.; Slower than Compilation; Operationally, using static analysis to; automatically find deep program bugs is about trading CPU time for the hardening; of code. Because of the deep analysis performed by state-of-the-art static; analysis tools, static analysis can be much slower than compilation.; While the Clang Static Analyzer is being designed to be as fast and; light-weight as possible, please do not expect it to be as fast as compiling a; program (even with optimizations enabled). Some of the algorithms needed to find; bugs require in the worst case exponential time.; The Clang Static Analyzer runs in a reasonable amount of time by both; bounding the amount of checking work it will do as well as using clever; algorithms to reduce the amount of work it must do to find bugs.; False Positives; Static analysis is not perfect. It can falsely flag bugs in a program where; the code behaves correctly. Because some code checks require more analysis; precision than others, the frequency of false positives can vary widely between; different checks. Our long-term goal is to have the analyzer have a low false; positive rate for most code on all checks.; Please help us in this endeavor by reporting false; positives. False positives cannot be addressed unless we know about; them.; More Checks; Static analysis is not magic; a static analyzer can only find bugs that it; has been specifically engineered to find. If there are specific kinds of bugs; you would like the Clang Static Analyzer to find, please feel free to; file feature requests or contribute your own; patches. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/index.html:3416,reduce,reduce,3416,interpreter/llvm-project/clang/www/analyzer/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/index.html,1,['reduce'],['reduce']
Energy Efficiency,"egratorMultiDim::kMISER` | `ROOT::Math:::GSLMCIntegrator` |; | `ROOT::Math::IntegratorMultiDim::kPLAIN` | `ROOT::Math:::GSLMCIntegrator` |. The control parameters for the integration algorithms can be specified using the; `ROOT::Math::IntegratorMultiDimOptions` class. Static methods are provided to change the default values.; It is possible to print the list of default control parameters using the `ROOT::Math::IntegratorMultiDimOptions::Print` function.; Example:; ```{.cpp}; ROOT::Math::IntegratorMultiDimOptions opt;; opt.Print();; Integrator Type : ADAPTIVE; Absolute tolerance : 1e-09; Relative tolerance : 1e-09; Workspace size : 100000; (max) function calls : 100000; ```; Depending on the algorithm, some of the control parameters might have no effect. #### `ROOT::Math::AdaptiveIntegratorMultiDim`. This class implements an adaptive quadrature integration method for multi dimensional functions. It is described in this paper; *Genz, A.A. Malik, An adaptive algorithm for numerical integration over an N-dimensional rectangular region, J. Comput. Appl. Math. 6 (1980) 295-302*.; It is part of the *MathCore* library.; The user can control the relative and absolute tolerance and the maximum allowed number of function evaluation. #### `ROOT::Math::GSLMCIntegrator`. It is a class for performing numerical integration of a multidimensional function. It uses the numerical integration algorithms of GSL, which reimplements the algorithms used; in the QUADPACK, a numerical integration package written in Fortran. Plain MC, MISER and VEGAS integration algorithms are supported for integration over finite (hypercubic) ranges.; For a detail description of the GSL methods visit the GSL users guide.; Specific configuration options (documented in the GSL user guide) for the `ROOT::Math::GSLMCIntegration` can be set directly in the class, or when using it via the `ROOT::Math::IntegratorMultiDim`; interface, can be defined using the `ROOT::Math::IntegratorMultiDimOptions`. ## Function Deriv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:61333,adapt,adaptive,61333,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['adapt'],['adaptive']
Energy Efficiency,"el; <https://discord.com/channels/636084430946959380/976196303681896538>`__.; * :ref:`IRC`. Doing this can help:; * overcome potential anxiety to call in for a first time,; * people who prefer to first exchange a few messages through text chat; before dialing in, and; * remind the wider community that office hours do exist.; * If you decide to no longer host office hours, please do remove your entry; from the list above. .. _IRC:. IRC; ---. Users and developers of the LLVM project (including subprojects such as Clang); can be found in #llvm on `irc.oftc.net <irc://irc.oftc.net/llvm>`_. The channel; is actively moderated. The #llvm-build channel has a bot for; `LLVM buildbot <http://lab.llvm.org/buildbot/#/console>`_ status changes. The; bot will post a message with a link to a build bot and a blamelist when a build; goes from passing to failing and again (without the blamelist) when the build; goes from failing back to passing. It is a good channel for actively monitoring; build statuses, but it is a noisy channel due to the automated messages. The; channel is not actively moderated. In addition to the traditional IRC there is a; `Discord <https://discord.com/channels/636084430946959380/636725486533345280>`_; chat server available. To sign up, please use this; `invitation link <https://discord.com/invite/xS7Z362>`_. .. _meetups-social-events:. Meetups and social events; -------------------------. .. toctree::; :hidden:. MeetupGuidelines. Besides developer `meetings and conferences <https://llvm.org/devmtg/>`_,; there are several user groups called; `LLVM Socials <https://www.meetup.com/pro/llvm/>`_. We greatly encourage you to; join one in your city. Or start a new one if there is none:. :doc:`MeetupGuidelines`. .. _community-proposals:. Community wide proposals; ------------------------. Proposals for massive changes in how the community behaves and how the work flow; can be better. .. toctree::; :hidden:. Proposals/GitHubMove; BugpointRedesign; Proposals/TestSuite;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingInvolved.rst:17396,monitor,monitoring,17396,interpreter/llvm-project/llvm/docs/GettingInvolved.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingInvolved.rst,1,['monitor'],['monitoring']
Energy Efficiency,"elect=movl; --report=list; --print=symbols,types,instructions,summary; test-dwarf-clang.o. Logical View:; [000] {File} 'test-dwarf-clang.o'. [001] {CompileUnit} 'test.cpp'; [003] {Code} 'movl	$0x7, -0x1c(%rbp)'; [003] {Code} 'movl	$0x7, -0x4(%rbp)'; [003] {Code} 'movl	%eax, -0x4(%rbp)'; [003] {Code} 'movl	%esi, -0x14(%rbp)'; [003] {Code} 'movl	-0x14(%rbp), %eax'; [003] {Code} 'movl	-0x4(%rbp), %eax'; [003] 4 {TypeAlias} 'INTEGER' -> 'int'; [004] 5 {Variable} 'CONSTANT' -> 'const INTEGER'. -----------------------------; Element Total Found; -----------------------------; Scopes 3 0; Symbols 4 1; Types 2 1; Lines 17 6; -----------------------------; Total 26 8. COMPARISON MODE; ^^^^^^^^^^^^^^^; In this mode :program:`llvm-debuginfo-analyzer` compares logical views; to produce a report with the logical elements that are missing or added.; This a very powerful aid in finding semantic differences in the debug; information produced by different toolchain versions or even completely; different toolchains altogether (For example a compiler producing DWARF; can be directly compared against a completely different compiler that; produces CodeView). Given the previous example we found the above debug information issue; (related to the previous invalid scope location for the **'typedef int; INTEGER'**) by comparing against another compiler. Using GCC to generate test-dwarf-gcc.o, we can apply a selection pattern; with the printing mode to obtain the following logical view output. .. code-block:: none. llvm-debuginfo-analyzer --attribute=level; --select-regex --select-nocase --select=INTe; --report=list; --print=symbols,types; test-dwarf-clang.o test-dwarf-gcc.o. Logical View:; [000] {File} 'test-dwarf-clang.o'. [001] {CompileUnit} 'test.cpp'; [003] 4 {TypeAlias} 'INTEGER' -> 'int'; [004] 5 {Variable} 'CONSTANT' -> 'const INTEGER'. Logical View:; [000] {File} 'test-dwarf-gcc.o'. [001] {CompileUnit} 'test.cpp'; [004] 4 {TypeAlias} 'INTEGER' -> 'int'; [004] 5 {Variable} 'CONSTANT' -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-debuginfo-analyzer.rst:28122,power,powerful,28122,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-debuginfo-analyzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-debuginfo-analyzer.rst,1,['power'],['powerful']
Energy Efficiency,"element, not the number of elements. A common example of how this is used is arrays where the size is not known.; It's common to use array types with zero length to represent these. The fact; that the static type says there are zero elements is irrelevant; it's perfectly; valid to compute arbitrary element indices, as the computation only depends on; the size of the array element, not the number of elements. Note that zero-sized; arrays are not a special case here. This sense is unconnected with ``inbounds`` keyword. The ``inbounds`` keyword is; designed to describe low-level pointer arithmetic overflow conditions, rather; than high-level array indexing rules. Analysis passes which wish to understand array indexing should not assume that; the static array type bounds are respected. The second sense of being out of bounds is computing an address that's beyond; the actual underlying allocated object. With the ``inbounds`` keyword, the result value of the GEP is ``poison`` if the; address is outside the actual underlying allocated object and not the address; one-past-the-end. Without the ``inbounds`` keyword, there are no restrictions on computing; out-of-bounds addresses. Obviously, performing a load or a store requires an; address of allocated and sufficiently aligned memory. But the GEP itself is only; concerned with computing addresses. Can array indices be negative?; ------------------------------. Yes. This is basically a special case of array indices being out of bounds. Can I compare two values computed with GEPs?; --------------------------------------------. Yes. If both addresses are within the same allocated object, or; one-past-the-end, you'll get the comparison result you expect. If either is; outside of it, integer arithmetic wrapping may occur, so the comparison may not; be meaningful. Can I do GEP with a different pointer type than the type of the underlying object?; ----------------------------------------------------------------------------------. Ye",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:13867,allocate,allocated,13867,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['allocate'],['allocated']
Energy Efficiency,"elevant primitive types by the interpreter loop or by the; evaluating emitter. Primitive Types; ---------------. * ``PT_{U|S}int{8|16|32|64}``. Signed or unsigned integers of a specific bit width, implemented using; the ```Integral``` type. * ``PT_{U|S}intFP``. Signed or unsigned integers of an arbitrary, but fixed width used to; implement integral types which are required by the target, but are not; supported by the host. Under the hood, they rely on APValue. The; ``Integral`` specialisation for these types is required by opcodes to; share an implementation with fixed integrals. * ``PT_Bool``. Representation for boolean types, essentially a 1-bit unsigned; ``Integral``. * ``PT_RealFP``. Arbitrary, but fixed precision floating point numbers. Could be; specialised in the future similarly to integers in order to improve; floating point performance. * ``PT_Ptr``. Pointer type, defined in ``""Pointer.h""``. A pointer can be either null,; reference interpreter-allocated memory (``BlockPointer``) or point to an; address which can be derived, but not accessed (``ExternPointer``). * ``PT_FnPtr``. Function pointer type, can also be a null function pointer. Defined; in ``""FnPointer.h""``. * ``PT_MemPtr``. Member pointer type, can also be a null member pointer. Defined; in ``""MemberPointer.h""``. * ``PT_VoidPtr``. Void pointer type, can be used for round-trip casts. Represented as; the union of all pointers which can be cast to void.; Defined in ``""VoidPointer.h""``. * ``PT_ObjCBlockPtr``. Pointer type for ObjC blocks. Defined in ``""ObjCBlockPointer.h""``. Composite types; ---------------. The interpreter distinguishes two kinds of composite types: arrays and; records (structs and classes). Unions are represented as records, except; at most a single field can be marked as active. The contents of inactive; fields are kept until they are reactivated and overwritten.; Complex numbers (``_Complex``) and vectors; (``__attribute((vector_size(16)))``) are treated as arrays. Bytecode Executi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst:2458,allocate,allocated,2458,interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,1,['allocate'],['allocated']
Energy Efficiency,"eliminated by ``InstCombine``. The major benefit of this; transformation is that it makes many other loop optimizations, such as; ``LoopUnswitch``\ ing, simpler. You can read more in the; :ref:`loop terminology section for the LCSSA form <loop-terminology-lcssa>`. .. _passes-licm:. ``licm``: Loop Invariant Code Motion; ------------------------------------. This pass performs loop invariant code motion, attempting to remove as much; code from the body of a loop as possible. It does this by either hoisting code; into the preheader block, or by sinking code to the exit blocks if it is safe.; This pass also promotes must-aliased memory locations in the loop to live in; registers, thus hoisting and sinking ""invariant"" loads and stores. Hoisting operations out of loops is a canonicalization transform. It enables; and simplifies subsequent optimizations in the middle-end. Rematerialization; of hoisted instructions to reduce register pressure is the responsibility of; the back-end, which has more accurate information about register pressure and; also handles other optimizations than LICM that increase live-ranges. This pass uses alias analysis for two purposes:. #. Moving loop invariant loads and calls out of loops. If we can determine; that a load or call inside of a loop never aliases anything stored to, we; can hoist it or sink it like any other instruction. #. Scalar Promotion of Memory. If there is a store instruction inside of the; loop, we try to move the store to happen AFTER the loop instead of inside of; the loop. This can only happen if a few conditions are true:. #. The pointer stored through is loop invariant.; #. There are no stores or loads in the loop which *may* alias the pointer.; There are no calls in the loop which mod/ref the pointer. If these conditions are true, we can promote the loads and stores in the; loop of the pointer to use a temporary alloca'd variable. We then use the; :ref:`mem2reg <passes-mem2reg>` functionality to construct the appropriat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:24056,reduce,reduce,24056,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['reduce'],['reduce']
Energy Efficiency,eltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/too,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338257,reduce,reduce,338257,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"em->Load(""libA""); // #4: explicit loading of libA. No full descriptor required.; root [] do(); // #5: error: implicit loading of libA is currently unsupported. ```. This pattern is not only used in the ROOT prompt but in I/O hotspots such as; `ShowMembers` and `TClass::IsA`. A naive implementation of this feature would require inclusion of all reachable; library descriptors (aka header files) at ROOT startup time. Of course this is; not feasible and ROOT inserts a set of optimizations to fence itself from the; costly full header inclusion. Unfortunately, several of them are home-grown and; in a few cases inaccurate (eg line #5) causing a noticeable technical debt. Here we will briefly describe the three common layers of optimizations: ROOT PCH,; ROOTMAP and RDICT. The ROOT precompiled header (PCH) reduces the CPU and memory cost for ROOT's; most used libraries. The precompiled header technology is well-understood since; decades [[4]]. It is an efficient on-disk representation of the state of the; compiler after parsing a set of headers. It can be loaded before starting the; next instance to avoid doing redundant work. At build time, rootcling (ROOT's; dictionary generator) creates such PCH file which is attached at ROOT startup; time. Its major drawback is the fact that if third-party users want to include; their libraries, they have to recompile it every time there is a change. RDICT files store some useful information (in particular about class offsets) in; ROOT files to avoid the potentially expensive call to the interpreter if the; information is not the PCH. For example, ROOT's libGeom and other third-party; code. This is done to circumvent the costly call to `ShowMembers` which will; require parsing. ROOTMAP files reduce parsing for code which is not in the PCH. Consider; `foo::bar` and `S` are defined in `libFoo`'s `Foo.h`:; ```cpp; // Foo.h; namespace foo { struct bar{}; }; struct S{};; ```. ```bash; # libFoo.rootmap; { decls }; namespace foo { }; struct S;;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:6051,efficient,efficient,6051,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['efficient'],['efficient']
Energy Efficiency,"emcpy.element.unordered.atomic.*``' intrinsic is a specialization of the; '``llvm.memcpy.*``' intrinsic. It differs in that the ``dest`` and ``src`` are treated; as arrays with elements that are exactly ``element_size`` bytes, and the copy between; buffers uses a sequence of :ref:`unordered atomic <ordering>` load/store operations; that are a positive integer multiple of the ``element_size`` in size. Arguments:; """""""""""""""""""". The first three arguments are the same as they are in the :ref:`@llvm.memcpy <int_memcpy>`; intrinsic, with the added constraint that ``len`` is required to be a positive integer; multiple of the ``element_size``. If ``len`` is not a positive integer multiple of; ``element_size``, then the behaviour of the intrinsic is undefined. ``element_size`` must be a compile-time constant positive power of two no greater than; target-specific atomic access size limit. For each of the input pointers ``align`` parameter attribute must be specified. It; must be a power of two no less than the ``element_size``. Caller guarantees that; both the source and destination pointers are aligned to that boundary. Semantics:; """""""""""""""""""". The '``llvm.memcpy.element.unordered.atomic.*``' intrinsic copies ``len`` bytes of; memory from the source location to the destination location. These locations are not; allowed to overlap. The memory copy is performed as a sequence of load/store operations; where each access is guaranteed to be a multiple of ``element_size`` bytes wide and; aligned at an ``element_size`` boundary. The order of the copy is unspecified. The same value may be read from the source; buffer many times, but only one write is issued to the destination buffer per; element. It is well defined to have concurrent reads and writes to both source and; destination provided those reads and writes are unordered atomic when specified. This intrinsic does not provide any additional ordering guarantees over those; provided by a set of unordered loads from the source locati",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:958620,power,power,958620,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"ementPtr; GlobalISel/index; GwpAsan; HowToSetUpLLVMStyleRTTI; HowToUseAttributes; InAlloca; LangRef; LibFuzzer; MarkedUpDisassembly; MIRLangRef; OptBisect; PCSectionsMetadata; PDB/index; PointerAuth; ScudoHardenedAllocator; MemTagSanitizer; Security; SecurityTransparencyReports; SegmentedStacks; StackMaps; SpeculativeLoadHardening; Statepoints; SymbolizerMarkupFormat; SystemLibrary; TestingGuide; TransformMetadata; TypeMetadata; XRay; XRayExample; XRayFDRFormat; YamlIO. API Reference; -------------. `Doxygen generated documentation <https://llvm.org/doxygen/>`_; (`classes <https://llvm.org/doxygen/inherits.html>`_). :doc:`HowToUseAttributes`; Answers some questions about the new Attributes infrastructure. LLVM Reference; --------------. ======================; Command Line Utilities; ======================. :doc:`LLVM Command Guide <CommandGuide/index>`; A reference manual for the LLVM command line utilities (""man"" pages for LLVM; tools). :doc:`Bugpoint`; Automatic bug finder and test-case reducer description and usage; information. :doc:`OptBisect`; A command line option for debugging optimization-induced failures. :doc:`SymbolizerMarkupFormat`; A reference for the log symbolizer markup accepted by ``llvm-symbolizer``. :doc:`The Microsoft PDB File Format <PDB/index>`; A detailed description of the Microsoft PDB (Program Database) file format. ==================; Garbage Collection; ==================. :doc:`GarbageCollection`; The interfaces source-language compilers should use for compiling GC'd; programs. :doc:`Statepoints`; This describes a set of experimental extensions for garbage; collection support. =========; LibFuzzer; =========. :doc:`LibFuzzer`; A library for writing in-process guided fuzzers. :doc:`FuzzingLLVM`; Information on writing and using Fuzzers to find bugs in LLVM. ========; LLVM IR; ========. :doc:`LLVM Language Reference Manual <LangRef>`; Defines the LLVM intermediate representation and the assembly form of the; different nodes. :doc:`InAllo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Reference.rst:1379,reduce,reducer,1379,interpreter/llvm-project/llvm/docs/Reference.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Reference.rst,1,['reduce'],['reducer']
Energy Efficiency,"ement_size>); declare void @llvm.memmove.element.unordered.atomic.p0.p0.i64(ptr <dest>,; ptr <src>,; i64 <len>,; i32 <element_size>). Overview:; """""""""""""""""". The '``llvm.memmove.element.unordered.atomic.*``' intrinsic is a specialization; of the '``llvm.memmove.*``' intrinsic. It differs in that the ``dest`` and; ``src`` are treated as arrays with elements that are exactly ``element_size``; bytes, and the copy between buffers uses a sequence of; :ref:`unordered atomic <ordering>` load/store operations that are a positive; integer multiple of the ``element_size`` in size. Arguments:; """""""""""""""""""". The first three arguments are the same as they are in the; :ref:`@llvm.memmove <int_memmove>` intrinsic, with the added constraint that; ``len`` is required to be a positive integer multiple of the ``element_size``.; If ``len`` is not a positive integer multiple of ``element_size``, then the; behaviour of the intrinsic is undefined. ``element_size`` must be a compile-time constant positive power of two no; greater than a target-specific atomic access size limit. For each of the input pointers the ``align`` parameter attribute must be; specified. It must be a power of two no less than the ``element_size``. Caller; guarantees that both the source and destination pointers are aligned to that; boundary. Semantics:; """""""""""""""""""". The '``llvm.memmove.element.unordered.atomic.*``' intrinsic copies ``len`` bytes; of memory from the source location to the destination location. These locations; are allowed to overlap. The memory copy is performed as a sequence of load/store; operations where each access is guaranteed to be a multiple of ``element_size``; bytes wide and aligned at an ``element_size`` boundary. The order of the copy is unspecified. The same value may be read from the source; buffer many times, but only one write is issued to the destination buffer per; element. It is well defined to have concurrent reads and writes to both source; and destination provided those reads and wri",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:961548,power,power,961548,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"ements associated to the accessed pages, which could; speed up operations that need to iterate over initialized elements in a; non-ordered manner. .. _dss_vector:. <vector>; ^^^^^^^^. ``std::vector<T>`` is well loved and respected. However, ``SmallVector<T, 0>``; is often a better option due to the advantages listed above. std::vector is; still useful when you need to store more than ``UINT32_MAX`` elements or when; interfacing with code that expects vectors :). One worthwhile note about std::vector: avoid code like this:. .. code-block:: c++. for ( ... ) {; std::vector<foo> V;; // make use of V.; }. Instead, write this as:. .. code-block:: c++. std::vector<foo> V;; for ( ... ) {; // make use of V.; V.clear();; }. Doing so will save (at least) one heap allocation and free per iteration of the; loop. .. _dss_deque:. <deque>; ^^^^^^^. ``std::deque`` is, in some senses, a generalized version of ``std::vector``.; Like ``std::vector``, it provides constant time random access and other similar; properties, but it also provides efficient access to the front of the list. It; does not guarantee continuity of elements within memory. In exchange for this extra flexibility, ``std::deque`` has significantly higher; constant factor costs than ``std::vector``. If possible, use ``std::vector`` or; something cheaper. .. _dss_list:. <list>; ^^^^^^. ``std::list`` is an extremely inefficient class that is rarely useful. It; performs a heap allocation for every element inserted into it, thus having an; extremely high constant factor, particularly for small data types.; ``std::list`` also only supports bidirectional iteration, not random access; iteration. In exchange for this high cost, std::list supports efficient access to both ends; of the list (like ``std::deque``, but unlike ``std::vector`` or; ``SmallVector``). In addition, the iterator invalidation characteristics of; std::list are stronger than that of a vector class: inserting or removing an; element into the list does not inva",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:65540,efficient,efficient,65540,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"emory.; :program:`llvm-exegesis` checks the liveliness of registers (i.e. any register; use has a corresponding def or is a ""live in""). If your code depends on the; value of some registers, you need to use snippet annotations to ensure setup; is performed properly. For example, the following code snippet depends on the values of XMM1 (which; will be set by the tool) and the memory buffer passed in RDI (live in). .. code-block:: none. # LLVM-EXEGESIS-LIVEIN RDI; # LLVM-EXEGESIS-DEFREG XMM1 42; vmulps	(%rdi), %xmm1, %xmm2; vhaddps	%xmm2, %xmm2, %xmm3; addq $0x10, %rdi. Example 3: benchmarking with memory annotations; -----------------------------------------------. Some snippets require memory setup in specific places to execute without; crashing. Setting up memory can be accomplished with the `LLVM-EXEGESIS-MEM-DEF`; and `LLVM-EXEGESIS-MEM-MAP` annotations. To execute the following snippet:. .. code-block:: none. movq $8192, %rax; movq (%rax), %rdi. We need to have at least eight bytes of memory allocated starting `0x2000`.; We can create the necessary execution environment with the following; annotations added to the snippet:. .. code-block:: none. # LLVM-EXEGESIS-MEM-DEF test1 4096 7fffffff; # LLVM-EXEGESIS-MEM-MAP test1 8192. movq $8192, %rax; movq (%rax), %rdi. EXAMPLE 4: analysis; -------------------. Assuming you have a set of benchmarked instructions (either latency or uops) as; YAML in file `/tmp/benchmarks.yaml`, you can analyze the results using the; following command:. .. code-block:: bash. $ llvm-exegesis --mode=analysis \; --benchmarks-file=/tmp/benchmarks.yaml \; --analysis-clusters-output-file=/tmp/clusters.csv \; --analysis-inconsistencies-output-file=/tmp/inconsistencies.html. This will group the instructions into clusters with the same performance; characteristics. The clusters will be written out to `/tmp/clusters.csv` in the; following format:. .. code-block:: none. cluster_id,opcode_name,config,sched_class; ...; 2,ADD32ri8_DB,,WriteALU,1.00; 2,AD",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:7203,allocate,allocated,7203,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['allocate'],['allocated']
Energy Efficiency,"en an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest cycle for a TFile being written since v5.34/11. ## Networking Libraries. ### HTTP Server. ##### Command Interface; One can now register an arbitrary command to the server, which become visible in the web browser. Then, when the item is clicked by the user, the command ends-up in a gROOT->ProcessLineSync() call. ##### Custom Properties ; Custom properties can be configured for any item in the server. For example, one could configure an icon for each item visible in the browser. Or one could 'hide' any item from the user (but keep access with normal http requests). With such properties one could specify which item is drawn when web page is loaded, or configure monitoring. See tutorials/http/httpcontrol.C macro for more details. ##### Method Calls; Implement exe.json requests to be able to execute any method of registered objects. This request is used to provide remote TTree::Draw() functionality. ##### Misc; Correctly set 'Cache-Control' headers when replying to http requests.; Better support of STL containers when converting objects into json with TBufferJSON class. ## JavaScript ROOT. - Several files can now be loaded simultaneously; - Use d3.time.scale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (via url parameter); - One could monitor simultaneously objects from server and root files; - Implement 'autocol' draw option - when superimposing histograms,; their line colors will be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:9943,monitor,monitoring,9943,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['monitor'],['monitoring']
Energy Efficiency,"en expecting an expression"");; case tok_identifier:; return ParseIdentifierExpr();; case tok_number:; return ParseNumberExpr();; case '(':; return ParseParenExpr();; }; }. Now that you see the definition of this function, it is more obvious why; we can assume the state of CurTok in the various functions. This uses; look-ahead to determine which sort of expression is being inspected, and; then parses it with a function call. Now that basic expressions are handled, we need to handle binary; expressions. They are a bit more complex. Binary Expression Parsing; =========================. Binary expressions are significantly harder to parse because they are; often ambiguous. For example, when given the string ""x+y\*z"", the parser; can choose to parse it as either ""(x+y)\*z"" or ""x+(y\*z)"". With common; definitions from mathematics, we expect the later parse, because ""\*""; (multiplication) has higher *precedence* than ""+"" (addition). There are many ways to handle this, but an elegant and efficient way is; to use `Operator-Precedence; Parsing <http://en.wikipedia.org/wiki/Operator-precedence_parser>`_.; This parsing technique uses the precedence of binary operators to guide; recursion. To start with, we need a table of precedences:. .. code-block:: c++. /// BinopPrecedence - This holds the precedence for each binary operator that is; /// defined.; static std::map<char, int> BinopPrecedence;. /// GetTokPrecedence - Get the precedence of the pending binary operator token.; static int GetTokPrecedence() {; if (!isascii(CurTok)); return -1;. // Make sure it's a declared binop.; int TokPrec = BinopPrecedence[CurTok];; if (TokPrec <= 0) return -1;; return TokPrec;; }. int main() {; // Install standard binary operators.; // 1 is lowest precedence.; BinopPrecedence['<'] = 10;; BinopPrecedence['+'] = 20;; BinopPrecedence['-'] = 20;; BinopPrecedence['*'] = 40; // highest.; ...; }. For the basic form of Kaleidoscope, we will only support 4 binary; operators (this can obviously be exten",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst:12509,efficient,efficient,12509,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst,1,['efficient'],['efficient']
Energy Efficiency,"en implemented specifically for use by; the `High-Performance Erlang; (HiPE) <http://www.it.uu.se/research/group/hipe/>`_ compiler, *the*; native code compiler of the `Ericsson's Open Source Erlang/OTP; system <http://www.erlang.org/download.shtml>`_. It uses more; registers for argument passing than the ordinary C calling; convention and defines no callee-saved registers. The calling; convention properly supports `tail call; optimization <CodeGenerator.html#tail-call-optimization>`_ but requires; that both the caller and the callee use it. It uses a *register pinning*; mechanism, similar to GHC's convention, for keeping frequently; accessed runtime components pinned to specific hardware registers.; At the moment only X86 supports this convention (both 32 and 64; bit).; ""``anyregcc``"" - Dynamic calling convention for code patching; This is a special convention that supports patching an arbitrary code; sequence in place of a call site. This convention forces the call; arguments into registers but allows them to be dynamically; allocated. This can currently only be used with calls to; llvm.experimental.patchpoint because only this intrinsic records; the location of its arguments in a side table. See :doc:`StackMaps`.; ""``preserve_mostcc``"" - The `PreserveMost` calling convention; This calling convention attempts to make the code in the caller as; unintrusive as possible. This convention behaves identically to the `C`; calling convention on how arguments and return values are passed, but it; uses a different set of caller/callee-saved registers. This alleviates the; burden of saving and recovering a large register set before and after the; call in the caller. If the arguments are passed in callee-saved registers,; then they will be preserved by the callee across the call. This doesn't; apply for values returned in callee-saved registers. - On X86-64 the callee preserves all general purpose registers, except for; R11 and return registers, if any. R11 can be used as a sc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:15970,allocate,allocated,15970,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"en on the [demo page](https://root.cern/js/latest/httpserver.C/). One could also specify similar URL parameters to configure the displayed items and drawing options. It is also possible to display one single item from the THttpServer server like:. <https://root.cern/js/latest/httpserver.C/Files/job1.root/hpxpy/draw.htm?opt=colz>. ## Data monitoring with JSROOT. ### Monitoring with http server. The best possibility to organize the monitoring of data from a running application; is to use THttpServer. In such case the client can always access the latest; changes and request only the items currently displayed in the browser.; To enable monitoring, one should activate the appropriate checkbox or; provide __monitoring__ parameter in the URL string like:. <https://root.cern/js/latest/httpserver.C/Files/job1.root/hprof/draw.htm?monitoring=1000>. The parameter value is the update interval in milliseconds. ### JSON file-based monitoring. Solid file-based monitoring (without integration of THttpServer into application) can be; implemented in JSON format. There is the [TBufferJSON](https://root.cern/doc/master/classTBufferJSON.html) class,; which is capable to convert any (beside TTree) ROOT object into JSON. Any ROOT application can use such class to; create JSON files for selected objects and write such files in a directory,; which can be accessed via web server. Then one can use JSROOT to read such files and display objects in a web browser. There is a demonstration page showing such functionality: <https://root.cern/js/latest/demo/update_draw.htm>.; This demo page reads in cycle 20 json files and displays them. If one has a web server which already provides such JSON file, one could specify the URL to this file like:. <https://root.cern/js/latest/demo/update_draw.htm?addr=../httpserver.C/Canvases/c1/root.json.gz>. Here the same problem with [Cross-Origin Request](https://developer.mozilla.org/en/http_access_control) can appear. If the web server configuration cannot be chan",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:31056,monitor,monitoring,31056,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['monitor'],['monitoring']
Energy Efficiency,"en the block is exited normally,; whether by fallthrough or directed control flow (such as ``return`` or; ``break``), the autorelease pool is restored to the saved state, releasing all; the objects in it. When the block is exited with an exception, the pool is not; drained. ``@autoreleasepool`` may be used in non-ARC translation units, with equivalent; semantics. A program is ill-formed if it refers to the ``NSAutoreleasePool`` class. .. admonition:: Rationale. Autorelease pools are clearly important for the compiler to reason about, but; it is far too much to expect the compiler to accurately reason about control; dependencies between two calls. It is also very easy to accidentally forget; to drain an autorelease pool when using the manual API, and this can; significantly inflate the process's high-water-mark. The introduction of a; new scope is unfortunate but basically required for sane interaction with the; rest of the language. Not draining the pool during an unwind is apparently; required by the Objective-C exceptions implementation. .. _arc.misc.externally_retained:. Externally-Retained Variables; -----------------------------. In some situations, variables with strong ownership are considered; externally-retained by the implementation. This means that the variable is; retained elsewhere, and therefore the implementation can elide retaining and; releasing its value. Such a variable is implicitly ``const`` for safety. In; contrast with ``__unsafe_unretained``, an externally-retained variable still; behaves as a strong variable outside of initialization and destruction. For; instance, when an externally-retained variable is captured in a block the value; of the variable is retained and released on block capture and destruction. It; also affects C++ features such as lambda capture, ``decltype``, and template; argument deduction. Implicitly, the implementation assumes that the :ref:`self parameter in a; non-init method <arc.misc.self>` and the :ref:`variable in a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:91810,drain,draining,91810,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['drain'],['draining']
Energy Efficiency,"en unmaintained for several years; it does not build with current ruby versions.; Given that this effectively meant that Ruby was dysfunctional and given that nobody (but package maintainers) has complained, we decided to remove it. ### Removal of previously deprecated or disabled packages. The packages `afs`, `chirp`, `glite`, `sapdb`, `srp` and `ios` have been removed from ROOT.; They were deprecated before, or never ported from configure, make to CMake. ### Remove GLUtesselator forward declaration from TVirtualX.h. It was never used in TVirtualX interfaces. If GLUtesselator forward declaration is required, use TGLUtil.h include instead. ## C++ Modules Technology Preview. ROOT has several features which interact with libraries and require implicit; header inclusion. This can be triggered by reading or writing data on disk,; or user actions at the prompt. Often, the headers are immutable and reparsing is; redundant. C++ Modules are designed to minimize the reparsing of the same; header content by providing an efficient on-disk representation of C++ Code. This is an experimental feature which can be enabled by compiling ROOT with; `-Druntime_cxxmodules=On`. You can read more about the current state of the; feature [here](../../README.CXXMODULES.md). ## Core Libraries. ### New command line flag ""--version"" for root. `root --version` now displays ROOT version and build info and quits:. ```; ROOT Version: 6.15/01; Built for linuxx8664gcc on Sep 20 2018, 11:04:35; From heads/master@v6-13-04-1273-gea3f4333a2; ```. ### Fish support for thisroot script. `. bin/thisroot.fish` sets up the needed ROOT environment variables for one of the ROOT team's favorite shells, the [fish shell](https://fishshell.com/). ### Change of setting the compression algorithm in `rootrc`. The previous setting called `ROOT.ZipMode` is now unused and ignored.; Instead, use `Root.CompressionAlgorithm` which sets the compression algorithm according to the values of [ECompression](https://root.cern/doc/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md:2277,efficient,efficient,2277,README/ReleaseNotes/v616/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md,1,['efficient'],['efficient']
Energy Efficiency,"en.wikipedia.org/wiki/Control-flow_graph#Reducibility>`_; has a more formal definition, which basically says that every cycle has; a dominating header. * Irreducible control-flow can occur at any level of the loop nesting.; That is, a loop that itself does not contain any loops can still have; cyclic control flow in its body; a loop that is not nested inside; another loop can still be part of an outer cycle; and there can be; additional cycles between any two loops where one is contained in the other.; However, an LLVM :ref:`cycle<cycle-terminology>` covers both, loops and; irreducible control flow. * The `FixIrreducible <https://llvm.org/doxygen/FixIrreducible_8h.html>`_; pass can transform irreducible control flow into loops by inserting; new loop headers. It is not included in any default optimization pass; pipeline, but is required for some back-end targets. * Exiting edges are not the only way to break out of a loop. Other; possibilities are unreachable terminators, [[noreturn]] functions,; exceptions, signals, and your computer's power button. * A basic block ""inside"" the loop that does not have a path back to the; loop (i.e. to a latch or header) is not considered part of the loop.; This is illustrated by the following code. .. code-block:: C. for (unsigned i = 0; i <= n; ++i) {; if (c1) {; // When reaching this block, we will have exited the loop.; do_something();; break;; }; if (c2) {; // abort(), never returns, so we have exited the loop.; abort();; }; if (c3) {; // The unreachable allows the compiler to assume that this will not rejoin the loop.; do_something();; __builtin_unreachable();; }; if (c4) {; // This statically infinite loop is not nested because control-flow will not continue with the for-loop.; while(true) {; do_something();; }; }; }. * There is no requirement for the control flow to eventually leave the; loop, i.e. a loop can be infinite. A **statically infinite loop** is a; loop that has no exiting edges. A **dynamically infinite loop** has;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst:5976,power,power,5976,interpreter/llvm-project/llvm/docs/LoopTerminology.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst,1,['power'],['power']
Energy Efficiency,"enVector_exception class is created only when the throwing of exception is enabled. This avoids the allocation of an un-needed std::string. This problem was observed in CMS when converting from 4D-vectors based on mass to standard (x,y,z,t) vectors, when the mass is zero. In this case, a numerical error creates artificially small negative masses returned by the (x,y,z,t) vector. Eventually a protection could be added when calculating M2(), to avoid negative values due to numerical rounding.; ; Fix a problem in the assignment operator of the ROOT::Math::PxPyPzM4D class. Avoid having nan when converting for example from PxPyPzME4D to PxPyPzM4D when the mass is negative. ; Throw always exception in the non-supported setters (i.e. SetPt on a PxPyPzEVector) methods, which are generated only for the CINT dictionary. These methods flag a compiled-error when running in C++ mode. SMatrix. Change implementation of the SMatrix::Invert and SMatrix::Inverse methods. Now the optimized method based on the Cramer rule is used only for matrix up to sizes 2x2. The standard methods based on LU (for ordinary square matrix) or Bunch-Kaufman factorization (for square matrix) are used. The factorization method, although slower for small size matrices, they suffer much less from numerical precision problems.; New methods SMatrix::Invert and SMatrix::InverseFast are added for using the Cramer rule for up to matrix of sizes 5x5. This method has exactly the same implementation as the Invert and Inverse of the previous ROOT version.; ; Physics. TLorentzVector:Change in the implementation of the function SetPtEtaPhi and SetPtEtaPhiM the algorithm to calculate z from pt and eta. Use now, as in the GenVector package, the expression z = pt * sinh(eta) instead of using the tangent and the arc-tangent. This is is more efficient and avoids a problem found on 64 bit machines when eta=0. by Dariusz Miskowiec. Unuran. New version (1.3) from Josef Leydold fixing some warnings on Windows Visual Studio 9. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v522/index.html:5910,efficient,efficient,5910,math/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v522/index.html,1,['efficient'],['efficient']
Energy Efficiency,"enable optimizations that may decrease floating point; precision. .. option:: -soft-float. Causes :program:`lli` to generate software floating point library calls instead of; equivalent hardware instructions. CODE GENERATION OPTIONS; -----------------------. .. option:: -code-model=model. Choose the code model from:. .. code-block:: text. default: Target default code model; tiny: Tiny code model; small: Small code model; kernel: Kernel code model; medium: Medium code model; large: Large code model. .. option:: -disable-post-RA-scheduler. Disable scheduling after register allocation. .. option:: -disable-spill-fusing. Disable fusing of spill code into instructions. .. option:: -jit-enable-eh. Exception handling should be enabled in the just-in-time compiler. .. option:: -join-liveintervals. Coalesce copies (default=true). .. option:: -nozero-initialized-in-bss. Don't place zero-initialized symbols into the BSS section. .. option:: -pre-RA-sched=scheduler. Instruction schedulers available (before register allocation):. .. code-block:: text. =default: Best scheduler for the target; =none: No scheduling: breadth first sequencing; =simple: Simple two pass scheduling: minimize critical path and maximize processor utilization; =simple-noitin: Simple two pass scheduling: Same as simple except using generic latency; =list-burr: Bottom-up register reduction list scheduling; =list-tdrr: Top-down register reduction list scheduling; =list-td: Top-down list scheduler. .. option:: -regalloc=allocator. Register allocator to use (default=linearscan). .. code-block:: text. =bigblock: Big-block register allocator; =linearscan: linear scan register allocator; =local: local register allocator; =simple: simple register allocator. .. option:: -relocation-model=model. Choose relocation model from:. .. code-block:: text. =default: Target default relocation model; =static: Non-relocatable code; =pic: Fully relocatable, position independent code; =dynamic-no-pic: Relocatable external referenc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst:4279,schedul,schedulers,4279,interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,1,['schedul'],['schedulers']
Energy Efficiency,"end(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %loop; i8 1, label %cleanup]; cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); call void @free(ptr %mem); br label %suspend; suspend:; %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none); ret ptr %hdl; }. The `entry` block establishes the coroutine frame. The `coro.size`_ intrinsic is; lowered to a constant representing the size required for the coroutine frame.; The `coro.begin`_ intrinsic initializes the coroutine frame and returns the; coroutine handle. The second parameter of `coro.begin` is given a block of memory; to be used if the coroutine frame needs to be allocated dynamically.; The `coro.id`_ intrinsic serves as coroutine identity useful in cases when the; `coro.begin`_ intrinsic get duplicated by optimization passes such as; jump-threading. The `cleanup` block destroys the coroutine frame. The `coro.free`_ intrinsic,; given the coroutine handle, returns a pointer of the memory block to be freed or; `null` if the coroutine frame was not allocated dynamically. The `cleanup`; block is entered when coroutine runs to completion by itself or destroyed via; call to the `coro.destroy`_ intrinsic. The `suspend` block contains code to be executed when coroutine runs to; completion or suspended. The `coro.end`_ intrinsic marks the point where; a coroutine needs to return control back to the caller if it is not an initial; invocation of the coroutine. The `loop` blocks represents the body of the coroutine. The `coro.suspend`_; intrinsic in combination with the following switch indicates what happens to; control flow when a coroutine is suspended (default case), resumed (case 0) or; destroyed (case 1). Coroutine Transformation; ------------------------. One of the steps of coroutine lowering is building the coroutine frame. The; def-use chains are analyzed to determine which objects need be kept alive across; suspend points. In the coroutine shown in the previous section, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:13056,allocate,allocated,13056,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['allocate'],['allocated']
Energy Efficiency,"end_amd_kernel_code_t* directive. For any; amd_kernel_code_t values that are unspecified a default value will be used. The; default value for all keys is 0, with the following exceptions:. - *amd_code_version_major* defaults to 1.; - *amd_kernel_code_version_minor* defaults to 2.; - *amd_machine_kind* defaults to 1.; - *amd_machine_version_major*, *machine_version_minor*, and; *amd_machine_version_stepping* are derived from the value of the -mcpu option; that is passed to the assembler.; - *kernel_code_entry_byte_offset* defaults to 256.; - *wavefront_size* defaults 6 for all targets before GFX10. For GFX10 onwards; defaults to 6 if target feature ``wavefrontsize64`` is enabled, otherwise 5.; Note that wavefront size is specified as a power of two, so a value of **n**; means a size of 2^ **n**.; - *call_convention* defaults to -1.; - *kernarg_segment_alignment*, *group_segment_alignment*, and; *private_segment_alignment* default to 4. Note that alignments are specified; as a power of 2, so a value of **n** means an alignment of 2^ **n**.; - *enable_tg_split* defaults to 1 if target feature ``tgsplit`` is enabled for; GFX90A onwards.; - *enable_wgp_mode* defaults to 1 if target feature ``cumode`` is disabled for; GFX10 onwards.; - *enable_mem_ordered* defaults to 1 for GFX10 onwards. The *.amd_kernel_code_t* directive must be placed immediately after the; function label and before any instructions. For a full list of amd_kernel_code_t keys, refer to AMDGPU ABI document,; comments in lib/Target/AMDGPU/AmdKernelCodeT.h and test/CodeGen/AMDGPU/hsa.s. .. _amdgpu-amdhsa-assembler-example-v2:. Code Object V2 Example Source Code; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .. warning::; Code object V2 generation is no longer supported by this version of LLVM. Here is an example of a minimal assembly source file, defining one HSA kernel:. .. code::; :number-lines:. .hsa_code_object_version 1,0; .hsa_code_object_isa. .hsatext; .globl hello_world; .p2align 8; .amdgpu_hsa_kernel hello_w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:434747,power,power,434747,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['power'],['power']
