quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Energy Efficiency,"Thanks for the explanation. It isn't clear to me that the SAMRecord API was ever intended to support ; headerless records (except maybe in very rare corner cases). I don't really know the scope of hellbender. If it is just for internal ; DSDE tools development, then I guess it doesn't matter.; If you ever want to leverage code/libraries from elsewhere, then those ; would have to be ""headerless-aware"", I guess. For example, a common operation in Genome STRiP is to ask for the sample ; associated with a read. This requires the header, I would think.; Anyway, my main point was just to stimulate thinking about the value of ; implementing an efficient way to transmit the headers.; It also seems to me that this generalizes to efficient patterns to ; transmit any widely shared data (that is referenced by many serialized ; individual data items) out-of-band. -Bob. On 9/21/15 11:42 AM, droazen wrote:. > @bhandsaker https://github.com/bhandsaker Thanks for chiming in with ; > your thoughts/concerns.; > ; > Under this proposal, the various classes in htsjdk that read and ; > return |SAMRecords| (eg., |SAMReader| & co.) would continue to put the ; > header inside of the records, so we would not be imposing an ; > additional burden on direct clients of htsjdk to check for null ; > headers any more than they do currently. The only difference is that ; > if downstream consumers of |SAMRecords| (like hellbender) choose to ; > strip the header from the records, there would be an explicit contract ; > governing the behavior of headerless |SAMRecords| (as opposed to the ; > status quo, in which the header may be null but behavior is totally ; > undocumented and in some cases inconsistent -- eg., the reference name ; > and index in a headerless |SAMRecord| can get out-of-sync in some cases).; > ; > In additional to documenting/clarifying the behavior of headerless ; > |SAMRecords| and fixing any consistency-related bugs we find when ; > operating without a header, we would also make an ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142402910:645,efficient,efficient,645,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142402910,2,['efficient'],['efficient']
Energy Efficiency,Thanks for the information about this @meganshand. I will use this class in my use case and if it is not efficient enough I will try another solution.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-267344402:105,efficient,efficient,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-267344402,1,['efficient'],['efficient']
Energy Efficiency,"Thanks for your question, @xysj1989. You are right that it can be advantageous to use SNP data for CNV calling. In my experience, however, it is not of high importance in practice. Indeed we do use BAF in our structural variation pipeline, but only for the purpose identifying high-quality calls. We typically find that BAF support tends to be weak/noisy for all but the largest CNVs, so requiring SNP evidence would greatly reduce sensitivity. @samuelklee can probably shed some more light on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6407#issuecomment-581659408:425,reduce,reduce,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6407#issuecomment-581659408,1,['reduce'],['reduce']
Energy Efficiency,"Thanks very much for your analysis. Job 4 does create a lot of garbage, but that appears to be inevitable whenever you are dealing with a PairRDD: You have to use a Tuple2 to represent key and value rather than using a more memory-conservative custom data object. You end up with a gazillion tiny objects that survive only during the shuffle. Too bad they didn't base PairRDD on an interface like Map.Entry. Also too bad that you cannot force a shuffle on a (plain old, non-Pair) RDD. Why not just treat it as a key-only structure and allow repartitioning? I mention this not merely to whine, but also in the faint hope that you've developed some helpful workarounds. I don't think we have enough memory to persist the reads, but we can revisit that later. Job 5 *is* doing a lot of computation. It's turning each read into kmers and testing each of those kmers to see if they exist in a large hash table. I don't think there's much opportunity for further optimization -- I knew this would be a bottleneck and tried my best to make the code efficient. The skew in task size is definitely a problem, and I'll be looking for opportunities to address that issue. Thanks again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292230002:1042,efficient,efficient,1042,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292230002,1,['efficient'],['efficient']
Energy Efficiency,"Thanks, @gokalpcelik ! I tested the workaround and indeed when used with a gvcf file rather than GenomicsDB the memory consumption remains reasonable. I only tried GATK 4.6 but it is probably the same with the other versions that have the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8989#issuecomment-2434583196:119,consumption,consumption,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8989#issuecomment-2434583196,1,['consumption'],['consumption']
Energy Efficiency,"That example data from the tutorial is good @sooheelee, but maybe it could be reduced in size to avoid adding it to the large file directory? It will be nice to include that example in the `RealignerTargetCreator` PR (#3112)...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319627989:78,reduce,reduced,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319627989,1,['reduce'],['reduced']
Energy Efficiency,"The AS_MQ never suffered from this issue because it uses AD for (allele-specific) depth instead of the INFO DP. The sum of the squared MQs there was allocated based on informative reads and the AD represents informative reads, so the data there was always in lock-step.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4969#issuecomment-415069583:149,allocate,allocated,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4969#issuecomment-415069583,1,['allocate'],['allocated']
Energy Efficiency,The FireCloud Job is here https://portal.firecloud.org/#workspaces/broad-firecloud-dsde/dsde-methods-sv-dev/monitor/ecdb3b72-7b4b-4612-9c87-1c0124f62708,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5217#issuecomment-424367893:108,monitor,monitor,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5217#issuecomment-424367893,1,['monitor'],['monitor']
Energy Efficiency,"The HaplotypeBAMWriter implementation as ported from GATK is currently spread out over 5 classes, with a base class and two subclasses for the writers and a base class and one subclass to represent the writer destination. All of the functionality can be reduced to one simple HaplotypeBAMWriter class (or possibly two if we want to keep the destination separate).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/944:254,reduce,reduced,254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/944,1,['reduce'],['reduced']
Energy Efficiency,"The Hardy-Weinberg equilibrium (HWE) theorem characterizes the distributions of genotype frequencies in populations that are not evolving. Letâ€™s recall it in its simplest form. [Hardy-Weinberg] Let ( A ) and ( a ) be alleles at a single locus in a non-evolving population with random mating. Let ( p ) and ( q ) be their respective frequencies in that population. ( p ) and ( q ) will remain constant in average from generation to generation. The expected frequencies of the genotypes, ( AA ), ( Aa ) and ( aa ), will also remain constant and are respectively ( p^2 ), ( 2pq ), and (q^2 ). Description:. Use Wiggintonâ€™s exact test because it adequately controls type I errors in large and small samples. Calculated by:. Pedstats and vcftools use efficient implementations from Wigginton et al.; use code by Wigginton as your starting point (need to translate to java i think). Remark:. Deviations from HWE can indicate inbreeding, admixture, or population stratification. In order to avoid the latter, HWE tests should be run for each ethnicity/population separately. Typically a variant is filtered out if, for any of the ethnicities, the P-value is lower than (10^\textrm{-6}). HWE tests can also identify loci with systematic genotyping errors, which makes HWE useful for QC.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/538:746,efficient,efficient,746,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/538,1,['efficient'],['efficient']
Energy Efficiency,The SV discovery pipeline threw a bunch of errors seemingly related to this:; https://issues.apache.org/jira/browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.conc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:287,schedul,scheduler,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491,4,['schedul'],['scheduler']
Energy Efficiency,"The SVConcordance tool is currently too inefficient in terms of memory usage, requiring several 100's of GB of heap space on ~100K samples. This PR aims to reduce memory usage in two ways:. 1. Truth VCF records are stripped of all genotype fields except `GT` and `CN`, which are necessary and sufficient for concordance computations.; 2. A new option `--do-not-sort` is introduced to skip output record sorting. A major source of heap usage is the output buffer in the `ClosestSVFinder` class, which ensures records are emitted in coordinate-sorted order. This buffer quickly fills, however, when there is at least one record being actively clustered that spans a large interval because the buffer cannot be flushed until a variant beyond the maximal clusterable coordinate of that large variant is encountered. This option will allow users to substantially reduce max heap usage on larger call sets (a single SVRecord can consume ~100MB with 100K samples). Includes an integration test to cover the `--do-not-sort` functionality.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8623:156,reduce,reduce,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8623,2,['reduce'],['reduce']
Energy Efficiency,The alignment we currently get from naively calling into `bwa mem` produces significantly overlapping alignments both on their reference span and read consumption. Hopefully realignment (with `SWPairwiseAlignment`?) could make this easier. Deciding which part of reference and (long) read to align against might be tricky.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3322:151,consumption,consumption,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3322,1,['consumption'],['consumption']
Energy Efficiency,"The approach I've taken in https://github.com/broadinstitute/hellbender/compare/master...tomwhite:hadoop-references is similar to sharding, in that each worker streams the portion that it needs from HDFS. @droazen I agree that comparing with a ""broadcast everything"" approach would be valuable - I'll write some code to do that and create a PR for it. @cwhelan - it's very similar to the Hadoop distributed cache, the main difference is that Spark uses a BitTorrent-like mechanism for distributing the data, which is more efficient for the network. You still need the memory to store the data in on the nodes, which for a genome is ~3GB. But that shouldn't be too onerous with modern hardware.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/567#issuecomment-112859930:522,efficient,efficient,522,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/567#issuecomment-112859930,1,['efficient'],['efficient']
Energy Efficiency,"The code difference between OSX and Linux is pretty small. . Here's the change in the native code. ; - Linux will define the `threads` variable and use it in the OpenMP pragma.; - OSX will not see the `threads` declaration and the OpenMP pragma will be a comment. ``` C; #ifdef linux; int threads = min((int)maxNumThreadsToUse, omp_get_max_threads());; #endif; #pragma omp parallel for schedule(dynamic, 1) num_threads(threads); ```. We also need a minor change in `build.gradle`. I'll submit the changes to this PR and you can decide from there.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1813#issuecomment-218857915:386,schedul,schedule,386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1813#issuecomment-218857915,1,['schedul'],['schedule']
Energy Efficiency,"The code to automatically inject ""--VERBOSITY ERROR"" was included in [#171](https://github.com/broadinstitute/hellbender/pull/171/files), but without [#603](https://github.com/broadinstitute/hellbender/pull/603) or equivalent it doesn't affect log4j output. dding in #603 reduces the log output by about another 7000 lines. In addition, we could squeeze out another 5000 lines by automatically injecting ""--QUIET false"" the same way we inject --VERBOSITY.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/147#issuecomment-116737455:272,reduce,reduces,272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/147#issuecomment-116737455,1,['reduce'],['reduces']
Energy Efficiency,"The current FindBreakpointEvidence code is classifying reads pairs that overlap such that the start position of the reverse read is before the start position of the forward read as ""OutiesPair"" discordant read pair evidence. However, these are likely due to sequencing of very short inserts that causes some of the adapter to be sequenced and potentially aligned. This change requires a read pair to not be overlapping to be counted as an 'OutiesPair'. On the CHM dataset this causes the number of intervals discovered to drop from 23152 to 21633, and the number of called variants to drop from 3467 to 3366. . @tedsharpe could you review?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2515:315,adapt,adapter,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2515,1,['adapt'],['adapter']
Energy Efficiency,"The current, early-stage ReadWalker interface has only an apply()/map operation. We need to determine whether the GATK engine should accumulate map output and/or provide full reduce functionality, or whether this should be done externally by a separate framework that runs the tools (a la Queue).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/114:175,reduce,reduce,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/114,1,['reduce'],['reduce']
Energy Efficiency,"The fix will enable run gradle build and test on PowerPC while the pairHMM native binary build is being sorted out. It also introduced tolerance when compare two floating point numbers, which caused test failure on PowerPC.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1761:49,Power,PowerPC,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1761,2,['Power'],['PowerPC']
Energy Efficiency,The goal of this PR is to adjust the ingest in two ways:; 1. To update the ingest to loop through all samples (not just the first 10k); 2. To update the ingest to be far more efficient in a few ways:; - To remove the files that are downloaded to each vm so that they do not carry around the extra weight; - To check that the samples in the fofns have not been ingested already so that additional work doesn't need to be done toward processing those samples. There is still work to do around making the bulk ingest process significantly more user-friendly,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8197:175,efficient,efficient,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8197,1,['efficient'],['efficient']
Energy Efficiency,"The htsjdk and Hadoop-BAM parts of this are done (some refactoring will be needed for ReadSparkSink). The gating factor is getting Hadoop-BAM to move to Java 8 (this will be a topic for the call with Hadoop-BAM scheduled for 1/21) and upgrading to a newer htsjdk with ref-factored CRAM support. It would possible to implement this without that upgrade, but the it would require each partition to write a complete CRAM file, which would make the merging at the end much less efficient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1270#issuecomment-171421991:211,schedul,scheduled,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1270#issuecomment-171421991,2,"['efficient', 'schedul']","['efficient', 'scheduled']"
Energy Efficiency,The htsjdk downstream tests were put together before gradle had composite builds and are very hacky. They should be refactored to use composite builds instead of installing a strangely named maven artifact. . We should also split them into unit/ integration tests to reduce wallclock time. This should be easy since we already to it in travis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3235:267,reduce,reduce,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3235,1,['reduce'],['reduce']
Energy Efficiency,"The idea is to partition the reference in the same way as reads, then do a `zipPartitions` to join them together. Then only the relevant part of the reference is sent to each executor, which should reduce memory usage.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2192:198,reduce,reduce,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2192,1,['reduce'],['reduce']
Energy Efficiency,"The main issue was that the `StatusRuntimeException`s that the baseline error handling code was trying to catch in practice always seem to be wrapped in at least one layer of exception of a different type. There was no catch handing for these wrapper exception types so the `CreateVariantIngestFiles` tool would simply crash. The changes here also more generally try to follow the recommendations in the [BQ Write API documentation](https://cloud.google.com/bigquery/docs/write-api#error_handling), in particular `close`ing the `JsonStreamWriter` before retrying error codes not explicitly called out by the documentation. An exponential backoff was also added before retry attempts. Parallel logic was also added to load status writing which should reduce (but not eliminate) the possibility of inconsistent sample status writes that require manual intervention. There is still the possibility of an inopportunely timed preemption, which is why VS-262 exists.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7787:750,reduce,reduce,750,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7787,1,['reduce'],['reduce']
Energy Efficiency,"The main issue was that the `StatusRuntimeException`s that the baseline error handling code was trying to catch in practice always seem to be wrapped in at least one layer of exception of a different type. There was no catch handing for these wrapper exception types so the `CreateVariantIngestFiles` tool would simply crash. ~The changes here also more generally try to follow the recommendations in the [BQ Write API documentation](https://cloud.google.com/bigquery/docs/write-api#error_handling), in particular `close`ing the `JsonStreamWriter` before retrying error codes not explicitly called out by the documentation.~. EDIT: actually closing the writer didn't work out too well as we use the writer in `PENDING` mode and closing it seems to lose all pending writes. ðŸ˜¬ So in this circumstance we just throw and let WDL-level `maxRetries` start the data loading over from the beginning. An exponential backoff was also added before retry attempts. Parallel logic was also added to load status writing which should reduce (but not eliminate) the possibility of inconsistent sample status writes that require manual intervention. There is still the possibility of an inopportunely timed preemption, which is why VS-262 exists. All of the WDL changes here are in support of a 2000-sample tieout, a large enough set that intermittent BigQuery errors are almost always observed. The tieout confirms that errors of the two major classes are seen (retryable and non-retryable) and that the number of rows per sample in the tieout dataset matches those in a reference dataset.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7841:1019,reduce,reduce,1019,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7841,1,['reduce'],['reduce']
Energy Efficiency,"The main purpose of this PR was to output the new estimated bytes read from the Read API for better monitoring and debugging. However in the course of that I discovered that we were using ancient versions of the google APIs. No massive improvements from the release logs, but a lot of nice features (cleaner logging, automatic retries for certain errors, ). bigQuery 1.131.1 -> 2.3.3 [Release log for bigQuery](https://github.com/googleapis/java-bigquery/blob/main/CHANGELOG.md). bigQueryStorage 1.22.3 -> 2.5.0 [Release log for bigQueryStorage](https://github.com/googleapis/java-bigquerystorage/blob/main/CHANGELOG.md)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7601:100,monitor,monitoring,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7601,1,['monitor'],['monitoring']
Energy Efficiency,The new validation tests for `ReadsPipelineSpark` should be easily runnable in either a push-button fashion or on a set automatic schedule (nightly or weekly) via a jenkins server. Depends on https://github.com/broadinstitute/gatk/issues/1400,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1401:130,schedul,schedule,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1401,1,['schedul'],['schedule']
Energy Efficiency,"The overarching goal of this PR is to reduce or eliminate the effect of cohort size on the filtering of variants for a specific sample. As an example this means the filtering for the genotypes for a GIAB sample should be the same whether you make a VCF of the full cohort and then subset to the GIAB sample (expensive) or you just make a callset with just the GIAB sample. This is good for users since their results won't get ""better"" with more samples that they don't care about in their VCF. - calculate and store LowQual filter as a part of Filter Set creation; - use LowQual filter from filter set rather than recalculating it from QUALapprox at extract time; - flag (default is true) to perform VQSLod filtering at the sample/genotype level. Before/After results showing minimal impact are at:; https://docs.google.com/spreadsheets/d/1LUrssKHBCwIzbA_9M3b01Ul0urMbOOmv4Z703dHwiyg/edit#gid=398306713",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7248:38,reduce,reduce,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7248,1,['reduce'],['reduce']
Energy Efficiency,"The problem is that the catch block in `CommandLineProgram` is calling both `commandLineParser.usage()` and `printDecoratedUserExceptionMessage()` -- it should only be calling `commandLineParser.usage()`, and letting the catch block in `Main.mainEntry()` call `printDecoratedUserExceptionMessage()`. Otherwise there are cases where a `CommandLineException` will be caught without printing any error message. This is a bug and should be fixed. The distinction between ""errors that are the user's fault"" and ""errors that are not the user's fault"" is very important for our support team -- it allows them to deal with bug reports and forum questions much more efficiently. Whatever solution we come up with here should maintain that distinction, and clearly label errors like ""bad argument value"" as being a user error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268712938:657,efficient,efficiently,657,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268712938,1,['efficient'],['efficiently']
Energy Efficiency,The progress meter is correct. There just happened to be 5 million empty no calls at the start of the file which processed very fast.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6631#issuecomment-647782238:13,meter,meter,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6631#issuecomment-647782238,1,['meter'],['meter']
Energy Efficiency,The proposal for a more officially support scatter/gather seems in theory OK to me. I was not proposing GATK make a scheduler and was agreeing that is problematic/difficult for you to realistically do that. I would tend to strongly favor keeping those more separate,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641540201:116,schedul,scheduler,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641540201,1,['schedul'],['scheduler']
Energy Efficiency,"The recent branch #8489 has demonstrated that there are some problematic edge cases in the pileup allele merging code that could cause pathological numbers of haplotypes to be handed to the genotyper. In updating the bug in that branch it was observed that it is very common that there are score ties at the 5th haplotype level for the pileupcaller as illustrated by the noise in the updated tests. This algorithm is not a good heuristic and we should replace it with something better, some ideas from that branch that might fix a few of its shortcomings:. 1) Increase/decouple the kmer size used with the reads from the assembly graph kmer size to prevent the filtering step from being redundant with assembly; 2) Normalize the scores to the haplotype lengths to deal with haplotype size bias.; 3) Change the scores to instead reflect the absolute count of unsupported kmers from the graph to also deal with hapotype size bias. ; 4) Iteratively expand the kmer size used for filtering to pare down the number of haplotypes in a more principled fashion.; 5) Utilize the read kmer occurrence counts to construct the scores in order to reduce the risk of spurious reads being sufficient support for a given haplotype. . We have observed that there can be significant changes to the actual genotyping engine output from the pileup engine from even relatively minor changes to the pileupcalling merging code. We should strive to find a more principled solution for merging haplotypes than the one we have currently.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8494:1134,reduce,reduce,1134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8494,1,['reduce'],['reduce']
Energy Efficiency,"The tests now pass with the Spark Dataflow Runner on Travis (this is due to the reduced memory usage). However, the cloud tests are failing with:. ```; com.google.cloud.dataflow.sdk.util.IllegalMutationException: DoFn BaseRecalibratorFn mutated input value KV{org.broadinstitute.hellbender.utils.read.GoogleGenomicsReadToGATKReadAdapter@412c8e5d, ReadContextData{referenceBases=ReferenceBases{bases=[67, 65, 65, 84, 67, 65, 84, 67, 67, 65, 67, 84, 71, 84, 67, 67, 67, 65, 65, 67, 67, 65, 84, 67, 67, 65, 67, 67, 65, 84, 67, 84, 65, 67, 67, 67, 65, 67, 67, 84, 65, 84, 67, 67, 65, 67, 67, 65, 67, 84, 67, 65, 67, 67, 67, 84, 84, 84, 67, 84, 84, 84, 67, 65, 84, 84, 67, 65, 67, 84, 67, 65, 84, 67, 67, 84, 67, 67, 67, 65, 84, 67, 67, 84, 67, 67, 67, 65, 84, 67, 67, 65, 67, 67, 65, 84, 67, 67, 65, 67, 67, 67, 84, 67, 67, 65, 67, 67, 67, 65, 84], interval=20:1000503-1000613}, variants=<>}} of class class com.google.cloud.dataflow.sdk.values.KV (new value was KV{org.broadinstitute.hellbender.utils.read.GoogleGenomicsReadToGATKReadAdapter@3e1f8308, ReadContextData{referenceBases=ReferenceBases{bases=[67, 65, 65, 84, 67, 65, 84, 67, 67, 65, 67, 84, 71, 84, 67, 67, 67, 65, 65, 67, 67, 65, 84, 67, 67, 65, 67, 67, 65, 84, 67, 84, 65, 67, 67, 67, 65, 67, 67, 84, 65, 84, 67, 67, 65, 67, 67, 65, 67, 84, 67, 65, 67, 67, 67, 84, 84, 84, 67, 84, 84, 84, 67, 65, 84, 84, 67, 65, 67, 84, 67, 65, 84, 67, 67, 84, 67, 67, 67, 65, 84, 67, 67, 84, 67, 67, 67, 65, 84, 67, 67, 65, 67, 67, 65, 84, 67, 67, 65, 67, 67, 67, 84, 67, 67, 65, 67, 67, 67, 65, 84], interval=20:1000503-1000613}, variants=<>}}). Input values must not be mutated in any way.; ```. (See https://travis-ci.org/broadinstitute/hellbender/jobs/76504336). Has anyone seen this before?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/845#issuecomment-133363894:80,reduce,reduced,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/845#issuecomment-133363894,1,['reduce'],['reduced']
Energy Efficiency,"The two main resources limiting how many gVCFs you can import at once will be memory and file handles. . I'm not sure if you mean incremental import or batch size when you mention the iterative approach. I assume the latter, but just want to clarify that there isn't any reason to break up the import using incremental import. The batch size parameter effectively does that, so you might as well import all gVCFs you have available (optionally using batch size if you're running out of memory). I'll throw out batch sizes of 50 or 100 as being reasonable, but the size of the intervals being imported will make a difference. It would be best to try to monitor how much memory is being used with those settings. There won't be a huge difference in import performance depending on the number of batches (ignoring memory issues) but if you have more than a 100 or so batches and you don't enable the `--consolidate` option you may see some query performance degradation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656376952:652,monitor,monitor,652,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656376952,1,['monitor'],['monitor']
Energy Efficiency,The vulnerabilities reduced a bit but most serious once continue to be there. Dependency upkeep is really needed to iron this out these.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1544539592:20,reduce,reduced,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1544539592,1,['reduce'],['reduced']
Energy Efficiency,"There appears to be something about this branch that is causing the tests to take ~2x longer than usual (~2 hours instead of ~1). Before merging this, we should make sure that the tests are not only green, but also back to the normal runtime for the test suite.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-462427965:199,green,green,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-462427965,1,['green'],['green']
Energy Efficiency,"There are no error messages.; The process was interrupted without any error messages.; I attached the screenshot.; I attached chr14 variant calling (completed) and chr14 variant calling; (interrupted).; In the system monitor, when I am using GATK 4.6.0.0., they are eating up; memory continuously.; When they are reaching up to 512Gb, the process was interrupted.; I tried to run this process on only 2-3 chromosomes, and I found that the; process was completed on chr 14, and the process was interrupted on the; rest of two chromosomes (interval -L).; So I rolled back to GATK 4.5.0.0, the process was normal. I can do; GenotypeGVCFs command entire chromosome simultaneously. My machine has 512Gb memory and 64 cores (5995wx AMD threadripper) dell; 7865 workstation.; Thanks; Jinu Han. On Fri, Jul 19, 2024 at 12:08â€¯AM GÃ¶kalp Ã‡elik ***@***.***>; wrote:. > Can you provide your logs that shows the error message?; >; > â€”; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2236819113>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AG7IXWWGPB73BXPN4Z5E4VTZM7LAFAVCNFSM6AAAAABLBRETECVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMZWHAYTSMJRGM>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2238806751:217,monitor,monitor,217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2238806751,1,['monitor'],['monitor']
Energy Efficiency,There has been a request to do some more work on the HMM again and its become clear that there is not an efficient way to rapidly generate large amounts of test data based on the old HMM results. It would be helpful to add an option to dump the hmm scores out to the command line in an easily machine parseable format. Here is an example of how it has been done in the past (and probably how we should do it this time): https://github.com/Intel-HLS/GKL/blob/master/src/test/resources/pairhmm-testdata.txt,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7647:105,efficient,efficient,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7647,1,['efficient'],['efficient']
Energy Efficiency,"There have been recent problems in GATK/Queue related to unmapped reads and intervals. Not sure if that's relevant here, but it may be worth monitoring how that's resolved.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/166#issuecomment-73307229:141,monitor,monitoring,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/166#issuecomment-73307229,1,['monitor'],['monitoring']
Energy Efficiency,"There were some good basic examples in the original ticket:. - get all the contiguously aligned reads (e.g, xxM); - get reads with soft clipping (e.g., xSxxM, could be reads with partial adapter sequence still left after trimming); - get reads with insertions (e.g., xxMxxIxxM, could be spliced reads, e.g., reads spanning exon-exon, or intron-intron junction); - get reads with deletions (g.g., xxMxxDxxM, could point at SV). Those would be the basic must-haves. Then the next step of nice-to-haves would be to be able to find specific patterns like ""D followed by I"" or specific numbers of operators like ""exactly five D in a row"" or ""five D in total, not necessarily in consecutive order"". Do you need me to be more specific than that?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/588#issuecomment-307890525:187,adapt,adapter,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/588#issuecomment-307890525,1,['adapt'],['adapter']
Energy Efficiency,"These are both `@Advanced` tool arguments, but they don't seem to impact the number of threads used by Python, based both on my own results and those reported in [this forum post](https://gatkforums.broadinstitute.org/gatk/discussion/comment/57482#Comment_57482). Setting OMP_NUM_THREADS to 1 does seem to reduce the number of threads used by python though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5846:306,reduce,reduce,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5846,1,['reduce'],['reduce']
Energy Efficiency,"These things always happen just before a 3-day weekend :) Since we're about out of time for this week, we'll have to follow up on this on Tuesday when the Broad re-opens. Hopefully the new dylib fixes the travis failures -- if not, perhaps it would be a good idea to schedule a troubleshooting session after our regular weekly meeting. Have a good weekend @kdatta @kgururaj @cmnbroad !",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294237177:267,schedul,schedule,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294237177,1,['schedul'],['schedule']
Energy Efficiency,"Thinking about this a bit more, we're actually quite close to a solution. In the existing Spark Mark Duplicates implementation, for example, you can set the parallelism (with -P). By default it is the same as the number of input partitions, but if the partitions are too large then each reducer has too much data to deal with and the job fails. This is why we made the number of partitions large by reducing the split size to 10MB. However, by increasing the number of reducers (by setting -P to be input data size/10MB), the input split size can be increased to its default of 128MB without causing a problem. So I think the work here is to work out a good set of defaults and the smallest number of knobs to override them. For example, I think we could always use the default split size, have some heuristics to choose a good value for the parallelism, and allow it to be overridden with -P.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1248#issuecomment-161988491:287,reduce,reducer,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1248#issuecomment-161988491,2,['reduce'],"['reducer', 'reducers']"
Energy Efficiency,"This PR contains fixes aimed at improving the performance of HaplotypeCaller at sites with a spanning deletion. There are three main changes:. * Modified the behavior of the `use-posteriors-to-calculate-qual` method for calculating QUAL. This method is supposed to assign a QUAL based on the posterior probabilities of genotypes which do not include a variant allele. In most cases, this set of genotypes is limited to HOM-REF. However, if a `*` allele is present at the site, it does not represent a variant allele at the locus in question (its QUAL is computed upstream at the deletion start site). Therefore, `use-posteriors-to-calculate-qual` should use any genotype that is composed of combinations of REF and `*` -- in the diploid case this would be `REF/REF`, `*/REF`, and `*/*`. This dramatically reduces the QUAL of sites that have a spanning deletion, as often most of the reads that don't support the variants beginning at the site support the overlapping deletion, increasing the likelihood of `REF/*` and `REF/REF`. This summation parallels that computed by `VariationalAlleleFrequencyCalculator`, which also special-cases `*` as an allele which does not contribute to the the likelihood of a variant allele at the site in question.; * Fixed a bug in `VariationalAlleleFrequencyCalculator` relating to summing across non-site specific variant alleles as mentioned above. An indexing problem was causing the calculator to sum `REF/REF` and `REF/*` genotypes but not `*/*` genotypes (in the diploid case).; * Added an option `limit-spanning-events-to-called-variants` to HaplotypeCaller. If enabled, the current implementation of this method only allows the `*` allele to be included in genotyping and QUAL calculations if at least one of the variants found in haplotypes overlapping the locus matches a deletion that was actually called upstream (without this option HaplotypeCaller reverts to its current behavior, which is to allow any haplotype with a deletion overlapping the location ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6816:805,reduce,reduces,805,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6816,1,['reduce'],['reduces']
Energy Efficiency,"This PR fixes #3823 opened by @LeeTL1220 . There are several series of commits applied here:. 1. The first set of commits rebase `ll_CollectAllelicCountsSpark` on `master`.; 2. Then there's a commit (https://github.com/broadinstitute/gatk/commit/21e1dcfb88fc6543f6ba3e6095eba512a33f9f8d) to fix up some changes to make `CollectAllelicCountsSpark` work on `master`.; 3. The next set of commits applies the changes from #5127 and #5221 (since they have not yet been merged) to make passing the reference in Spark more efficient. These changes are needed for the fix below to work.; 4. The actual fix is in https://github.com/broadinstitute/gatk/commit/3326b9093246ff6fb51ad5537951b4646411d80f.; 5. There's also a new test for `ExampleLocusWalkerSpark` in addition to the one for `CollectAllelicCountsSpark`. The problem was that `emitEmptyLoci()` in `LocusWalkerSpark` was not working properly. Any intervals that didn't overlap with reads were being dropped, which meant that those loci were not being passed to the `LocusWalkerSpark` subclass.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5222:516,efficient,efficient,516,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5222,1,['efficient'],['efficient']
Energy Efficiency,"This addresses https://github.com/broadinstitute/gatk/issues/1015 and https://github.com/broadinstitute/gatk/issues/1094. The idea is to remove the single reducer sort (which doesn't scale), by performing a totally ordered parallel sort on the reads, then writing each partition as a (headerless) BAM file. Finally, the BAM files are concatenated together after writing an initial header. This is very similar to the approach that Hadoop-BAM takes, but adapted to work on Spark. I haven't done extensive benchmarking, but when I ran MD on a ~75MB BAM the runtime dropped from >30 mins to around 8 mins. This is still worse than the walker equivalent for small files, but it's an improvement that means many jobs that didn't finish before now do. Note that this includes the changes from https://github.com/broadinstitute/gatk/pull/1127. I'll rebase once that is committed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1174:155,reduce,reducer,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1174,2,"['adapt', 'reduce']","['adapted', 'reducer']"
Energy Efficiency,This also happens when there are more reducers than reads such that at least one reducer writes an empty split bam.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2219#issuecomment-318399649:38,reduce,reducers,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2219#issuecomment-318399649,2,['reduce'],"['reducer', 'reducers']"
Energy Efficiency,"This code (building off of Louis' fixes) adds the following:; - AuthHolder, a replacement for the PipelineOptions. It stores the authentication info we need for GCS and supports both API_KEY and client-secrets.json. I adapted a few classes to accept an AuthHolder.; - BaseRecalibratorOptimizedSpark, a port of the ""shard"" approach I first did on the Dataflow side. Note that currently this code only performs reasonably for small inputs if you specify -L on the command line (for large inputs it doesn't matter).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/987:218,adapt,adapted,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/987,1,['adapt'],['adapted']
Energy Efficiency,This greatly reduces wall clock time in M2 scatters without affecting sensitivity. It is decoupled from HaplotypeCaller's downsampling.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3988:13,reduce,reduces,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3988,1,['reduce'],['reduces']
Energy Efficiency,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/443:966,efficient,efficiently,966,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443,1,['efficient'],['efficiently']
Energy Efficiency,"This is a checkpoint PR for https://github.com/broadinstitute/gatk/issues/1237 and https://github.com/broadinstitute/gatk/issues/1643. This is the first step in refactoring metrics collectors so they can be pipelined in Spark and reuse RDDs, but still share metrics computation code between walker and Spark versions. The next step will be to extend MultilevelCollector to be able to merge its own instances in order to support efficient map and reduce phases for multi level collectors. Suggested review order:. -MetricsCollectorSpark: interface to be implemented by all Spark collectors; -MetricsArgs:base class for all collector argument sets; -MetricsCollectorToolSpark: base class for all Spark metrics collector tools; -CollectQualityYieldMetrics: Spark version of QualityYieldMetrics using these new interfaces; -CollectInsertSizeMetricsSpark: existing Spark version of InsertSizeMetrics collector ported; to these interfaces; -CollectMultipleMetricsSpark: Spark version of CollectMultipleMetrics; currently only works; on QualityYieldMetrics and InsertSizeMetrics. The rest of the PR is refactoring existing to get QualityYieldMetrics and InsertSizeMetrics to conform to these interfaces (moving CollectInsertSizeMetrics out of the sv package and Program Groups, etc.). Note that the existing InsertSizeMetrics Spark collector doesnâ€™t really share code with the walker; version (and their command line param sets are way out of sync) but this should be fixed separately from these changes as the interfaces evolve.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1827:428,efficient,efficient,428,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1827,2,"['efficient', 'reduce']","['efficient', 'reduce']"
Energy Efficiency,"This is a hot topic recently, so I already have a doc to compare and contrast: https://docs.google.com/document/d/1qws0owSEc0XGcZGAcxmBOEk8fiWS1Dnv4tvHNgC_xVU/edit?usp=sharing. Gnarly is still a ""beta"" tool. I wanted to add some way to reduce the number of alternate alleles, but that may be easier to do after this recent GenomicsDB update.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1069164647:236,reduce,reduce,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1069164647,1,['reduce'],['reduce']
Energy Efficiency,"This is a serious issue. Here's another error I've seen when running with `--sparkRunner SPARK` and `--sparkMaster local[*]`:. ```; ./gatk-launch PrintReadsSpark -I src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.bam -O foo.bam -- --sparkRunner SPARK --sparkMaster local[*]. org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost): ; java.lang.ClassCastException: htsjdk.samtools.SAMFileHeader cannot be cast to htsjdk.samtools.SAMFileHeader; at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.lambda$writeReadsSingle$4e0a7f18$1(ReadsSparkSink.java:186); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$86/1825278638.call(Unknown Source); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:686); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:686); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277); at org.apache.spark.rdd.RDD.iterator(RDD.scala:244); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277); at org.apache.spark.rdd.RDD.iterator(RDD.scala:244); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:63); at org.apache.spark.scheduler.Task.run(Task.scala:70); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1315#issuecomment-164085312:1601,schedul,scheduler,1601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1315#issuecomment-164085312,2,['schedul'],['scheduler']
Energy Efficiency,"This is based on @davidadamsphd's initial work to port mark duplicates to Spark. It's not finished yet, but I wanted to post this for discussion. In particular 7 of the 56 mark duplicates integration tests are failing with ""Cannot get mate information for an unpaired read"" - I'm not sure how to address that. I'd appreciate some help on this one. The code currently has four shuffles: one groupBy in transformFragments (in MarkDuplicatesSparkUtils), two groupBys in transformReads, and one combine (foldByKey) in generateMetrics. The combine is more efficient than the others since it can run on the map side, reducing the amount of data that goes through the shuffle. I think it may be possible to merge the processing of the fragments and the reads to eliminate a shuffle - so there are only two shuffles for the main transform. A fragment would be represented as a pair with an empty second slot, so it can be handed in the processing separately from the true pairs that have both slots filled.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/889:551,efficient,efficient,551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/889,1,['efficient'],['efficient']
Energy Efficiency,"This is causing an issue in our project with green team, due to ExAC. I will design a fix. @jonn-smith",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4792#issuecomment-400756954:45,green,green,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4792#issuecomment-400756954,1,['green'],['green']
Energy Efficiency,"This is rebased off of https://github.com/broadinstitute/gatk/pull/3716, since it depends on code there. Hence, only the second commit needs to be reviewed in this PR. The code and tests are quite similar to that for PlotSegmentedCopyRatio/PlotACNVResults. However, I've changed the R scripts to be more efficient (WGS plots no longer take several hours). Furthermore, PlotModeledSegments is more flexible than PlotACNVResults in that it plots CR, AF, or both on the fly depending on the available inputs. I've also added some more input validation, changed some terminology, and moved over to data.table for reading TSVs in R.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3729:304,efficient,efficient,304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3729,1,['efficient'],['efficient']
Energy Efficiency,"This is to substantially reduce disk costs in high resolution WGS gCNV runs per #5716. As discussed elsewhere, we can enable indexing/gzipping/streaming in the gCNV WDLs themselves, but this should happen after updating to WDL 1.0 (which we need for optional localization). This PR only partially addresses that issue, since we could make more sweeping changes in the abstract CNV collection classes. However, I did make a small change to TableReader that allows all TSV/CNV collection files to be gzipped. I fixed format specification in the CollectReadCounts WDL task, which was kind of wonky and incorrect. It's still kind of wonky (due to WDL limitations), but it should be correct. Some exception handling is now done in bash. I also had to fix some missing newlines at EOFs. One such missing newline in the test counts file caused indexing of the gzipped version of the file to miss the last count upon querying during initial testing. Although probably unnecessary, I changed JSON writing in gCNV to include such newlines.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6266:25,reduce,reduce,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6266,1,['reduce'],['reduce']
Energy Efficiency,"This likely has to do with your spark configuration. Check on the Spark job's progress through the web interface, which should be something like http://<driver_address>:4040 (see https://spark.apache.org/docs/latest/monitoring.html). . If your BAM is very small, you can also try increasing the number of partitions by reducing --bamPartitionSize.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932:216,monitor,monitoring,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932,1,['monitor'],['monitoring']
Energy Efficiency,"This micro-optimization fell out of profiling of the HaplotypeCaller in GVCF mode. . Profiler view over an Exome before this patch:; <img width=""906"" alt=""screen shot 2018-11-30 at 2 06 34 pm"" src=""https://user-images.githubusercontent.com/16102845/49310230-bc44a380-f4ab-11e8-98aa-1c0b321223c0.png"">. Profiler view over the same Exome after this patch:; <img width=""886"" alt=""screen shot 2018-11-30 at 2 20 39 pm"" src=""https://user-images.githubusercontent.com/16102845/49310291-e4cc9d80-f4ab-11e8-9fb3-4d819fbce43a.png"">. I suspect given the remaining 9% runtime could be reduced further by looking more closely at the array operations in `isReadInformativeAboutIndelsOfSize()` . (It should be noted that these profiler results lie within the ReferenceModelForNoVariation codepath which since this is over an Exome we expect the runtime to overall be skewed towards no-variation blocks). Resolves #5648",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5469:574,reduce,reduced,574,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5469,1,['reduce'],['reduced']
Energy Efficiency,"This new PathSeq WDL redesigns the workflow for improved performance in the cloud. Downsampling can be applied to BAMs with high microbial content (ie >10M reads) that normally cause performance issues. . Other improvements include:. * Removed microbial fasta input, as only the sequence dictionary is needed.; * Broke pipeline down to into smaller tasks. This helps reduce costs by a) provisioning fewer resources at the filter and score phases of the pipeline and b) reducing job wall time to minimize the likelihood of VM preemption.; * Filter-only option, which can be used to cheaply estimate the number of microbial reads in the sample.; * Metrics are now parsed so they can be fed as output to the Terra data model.; * CRAM-to-BAM capability; * Updated WDL readme; * Deleted unneeded WDL json configuration, as the configuration can be provided in Terra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6536:367,reduce,reduce,367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6536,1,['reduce'],['reduce']
Energy Efficiency,This optimizes the defaults in mitochondria-mode for WGS mitochondria calling. It changes the `pruning-lod-threshold` in adaptive pruning and the `lod-divided-by-depth` threshold in `FilterMutectCalls`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5544:121,adapt,adaptive,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5544,1,['adapt'],['adaptive']
Energy Efficiency,This reduces the size of the docker image from ~9GB when LFS tests were being run to 2.74GB. fixes #3414,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3418:5,reduce,reduces,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3418,1,['reduce'],['reduces']
Energy Efficiency,"This script will look for a small input that trips BaseRecalibrator. However, it can be adapted for debugging pretty much anything else, so long as you have two versions of the code: a ""known good"" one to compare against, and a ""under test"" one that has the bug you're trying to generate a minimal input for.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/913:88,adapt,adapted,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/913,1,['adapt'],['adapted']
Energy Efficiency,"This set of optimizations brings the GATK4 HaplotypeCaller performance into line; with GATK3.x performance. Note that HaplotypeCallerSpark is not touched by this PR (that is for a future PR). Summary of changes:. * AssemblyRegionWalker: query all intervals on each contig simultaneously, rather than individually; * GATKRead: Cache adaptor boundary, soft start/end, and cigar length; * GATKRead: add getBasesNoCopy() / getBaseQualitiesNoCopy(); * ReadPileup: speed up stratified constructor; * LIBS.lazyLoadNextAlignmentContext(): don't keep pileup elements unnecessarily separated by sample during pileup creation; * Restore faster GATK3 version of ReferenceConfidenceModel.sumMismatchingQualities(); * RefVsAnyResult: nest within ReferenceConfidenceModel, and allow direct field access; * Remove redundant getBases() call in ReadThreadingGraph; * Fix BaseGraph Utils.validateArg() call; * ReadPileup: replace Collections.unmodifiableList(pileupElements).iterator() with direct return of an iterator that forbids removal; * Kill expensive bounds checking in GATKRead getBase()/getBaseQuality()/getCigarElement(); * Kill nonNull checks in PileupElement; * Kill expensive PileupElement and ReadPileup arg validation; * GATKRead adapter: clear cached values upon mutation",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4031:332,adapt,adaptor,332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4031,2,['adapt'],"['adapter', 'adaptor']"
Energy Efficiency,"This tool always emits ""Processed 0 total records"" at traversal end. We just need to hook it up to the standard progress meter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2683:121,meter,meter,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2683,1,['meter'],['meter']
Energy Efficiency,This uses the new defaults with adaptive pruning in version 4.1.0.0 in Mutect and removes the old ad hoc pruning argument. @ldgauthier can you please take a look when you get a chance?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5669:32,adapt,adaptive,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5669,1,['adapt'],['adaptive']
Energy Efficiency,"This was an oversight on our part that we'll fix. You should also note, however, that we have a branch coming soon that will *significantly* reduce the size of the main GATK docker image (by several GB).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4610#issuecomment-377297997:141,reduce,reduce,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4610#issuecomment-377297997,1,['reduce'],['reduce']
Energy Efficiency,This was debugged while testing https://github.com/samtools/htsjdk/pull/576. Readers allocated in `AbstractMarkDuplicatesCommandLineProgram.openInputs` were never closed. In the asyncIO realm (if we switch to async reading) this is a big problem because one worker thread is then created and abandoned (it keeps living after its master is long gone - unless the master is closed which will inform the worker to finish). The diffs are much more trivial than it looks in github gui - essentially 2 things were put in try-with-resources (two lines like this) and lot of white-space shifting followed.; `final SamHeaderAndIterator headerAndIterator = openInputs();`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1729:85,allocate,allocated,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1729,1,['allocate'],['allocated']
Energy Efficiency,"This was showing up in the profile, as with a few other places this was copying the cigar for each read over each pileup, which is not efficient.; Before:; <img width=""912"" alt=""screen shot 2019-02-07 at 11 55 24 am"" src=""https://user-images.githubusercontent.com/16102845/52429724-a4ecec80-2ad2-11e9-9e63-e79c62767215.png"">; After:; <img width=""951"" alt=""screen shot 2019-02-07 at 12 20 16 pm"" src=""https://user-images.githubusercontent.com/16102845/52429818-cf3eaa00-2ad2-11e9-84fb-b8cbcf7617b2.png"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5652:135,efficient,efficient,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5652,1,['efficient'],['efficient']
Energy Efficiency,"ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). 00:11:09.634 ERROR TaskSetManager:70 - Task 15 in stage 1.0 failed 1 times; aborting job; 00:11:09.810 WARN TaskSetManager:66 - Lost task 33.0 in stage 1.0 (TID 528, localhost): TaskKilled (killed intentionally); 00:11:24.786 INFO HaplotypeCallerSpark - Shutting down engine; [May 26, 2017 12:11:24 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 10.58 minutes.; Runtime.totalMemory()=16622026752; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 1.0 failed 1 times, most recent failure: Lost task 15.0 in stage 1.0 (TID 519; , localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculation",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:10067,Reduce,ReduceOps,10067,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Reduce'],['ReduceOps']
Energy Efficiency,"Three main performance optimizations:. 1. **Avro Parsing**: More efficient parsing and representation of primitive types in Avro-based records (ExtractCohortRecord, ReferenceRecord). We previously called toString() and then parseLong() on everything, even though it was already the right datatype. 2. **Inferred State**: we keep track of which samples have been seen, so that later we can determine which samples have **not** been seen for each site. The data structures here were slow with 100k samples and lots of variants. Moved to using a TreeSet and BitSet. 3. **Reference Genotypes**: Add reference genotypes in bulk (via ReferenceGenotypeInfo, rather than a heavy Variant Context) rather than one at a time. More Details from profiling. https://docs.google.com/spreadsheets/d/1aA7LKgPsaELiGurw95qVX1PwGt54I5rn1h_fAAhkPMo/edit#gid=0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7686:65,efficient,efficient,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7686,1,['efficient'],['efficient']
Energy Efficiency,"To be honest, I don't have a clear idea of why this is happening. I tried running a query with 1000 samples using the same GenomicsDB jar that GATK uses and the memory consumption stayed below 1 GB. Some suggestions/questions:; * If you were importing/querying multiple intervals at once, I would expect #4994 to be relevant. But your script shows a single interval being imported/queried.; * Would it be possible to run the SelectVariants tool using the GenomicsDB workspace as input and see how much memory is being consumed (instead of GenotypeGVCFs)? The Select tool simply extracts the data from GenomicsDB and prints out a VCF.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5024#issuecomment-406750537:168,consumption,consumption,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5024#issuecomment-406750537,1,['consumption'],['consumption']
Energy Efficiency,"To test GATK on IBM's power systems we need to run an automated test suite off-travis (they do not have power support). We have an account at http://osuosl.org/ - @droazen has an account. Ideally, this would run on all pushes to all branches (+ add a badge to our repo) but we can start with a nightly build of master",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1808:22,power,power,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1808,2,['power'],['power']
Energy Efficiency,Tool to create a reduced input bam file with those reads that constitute the evidence of a set of given variants.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2504:17,reduce,reduced,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2504,1,['reduce'],['reduced']
Energy Efficiency,"Travis [updated](https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/) the trusty images last night (seems to be ok so far). They also added a new update schedule and a new [group](https://blog.travis-ci.com/2017-12-01-new-update-schedule-for-linux-build-images) declaration. The default appears to be ""stability ensured"", but this adds an explicit declaration for that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3953:171,schedul,schedule,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3953,2,['schedul'],"['schedule', 'schedule-for-linux-build-images']"
Energy Efficiency,"Travis is green, this is ready for review!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4695#issuecomment-383997874:10,green,green,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4695#issuecomment-383997874,1,['green'],['green']
Energy Efficiency,Travis tests failed -- rerunning. This one can be merged once it turns green.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6751#issuecomment-705685609:71,green,green,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6751#issuecomment-705685609,1,['green'],['green']
Energy Efficiency,"Try to determine peak `HaplotypeCaller` memory requirements by running on some unusually deep samples / samples that have caused memory issues in the past. Ask palantir or green team if they have any known ""problem samples"" that could be used for this purpose. Target is to stay under 6 GB peak memory usage.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4272:172,green,green,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4272,1,['green'],['green']
Energy Efficiency,Tune the split size and number of reducers for spark tools (sensible defaults + ability to override),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1403:34,reduce,reducers,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1403,1,['reduce'],['reducers']
Energy Efficiency,"Turns out that the failure rate with this patch was greatly reduced, but there were still a few failures. We're trying a run now where we tell the tool to import one file at a time (as opposed to a batch of 25 or 100), and we'll see how that goes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307506558:60,reduce,reduced,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307506558,1,['reduce'],['reduced']
Energy Efficiency,Two commits here:. - The first is to fix a no longer accurate message in `UserException.BadTmpDir`; - The second is a few improvements to IOUtils. ; 1. Rename and simplify `tmpDir` -> `createTempDir` and make it automatically scheduled for deletion; 2. Add documentation to the confusing `absolute` method so that I stop wondering what it's for,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4711:226,schedul,scheduled,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4711,1,['schedul'],['scheduled']
Energy Efficiency,"Two primary sets of changes. 1. split out the combined ""CREATE TABLE AS... SELECT... join PET + VET"" into 3 separate items. CREATE, INSERT vet, INSERT pet; 2. To keep our shuffle down we are not joining in sample_id at query time, since we already have the id -> name mapping in ExtractCohort... we just needed to use it (should reduce costs slightly also). Testing. Tested on the GVS tieout set. As expected the only difference in the cohort extract tables is that we are no longer seeing mis-joined VET information at `*` sites (which is a nice side benefits). Otherwise tables tie out exactly in SQL. In addition, I ran a full GIAB tieout before and after and the results are identical",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7288:329,reduce,reduce,329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7288,1,['reduce'],['reduce']
Energy Efficiency,"Unless I hear otherwise, I'll merge when tests turn green.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/913#issuecomment-142750701:52,green,green,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/913#issuecomment-142750701,1,['green'],['green']
Energy Efficiency,Updated:; Successful VQSR Lite Run (with monitoring summary output) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/ccdc0ec5-3737-407f-ac84-ca2309167a2b); Successful VQSR Classic Run (with monitoring summary output) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/001671aa-21db-437a-8d92-42bced766ca6),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1502284208:41,monitor,monitoring,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1502284208,2,['monitor'],['monitoring']
Energy Efficiency,Updates to reduce size of docker,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8259:11,reduce,reduce,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8259,1,['reduce'],['reduce']
Energy Efficiency,Use conditionals to reduce the coverage collection to one task call in case and pon GATK ACNV wdl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2940:20,reduce,reduce,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2940,1,['reduce'],['reduce']
Energy Efficiency,"User would like to know if we have guidelines to provide. It would be nice to have a timeframe to tell our users or some generic guidelines in setting parameters. . ---; I find really interesting the Flagstat [chart](https://software.broadinstitute.org/gatk/resources/img_tutorials/tutorial_10060_figures/wes_increase_executors_chart.png ""chart"") and the relative [table](https://software.broadinstitute.org/gatk/resources/img_tutorials/tutorial_10060_figures/wes_increase_executors_table.png ""table""), it lets me understand that 7 is the most efficient executors-number for this tool. It's the same even for other tools? Or is there something similar (charts) for Pipelines like [BwaAndMarkDuplicatesPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.2/org_broadinstitute_hellbender_tools_spark_pipelines_BwaAndMarkDuplicatesPipelineSpark.php ""BwaAndMarkDuplicatesPipelineSpark""), [BQSRPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.3/org_broadinstitute_hellbender_tools_spark_pipelines_BQSRPipelineSpark.php ""BQSRPipelineSpark""), HaplotypeCallerSpark and [ReadsPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.5/org_broadinstitute_hellbender_tools_spark_pipelines_ReadsPipelineSpark.php ""ReadsPipelineSpark"") ?; And then, the ```--driver-memory``` is an important parameter? Which should be his value?. I'm waiting for a your kind answer,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/43894#Comment_43894",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3822:544,efficient,efficient,544,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3822,1,['efficient'],['efficient']
Energy Efficiency,"Users (@yfarjoun @jnoms) have been reporting high run times in PathSeq when the samples have a large proportion (on the order of 10%+) of microbial reads. PathSeq was designed to run on samples with low numbers (<1%) microbial reads, but there are two ways users can currently improve performance when that's not the case:. 1) Run the 3 PathSeq tools individually (Filter, Align, and Score) instead of using `PathSeqPipelineSpark`, which simply runs those in series. This will eliminate over-allocation of resources during Filter and Score. This also will reduce the likelihood that Spark will recompute parts of the graph when it is low on memory/disk. ; 2) Enable `--skip-pre-bwa-repartition`, see https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_hellbender_tools_spark_pathseq_PathSeqPipelineSpark.php#--skip-pre-bwa-repartition; 3) Omit metric file outputs. This may also help Spark to avoid recomputing tasks from earlier parts of the graph. Planned features to help improve this:; 1) Automatically enable `--skip-pre-bwa-repartition` when a large amount of non-host reads is detected.; 2) Option to downsample the input BAM on the fly. This is also useful for estimating the proportion of non-host contamination.; 3) Option to limit the number of non-host reads that are processed. This is essentially equivalent to (2), but the downsampling would be performed after host filtering and could be used when the fraction of non-host reads is unknown a priori.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5780:556,reduce,reduce,556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5780,1,['reduce'],['reduce']
Energy Efficiency,Using adaptive pruning in mitochondria pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5669:6,adapt,adaptive,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5669,1,['adapt'],['adaptive']
Energy Efficiency,"Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 21/04/13 07:32:24 ERROR SparkHadoopWriter: Task attempt_20210413073224_0026_r_000000_0 aborted.; 21/04/13 07:32:24 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 105); org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Sequence [VC HC @ chr4_GL000008v2_random:7168-7691 Q. of type=SYMBOLIC alleles=[T*, <NON_REF>] attr={END=7691} GT=[[NA12878 T*/T* GQ 0 DP 0 PL 0,0,0 {MIN_DP=0}]] filters= added out of order currentReferenceIndex: 25, referenceIndex:37; at htsjdk.tribble.index.tabix.AllRefsTabixIndexCreator.addFeature(AllRefsTabixIndexCreator.java:79); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:203); at htsjdk.variant.variantconte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:6036,schedul,scheduler,6036,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,VS-943.; Fixes a bug in summarize_monitoring_logs script where it didn't recognize the format of certain monitoring log files.; This PR also migrates the changes to support VQSR Lite in gvs_avros_to_vds.py to import_gvs.py and removes the former since it is no longer used.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8345:105,monitor,monitoring,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8345,1,['monitor'],['monitoring']
Energy Efficiency,Vs 1063 bit pack ref ranges data into a more efficient representation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8543:45,efficient,efficient,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8543,1,['efficient'],['efficient']
Energy Efficiency,"VsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (Ã¸)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `77.6% <0%> (-9.6%)` | `28% <0%> (-8%)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2467?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2467?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2467?src=pr&el=footer). Last update [e1e71d7...71c03a3](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2467#issuecomment-287565894:4983,Power,Powered,4983,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2467#issuecomment-287565894,1,['Power'],['Powered']
Energy Efficiency,"W9uVGVzdC5qYXZh) | `1.66% <0%> (-98.34%)` | `1% <0%> (-5%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.75% <0%> (-98.25%)` | `1% <0%> (-6%)` | |; | [...bender/tools/spark/PileupSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QaWxldXBTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `2.04% <0%> (-97.96%)` | `2% <0%> (-13%)` | |; | [...tute/hellbender/tools/FlagStatIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GbGFnU3RhdEludGVncmF0aW9uVGVzdC5qYXZh) | `2.08% <0%> (-97.92%)` | `1% <0%> (-5%)` | |; | [...rs/variantutils/SelectVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `0.25% <0%> (-97.75%)` | `1% <0%> (-70%)` | |; | ... and [154 more](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=footer). Last update [1d6f5b3...d98f9dc](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399:4752,Power,Powered,4752,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399,1,['Power'],['Powered']
Energy Efficiency,"WRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9FdmlkZW5jZVRhcmdldExpbmsuamF2YQ==) | `70.51% <0%> (-4.12%)` | `18% <0%> (+2%)` | |; | [...ools/copynumber/CreateReadCountPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NyZWF0ZVJlYWRDb3VudFBhbmVsT2ZOb3JtYWxzLmphdmE=) | `86.07% <0%> (-3.93%)` | `11% <0%> (+2%)` | |; | [...er/tools/copynumber/formats/records/CopyRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9Db3B5UmF0aW8uamF2YQ==) | `74.35% <0%> (-1.65%)` | `17% <0%> (+8%)` | |; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `95.74% <0%> (-1.56%)` | `20% <0%> (+3%)` | |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `70.62% <0%> (-1.32%)` | `71% <0%> (+26%)` | |; | ... and [170 more](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=footer). Last update [9eb1704...ff52e6b](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327:4552,Power,Powered,4552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327,1,['Power'],['Powered']
Energy Efficiency,"WRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <Ã¸> (-62.264%)` | `8% <Ã¸> (+8%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <Ã¸> (-60.87%)` | `2% <Ã¸> (+2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `44.444% <Ã¸> (-29.861%)` | `28% <Ã¸> (+28%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <Ã¸> (-23.729%)` | `0% <Ã¸> (Ã¸)` | |; | ... and [15 more](https://codecov.io/gh/broadinstitute/gatk/pull/2385/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2385?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2385?src=pr&el=footer). Last update [14f73e2...b1802b2](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2385#issuecomment-279409892:5036,Power,Powered,5036,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2385#issuecomment-279409892,1,['Power'],['Powered']
Energy Efficiency,"We already have a battery of carrot tests that we would like to run to evaluate the HaplotypeCaller. However those tests do not currently cover any of the new use cases in the FlowBasedGATK code. The ask here is that we should create and design a set of longer running, multi-sample evaluation code for the FlowBasedGATK on a reasonable set of non-sensitive input bams that we can call and then subsequently run evaluation metrics on so we can have a better evaluation of how future improvements impact the FlowBasedCode.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7982:18,battery,battery,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7982,1,['battery'],['battery']
Energy Efficiency,"We are currently plagued with cryptic intermittent failures coming from the BWA and FML bindings in Travis CI. These usually manifest as a simple ""exited with code 137"" (ie., killed by signal 9) error, but sometimes we get an explicit segfault or out-of-memory error. Examples:. ```; ï¿½[31mFAILURE: ï¿½[39mï¿½[31mBuild failed with an exception.ï¿½[39m; * What went wrong:; Execution failed for task ':test'.; ï¿½[33m> ï¿½[39mProcess 'Gradle Test Executor 1' finished with non-zero exit value 137; ```. ```; :test[M::bwa_idx_load_from_disk] read 0 ALT contigs; OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000715180000, 719847424, 0) failed; error='Cannot allocate memory' (errno=12). #; # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 719847424 bytes for committing reserved memory.; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid11513.log; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f27ebfe7d9a, pid=11455, tid=0x00007f27e87e5700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libfml.6198146539708364717.jnilib+0xed9a] rld_itr_init+0x4a; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fd2680a350c, pid=11685, tid=0x00007fd2b02bf700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libbwa.5694772191018335324.jnilib+0x850c] bwa_mem2idx+0xcc; ```. The underlying issue in these cases is likely either ""out of memory"" or, perhaps in the case of the seg faults, ""file not found"" o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3209:663,allocate,allocate,663,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209,1,['allocate'],['allocate']
Energy Efficiency,"We can split the tests up into a bunch of build units, but we get rapidly diminishing returns since we spend minutes installing things and building the artifacts for every vm. Travis doesn't have any notion of a build pipeline, so we can't say ""build the artifact on 1 vm and then share it and run the tests on these 10 vms"". Since we have a hard limit of the number of VMs we can use at a time for DSDE ( currently 15) being less efficient is very bad news. ( We could of course pay for more... I recently asked travis support if we could switch to an unlimited pay for usage model and they said no. ) We could also try optimizing wasted vm time by prebuilding dockers to run in, but that's additional complication. (maybe not to much, might be worth it). We also would need a scheme for dividing tests evenly between VM's. I tried writing a testng test listener to distribute them between N nodes based on the hashcode of the test class, for use on circleci, but it fell over and exploded for some reason that I never debugged. We could either debug it, or possibly split the tests by splitting the list of test files and then passing those in specifically. (May run into character limits for command lines... ). Balancing it is going to be tricky though in any case since the tests are very unevenly expensive. (We could probably manually balance it since there are a small number of slow tests and the rest are so fast they don't really matter) . The easiest thing would be to set the test to run in parallel on their existing vm. I can try turning it on again. I remember it caused problems before though, which I assume we haven't addressed. Each vm has 2 cores, so we might see some speedup. I suspect we may be using both cores to some degree already, since performance nearly doubled when we switched from the 1 core to 2 core build machines. We could probably build a more efficient pipeline on jenkins if we wanted since it does have a notion of pipelines.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1769#issuecomment-214492346:431,efficient,efficient,431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1769#issuecomment-214492346,2,['efficient'],['efficient']
Energy Efficiency,"We currently repartition the data into a fixed number of assemblies per partition. Once getExecutorCores is implemented in https://github.com/broadinstitute/gatk/pull/1947, we could make sure that we don't reduce the number of partitions to less than the number of cores.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1967:206,reduce,reduce,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1967,1,['reduce'],['reduce']
Energy Efficiency,"We don't run the cloud tests on every check-in because they take too long, but we should be running them automatically on some schedule so we catch bugs early rather than late.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/656:127,schedul,schedule,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/656,1,['schedul'],['schedule']
Energy Efficiency,"We feel that users potentially getting unexpected bills for requester-pays usage would be even more user-unfriendly than having to explicitly opt-in to such charges via a command line argument. If you're running GATK via a WDL, it seems like the billing project could be a single unified input parameter in the accompanying JSON which then gets passed to all individual tasks, which doesn't seem too cumbersome.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6669#issuecomment-647679332:157,charge,charges,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6669#issuecomment-647679332,1,['charge'],['charges']
Energy Efficiency,"We have a tool, VariantQC, that extends VariantEval. This PR is a minor refactor to expose the code that creates the list of VariantStratifier and VariantEvaluator objects as protected methods, so subclasses could modify them. This should have no functional difference on VariantEval itself. We're hoping to use these changes in order to adapt our tool in response to reviewers, so if there is any way to push these changes we would appreciate it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5998:338,adapt,adapt,338,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5998,1,['adapt'],['adapt']
Energy Efficiency,We have asked the green team to run their pipeline tests on this branch to at least limit the risk of more full sample failures. It will probably be a few more days before we have those results. @gbggrant,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-614126868:18,green,green,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-614126868,1,['green'],['green']
Energy Efficiency,"We recently created the ""variantcalling"" task in the travis CI test suite to reduce the runtime of our integration tests. Once we refactored the docker image we found that the the integration tests are still taking an uncomfortable amount of time to run (upwards of 57 minutes). Short of resolving the issue more permanently (#4989) we can temporarily fix the solution by just splitting off more of the integration tests to other jobs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4990:77,reduce,reduce,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4990,1,['reduce'],['reduce']
Energy Efficiency,"We recommend backing up data just because it is the ""cleanest"" way to roll back. If backing up data is really such a pain point, you could skip doing that. Just back up the callset.json file, and don't turn on `--consolidate` when you're doing incremental import. If a failure happens, just roll back the callset.json and re-do the import. The downside is that the failed import will hang around and take up disk space, but hopefully it is a rare enough occurrence that it doesn't matter - and you will have saved yourself backing up the data. In response to 2) - I guess you're implying that the overhead of cluster/job scheduling won't amortize any benefits from parallelism there? I suppose that could be true, but doesn't seem to be worth optimizing towards that. What I'm asking is whether split and merge are purely an instrument to allow you to choose the granularity of parallelism you want to use? Or is there something else? As I said before, we are considering enabling other ways to do distributed import which would work for the former. It might go something like:; - Create a workspace/initialize configuration+intervals to be imported; - Actually do the import by kicking off (multiple) import(s). User can pick the number of intervals each import is responsible for. User must ensure that no interval gets specified in multiple import processes. P.S: regarding 1000s of small contigs - the current GenomicsDBImport doesn't so so well with large number of contigs (unless you do concatenate the contigs into fewer groups). We hope to have some changes coming soon that will help with that by adding an option for the tool to merge multiple contigs into a single folder in the workspace.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641037548:621,schedul,scheduling,621,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641037548,1,['schedul'],['scheduling']
Energy Efficiency,"We see a massive (18x) slowdown of our spark performance tests on jenkins. The failures started on July 20th. The last good build was of a21447f. Which leaves one of:; - 4c697e06ea33c9179840c81c843658442c82a951: Move to google-cloud-java snapshot with more robust retries, and set â€¦ ; - 1bc0bbfc5a2240e85fd4b9f9010673c7242552a0 Filter Mutect2 artifacts that arise from apparent-duplicate reads. as the culprit. It seems more likely that the google cloud changes are causing the slowdown.; It seems like the slowdown is happening because of a change in the scattering, going from many partitions to fewer partitions which then all get scheduled on the same shard.; It's not immediately obvious what's causing this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3437:634,schedul,scheduled,634,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3437,1,['schedul'],['scheduled']
Energy Efficiency,"We should probably adapt the IntervalTree from htsjdk to work for us. We've run into a number of cases where this is needed, in Valentine's exome code and in Tom's hadoop reader. We could use both. `boolean overlaps(Locatable locatable, IntervalTree<Locatable> locatables)`. and . `Set<Locatable> getOverlapping(Locatable locatable, IntervalTree<Locatable> locatables)`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/559:19,adapt,adapt,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/559,1,['adapt'],['adapt']
Energy Efficiency,"We use Gauss-Legendre integration in the strand bias model. The number of subdivisions increases with the read count and for very deep coverage this can cause a stack overflow because, unfortunately, Apache Commons has a very questionable recursive implementation. The short-term fix is to cap the number of subdivisions. The long-term fix is to write some sort of simple adaptive 1D and 2D quadrature method. This ticket is for the short-term fix.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3317:372,adapt,adaptive,372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3317,1,['adapt'],['adaptive']
Energy Efficiency,"We want tasks such as parsing VCF files to be done in Java, rather than in Python, so that we can leverage all the work we do in htsjdk even in tools that call into a `PythonScriptExecutor`. This implies that we need an easy/efficient means of streaming data in and out of the child Python process. Perhaps a ""popen()""-like approach would be good here (or a named FIFO, or protocol buffers...lots of options).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3698:225,efficient,efficient,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3698,1,['efficient'],['efficient']
Energy Efficiency,"We want to move all the production GVCFs to the ""reblocked"" format to reduce the storage footprint. The new format doesn't list PLs for hom ref genotypes, so some changes to GenotypeGVCFs need to be made.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7223:70,reduce,reduce,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7223,1,['reduce'],['reduce']
Energy Efficiency,"We're trying to chop out huge pile-ups, and genomically ubiquitous kmers, and high frequency kmers in the read set, and then we yet again eliminate kmers that appear in numerous intervals. Can't we do something simpler that cleans up the drek more efficiently?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1889:248,efficient,efficiently,248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1889,1,['efficient'],['efficiently']
Energy Efficiency,"Well, we're definitely happy to accept contributions to the code base should you be interested in trying to implement it yourself. :) . I estimate that implementing the sliding window walker will be relatively easy to do, but making it perform well may be more difficult since the necessary caching for efficient traversal may not be implemented in the engine yet. . We definitely won't have time to spend on it this week since we're pretty busy with work for our first release. It's a feature we're already interested in though, and since others are also obviously interested I'll try and see if we can bump up it's priority.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1198#issuecomment-160752441:303,efficient,efficient,303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1198#issuecomment-160752441,1,['efficient'],['efficient']
Energy Efficiency,"What do you mean by more automated? It looks like you're allocating space based on the input file sizes and some padding, which is already more automated than the user adjusting disk size by hand. Do you mean that Cromwell should allocate space appropriately given the inputs? The issue is that you also need space for the outputs, which is harder to predict unless you have a sense of what the task is doing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4737#issuecomment-386594579:230,allocate,allocate,230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4737#issuecomment-386594579,1,['allocate'],['allocate']
Energy Efficiency,"What we really want in implementations of `Variant`, I think, is what we already have for `GATKRead`: both a strict `equals()` that checks everything including UUID, as well as an `equalsIgnoreUUID()` that checks for value equality and ignores the UUIDs (and allows different implementations of `Variant` to evaluate as equal). While we're at it, we could make both `Variant.equals()` and `Variant.equalsIgnoreUUID()` call into `VariantUtils.variantsAreEqual()` to reduce code duplication.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/664:465,reduce,reduce,465,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/664,1,['reduce'],['reduce']
Energy Efficiency,"When performing an action on an RDD, things will be fast and efficient if the output of each task fits in the available memory, and poky slow if we start spilling to disk. I could easily set the number of partitions on my input RDD to make sure that the output would fit in available memory, if only I knew how much memory was available. That's what I want to know, and why.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1456#issuecomment-177210646:61,efficient,efficient,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1456#issuecomment-177210646,1,['efficient'],['efficient']
Energy Efficiency,"When run with the current master build against our snapshot HG00514 sample, the experimental variant interpretation pipeline fails with the following exception:. ```; 18/04/11 20:27:50 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 32.0 in stage 42.0 (TID 56552, cwhelan-hg00514-1-cram-samtools-bam-feature-w-4.c.broad-dsde-methods.internal, executor 28): org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter$UnhandledCaseSeen: 1st segment is not overlapping with head alignment but it is not immediately before/after the head alignment either; AssemblyContigWithFineTunedAlignments{sourceTig=(asm022672:tig00004, [1_1430_chr9:130955309-130956738_-_1430M2216S_60_-1_-1_S, 1587_1763_chr9:130955156-130955308_-_1586S54M24I99M1883S_60_-1_-1_S, 1824_2015_chr9:130954964-130955155_-_1823S192M1631S_60_-1_-1_S, 2164_3646_chr9:130953867-130955307_-_2163H167M42I1274M_60_55_1318_O]), insertionMappings=[1963_2177_chr9:130955093-130955304_-_1962H179M3I33M1469H_19_14_138_O], hasEquallyGoodAlnConfigurations=false, saTAGForGoodMappingToNonCanonicalChromosome='NONE'}; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantCanonicalRepresentation.extractAltHaplotypeSeq(CpxVariantCanonicalRepresentation.java:338); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantCanonicalRepresentation.<init>(CpxVariantCanonicalRepresentation.java:143); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.lambda$inferCpxVariant$b3be3b47$1(CpxVariantInterpreter.java:53); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4649:207,schedul,scheduler,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4649,1,['schedul'],['scheduler']
Energy Efficiency,"When running StructuralVariationDiscoveryPipelineSpark (GATK 4.0.1.1) on a hadoop cluster, the following exception occurs. The pipeline has been running fine on other cram files. **Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0**. Below is the stack and other details. . The pipeline looks like it is running through all the contigs and is not limited to chr1-chr22, ChrY, ChrX and ChrM. Would it help running the software if the extra 3000+ contig names in the GRCh38 reference are excluded? If so, what is the best way to exclude processing the extra contigs?. ```; 18/02/23 23:06:22 INFO scheduler.TaskSetManager: Finished task 24.0 in stage 15.0 (TID 29435) in 2906 ms on scc-q04.scc.bu.edu (executor 1) (48/70); 18/02/23 23:06:23 INFO scheduler.TaskSetManager: Finished task 52.0 in stage 15.0 (TID 29463) in 2354 ms on scc-q04.scc.bu.edu (executor 1) (49/70); 18/02/23 23:06:23 INFO scheduler.TaskSetManager: Finished task 37.0 in stage 15.0 (TID 29448) in 2653 ms on scc-q03.scc.bu.edu (executor 6) (50/70); 18/02/23 23:06:23 WARN scheduler.TaskSetManager: Lost task 27.0 in stage 15.0 (TID 29438, scc-q13.scc.bu.edu, executor 7): org.broadinstitute.hellbender.exceptions.GATKException: Erred when inferring breakpoint location and event type from chimeric alignment:; asm010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); at java.util.stream.StreamSplitera",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:657,schedul,scheduler,657,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,3,['schedul'],['scheduler']
Energy Efficiency,"When running a large genome data set (`WGS-G94982-NA12878-no-NC_007605.bam`), the haplotypeCallerSpark raised an Null pointer exception in MannWhitney permutation test. Trace:. ```; 18/01/22 17:11:46 WARN scheduler.TaskSetManager: Lost task 161.0 in stage 26.0 (TID 110570, 192.168.100.210, executor 75): java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.MannWhitneyU.permutationTest(MannWhitneyU.java:537); at org.broadinstitute.hellbender.utils.MannWhitneyU.test(MannWhitneyU.java:409); at org.broadinstitute.hellbender.tools.walkers.annotator.RankSumTest.annotate(RankSumTest.java:75); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:266); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.makeAnnotatedCall(HaplotypeCallerGenotypingEngine.java:298); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:148); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:566); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:253); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark$$Lambda$312.00000000EC650830.apply(Unknown Source); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:278); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1823); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:305); at java.util.stream.StreamSpliterators$WrappingSpliterator$$Lambda$314.00000000EC651070.getAsBoolean(Unknown Source); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:217); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdv",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4265:205,schedul,scheduler,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4265,1,['schedul'],['scheduler']
Energy Efficiency,"When splitting up samples over regions to pass to HaplotypeCallerSpark, we ran into an edge case where it will die on regions not containing any reads, with a empty collection error. It would be great if we could catch this cleanly and generate a VCF without any calls. Here is a small self contained test case which demonstrates the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_hcspark_noreads.tar.gz. and the full error message:; ```; java.lang.UnsupportedOperationException: empty collection; at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$apply$35.apply(RDD.scala:1004); at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$apply$35.apply(RDD.scala:1004); at scala.Option.getOrElse(Option.scala:121); at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1004); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.reduce(RDD.scala:984); at org.apache.spark.api.java.JavaRDDLike$class.reduce(JavaRDDLike.scala:384); at org.apache.spark.api.java.AbstractJavaRDDLike.reduce(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.callVariantsWithHaplotypeCaller(HaplotypeCallerSpark.java:229); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.callVariantsWithHaplotypeCallerAndWriteOutput(HaplotypeCallerSpark.java:182); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.runTool(HaplotypeCallerSpark.java:143); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:387); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4234:551,reduce,reduce,551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4234,3,['reduce'],['reduce']
Energy Efficiency,"When the gvcf was merged by ""bcftools concat"", the following error will be happen. more info: ; https://gatkforums.broadinstitute.org/gatk/discussion/10817/gatk-runtime-error-on-genotypegvcfs-java-lang-double-cannot-be-cast-to-java-lang-integer. **java.lang.ClassCastException: java.lang.Double cannot be cast to java.lang.Integer**; 	at java.lang.Integer.compareTo(Integer.java:52); 	at java.util.Comparators$NaturalOrderComparator.compare(Comparators.java:52); 	at java.util.Comparators$NaturalOrderComparator.compare(Comparators.java:47); 	at java.util.TimSort.countRunAndMakeAscending(TimSort.java:351); 	at java.util.TimSort.sort(TimSort.java:216); 	at java.util.Arrays.sort(Arrays.java:1507); 	at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:302); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:513); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.utils.Utils.getMedianValue(Utils.java:1137); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:277); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:101); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.endPreviousStates(CombineGVCFs.java:340); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.createIntermediateVariants(CombineGVCFs.java:189); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.apply(CombineGVCFs.java:134); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:73); 	at org.broadinstitute.hellben",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4633:953,Reduce,ReduceOps,953,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4633,3,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"Why are you running VariantRecalibrator on multiple files? In the current implementation the tool does read all the variants into memory, so merging the files somehow before would dramatically reduce the memory requirements.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6165#issuecomment-532795397:193,reduce,reduce,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6165#issuecomment-532795397,1,['reduce'],['reduce']
Energy Efficiency,"With the new GCS NIO reader, it may well be preferable to access large side inputs directly in GCS buckets rather than broadcasting them. This would reduce our memory usage dramatically relative to broadcast, and if the performance is the same or better it seems like the way to go.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2015:149,reduce,reduce,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2015,1,['reduce'],['reduce']
Energy Efficiency,"Works with local files, and a PR for cloud functionality (complete with passing test) is under review (it's PR #595). The one thing left to do is to adapt to the skeleton once that's merged in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/426#issuecomment-114635562:149,adapt,adapt,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/426#issuecomment-114635562,1,['adapt'],['adapt']
Energy Efficiency,"Yeah, I don't like these new interface methods -- they make `GATKRead` significantly worse. We should cache `isUnmapped`, etc. in the adapter to accomplish the same thing, as @lbergelson suggests. Not that hard, and we can just unconditionally invalidate the cached values (using `Boolean` fields set to null) whenever the read is mutated in any way in order to simplify the logic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235102282:134,adapt,adapter,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235102282,1,['adapt'],['adapter']
Energy Efficiency,"Yeah, the workaround was simply to add the library jar to the classpath and not try to compile them together. I created the issue to soon, Sorry. . As for the NIO library, it is for AWS S3. We are adapting this one https://github.com/Upplication/Amazon-S3-FileSystem-NIO2 to meet our needs. We didn't like the way it handles s3 endpoints because AWS EMR Spark clusters don't support s3 uri's with that particular syntax. Our version modifies it to support normal s3 uri's without endpoints, instead setting the endpoint with a configuration parameter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431:197,adapt,adapting,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431,1,['adapt'],['adapting']
Energy Efficiency,"Yes, Hadoop-BAM uses the NIO API to do file merging, whereas in GATK we were using the Hadoop APIs (and therefore the GCS<->HDFS adapter) to do it. It looks like there are a couple of things needed in GCS-NIO to use the NIO API for this.; 1. https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1450 so that we don't have to special-case `gs` URIs to remove everything except the scheme and host when looking up the filesystem (see https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L40); 2. https://github.com/GoogleCloudPlatform/google-cloud-java/issues/813 to support path matching (https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L90). There may be more, as I stopped there. The best way forward is probably to go back to the old code in GATK while the deficiencies in GCS-NIO are fixed and then released. The stacktrace I got for 1 was:. ```; java.lang.IllegalArgumentException: GCS FileSystem URIs mustn't have: port, userinfo, path, query, or fragment: gs://gatk-demo-tom/TEST/markdups.parts/_SUCCESS; 	at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:192); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:83); 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:336); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:54); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); ```. And for 2:. ```; java.lang.UnsupportedOperationException; 	at com.google.cloud.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265132050:129,adapt,adapter,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265132050,1,['adapt'],['adapter']
Energy Efficiency,"Yes, it's important to realize that GenomicsDB is implemented in C (not Java), and so the memory allocated for GenomicsDB is whatever is NOT allocated to Java (ie., whatever is left over after -Xmx). So -Xmx should never claim all of the memory on the machine, and should leave enough free memory for GenomicsDB to use.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8777#issuecomment-2059629285:97,allocate,allocated,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8777#issuecomment-2059629285,2,['allocate'],['allocated']
Energy Efficiency,"Yes, merging GenomicsDBs with different samples in the same region. I think it may be more efficient with parallel processing for large samples. Is it possible to add the function?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6629#issuecomment-637207084:91,efficient,efficient,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6629#issuecomment-637207084,1,['efficient'],['efficient']
Energy Efficiency,"Yes, that's true in general. The -nt / -ntc flags options were never very good in gatk3. They usually scaled very poorly with number of cores, and were the cause of a lot of complexity and bugs. We decided not to try to roll our own map reduce framework for gatk4, but use an existing much better one, ie spark. . We recommend multiprocess parallelism with an external job runner like [cromwell](https://github.com/broadinstitute/cromwell) if you want parallelism in tools that aren't ready in spark yet. This is more complicated to setup and run, but it results in much more efficient use of compute resources. There are few limited multithreaded options remaining in GATK4 outside of spark. One specific one is the option to use multiple threads with HaplotypeCaller's pairHmm. This is only available on linux systems and defaults to using 4 threads.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4448#issuecomment-368051007:237,reduce,reduce,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4448#issuecomment-368051007,2,"['efficient', 'reduce']","['efficient', 'reduce']"
Energy Efficiency,YnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zdi9jbHVzdGVyL1NWQ2x1c3RlckVuZ2luZS5qYXZh) | `93.269% <0.000%> (-1.002%)` | :arrow_down: |; | [...stitute/hellbender/tools/walkers/sv/SVCluster.java](https://codecov.io/gh/broadinstitute/gatk/pull/7858/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3N2L1NWQ2x1c3Rlci5qYXZh) | `89.773% <0.000%> (-0.881%)` | :arrow_down: |; | [...tools/walkers/sv/JointGermlineCNVSegmentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/7858/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3N2L0pvaW50R2VybWxpbmVDTlZTZWdtZW50YXRpb24uamF2YQ==) | `86.047% <0.000%> (-0.752%)` | :arrow_down: |; | [...der/tools/walkers/sv/SVClusterIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7858/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3N2L1NWQ2x1c3RlckludGVncmF0aW9uVGVzdC5qYXZh) | `99.496% <0.000%> (-0.004%)` | :arrow_down: |; | [...rs/haplotypecaller/graphs/AdaptiveChainPruner.java](https://codecov.io/gh/broadinstitute/gatk/pull/7858/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQWRhcHRpdmVDaGFpblBydW5lci5qYXZh) | `97.368% <0.000%> (+0.035%)` | :arrow_up: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/7858/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7858#issuecomment-1130438520:4985,Adapt,AdaptiveChainPruner,4985,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7858#issuecomment-1130438520,1,['Adapt'],['AdaptiveChainPruner']
Energy Efficiency,"You know, I think I will clean up all the entangled genotype allele count caching and iterating. . I have benchmarked pretty thoroughly and discovered that caching `GenotypeAlleleCounts` for the sake of iterating in sequence is totally pointless. The `GenotypeAlleleCounts::increase` method is already so efficient that it makes no difference. In fact, caching is slower than using `increase` when the allele count and ploidy yield more than a few hundred genotypes. Caching is a bit faster for the commonest cases of 2 or 3 alleles in a diploid genotype, but the savings is less than a tenth of a second over an entire WGS run.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1067967439:305,efficient,efficient,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1067967439,1,['efficient'],['efficient']
Energy Efficiency,"Your solution doesn't address your third listed drawback to the current; approach, though I'm not sure there's any way to do that that wouldn't; require a pretty dramatic change. It's not obvious to me why we wanted the given alleles in the graph; originally. Maybe the use case was variants from UG that we didn't; necessarily believe were aligned properly?. I don't have any objections, but I'd feel better if we had a better guess; at what the original method was trying to do. On Wed, Apr 3, 2019 at 9:56 PM David Benjamin <notifications@github.com>; wrote:. > In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them; > into the ref haplotype, then threading these constructed haplotypes into; > the assembly graph with a large edge weight. There are several drawbacks to; > this approach:; >; > - The strange edge weights interfere with the AdaptiveChainPruner.; > - The large edge weights may not be large enough to avoid pruning when; > depth is extremely high.; > - The alleles may be lost if assembly fails.; > - If the alleles actually exist but are in phase with another variant; > we end up putting an enormous amount of weight on a false haplotype.; >; > We can get around these issue with the following method:; >; > - assemble haplotypes without regard to the force-called alleles.; > - if an allele is present in these haplotypes, do nothing further.; > - otherwise, add a haplotype in which the allele is injected into the; > reference haplotype.; >; > @LeeTL1220 <https://github.com/LeeTL1220> I prototyped this and it seems; > to resolve the missed forced alleles that Ziao found.; >; > @ldgauthier <https://github.com/ldgauthier> Can you think of any; > objections to making this change in HaplotypeCaller?; >; > â€”; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMcaTJg47gn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767:862,Adapt,AdaptiveChainPruner,862,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767,1,['Adapt'],['AdaptiveChainPruner']
Energy Efficiency,"[Broadcast data presentation.pdf](https://github.com/broadinstitute/gatk/files/369684/Broadcast.data.presentation.pdf). Here is a link to the presentation I gave on the broadcasting profiling data that I collected. The big takeaways are:; - Broadcasting is relatively time efficient and appears to scale linearly with filesize; - Reference broadcasting takes longer and is much more variable compared to the variants which get broadcast immediately before; - There doesn't seem to be any memory shared between executors for broadcast variables, making it very memory inefficient when there are many executors ; - The brodcast block size is best kept small, (in the order of 4-10MB) as it can explode the broadcast time to be very slow; - Having files in HDFS is significantly faster than using the GCS adapter for large file sizes",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1675#issuecomment-233396177:273,efficient,efficient,273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1675#issuecomment-233396177,2,"['adapt', 'efficient']","['adapter', 'efficient']"
Energy Efficiency,[Errno 12] Cannot allocate memory : GermlineCNVCaller,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053:18,allocate,allocate,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053,1,['allocate'],['allocate']
Energy Efficiency,"[Executor task launch worker-0,5,main]; java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 16/11/16 23:25:11 INFO SparkContext: Invoking stop() from shutdown hook; 16/11/16 23:25:11 WARN TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1, localhost): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apach",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:14289,schedul,scheduler,14289,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,\* Hangs head in shame *; I made a mistake in the buffer size computation in the Java side - over allocated .; Fixed now - consumes approximately the same amount of memory now,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-388221783:98,allocate,allocated,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-388221783,1,['allocate'],['allocated']
Energy Efficiency,"_2_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:44818 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157) (first 15 tasks are for partitions Vector(0)); 17/10/13 18:11:44 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks; 17/10/13 18:11:45 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1); 17/10/13 18:11:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.131.101.145:54024) with ID 1; 17/10/13 18:11:48 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1); 17/10/13 18:11:48 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 4877 bytes); 17/10/13 18:11:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:45501 with 366.3 MB RAM, BlockManagerId(1, com2, 45501, None); 17/10/13 18:11:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:45501 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:51 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:45501 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4638 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.668 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: looking for new",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:18347,schedul,scheduler,18347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['schedul'],['scheduler']
Energy Efficiency,"_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.029108712999999998,Cpu time(s),0.029110260000000002; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.0073808319999999995,Cpu time(s),0.007382536; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.029078561,Cpu time(s),0.029079955999999997; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.006109087,Cpu time(s),0.006077208000000001; 13:25:54.636 INFO ProgressMeter - 20:7039750 25.4 1000 39.3; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.3064205629999998,Cpu time(s),0.30639567500000026; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.016820958,Cpu time(s),0.016806184. ```. So you'll see it's progressing, but ~38 variants/min if I read this right. A few other things to note:. - FWIW, this is using a GATK JAR I built locally using #7962, which has some minor changes to side-step a bug in GenotypeGVCFs. Those changes only touch two annotation classes. - GenomicsDB 1.4.4 mentions memory improvements - any reason to think trying that would make a difference?. - One other thing to mention is that the MMul10 genome has ~2900 contigs. I dont understand precisely why this is a problem for GenomicsDB, but that has come up. Since we're only working on one contig (and usually a fraction of a contig) per job, could I subset my workspace to coax GenomicsDB to think it only has one contig? I believe I could just copy the contig folder and touch up the metadata JSON? I realize this isnt a great solution, but we're completely blocked here in terms of genotyping our data. - If SelectVariants actually worked here, could I run SelectVariants on the GenomicsDB workspace to create a combined gVCF for my ~2m site interval, and then run GenotypeGVCFs against this subset? It's not especially efficient, but if SelectVariants can pass and produce an output that's valid for GenotypeGVCFs that would actually be quite useful.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1209854842:4739,efficient,efficient,4739,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1209854842,1,['efficient'],['efficient']
Energy Efficiency,"`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2416 +/- ##; ===============================================; - Coverage 76.224% 76.218% -0.006% ; + Complexity 10820 10819 -1 ; ===============================================; Files 750 750 ; Lines 39422 39420 -2 ; Branches 6883 6883 ; ===============================================; - Hits 30049 30045 -4 ; - Misses 6755 6757 +2 ; Partials 2618 2618; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2416?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...alkers/genotyper/afcalc/CustomAFPriorProvider.java](https://codecov.io/gh/broadinstitute/gatk/compare/75f633135798145079ddb32c7dc2e884d47de4b3...3f2a04aa9723a86271120755e6be8945ff103532?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQ3VzdG9tQUZQcmlvclByb3ZpZGVyLmphdmE=) | `94.444% <Ã¸> (-0.556%)` | `6 <Ã¸> (-1)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/75f633135798145079ddb32c7dc2e884d47de4b3...3f2a04aa9723a86271120755e6be8945ff103532?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `66.667% <Ã¸> (-3.333%)` | `10% <Ã¸> (Ã¸)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2416?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2416?src=pr&el=footer). Last update [75f6331...3f2a04a](https://codecov.io/gh/broadinstitute/gatk/compare/75f633135798145079ddb32c7dc2e884d47de4b3...3f2a04aa9723a86271120755e6be8945ff103532?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2416#issuecomment-281483092:1962,Power,Powered,1962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2416#issuecomment-281483092,1,['Power'],['Powered']
Energy Efficiency,"`AFCalculator` has a couple of methods that don't belong: `reduceScope()`, which is called _before_ the AF calculation to reduce its computational burden, and `subsetAlleles()`, which is called _after_ the calculation to eliminate alleles that don't exist in called genotypes (in conformance with the dubious VCF spec). These methods are chronologically distinct from the rest of `AFCalculator` and do not appear to use any private variables. Thus they could easily be turned into static methods and removed from `AFCalculator`. Furthermore, `reduceScope()` and `subsetAlleles()` each have two implementations, in `DiploidExactAFCalculator` and `GeneralPloidyExactAFCalculator`. Since these two cases are complementary, they could easily be merged in a single method with an `if (ploidy == 2) . . .`. Finally, the general ploidy code is more complicated than it needs to be and needs editing. Beyond general housekeeping, the main motivation here is to untangle the AF/qual code as much as possible _without_ changing behavior before introducing the new model into the mix (issue #1697).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1891:59,reduce,reduceScope,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1891,3,['reduce'],"['reduce', 'reduceScope']"
Energy Efficiency,"`GatherVcfsIntegrationTest.testBlockGather()` is currently disabled in master, since when running on travis with it enabled the JVM appears to run out of memory, resulting in errors like the following:. ```; OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x00007f5293240000, 65536, 1) failed; error='Cannot allocate memory' (errno=12). #; # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 65536 bytes for committing reserved memory.; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid11418.log. [error occurred during error reporting , id 0xb]; ```. ```; :test[M::bwa_idx_load_from_disk] read 0 ALT contigs; OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000715180000, 719847424, 0) failed; error='Cannot allocate memory' (errno=12). #; # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 719847424 bytes for committing reserved memory.; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid11513.log; ```. This often manifests as a generic ""exited with code 137"" error, which appears to mean ""JVM killed with signal 9"":. ```; [31mFAILURE: [39m[31mBuild failed with an exception.[39m; * What went wrong:; Execution failed for task ':test'.; [33m> [39mProcess 'Gradle Test Executor 1' finished with non-zero exit value 137; ```. See https://travis-ci.org/broadinstitute/gatk/builds/248893875 for an example failed travis build. We should either modify the test to use less memory, or make more memory available to it on travis. I've tried increasing `maxHeapSize` for the test suite in `build.gradle` from `4G` to `6G`, but this did not help (see https://travis-ci.org/broadinstitute/gatk/builds/249355697)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3208:318,allocate,allocate,318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3208,2,['allocate'],['allocate']
Energy Efficiency,"`VariantsSparkSink` will always sort variants before writing them out. However, `HaplotypeCallerSpark` always processes reads in coordinate-sorted order, and produces variants in the same order, so there is no need for `VariantsSparkSink` to sort variants. (In fact, in GVCF mode the sort is prohibitive since the engine creates a variant for every locus over the interval of interest, which go through the sort step before being merged into GVCF bands.). This PR removes the sort step for `HaplotypeCallerSpark` (and `PrintVariantsSpark`, which doesn't need it either). All of the concordance unit tests pass, and as an additional sanity check I compared the GVCF output from running regular `HaplotypeCaller` on a large input BAM to `HaplotypeCallerSpark` (with and without variant sorting). Removing variant sorting actually made the GVCF output more similar to regular `HaplotypeCaller` - it reduced the number of differences from three to one. (The one difference is a minor difference in QUAL due to a boundary artifact.) See VCFs in [vcfs.zip](https://github.com/broadinstitute/gatk/files/3134046/vcfs.zip).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5909:896,reduce,reduced,896,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5909,1,['reduce'],['reduced']
Energy Efficiency,"```; [Stage 21:> (0 + 60) / 3539]18/12/21 16:08:27 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 46.0 in stage 21.0 (TID 2398, readpipeline-w-2.c.broad-gatk-test.internal, executor 12): java.io.IOException: com.esotericsoftware.kryo.KryoException: java.lang.UnsupportedOperationException; Serialization trace:; requestOptions (com.google.cloud.storage.BlobReadChannel); channel (com.google.cloud.storage.contrib.nio.CloudStorageReadChannel); channel (htsjdk.samtools.reference.IndexedFastaSequenceFile); rsFile (htsjdk.samtools.cram.ref.ReferenceSource); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.disq_bio.disq.impl.formats.sam.AnySamSinkMultiple.lambda$save$bddeb71b$1(AnySamSinkMultiple.java:91); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545:73,schedul,scheduler,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545,1,['schedul'],['scheduler']
Energy Efficiency,"a"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": ""b9fadac2-4e94-424f-a397-004684d1e51e"",; ""eval_cromwell_job_id"": ""acc9e2ac-b10a-4d6a-b586-cd3e47f04e41"",; ""created_at"": ""2023-05-16T17:15:43.799702"",; ""created_by"": null,; ""finished_at"": ""2023-05-17T02:34:53.616"",; ""results"": {; ""CHM controlHCprocesshours"": ""84.8981027777778"",; ""CHM controlHCsystemhours"": ""0.19177500000000003"",; ""CHM controlHCwallclockhours"": ""60.16600277777776"",; ""CHM controlHCwallclockmax"": ""3.0439777777777777"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-CHMSampleHeadToHead/BenchmarkComparison/1731c546-7466-4adf-9790-3f99d07df05b/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-CHMSampleHeadToHead/BenchmarkComparison/1731c546-7466-4adf-9790-3f99d07df05b/call-BenchmarkVCFControlSample/Benchmark/669edf6c-76a1-4d82-8cf7-5cd104df2496/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""83.2423166666667"",; ""CHM evalHCsystemhours"": ""0.18843333333333337"",; ""CHM evalHCwallclockhours"": ""61.06540555555557"",; ""CHM evalHCwallclockmax"": ""3.1854916666666666"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550601099:17351,monitor,monitoring,17351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550601099,1,['monitor'],['monitoring']
Energy Efficiency,"a-source gnomad --lenient true; ; ; ; ; . However, the command fails with the error message below:. ; ; ; ; [October 14, 2021 at 12:20:24 PM CEST] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 16.57 minutes. ; Runtime.totalMemory()=1134559232 ; java.lang.IllegalStateException: Duplicate key Gencode\_34\_annotationTranscript (attempted merging values ENST00000450305.2 and ENST00000456328.2) ; at java.base/java.util.stream.Collectors.duplicateKeyException(Collectors.java:133) ; at java.base/java.util.stream.Collectors.lambda$uniqKeysMapAccumulator$1(Collectors.java:180) ; at java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; at java.base/java.util.HashMap$KeySpliterator.forEachRemaining(HashMap.java:1603) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.AlleleFrequencyUtils.lambda$buildMaxMafRule$1(AlleleFrequencyUtils.java:30) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.lambda$checkFilter$0(FuncotationFilter.java:48) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.eva",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:2666,Reduce,ReduceOps,2666,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 1.2 in stage 0.0 (TID 6, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 INFO TaskSetManager:54 - Lost task 3.1 in stage 0.0 (TID 4) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 1]; 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 7, scc-q12.scc.bu.edu, executor 2, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 WARN TaskSetManager:66 - Lost task 9.0 in stage 0.0 (TID 5",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:28791,schedul,scheduler,28791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['schedul'],['scheduler']
Energy Efficiency,"a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:50 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 4, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:50 WARN TaskSetManager:66 - Lost task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.col",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:25889,schedul,scheduler,25889,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['schedul'],['scheduler']
Energy Efficiency,a7258df116ba2a3af7df191ebc8a?src=pr&el=desc) will **decrease** coverage by `<.001%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5062 +/- ##; ==============================================; - Coverage 86.35% 86.349% -<.001% ; - Complexity 28824 28826 +2 ; ==============================================; Files 1791 1791 ; Lines 133601 133619 +18 ; Branches 14920 14920 ; ==============================================; + Hits 115364 115379 +15 ; - Misses 12834 12837 +3 ; Partials 5403 5403; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5062?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...bender/utils/GATKProtectedVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5062/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HQVRLUHJvdGVjdGVkVmFyaWFudENvbnRleHRVdGlscy5qYXZh) | `65.746% <Ã¸> (Ã¸)` | `61 <0> (Ã¸)` | :arrow_down: |; | [...ion/basicshortmutpileup/PowerCalculationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5062/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9Qb3dlckNhbGN1bGF0aW9uVXRpbHMuamF2YQ==) | `96.667% <100%> (+1.429%)` | `18 <7> (+3)` | :arrow_up: |; | [...tmutpileup/BasicSomaticShortMutationValidator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5062/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9CYXNpY1NvbWF0aWNTaG9ydE11dGF0aW9uVmFsaWRhdG9yLmphdmE=) | `62.5% <100%> (+1.974%)` | `5 <0> (Ã¸)` | :arrow_down: |; | [...ion/basicshortmutpileup/BasicValidationResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/5062/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9CYXNpY1ZhbGlkYXRpb25SZXN1bHQuamF2YQ==) | `96.774% <10,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5062#issuecomment-408490831:1248,Power,PowerCalculationUtils,1248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5062#issuecomment-408490831,1,['Power'],['PowerCalculationUtils']
Energy Efficiency,"a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :white_check_mark: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.694% <0%> (+2.083%)` | `36% <0%> (Ã¸)` | :x: |; | [...oadinstitute/hellbender/utils/GenomeLocParser.java](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2NQYXJzZXIuamF2YQ==) | `90.083% <0%> (+4.132%)` | `57% <0%> (+2%)` | :white_check_mark: |; | [...ellbender/utils/test/CommandLineProgramTester.java](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0NvbW1hbmRMaW5lUHJvZ3JhbVRlc3Rlci5qYXZh) | `90.476% <0%> (+4.762%)` | `8% <0%> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2423?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2423?src=pr&el=footer). Last update [5211285...cab0d17](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282342687:3101,Power,Powered,3101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282342687,1,['Power'],['Powered']
Energy Efficiency,a:1423); > 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); > 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); > 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1423); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); > 	at scala.Option.foreach(Option.scala:257); > 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1651); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1606); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1595); > 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); > 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); > 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); > 	at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); > 	at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); > 	at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:38); > 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:362); > 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); > 	at org.broadinstitute.hellbender.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936:1847,schedul,scheduler,1847,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936,1,['schedul'],['scheduler']
Energy Efficiency,a:148); 	at org.apache.commons.math3.optim.univariate.BrentOptimizer.doOptimize(BrentOptimizer.java:225); 	at org.apache.commons.math3.optim.univariate.BrentOptimizer.doOptimize(BrentOptimizer.java:43); 	at org.apache.commons.math3.optim.BaseOptimizer.optimize(BaseOptimizer.java:153); 	at org.apache.commons.math3.optim.univariate.UnivariateOptimizer.optimize(UnivariateOptimizer.java:70); 	at org.broadinstitute.hellbender.utils.OptimizationUtils.max(OptimizationUtils.java:40); 	at org.broadinstitute.hellbender.tools.walkers.contamination.ContaminationModel.lambda$calculateContamination$13(ContaminationModel.java:214); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.contamination.ContaminationModel.calculateContamination(ContaminationModel.java:215); 	at org.broadinstitute.hellbender.tools.walkers.contamination.ContaminationModel.<init>(ContaminationModel.java:67); 	at org.broadinstitute.hellbender.tools.walkers.contamination.CalculateContamination.doWork(CalculateContamination.java:127); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(M,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6282:1607,Reduce,ReduceOps,1607,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6282,1,['Reduce'],['ReduceOps']
Energy Efficiency,a:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:213); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866); at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670); at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149:4051,schedul,scheduler,4051,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149,2,['schedul'],['scheduler']
Energy Efficiency,"a:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1144,schedul,scheduler,1144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['schedul'],['scheduler']
Energy Efficiency,aSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:978) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:805) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:789) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:474) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:475) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:530) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172) ; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651:4199,Reduce,ReduceOps,4199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651,1,['Reduce'],['ReduceOps']
Energy Efficiency,"ab"" as of scales 0.3.0. This parameter is used repeatedly in the generated R-script via. ```R; scale_fill_gradient(high=""green"", low=""red"", space=""rgb""); ```. #### Steps to reproduce. ```shell; $ R --version; R version 4.1.2 (2021-11-01) -- ""Bird Hippie""; $ rm -rf ~/R; $ R; > install.packages(""ggplot2"", repos=""https://cloud.r-project.org/""); > packageVersion(""scales""); [1] â€˜1.3.0â€™; > quit(); $ gatk --version; The Genome Analysis Toolkit (GATK) v4.5.0.0; HTSJDK Version: 4.1.0; Picard Version: 3.1.1; $ gatk VariantRecalibrator [arguments omitted for brevity]; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.9339186078473502558';source('/path/to/rscript.r');; Stdout: ; Stderr: Error:; ! The `space` argument of `pal_gradient_n()` only supports be ""Lab"" as; of scales 0.3.0.; Backtrace:; â–†; 1. â”œâ”€base::source(""/path/to/rscript.r""); 2. â”‚ â”œâ”€base::withVisible(eval(ei, envir)); 3. â”‚ â””â”€base::eval(ei, envir); 4. â”‚ â””â”€base::eval(ei, envir); 5. â””â”€ggplot2::scale_fill_gradient(high = ""green"", low = ""red"", space = ""rgb""); 6. â”œâ”€ggplot2::continuous_scale(...); 7. â”‚ â””â”€ggplot2::ggproto(...); 8. â”‚ â””â”€rlang::list2(...); 9. â””â”€scales::seq_gradient_pal(low, high, space); 10. â””â”€scales::pal_gradient_n(c(low, high), space = space); 11. â””â”€lifecycle::deprecate_stop(""0.3.0"", ""pal_gradient_n(space = 'only supports be \""Lab\""')""); 12. â””â”€lifecycle:::deprecate_stop0(msg); 13. â””â”€rlang::cnd_signal(...); Execution halted; $ R; > install.packages(""remotes"", repos=""https://cloud.r-project.org/""); > library(remotes); > install_version(""scales"", version=""1.2.1"", repos=""https://cloud.r-project.org/""); > packageVersion(""scales""); [1] â€˜1.2.1â€™; > quit(); $ gatk VariantRecalibrator [arguments omitted for brevity]; $; ```. #### Expected behavior; The output rscript file is used to generate a PDF. #### Actual behavior; Generation of the PDF fails due to an deprecation in the `scales` library causing the `Rscript` command to abort.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664:1549,green,green,1549,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664,1,['green'],['green']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.collect(RDD.scala:934); at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:152); at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:62); at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:61); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.sc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:2366,schedul,scheduler,2366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.collect(RDD.scala:934); at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361); at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.discoverVariantsFromChimeras(DiscoverVariantsFromContigAlignmentsSAMSpark.java:183),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:9104,schedul,scheduler,9104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD.count(RDD.scala:1157); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:80); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:470); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceM,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:15643,schedul,scheduler,15643,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1925); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1938); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1951); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1965); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.collect(RDD.scala:935); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:748); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:747); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:7285,schedul,scheduler,7285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.collect(RDD.scala:911); at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:360); at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.writeVariants(HaplotypeCallerSpark.java:205); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.runTool(HaplotypeCal,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:14924,schedul,scheduler,14924,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,2,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.collect(RDD.scala:911); at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:360); at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.<init>(ReadMetadata.java:59); at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.g,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:3203,schedul,scheduler,3203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,1,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.collect(RDD.scala:911); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:372); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:372); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3679:5590,schedul,scheduler,5590,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679,1,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1936); at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1002); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.reduce(RDD.scala:984); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1127); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1104); at org.apache.spark.api.java.JavaRDDLike$class.treeAggregate(JavaRDDLike.scala:438); at org.apache.spark.api.java.AbstractJ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515:4505,schedul,scheduler,4505,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515,1,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); at org.apache.spark.rdd.RDD.count(RDD.scala:1158); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark.runTool(PathSeqPipelineSpark.java:245); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:387); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:41804,schedul,scheduler,41804,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); at org.apache.spark.rdd.RDD.count(RDD.scala:1158); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark.runTool(PathSeqPipelineSpark.java:245); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:387); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:42550,schedul,scheduler,42550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1354); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.take(RDD.scala:1327); at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1368); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.first(RDD.scala:1367); at org.apache.spark.api.java.JavaRDDLike$class.first(JavaRDDLike.scala:538);,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:20084,schedul,scheduler,20084,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); at org.apache.spark.rdd.RDD.collect(RDD.scala:938); at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361); at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.getQNames(FindBreakpointEvidenceSpark.java:963); at org.broadinstitute.hellbender.tools.spark.sv.evid,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:51021,schedul,scheduler,51021,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:80); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:470); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceM,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:39608,schedul,scheduler,39608,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1878); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1083); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1081); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1081); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:385); at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopDataset(PairRDDFunctions.scala:1081); ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:17750,schedul,scheduler,17750,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,"ac327-c59c-43f7-a850-21bc3e0ccf52/call-CHMSampleHeadToHead/BenchmarkComparison/cd28fe49-1672-4321-a836-47f76419c1c8/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-CHMSampleHeadToHead/BenchmarkComparison/cd28fe49-1672-4321-a836-47f76419c1c8/call-BenchmarkVCFControlSample/Benchmark/d5df8455-36cf-4ecb-8dc2-ec35b974c0b7/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""78.23616944444446"",; ""CHM evalHCsystemhours"": ""0.16188333333333332"",; ""CHM evalHCwallclockhours"": ""55.167422222222214"",; ""CHM evalHCwallclockmax"": ""2.887522222222222"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-CHMSampleHeadToHead/BenchmarkComparison/cd28fe49-1672-4321-a836-47f76419c1c8/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-CHMSampleHeadToHead/BenchmarkComparison/cd28fe49-1672-4321-a836-47f76419c1c8/call-BenchmarkVCFTestSample/Benchmark/83a51739-dd4e-4f2d-b09a-3c78b132fbf1/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1182703672:17682,monitor,monitoring,17682,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1182703672,1,['monitor'],['monitoring']
Energy Efficiency,acencyReferenceLocations.java:46); ... 18 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.collect(RDD.sc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:8749,schedul,scheduler,8749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['schedul'],['scheduler']
Energy Efficiency,ache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 05:09:10.813 ERROR Executor:91 - Exception in task 16.0 in stage 1.0 (TID 353); org.apache.spark.SparkException: Error communicating with MapOutputTracker; at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:104); at org.apache.spark.MapOutputTracker.getStatuses(MapOutputTracker.scala:202); at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:142); at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49); at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:109); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:3749,schedul,scheduler,3749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['schedul'],['scheduler']
Energy Efficiency,"ache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:100); ... 24 more; 05:12:04.045 INFO HaplotypeCallerSpark - Shutting down engine; [May 18, 2017 5:12:04 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 131.63 minutes.; Runtime.totalMemory()=16201547776; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 1.0 failed 1 times, most recent failure: Lost task 8.0 in stage 1.0 (TID 345, localhost): java.lang.ArrayI; ndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esot",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:5633,schedul,scheduler,5633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['schedul'],['scheduler']
Energy Efficiency,"action model to allow for the modeling of hom sites. I wrote up such a model in some notes I sent around a few months back. This model allows for an allelic PoN that uses all sites to learn reference bias, not just hets. Depending on how our python development proceeds, I may try to implement this model using the old `GibbsSampler` code instead.; - [x] In the meantime, we can try to speed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed the mode and highest density credible interval (because of the below item).; - [x] Some residual bias remains in the estimate of the minor-allele fraction posterior mode. This is simply because we are performing kernel density estimation of a bounded quantity. One possibility would be to logit transform to an unbounded support, perform the estimation, then transform back. EDIT: Just removed kernel density estimation for now, partly due to #3599 as well.; - Hmm, actually still a tiny bit of residual bias. This is apparent e.g. in WGS normals. I think focusing on a new allele-fraction model rather than trying to figure out where the old one is failing would be best.; - [x] For small bins (250bp), the copy-ratio model is currently a bit memory intensive, since it stores an outlier indicator boolean for every data point",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:6221,reduce,reduced,6221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['reduce'],['reduced']
Energy Efficiency,"adcast at ReadsSparkSink.java:195; 17/10/11 14:19:18 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.2 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:34044 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:11422,schedul,scheduler,11422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"adcast_1_piece0 in memory on 10.131.101.159:44818 (size: 2.1 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/13 18:11:44 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/13 18:11:44 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/13 18:11:44 INFO spark.SparkContext: Starting job: runJob at SparkHadoopMapReduceWriter.scala:88; 17/10/13 18:11:44 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Got job 0 (runJob at SparkHadoopMapReduceWriter.scala:88) with 1 output partitions; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.9 KB, free 366.0 MB); 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:44818 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:15",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:16789,schedul,scheduler,16789,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['schedul'],['scheduler']
Energy Efficiency,adding support for jBWA on power,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2078:27,power,power,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2078,1,['power'],['power']
Energy Efficiency,adinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:9012,schedul,scheduler,9012,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['schedul'],['scheduler']
Energy Efficiency,"agStatus;"" the class loader (instance of org/apache/spark/util/ChildFirstURLClassLoader) of the current class, org/broadinstitute/hellbender/tools/spark/pipelines/FlagStatSpark, and the class loader (instance of org/apache/spark/util/ChildFirstURLClassLoader) for the method's defining class, org/broadinstitute/hellbender/tools/FlagStat$FlagStatus, have different Class objects for the type org/broadinstitute/hellbender/utils/read/GATKRead used in the signature; at java.lang.invoke.MethodHandleNatives.resolve(Native Method); at java.lang.invoke.MemberName$Factory.resolve(MemberName.java:965); at java.lang.invoke.MemberName$Factory.resolveOrFail(MemberName.java:990); at java.lang.invoke.MethodHandles$Lookup.resolveOrFail(MethodHandles.java:1387); at java.lang.invoke.MethodHandles$Lookup.linkMethodHandleConstant(MethodHandles.java:1739); at java.lang.invoke.MethodHandleNatives.linkMethodHandleConstant(MethodHandleNatives.java:442); ... 41 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1273); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1264); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1263); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1263); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730); at scala.Option.foreach(Option.scala:236); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:730); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1457); at org.apache.spark.sch",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1315:5067,schedul,scheduler,5067,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1315,1,['schedul'],['scheduler']
Energy Efficiency,age(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2281); at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83); ... 27 more; Caused by: java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; at java.base/jdk.internal.util.ArraysSupport.hugeLength(ArraysSupport.java:649); at java.base/jdk.internal.util.ArraysSupport.newLength(ArraysSupport.java:642); at java.base/java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:100); at java.base/java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:130); at org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41); at java.base/java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1862); at java.base/java.io.ObjectOutputStream.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:32992,schedul,scheduler,32992,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,ala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:31642,schedul,scheduler,31642,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"ala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); 18/10/17 19:23:59 WARN TaskSetManager: Lost task 517.0 in stage 0.0 (TID 517, localhost, executor driver): org.broadinstitute.hellbender.exceptions.UserException$NoSuitableCodecs: Cannot read /dev/shm/gatktmp/spark-30e238e4-b1b7-41f9-b31e-844f16879051/userFiles-4621c82d-5f86-4b51-9321-ccc84ab49979/dbsnp_138.hg19.vcf because no suitable codecs found; 	at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:462); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:320); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:300); 	at org.broadi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:7769,schedul,scheduler,7769,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,1,['schedul'],['scheduler']
Energy Efficiency,ala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:8404,schedul,scheduler,8404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,ala:800); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); 18/10/17 19:23:59 ERROR Executor: Exception in task 518.0 in stage 0.0 (TID 518); java.io.FileNotFoundException: /home/data/WGS/F002/F002.sort.bam (Too many open files); 	at java.io.FileInputStream.open0(Native Method); 	at java.io.FileInputStream.open(FileInputStream.java:195); 	at java.io.FileInputStream.<init>(FileInputStream.java:138); 	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.<init>(RawLocalFileSystem.java:106); 	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:202); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:349); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.seqdoo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:4425,schedul,scheduler,4425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,1,['schedul'],['scheduler']
Energy Efficiency,"alizing engine; 16:58:10.116 INFO PrintVariantsSpark - Done initializing engine; 19/02/18 16:58:10 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19/02/18 16:58:10 INFO org.spark_project.jetty.util.log: Logging initialized @8431ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: Started @8536ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 19/02/18 16:58:11 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 19/02/18 16:58:12 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:8032; 19/02/18 16:58:13 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:10200; 19/02/18 16:58:15 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1550508751046_0004; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; 19/02/18 16:58:25 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total in",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:4836,schedul,scheduler,4836,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,all.out.bam \; -- \; --sparkRunner SPARK --sparkMaster yarn-client \; --num-executors 5 --executor-cores 2 --executor-memory 4g \; --conf spark.yarn.executor.memoryOverhead=600; ```. blows up with . ```; java.lang.ClassCastException: org.apache.hadoop.fs.RawLocalFileSystem cannot be cast to org.apache.hadoop.fs.LocalFileSystem; at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:350); at org.apache.spark.deploy.yarn.Client$.org$apache$spark$deploy$yarn$Client$$getQualifiedLocalPath(Client.scala:1373); at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:329); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:422); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:635); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:124); at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:56); at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144); at org.apache.spark.SparkContext.<init>(SparkContext.scala:523); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); at org.broadinstitute.hellbender.Main.main(Main.java:81); at sun.reflect.N,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1389:1265,schedul,scheduler,1265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1389,1,['schedul'],['scheduler']
Energy Efficiency,"allclockmax"": ""3.8631972222222224"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-NISTSampleHeadToHead/BenchmarkComparison/243c7bf2-b0d7-48ed-acd0-e2ebd74b9fd3/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-NISTSampleHeadToHead/BenchmarkComparison/243c7bf2-b0d7-48ed-acd0-e2ebd74b9fd3/call-BenchmarkVCFControlSample/Benchmark/135b02c2-d7c5-4fd2-9cc5-cdeeed953bbc/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""103.49634722222224"",; ""NIST evalHCsystemhours"": ""0.20633611111111116"",; ""NIST evalHCwallclockhours"": ""75.91255833333332"",; ""NIST evalHCwallclockmax"": ""3.76305"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-NISTSampleHeadToHead/BenchmarkComparison/243c7bf2-b0d7-48ed-acd0-e2ebd74b9fd3/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-NISTSampleHeadToHead/BenchmarkComparison/243c7bf2-b0d7-48ed-acd0-e2ebd74b9fd3/call-BenchmarkVCFTestSample/Benchmark/ad8885d7-137d-4645-b37d-f54f8362713d/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1546478988:21356,monitor,monitoring,21356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1546478988,1,['monitor'],['monitoring']
Energy Efficiency,"allclockmax"": ""4.163775"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-NISTSampleHeadToHead/BenchmarkComparison/24ad1003-6862-4e29-9d4d-ea8e85bcc78b/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-NISTSampleHeadToHead/BenchmarkComparison/24ad1003-6862-4e29-9d4d-ea8e85bcc78b/call-BenchmarkVCFControlSample/Benchmark/7d69a7b4-2884-4b7e-9bce-fc2eab77b125/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""103.71990555555556"",; ""NIST evalHCsystemhours"": ""0.20632500000000004"",; ""NIST evalHCwallclockhours"": ""76.41897222222222"",; ""NIST evalHCwallclockmax"": ""4.163391666666667"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-NISTSampleHeadToHead/BenchmarkComparison/24ad1003-6862-4e29-9d4d-ea8e85bcc78b/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-NISTSampleHeadToHead/BenchmarkComparison/24ad1003-6862-4e29-9d4d-ea8e85bcc78b/call-BenchmarkVCFTestSample/Benchmark/aba51ebf-90d5-44fa-8caa-0beb3cf1643b/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574622123:21328,monitor,monitoring,21328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574622123,1,['monitor'],['monitoring']
Energy Efficiency,"alled with curMem=10409, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.5 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(7006) called with curMem=22233, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.8 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:65240 (size: 6.8 KB, free: 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerMaster: Updated info of block broadcast_1_piece0; 15/07/14 13:14:53 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:839; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MapPartitionsRDD[8] at mapToPair at TransformTranslator.java:405); 15/07/14 13:14:53 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 1 tasks; 15/07/14 13:14:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1296 bytes); 15/07/14 13:14:53 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1); 15/07/14 13:14:53 INFO storage.BlockManager: Removing broadcast 0; 15/07/14 13:14:53 INFO storage.BlockManager: Removing block broadcast_0; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_0 of size 6656 dropped from memory (free 277996857); 15/07/14 13:14:53 INFO storage.BlockManager: Removing block broadcast_0_piece0; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_0_piece0 of size 3753 dropped from memory (free 278000610); 15/07/14 13:14:53 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on localhost:65240 in memory (size: 3.7 KB, free: 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerMaster: Updated info of block broadcast_0_piece0; 15/07/14 13:14:53 INFO spark.ContextCleaner: Cleaned broadcast 0; 15/07/14 13:14:53 ERROR executor.Executor: Exception",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:27544,schedul,scheduler,27544,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['schedul'],['scheduler']
Energy Efficiency,"aller_7_of_8-calls/ --calls-shard-path /srv/scratch/testardqu/CNV_Hyperexome/GermlineCNVCaller/GermlineCNVCaller_8_of_8-calls/ --clustered-breakpoints /srv/scratch/testardqu/CNV_Hyperexome/CNV_Hyperexome.vcf.gz --input-intervals-vcf /srv/scratch/testardqu/CNV_Hyperexome/intervals/genotyped-intervals-SAMPLE_6.vcf.gz --allosomal-contig chrX --allosomal-contig chrY --autosomal-ref-copy-number 2 --contig-ploidy-calls /srv/scratch/testardqu/CNV_Hyperexome/DetermineGermlineContigPloidy/DetermineGermlineContigPloidy-calls/ --sample-index 6 --output-genotyped-intervals /srv/scratch/testardqu/CNV_Hyperexome/intervals_joint/genotyped-intervals-SAMPLE_6.vcf.gz --output-genotyped-segments /srv/scratch/testardqu/CNV_Hyperexome/segments_joint/genotyped-segments-SAMPLE_6.vcf.gz --output-denoised-copy-ratios /srv/scratch/testardqu/CNV_Hyperexome/ratios_joint/denoised-copy-ratios-SAMPLE_6.tsv --sequence-dictionary /srv/scratch/testardqu/CNV_Hyperexome/hg19_min_oldM.dict. Is this normal ? Is there a way to reduce the calculation time?. In addition, I noticed that an abnormal number of most likely artifactual CNVs were called on the sex chromosomes in the joined vcfs, no CNVs are operable there, while some CNVs were (supposedly) called correctly in the VCFs produced by the first iteration of PostProcessGermlineCNVCalls. Here are commands that were run on the VCF segments produced by the 2nd iteration (with --clustered-breakpoints) that show a large number of artifactual CNVs on the sex chromosomes in my data (for the autosomal chromosomes, everything looks normal) :. zgrep -v ""#"" *.gz | grep chrY | sort | uniq | cut -f 3 | sort -V | uniq -c; 540 CNV_chrY_7042509_7064541; 540 CNV_chrY_9357472_9360034; ...; 540 CNV_chrY_24795591_24796548; 540 CNV_chrY_24795591_24893824; zgrep -v ""#"" *.gz | grep chrY | sort | uniq | cut -f 3 | sort -V | uniq -c | wc -l; 27; zgrep -v ""#"" *.gz | grep chrY | sort | uniq | grep PASS | cut -f 3 | sort -V | uniq -c; 540 CNV_chrY_7042509_7064541; 288 CNV_chrY_93",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8183:14273,reduce,reduce,14273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8183,1,['reduce'],['reduce']
Energy Efficiency,am.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); at org.apache.spark.rdd.RDD.count(RDD.scala:1158); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tool,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:41361,schedul,scheduler,41361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,am.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); at org.apache.spark.rdd.RDD.count(RDD.scala:1158); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tool,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:42107,schedul,scheduler,42107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,am.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; at htsjdk.variant.variantcontext.CommonInfo.getAttributeAsList(CommonInfo.java:274) ; ; at htsjdk.variant.variantcontext.CommonInfo.getAttributeAsIntList(CommonInfo.java:282) ; ; at htsjdk.variant.variantcontext.VariantContext.getAttributeAsIntList(VariantContext.java:827) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.DuplicatedAltReadFilter.areAllelesArtifacts(DuplicatedAltReadFilter.java:26) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.HardAlleleFilter.calculateErrorProbabilityForAlleles(HardAlleleFilter.java:16) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2AlleleFilter.errorProbabilities(Mutect2AlleleFilter.java:86) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$0(ErrorProbabilities.java:27) ; ; at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321) ; ; at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:25) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:138) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:154) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(M,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:7695,Reduce,ReduceOps,7695,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['Reduce'],['ReduceOps']
Energy Efficiency,and non-NAN; 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:10720,Reduce,ReduceOps,10720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,1,['Reduce'],['ReduceOps']
Energy Efficiency,ang.IllegalArgumentException: Requested start 8613 is beyond the sequence length HLA-DRB1*04:03:01; at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490); at java.base/java.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:600); at java.base/java.util.concurrent.ForkJoinTask.reportException(ForkJoinTask.java:678); at java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:737); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateParallel(ReduceOps.java:919); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233); at java.base/java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:558); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.lambda$collectCaseStatsParallel$14(CalibrateDragstrModel.java:568); at java.base/java.util.concurrent.ForkJoinTask$AdaptedCallable.exec(ForkJoinTask.java:1448); at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290); at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020); at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656); at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594); at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183); Caused by: java.lang.IllegalArgumentException: Requested start 8613 is beyond the sequence length HLA-DRB1*04:03:01; at htsjdk.samtools.cram.ref.ReferenceSource.getReferenceBasesByRegion(ReferenceSource.java:207); at htsjdk.samtools.cram.build.CRAMReferenceRegion.fetchReferenceBasesByRegion(CRAMReferenceRegion.java:169); a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8139:8174,reduce,reduce,8174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8139,1,['reduce'],['reduce']
Energy Efficiency,"ang.RuntimeException: found the bad record: 1,801305857; at org.broadinstitute.hellbender.tools.spark.pipelines.Utils.key(KeyReadsSpark.java:43); at org.broadinstitute.hellbender.tools.spark.pipelines.KeyReadsSpark.lambda$runTool$72eaf22$1(KeyReadsSpark.java:28); at org.broadinstitute.hellbender.tools.spark.pipelines.KeyReadsSpark$$Lambda$11/1228804001.call(Unknown Source); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1002); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1002); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:219); at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41); at org.apache.spark.scheduler.Task.run(Task.scala:64); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```. This start offset is 2176858951 (142662628213169L>>>16) - i.e. around 2GB in. I've managed to reproduce with a local program now. This reveals the following problem:. ```; Caused by: java.lang.IllegalArgumentException: Unrecognized CigarOperator: 11; at htsjdk.samtools.CigarOperator.binaryToEnum(CigarOperator.java:143); at htsjdk.samtools.BinaryCigarCodec.binaryCigarToCigarElement(BinaryCigarCodec.java:87); at htsjdk.samtools.BinaryCigarCodec.decode(BinaryCigarCodec.java:63); at htsjdk.samtools.BAMRecord.getCigar(BAMRecord.java:243); at htsjdk.samtools.SAMRecord.getUnclippedStart(SAMRecord.java:482); at org.seqdoop.hadoop_bam.TestBAMInputFormat.getUnclippedStart(TestBAMInp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1098#issuecomment-156150350:1458,schedul,scheduler,1458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1098#issuecomment-156150350,1,['schedul'],['scheduler']
Energy Efficiency,"anies:; ![grafik](https://user-images.githubusercontent.com/1612006/35342524-94fcab50-0128-11e8-800e-840d891058ef.png). 1. How to convince people:; I agree. I think it is most effective to make people ""feel"" the difference, i.e. output like ""you have been waiting 1324s or 60% of additional processing time on this step due to compression"".; Or ""Processing still hasn't started due to compression/decompression."". GATK4, especially on Spark hides that pretty well.; For example, turning off Spark lz4 and relying on ZFS lz4 for the writing of temporary data was instructive about how much CPU was used for it (not that much). 2. Compression differences:; I might help to look at the used dictionary size for the differences and also the possible method of compression parallelization. Multi-core compression mostly cuts files into pieces and can greatly decrease compression if the data is highly repetitive. Because another core starts anew on data that the previous one might have reduced to almost nothing (zstd allows some sharing of the dictionary between cores, but most do not I think). Example about the dictionary difference: For long distance repetitive files, compression with; xz --lzma2=preset=1,dict=1500M can bringe a huge gain in compression, but still be much faster than level 9 (which has normally only a dictionary of 64MB). Compression levels are correlated with dict size for most compressors to ensure monotonically increasing memory usage, but that doesn't have to be so.; zstd, for example, allows many parameters to change this. Even more than xz. I suspect due to my experiments that quality values gain more from increased dictionary size, because they are more repetitive than the DNA data. And shorter BAMs would be different because they are less repetitive (usually less coverage), so their compression relies more on CPU-expensive crunching of the ""2bit nature"" of the DNA.; So they might logically suffer more from a lower compression level.; It might be instructive ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673:1109,reduce,reduced,1109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673,1,['reduce'],['reduced']
Energy Efficiency,anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38484,schedul,scheduler,38484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:15275,schedul,scheduler,15275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['schedul'],['scheduler']
Energy Efficiency,apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1661); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1649); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1648); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1648); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1882); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1820); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:4173,schedul,scheduler,4173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['schedul'],['scheduler']
Energy Efficiency,appers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-02-17 16:25:50 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-02-17 16:25:50 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-4adbc571-167b-4e5f-af72-d3df0d3601e6; 2019-02-17 16:25:50 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-cf45c696-2402-4d31-be67-f3063bec805a. real 5m25.740s; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:55960,schedul,scheduler,55960,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,2,['schedul'],['scheduler']
Energy Efficiency,apted(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.ru,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:14055,adapt,adapted,14055,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['adapt'],['adapted']
Energy Efficiency,"arch 9, 2018 9:22:08 AM UTC] org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark done. Elapsed time: 61.53 minutes.; Runtime.totalMemory()=16815489024; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 0.0 failed 1 times, most recent failure: Lost task 8.0 in stage 0.0 (TID 8, localhost): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 126542 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1936); at org.apache.spark.rdd.RDD$$anonfun$reduc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515:3729,schedul,scheduler,3729,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515,1,['schedul'],['scheduler']
Energy Efficiency,"ark-runner GCS --cluster cw-test --num-executors 20 --driver-memory 30G --executor-memory 30G --conf spark.yarn.executor.memoryOverhead=5000 --conf spark.network.timeout=600 --conf spark.executor.heartbeatInterval=120 --conf spark.driver.userClassPathFirst=false; ```. It failed near the end of the pipeline. Here is the tail of the log:. ```; 20:38:14.368 INFO StructuralVariationDiscoveryPipelineSpark - Used 3549 evidence target links to annotate assembled breakpoints; 20:38:14.462 INFO StructuralVariationDiscoveryPipelineSpark - Called 662 imprecise deletion variants; 20:38:14.492 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 7234 variants.; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - INV: 184; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4486; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1170; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1394; 18/01/12 20:38:16 WARN org.apache.spark.scheduler.TaskSetManager: Stage 17 contains a task of very large size (2518 KB). The maximum recommended task size is 100 KB.; 18/01/12 20:38:22 WARN org.apache.spark.scheduler.TaskSetManager: Stage 18 contains a task of very large size (2307 KB). The maximum recommended task size is 100 KB.; 20:38:27.207 INFO StructuralVariationDiscoveryPipelineSpark - Processing 501267 raw alignments from 426041 contigs.; 18/01/12 20:38:27 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2518 KB). The maximum recommended task size is 100 KB.; 20:38:35.835 INFO StructuralVariationDiscoveryPipelineSpark - Primitive filtering based purely on MQ left 339065 contigs.; 20:38:37.378 INFO StructuralVariationDiscoveryPipelineSpark - 17574 contigs with chimeric alignments potentially giving SV signals.; 18/01/12 20:38:37 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 284.0 in stage 25.0 (TID 43189, cw-test-w-6.c.broad-dsde-methods.internal, executor 7): java.la",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:2029,schedul,scheduler,2029,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,ark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:471); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:470); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:470); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:468); at scala.collection.immutable.List.foreach(List.scala:318); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:468); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:727); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:142); at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:57); at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144); at org.apache.spark.SparkContext.<init>(SparkContext.scala:530); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); at sun.reflect.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:2111,schedul,scheduler,2111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,2,['schedul'],['scheduler']
Energy Efficiency,ark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:18536,schedul,scheduler,18536,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,ark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:10760,schedul,scheduler,10760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,arkDuplicatesSpark --spark-master local[28] --conf spark.local.dir=/datatmp/ -I ./A.sort.bam -O ./A.sort.bam.Mdup.bam -M ./A.sort.bam.Md.metrics.txt --tmp-dir /datatmp/ --conf spark.network.timeout=200h --conf spark.executor.heartbeatInterval=100h --read-name-regex null`; It reports the error below.; `20/12/15 11:43:00 ERROR Executor: Exception in task 15.0 in stage 7.0 (TID 12538); java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$handleFragments$12(MarkDuplicatesSparkUtils.java:395); at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.shuffle.sort.Unsaf,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7001:1293,Reduce,ReduceOps,1293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,ase.initializeIterator(CRAMFileReader.java:500); 	at htsjdk.samtools.CRAMFileReader$CRAMIntervalIterator.<init>(CRAMFileReader.java:558); 	at htsjdk.samtools.CRAMFileReader$CRAMIntervalIterator.<init>(CRAMFileReader.java:553); 	at htsjdk.samtools.CRAMFileReader.query(CRAMFileReader.java:425); 	at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.query(SamReader.java:533); 	at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.queryOverlapping(SamReader.java:405); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextIterator(SamReaderQueryingIterator.java:130); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.<init>(SamReaderQueryingIterator.java:69); 	at org.broadinstitute.hellbender.engine.ReadsPathDataSource.prepareIteratorsForTraversal(ReadsPathDataSource.java:412); 	at org.broadinstitute.hellbender.engine.ReadsPathDataSource.prepareIteratorsForTraversal(ReadsPathDataSource.java:389); 	at org.broadinstitute.hellbender.engine.ReadsPathDataSource.query(ReadsPathDataSource.java:352); 	at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.readStream(CalibrateDragstrModel.java:835); 	at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.lambda$null$10(CalibrateDragstrModel.java:478); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:747); 	at java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:721); 	at java.util.stream.AbstractTask.compute(AbstractTask.java:327); 	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731); 	... 4 more; Using GATK jar /gatk/gatk-package-4.1.9.0-15-g8f07c46-SNAPSHOT-local.jar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7060:5929,Reduce,ReduceOps,5929,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7060,6,['Reduce'],"['ReduceOps', 'ReduceTask']"
Energy Efficiency,ask of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:19:46.133 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 573670 contigs.; 17:19:46.995 INFO StructuralVariationDiscoveryPipelineSpark - 23730 contigs with chimeric alignments potentially giving SV signals.; 17:19:47.546 INFO StructuralVariationDiscoveryPipelineSpark - 8559 contigs indicating InsDel; 18/01/25 17:19:47 WARN org.apache.spark.scheduler.TaskSetManager: Stage 29 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:00.012 INFO StructuralVariationDiscoveryPipelineSpark - 324 contigs indicating IntraChrStrandSwitch; 18/01/25 17:20:00 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:11.779 INFO StructuralVariationDiscoveryPipelineSpark - 3946 contigs indicating MappedInsertionBkpt; 18/01/25 17:20:11 WARN org.apache.spark.scheduler.TaskSetManager: Stage 37 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:23.416 INFO StructuralVariationDiscoveryPipelineSpark - 853 contigs indicating Cpx; 18/01/25 17:20:23 WARN org.apache.spark.scheduler.TaskSetManager: Stage 41 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:34.830 INFO StructuralVariationDiscoveryPipelineSpark - 1521 contigs indicating Incomplete; 18/01/25 17:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 45 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:44.949 INFO StructuralVariationDiscoveryPipelineSpark - 5277 contigs indicating Ambiguous; 18/01/25 17:20:45 WARN org.apache.spark.scheduler.TaskSetManager: Stage 49 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:55.516 INFO StructuralVariationDiscoveryPipelineSpark - 15 contigs indicating MisAssem,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260:2651,schedul,scheduler,2651,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260,1,['schedul'],['scheduler']
Energy Efficiency,ask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:8855,schedul,scheduler,8855,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,"asn't presented an issue in other tools (including vanilla BaseRecalibrator). Searching thru the forum, I found an old issue with a similar stacktrace, but that issue appears to occur in GATK 2.4: https://gatkforums.broadinstitute.org/gatk/discussion/3265/bqsrgatherer-exception. In the below stacktrace, I've bolded the error message that seems to occur in each of these samples. `Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1026); 	at org.apache.spark.rdd.RDDOperationScope",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:1834,schedul,scheduler,1834,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['schedul'],['scheduler']
Energy Efficiency,at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3679:4999,schedul,scheduler,4999,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679,1,['schedul'],['scheduler']
Energy Efficiency,at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:14333,schedul,scheduler,14333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,2,['schedul'],['scheduler']
Energy Efficiency,at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD.count(RDD.scala:1157); at org.apache.spark.api.java.JavaRDDLike$cla,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:15052,schedul,scheduler,15052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:298); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1925); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1938); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1951); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1965); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); at org.apache.spark.rdd.RD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:6694,schedul,scheduler,6694,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['schedul'],['scheduler']
Energy Efficiency,at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:309); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1354); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apac,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:19493,schedul,scheduler,19493,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['schedul'],['scheduler']
Energy Efficiency,at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:7931,schedul,scheduler,7931,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['schedul'],['scheduler']
Energy Efficiency,at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939); at org.apache.spark.rdd.RD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:50430,schedul,scheduler,50430,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$cla,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:39017,schedul,scheduler,39017,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,"at org.apache.spark.storage.BlockManager.reportAllBlocks(BlockManager.scala:217); at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:236); at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:522); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308); at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180); at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 18/03/09 09:22:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/09 09:22:08 INFO SparkContext: Successfully stopped SparkContext; 09:22:08.389 INFO BaseRecalibratorSpark - Shutting down engine; [March 9, 2018 9:22:08 AM UTC] org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark done. Elapsed time: 61.53 minutes.; Runtime.totalMemory()=16815489024; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 0.0 failed 1 times, most recent failure: Lost task 8.0 in stage 0.0 (TID 8, localhost): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 126542 ms; Dr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515:2181,Schedul,ScheduledThreadPoolExecutor,2181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515,2,['Schedul'],"['ScheduledFutureTask', 'ScheduledThreadPoolExecutor']"
Energy Efficiency,"at org.broadinstitute.hellbender.Main.main(Main.java:291); Caused by: htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: Duplicate key 0, for input source: cadd.config; at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:263); at htsjdk.tribble.TribbleIndexedFeatureReader.&lt;init&gt;(TribbleIndexedFeatureReader.java:102); at htsjdk.tribble.TribbleIndexedFeatureReader.&lt;init&gt;(TribbleIndexedFeatureReader.java:127); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:120); at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:350); ... 14 more; Caused by: java.lang.IllegalStateException: Duplicate key 0; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1254); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec.readActualHeader(XsvLocatableTableCodec.java:341); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec.readActualHeader(XsvLocatableTableCodec.java:64); at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:79); at hts",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223:2856,Reduce,ReduceOps,2856,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223,1,['Reduce'],['ReduceOps']
Energy Efficiency,"at.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.2 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:34044 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157) (first 15 tasks are for partitions Vector(0)); 17/10/11 14:19:18 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks; 17/10/11 14:19:19 INFO spark.Ex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:11607,schedul,scheduler,11607,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"ated broadcast 3 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244) (first 15 tasks are for partitions Vector(0)); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks; 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, com2, executor 1, partition 0, NODE_LOCAL, 4632 bytes); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:45501 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.131.101.145:54024; 17/10/13 18:11:53 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 135 bytes; 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on com2:45501 (size: 2.1 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 565 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88) finished in 0.566 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Job 0 finished: runJob at SparkHadoopMapReduceWriter.scala:88, took 9.524571 s; 17/10/13 18:11:53 INFO io.SparkHadoopMapReduceWriter: Job job_20171013181144_0009 committed.; 17/10/13 18:11:53 INFO server.AbstractConnector: Stopped Spark@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:53 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/13 18:11:54 INFO cluster.YarnSchedulerBackend$Ya",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:21150,schedul,scheduler,21150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['schedul'],['scheduler']
Energy Efficiency,ationFactory.java:2866); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:239); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForSegment$2(FuncotatorEngine.java:223); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForSegment(FuncotatorEngine.java:226); at org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments.apply(FuncotateSegments.java:191); at org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments.apply(FuncotateSegments.java:59); at org.broadinstitute.hellbender.engine.FeatureWalker.lambda$traverse$0(FeatureWalker.java:99); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:647); at org.broadinstitute.hellbender.engine.FeatureWalker.traverse(FeatureWalker.java:97); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKT,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314:3126,Reduce,ReduceOps,3126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314,4,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,ator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:953); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:812); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:796); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:473); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:474); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:529); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036:8241,Reduce,ReduceOps,8241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036,1,['Reduce'],['ReduceOps']
Energy Efficiency,"atureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 00:17:06.850 INFO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 00:17:06.850 INFO IndexFeatureFile - Deflater: IntelDeflater; 00:17:06.855 INFO IndexFeatureFile - Inflater: IntelInflater; 00:17:06.856 INFO IndexFeatureFile - GCS max retries/reopens: 20; 00:17:06.858 INFO IndexFeatureFile - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 00:17:06.859 INFO IndexFeatureFile - Initializing engine; 00:17:06.860 INFO IndexFeatureFile - Done initializing engine; 00:17:07.292 INFO FeatureManager - Using codec VCFCodec to read file file://bad.vcf; 00:17:07.310 INFO IndexFeatureFile - Shutting down engine; [January 26, 2018 12:17:07 AM GMT] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=512229376; java.lang.IllegalStateException: the progress meter has not been started yet; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:697); at org.broadinstitute.hellbender.engine.ProgressMeter.stop(ProgressMeter.java:230); at org.broadinstitute.hellbender.utils.codecs.ProgressReportingDelegatingCodec.isDone(ProgressReportingDelegatingCodec.java:104); at htsjdk.tribble.index.IndexFactory$FeatureIterator.readNextFeature(IndexFactory.java:522); at htsjdk.tribble.index.IndexFactory$FeatureIterator.<init>(IndexFactory.java:440); at htsjdk.tribble.index.IndexFactory.createDynamicIndex(IndexFactory.java:326); at org.broadinstitute.hellbender.tools.IndexFeatureFile.createAppropriateIndexInMemory(IndexFeatureFile.java:122); at org.broadinstitute.hellbender.tools.IndexFeatureFile.doWork(IndexFeatureFile.java:71); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.br",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4269:2891,meter,meter,2891,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4269,1,['meter'],['meter']
Energy Efficiency,ava.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:558) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.checkFilter(FuncotationFilter.java:49) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$null$0(FilterFuncotations.java:194) ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:176) ; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$null$1(FilterFuncotations.java:196) ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.eva,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:4463,Reduce,ReduceOps,4463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['Reduce'],['ReduceOps']
Energy Efficiency,ava:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:20123,schedul,scheduler,20123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,2,['schedul'],['scheduler']
Energy Efficiency,"ava:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.AssemblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.TaskSetManager: Task 284 in stage 25.0 failed 4 times; aborting job; 18/01/12 20:38:37 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@23007ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(50,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has alrea",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:4463,schedul,scheduler,4463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,ava:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.AssemblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.ap,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:7839,schedul,scheduler,7839,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,ava:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:330); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335); 	at java.lang.ClassLoader.loadClass(ClassL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:6009,schedul,scheduler,6009,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['schedul'],['scheduler']
Energy Efficiency,avaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:2079,schedul,scheduler,2079,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,1,['schedul'],['scheduler']
Energy Efficiency,avaRDDLike.scala:153); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.ap,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:10096,schedul,scheduler,10096,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,avaSerializer.java:65); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:330); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:5933,schedul,scheduler,5933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['schedul'],['scheduler']
Energy Efficiency,"ax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-NISTSampleHeadToHead/BenchmarkComparison/338d644e-3327-471e-9d17-1c103fa5e01e/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-NISTSampleHeadToHead/BenchmarkComparison/338d644e-3327-471e-9d17-1c103fa5e01e/call-BenchmarkVCFControlSample/Benchmark/145d88de-5810-47e1-972a-18ff0169fe27/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""92.82975"",; ""NIST evalHCsystemhours"": ""0.17177777777777778"",; ""NIST evalHCwallclockhours"": ""66.4404388888889"",; ""NIST evalHCwallclockmax"": ""3.325327777777778"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-NISTSampleHeadToHead/BenchmarkComparison/338d644e-3327-471e-9d17-1c103fa5e01e/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-NISTSampleHeadToHead/BenchmarkComparison/338d644e-3327-471e-9d17-1c103fa5e01e/call-BenchmarkVCFTestSample/Benchmark/e37c2b01-a62d-4b8c-9fb3-6f86d8377ca7/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-CreateHTMLReport/cacheCopy/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1193038382:20668,monitor,monitoring,20668,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1193038382,1,['monitor'],['monitoring']
Energy Efficiency,"ax"": ""4.031741666666667"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-NISTSampleHeadToHead/BenchmarkComparison/3238c3ac-5e7c-4130-bb68-26871868b49e/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-NISTSampleHeadToHead/BenchmarkComparison/3238c3ac-5e7c-4130-bb68-26871868b49e/call-BenchmarkVCFControlSample/Benchmark/4121c5eb-9771-43ee-84f1-262115dcf151/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""93.23600000000005"",; ""NIST evalHCsystemhours"": ""0.2127972222222222"",; ""NIST evalHCwallclockhours"": ""62.422702777777786"",; ""NIST evalHCwallclockmax"": ""3.1571083333333334"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-NISTSampleHeadToHead/BenchmarkComparison/3238c3ac-5e7c-4130-bb68-26871868b49e/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-NISTSampleHeadToHead/BenchmarkComparison/3238c3ac-5e7c-4130-bb68-26871868b49e/call-BenchmarkVCFTestSample/Benchmark/499d7c71-c488-4bfb-9802-34f6c5696c8d/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8485#issuecomment-1684837497:21350,monitor,monitoring,21350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8485#issuecomment-1684837497,1,['monitor'],['monitoring']
Energy Efficiency,"ax"": ""4.166558333333334"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-NISTSampleHeadToHead/BenchmarkComparison/043115ef-b68a-49a3-8272-8352b304c3aa/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-NISTSampleHeadToHead/BenchmarkComparison/043115ef-b68a-49a3-8272-8352b304c3aa/call-BenchmarkVCFControlSample/Benchmark/b7031327-e5c1-4869-a5d9-98e5a8934db9/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""112.84528333333336"",; ""NIST evalHCsystemhours"": ""0.8645277777777777"",; ""NIST evalHCwallclockhours"": ""88.01737777777778"",; ""NIST evalHCwallclockmax"": ""4.8386555555555555"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-NISTSampleHeadToHead/BenchmarkComparison/043115ef-b68a-49a3-8272-8352b304c3aa/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-NISTSampleHeadToHead/BenchmarkComparison/043115ef-b68a-49a3-8272-8352b304c3aa/call-BenchmarkVCFTestSample/Benchmark/d4de27fe-6aca-42a5-8a9f-6daff7b890e8/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1687811441:21336,monitor,monitoring,21336,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1687811441,1,['monitor'],['monitoring']
Energy Efficiency,b.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:7089,Meter,MeteredStream,7089,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['Meter'],['MeteredStream']
Energy Efficiency,"b07a68-f04f-4396-80b4-f153b2d0020d/call-BenchmarkVCFControlSample/Benchmark/efb3b5ff-3860-46c3-8c6c-9141d1ff0e0a/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-EXOME1SampleHeadToHead/BenchmarkComparison/85b07a68-f04f-4396-80b4-f153b2d0020d/call-BenchmarkVCFTestSample/Benchmark/272d076b-7300-4ea4-bbf7-d63f80fad94b/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""108.95665833333332"",; ""NIST controlHCsystemhours"": ""0.21568055555555551"",; ""NIST controlHCwallclockhours"": ""78.62844166666666"",; ""NIST controlHCwallclockmax"": ""4.166558333333334"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-NISTSampleHeadToHead/BenchmarkComparison/043115ef-b68a-49a3-8272-8352b304c3aa/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-NISTSampleHeadToHead/BenchmarkComparison/043115ef-b68a-49a3-8272-8352b304c3aa/call-BenchmarkVCFControlSample/Benchmark/b7031327-e5c1-4869-a5d9-98e5a8934db9/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""112.84528333333336"",; ""NIST evalHCsystemhours"": ""0.8645277777777777"",; ""NIST evalHCwallclockhours"": ""88.01737777777778"",; ""NIST evalHCwallclockmax"": ""4.8386555555555555"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1687811441:20348,monitor,monitoring,20348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1687811441,1,['monitor'],['monitoring']
Energy Efficiency,"b6-04bd-4344-b4fc-8a1df66bb5d9/call-CHMSampleHeadToHead/BenchmarkComparison/79d1a2a4-6b5e-424a-8528-9059bda6db1c/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-CHMSampleHeadToHead/BenchmarkComparison/79d1a2a4-6b5e-424a-8528-9059bda6db1c/call-BenchmarkVCFControlSample/Benchmark/3046acf7-ded7-40c8-9b7a-3826f480418f/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""67.35536666666667"",; ""CHM evalHCsystemhours"": ""0.1557166666666667"",; ""CHM evalHCwallclockhours"": ""42.53388888888889"",; ""CHM evalHCwallclockmax"": ""2.7197444444444443"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-CHMSampleHeadToHead/BenchmarkComparison/79d1a2a4-6b5e-424a-8528-9059bda6db1c/call-EVALRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8778"",; ""CHM evalindelPrecision"": ""0.8968"",; ""CHM evalsnpF1Score"": ""0.9813"",; ""CHM evalsnpPrecision"": ""0.9774"",; ""CHM evalsnpRecall"": ""0.9852"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-CHMSampleHeadToHead/BenchmarkComparison/79d1a2a4-6b5e-424a-8528-9059bda6db1c/call-BenchmarkVCFTestSample/Benchmark/2f376005-bdfb-42bd-8736-1e6df978ab80/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-EXOME1Sampl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064:11456,monitor,monitoring,11456,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064,1,['monitor'],['monitoring']
Energy Efficiency,"b9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9MaWJyYXJ5UmVhZEZpbHRlci5qYXZh) | `100% <Ã¸> (Ã¸)` | `4 <Ã¸> (Ã¸)` | :x: |; | [...institute/hellbender/tools/picard/sam/SortSam.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9waWNhcmQvc2FtL1NvcnRTYW0uamF2YQ==) | `94.118% <Ã¸> (Ã¸)` | `3 <Ã¸> (Ã¸)` | :x: |; | [...adinstitute/hellbender/tools/IndexFeatureFile.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9JbmRleEZlYXR1cmVGaWxlLmphdmE=) | `90.323% <Ã¸> (Ã¸)` | `12 <Ã¸> (Ã¸)` | :x: |; | [...org/broadinstitute/hellbender/tools/ClipReads.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9DbGlwUmVhZHMuamF2YQ==) | `90.385% <Ã¸> (Ã¸)` | `35 <Ã¸> (Ã¸)` | :x: |; | ... and [81 more](https://codecov.io/gh/broadinstitute/gatk/pull/2327/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2327?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2327?src=pr&el=footer). Last update [10b16a6...d4483e8](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-268877705:4973,Power,Powered,4973,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-268877705,1,['Power'],['Powered']
Energy Efficiency,"bWVudENvbGxlY3Rpb24uamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...tools/examples/ExampleStreamingPythonExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlU3RyZWFtaW5nUHl0aG9uRXhlY3V0b3IuamF2YQ==) | `0% <0%> (-96.67%)` | `0% <0%> (-8%)` | |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `4.16% <0%> (-95.84%)` | `2% <0%> (-8%)` | |; | [...der/utils/python/PythonScriptExecutorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vUHl0aG9uU2NyaXB0RXhlY3V0b3JVbml0VGVzdC5qYXZh) | `3.84% <0%> (-94.24%)` | `1% <0%> (-11%)` | |; | [...number/arguments/HybridADVIArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2FyZ3VtZW50cy9IeWJyaWRBRFZJQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `0% <0%> (-94.12%)` | `0% <0%> (-3%)` | |; | ... and [36 more](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5329?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5329?src=pr&el=footer). Last update [f95b6fe...1c00f72](https://codecov.io/gh/broadinstitute/gatk/pull/5329?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5329#issuecomment-431146563:4744,Power,Powered,4744,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5329#issuecomment-431146563,1,['Power'],['Powered']
Energy Efficiency,"backs(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more. Driver stacktrace:; 21/04/13 07:32:25 INFO DAGScheduler: Job 2 failed: runJob at SparkHadoopWriter.scala:78, took 0.365288 s; 21/04/13 07:32:25 ERROR SparkHadoopWriter: Aborting job job_20210413073224_0026.; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 105, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Sequence [VC HC @ chr4_GL000008v2_random:7168-7691 Q. of type=SYMBOLIC alleles=[T*, <NON_REF>] attr={END=7691} GT=[[NA12878 T*/T* GQ 0 DP 0 PL 0,0,0 {MIN_DP=0}]] filters= added out of order currentReferenceIndex: 25, referenceIndex:37; at htsjdk.tribble.index.tabix.AllRefsTabixIndexCreator.addFeature(AllRefsTabixIndexCreator.java:79); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:14547,schedul,scheduler,14547,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,"bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `90% <0%> (-1.429%)` | `23% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `87.2% <0%> (+0.8%)` | `36% <0%> (+1%)` | :arrow_up: |; | [...ellbender/tools/walkers/annotator/RankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SYW5rU3VtVGVzdC5qYXZh) | `86.957% <0%> (+6.401%)` | `14% <0%> (+1%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.385% <0%> (+7.168%)` | `49% <0%> (+16%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2500?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2500?src=pr&el=footer). Last update [58cb99e...2a7f196](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2500#issuecomment-288139597:2681,Power,Powered,2681,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2500#issuecomment-288139597,1,['Power'],['Powered']
Energy Efficiency,bender.utils.MathUtils.log10BinomialProbability(MathUtils.java:934); 	at org.broadinstitute.hellbender.utils.MathUtils.binomialProbability(MathUtils.java:927); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:56); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemain,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098:6203,Reduce,ReduceOps,6203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098,1,['Reduce'],['ReduceOps']
Energy Efficiency,"bert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; >; > 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; >; > INFO: Failed to detect whether we are running on Google Compute Engine.; >; > 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------; >; > 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1; >; > 16:17:05.843 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; >; > 16:17:05.843 INFO HaplotypeCaller - Executing as robert@powerlinux on Linux v4.4.0-184-generic ppc64le; >; > 16:17:05.843 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-8u252-b09-1~16.04-b09; >; > 16:17:05.843 INFO HaplotypeCaller - Start Date/Time: September 4, 2020 4:17:04 PM UTC; >; > 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------; >; > 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------; >; > 16:17:05.844 INFO HaplotypeCaller - HTSJDK Version: 2.23.0; >; > 16:17:05.844 INFO HaplotypeCaller - Picard Version: 2.22.8; >; > 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; >; > 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; >; > 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; >; > 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; >; > 16:17:05.844 INFO Hapl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600:3034,power,powerlinux,3034,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600,1,['power'],['powerlinux']
Energy Efficiency,"bfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:14:00 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 0.0 (TID 3, scc-q16.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 124511724, span 7265, expected MD5 cf58e0adc447a66b188474efc3c84a43; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:8862,schedul,scheduler,8862,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,bfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:8,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:14022,schedul,scheduler,14022,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,bjectOutputStream.writeSerialData(ObjectOutputStream.java:1529) ~[?:?]; at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438) ~[?:?]; at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181) ~[?:?]; at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350) ~[?:?]; at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; 11:00,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:22941,schedul,scheduler,22941,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"both of these are updates to the ImportGenomes wdl:; - reduce memory/cpus for the CreateImportTsvs task from 10GB to 3.75GB and 2 CPU to 1 CPU. these settings were tested on 3000 gvcfs and none errored out because of memory. this ties out spec-ops issues #211 and #233; - before loading files using `bq load`, check for existing files in the gs bucket. only run `bq load` if there are matching files in the bucket. this will prevent an error if you run a subset of samples corresponding to a larger sample map such that you've created a pet_002 table but there aren't any samples to load for pet_002 yet. this was tested in Terra and worked as expected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7121:55,reduce,reduce,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7121,1,['reduce'],['reduce']
Energy Efficiency,"bqsrgatherer-exception. In the below stacktrace, I've bolded the error message that seems to occur in each of these samples. `Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1026); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.reduce(RDD.scala:1008); 	at org.apache.spark.r",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:2090,schedul,scheduler,2090,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['schedul'],['scheduler']
Energy Efficiency,broadinstitute) (9aa31e4) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/72684d0fae3326398c80e2f47d78eeff1fcc14fe?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) (72684d0) will **decrease** coverage by `0.001%`.; > The diff coverage is `100.000%`. ```diff; @@ Coverage Diff @@; ## master #7851 +/- ##; ===============================================; - Coverage 86.948% 86.947% -0.001% ; Complexity 36927 36927 ; ===============================================; Files 2219 2219 ; Lines 173673 173674 +1 ; Branches 18755 18755 ; ===============================================; - Hits 151006 151005 -1 ; + Misses 16055 16054 -1 ; - Partials 6612 6615 +3 ; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/7851?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) | Coverage Î” | |; |---|---|---|; | [...rs/haplotypecaller/graphs/AdaptiveChainPruner.java](https://codecov.io/gh/broadinstitute/gatk/pull/7851/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQWRhcHRpdmVDaGFpblBydW5lci5qYXZh) | `97.368% <100.000%> (+0.035%)` | :arrow_up: |; | [.../hellbender/utils/python/PythonUnitTestRunner.java](https://codecov.io/gh/broadinstitute/gatk/pull/7851/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vUHl0aG9uVW5pdFRlc3RSdW5uZXIuamF2YQ==) | `75.410% <0.000%> (-3.279%)` | :arrow_down: |; | [...itute/hellbender/tools/LocalAssemblerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7851/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7851#issuecomment-1126424538:1373,Adapt,AdaptiveChainPruner,1373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7851#issuecomment-1126424538,1,['Adapt'],['AdaptiveChainPruner']
Energy Efficiency,broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.lang.IllegalArgumentException: java.lang.IllegalArgumentException: Requested start 8613 is beyond the sequence length HLA-DRB1*04:03:01; at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490); at java.base/java.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:600); at java.base/java.util.concurrent.ForkJoinTask.reportException(ForkJoinTask.java:678); at java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:737); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateParallel(ReduceOps.java:919); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233); at java.base/java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:558); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.lambda$collectCaseStatsParallel$14(CalibrateDragstrModel.java:568); at java.base/java.util.concurrent.ForkJoinTask$AdaptedCallable.exec(ForkJoinTask.java:1448); at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290); at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020); at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656); at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594); at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183); Caused by: java.lang.IllegalArgumentException: Requested start 8613 is beyond the sequence length HLA-DRB1*04:03:01; at htsjdk.samtools.cram.ref.ReferenceS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8139:8021,Reduce,ReduceOps,8021,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8139,1,['Reduce'],['ReduceOps']
Energy Efficiency,broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:229); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:207); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpli,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:22670,Reduce,ReduceOps,22670,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['Reduce'],['ReduceOps']
Energy Efficiency,"broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `84% <100%> (+0.66%)` | `43 <4> (Ã¸)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (Ã¸)` | `2% <0%> (Ã¸)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/PathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUGF0aFNwZWNpZmllci5qYXZh) | `67.1% <0%> (+1.31%)` | `21% <0%> (+1%)` | :arrow_up: |; | [...institute/hellbender/engine/GATKPathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1BhdGhTcGVjaWZpZXIuamF2YQ==) | `48.21% <0%> (+1.78%)` | `16% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=footer). Last update [aa8e807...d462900](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094:2878,Power,Powered,2878,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094,1,['Power'],['Powered']
Energy Efficiency,"bsnp_138.vcf.gz \ ; --emitRefConfidence GVCF \; --readValidationStringency LENIENT \ ; --nativePairHmmThreads 32 \; --createOutputVariantIndex true \; --output NA12892.raw.snps.indels.g.vcf_. **This execution time for GATK 4 Beta2 is: 51 Hours, 32 min**. Alternatively, I was running the same sample (NA12892) using GATK 3.7 using the following command: . _time -p java -XX:+UseParallelGC -XX:ParallelGCThreads=32 -Xmx128g \; -jar /gpfs/software/genomics/GATK/3.7/base/GenomeAnalysisTK.jar -T HaplotypeCaller \; -nct 8 -pairHMM VECTOR_LOGLESS_CACHING \ ; -R /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa \; -I NA12892.realigned.recal.bam -\ ; -emitRefConfidence GVCF \; --variant_index_type LINEAR \; --variant_index_parameter 128000 \; --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz \; -o NA12892.raw.snps.indels.g.vcf _. **This execution time for GATK 3.7 is: 18 Hours, 12 min**. I don't know, how to use multithreads (e.g. -nct) for GATK 4 version to reduce the execution time on the single node. Because, we have 32 cores per node with 512GB memory available for benchmarking. To parallelize the GATK 4 workload, I used the Spark version also. . I used **GATK 4 Beta2 Spark job on the cluster of 32 nodes** (32 nodes x 32 cores, totaling 1024 cores). The execution time is almost same as GATK 4 Beta2 ( 50 Hours, 21 min). Please help me, how to reduce the execution time for GATK 4 Beta2 HaplotypeCaller? . Please see this below Spark logs:. + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//bin/spark-submit --master spark://nsnode11:6311 --driver-java-options -Dsamjdk.use_async_io_read_samtools=false,-Dsamjdk.use_async_io_write_samtools=true,-Dsamjdk.use_async_io_write_tribble=false,-Dsamjdk.compression_level=1 --conf spark.io.compression.codec=snappy --conf spark.yarn.executor.memoryOverhead=6000 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.userClassPathFirst=true --conf spark.driver.maxResultSize=0 --conf spark.executor.cores=1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3631:1475,reduce,reduce,1475,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631,1,['reduce'],['reduce']
Energy Efficiency,bstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.AlleleFrequencyUtils.lambda$buildMaxMafRule$1(AlleleFrequencyUtils.java:30) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.lambda$checkFilter$0(FuncotationFilter.java:48) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:558) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.checkFilter(FuncotationFilter.java:49) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$null$0(FilterFuncotations.java:194) ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:176) ; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at jav,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:3566,Reduce,ReduceOps,3566,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```; 18/03/07 20:32:55 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at FlagStatSpark.java:73, took 64.566359 s; 1205535516 in total; 0 QC failure; 37791118 duplicates; 1157122594 mapped (95.98%); 1205535516 paired in sequencing; 602767758 read1; 602767758 read2; 1145853318 properly paired (95.05%); 1150449216 with itself and mate mapped; 6673378 singletons (0.55%); 4595898 with mate mapped to a different chr; 3316623 with mate mapped to a different chr (mapQ>=5); 18/03/07 20:32:55 INFO server.ServerConnector: Stopped ServerConnector@79f5a6ed{HTTP/1.1}{0.0.0.0:4041}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:8446,schedul,scheduler,8446,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,1,['schedul'],['scheduler']
Energy Efficiency,"c.). The run can be found in /dsde/working/slee/wgs-pon-test/tieout/no-gc. It completed successfully with **-Xmx32G** (in comparison, CreatePanelOfNormals crashed after 40 minutes with -Xmx128G). The runtime breakdown was as follows:. - ~45 minutes simply from reading of the 90 TSV read-count files in serial. Hopefully #3349 should greatly speed this up. (In comparison, CombineReadCounts reading 10 files in parallel at a time took ~100 minutes to create the aforementioned 20GB combined TSV file, creating 25+GB of temp files along the way.). - ~5 minutes from the preprocessing and filtering steps. We could probably further optimize some of this code in terms of speed and heap usage. (I had to throw in a call to System.gc() to avoid an OOM with -Xmx32G, which I encountered in my first attempt at the run...). - ~5 minutes from performing the SVD of the post-filtering 8643028 x 86 matrix, maintaining 30 eigensamples. I could write a quick implementation of randomized SVD, which I think could bring this down a bit (the scikit-learn implementation takes <2 minutes on a 10M x 100 matrix), but this can probably wait. Clearly making I/O faster and more space efficient is the highest priority. Luckily it's also low hanging fruit. The 8643028 x 30 matrix of eigenvectors takes <2 minutes to read from HDF5 when the WGS PoN is used in DenoiseReadCounts, which gives us a rough idea of how long it should take to read in the original ~11.5M x 90 counts from HDF5. So once #3349 is in, then I think that a **~15 minute single-core WGS PoN could easily be viable**. I believe that a PoN on the order of this size will be all that is required for WGS denoising, if it is not already overkill. To go bigger by more than an order of magnitude, we'll have to go out of core, which will require more substantial changes to the code. But since the real culprit responsible for hypersegmentation is CBS, rather than insufficient denoising, I'd rather focus on finding a viable segmentation alternative.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-317614503:1499,efficient,efficient,1499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-317614503,1,['efficient'],['efficient']
Energy Efficiency,"c.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```; 18/03/07 20:32:55 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at FlagStatSpark.java:73, took 64.566359 s; 1205535516 in total; 0 QC failure; 37791118 duplicates; 1157122594 mapped (95.98%); 1205535516 paired in sequencing; 602767758 read1; 602767758 read2; 1145853318 properly paired (95.05%); 1150449216 w",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:8129,schedul,scheduler,8129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,1,['schedul'],['scheduler']
Energy Efficiency,"c/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_libs__7473738539612638927.zip; 2019-01-07 11:33:38 INFO Client:54 - Uploading resource file:/tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed/__spark_conf__4147634812449814799.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_conf__.zip; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:38 INFO Client:54 - Submitting application application_1542127286896_0153 to ResourceManager; 2019-01-07 11:33:38 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0153; 2019-01-07 11:33:38 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0153 and attemptId None; 2019-01-07 11:33:39 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:39 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1546878818531; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0153/; user: farrell; 2019-01-07 11:33:40 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:41 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:42 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:13021,Schedul,SchedulerExtensionServices,13021,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Schedul'],['SchedulerExtensionServices']
Energy Efficiency,"c/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_libs__7821719163562430010.zip; 2019-01-09 13:35:22 INFO Client:54 - Uploading resource file:/tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0/__spark_conf__4520928824604875683.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_conf__.zip; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:22 INFO Client:54 - Submitting application application_1542127286896_0166 to ResourceManager; 2019-01-09 13:35:22 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0166; 2019-01-09 13:35:22 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0166 and attemptId None; 2019-01-09 13:35:23 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:23 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1547058922320; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0166/; user: farrell; 2019-01-09 13:35:24 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:25 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:26 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:12760,Schedul,SchedulerExtensionServices,12760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Schedul'],['SchedulerExtensionServices']
Energy Efficiency,"c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9HQVRLU1ZWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `0% <Ã¸> (Ã¸)` | `0 <0> (Ã¸)` | :arrow_down: |; | [...ute/hellbender/tools/spark/sv/AlignmentRegion.java](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9BbGlnbm1lbnRSZWdpb24uamF2YQ==) | `63.265% <100%> (+1.16%)` | `16 <2> (Ã¸)` | :arrow_down: |; | [...lbender/tools/spark/sv/SVVariantConsensusCall.java](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlZhcmlhbnRDb25zZW5zdXNDYWxsLmphdmE=) | `85.556% <80%> (Ã¸)` | `21 <4> (Ã¸)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (Ã¸)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2512?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2512?src=pr&el=footer). Last update [9c1d1fb...f1380fe](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2512#issuecomment-288291739:2719,Power,Powered,2719,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2512#issuecomment-288291739,1,['Power'],['Powered']
Energy Efficiency,c=pr&el=desc) will **increase** coverage by `0.012%`.; > The diff coverage is `86.42%`. ```diff; @@ Coverage Diff @@; ## master #5462 +/- ##; ===============================================; + Coverage 87.075% 87.087% +0.012% ; + Complexity 31334 31225 -109 ; ===============================================; Files 1921 1915 -6 ; Lines 144602 144079 -523 ; Branches 15951 15891 -60 ; ===============================================; - Hits 125912 125474 -438 ; + Misses 12896 12834 -62 ; + Partials 5794 5771 -23; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5462?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...s/walkers/haplotypecaller/graphs/PathUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5462/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvUGF0aFVuaXRUZXN0LmphdmE=) | `93.258% <Ã¸> (-0.22%)` | `7 <0> (Ã¸)` | |; | [...rs/haplotypecaller/graphs/AdaptiveChainPruner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5462/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQWRhcHRpdmVDaGFpblBydW5lci5qYXZh) | `95.349% <100%> (Ã¸)` | `16 <0> (Ã¸)` | :arrow_down: |; | [...ller/readthreading/ReadThreadingGraphUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5462/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaFVuaXRUZXN0LmphdmE=) | `95.238% <100%> (+0.018%)` | `55 <0> (Ã¸)` | :arrow_down: |; | [...rs/haplotypecaller/graphs/ChainPrunerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5462/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQ2hhaW5QcnVuZXJVbml0VGVzdC5qYXZh) | `99.194% <100%> (-0.006%)` | `40 <0> (Ã¸)` | |; | [...der/t,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5462#issuecomment-450062027:1281,Adapt,AdaptiveChainPruner,1281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5462#issuecomment-450062027,1,['Adapt'],['AdaptiveChainPruner']
Energy Efficiency,"c=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUNhbGN1bGF0aW9uQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <Ã¸> (Ã¸)` | `2 <0> (Ã¸)` | :x: |; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.903% <33.333%> (Ã¸)` | `32 <0> (Ã¸)` | :x: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :white_check_mark: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (Ã¸)` | :x: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2314?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2314?src=pr&el=footer). Last update [5d2f859...ed0b8ca](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2314#issuecomment-267118800:2738,Power,Powered,2738,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2314#issuecomment-267118800,1,['Power'],['Powered']
Energy Efficiency,cala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:49799,schedul,scheduler,49799,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,cala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:49897,schedul,scheduler,49897,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,"cala:801); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Caused by: htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: /local/scratch/rieder/spark-bb59423b-0368-4de5-85e0-e6641fb25380/userFiles-a91d5958-33f5-4685-bf9d-c8fc0924f7c6/Homo_sapiens_assembly38.known_indels.vcf: Too many open files, for input source: /local/scratch/rieder/spark-bb59423b-0368-4de5-85e0-e6641fb25380/userFiles-a91d5958-33f5-4685-bf9d-c8fc0924f7c6/Homo_sapiens_assembly38.known_indels.vcf; a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6578:5538,schedul,scheduler,5538,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6578,1,['schedul'],['scheduler']
Energy Efficiency,cast$.unBlockifyObject(TorrentBroadcast.scala:294); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:226); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 21 more; Caused by: java.lang.UnsupportedOperationException; 	at shaded.cloud_nio.com.google.common.collect.ImmutableMap.put(ImmutableMap.java:407); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:162); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	... 38 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545:9794,schedul,scheduler,9794,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545,1,['schedul'],['scheduler']
Energy Efficiency,catable); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:144); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:362); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.invalidateSampleOrdering(LazyGenotypesContext.java:205); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:353,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:7198,schedul,scheduler,7198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,"cc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```; 18/03/07 20:32:55 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at FlagStatSpark.java:73, took 64.566359 s; 1205535516 in total; 0 QC failure; 37791",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:7969,schedul,scheduler,7969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,1,['schedul'],['scheduler']
Energy Efficiency,"cc.bu.edu, executor 4, partition 1, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 1, scc-q13.scc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```;",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:7811,schedul,scheduler,7811,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,1,['schedul'],['scheduler']
Energy Efficiency,ce for chr12).; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at java.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:593); 	at java.util.concurrent.ForkJoinTask.reportException(ForkJoinTask.java:677); 	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:735); 	at java.util.stream.ReduceOps$ReduceOp.evaluateParallel(ReduceOps.java:714); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233); 	at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:546); 	at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.lambda$collectCaseStatsParallel$13(CalibrateDragstrModel.java:489); 	at java.util.concurrent.ForkJoinTask$AdaptedCallable.exec(ForkJoinTask.java:1424); 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289); 	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056); 	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692); 	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157); Caused by: java.lang.IllegalArgumentException: A reference must be supplied that includes the reference sequence for chr12).; 	at htsjdk.samtools.cram.ref.CRAMLazyReferenceSource.getReferenceBases(CRAMLazyReferenceSource.java:41); 	at htsjdk.samtools.cram.build.CRAMReferenceRegion.getReferenceBases(CRAMReferenceRegion.java:74); 	at htsjdk.samtools.cram.structure.Slice.normalizeCRAMRecords(Slice.java:450); 	at htsjdk.samtools.cram.structure.Container.getSAMRecords(Container.java:322); 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:112); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:204); 	at htsjdk.samtools.CRAMFi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7060:3142,Adapt,AdaptedCallable,3142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7060,1,['Adapt'],['AdaptedCallable']
Energy Efficiency,"ce output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes quite long, I checked the WARN messages of the output above. Especially the last one about the AVX instruction set where it says that a **MUCH** slower implementation will be used. From the few WARN messages it seems like the root cause is the failure to load libgkl and that again seems to be related to my platform. From another thread/topic I concluded that the instruction set problem might be gone if libgkl could be loaded. Does anyone know more about this issue or how to work around it?. Best regards,; Robert",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794:5151,Power,Power,5151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794,1,['Power'],['Power']
Energy Efficiency,"ce326-baa5-4052-bff9-bd684393ff6c/call-CHMSampleHeadToHead/BenchmarkComparison/a1db35b8-cc7b-4019-bdd0-9f423762542e/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-CHMSampleHeadToHead/BenchmarkComparison/a1db35b8-cc7b-4019-bdd0-9f423762542e/call-BenchmarkVCFControlSample/Benchmark/7195c554-534f-43ef-80c2-77bdafa1827f/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""78.10181666666668"",; ""CHM evalHCsystemhours"": ""0.16157500000000005"",; ""CHM evalHCwallclockhours"": ""55.006172222222226"",; ""CHM evalHCwallclockmax"": ""2.8554194444444443"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-CHMSampleHeadToHead/BenchmarkComparison/a1db35b8-cc7b-4019-bdd0-9f423762542e/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-CHMSampleHeadToHead/BenchmarkComparison/a1db35b8-cc7b-4019-bdd0-9f423762542e/call-BenchmarkVCFTestSample/Benchmark/5c4f9069-86b3-4d8c-b765-38a67169e4b4/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1194801748:17683,monitor,monitoring,17683,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1194801748,1,['monitor'],['monitoring']
Energy Efficiency,"ce:54 - Server created on scc-hadoop.bu.edu:45270; 2019-01-07 11:33:53 INFO BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 2019-01-07 11:33:53 INFO BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-hadoop.bu.edu:45270 with 408.6 MB RAM, BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:54 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60251ddb{/metrics/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:58 INFO YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms); 2019-01-07 11:33:59 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.196:49862) with ID 2; 2019-01-07 11:33:59 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q12.scc.bu.edu:38418 with 366.3 MB RAM, BlockManagerId(2, scc-q12.scc.bu.edu, 38418, None); 2019-01-07 11:33:59 INFO MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 1229.0 KB, free 407.4 MB); 2019-01-07 11:34:00 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.229:59962) with ID 1; 2019-01-07 11:34:00 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q21.scc.bu.edu:41630 with 366.3 MB RAM, BlockManagerId(1, scc-q21.scc.bu.edu, 41630, None); 2019-01-07 11:34:00 INFO MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 113.9 KB, free 40",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:17313,Schedul,SchedulerBackend,17313,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,"['Schedul', 'schedul']","['SchedulerBackend', 'scheduling']"
Energy Efficiency,ceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:11140,schedul,scheduler,11140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,3,['schedul'],['scheduler']
Energy Efficiency,"ception occurred:. Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/pymc3/__init__.py"", line 5, in <module>; from .distributions import *; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/pymc3/distributions/__init__.py"", line 1, in <module>; from . import timeseries; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/pymc3/distributions/timeseries.py"", line 1, in <module>; import theano.tensor as tt; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/__init__.py"", line 124, in <module>; from theano.scan_module import (scan, map, reduce, foldl, foldr, clone,; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/scan_module/__init__.py"", line 41, in <module>; from theano.scan_module import scan_opt; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/scan_module/scan_opt.py"", line 60, in <module>; from theano import tensor, scalar; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/tensor/__init__.py"", line 17, in <module>; from theano.tensor import blas; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/tensor/blas.py"", line 155, in <module>; from theano.tensor.blas_headers import blas_header_text; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/tensor/blas_headers.py"", line 987, in <module>; if not config.blas.ldflags:; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8387:3223,reduce,reduce,3223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8387,1,['reduce'],['reduce']
Energy Efficiency,"cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZU1hbmFnZXIuamF2YQ==) | `86.592% <Ã¸> (+1.025%)` | `78% <Ã¸> (+34%)` | :white_check_mark: |; | [...tute/hellbender/engine/MultiVariantDataSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTXVsdGlWYXJpYW50RGF0YVNvdXJjZS5qYXZh) | `84.106% <Ã¸> (+2.001%)` | `52% <Ã¸> (+18%)` | :white_check_mark: |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `72.105% <Ã¸> (+2.54%)` | `4% <Ã¸> (Ã¸)` | :x: |; | [...rg/broadinstitute/hellbender/utils/io/IOUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9JT1V0aWxzLmphdmE=) | `65.704% <Ã¸> (+8.146%)` | `88% <Ã¸> (+45%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2391?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2391?src=pr&el=footer). Last update [6f9de16...7247260](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-278096683:3842,Power,Powered,3842,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-278096683,1,['Power'],['Powered']
Energy Efficiency,change shards `hashCode` to fix bad distribution to partitions. fix NPE. adding uri's change from distinct to aggregate. reduce shard size by half,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/937:121,reduce,reduce,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/937,1,['reduce'],['reduce']
Energy Efficiency,che.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513:7069,schedul,scheduler,7069,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513,1,['schedul'],['scheduler']
Energy Efficiency,che.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:7080,schedul,scheduler,7080,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['schedul'],['scheduler']
Energy Efficiency,cheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.sche,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:12874,schedul,scheduler,12874,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,cheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:14228,schedul,scheduler,14228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,2,['schedul'],['scheduler']
Energy Efficiency,cheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:14947,schedul,scheduler,14947,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,"cheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 18/07/24 21:02:09 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.9.0-hadoop2; 18/07/24 21:02:10 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at shuang-small-m/10.128.5.217:8032; 18/07/24 21:02:10 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at shuang-small-m/10.128.5.217:10200; 18/07/24 21:02:12 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1532457503538_0038; 21:02:16.702 INFO FeatureManager - Using codec BEDCodec to read file hdfs://shuang-small-m:8020/data/intervals.bed; 21:02:16.863 INFO IntervalArgumentCollection - Processing 1219 bp from intervals; 18/07/24 21:02:17 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 18/07/24 21:02:25 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 1.0 in stage 0.0 (TID 1, shuang-small-m.c.broad-dsde-methods.internal, executor 1): htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:532); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:468); 	at htsjdk.samtools.util.BlockCompressedInputStream.seek(BlockCompressedInputStream.java:380); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:977); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.sa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:8006,schedul,scheduler,8006,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['schedul'],['scheduler']
Energy Efficiency,"ci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.491% <0%> (-2.632%)` | `32% <0%> (-9%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `77.996% <0%> (-0.179%)` | `175% <0%> (-1%)` | |; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `94.444% <0%> (-0.15%)` | `16% <0%> (-1%)` | |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `85.484% <0%> (-0.116%)` | `49% <0%> (-1%)` | |; | [...ender/tools/walkers/annotator/InbreedingCoeff.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9JbmJyZWVkaW5nQ29lZmYuamF2YQ==) | `82.759% <0%> (Ã¸)` | `11% <0%> (Ã¸)` | :arrow_down: |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=footer). Last update [62d58c5...0492c9c](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2559#issuecomment-290845420:4321,Power,Powered,4321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2559#issuecomment-290845420,1,['Power'],['Powered']
Energy Efficiency,"ck manager 10.131.101.159:44818 with 366.3 MB RAM, BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO storage.BlockManager: external shuffle service port = 7337; 17/10/13 18:11:42 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@544300a6{/metrics/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:42 INFO scheduler.EventLoggingListener: Logging events to hdfs://mg:8020/user/spark/spark2ApplicationHistory/application_1507856833944_0003; 17/10/13 18:11:42 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances; 17/10/13 18:11:43 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 17/10/13 18:11:43 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 286.0 KB, free 366.0 MB); 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 26.0 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.131.101.159:44818 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.5 KB, free 366.0 MB); 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:44818 (size: 2.1 KB, free: 366.3 MB); 17/10/13 18",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:14836,Schedul,SchedulerBackend,14836,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,"['Schedul', 'schedul']","['SchedulerBackend', 'scheduling']"
Energy Efficiency,"ckManagerInfo: Removed broadcast_0_piece0 on localhost:65240 in memory (size: 3.7 KB, free: 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerMaster: Updated info of block broadcast_0_piece0; 15/07/14 13:14:53 INFO spark.ContextCleaner: Cleaned broadcast 0; 15/07/14 13:14:53 ERROR executor.Executor: Exception in task 0.0 in stage 1.0 (TID 1); java.lang.IncompatibleClassChangeError: Found class org.apache.hadoop.mapreduce.TaskAttemptContext, but interface was expected; at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getOutputFile(TemplatedTextOutputFormat.java:50); at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getDefaultWorkFile(TemplatedTextOutputFormat.java:46); at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:995); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:979); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61); at org.apache.spark.scheduler.Task.run(Task.scala:64); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 15/07/14 13:14:53 ERROR util.SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-0,5,main]; java.lang.IncompatibleClassChangeError: Found class org.apache.hadoop.mapreduce.TaskAttemptContext, but interface was expected; at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getOutputFile(TemplatedTextOutputFormat.java:50); at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getDefaultWorkFile(TemplatedTextOutputFormat.java:46); at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125); at org.apache.spark.rdd.PairRD",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:29211,schedul,scheduler,29211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['schedul'],['scheduler']
Energy Efficiency,cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 41 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 47 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727:5383,Meter,MeteredStream,5383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727,1,['Meter'],['MeteredStream']
Energy Efficiency,cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:8871,Meter,MeteredStream,8871,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['Meter'],['MeteredStream']
Energy Efficiency,"cmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `66.667% <0%> (+3.252%)` | `4% <0%> (Ã¸)` | :arrow_down: |; | [...g/broadinstitute/hellbender/engine/AuthHolder.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXV0aEhvbGRlci5qYXZh) | `15.254% <0%> (+5.085%)` | `2% <0%> (Ã¸)` | :arrow_down: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `77.703% <0%> (+6.757%)` | `22% <0%> (+4%)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `86.4% <0%> (+8.8%)` | `35% <0%> (+7%)` | :arrow_up: |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `23.729% <0%> (+13.559%)` | `2% <0%> (+1%)` | :arrow_up: |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=footer). Last update [5ccfd00...8360cbe](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2573#issuecomment-291977600:3974,Power,Powered,3974,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2573#issuecomment-291977600,1,['Power'],['Powered']
Energy Efficiency,"code 50. Driver stacktrace:; 17/10/11 14:19:38 INFO spark.ExecutorAllocationManager: Existing executor 2 has been removed (new total is 0); 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203, took 19.909238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runComma",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:31515,schedul,scheduler,31515,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at org.apache.spark.storage.BlockManager.reportAllBlocks(BlockManager.scala:217); at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:236); at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:522); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308); at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180); at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 18/03/09 09:22:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/09 09:22:08 INFO SparkContext: Successfully stopped SparkContext; 09:22:08.389 INFO BaseRecalibratorSpark - Shutting down engine; [March 9, 2018 9:22:08 AM UTC] org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark done. Elapsed time: 61.53 minutes.; Runtime.totalMemory()=16815489024; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 0.0 failed 1 times, most recent failure: Lost task 8.0 in stage 0.0 (TID 8, localhost): ExecutorLostFa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515:2059,Schedul,ScheduledThreadPoolExecutor,2059,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515,2,['Schedul'],"['ScheduledFutureTask', 'ScheduledThreadPoolExecutor']"
Energy Efficiency,commit 558160 fails on PowerPC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2302:23,Power,PowerPC,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2302,1,['Power'],['PowerPC']
Energy Efficiency,"cotationFactory.createDefaultFuncotationsOnVariant(GencodeFuncotationFactory.java:499); 22 Jun 2023 14:54:27,163 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:217); 22 Jun 2023 14:54:27,164 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 22 Jun 2023 14:54:27,166 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:152); 22 Jun 2023 14:54:27,167 DEBUG: 		at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197); 22 Jun 2023 14:54:27,168 DEBUG: 		at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179); 22 Jun 2023 14:54:27,170 DEBUG: 		at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625); 22 Jun 2023 14:54:27,171 DEBUG: 		at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509); 22 Jun 2023 14:54:27,172 DEBUG: 		at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499); 22 Jun 2023 14:54:27,174 DEBUG: 		at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:921); 22 Jun 2023 14:54:27,175 DEBUG: 		at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 22 Jun 2023 14:54:27,177 DEBUG: 		at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:682); 22 Jun 2023 14:54:27,178 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); 22 Jun 2023 14:54:27,180 DEBUG: 		at com.github.discvrseq.walkers.ExtendedFuncotator.enqueueAndHandleVariant(ExtendedFuncotator.java:209); 22 Jun 2023 14:54:27,181 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1603412226:2901,Reduce,ReduceOps,2901,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1603412226,3,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"cratch/FPTVM/src/warp/pipelines/broad/annotation\_filtration/cromwell-executions/AnnotationFiltration/4e3bd06b-3018-4c94-ac98-feb78b924d1f/call-FilterFuncotations/shard-0/inputs/1333115969/104566-001-001.filtered.vcf.funcotated.vcf.gz \ ; --output 104566-001-001.filtered.vcf.filtered.vcf.gz \ ; --ref-version hg38 \ ; --allele-frequency-data-source gnomad --lenient true; ; ; ; ; . However, the command fails with the error message below:. ; ; ; ; [October 14, 2021 at 12:20:24 PM CEST] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 16.57 minutes. ; Runtime.totalMemory()=1134559232 ; java.lang.IllegalStateException: Duplicate key Gencode\_34\_annotationTranscript (attempted merging values ENST00000450305.2 and ENST00000456328.2) ; at java.base/java.util.stream.Collectors.duplicateKeyException(Collectors.java:133) ; at java.base/java.util.stream.Collectors.lambda$uniqKeysMapAccumulator$1(Collectors.java:180) ; at java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; at java.base/java.util.HashMap$KeySpliterator.forEachRemaining(HashMap.java:1603) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.AlleleFrequencyUtils.lambda$buildMaxMafRule$1(AlleleFrequencyUtils.java:30) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.lambda$checkFilter$0(FuncotationFilter.java:48) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:2322,Reduce,ReduceOps,2322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['Reduce'],['ReduceOps']
Energy Efficiency,create automated test environment on Power systems at http://osuosl.org/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1808:37,Power,Power,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1808,1,['Power'],['Power']
Energy Efficiency,createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1025); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.Fun,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680:2169,Reduce,ReduceOps,2169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680,1,['Reduce'],['ReduceOps']
Energy Efficiency,ctInputStream.readObject0(ObjectInputStream.java:1565); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2227); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2151); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2009); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1533); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:420); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:298); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:6063,schedul,scheduler,6063,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['schedul'],['scheduler']
Energy Efficiency,ctInputStream.readObject0(ObjectInputStream.java:1567); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:309); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:18862,schedul,scheduler,18862,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['schedul'],['scheduler']
Energy Efficiency,ction.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.SparkContext.runJob,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:14376,schedul,scheduler,14376,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,ctory.java:314); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:229); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:207); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.S,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:22632,Reduce,ReduceOps,22632,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,culateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePas,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6237:1934,Reduce,ReduceOps,1934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6237,1,['Reduce'],['ReduceOps']
Energy Efficiency,culateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePas,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1934,Reduce,ReduceOps,1934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300,1,['Reduce'],['ReduceOps']
Energy Efficiency,culateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-30T13:35:51.795082090Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-30T13:35:51.795253632Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.795448274Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePas,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1935,Reduce,ReduceOps,1935,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227,1,['Reduce'],['ReduceOps']
Energy Efficiency,"current monitor always says ""Records Processed Records/Minute""; this is less good than ; ""Reads Processed Reads/Minute""; ""Assembly Regions Processed Assembly Regions/Minute""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1943:8,monitor,monitor,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1943,1,['monitor'],['monitor']
Energy Efficiency,customizable labels in progress monitor,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1943:32,monitor,monitor,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1943,1,['monitor'],['monitor']
Energy Efficiency,cutor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **Driver stacktrace:** ; **at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)** ; **at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)** ; **at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)** ; **at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)** ; **at scala.Option.foreach(Option.scala:257)** ; **at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)** ; **at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)** ; **at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:46257,schedul,scheduler,46257,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,cutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:7842,schedul,scheduler,7842,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['schedul'],['scheduler']
Energy Efficiency,"cutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.TaskSetManager: Task 284 in stage 25.0 failed 4 times; aborting job; 18/01/12 20:38:37 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@23007ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(50,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(52,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(34,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(60,WrappedArray()); 20:38:37.897 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [January 12, 2018 8:38:37 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 42.74 minutes.; Runtime.totalMemory()=16692805632; org.apache.spark.SparkException: Job aborted due to stage failure: Task 284 in stage 25.0 failed 4 times, most recent failure: Lost task 284.3 in stage 25.0 (TID 43224, cw-test-w-6.c.broad-dsde-methods.internal, executor 7): java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.pro",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:5767,schedul,scheduler,5767,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,"d by some of the discussion and work by @mbabadi in #4558, I quickly revisited the revision of the ploidy model. The key difference is now we use the per-contig coverage *histogram* (rather than just the per-contig total coverage). This histogram conveys a lot more information and, with some naive filtering (see more discussion in #4558), provides relatively easy peaks to fit. I think this is a better solution than subsampling intervals and fitting a model that would require modeling per-interval bias. Another key change I added was to provide *per-genotype* priors, rather than per-contig priors. For the autosomes, this is immaterial, but it's extremely useful for the allosomes. That is, we currently provide per-contig priors like so:. ````; CONTIG PLOIDY_0 PLOIDY_1 PLOIDY_2 PLOIDY_3; 1 0.0 0.0 1.0 0.0; ...; X 0.01 0.48 0.48 0.01; Y 0.48 0.48 0.01 0.01; ````. However, note that this implies that X and XXY are just as probable as XX and XY! It's much more powerful to be able to specify *per-genotype* priors (although this requires a bit more bookkeeping when translating to implications for per-contig histograms):. ````; CONTIG_SET PLOIDY_STATE RELATIVE_PROBABILITY; (1) (2) 1.0; ...; (X,Y) (2,0) 1.0; (X,Y) (1,1) 1.0; (X,Y) (1,0) 0.01; (X,Y) (2,1) 0.01; (X,Y) (1,2) 0.01; (X,Y) (3,0) 0.01; ````. We then fit the per-contig coverage histograms across all samples with the appropriate negative-binomial distributions corresponding to a sparse mixture of genotypes, while accounting for 1) sample-specific depth (which determines the means of the negative-binomial distributions), 2) multiplicative contig-specific bias (which is mild, at least for WGS), and 3) additive sample-contig-specific mosaicism or bias (note that the above genotype priors imply that mosaicism/bias on top of a baseline of CN = 2 is the only deviation allowed for the autosomes, which is somewhat restrictive but greatly aids convergence). I put together a pure PyMC3 prototype that seems to work relatively wel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:977,power,powerful,977,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271,1,['power'],['powerful']
Energy Efficiency,d in https://github.com/samtools/htsjdk/pull/724. . ```; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337:1108,schedul,scheduler,1108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337,1,['schedul'],['scheduler']
Energy Efficiency,d); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); at org.apache.spark.rdd.RDD.count(RDD.scala:1158); at org.apache.spark.api.java.JavaRDDLike$cla,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:41213,schedul,scheduler,41213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,d); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); at org.apache.spark.rdd.RDD.count(RDD.scala:1158); at org.apache.spark.api.java.JavaRDDLike$cla,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:41959,schedul,scheduler,41959,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,d.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:18733,schedul,scheduler,18733,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,"d.RDD.iterator(RDD.scala:285); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.scheduler.Task.run(Task.scala:108); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.lang.Thread.run(Thread.java:745); ```; and in case I am missing anything in how I'm calling HaplotypeCallerSpark, here is the full command line we're using:; ```; gatk-launch --java-options '-Xms1000m -Xmx46965m -Djava.io.tmpdir=/mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2018-04-14-195952.723/root/variantcall/2/variantcall_batch_region/3/bcbiotx/tmpno7wyh' HaplotypeCallerSpark --reference /mnt/work/cwl/bcbio_validation_workflows/giab",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661:6041,schedul,scheduler,6041,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661,1,['schedul'],['scheduler']
Energy Efficiency,d.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.WellformedReadFilter.test(WellformedReadFilter.java:77); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.lambda$getReads$e4b35a40$1(GATKSparkTool.java:213); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool$$Lambda$93/2063469002.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.sca,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:2447,Reduce,ReduceOps,2447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"d020/fetchFileTemp6888440563594800088.tmp; 15/07/14 13:14:53 INFO executor.Executor: Adding file:/var/folders/xt/vq7wz8955r1401mv8w0f4zf9qbfwzl/T/louisb/spark-ccf49262-23e0-45d9-a273-0096f310c64a/userFiles-0909d070-1b0a-4cf7-8d86-e4144a2dd020/hellbender-all-GATK.4.alpha-413-g741d007-SNAPSHOT-spark.jar to class loader; 13:14:53.486 [Executor task launch worker-0] INFO org.broadinstitute.hellbender.engine.ReadsDataSource - Preparing intervals for traversal; 13:14:53.486 [Executor task launch worker-0] INFO org.broadinstitute.hellbender.engine.ReadsDataSource - Done preparing intervals for traversal; 13:14:53.486 [Executor task launch worker-0] INFO org.broadinstitute.hellbender.engine.ReadsDataSource - Preparing readers for traversal; 13:14:53.506 [Executor task launch worker-0] INFO org.broadinstitute.hellbender.engine.ReadsDataSource - Done preparing readers for traversal; 15/07/14 13:14:53 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 779 bytes result sent to driver; 15/07/14 13:14:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 403 ms on localhost (1/1); 15/07/14 13:14:53 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Stage 0 (aggregate at TransformTranslator.java:183) finished in 0.416 s; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at TransformTranslator.java:183, took 0.607813 s; 15/07/14 13:14:53 INFO spark.SparkPipelineRunner: Evaluating AnonymousParDo [ParDo]; 15/07/14 13:14:53 INFO spark.SparkPipelineRunner: Evaluating TextIO.Write [TextIO.Write]; 15/07/14 13:14:53 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at TransformTranslator.java:432; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Got job 1 (saveAsNewAPIHadoopFile at TransformTranslator.java:432) with 1 output partitions (allowLocal=false); 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Final stage: Stage 1(saveAsNe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:25120,schedul,scheduler,25120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['schedul'],['scheduler']
Energy Efficiency,dToGATKReadAdapter.getBase(SAMRecordToGATKReadAdapter.java:264); 	at org.broadinstitute.hellbender.tools.walkers.annotator.CountNs.doesReadHaveN(CountNs.java:61); 	at org.broadinstitute.hellbender.tools.walkers.annotator.CountNs.lambda$annotate$1(CountNs.java:46); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:174); 	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948); 	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:270); 	at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); 	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); 	at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.LongPipeline.reduce(LongPipeline.java:438); 	at java.util.stream.LongPipeline.sum(LongPipeline.java:396); 	at java.util.stream.ReferencePipeline.count(ReferencePipeline.java:526); 	at org.broadinstitute.hellbender.tools.walkers.annotator.CountNs.annotate(CountNs.java:46); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:268); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:192); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:233); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:232); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstit,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6336:1411,Reduce,ReduceOps,1411,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6336,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"dToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-CHMSampleHeadToHead/BenchmarkComparison/deb85607-d693-4232-a4da-0fb88dd29cad/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-CHMSampleHeadToHead/BenchmarkComparison/deb85607-d693-4232-a4da-0fb88dd29cad/call-BenchmarkVCFControlSample/Benchmark/c0877490-fd2d-4f42-bb92-f06210e94d95/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""84.33091111111112"",; ""CHM evalHCsystemhours"": ""0.18621944444444444"",; ""CHM evalHCwallclockhours"": ""61.43"",; ""CHM evalHCwallclockmax"": ""3.073069444444444"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-CHMSampleHeadToHead/BenchmarkComparison/deb85607-d693-4232-a4da-0fb88dd29cad/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-CHMSampleHeadToHead/BenchmarkComparison/deb85607-d693-4232-a4da-0fb88dd29cad/call-BenchmarkVCFTestSample/Benchmark/a15fdeb6-16e8-48d7-82cb-168726f4dc18/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1549231169:18345,monitor,monitoring,18345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1549231169,1,['monitor'],['monitoring']
Energy Efficiency,"da9b236b88b509; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:14:00 WARN scheduler.TaskSetManager: Lost task 16.0 in stage 0.0 (TID 2, scc-q15.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.coll",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:7276,schedul,scheduler,7276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,datanode:; namenode:. networks:; workbench:; external: true; ```; the datanodes and namenode and spark master and workers are all working.; My hardware resources are:; 16 core and 1Tb memory ssd and 56Gb ram for 3 machines. I have this problem when I launch the version(GATK) v4.0.4.0 but not with this version v4.0.2.0-4-gb59d863-SNAPSHOT:. >java.lang.IllegalStateException: Duplicate key -1; 	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); 	at java.util.HashMap.merge(HashMap.java:1253); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$mark$2142e97f$1(MarkDuplicatesSpark.java:82); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:4196,Reduce,ReduceOps,4196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"dd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:28 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 1.0 (TID 2, com2, executor 1, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Disabling executor 1.; 17/10/11 14:19:28 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 1); 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.; 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, com2, 38568); 17/10/11 14:19:28 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor; 17/10/11 14:19:28 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:17052,schedul,scheduler,17052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"dd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:37 INFO scheduler.TaskSetManager: Starting task 0.3 in stage 1.0 (TID 4, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Disabling executor 2.; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 1); 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, com2, 46254); 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor; 17/10/11 14:19:38 ERROR cluster.YarnScheduler: Lost executor 2 on com2: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:24065,schedul,scheduler,24065,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:07 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 3, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:07 WARN TaskSetManager:66 - Lost task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.coll",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:24865,schedul,scheduler,24865,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['schedul'],['scheduler']
Energy Efficiency,"de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:49 INFO TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:49 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 1, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.co",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:24152,schedul,scheduler,24152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['schedul'],['scheduler']
Energy Efficiency,"de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExten",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:34770,schedul,scheduler,34770,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['schedul'],['scheduler']
Energy Efficiency,"de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExt",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:34520,schedul,scheduler,34520,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['schedul'],['scheduler']
Energy Efficiency,de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:37986,schedul,scheduler,37986,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-ed279998-3783-4f41-8fe5-f44a4fac3ee4; ```. CountReads runs fine..... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:42881,schedul,scheduler,42881,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['schedul'],['scheduler']
Energy Efficiency,"de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-0bd07e00-4f6d-43bd-b9d2-b1999376c72b; ```. Just to verify, the non-spark version still runs fine with the compressed fasta.... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:42633,schedul,scheduler,42633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['schedul'],['scheduler']
Energy Efficiency,der$PrimitiveSamReaderToSamReaderAdapter.query(SamReader.java:550); at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.queryOverlapping(SamReader.java:417); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextIterator(SamReaderQueryingIterator.java:130); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.<init>(SamReaderQueryingIterator.java:69); at org.broadinstitute.hellbender.engine.ReadsPathDataSource.prepareIteratorsForTraversal(ReadsPathDataSource.java:412); at org.broadinstitute.hellbender.engine.ReadsPathDataSource.prepareIteratorsForTraversal(ReadsPathDataSource.java:389); at org.broadinstitute.hellbender.engine.ReadsPathDataSource.query(ReadsPathDataSource.java:352); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.readStream(CalibrateDragstrModel.java:915); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.lambda$null$11(CalibrateDragstrModel.java:556); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at org.broadinstitute.hellbender.tools.dragstr.InterleavingListSpliterator.forEachRemaining(InterleavingListSpliterator.java:87); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:952); at java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:926); at java.base/java.util.stream.AbstractTask.compute(AbstractTask.java:327); at java.base/java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:746); ... 5 more; ```. However it does work when running the tool single threaded with the exact same options. . #### Steps to reproduce; I've sadly been unable to create a reproducible example. I've only encountered this with non-public data which I can't share here. I'd be happy to run tests for you though.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8139:11356,Reduce,ReduceOps,11356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8139,6,['Reduce'],"['ReduceOps', 'ReduceTask']"
Energy Efficiency,der.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:978) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:805) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:789) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:474) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:475) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:530) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172) ; at org.broadinstitute.hellbender.tools.fu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651:4161,Reduce,ReduceOps,4161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"der/utils/MannWhitneyU.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9NYW5uV2hpdG5leVUuamF2YQ==) | `92.793% <92.593%> (+17.237%)` | `48 <48> (+21)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `72.078% <0%> (-1.948%)` | `35% <0%> (Ã¸)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `93.75% <0%> (-1.563%)` | `21% <0%> (-1%)` | |; | [...titute/hellbender/tools/spark/sv/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkTWV0YWRhdGEuamF2YQ==) | `84.104% <0%> (+2.358%)` | `36% <0%> (+11%)` | :arrow_up: |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `42.989% <0%> (+4.441%)` | `46% <0%> (+18%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=footer). Last update [c350a09...3b4f53e](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2605#issuecomment-294213579:3261,Power,Powered,3261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2605#issuecomment-294213579,1,['Power'],['Powered']
Energy Efficiency,"dexedFeatureReader.java:127); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:120); at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:350); ... 14 more; Caused by: java.lang.IllegalStateException: Duplicate key 0; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1254); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec.readActualHeader(XsvLocatableTableCodec.java:341); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec.readActualHeader(XsvLocatableTableCodec.java:64); at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:79); at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:37); at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:261); ... 18 more; ```. java version:; ```; java -version; openjdk version ""1.8.0_222""; OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1~deb9u1-b10); OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode); ```; I added the cadd folder into data source folder like the structure mentioned in document:; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223:3342,Reduce,ReduceOps,3342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223,1,['Reduce'],['ReduceOps']
Energy Efficiency,"dinstitute.hellbender.engine.spark.datasources.VariantsSparkSink.lambda$writeVariantsSingle$516343c4$1(VariantsSparkSink.java:127); 	at org.apache.spark.api.java.JavaRDDLike.$anonfun$mapPartitions$1(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858); 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:56); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:56); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:56); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93); 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166); 	at org.apache.spark.scheduler.Task.run(Task.scala:141); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620); 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64); 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:93); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635); 	at java.base/java.lang.Thread.run(Thread.java:833); ``` . #### Steps to reproduce; Run HaplotypeCallerSpark multiple times, it had a chance to fail.; Looks like the method ensureCapacity of GenotypesCache is not synchroni",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8961:3878,schedul,scheduler,3878,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8961,1,['schedul'],['scheduler']
Energy Efficiency,dinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector.lambda$inferSvAndWriteVCF$14707a88$1(CpxVariantDetector.java:60); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); ```. We should fix this before turning on the new variant interpretation code.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260:7607,schedul,scheduler,7607,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260,2,['schedul'],['scheduler']
Energy Efficiency,discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935); at org.apache.spark.rdd.RD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:8513,schedul,scheduler,8513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['schedul'],['scheduler']
Energy Efficiency,"dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 10; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2899.968; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 11; cpu cores	: 14; apicid		: 22; initial apicid	: 22; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 11; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 12; cpu cores	: 14; apicid		: 24; initial apicid	: 24; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat ps",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:55185,monitor,monitor,55185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['monitor'],['monitor']
Energy Efficiency,"dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 11; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 12; cpu cores	: 14; apicid		: 24; initial apicid	: 24; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 12; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 13; cpu cores	: 14; apicid		: 26; initial apicid	: 26; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat ps",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:56360,monitor,monitor,56360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['monitor'],['monitor']
Energy Efficiency,"dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 12; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 13; cpu cores	: 14; apicid		: 26; initial apicid	: 26; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 13; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 14; cpu cores	: 14; apicid		: 28; initial apicid	: 28; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat ps",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:57535,monitor,monitor,57535,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['monitor'],['monitor']
Energy Efficiency,"dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 13; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 14; cpu cores	: 14; apicid		: 28; initial apicid	: 28; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 14; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 1; siblings	: 14; core id		: 0; cpu cores	: 14; apicid		: 32; initial apicid	: 32; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:58710,monitor,monitor,58710,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['monitor'],['monitor']
Energy Efficiency,"dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4803.25; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 23; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2899.968; cache size	: 17920 KB; physical id	: 1; siblings	: 14; core id		: 10; cpu cores	: 14; apicid		: 52; initial apicid	: 52; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4803.25; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 24; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2899.968; cache size	: 17920 KB; physical id	: 1; siblings	: 14; core id		: 11; cpu cores	: 14; apicid		: 54; initial apicid	: 54; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat ps",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:70451,monitor,monitor,70451,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['monitor'],['monitor']
Energy Efficiency,"dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4803.25; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 24; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2899.968; cache size	: 17920 KB; physical id	: 1; siblings	: 14; core id		: 11; cpu cores	: 14; apicid		: 54; initial apicid	: 54; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4803.25; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 25; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2899.968; cache size	: 17920 KB; physical id	: 1; siblings	: 14; core id		: 12; cpu cores	: 14; apicid		: 56; initial apicid	: 56; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat ps",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:71626,monitor,monitor,71626,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['monitor'],['monitor']
Energy Efficiency,"dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4803.25; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 25; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2899.968; cache size	: 17920 KB; physical id	: 1; siblings	: 14; core id		: 12; cpu cores	: 14; apicid		: 56; initial apicid	: 56; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4803.25; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 26; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2899.875; cache size	: 17920 KB; physical id	: 1; siblings	: 14; core id		: 13; cpu cores	: 14; apicid		: 58; initial apicid	: 58; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat ps",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:72801,monitor,monitor,72801,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['monitor'],['monitor']
Energy Efficiency,"dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4803.25; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 26; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2899.875; cache size	: 17920 KB; physical id	: 1; siblings	: 14; core id		: 13; cpu cores	: 14; apicid		: 58; initial apicid	: 58; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4803.25; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 27; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2899.687; cache size	: 17920 KB; physical id	: 1; siblings	: 14; core id		: 14; cpu cores	: 14; apicid		: 60; initial apicid	: 60; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat ps",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:73976,monitor,monitor,73976,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['monitor'],['monitor']
Energy Efficiency,"dpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.131.101.145:54024) with ID 1; 17/10/13 18:11:48 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1); 17/10/13 18:11:48 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 4877 bytes); 17/10/13 18:11:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:45501 with 366.3 MB RAM, BlockManagerId(1, com2, 45501, None); 17/10/13 18:11:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:45501 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:51 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:45501 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4638 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.668 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: running: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: failed: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.8 KB, free 365.9 MB); 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KB, free 365.8 MB); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:44818 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 I",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:19143,schedul,scheduler,19143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['schedul'],['scheduler']
Energy Efficiency,"dsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `93.103% <100%> (+1.103%)` | `8 <1> (+1)` | :arrow_up: |; | [...adinstitute/hellbender/utils/spark/SparkUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zcGFyay9TcGFya1V0aWxzLmphdmE=) | `71.154% <63.158%> (-4.604%)` | `9 <5> (+5)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `95.313% <0%> (+1.563%)` | `22% <0%> (+1%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (Ã¸)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.909% <0%> (+3.831%)` | `46% <0%> (+11%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=footer). Last update [2ecdef4...71a1b94](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2419#issuecomment-293289091:3280,Power,Powered,3280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2419#issuecomment-293289091,1,['Power'],['Powered']
Energy Efficiency,duler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:31967,schedul,scheduler,31967,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,duler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.sch,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:13007,schedul,scheduler,13007,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"dulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Cancelling stage 5; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage cancelled; 21/04/13 07:32:25 INFO DAGScheduler: ResultStage 5 (runJob at SparkHadoopWriter.scala:78) failed in 0.353 s due to Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 105, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Sequence [VC HC @ chr4_GL000008v2_random:7168-7691 Q. of type=SYMBOLIC alleles=[T*, <NON_REF>] attr={END=7691} GT=[[NA12878 T*/T* GQ 0 DP 0 PL 0,0,0 {MIN_DP=0}]] filters= added out of order currentReferenceIndex: 25, referenceIndex:37; at htsjdk.tribble.index.tabix.AllRefsTabixIndexCreator.addFeature(AllRefsTabixIndexCreator.java:79); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:203); at htsjdk.variant.variantconte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:11901,schedul,scheduler,11901,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,"e from master. I've renamed this issue to make the problem we're trying to solve clearer. @akiezun @lbergelson @LeeTL1220 @vdauwera would you vote for any of the above options? Do you have alternate proposals that solve the same problem and you think are better? Should we seek professional (release engineering) help?. ---. @akiezun commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215761749). only 4 seems remotely sane to me. ---. @vdauwera commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215779225). 3 and 4 both produce an acceptable result for me but I could see 3 being too hard on the dev team. So I'll go with 4. I think the inconvenience of cutting a special cherry picked release is enough to dissuade casual/unnecessary releases, but low enough to not be a blocker if we really do need to release a hot fix. ---. @LeeTL1220 commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215793338). Cherry-picking sounds awful to me, but not as awful as the others... I could do number three. ---. @akiezun commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215801993). To clarify my position though - I think we should just never need it and simply coordinate between the various tool teams on a common release schedule. The toolkit would then be released because all tool are ready. ---. @droazen commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215816252). @akiezun We should strive for this, but in practice there will be times when Lee needs a release and we're not ready for one, and we need to have a plan in place to deal with that scenario. Since options 3 and 4 seem to be the only options with votes, let's sit down next week and discuss in detail the pain points of these two options, and make a choice between them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:6040,schedul,schedule,6040,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,1,['schedul'],['schedule']
Energy Efficiency,e or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112)**; at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more; ```. Thank you. Full log:; ````; 17:54:54.447 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PRO,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:2020,schedul,scheduler,2020,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,"e typically used to indicate adapter sequence. See reply to jhess in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/35120#Comment_35120>:. > That's correct, Q2 bases are considered to be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3540:1145,adapt,adapter,1145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540,1,['adapt'],['adapter']
Energy Efficiency,e(BucketUtils.java:112)**; at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more; ```. Thank you. Full log:; ````; 17:54:54.447 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop conn,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:2099,schedul,scheduler,2099,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,e(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513:7304,schedul,scheduler,7304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513,1,['schedul'],['scheduler']
Energy Efficiency,e(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:7315,schedul,scheduler,7315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['schedul'],['scheduler']
Energy Efficiency,e(SparkHadoopWriter.scala:358); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:132); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:16974,schedul,scheduler,16974,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,"e. This seemed to fix the index out of bounds error, but the job then failed at the filtering step, with the following error:. ```; java.lang.IllegalArgumentException: log10p: Log10-probability must be 0 or less; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); 	at org.broadinstitute.hellbender.utils.MathUtils.log10BinomialProbability(MathUtils.java:934); 	at org.broadinstitute.hellbender.utils.MathUtils.binomialProbability(MathUtils.java:927); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:56); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 	at or",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098:5882,Reduce,ReduceOps,5882,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098,1,['Reduce'],['ReduceOps']
Energy Efficiency,e.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.AlleleFrequencyUtils.lambda$buildMaxMafRule$1(AlleleFrequencyUtils.java:30) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.lambda$checkFilter$0(FuncotationFilter.java:48) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:558) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.checkFilter(FuncotationFilter.java:49) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$null$0(FilterFuncotations.java:194) ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:176) ; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$null$1(FilterFuncotations.java:196) ; at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:3759,reduce,reduce,3759,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['reduce'],['reduce']
Energy Efficiency,"e.hellbender.Main.main(Main.java:291); Caused by: htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: Duplicate key 0, for input source: cadd.config; at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:263); at htsjdk.tribble.TribbleIndexedFeatureReader.&lt;init&gt;(TribbleIndexedFeatureReader.java:102); at htsjdk.tribble.TribbleIndexedFeatureReader.&lt;init&gt;(TribbleIndexedFeatureReader.java:127); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:120); at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:350); ... 14 more; Caused by: java.lang.IllegalStateException: Duplicate key 0; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1254); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec.readActualHeader(XsvLocatableTableCodec.java:341); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec.readActualHeader(XsvLocatableTableCodec.java:64); at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:79); at htsjdk.tribble.AsciiFeat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223:2887,Reduce,ReduceOps,2887,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223,1,['Reduce'],['ReduceOps']
Energy Efficiency,e.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.correctGenotypePloidy(JointGermlineCNVSegmentation.java:701); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.prepareGenotype(JointGermlineCNVSegmentation.java:682); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.lambda$createDepthOnlyFromGCNVWithOriginalGenotypes$4(JointGermlineCNVSegmentation.java:666); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.ArrayList$Itr.forEachRemaining(ArrayList.java:1033); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.createDepthOnlyFromGCNVWithOriginalGenotypes(JointGermlineCNVSegmentation.java:667); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.apply(JointGermlineCNVSegmentation.java:280); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:133); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.afterTraverse(MultiVariantWalkerGroupedOnStart.java:193); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:166); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1095); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8164:1615,Reduce,ReduceOps,1615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8164,1,['Reduce'],['ReduceOps']
Energy Efficiency,"e0 in memory on 10.131.101.159:34044 (size: 2.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/11 14:19:18 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.2 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:34044 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004; 17/10/11 14",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:11295,schedul,scheduler,11295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.TaskSetManager: Task 284 in stage 25.0 failed 4 times; aborting job; 18/01/12 20:38:37 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@23007ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(50,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(52,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:4623,schedul,scheduler,4623,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGSched,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:7999,schedul,scheduler,7999,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,"e40-2025-46fd-9aa0-d591a3799007/call-CHMSampleHeadToHead/BenchmarkComparison/f65a7960-7b66-4a5d-a346-bd188a1b3830/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-CHMSampleHeadToHead/BenchmarkComparison/f65a7960-7b66-4a5d-a346-bd188a1b3830/call-BenchmarkVCFControlSample/Benchmark/8d0e47ca-66f5-42a0-8785-6aa8d2db2663/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""80.5165222222222"",; ""CHM evalHCsystemhours"": ""0.1713305555555555"",; ""CHM evalHCwallclockhours"": ""53.10978888888891"",; ""CHM evalHCwallclockmax"": ""2.7458416666666667"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-CHMSampleHeadToHead/BenchmarkComparison/f65a7960-7b66-4a5d-a346-bd188a1b3830/call-EVALRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-CHMSampleHeadToHead/BenchmarkComparison/f65a7960-7b66-4a5d-a346-bd188a1b3830/call-BenchmarkVCFTestSample/Benchmark/96c96714-3ac6-4d2b-a79c-57086cda6373/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-EXOME1Sampl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815:11455,monitor,monitoring,11455,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815,1,['monitor'],['monitoring']
Energy Efficiency,e: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:9093,schedul,scheduler,9093,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['schedul'],['scheduler']
Energy Efficiency,eArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2281); at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83); ... 27 more; Caused by: java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; at java.base/jdk.internal.util.ArraysSupport.hugeLength(ArraysSupport.java:649); at java.base/jdk.internal.util.ArraysSupport.newLength(ArraysSupport.java:642); at java.base/java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:100); at java.base/java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:130); at org.apache.spark.util.ByteBufferOutputStream.write(ByteBuffer,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:32829,schedul,scheduler,32829,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,eFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:152); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:924); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.Iterator.forEa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680:3759,Reduce,ReduceOps,3759,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680,1,['Reduce'],['ReduceOps']
Energy Efficiency,"eHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:41.089 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:45.460 WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:45.460 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:11:09.609 WARN TaskMemoryManager:381 - leak 166.6 MB memory from org.apache.spark.util.collection.ExternalAppendOnlyMap@60a3c432; 00:11:09.611 ERROR Executor:91 - Exception in task 15.0 in stage 1.0 (TID 519); java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:1595,Reduce,ReduceOps,1595,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Reduce'],['ReduceOps']
Energy Efficiency,"eProgram.doWork(SparkCommandLineProgram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Sequence [VC HC @ chr4_GL000008v2_random:7168-7691 Q. of type=SYMBOLIC alleles=[T*, <NON_REF>] attr={END=7691} GT=[[NA12878 T*/T* GQ 0 DP 0 PL 0,0,0 {MIN_DP=0}]] filters= added out of order currentReferenceIndex: 25, referenceIndex:37; at htsjdk.tribble.index.tabix.AllRefsTabixIndexCreator.addFeature(AllRefsTabixIndexCreator.java:79); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:21495,schedul,scheduler,21495,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,eSpark. ### Affected version(s); - [x] Latest public release version 4.1.0.0; - [ ] Latest master branch as of [date of test?]. ### Description . ```; java.lang.IllegalArgumentException: Interval NC_007605:1-171823 not within the bounds of a contig in the provided dictionary; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.engine.Shard.divideIntervalIntoShards(Shard.java:87); 	at org.broadinstitute.hellbender.engine.Shard.divideIntervalIntoShards(Shard.java:66); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.lambda$runTool$0(ReadsPipelineSpark.java:221); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.runTool(ReadsPipelineSpark.java:222); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5644:1053,Reduce,ReduceOps,1053,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5644,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"eadObject(ObjectInputStream.java:422); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:8521,schedul,scheduler,8521,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['schedul'],['scheduler']
Energy Efficiency,eader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at org.seqdoop.hadoop_bam.BAMRecordReader.nextKeyValue(BAMRecordReader.java:225); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:182); 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.sca,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:7498,Reduce,ReduceOps,7498,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,eatureDataSource.java:320); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:300); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:256); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:230); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:214); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.compu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:2743,Reduce,ReduceOps,2743,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,4,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,eatureDataSource.java:324); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:304); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:256); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:230); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:214); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.compu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5979#issuecomment-498620174:2152,Reduce,ReduceOps,2152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5979#issuecomment-498620174,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"ect(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). 11:00:53.977 INFO DAGScheduler - Job 1 failed: runJob at SparkHadoopWriter.scala:83, took 3.799268 s; 11:00:53.979 ERROR SparkHadoopWriter - Aborting job job_202408111100502620487673658411251_0021.; org.apache.spark.SparkException: Job aborted due to stage failure: Task serialization failed: java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; at java.base/jdk.internal.util.ArraysSupport.hugeLength(ArraysSupport.java:649); at java.base/jdk.internal.util.ArraysSupport.newLength(ArraysSupport.java:642); at java.base/java.io.ByteArrayOutputStream.ensureCapac",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:8056,schedul,scheduler,8056,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,ect(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collectio,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:12380,schedul,scheduler,12380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,ect(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.sc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:31099,schedul,scheduler,31099,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,ect(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 11:00:54.334 INFO ShutdownHookManager - Shutdown hook called; 11:00:54.335 INFO ShutdownHookManager - Deleting directory /raid/tmp/d6/c66ba827e22dbc38625af1cbc85adc/tmp/spark-f9c7c336-4e98-4fcc-855b-ba8a5a29e074; ```. The first lines of the log file:; ```; vm.max_map_count = 2147483642; Using GATK jar /Public/Everythings/misc/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -XX:+UnlockDiagnosticVMOptions -XX:GCLockerRetryAllocationCount=96 -XX:+UseNUMA -XX:+UseZGC -Xmx1794G -jar /Public/Everythings/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:36970,schedul,scheduler,36970,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,ectOutputStream.java:1181) ~[?:?]; at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1572) ~[?:?]; at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1529) ~[?:?]; at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438) ~[?:?]; at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181) ~[?:?]; at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350) ~[?:?]; at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-l,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:22807,schedul,scheduler,22807,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,ectOutputStream.java:1572) ~[?:?]; at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1529) ~[?:?]; at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438) ~[?:?]; at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181) ~[?:?]; at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1572) ~[?:?]; at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1529) ~[?:?]; at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438) ~[?:?]; at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181) ~[?:?]; at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350) ~[?:?]; at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:22554,schedul,scheduler,22554,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"ecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:35488,monitor,monitor,35488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,3,"['Schedul', 'monitor']","['SchedulerExtensionServices', 'monitor']"
Energy Efficiency,ed time: 0.34 minutes.; Runtime.totalMemory()=1106771968; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException; Serialization trace:; genotypes (htsjdk.variant.variantcontext.VariantContext); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:9950,schedul,scheduler,9950,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,"ed(App.scala:80); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at scala.App.main(App.scala:80); 	at scala.App.main$(App.scala:78); 	at womtool.WomtoolMain$.main(WomtoolMain.scala:24); 	at womtool.WomtoolMain.main(WomtoolMain.scala); ```. for pon; ```; Exception in thread ""main"" wdl.draft2.parser.WdlParser$SyntaxError: Unrecognized token on line 151, column 69:. gatk GenomicsDBImport --genomicsdb-workspace-path pon_db -R ~{ref_fasta} -V ~{sep=' -V ' input_vcfs} -L ~{intervals}; ^; 	at wdl.draft2.parser.WdlParser.unrecognized_token(WdlParser.java:6975); 	at wdl.draft2.parser.WdlParser.lex(WdlParser.java:7048); 	at wdl.draft2.model.AstTools$.getAst(AstTools.scala:263); 	at wdl.draft2.model.WdlNamespace$.$anonfun$load$1(WdlNamespace.scala:170); 	at scala.util.Try$.apply(Try.scala:213); 	at wdl.draft2.model.WdlNamespace$.load(WdlNamespace.scala:169); 	at wdl.draft2.model.WdlNamespace$.loadUsingSource(WdlNamespace.scala:161); 	at wdl.draft2.model.WdlNamespaceWithWorkflow$.load(WdlNamespace.scala:630); 	at womtool.graph.GraphPrint$.generateWorkflowDigraph(GraphPrint.scala:19); 	at womtool.WomtoolMain$.graph(WomtoolMain.scala:131); 	at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:54); 	at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:162); 	at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:167); 	at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:24); 	at scala.Function0.apply$mcV$sp(Function0.scala:39); 	at scala.Function0.apply$mcV$sp$(Function0.scala:39); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17); 	at scala.App.$anonfun$main$1$adapted(App.scala:80); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at scala.App.main(App.scala:80); 	at scala.App.main$(App.scala:78); 	at womtool.WomtoolMain$.main(WomtoolMain.scala:24); 	at womtool.WomtoolMain.main(WomtoolMain.scala); ```. Am I using womtool wrong, or is there a bug with it, or is this an issue with wdls?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6261:4916,adapt,adapted,4916,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6261,1,['adapt'],['adapted']
Energy Efficiency,ed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=false never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.mixed.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:4706,monitor,monitorThreadEfficiency,4706,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834,1,['monitor'],['monitorThreadEfficiency']
Energy Efficiency,ed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=true never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.mixed.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/VQSR.AStest.input.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false keepOriginalDP=false mendelianViola,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:1598,monitor,monitorThreadEfficiency,1598,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834,1,['monitor'],['monitorThreadEfficiency']
Energy Efficiency,edBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:8408,schedul,scheduler,8408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['schedul'],['scheduler']
Energy Efficiency,eduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2281); at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83); ... 27 more; Caused by: java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; at java.base/jdk.internal.util.ArraysSupport.hugeLength(ArraysSupport.java:649); at java.base/jdk.internal.util.Arrays,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:32549,schedul,scheduler,32549,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"eduler.TaskSetManager: Starting task 4.0 in stage 6.0 (TID 519, localhost, executor 1, partition 4, NODE_LOCAL, 5317 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 6.0 (TID 520, localhost, executor 2, partition 5, NODE_LOCAL, 5598 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 6.0 (TID 521, localhost, executor 1, partition 6, NODE_LOCAL, 5315 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 6.0 (TID 522, localhost, executor 2, partition 7, NODE_LOCAL, 5316 bytes); 18/09/08 10:32:49 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:37617 (size: 59.2 KB, free: 2004.5 MB); 18/09/08 10:32:49 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:45786 (size: 59.2 KB, free: 2004.5 MB); 18/09/08 10:32:50 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:37617 (size: 9.0 B, free: 2004.5 MB); 18/09/08 10:32:50 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 6.0 (TID 523, localhost, executor 1, partition 8, NODE_LOCAL, 5604 bytes); 18/09/08 10:32:50 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 6.0 (TID 524, localhost, executor 1, partition 9, NODE_LOCAL, 5598 bytes); 18/09/08 10:32:50 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 6.0 (TID 515, localhost, executor 1): java.lang.NullPointerException; 	at org.broadinstitute.hellbender.utils.read.markduplicates.sparkrecords.EmptyFragment.<init>(EmptyFragment.java:35); 	at org.broadinstitute.hellbender.utils.read.markduplicates.sparkrecords.MarkDuplicatesSparkRecord.newEmptyFragment(MarkDuplicatesSparkRecord.java:37); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$null$0(MarkDuplicatesSparkUtils.java:114); 	at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5169:1875,schedul,scheduler,1875,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5169,1,['schedul'],['scheduler']
Energy Efficiency,eduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:13622,schedul,scheduler,13622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"ee#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9mZXJtaS9GZXJtaUxpdGVBc3NlbWJsZXIuamF2YQ==) | `80.645% <80.645%> (Ã¸)` | `8 <8> (?)` | |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `92.308% <Ã¸> (+0.447%)` | `28% <Ã¸> (+28%)` | :white_check_mark: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `87.097% <Ã¸> (+0.986%)` | `59% <Ã¸> (+59%)` | :white_check_mark: |; | [...adinstitute/hellbender/tools/spark/sv/SVUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlV0aWxzLmphdmE=) | `38.462% <Ã¸> (+5.52%)` | `12% <Ã¸> (+12%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2381?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2381?src=pr&el=footer). Last update [8a42977...d6fb1ba](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2381#issuecomment-276803321:3433,Power,Powered,3433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2381#issuecomment-276803321,1,['Power'],['Powered']
Energy Efficiency,efficient queries for pet data into DATA table,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7478:0,efficient,efficient,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7478,1,['efficient'],['efficient']
Energy Efficiency,egate(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1136); 	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24.apply(RDD.scala:1136); 	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1137); 	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1137); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 19/03/26 20:02:39 INFO ShutdownHookManager: Shutdown hook called; 19/03/26 20:02:39 INFO ShutdownHookManager: Deleting directory /docker/working/7dd5e9aa-fa24-45ca-9979-13623c0ff8d5/a0d4bfdf-66b4-47af-b002-3c3935a7b633/spark-44911f4d-4d54-42b0-b6d1-35614170c1fc; Using GATK jar /docker/reference/Apps/GATK/4.1.0.0/gatk-package-4.1.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:6743,schedul,scheduler,6743,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['schedul'],['scheduler']
Energy Efficiency,"el=desc) will **decrease** coverage by `-<.001%`.; > The diff coverage is `75%`. ```diff; @@ Coverage Diff @@; ## master #2366 +/- ##; ===============================================; - Coverage 76.201% 76.201% -<.001% ; - Complexity 10808 10812 +4 ; ===============================================; Files 750 750 ; Lines 39417 39421 +4 ; Branches 6858 6859 +1 ; ===============================================; + Hits 30036 30039 +3 ; Misses 6775 6775 ; - Partials 2606 2607 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2366?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...75c14f4c17c957aa969a69a94c966fad3d5c8f1d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <Ã¸> (Ã¸)` | `0 <Ã¸> (Ã¸)` | :x: |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...75c14f4c17c957aa969a69a94c966fad3d5c8f1d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `92.568% <75%> (-0.488%)` | `74 <2> (+3)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2366?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2366?src=pr&el=footer). Last update [f45f6a5...75c14f4](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...75c14f4c17c957aa969a69a94c966fad3d5c8f1d?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2366#issuecomment-276527211:1915,Power,Powered,1915,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2366#issuecomment-276527211,1,['Power'],['Powered']
Energy Efficiency,"el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnMuamF2YQ==) | `90.71% <0%> (-0.43%)` | `100% <0%> (-1%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `87.3% <0%> (-0.31%)` | `244% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (Ã¸)` | `2% <0%> (Ã¸)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (+0.47%)` | `33% <0%> (Ã¸)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `80% <0%> (+30%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=footer). Last update [7c24e67...43708f1](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576:3591,Power,Powered,3591,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576,1,['Power'],['Powered']
Energy Efficiency,ellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:9438,schedul,scheduler,9438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['schedul'],['scheduler']
Energy Efficiency,ellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:10295,schedul,scheduler,10295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,emoryStore.scala:217); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1661); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1649); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1648); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1648); 	at org.apache.sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:3245,schedul,scheduler,3245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['schedul'],['scheduler']
Energy Efficiency,"emoved TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88) finished in 0.566 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Job 0 finished: runJob at SparkHadoopMapReduceWriter.scala:88, took 9.524571 s; 17/10/13 18:11:53 INFO io.SparkHadoopMapReduceWriter: Job job_20171013181144_0009 committed.; 17/10/13 18:11:53 INFO server.AbstractConnector: Stopped Spark@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:53 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/13 18:11:54 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 17/10/13 18:11:54 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/13 18:11:54 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/13 18:11:54 INFO memory.MemoryStore: MemoryStore cleared; 17/10/13 18:11:54 INFO storage.BlockManager: BlockManager stopped; 17/10/13 18:11:54 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/13 18:11:54 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/13 18:11:54 INFO spark.SparkContext: Successfully stopped SparkContext; 18:11:54.552 INFO PrintReadsSpark - Shutting down engine; [October 13, 2017 6:11:54 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.35 minutes.; Runtime.totalMemory()=806354944; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /gatk4/output_3.bam becau",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:22224,Schedul,SchedulerExtensionServices,22224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['Schedul'],['SchedulerExtensionServices']
Energy Efficiency,"en.); ; ```bash; ./gatk-launch FindBreakpointEvidenceSpark \; -I hdfs:///user/$USER/broad-svdev-test-data/data/NA12878_PCR-_30X.bam \; -O hdfs:///user/$USER/broad-svdev-test-data/assembly \; --exclusionIntervals hdfs:///user/$USER/broad-svdev-test-data/reference/GRCh37.kill.intervals \; --kmersToIgnore hdfs:///user/$USER/broad-svdev-test-data/reference/Homo_sapiens_assembly38.dups \; -- \; --sparkRunner SPARK --sparkMaster yarn-client --sparkSubmitCommand spark2-submit\; --driver-memory 16G \; --num-executors 5 \; --executor-cores 7 \; --executor-memory 25G; ```. What does FindBreakpointEvidenceSpark do, from the perspective of Spark?. * [runTool] filter out secondary and supplementary alignments; * [getMappedQNamesSet] filter out duplicate reads, reads that failed vendor checks, unmapped reads; * Job 0 [ReadMetadata] mapPartitions to find partition stats; * Job 1 [getIntervals] filter and multiple map partitions to find breakpoint intervals ; * Job 2 [removeHighCoverageIntervals] mapPartitionsToPair to find coverage for each interval, then reduceByKey; * Job 3 [getQNames] mapPartitions; * Job 4 [addAssemblyQNames -> getKmerIntervals] mapPartitionsToPair, then reduceByKey, then mapPartitions; * Job 5 [getAssemblyQNames] mapPartitions twice and a collect; * Job 6 [generateFastqs] mapPartitions and combineByKey, then write FASTQ to files. A few observations:; * Jobs 0,1,3 are simple map jobs - very quick 1-2 mins each.; * Job 2 is a simple MR, with a tiny shuffle to sum by key (<1MB of shuffle data); * Job 4 takes a bit longer longer (3min), and shuffles ~3GB. This is a lot faster than when I ran it before with less memory, when it took 9 min. Is it creating a lot of garbage? If you wanted to speed things up you might look at what this is doing on a local machine and see if there are any opportunities to improve CPU efficiency.; * Job 5 takes ~8 mins, and has no shuffle. CPU intensive processing again?; * Job 6 take a little over 3 mins, shuffling ~3GB. Overall, it loo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292171884:1344,reduce,reduceByKey,1344,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292171884,2,['reduce'],['reduceByKey']
Energy Efficiency,enFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more; 18/04/24 17:42:11 INFO ShutdownHookManager: Shutdown hook called; 18/04/24 17:42:11 INFO ShutdownHookManager: Deleting directory /tmp/username/spark-99d4cb79-5c44-425b-8f72-9476e7fd884c; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:45837,schedul,scheduler,45837,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:07 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 3, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:07 WARN TaskSetManager:66 - Lost task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseI",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:24794,schedul,scheduler,24794,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['schedul'],['scheduler']
Energy Efficiency,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:49 INFO TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:49 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 1, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.Autoclos",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:24081,schedul,scheduler,24081,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['schedul'],['scheduler']
Energy Efficiency,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:34699,schedul,scheduler,34699,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['schedul'],['scheduler']
Energy Efficiency,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:34449,schedul,scheduler,34449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['schedul'],['scheduler']
Energy Efficiency,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.schedule",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:37915,schedul,scheduler,37915,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-ed279998-3783-4f41-8fe5-f44a4fac3ee4; ```. CountReads runs fine..... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:42810,schedul,scheduler,42810,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['schedul'],['scheduler']
Energy Efficiency,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-0bd07e00-4f6d-43bd-b9d2-b1999376c72b; ```. Just to verify, the non-spark version still runs fine with the compressed fasta.... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:42562,schedul,scheduler,42562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['schedul'],['scheduler']
Energy Efficiency,"ence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:14:00 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 0.0 (TID 3, scc-q16.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 124511724, span 7265, expected MD5 cf58e0adc447a66b188474efc3c84a43; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.co",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:8791,schedul,scheduler,8791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,"ence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:13951,schedul,scheduler,13951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,"ence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:51 INFO TaskSetManager:54 - Starting task 4.1 in stage 0.0 (TID 5, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:51 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 4) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 6, scc-q01.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 7992 bytes); 2019-0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:27554,schedul,scheduler,27554,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['schedul'],['scheduler']
Energy Efficiency,"ence id 3, start 97885291, span 192458, expected MD5 ef90368731b6e0be845bc82cd92b0c6a; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 3.2 in stage 0.0 (TID 8, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 INFO TaskSetManager:54 - Lost task 1.2 in stage 0.0 (TID 6) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 2]; 2019-01-07 11:34:11 INFO TaskSetManager:54 - Starting task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:30909,schedul,scheduler,30909,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['schedul'],['scheduler']
Energy Efficiency,"eport; > Merging [#2550](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c8ede6ef810a3d9a05c7deb8052e27ca724ce8ba?src=pr&el=desc) will **increase** coverage by `0.003%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #2550 +/- ##; ===============================================; + Coverage 76.279% 76.282% +0.003% ; - Complexity 10891 10892 +1 ; ===============================================; Files 752 752 ; Lines 39590 39590 ; Branches 6925 6925 ; ===============================================; + Hits 30199 30200 +1 ; Misses 6768 6768 ; + Partials 2623 2622 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...recalibration/RecalibrationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL1JlY2FsaWJyYXRpb25Bcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `93.827% <100%> (Ã¸)` | `7 <0> (Ã¸)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=footer). Last update [c8ede6e...f810842](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2550#issuecomment-290461016:1803,Power,Powered,1803,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2550#issuecomment-290461016,1,['Power'],['Powered']
Energy Efficiency,"equence id 2, start 93470412, span 157, expected MD5 56b7844faa4e0c4f61fd6774df454b09; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:14:09 ERROR scheduler.TaskSetManager: Task 16 in stage 0.0 failed 4 times; aborting job; 13:14:09.675 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 1:14:09 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.97 minutes.; Runtime.totalMemory()=937426944; org.apache.spark.SparkException: Job aborted due to stage failure: Task 16 in stage 0.0 failed 4 times, most recent failure: Lost task 16.3 in stage 0.0 (TID 11, scc-q16.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:11958,schedul,scheduler,11958,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,er.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at or,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:14009,schedul,scheduler,14009,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"er.DAGScheduler: failed: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.1 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.3 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:34044 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244) (first 15 tasks are for partitions Vector(0)); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks; 17/10/11 14:19:27 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, com2, executor 1, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:38568 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to com2:35572; 17/10/11 14:19:27 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 134 bytes; 17/10/11 14:19:28 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1, com2, executor 1): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$26/353370312.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$an",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:15094,schedul,scheduler,15094,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1832); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1845); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1922); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1144); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150); 	at org.apache.spark.rdd.RDDOperationScope$.withScop,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:19511,schedul,scheduler,19511,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:911); 	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:264); 	at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3659:3861,schedul,scheduler,3861,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659,1,['schedul'],['scheduler']
Energy Efficiency,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:911); 	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337:1206,schedul,scheduler,1206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337,1,['schedul'],['scheduler']
Energy Efficiency,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1862); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1875); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1952); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1144); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150); 	at org.apache.spark.rdd.RDDOperationScope$.withScop,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:34378,schedul,scheduler,34378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:935); 	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:9536,schedul,scheduler,9536,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,2,['schedul'],['scheduler']
Energy Efficiency,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); 	at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); 	at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); 	at org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark.runTool(PathSeqPipelineSpark.java:245); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:387);,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:3275,schedul,scheduler,3275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['schedul'],['scheduler']
Energy Efficiency,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1026); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.reduce(RDD.scala:1008); 	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.with,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:2277,schedul,scheduler,2277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['schedul'],['scheduler']
Energy Efficiency,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.internal.io.SparkHadoopMapReduceWriter$.write(SparkHadoopMapReduceWriter.scala:88); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1085); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1085); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1085); 	at org.apache.spark.rdd.RDDOpe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545:10572,schedul,scheduler,10572,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545,1,['schedul'],['scheduler']
Energy Efficiency,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:938); 	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:306); 	at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:15799,schedul,scheduler,15799,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['schedul'],['scheduler']
Energy Efficiency,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:944); 	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:10393,schedul,scheduler,10393,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1661); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1649); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1648); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1648); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1882); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1820); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:944); 	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:4697,schedul,scheduler,4697,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['schedul'],['scheduler']
Energy Efficiency,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); 	at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78); 	... 87 more; Caused by: java.util.ConcurrentModificationException; 	at java.util.ArrayList.sort(ArrayList.java:1464); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.<init>(ReadThreadingAssembler.java:81); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerReadThreadingAssemblerArgumentCollection.makeReadThreadingAsse,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:11636,schedul,scheduler,11636,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,er.read(MapSerializer.java:162); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	... 38 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.internal.io.SparkHadoopMapReduceWriter$.write(SparkHadoopMapReduceWriter.scala:88); 	at org.apache.spark.rdd.PairRDDFunctions$$ano,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545:10235,schedul,scheduler,10235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545,1,['schedul'],['scheduler']
Energy Efficiency,er.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.fu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6774:3355,Reduce,ReduceOps,3355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,er.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.fu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069:2533,Reduce,ReduceOps,2533,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"er/tools/spark/pipelines/FlagStatSpark, and the class loader (instance of org/apache/spark/util/ChildFirstURLClassLoader) for the method's defining class, org/broadinstitute/hellbender/tools/FlagStat$FlagStatus, have different Class objects for the type org/broadinstitute/hellbender/utils/read/GATKRead used in the signature; at java.lang.invoke.MethodHandleNatives.resolve(Native Method); at java.lang.invoke.MemberName$Factory.resolve(MemberName.java:965); at java.lang.invoke.MemberName$Factory.resolveOrFail(MemberName.java:990); at java.lang.invoke.MethodHandles$Lookup.resolveOrFail(MethodHandles.java:1387); at java.lang.invoke.MethodHandles$Lookup.linkMethodHandleConstant(MethodHandles.java:1739); at java.lang.invoke.MethodHandleNatives.linkMethodHandleConstant(MethodHandleNatives.java:442); ... 41 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1273); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1264); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1263); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1263); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730); at scala.Option.foreach(Option.scala:236); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:730); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1457); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1418); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1315:5205,schedul,scheduler,5205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1315,8,['schedul'],['scheduler']
Energy Efficiency,erArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWFkVGhyZWFkaW5nQXNzZW1ibGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `94.118% <Ã¸> (Ã¸)` | `1 <0> (Ã¸)` | :arrow_down: |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `76.923% <Ã¸> (-0.946%)` | `34 <0> (-1)` | |; | [...walkers/haplotypecaller/HaplotypeCallerEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJFbmdpbmUuamF2YQ==) | `78.425% <100%> (Ã¸)` | `76 <0> (Ã¸)` | :arrow_down: |; | [...rs/haplotypecaller/graphs/AdaptiveChainPruner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQWRhcHRpdmVDaGFpblBydW5lci5qYXZh) | `95.349% <100%> (+0.111%)` | `16 <0> (Ã¸)` | :arrow_down: |; | [...hellbender/tools/walkers/mutect/Mutect2Engine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `90.173% <100%> (Ã¸)` | `65 <0> (Ã¸)` | :arrow_down: |; | [...otypecaller/HaplotypeCallerArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <100%> (Ã¸)` | `3 <1> (+1)` | :arrow_up: |; | [...r/tools/walkers/mutect/Mutect2Integrati,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5544#issuecomment-449424951:2272,Adapt,AdaptiveChainPruner,2272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5544#issuecomment-449424951,1,['Adapt'],['AdaptiveChainPruner']
Energy Efficiency,"erEndpoint stopped!; 18/05/01 14:23:29 INFO MemoryStore: MemoryStore cleared; 18/05/01 14:23:29 INFO BlockManager: BlockManager stopped; 18/05/01 14:23:29 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/05/01 14:24:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/05/01 14:25:36 INFO SparkContext: Successfully stopped SparkContext; 14:25:37.027 INFO PathSeqPipelineSpark - Shutting down engine; [May 1, 2018 2:25:37 PM EDT] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 37.98 minutes.; Runtime.totalMemory()=23999283200; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 1.0 failed 1 times, most recent failure: Lost task 20.0 in stage 1.0 (TID 891, localhost, executor driver): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 131031 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:2260,schedul,scheduler,2260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['schedul'],['scheduler']
Energy Efficiency,"erage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2521 +/- ##; ===============================================; + Coverage 76.256% 76.261% +0.005% ; Complexity 10864 10864 ; ===============================================; Files 750 750 ; Lines 39543 39543 ; Branches 6915 6915 ; ===============================================; + Hits 30154 30156 +2 ; + Misses 6771 6769 -2 ; Partials 2618 2618; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2521?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...notyper/GenotypeCalculationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/compare/7ad3c91b96448c4a867451b40b7ce6ae41cef690...2622598137d07ee362c7d98cb67e89862df0276e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUNhbGN1bGF0aW9uQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <Ã¸> (Ã¸)` | `2 <0> (Ã¸)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/7ad3c91b96448c4a867451b40b7ce6ae41cef690...2622598137d07ee362c7d98cb67e89862df0276e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (Ã¸)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2521?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2521?src=pr&el=footer). Last update [7ad3c91...2622598](https://codecov.io/gh/broadinstitute/gatk/compare/7ad3c91b96448c4a867451b40b7ce6ae41cef690...2622598137d07ee362c7d98cb67e89862df0276e?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2521#issuecomment-288757656:1979,Power,Powered,1979,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2521#issuecomment-288757656,1,['Power'],['Powered']
Energy Efficiency,erator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **Driver stacktrace:** ; **at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)** ; **at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)** ; **at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)** ; **at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)** ; **at scala.Option.foreach(Option.scala:257)** ; **at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)** ; **at org.apache.spark.sched,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:45786,schedul,scheduler,45786,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,erators$ConcatenatedIterator.getTopMetaIterator(Iterators.java:1379); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$ConcatenatedIterator.hasNext(Iterators.java:1395); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.fillCache(PushToPullIterator.java:71); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.advanceToNextElement(PushToPullIterator.java:58); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.(PushToPullIterator.java:37); 	at org.broadinstitute.hellbender.utils.variant.writers.GVCFBlockCombiningIterator.(GVCFBlockCombiningIterator.java:14); 	at org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSink.lambda$writeVariantsSingle$516343c4$1(VariantsSparkSink.java:127); 	at org.apache.spark.api.java.JavaRDDLike.$anonfun$mapPartitions$1(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858); 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:56); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:56); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:56); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93); 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166); 	at org.apache.spark.scheduler.Task.run(Task.scala:141); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620); 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8961:3230,adapt,adapted,3230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8961,1,['adapt'],['adapted']
Energy Efficiency,"erent results by the first filtering step (on intervals by interval median). @LeeTL1220 @davidbenjamin what is the ""official ReCapSeg"" behavior, and do we want to keep the current behavior? In general, I think all of the standardization (i.e., filtering/imputation/truncation/transformation) steps could stand some revisiting. Evaluation:. - [ ] Revisit standardization procedure by checking with simulated data. We should make sure that the centering of the data does not rescale the true copy ratio.; - [x] <s>Investigate the effect of keeping duplicates. I am still not sure why we do this, and it may have a more drastic impact on WGS data.</s> Turns out we don't keep duplicates for WGS; see #3367.; - [ ] Check that GC-bias-correction+PCA and PCA-only perform comparably, even at small bin sizes (~300bp). From what I've seen, this is true for larger bin sizes (~3kbp), so explicit GC-bias correction may not be necessary. (That is, even at these (purportedly) large bin sizes, the effect of the read-based GC-bias correction is obvious for those samples where it is important. However, the end result is not very different from PCA-only denoising with no GC-bias correction performed.); - [x] <s>Check that changing CBS alpha parameter sufficiently reduces hypersegmentation.</s> <s>Looks like the hybrid p-value calculation in DNACopy is not accurate enough to handle WGS-size data. (Also, it's relatively slow, taking ~30 minutes on ~10M intervals.) Even if I set alpha to 0, I still get a ridiculous number of segments! So I think it's finally time to scrap CBS. I'll look into other R segmentation packages that might give us a quick drop-in solution, but we may want to roll our own simple algorithm (which we will scrap anyway once the coverage model is in for somatic).</s> I've implemented a fast kernel-segmentation method that seems very promising, see below.; - [ ] Investigate performance vs. CGA ReCapSeg pipeline on THCA samples.; - [ ] Investigate concordance with Genome STRiP.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351:5171,reduce,reduces,5171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351,1,['reduce'],['reduces']
Energy Efficiency,"ersion(s); - 4.2 through 4.6. ### Description ; We tried to run GenotypeGVCFs from GATK 4.5 with `-all-sites` on a dataset with 120 samples and GRCh37 as the reference. Each run was limited to a single chromosome. All of them failed after consuming 3 TB of memory. Subsequently, I tried a smaller subset of 8 samples limiting the memory to 32 GB and all the runs failed after 3-10 Mbp depending on the chromosome. Finally, I randomly picked chromosome 9 and used GATK versions from 4.1 to 4.6 and only 4.1 did not experience the problem. It finished the whole chromosome (141 Mbp) with the max memory usage of around 8 GB. All others failed after 3-6 Mbp (Sorry, I used different memory settings for 4.5, so I did not include it.). ![memory_usage](https://github.com/user-attachments/assets/df354842-d420-4a99-b3d3-01fec64d18fd). Time is in seconds, memory is in MB. If I run the same command without `-all-sites`, the maximum memory usage is around 1.6 GB. #### Steps to reproduce. GenomicDB was created using the corresponding GATK version as:. ```; gatk --java-options ""-Xmx12000m"" GenomicsDBImport --genomicsdb-workspace-path tmp/genomicsdb44/9 \; --genomicsdb-shared-posixfs-optimizations --batch-size 120 --verbosity DEBUG \; -L 9 -V data/gatk/gvcf/9/1.g.vcf.gz -V data/gatk/gvcf/9/2.vcf.gz -V data/gatk/gvcf/9/3.g.vcf.gz \; -V data/gatk/gvcf/9/4.g.vcf.gz -V data/gatk/gvcf/9/5.g.vcf.gz -V data/gatk/gvcf/9/6.g.vcf.gz \; -V data/gatk/gvcf/9/7.g.vcf.gz -V data/gatk/gvcf/9/8.g.vcf.gz; ```. GenotypeGVCFs was run as:. ```; gatk --java-options ""-Xmx12g"" GenotypeGVCFs -R data/ref/hs37d5.fa.gz \; -V gendb://tmp/genomicsdb44/9 -O data/gatk/variants/9/raw44.vcf.gz -L 9 \; --tmp-dir ./tmp/tmp -all-sites; ```. All runs were performed with resource_monitor and it was instructed to kill the process if it consumes more than 14000 MB of memory. Thus, at least 2 GB was allocated for reading GenomicsDB. The size of the GenomicsDB on disk is around 3.1 GB for versions >=4.2 and 3.0 GB for version 4.1.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8989:1965,allocate,allocated,1965,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8989,1,['allocate'],['allocated']
Energy Efficiency,"estrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-CHMSampleHeadToHead/BenchmarkComparison/1731c546-7466-4adf-9790-3f99d07df05b/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-CHMSampleHeadToHead/BenchmarkComparison/1731c546-7466-4adf-9790-3f99d07df05b/call-BenchmarkVCFControlSample/Benchmark/669edf6c-76a1-4d82-8cf7-5cd104df2496/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""83.2423166666667"",; ""CHM evalHCsystemhours"": ""0.18843333333333337"",; ""CHM evalHCwallclockhours"": ""61.06540555555557"",; ""CHM evalHCwallclockmax"": ""3.1854916666666666"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-CHMSampleHeadToHead/BenchmarkComparison/1731c546-7466-4adf-9790-3f99d07df05b/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-CHMSampleHeadToHead/BenchmarkComparison/1731c546-7466-4adf-9790-3f99d07df05b/call-BenchmarkVCFTestSample/Benchmark/8e83736f-3023-4bee-9c42-36c836b75297/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550601099:18325,monitor,monitoring,18325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550601099,1,['monitor'],['monitoring']
Energy Efficiency,"estrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-CHMSampleHeadToHead/BenchmarkComparison/b7ddd5f2-fded-4076-b163-33ad637fb5bd/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-CHMSampleHeadToHead/BenchmarkComparison/b7ddd5f2-fded-4076-b163-33ad637fb5bd/call-BenchmarkVCFControlSample/Benchmark/10080eab-b0ad-4752-80cb-fc6d34bd9ad9/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""93.63756388888888"",; ""CHM evalHCsystemhours"": ""0.6379805555555556"",; ""CHM evalHCwallclockhours"": ""70.50882222222222"",; ""CHM evalHCwallclockmax"": ""3.5186027777777777"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-CHMSampleHeadToHead/BenchmarkComparison/b7ddd5f2-fded-4076-b163-33ad637fb5bd/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-CHMSampleHeadToHead/BenchmarkComparison/b7ddd5f2-fded-4076-b163-33ad637fb5bd/call-BenchmarkVCFTestSample/Benchmark/c718736b-bf86-491f-9f9c-56c07cbd0c90/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1687811441:18315,monitor,monitoring,18315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1687811441,1,['monitor'],['monitoring']
Energy Efficiency,exOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:7495,schedul,scheduler,7495,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['schedul'],['scheduler']
Energy Efficiency,"executor 9 requested; 18/01/09 18:31:21 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 9; 18/01/09 18:31:21 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 9 from BlockManagerMaster.; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms); 18/01/09 18:31:26 INFO server.AbstractConnector: Stopped Spark@283ab206{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/09 18:31:26 INFO ui.SparkUI: Stopped Spark web UI at http://192.168.1.4:4040; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/01/09 18:31:26 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/01/09 18:31:26 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/01/09 18:31:26 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/01/09 18:31:26 INFO memory.MemoryStore: MemoryStore cleared; 18/01/09 18:31:26 INFO storage.BlockManager: BlockManager stopped; 18/01/09 18:31:26 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/01/09 18:31:26 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/01/09 18:31:26 INFO spark.SparkContext: Successfully stopped SparkContext; 18:31:26.896 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [January 9, 2018 6:31:26 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 0.89 minutes.; Runtime.totalMemory()=881328128; ***********************************************************************. A USER ERROR has occurred: Input file",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:30311,Schedul,SchedulerExtensionServices,30311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,2,['Schedul'],['SchedulerExtensionServices']
Energy Efficiency,exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1862); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1875); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1952); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1144); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.RDDOperationS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:34280,schedul,scheduler,34280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,f spark.network.timeout=200h --conf spark.executor.heartbeatInterval=100h --read-name-regex null`; It reports the error below.; `20/12/15 11:43:00 ERROR Executor: Exception in task 15.0 in stage 7.0 (TID 12538); java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$handleFragments$12(MarkDuplicatesSparkUtils.java:395); at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); at org.apache.spark.scheduler.ShuffleMapTas,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7001:1464,reduce,reduce,1464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001,1,['reduce'],['reduce']
Energy Efficiency,"f-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `53.247% <0%> (-18.071%)` | `28% <0%> (-6%)` | |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `40.469% <0%> (-18.009%)` | `28% <0%> (Ã¸)` | |; | ... and [42 more](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=footer). Last update [781db35...13a10e2](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2574#issuecomment-292193941:4237,Power,Powered,4237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2574#issuecomment-292193941,1,['Power'],['Powered']
Energy Efficiency,"f92bbd488ac81d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:13:58 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0, scc-q16.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 9999, span 21707, expected MD5 059b07ed1e0589040ada9b236b88b509; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:5696,schedul,scheduler,5696,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,"f_genome/GCA_905319855.2_mCanLor1.2_genomic.fa \; -V gendb://Wolf_Genome_Variantsdb \; -O All_Wolf_Samples_Joint_Genotypes_Raw.vcf.gz \; -L /scratch/dan/Wolf_reads_raw/Wolf_GenCov300_Q20_Merged.interval_list \; -imr ALL \; --genomicsdb-max-alternate-alleles 10 \; --max-alternate-alleles 6 . This runs perfectly until it reaches the 2 millionth variant mark whereupon everything stops, and all processes are terminated. You will notice this isn't occurring at chr1= ~200k (as in previous reports), but instead on the variants processed = ~2million. It seems odd that previous posts had a similar error (reported alternately as chr position ~200k or 2m). ; ; If I try running ""SelectVariants"" on any interval in the database ; ; gatk SelectVariants \; -R /home/dan_vanderpool/Wolf_raw_reads/Wolf_genome/GCA_905319855.2_mCanLor1.2_genomic.fa \; -V gendb://Wolf_Genome_Variantsdb \; -select-type SNP \; -O test_error1m.vcf.gz; -L chr1:1000000-2000000. The process stalls (doesn't terminate) without reporting any variants with the progress meter as below. . 18:46:19.529 INFO SelectVariants - Done initializing engine; 18:46:19.574 INFO ProgressMeter - Starting traversal; 18:46:19.574 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute. The stack trace on the stalled ""SelectVariants"" command looks like:. ""G1 Refine#78"" os_prio=0 tid=0x00007ff536ea6000 nid=0x1af0e0 runnable . ""G1 Refine#79"" os_prio=0 tid=0x00007ff536ea8000 nid=0x1af0e1 runnable . ""G1 Refine#80"" os_prio=0 tid=0x00007ff536ea9800 nid=0x1af0e2 runnable . ""G1 Refine#81"" os_prio=0 tid=0x00007ff536eab800 nid=0x1af0e3 runnable . ""G1 Refine#82"" os_prio=0 tid=0x00007ff536ead000 nid=0x1af0e4 runnable . ""G1 Young RemSet Sampling"" os_prio=0 tid=0x00007ff536eaf000 nid=0x1af0e5 runnable ; ""VM Periodic Task Thread"" os_prio=0 tid=0x00007ff5310eb000 nid=0x1af101 waiting on condition . JNI global references: 13. Heap; garbage-first heap total 5378048K, used 1388875K [0x0000000082000000, 0x0000000800000000)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1049112454:1827,meter,meter,1827,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1049112454,1,['meter'],['meter']
Energy Efficiency,failJobAndIndependentStages(DAGScheduler.scala:1889)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)** ; **at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)** ; **at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)** ; **at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)** ; **at scala.Option.foreach(Option.scala:257)** ; **at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)** ; **at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)** ; **at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)** ; **at org.apache.spark.rdd.RDD.count(RDD.scala:1168)** ; **at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455)** ; **at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark.runTool(PathSeqPipelineSpark.java:245)** ; **at org.broadinstitute.hellbender.engine.spark.GA,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:46805,schedul,scheduler,46805,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,"far have shown that there are lots of; configuration points where one or the other performs poorly; the onus is on; finding the good configuration values that result in better performance, or; identifying which algorithms may be performant for a larger range of; parameter choices. To maximize understanding I would suggest that we not change too many; parameters at a time. For example it seems unnecessary to have multiple; variants of the 128Mbp input. I found there can be significant (>50%) variation between identical runs.; One way to reduce this is to set spark.task.maxFailures=1 which I strongly; recommend for all experiments going forward. One concern I have is that our cluster memory is already far larger than; the input size. In fact here each machine can fit the whole input; comfortably in RAM. This is not going to be the case for the full input.; Since it would take too long to iterate using the full input, it seems wise; instead to reduce both the input size and to keep a close eye on the amount; of memory we're using to make sure we're not going down a path that would; not be able to cope with the full input. On Wed, Nov 18, 2015 at 11:08 AM, droazen notifications@github.com wrote:. > I did some additional runs on the Broad cluster on a 14 GB bam, twice as; > large as the bam used in the plot above. This was with 60 cores, 4 cores; > per executor, and 16 GB of memory per executor. Results:; > ; > Broadcast (3 runs): 10m52.020s, 11m46.975s, 10m17.274s; > Sharded (3 runs): 19m33.310s, 13m36.466s, (died from out-of-memory error); > ; > Not sure what's going on here, but something about this configuration is; > favorable to Broadcast and unfavorable to Sharded. We should try to; > understand what and why.; > ; > Below are the commands I used to run each implementation on dataflow01,; > for reference:; > ; > spark-submit \; > --master yarn-client \; > --driver-memory 8G \; > --num-executors 16 \; > --executor-cores 4 \; > --executor-memory 16G \; > --conf spark.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/995#issuecomment-157838734:1434,reduce,reduce,1434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/995#issuecomment-157838734,1,['reduce'],['reduce']
Energy Efficiency,"fd6774df454b09; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:14:09 ERROR scheduler.TaskSetManager: Task 16 in stage 0.0 failed 4 times; aborting job; 13:14:09.675 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 1:14:09 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.97 minutes.; Runtime.totalMemory()=937426944; org.apache.spark.SparkException: Job aborted due to stage failure: Task 16 in stage 0.0 failed 4 times, most recent failure: Lost task 16.3 in stage 0.0 (TID 11, scc-q16.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:12029,schedul,scheduler,12029,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,"ference/ReferenceBases.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWZlcmVuY2UvUmVmZXJlbmNlQmFzZXMuamF2YQ==) | `38.46% <0%> (-19.24%)` | `4% <0%> (-2%)` | |; | [...oadinstitute/hellbender/engine/ReferenceShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlU2hhcmQuamF2YQ==) | `62.5% <0%> (-18.75%)` | `6% <0%> (-1%)` | |; | [...broadinstitute/hellbender/engine/VariantShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVmFyaWFudFNoYXJkLmphdmE=) | `63.63% <0%> (-13.64%)` | `7% <0%> (-1%)` | |; | [...ne/spark/datasources/ReferenceWindowFunctions.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVmZXJlbmNlV2luZG93RnVuY3Rpb25zLmphdmE=) | `12.5% <0%> (-12.5%)` | `1% <0%> (Ã¸)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (+1.21%)` | `42% <0%> (Ã¸)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5292?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5292?src=pr&el=footer). Last update [a74e571...3768ba2](https://codecov.io/gh/broadinstitute/gatk/pull/5292?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5292#issuecomment-427904892:4339,Power,Powered,4339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5292#issuecomment-427904892,1,['Power'],['Powered']
Energy Efficiency,ferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:2829,schedul,scheduler,2829,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,3,['schedul'],['scheduler']
Energy Efficiency,"ffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.TaskSetManager: Task 284 in stage 25.0 failed 4 times; aborting job; 18/01/12 20:38:37 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@23007ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(50,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(52,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(34,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(60,WrappedArray()); 20:38:37.897 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [January 12, 2018 8:38:37 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 42.74 minutes.; Runtime.totalMemory()=16692805632; org.apache.spark.SparkException: Job aborted due to stage failure: Task 284 in stage 25.0 failed 4 times, most recent failure: Lost task 284.3 in stage 25.0 (TID 43224, cw-test-w-6.c.broad-dsde-methods.internal, executor 7): java.lang.Illegal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:5415,schedul,scheduler,5415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,"file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; >; > 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; >; > 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; >; > INFO: Failed to detect whether we are running on Google Compute Engine.; >; > 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------; >; > 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1; >; > 16:17:05.843 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; >; > 16:17:05.843 INFO HaplotypeCaller - Executing as robert@powerlinux on Linux v4.4.0-184-generic ppc64le; >; > 16:17:05.843 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-8u252-b09-1~16.04-b09; >; > 16:17:05.843 INFO HaplotypeCaller - Start Date/Time: September 4, 2020 4:17:04 PM UTC; >; > 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------; >; > 16:17:05.843 INFO HaplotypeCaller - -----------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600:2437,Power,Power,2437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600,1,['Power'],['Power']
Energy Efficiency,fn$4$1.apply(JavaRDDLike.scala:153); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:6562,schedul,scheduler,6562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['schedul'],['scheduler']
Energy Efficiency,"for writing BAM files. This reduces memory usage since the reads; don't need to all be stored in memory. Also add some missing calls to addDataflowRunnerArgs in the integration; tests to ensure the correct dataflow runner is being picked up. This is related to https://github.com/broadinstitute/hellbender/issues/771, for the Spark/Hadoop side.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/845:28,reduce,reduces,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/845,1,['reduce'],['reduces']
Energy Efficiency,"found an old issue with a similar stacktrace, but that issue appears to occur in GATK 2.4: https://gatkforums.broadinstitute.org/gatk/discussion/3265/bqsrgatherer-exception. In the below stacktrace, I've bolded the error message that seems to occur in each of these samples. `Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1026); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperati",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:1940,schedul,scheduler,1940,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['schedul'],['scheduler']
Energy Efficiency,"g libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1. 16:17:05.843 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/. 16:17:05.843 INFO HaplotypeCaller - Executing as robert@powerlinux on Linux v4.4.0-184-generic ppc64le. 16:17:05.843 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-8u252-b09-1~16.04-b09. 16:17:05.843 INFO HaplotypeCaller - Start Date/Time: September 4, 2020 4:17:04 PM UTC. 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794:1644,Power,Power,1644,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794,1,['Power'],['Power']
Energy Efficiency,"g parents: List(); 15/07/14 13:14:52 INFO scheduler.DAGScheduler: Submitting Stage 0 (MapPartitionsRDD[4] at map at TransformTranslator.java:181), which has no missing parents; 15/07/14 13:14:52 INFO storage.MemoryStore: ensureFreeSpace(6656) called with curMem=0, maxMem=278019440; 15/07/14 13:14:52 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.5 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(3753) called with curMem=6656, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:65240 (size: 3.7 KB, free: 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerMaster: Updated info of block broadcast_0_piece0; 15/07/14 13:14:53 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:839; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MapPartitionsRDD[4] at map at TransformTranslator.java:181); 15/07/14 13:14:53 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 1 tasks; 15/07/14 13:14:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1435 bytes); 15/07/14 13:14:53 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0); 15/07/14 13:14:53 INFO executor.Executor: Fetching http://10.1.4.233:65239/jars/hellbender-all-GATK.4.alpha-413-g741d007-SNAPSHOT-spark.jar with timestamp 1436894092643; 15/07/14 13:14:53 INFO util.Utils: Fetching http://10.1.4.233:65239/jars/hellbender-all-GATK.4.alpha-413-g741d007-SNAPSHOT-spark.jar to /var/folders/xt/vq7wz8955r1401mv8w0f4zf9qbfwzl/T/louisb/spark-ccf49262-23e0-45d9-a273-0096f310c64a/userFiles-0909d070-1b0a-4cf7-8d86-e4144a2dd020/fetchFileTemp6888440563594800088.tmp; 15/07/14 13:14:53 INFO executor.Executor: Adding file:/var/folders/xt/vq7wz895",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:23229,schedul,scheduler,23229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['schedul'],['scheduler']
Energy Efficiency,g.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:10661,schedul,scheduler,10661,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,"g.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$14/1380582544.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:37 INFO scheduler.TaskSetManager: Starting task 0.3 in stage 1.0 (TID 4, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Disabling executor 2.; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 1); 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, com2, 46254); 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor; 17/10/11 14:19:38 ERROR cluster.YarnScheduler: Lost executor ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:23719,schedul,scheduler,23719,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,g.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:134)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)** ; **20/03/05 09:28:58 INFO ShutdownHookManager: Shutdown hook called** ; **20/03/05 09:28:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-9e0e0327-45a3-46e8-872a-f5a63c3c7a98** ; **Using GATK jar /mnt/clinix1/Analysis/mongol/phenomata/Tools/Anaconda3/envs/gatk4/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar** ; **Running:** ; **java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:51048,schedul,scheduler,51048,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,"g.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:134)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)** ; **20/03/05 09:28:58 INFO TaskSetManager: Starting task 40.0 in stage 0.0 (TID 40, localhost, executor driver, partition 40, PROCESS\_LOCAL, 7972 bytes)** ; **20/03/05 09:28:58 INFO Executor: Running task 40.0 in stage 0.0 (TID 40)** ; **20/03/05 09:28:58 WARN TaskSetManager: Lost task 34.0 in stage 0.0 (TID 34, localhost, executor driver): com.esotericsoftware.kryo.KryoException: Buffer underflow.** ; **at ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:28616,schedul,scheduler,28616,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,"g.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:134)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **20/03/05 09:28:58 ERROR TaskSetManager: Task 34 in stage 0.0 failed 1 times; aborting job** ; **20/03/05 09:28:58 INFO TaskSchedulerImpl: Cancelling stage 0** ; **20/03/05 09:28:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 0.0 in stage 0.0 (TID 0), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:32064,schedul,scheduler,32064,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,"g.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:134)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **Driver stacktrace:** ; **20/03/05 09:28:58 INFO DAGScheduler: Job 0 failed: count at PathSeqPipelineSpark.java:245, took 63.806676 s** ; **20/03/05 09:28:58 INFO SparkUI: Stopped Spark web UI at http://cm132:4040** ; **20/03/05 09:28:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!** ; **20/03/05 09:28:58 INFO NewHadoopRDD: Input split: file:/clinix1/Analysis/mongol/phenomata",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:40678,schedul,scheduler,40678,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,g.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:134)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **Driver stacktrace:** ; **at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)** ; **at scala.collection.mutable.Resizable,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:45105,schedul,scheduler,45105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,g.broadinstitute.hellbender.tools.walkers.annotator.CountNs.lambda$annotate$1(CountNs.java:46); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:174); 	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948); 	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:270); 	at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); 	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); 	at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.LongPipeline.reduce(LongPipeline.java:438); 	at java.util.stream.LongPipeline.sum(LongPipeline.java:396); 	at java.util.stream.ReferencePipeline.count(ReferencePipeline.java:526); 	at org.broadinstitute.hellbender.tools.walkers.annotator.CountNs.annotate(CountNs.java:46); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:268); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:192); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:233); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:232); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6336:1579,reduce,reduce,1579,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6336,1,['reduce'],['reduce']
Energy Efficiency,g.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-29T18:18:04.001518160Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-29T18:18:04.001673083Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6237:1489,Reduce,ReduceOps,1489,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6237,1,['Reduce'],['ReduceOps']
Energy Efficiency,g.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-29T18:18:04.001518160Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-29T18:18:04.001673083Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1489,Reduce,ReduceOps,1489,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300,1,['Reduce'],['ReduceOps']
Energy Efficiency,g.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-30T13:35:51.792559803Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-30T13:35:51.792736667Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1490,Reduce,ReduceOps,1490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227,1,['Reduce'],['ReduceOps']
Energy Efficiency,"gate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 13:59:26 INFO cluster.YarnScheduler: Adding task set 0.0 with 252 tasks; 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 0, scc-q05.scc.bu.edu, executor 4, partition 2, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 25.0 in stage 0.0 (TID 1, scc-q10.scc.bu.edu, executor 3, partition 25, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 0.0 (TID 2, scc-q07.scc.bu.edu, executor 1, partition 15, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 3, scc-q16.scc.bu.edu, executor 8, partition 4, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 4, scc-q14.scc.bu.edu, executor 2, partition 3, NODE_L",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:2897,schedul,scheduler,2897,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304,1,['schedul'],['scheduler']
Energy Efficiency,ge failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:9199,schedul,scheduler,9199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['schedul'],['scheduler']
Energy Efficiency,"ge size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:23.416 INFO StructuralVariationDiscoveryPipelineSpark - 853 contigs indicating Cpx; 18/01/25 17:20:23 WARN org.apache.spark.scheduler.TaskSetManager: Stage 41 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:34.830 INFO StructuralVariationDiscoveryPipelineSpark - 1521 contigs indicating Incomplete; 18/01/25 17:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 45 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:44.949 INFO StructuralVariationDiscoveryPipelineSpark - 5277 contigs indicating Ambiguous; 18/01/25 17:20:45 WARN org.apache.spark.scheduler.TaskSetManager: Stage 49 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:55.516 INFO StructuralVariationDiscoveryPipelineSpark - 15 contigs indicating MisAssemblySuspect; 18/01/25 17:20:55 WARN org.apache.spark.scheduler.TaskSetManager: Stage 53 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:21:06.632 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 14088 variants.; 17:21:06.647 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 6100; 17:21:06.647 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 240; 17:21:06.647 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 230; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4488; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1355; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1675; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - INV: 0; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/01/25 17:21:07 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 29.0 in stage 61.0 (TID 60915, cwhelan-hg0051",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260:3708,schedul,scheduler,3708,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260,1,['schedul'],['scheduler']
Energy Efficiency,ger.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1862); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1875); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1952); 	at org.apache.spark.rdd.PairRDDFunctions$$an,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:33935,schedul,scheduler,33935,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"ges/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:33:28 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-07 11:33:29 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-07 11:33:30 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-07 11:33:30 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-07 11:33:30 INFO Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-07 11:33:30 INFO Client:54 - Setting up container launch context for our AM; 2019-01-07 11:33:30 INFO Client:54 - Setting up the launch environment for our AM container; 2019-01-07 11:33:30 INFO Client:54 - Preparing resources for our AM container; 2019-01-07 11:33:30 INFO HadoopFSDelegationTokenProvider:54 - getting token for: DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1883879239_1, ugi=farrell@AD.BU.EDU (auth:KERBEROS)]]; 2019-01-07 11:33:30 INFO DFSClient:1023 - Created HDFS_DELEGATION_TOKEN token 11334 for farrell on ha-hdfs:scc; 2019-01-07 11:33:32 WARN Client:66 - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 2019-01-07 11:33:36 INFO Client:54 - Uploading resource file:/tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed/__spark_libs__7473738539612638927.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_libs__7473738539612638927.zip; 2019-01-07 11:33:38 INFO Client:54 - Uploading resource file:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:10934,allocate,allocate,10934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['allocate'],['allocate']
Energy Efficiency,"ges/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:42689/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1547058912934; 2019-01-09 13:35:13 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-09 13:35:13 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-09 13:35:14 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-09 13:35:14 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-09 13:35:14 INFO Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-09 13:35:14 INFO Client:54 - Setting up container launch context for our AM; 2019-01-09 13:35:14 INFO Client:54 - Setting up the launch environment for our AM container; 2019-01-09 13:35:14 INFO Client:54 - Preparing resources for our AM container; 2019-01-09 13:35:14 INFO HadoopFSDelegationTokenProvider:54 - getting token for: DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-682487019_1, ugi=farrell@AD.BU.EDU (auth:KERBEROS)]]; 2019-01-09 13:35:14 INFO DFSClient:1023 - Created HDFS_DELEGATION_TOKEN token 11353 for farrell on ha-hdfs:scc; 2019-01-09 13:35:16 WARN Client:66 - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 2019-01-09 13:35:20 INFO Client:54 - Uploading resource file:/tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0/__spark_libs__7821719163562430010.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_libs__7821719163562430010.zip; 2019-01-09 13:35:22 INFO Client:54 - Uploading resource file:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:10674,allocate,allocate,10674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['allocate'],['allocate']
Energy Efficiency,getBaseQualities is expensive because it allocates a new byte array every time; getSoftStart etc are also costly because they create many objects; getCigar creates a new Cigar object every time. all of those clearly show on the profiler when running BaseRecalibrator. this PR lifts these operations out of the loops they're in. ; @lbergelson please review -,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1475:41,allocate,allocates,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1475,1,['allocate'],['allocates']
Energy Efficiency,"getCoverage done. Elapsed time: 2.87 minutes.; Runtime.totalMemory()=10377756672; htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248681942, span 176823, expected MD5 4b8526e90896b01860301e5a1ef4988b; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:601); at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.hasNext(SAMRecordToReadIterator.java:24); at java.util.Iterator.forEachRemaining(Iterator.java:115); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:779); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); at org.broadinstitute.hellbender.Main.main(Main.java:221); ```; This error occurs fairly soon after launching the job, after the progress meter shows the tool iterating over chromosome 1.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154:3252,meter,meter,3252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154,1,['meter'],['meter']
Energy Efficiency,"ggregate at FlagStatSpark.java:73) with 629 output partitions; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.9 KB, free 8.4 GB); 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting 629 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 20:31:51 INFO cluster.YarnScheduler: Adding task set 0.0 with 629 tasks; 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 0, scc-q03.scc.bu.edu, executor 4, partition 1, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 1, scc-q13.scc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:6467,schedul,scheduler,6467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,1,['schedul'],['scheduler']
Energy Efficiency,ggregate$1$$anonfun$24.apply(RDD.scala:1136); 	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1137); 	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25.apply(RDD.scala:1137); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 19/03/26 20:02:39 INFO ShutdownHookManager: Shutdown hook called; 19/03/26 20:02:39 INFO ShutdownHookManager: Deleting directory /docker/working/7dd5e9aa-fa24-45ca-9979-13623c0ff8d5/a0d4bfdf-66b4-47af-b002-3c3935a7b633/spark-44911f4d-4d54-42b0-b6d1-35614170c1fc; Using GATK jar /docker/reference/Apps/GATK/4.1.0.0/gatk-package-4.1.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx10876M -Djava.io.tmpdir=./ -jar /docker/reference/Apps/GATK/4.1.0.0/gatk-package-4.1.0.0-local.jar BaseRecalibratorSpark --spark-master local[8] -R /docker/refer,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:6903,schedul,scheduler,6903,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['schedul'],['scheduler']
Energy Efficiency,"gistering block manager xx.xx.xx.xx:42081 with 366.3 MB RAM, BlockManagerId(driver, xx.xx.xx.xx, 42081, None); 18/04/24 17:39:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/0 is now RUNNING; 18/04/24 17:39:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/1 is now RUNNING; 18/04/24 17:39:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/2 is now RUNNING; 18/04/24 17:39:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, xx.xx.xx.xx, 42081, None); 18/04/24 17:39:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, xx.xx.xx.xx, 42081, None); 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/6 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/4 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/3 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/5 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0; 18/04/24 17:39:22 INFO GoogleHadoopFileSystemBase: GHFS version: 1.6.3-hadoop2; 18/04/24 17:39:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 276.0 KB, free 366.0 MB); 00:08 DEBUG: [kryo] Write: SerializableConfiguration; 18/04/24 17:39:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.1 KB, free 366.0 MB); 18/04/24 17:39:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.xx:42081 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:39:27 INFO SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:113; 18/04/24 17:39:27 INFO FileInputFormat: Total input p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:13395,Schedul,SchedulerBackend,13395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,"['Schedul', 'schedul']","['SchedulerBackend', 'scheduling']"
Energy Efficiency,"haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...ark/sv/CallVariantsFromAlignedContigsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9DYWxsVmFyaWFudHNGcm9tQWxpZ25lZENvbnRpZ3NTQU1TcGFyay5qYXZh) | `0% <0%> (-26.087%)` | `0% <0%> (-5%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `48.837% <0%> (-24.774%)` | `27% <0%> (-9%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (Ã¸)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | ... and [27 more](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=footer). Last update [5d2f859...7a651b7](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-287020306:4309,Power,Powered,4309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-287020306,1,['Power'],['Powered']
Energy Efficiency,"hbmRMaW5lUHJvZ3JhbS5qYXZh) | `95.714% <0%> (+2.456%)` | `38% <0%> (+9%)` | :arrow_up: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `87.156% <0%> (+2.945%)` | `66% <0%> (+13%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (Ã¸)` | :arrow_down: |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `70.47% <0%> (+4.154%)` | `46% <0%> (+18%)` | :arrow_up: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2495?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2495?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2495?src=pr&el=footer). Last update [88c181d...298212c](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2495#issuecomment-287912625:5172,Power,Powered,5172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2495#issuecomment-287912625,1,['Power'],['Powered']
Energy Efficiency,"he superclass, but for `AssemblyRegionWalker` it was the unit of I/O and `AssemblyRegion` was the unit of processing, and I couldn't update the docs for `ReadWindowWalker` to clear up the confusion without mentioning `AssemblyRegion`-specific concepts.; - The `ReadShard` / `ReadWindow` was/is **only** there to prove that we can shard the data without introducing calling artifacts, and to provide a unit of parallelism for the upcoming Spark implementation. It's not something we really want to expose to users as a prominent knob, and we may hide it completely in the future once the shard size is tuned for performance.; - Inheriting from a more abstract walker type caused a number of other problems as well: methods that should have been final in the supertype could no longer be made final, with the result that tool implementations could inappropriately override engine initialization/shutdown routines. Also, there were issues with the progress meter, since both the supertype traversal and subtype traversal needed their own progress meter for their different units of processing. Ultimately it was just too awkward and forced, and the read shard is something that we eventually want to make an internal/encapsulated implementation detail anyway. GATK3 made the mistake, I think, of using long, confusing inheritance chains for its walker types, with the result that you got awkward and forced relationships like `RodWalker` inheriting from `LocusWalker`. It's better, I think, to make each traversal as standalone as possible, especially given the simplicity of writing a new walker type in GATK4. For all of these reasons we don't want `AssemblyRegionWalker` to inherit from a more abstract traversal type -- it's just going to be its own standalone thing, so that it can evolve freely without affecting anyone else. For `SlidingWindowWalker`, which we still want to merge, I recommend making the traversal do **exactly** what you want for your use case, as clearly and simply as possible,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513:1712,meter,meter,1712,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513,2,['meter'],['meter']
Energy Efficiency,he.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1832); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1845); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1922); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1144); 	at org.apache.spark.rdd.Pair,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:19174,schedul,scheduler,19174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,he.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3659:3524,schedul,scheduler,3524,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659,1,['schedul'],['scheduler']
Energy Efficiency,he.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:9042,schedul,scheduler,9042,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,he.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939); 	at org.apache,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:15462,schedul,scheduler,15462,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['schedul'],['scheduler']
Energy Efficiency,he.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1661); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1649); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1648); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1648); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1882); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1820); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945); 	at org.apache,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:4360,schedul,scheduler,4360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['schedul'],['scheduler']
Energy Efficiency,he.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); 	at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78); 	... 87 more; Caused by: java.util.ConcurrentModificationExcepti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:11299,schedul,scheduler,11299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,"he.spark.storage.BlockManager.reportAllBlocks(BlockManager.scala:217); 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:236); 	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:522); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); 	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308); 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180); 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 17/10/18 17:35:58 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/10/18 17:35:58 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-1,5,main]; java.lang.OutOfMemoryError: Java heap space; 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:208); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:5595,Schedul,ScheduledThreadPoolExecutor,5595,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,2,['Schedul'],"['ScheduledFutureTask', 'ScheduledThreadPoolExecutor']"
Energy Efficiency,heartbeat timed out after 131031 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); 	at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); 	at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); 	at org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark.runTool(PathSeqPipelineSpark.java:245);,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:3177,schedul,scheduler,3177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['schedul'],['scheduler']
Energy Efficiency,heduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1436); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1424); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); > 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); > 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); > 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1423); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); > 	at scala.Option.foreach(Option.scala:257); > 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1651); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1606); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1595); > 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); > 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); > 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); > 	at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); > 	at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); > 	at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:38); > 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSpark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936:1580,schedul,scheduler,1580,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936,1,['schedul'],['scheduler']
Energy Efficiency,heduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:50325,schedul,scheduler,50325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,heduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38912,schedul,scheduler,38912,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,"heduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, com2, executor 1, partition 0, NODE_LOCAL, 4632 bytes); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:45501 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.131.101.145:54024; 17/10/13 18:11:53 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 135 bytes; 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on com2:45501 (size: 2.1 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 565 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88) finished in 0.566 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Job 0 finished: runJob at SparkHadoopMapReduceWriter.scala:88, took 9.524571 s; 17/10/13 18:11:53 INFO io.SparkHadoopMapReduceWriter: Job job_20171013181144_0009 committed.; 17/10/13 18:11:53 INFO server.AbstractConnector: Stopped Spark@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:53 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/13 18:11:54 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 17/10/13 18:11:54 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/13 18:11:54 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint st",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:21517,schedul,scheduler,21517,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['schedul'],['scheduler']
Energy Efficiency,heduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.schedul,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:31551,schedul,scheduler,31551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); Caused by: java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:192); at java.util.stream.ReferencePipeline$7$1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:17268,Reduce,ReduceOps,17268,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653:3239,Reduce,ReduceOps,3239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"hhaW5QcnVuZXIuamF2YQ==) | `83.33% <0%> (-12.23%)` | `5% <0%> (-15%)` | |; | [...r/arguments/CopyNumberArgumentValidationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2FyZ3VtZW50cy9Db3B5TnVtYmVyQXJndW1lbnRWYWxpZGF0aW9uVXRpbHMuamF2YQ==) | `66.66% <0%> (-11.12%)` | `19% <0%> (-1%)` | |; | [...tools/funcotator/DataSourceFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0RhdGFTb3VyY2VGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `75.92% <0%> (-11.04%)` | `17% <0%> (Ã¸)` | |; | [...ools/walkers/haplotypecaller/graphs/SeqVertex.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvU2VxVmVydGV4LmphdmE=) | `92.85% <0%> (-7.15%)` | `10% <0%> (-1%)` | |; | [...te/hellbender/tools/funcotator/OutputRenderer.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL091dHB1dFJlbmRlcmVyLmphdmE=) | `92.85% <0%> (-7.15%)` | `4% <0%> (Ã¸)` | |; | ... and [170 more](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5475?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5475?src=pr&el=footer). Last update [1f6a172...623830b](https://codecov.io/gh/broadinstitute/gatk/pull/5475?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5475#issuecomment-443759397:4616,Power,Powered,4616,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5475#issuecomment-443759397,1,['Power'],['Powered']
Energy Efficiency,"hila.sorted.bam \; -O hdfs://master2:9000/Drosophila/output/Drosophila.sorted.markdup.bam \; -M; hdfs://master2:9000/Drosophila/output/Drosophila.sorted.markdup_metrics.txt; \; -- \; --spark-runner SPARK --spark-master spark://master2:7077; ```; **error logs:**. ```; Exception in thread ""main"" java.lang.NoClassDefFoundError:; scala/Product$class; at; org.bdgenomics.adam.serialization.InputStreamWithDecoder.<init>(ADAMKryoRegistrator.scala:35); at; org.bdgenomics.adam.serialization.AvroSerializer.<init>(ADAMKryoRegistrator.scala:45); at; org.bdgenomics.adam.models.VariantContextSerializer.<init>(VariantContext.scala:94); at; org.bdgenomics.adam.serialization.ADAMKryoRegistrator.registerClasses(ADAMKryoRegistrator.scala:179); at; org.broadinstitute.hellbender.engine.spark.GATKRegistrator.registerClasses(GATKRegistrator.java:78); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$8(KryoSerializer.scala:170); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$8$adapted(KryoSerializer.scala:170); at scala.Option.foreach(Option.scala:407); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$5(KryoSerializer.scala:170); at; scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); at; org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:221); at; org.apache.spark.serializer.KryoSerializer.newKryo(KryoSerializer.scala:161); at; org.apache.spark.serializer.KryoSerializer$$anon$1.create(KryoSerializer.scala:102); at; com.esotericsoftware.kryo.pool.KryoPoolQueueImpl.borrow(KryoPoolQueueImpl.java:48); at; org.apache.spark.serializer.KryoSerializer$PoolWrapper.borrow(KryoSerializer.scala:109); at; org.apache.spark.serializer.KryoSerializerInstance.borrowKryo(KryoSerializer.scala:336); at; org.apache.spark.serializer.KryoSerializationStream.<init>(KryoSerializer.scala:256); at; org.apache.spark.serializer.KryoSerializerInstance.serializeStream(KryoSerializer.scala:422); at; org.apache.spark.broadcast.TorrentBroadcast$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6644:1308,adapt,adapted,1308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644,1,['adapt'],['adapted']
Energy Efficiency,"his would be fixed by #1433, but it only fixed the inverse of this problem. It's possible now to load HDFS files from the local runner using the full namenode path . i.e. ; `hdfs://dataflow01.broadinstitute.org/user/louisb/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam`, . Loading files with the sparkRunner and yarn-client is still failing. . We're getting a new error now though. ```; java.lang.IllegalArgumentException: unknown SAM format, cannot create RecordReader: file:/local/dev/akiezun/bin/gatk/src/test/resources/org/broadinstitute/hellbender/tools/valid.bam; at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:181); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:151); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:124); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:65); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297); at org.apache.spark.rdd.RDD.iterator(RDD.scala:264); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297); at org.apache.spark.rdd.RDD.iterator(RDD.scala:264); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297); at org.apache.spark.rdd.RDD.iterator(RDD.scala:264); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297); at org.apache.spark.rdd.RDD.iterator(RDD.scala:264); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); at org.apache.spark.scheduler.Task.run(Task.scala:88); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1417#issuecomment-174655123:1628,schedul,scheduler,1628,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1417#issuecomment-174655123,2,['schedul'],['scheduler']
Energy Efficiency,"hon3.6/site-packages/theano/misc/windows.py"", line 43, in subprocess_Popen; proc = subprocess.Popen(command, startupinfo=startupinfo, **params); File ""/home/tintest/miniconda2/envs/aurexome/lib/python3.6/subprocess.py"", line 707, in __init__; restore_signals, start_new_session); File ""/home/tintest/miniconda2/envs/aurexome/lib/python3.6/subprocess.py"", line 1267, in _execute_child; restore_signals, start_new_session, preexec_fn); OSError: [Errno 12] Cannot allocate memory. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.executeGermlineCNVCallerPythonScript(GermlineCNVCaller.java:454); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.doWork(GermlineCNVCaller.java:291); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. ----. ## Solutions. Any ideas ?. Maybe my command need to be modified to handle such a great number of samples ?. Maybe you should add some option to expand the python memory to allocate ? . ----. Thank you",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053:68416,allocate,allocate,68416,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053,1,['allocate'],['allocate']
Energy Efficiency,"http://www.hammerlab.org/2015/02/27/monitoring-spark-with-graphite-and-grafana/. the task here to set this up and, if it's useful, update the readme on how to set it up and use. @laserson do you have experience with Graphite and Grafana",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1377:36,monitor,monitoring-spark-with-graphite-and-grafana,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1377,1,['monitor'],['monitoring-spark-with-graphite-and-grafana']
Energy Efficiency,"https://gatk-jenkins.broadinstitute.org/view/HTSJDK%20Release%20Tests/ has a display showing a pipeline view of 3 jobs, 1 builds htsjdk on its own, it then launches picard and gatk4 tests on that version of htsjdk. all 3 green means that they succeeded, but for now we should dig into the console output and verify that they look ok until we've run it enough times that we trust nothing new and funny is going on.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1705#issuecomment-212129739:221,green,green,221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1705#issuecomment-212129739,1,['green'],['green']
Energy Efficiency,"https://github.com/broadinstitute/gatk/blob/b4cba377e0aff179dbff615783506913e7fe3aa4/src/main/java/org/broadinstitute/hellbender/tools/funcotator/dataSources/xsv/LocatableXsvFuncotationFactory.java#L245-L247. Double-Checked Locking is widely cited and used as an efficient method for implementing lazy initialization in a multithreaded environment.; Unfortunately, it will not work reliably in a platform independent way when implemented in Java, without additional synchronization. Modify the variable â€˜supportedFieldNamesâ€™ with volatile to tackle the problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7376:263,efficient,efficient,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7376,1,['efficient'],['efficient']
Energy Efficiency,https://spark.apache.org/docs/1.2.0/monitoring.html is the basic overview of monitoring Spark applications.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/284#issuecomment-143379723:36,monitor,monitoring,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/284#issuecomment-143379723,2,['monitor'],['monitoring']
Energy Efficiency,"hutting down engine ; ; \[June 4, 2021 11:03:51 AM CST\] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.19 minutes. ; ; Runtime.totalMemory()=625999872 ; ; java.lang.NumberFormatException: **For input string: ""167|35|14""** ; ; at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) ; ; at java.lang.Integer.parseInt(Integer.java:580) ; ; at java.lang.Integer.valueOf(Integer.java:766) ; ; at htsjdk.variant.variantcontext.CommonInfo.lambda$getAttributeAsIntList$1(CommonInfo.java:288) ; ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; ; at java.util.Collections$2.tryAdvance(Collections.java:4717) ; ; at java.util.Collections$2.forEachRemaining(Collections.java:4725) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; at htsjdk.variant.variantcontext.CommonInfo.getAttributeAsList(CommonInfo.java:274) ; ; at htsjdk.variant.variantcontext.CommonInfo.getAttributeAsIntList(CommonInfo.java:282) ; ; at htsjdk.variant.variantcontext.VariantContext.getAttributeAsIntList(VariantContext.java:827) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.DuplicatedAltReadFilter.areAllelesArtifacts(DuplicatedAltReadFilter.java:26) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.HardAlleleFilter.calculateErrorProbabilityForAlleles(HardAlleleFilter.java:16) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2AlleleFilter.errorProbabilities(Mutect2AlleleFilter.java:86) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$0(ErrorProbabilit",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:6589,Reduce,ReduceOps,6589,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['Reduce'],['ReduceOps']
Energy Efficiency,i fixed what was requested. the illumina classes are scheduled for deletion (in another pull req),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/449#issuecomment-97282777:53,schedul,scheduled,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/449#issuecomment-97282777,1,['schedul'],['scheduled']
Energy Efficiency,iant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:203); at htsjdk.variant.variantcontext.writer.VCFWriter.add(VCFWriter.java:242); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:93); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:56); at org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil.write(SparkHadoopWriter.scala:358); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:132); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); at org.apache.spark.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:16488,schedul,scheduler,16488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,"ibratorSpark done. Elapsed time: 61.53 minutes.; Runtime.totalMemory()=16815489024; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 0.0 failed 1 times, most recent failure: Lost task 8.0 in stage 0.0 (TID 8, localhost): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 126542 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1936); at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1002); at org.apache.spark.rdd.RDDOperationScope$.withScope(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515:3809,schedul,scheduler,3809,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515,1,['schedul'],['scheduler']
Energy Efficiency,ibution.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9CZXRhQmlub21pYWxEaXN0cmlidXRpb24uamF2YQ==) | `68.182% <68.182%> (Ã¸)` | `4 <4> (?)` | |; | [...ation/basicshortmutpileup/AllelePileupCounter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9BbGxlbGVQaWxldXBDb3VudGVyLmphdmE=) | `81.25% <81.25%> (Ã¸)` | `12 <12> (?)` | |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `85.965% <85.965%> (Ã¸)` | `7 <7> (?)` | |; | [...ion/basicshortmutpileup/PowerCalculationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9Qb3dlckNhbGN1bGF0aW9uVXRpbHMuamF2YQ==) | `95.238% <95.238%> (Ã¸)` | `15 <15> (?)` | |; | [...bender/utils/GATKProtectedVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HQVRLUHJvdGVjdGVkVmFyaWFudENvbnRleHRVdGlscy5qYXZh) | `77.901% <95.833%> (+6.472%)` | `70 <23> (+23)` | :arrow_up: |; | [...ion/basicshortmutpileup/BasicValidationResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9CYXNpY1ZhbGlkYXRpb25SZXN1bHQuamF2YQ==) | `96.552% <96.552%> (Ã¸)` | `15 <15> (?)` | |; | ... and [9 more](https://codecov.io/gh/broa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3755#issuecomment-341515732:3190,Power,PowerCalculationUtils,3190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3755#issuecomment-341515732,1,['Power'],['PowerCalculationUtils']
Energy Efficiency,ic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:945); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:945); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1798951329-10.128.1.77-1564169124618:blk_1073741844_1020 file=/reference/Homo_sapiens_assembly38.fasta; 	at org.apache.hadoop.hdfs.DFSInputStream.refetchLocations(DFSInputStream.java:1085); 	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:1068); 	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:1047); 	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:655); 	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:949); 	a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6064:3387,schedul,scheduler,3387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6064,1,['schedul'],['scheduler']
Energy Efficiency,"ich has no missing parents; 15/07/14 13:14:52 INFO storage.MemoryStore: ensureFreeSpace(6656) called with curMem=0, maxMem=278019440; 15/07/14 13:14:52 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.5 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(3753) called with curMem=6656, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:65240 (size: 3.7 KB, free: 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerMaster: Updated info of block broadcast_0_piece0; 15/07/14 13:14:53 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:839; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MapPartitionsRDD[4] at map at TransformTranslator.java:181); 15/07/14 13:14:53 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 1 tasks; 15/07/14 13:14:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1435 bytes); 15/07/14 13:14:53 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0); 15/07/14 13:14:53 INFO executor.Executor: Fetching http://10.1.4.233:65239/jars/hellbender-all-GATK.4.alpha-413-g741d007-SNAPSHOT-spark.jar with timestamp 1436894092643; 15/07/14 13:14:53 INFO util.Utils: Fetching http://10.1.4.233:65239/jars/hellbender-all-GATK.4.alpha-413-g741d007-SNAPSHOT-spark.jar to /var/folders/xt/vq7wz8955r1401mv8w0f4zf9qbfwzl/T/louisb/spark-ccf49262-23e0-45d9-a273-0096f310c64a/userFiles-0909d070-1b0a-4cf7-8d86-e4144a2dd020/fetchFileTemp6888440563594800088.tmp; 15/07/14 13:14:53 INFO executor.Executor: Adding file:/var/folders/xt/vq7wz8955r1401mv8w0f4zf9qbfwzl/T/louisb/spark-ccf49262-23e0-45d9-a273-0096f310c64a/userFiles-0909d070-1b0a-4cf7-8d86-e4144a2dd020/hellbender-all-GATK.4.alpha",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:23378,schedul,scheduler,23378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['schedul'],['scheduler']
Energy Efficiency,idation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH --annotation ClippingRankSumTest --annotation DepthPerSampleHC --output /mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH/NA24631-chr15_68578892_84670250-block.vcf.gz --emitRefConfidence GVCF -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 60 -GQB 80; ```; and the full traceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3659:2846,schedul,scheduler,2846,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659,1,['schedul'],['scheduler']
Energy Efficiency,"iff coverage is `66.667%`. ```diff; @@ Coverage Diff @@; ## master #2515 +/- ##; ===============================================; - Coverage 76.273% 76.268% -0.004% ; - Complexity 10876 10878 +2 ; ===============================================; Files 752 752 ; Lines 39583 39584 +1 ; Branches 6922 6922 ; ===============================================; - Hits 30191 30190 -1 ; - Misses 6772 6774 +2 ; Partials 2620 2620; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...tute/hellbender/tools/spark/sv/ReadClassifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkQ2xhc3NpZmllci5qYXZh) | `82.813% <66.667%> (-1.314%)` | `30 <0> (-1)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `66.667% <0%> (-3.333%)` | `10% <0%> (Ã¸)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=footer). Last update [d40ccc2...d5c85bb](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2515#issuecomment-288529799:2064,Power,Powered,2064,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2515#issuecomment-288529799,1,['Power'],['Powered']
Energy Efficiency,"iff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `90.476% <0%> (+1.587%)` | `61% <0%> (+2%)` | :arrow_up: |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `66.667% <0%> (+3.252%)` | `4% <0%> (Ã¸)` | :arrow_down: |; | [...g/broadinstitute/hellbender/engine/AuthHolder.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXV0aEhvbGRlci5qYXZh) | `15.254% <0%> (+5.085%)` | `2% <0%> (Ã¸)` | :arrow_down: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `77.703% <0%> (+6.757%)` | `22% <0%> (+4%)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `86.4% <0%> (+8.8%)` | `35% <0%> (+7%)` | :arrow_up: |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=footer). Last update [5ccfd00...b1d407f](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2540#issuecomment-290122549:3968,Power,Powered,3968,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2540#issuecomment-290122549,1,['Power'],['Powered']
Energy Efficiency,ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more**. 00:59 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:55:54 INFO TaskSetManager: Starting task 1.1 in stage,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:26035,schedul,scheduler,26035,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 01:12 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:56:07 INFO TaskSetManager: Starting task 1.2 in stage 2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:30533,schedul,scheduler,30533,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 01:44 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:56:39 INFO TaskSetManager: Starting task 1.3 in stage 2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:33130,schedul,scheduler,33130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,"ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 02:12 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:28724,schedul,scheduler,28724,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,"ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 02:34 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:31423,schedul,scheduler,31423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,"ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 18/04/24 17:40:52 INFO TaskSetManager: Lost task 0.0 in stage 2.0 (TID 3) on xx.xx.xx.25, executor 2: org.broadins",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:25537,schedul,scheduler,25537,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,"ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; 18/04/24 17:42:02 INFO DAGScheduler: Job 2 failed: count at PathSeqPipelineSpark.java:245, too",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:35161,schedul,scheduler,35161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,"ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; 18/04/24 17:56:39 INFO DAGScheduler: Job 2 failed: count at PathSeqPipelineSpark.java:245, too",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:36280,schedul,scheduler,36280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAnd,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:39611,schedul,scheduler,39611,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAnd,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:40357,schedul,scheduler,40357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more; 18/04/24 17:42:11 INFO ShutdownHookManager: Shutdown hook called; 18/04/24 17:42:11 INFO ShutdownHookManager: Dele,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:45758,schedul,scheduler,45758,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,"ile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more**. 00:59 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:55:54 INFO TaskSetManager: Starting task 1.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 1, partition 1, PROCESS_LOCAL, 5371 bytes); ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:26114,schedul,scheduler,26114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,"ile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 01:12 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:56:07 INFO TaskSetManager: Starting task 1.2 in stage 2.0 (TID 9, xx.xx.xx.27, executor 0, partition 1, PROCESS_LOCAL, 5371 bytes); 18",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:30612,schedul,scheduler,30612,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,"ile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 01:44 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:56:39 INFO TaskSetManager: Starting task 1.3 in stage 2.0 (TID 10, xx.xx.xx.16, executor 3, partition 1, PROCESS_LOCAL, 5371 bytes); 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:33209,schedul,scheduler,33209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,"ile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 02:12 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:41:31 INFO TaskSetManager: Start",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:28803,schedul,scheduler,28803,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,"ile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 02:34 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:41:53 INFO TaskSetManager: Start",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:31502,schedul,scheduler,31502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,"ile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 18/04/24 17:40:52 INFO TaskSetManager: Lost task 0.0 in stage 2.0 (TID 3) on xx.xx.xx.25, executor 2: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:25616,schedul,scheduler,25616,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,"ile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; 18/04/24 17:42:02 INFO DAGScheduler: Job 2 failed: count at PathSeqPipelineSpark.java:245, took 117.869179 s; 18/04/24 17:42:02 INFO SparkUI: Stopped Spark web UI at http://",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:35240,schedul,scheduler,35240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,"ile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; 18/04/24 17:56:39 INFO DAGScheduler: Job 2 failed: count at PathSeqPipelineSpark.java:245, took 45.308012 s; 18/04/24 17:56:39 INFO SparkUI: Stopped Spark web UI at http://x",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:36359,schedul,scheduler,36359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,ile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGSc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:39690,schedul,scheduler,39690,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,ile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGSc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:40436,schedul,scheduler,40436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,"ils/genotyper/SampleList.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvU2FtcGxlTGlzdC5qYXZh) | `75.676% <0%> (Ã¸)` | `8% <0%> (?)` | |; | [...hellbender/tools/walkers/annotator/SampleList.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TYW1wbGVMaXN0LmphdmE=) | `81.25% <0%> (+1.658%)` | `9% <0%> (Ã¸)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (Ã¸)` | :arrow_down: |; | [.../broadinstitute/hellbender/tools/exome/Sample.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9TYW1wbGUuamF2YQ==) | `100% <0%> (+12.308%)` | `5% <0%> (-21%)` | :arrow_down: |; | [...stitute/hellbender/engine/ReferenceFileSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlRmlsZVNvdXJjZS5qYXZh) | `72.727% <0%> (+15.584%)` | `4% <0%> (-4%)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=footer). Last update [62d58c5...fde9d36](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2556#issuecomment-290787479:3513,Power,Powered,3513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2556#issuecomment-290787479,1,['Power'],['Powered']
Energy Efficiency,"imated size 14.5 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:34044 (size: 2.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/11 14:19:18 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.2 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KB, free 529.7 MB); 17/10/11 14:1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:11059,schedul,scheduler,11059,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"ime: 37.98 minutes.; Runtime.totalMemory()=23999283200; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 1.0 failed 1 times, most recent failure: Lost task 20.0 in stage 1.0 (TID 891, localhost, executor driver): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 131031 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(Spar",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:2832,schedul,scheduler,2832,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['schedul'],['scheduler']
Energy Efficiency,implement an efficient overlaps function for collections of Locatable,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/559:13,efficient,efficient,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/559,1,['efficient'],['efficient']
Energy Efficiency,"in memory (estimated size 25.3 KB, free 8.4 GB); 18/03/07 20:31:50 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:41567 (size: 25.3 KB, free: 8.4 GB); 18/03/07 20:31:50 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 20:31:50 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7175 for farrell on ha-hdfs:scc; 18/03/07 20:31:50 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7175 for farrell); 18/03/07 20:31:50 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 20:31:51 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 629 output partitions; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.9 KB, free 8.4 GB); 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting 629 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 20:31:51 INFO cluster.YarnScheduler",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:5653,schedul,scheduler,5653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,1,['schedul'],['scheduler']
Energy Efficiency,"in memory (estimated size 25.5 KB, free 8.4 GB); 18/03/07 13:24:28 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:32895 (size: 25.5 KB, free: 8.4 GB); 18/03/07 13:24:28 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 13:24:28 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7164 for farrell on ha-hdfs:scc; 18/03/07 13:24:28 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7164 for farrell); 18/03/07 13:24:28 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 13:59:26 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 13:59:26 INFO cluster.YarnSched",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:2079,schedul,scheduler,2079,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304,1,['schedul'],['scheduler']
Energy Efficiency,"in stage 1.0 (TID 1, com2, executor 1): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$26/353370312.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:28 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 1.0 (TID 2, com2, executor 1, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Disabling executor 1.; 17/10/11 14:19:28 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 1); 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.; 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, com2, 38568); 17/10/11 14:19:28 INFO storage.BlockManagerMaster: Removed 1 successfully in remov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:16634,schedul,scheduler,16634,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"inaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run. ...skipped for brevity... VcfFormatConverter (Picard) Converts VCF to BCF or BCF to VCF.; VcfToIntervalList (Picard) Converts a VCF or BCF file to a Picard Interval List. --------------------------------------------------------------------------------------. Exception in thread ""main"" org.broadinstitute.hellbender.exceptions.UserException: 'FixVcfHead' is not a valid command.; Did you mean this?; FixVcfHeader; 	at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:341); 	at org.broadinstitute.hellbender.Main.setupConfigAndExtractProgram(Main.java:172); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:192); 	at org.broadinstitute.hellbender.Main.main(Main.java:275); ```. I expect something without the stack trace and the scary ""Exception"" message. For example:. ```; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Base Calling: Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run. ...skipped for brevity... VcfFormatConverter (Picard) Converts VCF to BCF or BCF to VCF.; VcfToIntervalList (Picard) Converts a VCF or BCF file to a Picard Interval List. --------------------------------------------------------------------------------------. Did you mean this?; FixVcfHeader; ```. The same happens with unknown commands. The code that should be changed for that is the following, where the `setupConfigAndExtractProgram` call should be also inside the try block:. https://github.com/broadinstitute/gatk/blob/8ac2f102b303f343c4787ad4e3359335641c5121/src/main/java/org/broadinstitute/hellbender/Main.java#L190-L212",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4256:1646,adapt,adapters,1646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4256,1,['adapt'],['adapters']
Energy Efficiency,"indicating MisAssemblySuspect; 18/01/25 17:20:55 WARN org.apache.spark.scheduler.TaskSetManager: Stage 53 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:21:06.632 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 14088 variants.; 17:21:06.647 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 6100; 17:21:06.647 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 240; 17:21:06.647 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 230; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4488; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1355; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1675; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - INV: 0; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/01/25 17:21:07 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 29.0 in stage 61.0 (TID 60915, cwhelan-hg00514-1-cram-samtools-bam-feature-w-1.c.broad-dsde-methods.internal, executor 48): java.lang.IllegalArgumentException: Unexpected CIGAR format with deletion neighboring clipping; cigar elements are: [1190M, 4D, 53M, 2I, 26M, 2I, 31M, 2D, 1450S]; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.validateCigar(SvCigarUtils.java:134); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.getUnclippedReadLength(SvCigarUtils.java:161); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.computeAssociatedDistOnRead(SvCigarUtils.java:330); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.AlignmentInterval.readIntervalAlignedToRefSpan(AlignmentInterval.java:634); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector.extractAltHaplotypeSeq(CpxVariant",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260:4632,schedul,scheduler,4632,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260,1,['schedul'],['scheduler']
Energy Efficiency,inerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1862); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1875); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:33854,schedul,scheduler,33854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"ing: PrintVariantsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!?[0m. 16:58:10.116 INFO PrintVariantsSpark - Initializing engine; 16:58:10.116 INFO PrintVariantsSpark - Done initializing engine; 19/02/18 16:58:10 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19/02/18 16:58:10 INFO org.spark_project.jetty.util.log: Logging initialized @8431ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: Started @8536ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 19/02/18 16:58:11 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 19/02/18 16:58:12 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:8032; 19/02/18 16:58:13 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:10200; 19/02/18 16:58:15 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1550508751046_0004; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an Asc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:4643,schedul,scheduler,4643,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,"institute.hellbender.engine.filters.ReadFilter.lambda$and$cbfb947b$1(ReadFilter.java:30); at org.broadinstitute.hellbender.engine.filters.ReadFilter.lambda$and$cbfb947b$1(ReadFilter.java:30); at org.broadinstitute.hellbender.engine.filters.ReadFilter.lambda$and$cbfb947b$1(ReadFilter.java:30); at org.broadinstitute.hellbender.engine.filters.WellformedReadFilter.test(WellformedReadFilter.java:31); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.lambda$getReads$e4b35a40$1(GATKSparkTool.java:196); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:390); at scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388); at scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327); at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:189); at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:64); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41); at org.apache.spark.scheduler.Task.run(Task.scala:89); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```. ---. @samuelklee commented on [Wed Aug 10 2016](https://github.com/broadinstitute/gatk-protected/issues/642#issuecomment-239064255). @LeeTL1220 have you seen this during your WGS runs? I got it on a few TCGA BAMs, not sure if they're just bad samples?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2878:2170,schedul,scheduler,2170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2878,3,['schedul'],['scheduler']
Energy Efficiency,"ion. M=10^6, k/K=10^3 ; chr1 10000-99 # from 10000 to 10099... ; # perhaps is best not to accept this as it might silence user input errors.; # but what about instead?; chr1 100[00-99]; chr1 10000+100 # 100 bps starting at 10000 so 10000-10099; chr1 4k # only poistion 4000.; chr20 1M+32K # from position 1 million extending to the following 32Kbps.; chr20 1M1+32K # from position 1 million and 1 instead. (avoiding all those 0s). chr1 *:200 # consecutive 200bp intervals for the entire chromosome; chr1 *:200(100) # 200bp intervals with 100 gaps; chr1 *:200/20 # 200bp intervals with an overlap of 20bp.; chr1 *:20/200 # 200bp starting every 20 positions (so 180bp overlap); chr1 *:200~20 # 200bp intervals truncating down to 20bp if necessary. ; chr1 { # we can combine interval specs in blocks if they apply to the same contig(s).; 1M-2M:150(20) # from 1 to 2Mbp 150 intervals with 20bp gap; 20M-25M # a big interval from 20 to 25M.; 40012451-40023451 # another standalone interval ; } . ```; ## Interval exclusion; We could specify the exclused interval in the same file:; ```; chr20 *:200 exclude *10000 11000000+10000 32510000* # 200bp intervals except telomere and centromere regions. chr20 { # another way using blocks.; *:200; } excl {; *10000 ; 11000000+10000 ; 32510000*; }. ```. ## Arbitrary interval list. Some other tools cannot specify intervals if these are very specific... for example in exome analysis targets do not fall at regular intervals and are tailor to the capture used. In this case explicit listing is not avoidable. However there are ways to gain. For one thing the language above allows to pack intervals on the same contig on the block so saving to specify the name at each line. (e.g. ```chr1 { 100-200 3124-5681 ... }````. . However real gains would come from ""publishing"" those list under some unique identifier or stable URL that reduce the need of marshaling the whole interval-file file every time. These lest could be retrieved and cached locally by the engine.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5702:3152,reduce,reduce,3152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5702,1,['reduce'],['reduce']
Energy Efficiency,"ionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:28 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 1.0 (TID 2, com2, executor 1, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Disabling executor 1.; 17/10/11 14:19:28 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 1); 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.; 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, com2, 38568); 17/10/11 14:19:28 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor; 17/10/11 14:19:28 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1507683879816_0006_01_000002 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000002; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(Defa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:17278,schedul,scheduler,17278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"ionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:37 INFO scheduler.TaskSetManager: Starting task 0.3 in stage 1.0 (TID 4, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Disabling executor 2.; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 1); 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, com2, 46254); 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removed 2 successfully in removeExecutor; 17/10/11 14:19:38 ERROR cluster.YarnScheduler: Lost executor 2 on com2: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1507683879816_0006_01_000003; Exit code: 50; Stack trace: ExitCodeException exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(Default",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:24291,schedul,scheduler,24291,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,ipeline.java:471); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.DoublePipeline.toArray(DoublePipeline.java:506); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.calculateLog10GP(GenotypeCopyNumberTriStateSegments.java:198); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.lambda$composeVariantContext$0(GenotypeCopyNumberTriStateSegments.java:125); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.composeVariantContext(GenotypeCopyNumberTriStateSegments.java:141); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.makeCalls(GenotypeCopyNumberTriStateSegments.java:104); at org.broadinstitute.hellbender.tools.exome.germlinehmm.CopyNumberTriStateSegmentCaller.doWork(CopyNumberTriStateSegmentCaller.java:121); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:108); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:166); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:185). ```. You can see all input files here:; /dsde/working/asmirnov,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2898:2009,Reduce,ReduceOps,2009,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2898,1,['Reduce'],['ReduceOps']
Energy Efficiency,irHMM - Total compute time in PairHMM computeLogLikelihoods() : 6.453042841; 15:48:19.347 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 10.39 sec; 15:48:19.348 INFO Mutect2 - Shutting down engine; [28 novembre 2019 15:48:19 CET] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.72 minutes.; Runtime.totalMemory()=3822583808; java.lang.IllegalArgumentException: Cannot construct fragment from more than two reads; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:725); 	at org.broadinstitute.hellbender.utils.read.Fragment.create(Fragment.java:36); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.groupEvidence(AlleleLikelihoods.java:595); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:93); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:251); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:320); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:281); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-559553558:4319,Reduce,ReduceOps,4319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-559553558,1,['Reduce'],['ReduceOps']
Energy Efficiency,irRDD.scala:1028); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7.apply$mcV$sp(PairRDDFunctions.scala:1204); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7.apply(PairRDDFunctions.scala:1203); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7.apply(PairRDDFunctions.scala:1203); 	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1348); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1211); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1190); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). **This is the stack I get when the test completes but fails (note that the expected line count appears to not match the line count of the expected output file in the repo): **. java.lang.AssertionError: line counts expected [2629] but found [507]; 	at org.testng.Assert.fail(Assert.java:94); 	at org.testng.Assert.failNotEquals(Assert.java:496); 	at org.testng.Assert.assertEquals(Assert.java:125); 	at org.testng.Assert.assertEquals(Assert.java:372); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:211); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:19,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:2640,schedul,scheduler,2640,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['schedul'],['scheduler']
Energy Efficiency,"irst 15 tasks are for partitions Vector(0)); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks; 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, com2, executor 1, partition 0, NODE_LOCAL, 4632 bytes); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:45501 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.131.101.145:54024; 17/10/13 18:11:53 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 135 bytes; 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on com2:45501 (size: 2.1 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 565 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88) finished in 0.566 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Job 0 finished: runJob at SparkHadoopMapReduceWriter.scala:88, took 9.524571 s; 17/10/13 18:11:53 INFO io.SparkHadoopMapReduceWriter: Job job_20171013181144_0009 committed.; 17/10/13 18:11:53 INFO server.AbstractConnector: Stopped Spark@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:53 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/13 18:11:54 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 17/10/13 18:11:54 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 17/10/13 18:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:21387,schedul,scheduler,21387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['schedul'],['scheduler']
Energy Efficiency,"is for the number of bias covariates _and_ how to take these numbers and project an approximate memory usage. 2. It would appear that GermlineCNVCaller will, by default, attempt to use all CPU cores available on the machine. From the WDL I see that setting environment variables `MKL_NUM_THREADS` and `OMP_NUM_THREADS` seems to control the parallelism? It would be nice if `GermlineCNVCaller` took a `--threads` and then set these before spawning the python process. 3. Runtime? This would be really nice to have some guidelines around as I get wildly varying results depending on how I'm running. My experimentation is with a) 20 45X WGS samples, b) bin size = 500bp, c) running on a 96-core general purpose machine at AWS with 384GB of memory. My first attempt a) scattered the genome into 48 shards of approximately 115k bins each, representing ~50mb of genome and b) ran 24 jobs concurrently but failed to set the environment variables to control parallelism. In that attempt the first wave of jobs were still running after 24 hours and getting close to finishing up the initial de-noising epoch, with 3/24 having failed due to memory allocation failures. My second attempt, now running, scattered the genome into 150 shards, and is running 12 jobs at a time with 8 cores each and the environment variables set. On the second attempt it looks like the jobs will finish the first denoising epoch in < 1 hour each. That's far faster than the 6x reduction in runtime you might expect if a) runtime is linear in the number of bins and b) runtime is proportional to 1/cpus used. Without doing a lot more experiments it's hard to tell whether the better runtime is due to less fighting over resources (I can imagine 24 jobs each running 96 threads could degrade performance) or because runtime is super-linear vs. number of bins. I'm not asking for total precision, but the current docs are not really enough for anyone outside the GATK team to get the CNV caller up and running in an efficient manner.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6166:2815,efficient,efficient,2815,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6166,1,['efficient'],['efficient']
Energy Efficiency,ite(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:40542,schedul,scheduler,40542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,ite(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:41288,schedul,scheduler,41288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,iter.java:242); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:93); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:56); at org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil.write(SparkHadoopWriter.scala:358); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:132); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 21/04/13 07:32:24 ERROR SparkHadoopWriter: Task attempt_20210413073224_0026_r_000000_0 aborted.; 21/04/13 07:32:24 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 105); org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkH,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:4821,schedul,scheduler,4821,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:8,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3679:3969,schedul,scheduler,3969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679,1,['schedul'],['scheduler']
Energy Efficiency,iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Generated by:. java -Xmx16g -jar /dsde/working/slee/CNV-1.5_HCC1143/resources/gatk-package-4.beta.5-97-g066c0b4-SNAPSHOT-local.jar SparkGenomeReadCounts \; --input /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-CollectReadCountsNormal/inputs/seq/picard_aggregation/G15511/HCC1143_BL/current/HCC1143_BL.bam \; --reference /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-CollectReadCountsNormal/inputs/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta \; --binLength 250 \; --keepXYMT false \; --disableToolDefaul,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3679:11800,schedul,scheduler,11800,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679,1,['schedul'],['scheduler']
Energy Efficiency,iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3679:4563,schedul,scheduler,4563,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679,1,['schedul'],['scheduler']
Energy Efficiency,ith chimeric alignments potentially giving SV signals.; 17:19:47.546 INFO StructuralVariationDiscoveryPipelineSpark - 8559 contigs indicating InsDel; 18/01/25 17:19:47 WARN org.apache.spark.scheduler.TaskSetManager: Stage 29 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:00.012 INFO StructuralVariationDiscoveryPipelineSpark - 324 contigs indicating IntraChrStrandSwitch; 18/01/25 17:20:00 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:11.779 INFO StructuralVariationDiscoveryPipelineSpark - 3946 contigs indicating MappedInsertionBkpt; 18/01/25 17:20:11 WARN org.apache.spark.scheduler.TaskSetManager: Stage 37 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:23.416 INFO StructuralVariationDiscoveryPipelineSpark - 853 contigs indicating Cpx; 18/01/25 17:20:23 WARN org.apache.spark.scheduler.TaskSetManager: Stage 41 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:34.830 INFO StructuralVariationDiscoveryPipelineSpark - 1521 contigs indicating Incomplete; 18/01/25 17:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 45 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:44.949 INFO StructuralVariationDiscoveryPipelineSpark - 5277 contigs indicating Ambiguous; 18/01/25 17:20:45 WARN org.apache.spark.scheduler.TaskSetManager: Stage 49 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:55.516 INFO StructuralVariationDiscoveryPipelineSpark - 15 contigs indicating MisAssemblySuspect; 18/01/25 17:20:55 WARN org.apache.spark.scheduler.TaskSetManager: Stage 53 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:21:06.632 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 14088,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260:2908,schedul,scheduler,2908,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260,1,['schedul'],['scheduler']
Energy Efficiency,"itioner$$anonfun$13.apply(Partitioner.scala:303); 	at org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:301); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 18/07/24 21:02:27 ERROR org.apache.spark.scheduler.TaskSetManager: Task 1 in stage 0.0 failed 4 times; aborting job; 18/07/24 21:02:27 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@42ecc554{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 21:02:27.703 INFO PrintReadsSpark - Shutting down engine; [July 24, 2018 9:02:27 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.32 minutes.; Runtime.totalMemory()=2463629312; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 7, shuang-small-m.c.broad-dsde-methods.internal, executor 2): htsjdk.samtools.SAMFormatException: Invalid GZIP header; 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:121); 	at htsjdk.samtools.util.BlockGunzipper.unzipBlock(BlockGunzipper.java:96); 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:550); 	at htsjdk.samtools.util.BlockCompressed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:11129,schedul,scheduler,11129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['schedul'],['scheduler']
Energy Efficiency,itioner$$anonfun$13.apply(Partitioner.scala:303); 	at org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:301); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); 	at org.apa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:14784,schedul,scheduler,14784,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['schedul'],['scheduler']
Energy Efficiency,"itions; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.9 KB, free 366.0 MB); 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:44818 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157) (first 15 tasks are for partitions Vector(0)); 17/10/13 18:11:44 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks; 17/10/13 18:11:45 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1); 17/10/13 18:11:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.131.101.145:54024) with ID 1; 17/10/13 18:11:48 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1); 17/10/13 18:11:48 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 4877 bytes); 17/10/13 18:11:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:45501 with 366.3 MB RAM, BlockManagerId(1, com2, 45501, None); 17/10/13 18:11:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:17648,schedul,scheduler,17648,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['schedul'],['scheduler']
Energy Efficiency,itute.hellbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:219); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:197); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7090:12385,Reduce,ReduceOps,12385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7090,1,['Reduce'],['ReduceOps']
Energy Efficiency,"itute/gatk/pull/2594?src=pr&el=h1) Report; > Merging [#2594](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/2ecdef4fba1658930c388676be3e388efd67b6a3?src=pr&el=desc) will **increase** coverage by `0.002%`.; > The diff coverage is `0%`. ```diff; @@ Coverage Diff @@; ## master #2594 +/- ##; ===============================================; + Coverage 75.985% 75.987% +0.003% ; - Complexity 11033 11034 +1 ; ===============================================; Files 769 769 ; Lines 40058 40058 ; Branches 6979 6979 ; ===============================================; + Hits 30438 30439 +1 ; Misses 6981 6981 ; + Partials 2639 2638 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...tute/hellbender/tools/BwaMemIndexImageCreator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Cd2FNZW1JbmRleEltYWdlQ3JlYXRvci5qYXZh) | `71.429% <0%> (Ã¸)` | `2 <0> (Ã¸)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `95.313% <0%> (+1.563%)` | `22% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=footer). Last update [2ecdef4...a853f7c](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2594#issuecomment-293665515:1767,Power,Powered,1767,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2594#issuecomment-293665515,1,['Power'],['Powered']
Energy Efficiency,"j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```. By backtracking, the problem goes away at commit d827adc81266c788482c9cb4f119f2e3c1e152b8. Since spark-submmit was broken after 8af8bcc920ee5f393562e3e632d9ccd4acd9a638, the bug could be anywhere between commit 8af8bcc920ee5f393562e3e632d9ccd4acd9a638 and d25894b3bc80e450210cf8a9124c4171e65f3717. The log4j.property file is below:; ```; # Set everything to be logged to the console; log4j.rootCategory=WARN,console; log4j.appender.console=org.apache.log4j.ConsoleAppender; log4j.appender.console.target=System.out; log4j.appender.console.layout=org.apache.log4j.PatternLayout; log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n. log4j.appender.file=org.apache.log4j.FileAppender; log4j.appender.file.file=/tmp/logs/spark/log4j-block_manager-output.txt; log4j.appender.file.layout=org.apache.log4j.PatternLayout; log4j.appender.file.layout.ConversionPattern=%d{ABSOLUTE} %p %c{1}: %m%n. # Settings to quiet third party logs that are too verbose; log4j.logger.org.eclipse.jetty=WARN; log4j.logger.org.eclipse.jetty.util.component.AbstractLifeCycle=ERROR; log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=WARN; log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=WARN; #log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO; #log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO. # added to suppres LiveListenerBus ; log4j.logger.org.apache.spark.scheduler.LiveListenerBus=OFF. #log4j.logger.org.apache.spark.storage.ShuffleBlockFetcherIterator=TRACE,file; log4j.logger.org.apache.spark.storage.ShuffleBlockFetcherIterator=WARN,file; log4j.additivity.org.apache.spark.storage.ShuffleBlockFetcherIterator=false; #log4j.logger.org.apache.spark.network.shuffle.OneForOneBlockFetcher=TRACE,file; #log4j.additivity.org.apache.spark.network.shuffle.OneForOneBlockFetcher=false; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2734:3202,schedul,scheduler,3202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2734,1,['schedul'],['scheduler']
Energy Efficiency,"java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350) ~[?:?]; at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; 11:00:54.078 INFO AbstractConnector - Stopped Spark@2f829853{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}; 11:00:54.091 INFO SparkUI - Stopped Spark web UI at http://172.20.19.130:4040; 11:00:54.122 INFO MapOutputTrackerMasterEndpoint - MapOutputTrackerMaste",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:23185,schedul,scheduler,23185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$transformToDuplicateNames$17d832cf$1(MarkDuplicatesSparkUtils.java:123); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:199); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). #### Steps to reproduce; Run the MarkDuplicatesSpark in a local SPARK cluster. The following function return a null, which cause the exception. public static String getLibrary( final GATKRead read, final SAMFileHeader header, String defaultLibrary) {; final SAMReadGroupRecord readGroup = getSAMReadGroupRecord(read, header);; String library = readGroup != null ? readGroup.getLibrary() : null;; return library==null? defaultLibrary : library;; }. public EmptyFragment(GATKRead read, SAMFileHeader header, Map<String, Byt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5169:3951,schedul,scheduler,3951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5169,1,['schedul'],['scheduler']
Energy Efficiency,"java:125); 	... 18 more; 19/02/18 16:58:29 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 16:58:29.970 INFO PrintVariantsSpark - Shutting down engine; [February 18, 2019 4:58:29 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.34 minutes.; Runtime.totalMemory()=1106771968; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException; Serialization trace:; genotypes (htsjdk.variant.variantcontext.VariantContext); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:9615,schedul,scheduler,9615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,"java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1572); at java.base/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1529); at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). 11:00:53.977 INFO DAGScheduler - Job 1 failed: runJob at SparkHadoopWriter.scala:83, took 3.799268 s; 11:00:53.979 ERROR SparkHadoopWriter - Aborting job job_202408111100502620487673658411251_0021.; org.apache.spark.SparkException: Job aborted due to stage failure: Task serialization failed: java.lang.OutOfMemoryError: Required array lengt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:7727,schedul,scheduler,7727,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1572); at java.base/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1529); at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adap,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:12051,schedul,scheduler,12051,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1572); at java.base/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1529); at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(Res,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:30770,schedul,scheduler,30770,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1572); at java.base/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1529); at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 11:00:54.334 INFO ShutdownHookManager - Shutdown hook called; 11:00:54.335 INFO ShutdownHookManager - Deleting directory /raid/tmp/d6/c66ba827e22dbc38625af1cbc85adc/tmp/spark-f9c7c336-4e98-4fcc-855b-ba8a5a29e074; ```. The first lines of the log file:; ```; vm.max_map_count = 2147483642; Using GATK jar /Public/Everythings/misc/gatk-4.4.0.0/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:36641,schedul,scheduler,36641,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"java:157) finished in 8.668 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: running: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: failed: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.8 KB, free 365.9 MB); 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KB, free 365.8 MB); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:44818 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244) (first 15 tasks are for partitions Vector(0)); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks; 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, com2, executor 1, partition 0, NODE_LOCAL, 4632 bytes); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:45501 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.131.101.145:54024; 17/10/13 18:11:53 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 135 bytes; 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on com2:45501 (size: 2.1 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:20223,schedul,scheduler,20223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['schedul'],['scheduler']
Energy Efficiency,"java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 13:59:26 INFO cluster.YarnScheduler: Adding task set 0.0 with 252 tasks; 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 0, scc-q05.scc.bu.edu, executor 4, partition 2, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 25.0 in stage 0.0 (TID 1, scc-q10.scc.bu.edu, executor 3, partition 25, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 0.0 (TID 2, scc-q07.scc.bu.edu, executor 1, partition 15, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 3, scc-q16.scc.bu.edu, executor 8, partition 4, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 4, scc-q14.scc.bu.edu, executor 2, partition 3, NODE_LOCAL, 6147 bytes). ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:3133,schedul,scheduler,3133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304,5,['schedul'],['scheduler']
Energy Efficiency,"jects/GATK/bin/current/GenomeAnalysisTK.jar -T HaplotypeCaller -R /humgen/gsa-hpprojects/GATK/bundle/2.8/hg19/ucsc.hg19.fasta -I /humgen/gsa-scr1/schandra/trevorconley_HaplotypeCallerNotCallingVariant/PersImmune_GATK/case/01-MDS-03A_CD14_interval.bam -o Sheila.HaplotypeCaller.g.vcf -bamout SheilaHaplotypeCaller.bam -L chr6:57397901-57398501 -ERC GVCF`. ---. @vruano commented on [Wed Dec 07 2016](https://github.com/broadinstitute/gsa-unstable/issues/1530#issuecomment-265534394). It seems that this missed variant is a assembly problem. The region has quite a few events resulting in very complex graphs with may possible haplotypes. . If one adds the -debug -l DEBUG options you can see in the logs that the number of haplotypes for kmer size 10 hits the default maximum of 128. If one increases the limit to 512 ```(-maxNumHaplotypesInPopulation 512)``` then the variant comes up in the output. . When such a limit is hit, we reduce the number of haplotypes for further analysis using an algorithm that calculates a pseudo likelihood based on the reads that support different paths in the graph. . One would hope that this algorithm would pick up at least one of the haplotypes that contain that variant amongst the top 128 haplotypes for any kmer size, however in this instance this is not the case. So we need to verify that that algorithm is doing what is supposed to do and if so, whether we can change the way such a pseudo likelihood is calculated in order to make a better selection for this case and in general. ---. @vruano commented on [Wed Dec 07 2016](https://github.com/broadinstitute/gsa-unstable/issues/1530#issuecomment-265535122). Also increase the kmer size to 35 does the job (-kmerSize 35) I guess that that prevents non-ref paths merge back into the reference between events thus resulting in less complex graphs. ---. @vruano commented on [Wed Dec 07 2016](https://github.com/broadinstitute/gsa-unstable/issues/1530#issuecomment-265535498). The user can be inform of using t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2954:3123,reduce,reduce,3123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2954,1,['reduce'],['reduce']
Energy Efficiency,"k 9.0 in stage 6.0 (TID 524, localhost, executor 1, partition 9, NODE_LOCAL, 5598 bytes); 18/09/08 10:32:50 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 6.0 (TID 515, localhost, executor 1): java.lang.NullPointerException; 	at org.broadinstitute.hellbender.utils.read.markduplicates.sparkrecords.EmptyFragment.<init>(EmptyFragment.java:35); 	at org.broadinstitute.hellbender.utils.read.markduplicates.sparkrecords.MarkDuplicatesSparkRecord.newEmptyFragment(MarkDuplicatesSparkRecord.java:37); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$null$0(MarkDuplicatesSparkUtils.java:114); 	at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$transformToDuplicateNames$17d832cf$1(MarkDuplicatesSparkUtils.java:123); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:199); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(S",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5169:3055,Reduce,ReduceOps,3055,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5169,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"k the `Optimized` version deals with avoiding replicating reads in a more nuanced manner, but if I understand correctly, it doesn't seem to me to avoid the shuffle. It looks like it essentially ignores the concept of data locality entirely, and potentially transfers a lot of data over the network. (Equivalent to performing a shuffle on a sorted file in HDFS.). IMO, the current ""shuffle"" implementation is already a ""Spark-y"" way to do it, but with multiple inefficiencies:; - Reads/variants are keyed to their corresponding shards, replicating reads if they cross over shard boundaries. This necessitates an `aggregateByKey` operation that potentially reshuffles the entire data set at the end to deal with neighboring shards that could be hashed to different machines.; - The impl uses `cogroup` and `groupByKey`, which require materializing all values for a key in memory (which could be large). Best to avoid these if possible.; - And related to the previous issue, the join strategy for reads and variants is basically a cross-product-and-filter, which is not very efficient, especially considering that the data can be ordered. I think the best implementation here would steal JP's method of sharding the reads/variants, but make use of `repartitionAndSortWithinPartition`, which lets you specify what partition to use and also sorts all the values within a given partition. This means that we could employ a sort-merge on each partition, and only scan through the datasets once after shuffling them. Do you already have an impl for doing a sort-merge of `Locatable`s? These can be a bit tricky. I wrote one for the `ShuffleRegionJoin` impl in ADAM, but there are semantic differences that would make it less efficient to use. (Specifically, it would require the `aggregateByKey` operation and also creating `SimpleInterval`-style objects from a separate model.). Finally, I would also add the ability to specify which join strategy to use separately for the reference bases and the variants.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1007#issuecomment-151721602:1078,efficient,efficient,1078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1007#issuecomment-151721602,2,['efficient'],['efficient']
Energy Efficiency,k.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1083); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:17307,schedul,scheduler,17307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,k.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:13897,schedul,scheduler,13897,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['schedul'],['scheduler']
Energy Efficiency,k.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:40777,schedul,scheduler,40777,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,k.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:41523,schedul,scheduler,41523,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,k.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1936); at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1002); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.reduce(RDD.scala:984); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1127); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1104); at org.apache.spark.api.java.JavaRDDLike$class.treeAggregate(JavaRDDLike.scala:438); at org.apache.spark.api.java.AbstractJavaRDDLike.treeAggregate(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.apply(BaseRecalibratorSparkFn.java:39); at org.broadinstitute.hellbender.tools.spark.Base,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515:4729,reduce,reduce,4729,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515,1,['reduce'],['reduce']
Energy Efficiency,"k/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `86.025% <0%> (+4.561%)` | `30% <0%> (+6%)` | :arrow_up: |; | [...ute/hellbender/tools/spark/bwa/BwaSparkEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `94.805% <0%> (+4.805%)` | `8% <0%> (+3%)` | :arrow_up: |; | [...titute/hellbender/tools/spark/sv/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkTWV0YWRhdGEuamF2YQ==) | `89.297% <0%> (+7.018%)` | `33% <0%> (+11%)` | :arrow_up: |; | [...ute/hellbender/utils/bwa/BwaMemAlignmentUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9id2EvQndhTWVtQWxpZ25tZW50VXRpbHMuamF2YQ==) | `85.507% <0%> (+13.093%)` | `17% <0%> (+1%)` | :arrow_up: |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `55.233% <0%> (+14.764%)` | `38% <0%> (+10%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=footer). Last update [d054e7a...8ecb688](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2581#issuecomment-292631877:3907,Power,Powered,3907,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2581#issuecomment-292631877,1,['Power'],['Powered']
Energy Efficiency,kContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:14148,schedul,scheduler,14148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['schedul'],['scheduler']
Energy Efficiency,kContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:14867,schedul,scheduler,14867,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,"kException: Job aborted due to stage failure: Task 8 in stage 0.0 failed 1 times, most recent failure: Lost task 8.0 in stage 0.0 (TID 8, localhost): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 126542 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1936); at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1002); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515:3914,schedul,scheduler,3914,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515,1,['schedul'],['scheduler']
Energy Efficiency,ke.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:1981,schedul,scheduler,1981,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,1,['schedul'],['scheduler']
Energy Efficiency,"l is 1); 17/10/13 18:11:48 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 4877 bytes); 17/10/13 18:11:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:45501 with 366.3 MB RAM, BlockManagerId(1, com2, 45501, None); 17/10/13 18:11:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:45501 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:51 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:45501 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4638 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.668 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: running: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: failed: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.8 KB, free 365.9 MB); 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KB, free 365.8 MB); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:44818 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:19346,schedul,scheduler,19346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['schedul'],['scheduler']
Energy Efficiency,"l with similar VAF that is detected in the vcf output(chr12:25380275). **chr12** 25380275Â Â  .Â Â Â  TÂ Â Â  GÂ Â Â  .Â Â Â  .Â Â Â Â  AS\_SB\_TABLE=3911,5343|26,21;DP=9485;ECNT=1;MBQ=36,36;MFRL=0,0;MMQ=42,42;MPOS=18;POPAF=7.30;TLOD=53.53Â Â Â Â  GT:AD:AF:DP:F1R2:F2R1:SBÂ Â  0/1:9254,47:4.970e-03:9301:5321,21:3867,26:3911,5343,26,21. The input and the output BAMs show this call with the variant. ![](https://gatk.broadinstitute.org/hc/user_images/FVlI3WhNIzYK7NB7PakCmw.png). In the logs, it shows the detection of an active region here:. 08:01:23.642 INFOÂ  Mutect2Engine - Assembling chr12:**2538**0238-**2538**0327 with 19912 reads:Â Â Â  (with overlap region = chr12:**2538**0138-**2538**0427). 08:01:24.119 INFOÂ  EventMap - >> Events = EventMap{chr12:**2538**0275-**2538**0275 \[T\*, G\],}. 08:01:24.154 INFOÂ  AssemblyResultSet - Trimming active region AssemblyRegion chr12:**2538**0238-**2538**0327 active?=true nReads=19912 with 2 haplotypes. 08:01:24.154 INFOÂ  AssemblyResultSet - Trimmed region to chr12:**2538**0255-**2538**0295 and reduced number of haplotypes from 2 to only 2. 08:01:25.383 INFOÂ  EventMap - >> Events = EventMap{chr12:**2538**0275-**2538**0275 \[T\*, G\],}. I have tried troubleshooting with the steps stated in this \[blog\](/hc/en-us/articles/360043491652-When-HaplotypeCaller-and-Mutect2-do-not-call-an-expected-variant). However, it does not change the output vcf. I used the force-calling mode by giving the above call in an input vcf and the call did appear in the vcf file. **chr12** 25398285Â Â  .Â Â Â  CÂ Â Â  AÂ Â Â  .Â Â Â  .Â Â Â Â  AS\_SB\_TABLE=4312,3630|14,8;DP=8096;ECNT=1;MBQ=36,36;MFRL=0,0;MMQ=42,42;MPOS=22;POPAF=7.30;TLOD=14.69Â Â Â Â  GT:AD:AF:DP:F1R2:F2R1:SBÂ Â  0/1:7942,22:2.576e-03:7964:3609,8:4268,13:4312,3630,14,8. However, I cannot rely on force-calling mutations on a set of calls. I am unsure if I am missing out more calls that are not showing up. Are there any parameters I need to tune so that I do not miss calls like above?<br><br><i>(created from <a href='https://broadinstitute.ze",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7232:3114,reduce,reduced,3114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7232,1,['reduce'],['reduced']
Energy Efficiency,"l=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50cy5qYXZh) | `80% <100%> (Ã¸)` | `119 <0> (Ã¸)` | :arrow_down: |; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.491% <20%> (-0.411%)` | `32 <0> (Ã¸)` | |; | [...ls/walkers/genotyper/afcalc/ExactAFCalculator.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `81.818% <50%> (-8.182%)` | `6 <3> (+3)` | |; | [...stitute/hellbender/utils/genotyper/AlleleList.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvQWxsZWxlTGlzdC5qYXZh) | `89.744% <0%> (+1.282%)` | `16% <0%> (Ã¸)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2528?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2528?src=pr&el=footer). Last update [c62914a...cc1b2b9](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2528#issuecomment-288859643:3970,Power,Powered,3970,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2528#issuecomment-288859643,1,['Power'],['Powered']
Energy Efficiency,lVariationDiscoveryPipelineSpark - Used 3957 evidence target links to annotate assembled breakpoints; 00:47:25.226 INFO StructuralVariationDiscoveryPipelineSpark - Called 336 imprecise deletion variants; 00:47:25.264 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 9651 variants.; 00:47:25.280 INFO StructuralVariationDiscoveryPipelineSpark - INV: 281; 00:47:25.281 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5630; 00:47:25.281 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 2248; 00:47:25.281 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1492; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/04/27 00:47:28 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:33 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2685 KB). The maximum recommended task size is 100 KB.; 00:47:39.417 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 00:47:39 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:47:47.083 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 00:47:48.135 INFO StructuralVariationDiscoveryPipelineSpark - 23702 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 00:47:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:57 WARN org.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:1058,schedul,scheduler,1058,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,lVariationDiscoveryPipelineSpark - Used 3957 evidence target links to annotate assembled breakpoints; 02:20:10.082 INFO StructuralVariationDiscoveryPipelineSpark - Called 336 imprecise deletion variants; 02:20:10.121 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 9651 variants.; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - INV: 281; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5630; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 2248; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1492; 02:20:10.147 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/04/27 02:20:12 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:18 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2599 KB). The maximum recommended task size is 100 KB.; 02:20:24.460 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 02:20:24 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:32.040 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 02:20:33.079 INFO StructuralVariationDiscoveryPipelineSpark - 23841 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 02:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:42 WARN org.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:4924,schedul,scheduler,4924,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,lVariationDiscoveryPipelineSpark - Used 3968 evidence target links to annotate assembled breakpoints; 17:19:09.449 INFO StructuralVariationDiscoveryPipelineSpark - Called 765 imprecise deletion variants; 17:19:09.490 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 8919 variants.; 17:19:09.509 INFO StructuralVariationDiscoveryPipelineSpark - INV: 195; 17:19:09.509 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5360; 17:19:09.509 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1569; 17:19:09.509 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1795; 17:19:09.519 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 17:19:09.520 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 17:19:09.520 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 17:19:09.520 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 17:19:09.520 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/01/25 17:19:14 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 18/01/25 17:19:24 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (4378 KB). The maximum recommended task size is 100 KB.; 17:19:33.313 INFO StructuralVariationDiscoveryPipelineSpark - Processing 821484 raw alignments from 708052 contigs.; 18/01/25 17:19:33 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:19:46.133 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 573670 contigs.; 17:19:46.995 INFO StructuralVariationDiscoveryPipelineSpark - 23730 contigs with chimeric alignments potentially giving SV signals.; 17:19:47.546 INFO StructuralVariationDiscoveryPipelineSpark - 8559 contigs indicating InsDel; 18/01/25 17:19:47 WARN org.apache.spark.scheduler.TaskSetManager: Stage 29 contains a task of very l,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260:1158,schedul,scheduler,1158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260,1,['schedul'],['scheduler']
Energy Efficiency,"la.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-02-17 16:25:48 INFO BlockManagerInfo:54 - Added taskresult_1024 in memory on scc-q02.scc.bu.edu:34157 (size: 4.5 MB, free: 42.5 GB); 2019-02-17 16:25:48 INFO TaskSetManager:54 - Starting task 181.1 in stage 5.0 (TID 1122, scc-q02.scc.bu.edu, executor 24, partition 181, NODE_LOCAL, 7996 bytes); 2019-02-17 16:25:48 INFO BlockManagerInfo:54 - Added taskresult_1013 in memory on scc-q08.scc.bu.edu:45340 (size: 4.6 MB, free: 42.5 GB); 2019-02-17 16:25:48 INFO TaskSetManager:54 - Starting task 173.0 in stage 5.0 (TID 1123, scc-q08.scc.bu.edu, executor 18, partition 173, NODE_LOCAL, 7996 bytes); 2019-02-17 16:25:48 INFO TaskSetManager:54 - Finished task 71.0 in stage 5.0 (TID 102",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:6339,schedul,scheduler,6339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,"la.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-02-17 16:25:48 INFO TaskSetManager:54 - Starting task 179.1 in stage 5.0 (TID 1128, scc-q03.scc.bu.edu, executor 9, partition 179, NODE_LOCAL, 7996 bytes); 2019-02-17 16:25:48 INFO BlockManagerInfo:54 - Added taskresult_1008 in memory on scc-q15.scc.bu.edu:35739 (size: 4.5 MB, free: 42.5 GB); 2019-02-17 16:25:48 INFO TaskSetManager:54 - Starting task 182.0 in stage 5.0 (TID 1129, scc-q15.scc.bu.edu, executor 15, partition 182, NODE_LOCAL, 7996 bytes); 2019-02-17 16:25:48 INFO TaskSetManager:54 - Finished task 6.0 in stage 5.0 (TID 948) in 28894 ms on scc-q10.scc.bu.edu (executor 14) (83/189); 2019-02-17 16:25:48 INFO BlockManagerInfo:54 - Removed taskresult_948 on scc-q10",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:12698,schedul,scheduler,12698,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,"la.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-02-17 16:25:49 INFO TaskSetManager:54 - Starting task 186.1 in stage 5.0 (TID 1133, scc-q03.scc.bu.edu, executor 26, partition 186, NODE_LOCAL, 7996 bytes); 2019-02-17 16:25:49 INFO TaskSetManager:54 - Finished task 55.0 in stage 5.0 (TID 1000) in 29228 ms on scc-q10.scc.bu.edu (executor 14) (92/189); 2019-02-17 16:25:49 INFO BlockManagerInfo:54 - Removed taskresult_1000 on scc-q10.scc.bu.edu:43393 in memory (size: 4.8 MB, free: 42.5 GB); 2019-02-17 16:25:49 INFO BlockManagerInfo:54 - Added taskresult_997 in memory on scc-q05.scc.bu.edu:36688 (size: 4.4 MB, free: 42.5 GB); 2019-02-17 16:25:49 INFO BlockManagerInfo:54 - Added taskresult_992 in memory on scc-q02.scc.bu.edu:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:19858,schedul,scheduler,19858,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,"la.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-02-17 16:25:50 INFO TaskSetManager:54 - Starting task 177.1 in stage 5.0 (TID 1140, scc-q08.scc.bu.edu, executor 29, partition 177, NODE_LOCAL, 7996 bytes); 2019-02-17 16:25:50 INFO BlockManagerInfo:54 - Added taskresult_1032 in memory on scc-q05.scc.bu.edu:37576 (size: 4.4 MB, free: 42.5 GB); 2019-02-17 16:25:50 INFO BlockManagerInfo:54 - Added taskresult_996 in memory on scc-q03.scc.bu.edu:42184 (size: 7.3 MB, free: 42.5 GB); 2019-02-17 16:25:50 INFO BlockManagerInfo:54 - Added taskresult_978 in memory on scc-q16.scc.bu.edu:34227 (size: 4.5 MB, free: 42.5 GB); 2019-02-17 16:25:50 INFO TaskSetManager:54 - Finished task 81.0 in stage 5.0 (TID 1032) in 30394 ms on scc-q05.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:30556,schedul,scheduler,30556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,"la.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-02-17 16:25:50 INFO TaskSetManager:54 - Starting task 178.1 in stage 5.0 (TID 1142, scc-q06.scc.bu.edu, executor 23, partition 178, NODE_LOCAL, 7996 bytes); 2019-02-17 16:25:50 INFO TaskSetManager:54 - Finished task 12.0 in stage 5.0 (TID 957) in 30736 ms on scc-q15.scc.bu.edu (executor 15) (117/189); 2019-02-17 16:25:50 INFO BlockManagerInfo:54 - Removed taskresult_957 on scc-q15.scc.bu.edu:35739 in memory (size: 5.2 MB, free: 42.5 GB); 2019-02-17 16:25:50 INFO TaskSetManager:54 - Lost task 181.3 in stage 5.0 (TID 1139) on scc-q02.scc.bu.edu, executor 24: java.lang.IllegalArgumentException (provided start is negative: -1) [duplicate 3]; 2019-02-17 16:25:50 ERROR TaskSetM",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:37996,schedul,scheduler,37996,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,"la.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-02-17 16:25:50 INFO DAGScheduler:54 - Job 4 failed: collect at FindBreakpointEvidenceSpark.java:963, took 30.909355 s; 2019-02-17 16:25:50 INFO AbstractConnector:318 - Stopped Spark@7433ca19{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-02-17 16:25:50 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-02-17 16:25:50 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-02-17 16:25:50 INFO SchedulerExtensionServices:54 - Stoppi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:41605,schedul,scheduler,41605,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,la.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:49399,schedul,scheduler,49399,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,"la.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). 00:11:09.634 ERROR TaskSetManager:70 - Task 15 in stage 1.0 failed 1 times; aborting job; 00:11:09.810 WARN TaskSetManager:66 - Lost task 33.0 in stage 1.0 (TID 528, localhost): TaskKilled (killed intentionally); 00:11:24.786 INFO HaplotypeCallerSpark - Shutting down engine; [May 26, 2017 12:11:24 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 10.58 minutes.; Runtime.totalMemory()=16622026752; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 1.0 failed 1 times, most recent failure: Lost task 15.0 in stage 1.0 (TID 519; , localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:8862,schedul,scheduler,8862,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['schedul'],['scheduler']
Energy Efficiency,la.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:8,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:13303,schedul,scheduler,13303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['schedul'],['scheduler']
Energy Efficiency,la:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3679:4328,schedul,scheduler,4328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679,1,['schedul'],['scheduler']
Energy Efficiency,la:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513:7109,schedul,scheduler,7109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513,1,['schedul'],['scheduler']
Energy Efficiency,la:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:7120,schedul,scheduler,7120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['schedul'],['scheduler']
Energy Efficiency,"lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. 8/02/23 23:06:24 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/02/23 23:06:24 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/02/23 23:06:24 INFO spark.SparkContext: Successfully stopped SparkContext; 23:06:24.240 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [February 23, 2018 11:06:24 PM EST] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 73.92 minutes.; Runtime.totalMemory()=10458497024; org.apache.spark.SparkException: Job aborted due to stage failure: Task 27 in stage 15.0 failed 4 times, most recent failure: Lost task 27.3 in stage 15.0 (TID 29483, scc-q15.scc.bu.edu, executor 13): org.broadinstitute.hellbender.exc eptions.GATKException: Erred when inferring breakpoint location and event type from chimeric alignment:; asm010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:4224,schedul,scheduler,4224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['schedul'],['scheduler']
Energy Efficiency,"lass org.apache.hadoop.mapreduce.TaskAttemptContext, but interface was expected; at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getOutputFile(TemplatedTextOutputFormat.java:50); at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getDefaultWorkFile(TemplatedTextOutputFormat.java:46); at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:995); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:979); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61); at org.apache.spark.scheduler.Task.run(Task.scala:64); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 15/07/14 13:14:53 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1, localhost): java.lang.IncompatibleClassChangeError: Found class org.apache.hadoop.mapreduce.TaskAttemptContext, but interface was expected; at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getOutputFile(TemplatedTextOutputFormat.java:50); at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getDefaultWorkFile(TemplatedTextOutputFormat.java:46); at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:995); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:979); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61); at org.apache.spark.scheduler.Task.run(Task.scala:64); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at ja",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:30795,schedul,scheduler,30795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['schedul'],['scheduler']
Energy Efficiency,"latter positives/negatives, and hence some arbitrariness in the F1 score itself. But I'd expect using gold-standard GIAB truth would be more straightforward. Not sure how much we can conclude, but that the validation and test F1s are similar and that the validation LL score isn't *too* far off are encouraging. That said, there is a pretty big drop in recall when optimizing LL. But we should also expect some discrepancy between LL and F1, according to one of the papers linked above. I would hope that with more variants or reliable training/truth (as in your data), things might stabilize or line up better. I'll try running with more malaria data, as well. The following trios x sites heatmap (top plot) for the validation set might better illustrate the arbitrariness in F1 (click to enlarge):. ![image](https://user-images.githubusercontent.com/11076296/158385585-1a0dfe8e-d4b7-4770-aed0-19ad81162c92.png). Here, yellow = het errors (since these are supposed to be clonal malaria samples), red = Mendelian errors, grey = no calls, green = Mendelian consistency, white = reference. The second plot shows the training/truth positives used to train the model and to calculate the LL score in the validation shard. The third plot shows the ""orthogonal truth"" positives/negatives used to calculate F1. So we can see that the difficulty in deriving F1 as a function of the score along the horizontal axis to give the third plot lies in collapsing the columns in the top plot into a single condition positive or condition negative status. Again, hard to do so without some arbitrariness; I simply came up with some rules to convert various amounts of red, yellow, green, etc. in each column to a red/white/green status. If you're using a single gold-standard sample, this should definitely be more straightforward. In any case, the optimal validation LL score at ~0.02 does appear to line up quite well visually with where one might manually set a threshold. It corresponds pretty well with the trans",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1067396431:1980,green,green,1980,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1067396431,1,['green'],['green']
Energy Efficiency,"lbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `88% <86.667%> (-12%)` | `7 <2> (+7)` | |; | [...ute/hellbender/tools/spark/bwa/BwaSparkEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `89.286% <88%> (+18.697%)` | `5 <5> (+5)` | :white_check_mark: |; | [...itute/hellbender/tools/spark/sv/ContigAligner.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9Db250aWdBbGlnbmVyLmphdmE=) | `88.462% <88.889%> (+6.643%)` | `8 <4> (+8)` | :white_check_mark: |; | [...g/broadinstitute/hellbender/utils/NativeUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9OYXRpdmVVdGlscy5qYXZh) | `25% <Ã¸> (-43.75%)` | `3% <Ã¸> (+3%)` | |; | ... and [96 more](https://codecov.io/gh/broadinstitute/gatk/pull/2367/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2367?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2367?src=pr&el=footer). Last update [9d82097...975121e](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276460872:5068,Power,Powered,5068,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276460872,1,['Power'],['Powered']
Energy Efficiency,lbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:229); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:207); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); > at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); > at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); > at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); > at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); > at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); > at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); > at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); > at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); > at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.Iterator.forEachRemaining(Iterator.java:116); > at java.util.S,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708:20194,Reduce,ReduceOps,20194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708,1,['Reduce'],['ReduceOps']
Energy Efficiency,"lbmRlci91dGlscy9waWxldXAvUGlsZXVwRWxlbWVudC5qYXZh) | `96.04% <0%> (+1.865%)` | `76 <0> (Ã¸)` | :arrow_down: |; | [...bender/tools/exome/HashedListTargetCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9IYXNoZWRMaXN0VGFyZ2V0Q29sbGVjdGlvbi5qYXZh) | `90.741% <0%> (+1.65%)` | `43 <0> (Ã¸)` | :arrow_down: |; | [.../utils/read/markduplicates/DuplicationMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL0R1cGxpY2F0aW9uTWV0cmljcy5qYXZh) | `85.366% <0%> (+2.033%)` | `13 <0> (Ã¸)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/read/CigarUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL0NpZ2FyVXRpbHMuamF2YQ==) | `89.404% <0%> (+0.588%)` | `68 <0> (Ã¸)` | :arrow_down: |; | [...der/utils/locusiterator/AlignmentStateMachine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9sb2N1c2l0ZXJhdG9yL0FsaWdubWVudFN0YXRlTWFjaGluZS5qYXZh) | `87.879% <0%> (+1.312%)` | `27 <1> (Ã¸)` | :arrow_down: |; | ... and [22 more](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=footer). Last update [62d58c5...cd59cde](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2543#issuecomment-290171890:4331,Power,Powered,4331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2543#issuecomment-290171890,1,['Power'],['Powered']
Energy Efficiency,"lculated, genotype is not called or alleleLikelihoodMap is null; 00:10:45.460 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:11:09.609 WARN TaskMemoryManager:381 - leak 166.6 MB memory from org.apache.spark.util.collection.ExternalAppendOnlyMap@60a3c432; 00:11:09.611 ERROR Executor:91 - Exception in task 15.0 in stage 1.0 (TID 519); java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:192); at java.util.stream.ReferencePipeline$7$1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:1874,Reduce,ReduceOps,1874,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"ld stuck at the first step `collect at ReadsSparkSource.java:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1104,schedul,scheduler,1104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['schedul'],['scheduler']
Energy Efficiency,"lection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-02-17 16:25:48 INFO BlockManagerInfo:54 - Added taskresult_1024 in memory on scc-q02.scc.bu.edu:34157 (size: 4.5 MB, free: 42.5 GB); 2019-02-17 16:25:48 INFO TaskSetManager:54 - Starting task 181.1 in stage 5.0 (TID 1122, scc-q02.scc.bu.edu, executor 24, partition 181, NODE_LOCAL, 7996 bytes); 2019-02-17 16:25:48 INFO BlockManagerInfo:54 - Added taskresult_1013 in memory on scc-q08.scc.bu.edu:45340 (size: 4.6 MB, free: 42.5 GB); 2019-02-17 16:25:48 INFO TaskSetManager:54 - Starting task 173.0 in stage 5.0 (TID 1123, scc-q08.scc.bu.edu, executor 18, partition 173, NODE_LOCAL, 7996 bytes); 2019-02-17 16:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:6268,schedul,scheduler,6268,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,"lection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-02-17 16:25:48 INFO TaskSetManager:54 - Starting task 179.1 in stage 5.0 (TID 1128, scc-q03.scc.bu.edu, executor 9, partition 179, NODE_LOCAL, 7996 bytes); 2019-02-17 16:25:48 INFO BlockManagerInfo:54 - Added taskresult_1008 in memory on scc-q15.scc.bu.edu:35739 (size: 4.5 MB, free: 42.5 GB); 2019-02-17 16:25:48 INFO TaskSetManager:54 - Starting task 182.0 in stage 5.0 (TID 1129, scc-q15.scc.bu.edu, executor 15, partition 182, NODE_LOCAL, 7996 bytes); 2019-02-17 16:25:48 INFO TaskSetManager:54 - Finished task 6.0 in stage 5.0 (TID 948) in 28894 ms on scc-q10.scc.bu.edu (executor 14) (83/189); 2019-02-1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:12627,schedul,scheduler,12627,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,"lection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-02-17 16:25:49 INFO TaskSetManager:54 - Starting task 186.1 in stage 5.0 (TID 1133, scc-q03.scc.bu.edu, executor 26, partition 186, NODE_LOCAL, 7996 bytes); 2019-02-17 16:25:49 INFO TaskSetManager:54 - Finished task 55.0 in stage 5.0 (TID 1000) in 29228 ms on scc-q10.scc.bu.edu (executor 14) (92/189); 2019-02-17 16:25:49 INFO BlockManagerInfo:54 - Removed taskresult_1000 on scc-q10.scc.bu.edu:43393 in memory (size: 4.8 MB, free: 42.5 GB); 2019-02-17 16:25:49 INFO BlockManagerInfo:54 - Added taskresult_997 in memory on scc-q05.scc.bu.edu:36688 (size: 4.4 MB, free: 42.5 GB); 2019-02-17 16:25:49 INFO Bloc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:19787,schedul,scheduler,19787,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,"lection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-02-17 16:25:50 INFO TaskSetManager:54 - Starting task 177.1 in stage 5.0 (TID 1140, scc-q08.scc.bu.edu, executor 29, partition 177, NODE_LOCAL, 7996 bytes); 2019-02-17 16:25:50 INFO BlockManagerInfo:54 - Added taskresult_1032 in memory on scc-q05.scc.bu.edu:37576 (size: 4.4 MB, free: 42.5 GB); 2019-02-17 16:25:50 INFO BlockManagerInfo:54 - Added taskresult_996 in memory on scc-q03.scc.bu.edu:42184 (size: 7.3 MB, free: 42.5 GB); 2019-02-17 16:25:50 INFO BlockManagerInfo:54 - Added taskresult_978 in memory on scc-q16.scc.bu.edu:34227 (size: 4.5 MB, free: 42.5 GB); 2019-02-17 16:25:50 INFO TaskSetManager:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:30485,schedul,scheduler,30485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,"lection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-02-17 16:25:50 INFO TaskSetManager:54 - Starting task 178.1 in stage 5.0 (TID 1142, scc-q06.scc.bu.edu, executor 23, partition 178, NODE_LOCAL, 7996 bytes); 2019-02-17 16:25:50 INFO TaskSetManager:54 - Finished task 12.0 in stage 5.0 (TID 957) in 30736 ms on scc-q15.scc.bu.edu (executor 15) (117/189); 2019-02-17 16:25:50 INFO BlockManagerInfo:54 - Removed taskresult_957 on scc-q15.scc.bu.edu:35739 in memory (size: 5.2 MB, free: 42.5 GB); 2019-02-17 16:25:50 INFO TaskSetManager:54 - Lost task 181.3 in stage 5.0 (TID 1139) on scc-q02.scc.bu.edu, executor 24: java.lang.IllegalArgumentException (provided s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:37925,schedul,scheduler,37925,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,"lection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-02-17 16:25:50 INFO DAGScheduler:54 - Job 4 failed: collect at FindBreakpointEvidenceSpark.java:963, took 30.909355 s; 2019-02-17 16:25:50 INFO AbstractConnector:318 - Stopped Spark@7433ca19{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-02-17 16:25:50 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-02-17 16:25:50 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:41534,schedul,scheduler,41534,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,lection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.schedule,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:49328,schedul,scheduler,49328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,"lection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). 00:11:09.634 ERROR TaskSetManager:70 - Task 15 in stage 1.0 failed 1 times; aborting job; 00:11:09.810 WARN TaskSetManager:66 - Lost task 33.0 in stage 1.0 (TID 528, localhost): TaskKilled (killed intentionally); 00:11:24.786 INFO HaplotypeCallerSpark - Shutting down engine; [May 26, 2017 12:11:24 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 10.58 minutes.; Runtime.totalMemory()=16622026752; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 1.0 failed 1 times, most recent failure: Lost task 15.0 in stage 1.0 (TID 519; , localhost): jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:8791,schedul,scheduler,8791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['schedul'],['scheduler']
Energy Efficiency,lection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:13232,schedul,scheduler,13232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['schedul'],['scheduler']
Energy Efficiency,led 336 imprecise deletion variants; 00:47:25.264 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 9651 variants.; 00:47:25.280 INFO StructuralVariationDiscoveryPipelineSpark - INV: 281; 00:47:25.281 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5630; 00:47:25.281 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 2248; 00:47:25.281 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1492; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/04/27 00:47:28 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:33 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2685 KB). The maximum recommended task size is 100 KB.; 00:47:39.417 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 00:47:39 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:47:47.083 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 00:47:48.135 INFO StructuralVariationDiscoveryPipelineSpark - 23702 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 00:47:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:57 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:48:04 WARN org.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:1225,schedul,scheduler,1225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,led 336 imprecise deletion variants; 02:20:10.121 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 9651 variants.; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - INV: 281; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5630; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 2248; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1492; 02:20:10.147 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/04/27 02:20:12 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:18 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2599 KB). The maximum recommended task size is 100 KB.; 02:20:24.460 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 02:20:24 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:32.040 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 02:20:33.079 INFO StructuralVariationDiscoveryPipelineSpark - 23841 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 02:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:42 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:49 WARN org.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:5091,schedul,scheduler,5091,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,led 765 imprecise deletion variants; 17:19:09.490 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 8919 variants.; 17:19:09.509 INFO StructuralVariationDiscoveryPipelineSpark - INV: 195; 17:19:09.509 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5360; 17:19:09.509 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1569; 17:19:09.509 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1795; 17:19:09.519 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 17:19:09.520 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 17:19:09.520 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 17:19:09.520 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 17:19:09.520 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/01/25 17:19:14 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 18/01/25 17:19:24 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (4378 KB). The maximum recommended task size is 100 KB.; 17:19:33.313 INFO StructuralVariationDiscoveryPipelineSpark - Processing 821484 raw alignments from 708052 contigs.; 18/01/25 17:19:33 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:19:46.133 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 573670 contigs.; 17:19:46.995 INFO StructuralVariationDiscoveryPipelineSpark - 23730 contigs with chimeric alignments potentially giving SV signals.; 17:19:47.546 INFO StructuralVariationDiscoveryPipelineSpark - 8559 contigs indicating InsDel; 18/01/25 17:19:47 WARN org.apache.spark.scheduler.TaskSetManager: Stage 29 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:00.012 INFO StructuralVariationDiscoveryPipelineSpark - 324 contigs indicating IntraChrStrandS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260:1325,schedul,scheduler,1325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260,1,['schedul'],['scheduler']
Energy Efficiency,"ler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@64a1116a{/stages/stage,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@c5e69a5{/stages/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@10131289{/stages,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@50f4b83d{/jobs/job/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5d66ae3a{/jobs/job,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@30159886{/jobs/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@33de7f3d{/jobs,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO ui.SparkUI: Stopped Spark web UI at http://10.48.225.55:4041; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/03/07 20:32:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/03/07 20:32:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/03/07 20:32:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/03/07 20:32:55 INFO memory.MemoryStore: MemoryStore cleared; 18/03/07 20:32:55 INFO storage.BlockManager: BlockManager stopped; 18/03/07 20:32:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/03/07 20:32:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/07 20:32:55 INFO spark.SparkContext: Successfully stopped SparkContext; 20:32:55.769 INFO FlagStatSpark - Shutting down engine; [M",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:12670,monitor,monitor,12670,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,1,['monitor'],['monitor']
Energy Efficiency,ler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-l,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:13875,schedul,scheduler,13875,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,ler.failJobAndIndependentStages(DAGScheduler.scala:2672); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2281); at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83); ... 27 more; Caused by: java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; at java.base/jdk.internal.util.Arrays,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:32468,schedul,scheduler,32468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,lerArgumentCollection.createReadThreadingAssembler(AssemblyBasedCallerArgumentCollection.java:36); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.initialize(HaplotypeCallerEngine.java:231); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.<init>(HaplotypeCallerEngine.java:166); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$assemblyFunction$29848511$1(HaplotypeCallerSpark.java:174); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	... 1 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:14264,schedul,scheduler,14264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,2,['schedul'],['scheduler']
Energy Efficiency,lidation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH/NA24631-chr15_68578892_84670250-block.vcf.gz --emitRefConfidence GVCF -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 60 -GQB 80; ```; and the full traceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3659:3083,schedul,scheduler,3083,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659,1,['schedul'],['scheduler']
Energy Efficiency,"lineRunner: Skipping 'CountReadsDataflowTransform/Globally/Combine.Globally/Values/Values'; already in composite transform.; 15/07/14 13:14:52 INFO spark.SparkPipelineRunner: Skipping 'CountReadsDataflowTransform/Globally/Combine.Globally/AsIterable/CreatePCollectionView'; already in composite transform.; 15/07/14 13:14:52 INFO spark.SparkPipelineRunner: Skipping 'CountReadsDataflowTransform/Globally/Combine.Globally/Create'; already in composite transform.; 15/07/14 13:14:52 INFO spark.SparkPipelineRunner: Skipping 'CountReadsDataflowTransform/Globally/Combine.Globally/AnonymousParDo'; already in composite transform.; 15/07/14 13:14:52 INFO spark.SparkPipelineRunner: Post-visiting directly-translatable composite transform: 'CountReadsDataflowTransform/Globally/Combine.Globally'; 15/07/14 13:14:52 INFO spark.SparkPipelineRunner: Evaluating Combine.Globally [Combine.Globally]; 15/07/14 13:14:52 INFO spark.SparkContext: Starting job: aggregate at TransformTranslator.java:183; 15/07/14 13:14:52 INFO scheduler.DAGScheduler: Got job 0 (aggregate at TransformTranslator.java:183) with 1 output partitions (allowLocal=false); 15/07/14 13:14:52 INFO scheduler.DAGScheduler: Final stage: Stage 0(aggregate at TransformTranslator.java:183); 15/07/14 13:14:52 INFO scheduler.DAGScheduler: Parents of final stage: List(); 15/07/14 13:14:52 INFO scheduler.DAGScheduler: Missing parents: List(); 15/07/14 13:14:52 INFO scheduler.DAGScheduler: Submitting Stage 0 (MapPartitionsRDD[4] at map at TransformTranslator.java:181), which has no missing parents; 15/07/14 13:14:52 INFO storage.MemoryStore: ensureFreeSpace(6656) called with curMem=0, maxMem=278019440; 15/07/14 13:14:52 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.5 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(3753) called with curMem=6656, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estim",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:21850,schedul,scheduler,21850,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['schedul'],['scheduler']
Energy Efficiency,"lla BaseRecalibrator works just fine on these bams (so I don't think the issue is with the bam). They are all suffering from the same/similar stacktrace. We've had BaseRecalibratorSpark work fine on other bam files. Additionally, changing the number of threads still results in the same stacktrace. I've also tried running the BQSRPipelineSpark to see if that would suffer the same issue and it fails in the same manner. Additionally, I've run ValidateSamFile. There are some reads missing their mates, but this hasn't presented an issue in other tools (including vanilla BaseRecalibrator). Searching thru the forum, I found an old issue with a similar stacktrace, but that issue appears to occur in GATK 2.4: https://gatkforums.broadinstitute.org/gatk/discussion/3265/bqsrgatherer-exception. In the below stacktrace, I've bolded the error message that seems to occur in each of these samples. `Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:1302,schedul,scheduler,1302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['schedul'],['scheduler']
Energy Efficiency,"llclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-NISTSampleHeadToHead/BenchmarkComparison/8e62c1c2-cf9c-4530-846e-1e0d6c6d8acf/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-NISTSampleHeadToHead/BenchmarkComparison/8e62c1c2-cf9c-4530-846e-1e0d6c6d8acf/call-BenchmarkVCFControlSample/Benchmark/e71074a5-27ad-4a8b-a533-cdc111c0374f/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""73.06777222222223"",; ""NIST evalHCsystemhours"": ""0.1622555555555555"",; ""NIST evalHCwallclockhours"": ""46.65241388888888"",; ""NIST evalHCwallclockmax"": ""2.7461055555555554"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-NISTSampleHeadToHead/BenchmarkComparison/8e62c1c2-cf9c-4530-846e-1e0d6c6d8acf/call-EVALRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9843"",; ""NIST evalindelPrecision"": ""0.9895"",; ""NIST evalsnpF1Score"": ""0.9908"",; ""NIST evalsnpPrecision"": ""0.992"",; ""NIST evalsnpRecall"": ""0.9896"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-NISTSampleHeadToHead/BenchmarkComparison/8e62c1c2-cf9c-4530-846e-1e0d6c6d8acf/call-BenchmarkVCFTestSample/Benchmark/d39f91bf-295b-4a15-bd0b-2b7c6b43a347/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-CreateHTMLReport/report.html""; }; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064:14477,monitor,monitoring,14477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064,1,['monitor'],['monitoring']
Energy Efficiency,llection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.Spar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:14253,schedul,scheduler,14253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,llerSpark.java:174); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.m,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:6491,schedul,scheduler,6491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['schedul'],['scheduler']
Energy Efficiency,"locks(BlockManager.scala:217); 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:236); 	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:522); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); 	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308); 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180); 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 17/10/18 17:35:58 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/10/18 17:35:58 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-1,5,main]; java.lang.OutOfMemoryError: Java heap space; 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:208); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at org.seqdoop.hado",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:5647,Schedul,ScheduledThreadPoolExecutor,5647,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['Schedul'],['ScheduledThreadPoolExecutor']
Energy Efficiency,looks fine. the biggest issue is that now we have completely separate integration tests for dataflow and non-dataflow tools. This is non sustainable i think. can you come up with a way to reuse and keep things in synch? back to @lbergelson,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/443#issuecomment-96791578:137,sustainab,sustainable,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443#issuecomment-96791578,1,['sustainab'],['sustainable']
Energy Efficiency,loud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketIm,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:7065,Meter,MeteredStream,7065,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['Meter'],['MeteredStream']
Energy Efficiency,"louises proposals seems simple and reasonable.... perhaps it should offer to provide a ```Function<R, String>``` to provide a alternative ```toString``` in case the tools natural record ```toString``` does not align well with progress reporting... or perhaps in that case the tool could use an alternative record object that is send to the progress meter instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577273465:349,meter,meter,349,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577273465,1,['meter'],['meter']
Energy Efficiency,ls.java:134)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)** ; **20/03/05 09:28:58 INFO ShutdownHookManager: Shutdown hook called** ; **20/03/05 09:28:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-9e0e0327-45a3-46e8-872a-f5a63c3c7a98** ; **Using GATK jar /mnt/clinix1/Analysis/mongol/phenomata/Tools/Anaconda3/envs/gatk4/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar** ; **Running:** ; **java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamj,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:51132,schedul,scheduler,51132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,"ls.java:134)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)** ; **20/03/05 09:28:58 INFO TaskSetManager: Starting task 40.0 in stage 0.0 (TID 40, localhost, executor driver, partition 40, PROCESS\_LOCAL, 7972 bytes)** ; **20/03/05 09:28:58 INFO Executor: Running task 40.0 in stage 0.0 (TID 40)** ; **20/03/05 09:28:58 WARN TaskSetManager: Lost task 34.0 in stage 0.0 (TID 34, localhost, executor driver): com.esotericsoftware.kryo.KryoException: Buffer underflow.** ; **at com.esotericsoftware.kryo.io.Input.require(Input.java:199)** ; **at com.esotericsoft",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:28700,schedul,scheduler,28700,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,"ls.java:134)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **20/03/05 09:28:58 ERROR TaskSetManager: Task 34 in stage 0.0 failed 1 times; aborting job** ; **20/03/05 09:28:58 INFO TaskSchedulerImpl: Cancelling stage 0** ; **20/03/05 09:28:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 0.0 in stage 0.0 (TID 0), reason: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill task 30.0 in stage 0.0 (TID 30), reason: Stage ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:32148,schedul,scheduler,32148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,"ls.java:134)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **Driver stacktrace:** ; **20/03/05 09:28:58 INFO DAGScheduler: Job 0 failed: count at PathSeqPipelineSpark.java:245, took 63.806676 s** ; **20/03/05 09:28:58 INFO SparkUI: Stopped Spark web UI at http://cm132:4040** ; **20/03/05 09:28:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!** ; **20/03/05 09:28:58 INFO NewHadoopRDD: Input split: file:/clinix1/Analysis/mongol/phenomata/04.GC\_CC/01.Alignment/Aligned/17039\_N.bam:1342177280+33554432** ; **20/03/05 09:2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:40762,schedul,scheduler,40762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,ls.java:134)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **Driver stacktrace:** ; **at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)** ; **at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)** ; **at scala.collection.mutable.Array,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:45189,schedul,scheduler,45189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,ls.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); at org.apache.spark.rdd.RDD.count(RDD.scala:1158); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark.runTool(PathSeqPipelineSpark.java:245); at org.broa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:41449,schedul,scheduler,41449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,ls.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); at org.apache.spark.rdd.RDD.count(RDD.scala:1158); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark.runTool(PathSeqPipelineSpark.java:245); at org.broa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:42195,schedul,scheduler,42195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,ltTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:15356,schedul,scheduler,15356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['schedul'],['scheduler']
Energy Efficiency,ltTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1661); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1649); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1648); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1648); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1882); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1820); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:4254,schedul,scheduler,4254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['schedul'],['scheduler']
Energy Efficiency,ly(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:2176,schedul,scheduler,2176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,1,['schedul'],['scheduler']
Energy Efficiency,ly(RDD.scala:801); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513:6551,schedul,scheduler,6551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513,1,['schedul'],['scheduler']
Energy Efficiency,"m 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 1; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 1; cpu cores	: 14; apicid		: 2; initial apicid	: 2; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 2; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 2; cpu cores	: 14; apicid		: 4; initial apicid	: 4; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 cl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:44631,monitor,monitor,44631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['monitor'],['monitor']
Energy Efficiency,"m 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 2; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 2; cpu cores	: 14; apicid		: 4; initial apicid	: 4; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 3; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 3; cpu cores	: 14; apicid		: 6; initial apicid	: 6; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 cl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:45802,monitor,monitor,45802,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['monitor'],['monitor']
Energy Efficiency,"m 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 3; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 3; cpu cores	: 14; apicid		: 6; initial apicid	: 6; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 4; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 4; cpu cores	: 14; apicid		: 8; initial apicid	: 8; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 cl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:46973,monitor,monitor,46973,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['monitor'],['monitor']
Energy Efficiency,"m 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 4; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 4; cpu cores	: 14; apicid		: 8; initial apicid	: 8; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 5; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 5; cpu cores	: 14; apicid		: 10; initial apicid	: 10; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:48144,monitor,monitor,48144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['monitor'],['monitor']
Energy Efficiency,"mE=) | `96.87% <85.71%> (-1.46%)` | `15 <1> (+1)` | |; | [...lotypecaller/AssemblyBasedCallerUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHNVbml0VGVzdC5qYXZh) | `95.77% <95.28%> (-4.23%)` | `45 <43> (+43)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (Ã¸)` | `2% <0%> (Ã¸)` | :arrow_down: |; | [...te/hellbender/utils/genotyper/ReadLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvUmVhZExpa2VsaWhvb2RzLmphdmE=) | `90.14% <0%> (+0.4%)` | `143% <0%> (Ã¸)` | :arrow_down: |; | ... and [1 more](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5215?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5215?src=pr&el=footer). Last update [8103bde...7d53fb9](https://codecov.io/gh/broadinstitute/gatk/pull/5215?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5215#issuecomment-425465744:4717,Power,Powered,4717,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5215#issuecomment-425465744,1,['Power'],['Powered']
Energy Efficiency,make progress meter async,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6484:14,meter,meter,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6484,1,['meter'],['meter']
Energy Efficiency,mandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.lang.IllegalArgumentException: java.lang.IllegalArgumentException: A reference must be supplied that includes the reference sequence for chr12).; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at java.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:593); 	at java.util.concurrent.ForkJoinTask.reportException(ForkJoinTask.java:677); 	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:735); 	at java.util.stream.ReduceOps$ReduceOp.evaluateParallel(ReduceOps.java:714); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233); 	at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:546); 	at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.lambda$collectCaseStatsParallel$13(CalibrateDragstrModel.java:489); 	at java.util.concurrent.ForkJoinTask$AdaptedCallable.exec(ForkJoinTask.java:1424); 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289); 	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056); 	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692); 	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157); Caused by: java.lang.IllegalArgumentException: A reference must be supplied that includes the reference sequence for chr12).; 	at htsjdk.samtools.cram.ref.CRAMLazyReferenceSource.getReferenceBases(CRAMLazyReferenceSource.java:41); 	at htsjdk.samtools.cram.build.CRAMReferenceR,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7060:2759,Reduce,ReduceOps,2759,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7060,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,mat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:93); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:56); at org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil.write(SparkHadoopWriter.scala:358); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:132); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:16723,schedul,scheduler,16723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,"max"": ""3.457286111111111"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-BenchmarkVCFControlSample/Benchmark/9033775b-223e-4c4a-8dc8-28b281b3f2e1/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""102.1011388888889"",; ""NIST evalHCsystemhours"": ""0.20356111111111105"",; ""NIST evalHCwallclockhours"": ""74.47628888888889"",; ""NIST evalHCwallclockmax"": ""4.013952777777778"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-BenchmarkVCFTestSample/Benchmark/79b5d82e-a482-465f-a161-f82a21b0436f/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535665125:21368,monitor,monitoring,21368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535665125,1,['monitor'],['monitoring']
Energy Efficiency,"max"": ""3.995058333333333"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-NISTSampleHeadToHead/BenchmarkComparison/56974c24-19c8-4f87-b7b1-b71028109732/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-NISTSampleHeadToHead/BenchmarkComparison/56974c24-19c8-4f87-b7b1-b71028109732/call-BenchmarkVCFControlSample/Benchmark/670f9cb4-5bb0-48e2-95c9-15a2e1ae7dee/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""103.23083611111107"",; ""NIST evalHCsystemhours"": ""0.2083694444444444"",; ""NIST evalHCwallclockhours"": ""76.16374166666664"",; ""NIST evalHCwallclockmax"": ""3.743883333333333"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-NISTSampleHeadToHead/BenchmarkComparison/56974c24-19c8-4f87-b7b1-b71028109732/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-NISTSampleHeadToHead/BenchmarkComparison/56974c24-19c8-4f87-b7b1-b71028109732/call-BenchmarkVCFTestSample/Benchmark/b84fd1b7-a21e-4098-aeaf-05de3b35b2df/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550601099:21344,monitor,monitoring,21344,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550601099,1,['monitor'],['monitoring']
Energy Efficiency,mit.main(SparkSubmit.scala); Caused by: java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 16/11/16 23:25:11 INFO SparkUI: Stopped Spark web UI at http://172.32.65.22:4040; 16/11/16 23:25:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 16/11/16 23:25:11 INFO MemoryStore: MemoryStore cleared; 16/11/16 23:25:11 INFO BlockManager: BlockManager stopped; 16/11/16 23:25:11 INFO BlockManagerMaster: BlockManagerMaster stopped; 16/11/16 23:25:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 16/11/16 23:25:11 INFO SparkContext: Successfully stopped SparkContext; 16/11/16 23:25:11 INFO ShutdownHookManager: Shutdown hook c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:24446,schedul,scheduler,24446,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,mon.collect.ImmutableMap.put(ImmutableMap.java:407); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:162); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	... 38 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.internal.io.SparkHadoopM,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545:10129,schedul,scheduler,10129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545,1,['schedul'],['scheduler']
Energy Efficiency,"moryStore cleared; 18/05/01 14:23:29 INFO BlockManager: BlockManager stopped; 18/05/01 14:23:29 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/05/01 14:24:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/05/01 14:25:36 INFO SparkContext: Successfully stopped SparkContext; 14:25:37.027 INFO PathSeqPipelineSpark - Shutting down engine; [May 1, 2018 2:25:37 PM EDT] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 37.98 minutes.; Runtime.totalMemory()=23999283200; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 1.0 failed 1 times, most recent failure: Lost task 20.0 in stage 1.0 (TID 891, localhost, executor driver): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 131031 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:2300,schedul,scheduler,2300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['schedul'],['scheduler']
Energy Efficiency,"mparison/bec4eb1e-a99f-4e27-a91c-a56274c3824a/call-BenchmarkVCFControlSample/Benchmark/4d248a53-86e2-46f5-9d28-3364c82b9d0c/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-EXOME1SampleHeadToHead/BenchmarkComparison/bec4eb1e-a99f-4e27-a91c-a56274c3824a/call-BenchmarkVCFTestSample/Benchmark/fcd023fe-e278-475d-8fce-613b57518972/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""96.55857222222222"",; ""NIST controlHCsystemhours"": ""0.1707444444444444"",; ""NIST controlHCwallclockhours"": ""69.28645"",; ""NIST controlHCwallclockmax"": ""3.8631972222222224"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-NISTSampleHeadToHead/BenchmarkComparison/243c7bf2-b0d7-48ed-acd0-e2ebd74b9fd3/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-NISTSampleHeadToHead/BenchmarkComparison/243c7bf2-b0d7-48ed-acd0-e2ebd74b9fd3/call-BenchmarkVCFControlSample/Benchmark/135b02c2-d7c5-4fd2-9cc5-cdeeed953bbc/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""103.49634722222224"",; ""NIST evalHCsystemhours"": ""0.20633611111111116"",; ""NIST evalHCwallclockhours"": ""75.91255833333332"",; ""NIST evalHCwallclockmax"": ""3.76305"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1546478988:20378,monitor,monitoring,20378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1546478988,1,['monitor'],['monitoring']
Energy Efficiency,"mpilerThread1"" daemon [_thread_blocked, id=85492, stack(0x00002b5f8f2c7000,0x00002b5f8f3c7aa8)]; 0x000056487672a000 JavaThread ""C2 CompilerThread0"" daemon [_thread_blocked, id=85491, stack(0x00002b5f8f1c5000,0x00002b5f8f2c5aa8)]; 0x0000564876728000 JavaThread ""Signal Dispatcher"" daemon [_thread_blocked, id=85490, stack(0x00002b5f8f0c3000,0x00002b5f8f1c3aa8)]; 0x00005648766f3800 JavaThread ""Finalizer"" daemon [_thread_blocked, id=85489, stack(0x00002b5f8efc2000,0x00002b5f8f0c2aa8)]; 0x00005648766f0800 JavaThread ""Reference Handler"" daemon [_thread_blocked, id=85488, stack(0x00002b5f8eec1000,0x00002b5f8efc1aa8)]; =>0x00005648765c2000 JavaThread ""main"" [_thread_in_native, id=85483, stack(0x00002b5f56d60000,0x00002b5f56e60aa8)]. Other Threads:; 0x00005648766e6800 VMThread [stack: 0x00002b5f8edc0000,0x00002b5f8eec0aa8] [id=85487]; 0x00005648767b7000 WatcherThread [stack: 0x00002b5f8f4ca000,0x00002b5f8f5caaa8] [id=85494]. VM state:not at safepoint (normal execution). VM Mutex/Monitor currently owned by a thread: None. Heap:; PSYoungGen total 1003520K, used 156121K [0x000000066ab00000, 0x00000006aef00000, 0x00000007c0000000); eden space 946688K, 10% used [0x000000066ab00000,0x0000000670bff978,0x00000006a4780000); from space 56832K, 99% used [0x00000006a5900000,0x00000006a9076d70,0x00000006a9080000); to space 85504K, 0% used [0x00000006a9b80000,0x00000006a9b80000,0x00000006aef00000); ParOldGen total 1497088K, used 20019K [0x00000003c0000000, 0x000000041b600000, 0x000000066ab00000); object space 1497088K, 1% used [0x00000003c0000000,0x00000003c138ceb0,0x000000041b600000); Metaspace used 36791K, capacity 37258K, committed 37504K, reserved 1081344K; class space used 5023K, capacity 5176K, committed 5248K, reserved 1048576K. Card table byte_map: [0x00002b5f67df9000,0x00002b5f69dfa000] byte_map_base: 0x00002b5f65ff9000. Marking Bits: (ParMarkBitMap*) 0x00002b5f57e71fa0; Begin Bits: [0x00002b5f6b656000, 0x00002b5f7b656000); End Bits: [0x00002b5f7b656000, 0x00002b5f8b656000). Polli",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:14303,Monitor,Monitor,14303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['Monitor'],['Monitor']
Energy Efficiency,mpute(RDD.scala:335); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1661); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1649); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1648); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1648); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1882); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:3722,schedul,scheduler,3722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['schedul'],['scheduler']
Energy Efficiency,"mx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4803.25; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 27; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2899.687; cache size	: 17920 KB; physical id	: 1; siblings	: 14; core id		: 14; cpu cores	: 14; apicid		: 60; initial apicid	: 60; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4803.25; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. Memory: 4k page, physical 131915956k(125850452k free), swap 8388604k(8322480k free). vm_info: OpenJDK 64-Bit Server VM (25.151-b12) for linux-amd64 JRE (1.8.0_151-b12), built on Nov 21 2017 11:32:26 by ""buildozer"" with gcc 6.4.0. time: Mon Jan 15 13:18:43 2018; elapsed time: 4 seconds (0d 0h 0m 4s); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:75151,monitor,monitor,75151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,2,"['monitor', 'power']","['monitor', 'power']"
Energy Efficiency,"my quickfix was to reduce the intervals to target regions of my WES (instead of using the full genome region) and give it to funcotator. Remark: The GATK mutect2 WDL does not give the default intervals to funcotator, only to mutect2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1183119853:19,reduce,reduce,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1183119853,1,['reduce'],['reduce']
Energy Efficiency,n exitCode=50: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:33403,schedul,scheduler,33403,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"n port 4040.; 19/04/08 19:01:44 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-xx.xx.xx.xx.ec2.internal:4040; 19/04/08 19:01:44 INFO SparkContext: Added JAR file:/home/hadoop/gatk/build/libs/gatk-spark.jar at spark://ip-xx.xx.xx.xx.ec2.internal:34715/jars/gatk-spark.jar with timestamp 1554750104322; 19/04/08 19:01:44 INFO Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances; 19/04/08 19:01:44 INFO GoogleHadoopFileSystemBase: GHFS version: 1.6.3-hadoop2; 19/04/08 19:01:44 INFO RMProxy: Connecting to ResourceManager at ip-xx.xx.xx.xx.ec2.internal/xx.xx.xx.xx:8032; 19/04/08 19:01:45 INFO Client: Requesting a new application from cluster with 2 NodeManagers; 19/04/08 19:01:45 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (24576 MB per container); 19/04/08 19:01:45 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 19/04/08 19:01:45 INFO Client: Setting up container launch context for our AM; 19/04/08 19:01:45 INFO Client: Setting up the launch environment for our AM container; 19/04/08 19:01:45 INFO Client: Preparing resources for our AM container; 19/04/08 19:01:45 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 19/04/08 19:01:47 INFO Client: Uploading resource file:/mnt/tmp/spark-ada67a34-2db0-488c-adf5-7e4607fe989f/__spark_libs__8661360236699028076.zip -> hdfs://ip-xx.xx.xx.xx.ec2.internal:8020/user/hadoop/.sparkStaging/application_1554748821802_0005/__spark_libs__8661360236699028076.zip; 19/04/08 19:01:48 INFO Client: Uploading resource file:/etc/spark/conf/hive-site.xml -> hdfs://ip-xx.xx.xx.xx.ec2.internal:8020/user/hadoop/.sparkStaging/application_1554748821802_0005/hive-site.xml; 19/04/08 19:01:48 INFO Client: Uploading resource file:/mnt/tmp/spark-ada67a34-2db0-488c-adf5-7e",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869:6704,allocate,allocate,6704,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869,1,['allocate'],['allocate']
Energy Efficiency,"n stage 1.0 (TID 3, com2, executor 2): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$14/1380582544.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:37 INFO scheduler.TaskSetManager: Starting task 0.3 in stage 1.0 (TID 4, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Disabling executor 2.; 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Executor lost: 2 (epoch 1); 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.; 17/10/11 14:19:38 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, com2, 46254); 17/10/11 14:19:38 INFO storage.BlockManagerMaster: Removed 2 successfully in remov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:23647,schedul,scheduler,23647,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"n$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.random.SamplingUtils$.reservoirSampleAndCount(SamplingUtils.scala:41); 	at org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:303); 	at org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:301); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 18/07/24 21:02:27 ERROR org.apache.spark.scheduler.TaskSetManager: Task 1 in stage 0.0 failed 4 times; aborting job; 18/07/24 21:02:27 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@42ecc554{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 21:02:27.703 INFO PrintReadsSpark - Shutting down engine; [July 24, 2018 9:02:27 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.32 minutes.; Runtime.totalMemory()=2463629312; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 7, shuang-small-m.c.broad-dsde-methods.internal, e",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:10764,schedul,scheduler,10764,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['schedul'],['scheduler']
Energy Efficiency,n$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.random.SamplingUtils$.reservoirSampleAndCount(SamplingUtils.scala:41); 	at org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:303); 	at org.apache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:301); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGSched,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:14419,schedul,scheduler,14419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['schedul'],['scheduler']
Energy Efficiency,n$doPutIterator$1.apply(BlockManager.scala:1094); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1661); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1649); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1648); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1648); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGSched,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:3317,schedul,scheduler,3317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['schedul'],['scheduler']
Energy Efficiency,n.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38386,schedul,scheduler,38386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,"n.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir; 17/10/11 14:19:18 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/11 14:19:18 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/11 14:19:18 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203; 17/10/11 14:19:18 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Got job 0 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203) with 1 output partitions; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:203); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.2 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:34044 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157) (first 15 tasks are for partitions Vector(0)); 17/10/11 14:19:18 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:11518,schedul,scheduler,11518,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,n.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2281); at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83); ... 27 more; Caused by: java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; at java.base/jdk.internal.util.ArraysSupport.hugeLength(ArraysSupport.java:649); at java.base/jdk.internal.util.ArraysSupport.newLength(ArraysSupport.java:642); at java.base/java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:100); at java.base/java.io.ByteArrayOutputStream.write(By,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:32734,schedul,scheduler,32734,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"nStream.writeObject(JavaSerializer.scala:46) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; 11:00:54.078 INFO AbstractConnector - Stopped Spark@2f829853{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}; 11:00:54.091 INFO SparkUI - Stopped Spark web UI at http://172.20.19.130:4040; 11:00:54.122 INFO MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!; 11:00:54.175 INFO MemoryStore - MemoryStore cleared; 11:00:54.175 INFO BlockManager - BlockManager stop",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:23308,schedul,scheduler,23308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"nVja2V0VXRpbHMuamF2YQ==) | `43.75% <0%> (-29.861%)` | `27% <0%> (-9%)` | |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `76.471% <0%> (-23.529%)` | `4% <0%> (Ã¸)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (Ã¸)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | ... and [24 more](https://codecov.io/gh/broadinstitute/gatk/pull/2401?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2401?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2401?src=pr&el=footer). Last update [51360c7...51285dc](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-279424649:5052,Power,Powered,5052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-279424649,1,['Power'],['Powered']
Energy Efficiency,"n\_FILTER ; ; 02:00:35.778 ERROR FuncotationMap - Values: Â , , , , , , , , , , , , , , , , , , , , , , , , , , , , false, ,Â  ; ; 02:00:35.793 INFO Â FilterFuncotations - Shutting down engine ; ; \[April 25, 2022 at 2:00:35 AM EDT\] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 0.03 minutes. ; ; Runtime.totalMemory()=319815680 ; ; org.broadinstitute.hellbender.exceptions.GATKException$ShouldNeverReachHereException: Cannot parse the funcotation attribute. Â Num values: 31 Â  Num keys: 53 ; ; Â  Â  at org.broadinstitute.hellbender.tools.funcotator.FuncotationMap.createAsAllTableFuncotationsFromVcf(FuncotationMap.java:224) ; ; Â  Â  at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.lambda$createAlleleToFuncotationMapFromFuncotationVcfAttribute$5(FuncotatorUtils.java:2256) ; ; Â  Â  at java.base/java.util.stream.Collectors.lambda$uniqKeysMapAccumulator$1(Collectors.java:178) ; ; Â  Â  at java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; ; Â  Â  at java.base/java.util.stream.IntPipeline$1$1.accept(IntPipeline.java:180) ; ; Â  Â  at java.base/java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:104) ; ; Â  Â  at java.base/java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:699) ; ; Â  Â  at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; ; Â  Â  at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; ; Â  Â  at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; ; Â  Â  at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; Â  Â  at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; ; Â  Â  at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createAlleleToFuncotationMapFromFuncotationVcfAttribute(FuncotatorUtils.java:2255) ; ; Â  Â  at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.ArHetvarFil",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7865:7497,Reduce,ReduceOps,7497,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7865,1,['Reduce'],['ReduceOps']
Energy Efficiency,"nagerMaster: Registering BlockManager BlockManagerId(driver, ip-xx.xx.xx.xx.ec2.internal, 38471, None); 19/04/08 19:01:52 INFO BlockManagerMasterEndpoint: Registering block manager ip-xx.xx.xx.xx.ec2.internal:38471 with 366.3 MB RAM, BlockManagerId(driver, ip-xx.xx.xx.xx.ec2.internal, 38471, None); 19/04/08 19:01:52 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-xx.xx.xx.xx.ec2.internal, 38471, None); 19/04/08 19:01:52 INFO BlockManager: external shuffle service port = 7337; 19/04/08 19:01:52 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-xx.xx.xx.xx.ec2.internal, 38471, None); 19/04/08 19:01:52 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/application_1554748821802_0005; 19/04/08 19:01:52 INFO Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances; 19/04/08 19:01:52 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 19:01:52.566 INFO HaplotypeCallerSpark - Spark verbosity set to INFO (see --spark-verbosity argument); 19/04/08 19:02:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 4.7 MB, free 361.6 MB); 19/04/08 19:02:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 450.5 KB, free 361.2 MB); 19/04/08 19:02:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ip-xx.xx.xx.xx.ec2.internal:38471 (size: 450.5 KB, free: 365.9 MB); 19/04/08 19:02:38 INFO SparkContext: Created broadcast 0 from broadcast at CramSource.java:114; 19/04/08 19:02:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 290.4 KB, free 360.9 MB); 19/04/08 19:02:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.6 KB, free 360.9 MB); 19/04/08 19:02:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in me",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869:11996,Schedul,SchedulerBackend,11996,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869,2,"['Schedul', 'schedul']","['SchedulerBackend', 'scheduling']"
Energy Efficiency,"nally); 00:11:24.786 INFO HaplotypeCallerSpark - Shutting down engine; [May 26, 2017 12:11:24 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 10.58 minutes.; Runtime.totalMemory()=16622026752; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 1.0 failed 1 times, most recent failure: Lost task 15.0 in stage 1.0 (TID 519; , localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:192); at java.util.stream.ReferencePipeline$7$1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:10377,Reduce,ReduceOps,10377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"nce id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 1.2 in stage 0.0 (TID 6, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 INFO TaskSetManager:54 - Lost task 3.1 in stage 0.0 (TID 4) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 1]; 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 7, scc-q12.scc.bu.edu, executor 2, partition 2, NODE_LOCAL, 7992 bytes); 2019-01",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:28720,schedul,scheduler,28720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['schedul'],['scheduler']
Energy Efficiency,"nce id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:50 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 4, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:50 WARN TaskSetManager:66 - Lost task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.Autoclose",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:25818,schedul,scheduler,25818,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['schedul'],['scheduler']
Energy Efficiency,"nce id 2, start 131325815, span 181534, expected MD5 c240a972d49aa89fb57dae94d1d90d36; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 1.2 in stage 0.0 (TID 7, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:52 INFO TaskSetManager:54 - Lost task 4.1 in stage 0.0 (TID 5) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683) [duplicate 1]; 2019-01-09 13:35:53 INFO TaskSetManager:54 - Starting task 7.1 in stage 0.0 (TID 8, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:29745,schedul,scheduler,29745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['schedul'],['scheduler']
Energy Efficiency,nce(StreamSpliterators.java:180); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:311); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:692); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948); at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:888); at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:948); at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:694); at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334); at org.apache.spark.rdd.RDD.iterator(RDD.scala:285); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1160); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635); at java.lang.Thread.run(Thread.java:785). ```; No vcf file was created. . So far it seems walker mode doesn't have this issue.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4265:3528,schedul,scheduler,3528,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4265,2,['schedul'],['scheduler']
Energy Efficiency,"nceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chrM:63 the annotation MLEAC=[2, 0] was not a numerical value and was ignored; 12:01:49.505 INFO CombineGVCFs - Shutting down engine; [August 24, 2020 12:01:49 PM HKT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=6277824512; java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.makeRawAnnotationString(StrandBiasUtils.java:46); at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_StrandBiasTest.combineRawData(AS_StrandBiasTest.java:115); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:210); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.endPreviousStates(CombineGVCFs.java:403); at org.broadinstitute",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766:6131,Reduce,ReduceOps,6131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766,1,['Reduce'],['ReduceOps']
Energy Efficiency,nch manually on gcs and get a new error which I believe is a GCS NIO bug that we discussed in https://github.com/samtools/htsjdk/pull/724. . ```; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337:1019,schedul,scheduler,1019,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337,1,['schedul'],['scheduler']
Energy Efficiency,"ncher.java:331); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:264); 	at htsjdk.samtools.metrics.MetricsFile.loadClass(MetricsFile.java:471); 	at htsjdk.samtools.metrics.MetricsFile.read(MetricsFile.java:353); 	... 8 more; ```. If it is replaced, the tool still errors but with a different error:; ```; java.lang.IllegalArgumentException: Features added out of order: previous (TabixFeature{referenceIndex=0, start=118314029, end=118314036, featureStartFilePosition=1403632633, featureEndFilePosition=-1}) > next (TabixFeature{referenceIndex=0, start=33414233, end=33414234, featureStartFilePosition=1403632876, featureEndFilePosition=-1}); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.addFeature(TabixIndexCreator.java:89); 	at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:170); 	at htsjdk.variant.variantcontext.writer.VCFWriter.add(VCFWriter.java:219); 	at java.util.ArrayList.forEach(ArrayList.java:1249); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalSuccess(FilterByOrientationBias.java:171); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:781); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); 	at org.broadinstitute.hellbender.Main.main(Main.java:221); ```. It does not matter if I produce the pre-adapter metrics with the latest Picard jar v2.9.2. I get the same error. . I'm using a M2 callset from GATK3. Even so, I don't think I should get the above error?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030:3915,adapt,adapter,3915,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030,1,['adapt'],['adapter']
Energy Efficiency,ncodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1025); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellben,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680:2131,Reduce,ReduceOps,2131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,ncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:239) ; ; Â  Â  at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211) ; ; Â  Â  at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182) ; ; Â  Â  at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForSegment$2(FuncotatorEngine.java:218) ; ; Â  Â  at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; ; Â  Â  at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; ; Â  Â  at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382) ; ; Â  Â  at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; Â  Â  at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; Â  Â  at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ; Â  Â  at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; Â  Â  at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; Â  Â  at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForSegment(FuncotatorEngine.java:221) ; ; Â  Â  at org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments.apply(FuncotateSegments.java:191) ; ; Â  Â  at org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments.apply(FuncotateSegments.java:59) ; ; Â  Â  at org.broadinstitute.hellbender.engine.FeatureWalker.lambda$traverse$0(FeatureWalker.java:99) ; ; Â  Â  at java.util.Iterator.forEachRemaining(Iterator.java:116) ; ; Â  Â  at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; Â  Â  at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) ; ; Â  Â  at org.broadinstitute.hellbender.engine.FeatureWalker.traverse(FeatureWalker.java:97) ; ; Â  Â  at org.b,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7676:4506,Reduce,ReduceOps,4506,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7676,1,['Reduce'],['ReduceOps']
Energy Efficiency,ndLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); Caused by: java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:192); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipelin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:17306,Reduce,ReduceOps,17306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Reduce'],['ReduceOps']
Energy Efficiency,nder.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:8661,schedul,scheduler,8661,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['schedul'],['scheduler']
Energy Efficiency,"ndledCaseSeen: 1st segment is not overlapping with head alignment but it is not immediately before/after the head alignment either; AssemblyContigWithFineTunedAlignments{sourceTig=(asm022672:tig00004, [1_1430_chr9:130955309-130956738_-_1430M2216S_60_-1_-1_S, 1587_1763_chr9:130955156-130955308_-_1586S54M24I99M1883S_60_-1_-1_S, 1824_2015_chr9:130954964-130955155_-_1823S192M1631S_60_-1_-1_S, 2164_3646_chr9:130953867-130955307_-_2163H167M42I1274M_60_55_1318_O]), insertionMappings=[1963_2177_chr9:130955093-130955304_-_1962H179M3I33M1469H_19_14_138_O], hasEquallyGoodAlnConfigurations=false, saTAGForGoodMappingToNonCanonicalChromosome='NONE'}; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantCanonicalRepresentation.extractAltHaplotypeSeq(CpxVariantCanonicalRepresentation.java:338); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantCanonicalRepresentation.<init>(CpxVariantCanonicalRepresentation.java:143); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.lambda$inferCpxVariant$b3be3b47$1(CpxVariantInterpreter.java:53); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4649:1977,schedul,scheduler,1977,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4649,3,['schedul'],['scheduler']
Energy Efficiency,nds 11 --gvcf-gq-bands 12 --gvcf-gq-bands 13 --gvcf-gq-bands 14 --gvcf-gq-bands 15 --gvcf-gq-bands 16 --gvcf-gq-bands 17 --gvc; f-gq-bands 18 --gvcf-gq-bands 19 --gvcf-gq-bands 20 --gvcf-gq-bands 21 --gvcf-gq-bands 22 --gvcf-gq-bands 23 --gvcf-gq-bands 24 --gvcf-gq-bands 25 --gvcf-gq-bands 26 --gvcf-gq-bands 27 --g; vcf-gq-bands 28 --gvcf-gq-bands 29 --gvcf-gq-bands 30 --gvcf-gq-bands 31 --gvcf-gq-bands 32 --gvcf-gq-bands 33 --gvcf-gq-bands 34 --gvcf-gq-bands 35 --gvcf-gq-bands 36 --gvcf-gq-bands 37 -; -gvcf-gq-bands 38 --gvcf-gq-bands 39 --gvcf-gq-bands 40 --gvcf-gq-bands 41 --gvcf-gq-bands 42 --gvcf-gq-bands 43 --gvcf-gq-bands 44 --gvcf-gq-bands 45 --gvcf-gq-bands 46 --gvcf-gq-bands 47; --gvcf-gq-bands 48 --gvcf-gq-bands 49 --gvcf-gq-bands 50 --gvcf-gq-bands 51 --gvcf-gq-bands 52 --gvcf-gq-bands 53 --gvcf-gq-bands 54 --gvcf-gq-bands 55 --gvcf-gq-bands 56 --gvcf-gq-bands ; 57 --gvcf-gq-bands 58 --gvcf-gq-bands 59 --gvcf-gq-bands 60 --gvcf-gq-bands 70 --gvcf-gq-bands 80 --gvcf-gq-bands 90 --gvcf-gq-bands 99 --floor-blocks false --indel-size-to-eliminate-in-re; f-model 10 --disable-optimizations false --dragen-mode false --flow-mode NONE --apply-bqd false --apply-frd false --disable-spanning-event-genotyping false --transform-dragen-mapping-quali; ty false --mapping-quality-threshold-for-genotyping 20 --max-effective-depth-adjustment-for-frd 0 --just-determine-active-regions false --dont-genotype false --do-not-run-physical-phasing ; false --do-not-correct-overlapping-quality false --use-filtered-reads-for-annotations false --use-flow-aligner-for-stepwise-hc-filtering false --adaptive-pruning false --do-not-recover-dan; gling-branches false --recover-dangling-heads false --kmer-size 10 --kmer-size 25 --dont-increase-kmer-sizes-for-cycles false --allow-non-unique-kmers-in-ref false --num-pruning-samples 1 ; --min-dangling-branch-length 4 --recover-all-dangling-branches false --max-num-haplotypes-in-population 128 --min-pruning 2 --adaptive-pruning-initial-error-rate 0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789:4845,adapt,adaptive-pruning,4845,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789,2,['adapt'],"['adaptive-pruning', 'adaptive-pruning-initial-error-rate']"
Energy Efficiency,nfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); at org.apache.spark.internal.io.SparkHadoopWriter$.write,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513:7635,schedul,scheduler,7635,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513,1,['schedul'],['scheduler']
Energy Efficiency,nfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); at org.apache.spark.internal.io.SparkHadoopWriter$.write,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:7646,schedul,scheduler,7646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['schedul'],['scheduler']
Energy Efficiency,"nfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 00:11:09.632 WARN TaskSetManager:66 - Lost task 15.0 in stage 1.0 (TID 519, localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:5657,Reduce,ReduceOps,5657,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Reduce'],['ReduceOps']
Energy Efficiency,ng the following command:; > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input maprfs://spark-ics/user/axverdier/data/710-PE-G1.bam --output maprfs://spark-ics/user/axverdier/testOutGATK_CountReadsSpark --sparkRunner SPARK --sparkMaster yarn --javaOptions -Dmapr.library.flatclass; I got the following error!. > Driver stacktrace:; > 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1436); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1424); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); > 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); > 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); > 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1423); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); > 	at scala.Option.foreach(Option.scala:257); > 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1651); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1606); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1595); > 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); > 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); > 	at org.apache.spark.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936:1127,schedul,scheduler,1127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936,1,['schedul'],['scheduler']
Energy Efficiency,"ng.; 17/10/11 14:19:17 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34044.; 17/10/11 14:19:17 INFO netty.NettyBlockTransferService: Server created on 34044; 17/10/11 14:19:17 INFO storage.BlockManager: external shuffle service port = 7337; 17/10/11 14:19:17 INFO storage.BlockManagerMaster: Trying to register BlockManager; 17/10/11 14:19:17 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.131.101.159:34044 with 530.0 MB RAM, BlockManagerId(driver, 10.131.101.159, 34044); 17/10/11 14:19:17 INFO storage.BlockManagerMaster: Registered BlockManager; 17/10/11 14:19:17 INFO scheduler.EventLoggingListener: Logging events to hdfs://mg:8020/user/spark/applicationHistory/application_1507683879816_0006; 17/10/11 14:19:17 INFO spark.SparkContext: Registered listener com.cloudera.spark.lineage.ClouderaNavigatorListener; 17/10/11 14:19:17 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 17/10/11 14:19:17 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 285.6 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 26.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.131.101.159:34044 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:18 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.5 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.7 MB); 17/10/11 14:19:18 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:34044 (size: 2.1 KB, free: 530.0 MB); 17/10/1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:9312,Schedul,SchedulerBackend,9312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,2,"['Schedul', 'schedul']","['SchedulerBackend', 'scheduling']"
Energy Efficiency,"ng: PrintReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 21:02:08.892 INFO PrintReadsSpark - Initializing engine; 21:02:08.892 INFO PrintReadsSpark - Done initializing engine; 18/07/24 21:02:08 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 18/07/24 21:02:09 INFO org.spark_project.jetty.util.log: Logging initialized @6492ms; 18/07/24 21:02:09 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 18/07/24 21:02:09 INFO org.spark_project.jetty.server.Server: Started @6584ms; 18/07/24 21:02:09 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@42ecc554{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/07/24 21:02:09 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 18/07/24 21:02:09 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.9.0-hadoop2; 18/07/24 21:02:10 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at shuang-small-m/10.128.5.217:8032; 18/07/24 21:02:10 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at shuang-small-m/10.128.5.217:10200; 18/07/24 21:02:12 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1532457503538_0038; 21:02:16.702 INFO FeatureManager - Using codec BEDCodec to read file hdfs://shuang-small-m:8020/data/intervals.bed; 21:02:16.863 INFO IntervalArgumentCollection - Processing 1219 bp from intervals; 18/07/24 21:02:17 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:6918,Schedul,Scheduler,6918,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,2,"['Schedul', 'schedul']","['Scheduler', 'scheduled']"
Energy Efficiency,non$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:8601,schedul,scheduler,8601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,nonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.SparkContext.runJob(SparkContext.scala:2281) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsNewAPIHadoopDataset$1(PairRDDFunctions.scala:1078) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperatio,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:15029,schedul,scheduler,15029,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,notypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:9349,schedul,scheduler,9349,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['schedul'],['scheduler']
Energy Efficiency,nsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:10858,schedul,scheduler,10858,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,"nsferService' on port 44190.; 18/01/09 18:31:06 INFO netty.NettyBlockTransferService: Server created on 192.168.1.4:44190; 18/01/09 18:31:06 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 18/01/09 18:31:06 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.4, 44190, None); 18/01/09 18:31:06 INFO storage.BlockManagerMasterEndpoint: Registering block manager 192.168.1.4:44190 with 2004.6 MB RAM, BlockManagerId(driver, 192.168.1.4, 44190, None); 18/01/09 18:31:06 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.4, 44190, None); 18/01/09 18:31:06 INFO storage.BlockManager: external shuffle service port = 7337; 18/01/09 18:31:06 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.4, 44190, None); 18/01/09 18:31:06 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@60c8909a{/metrics/json,null,AVAILABLE,@Spark}; 18/01/09 18:31:06 INFO scheduler.EventLoggingListener: Logging events to hdfs://tele-1:8020/user/spark/spark2ApplicationHistory/application_1515493209401_0001; 18/01/09 18:31:09 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Container marked as failed: container_1515493209401_0001_01_000002 on host: tele-6. Exit status: 1. Diagnostics: Exception from container-launch.; Container id: container_1515493209401_0001_01_000002; Exit code: 1; Stack trace: ExitCodeException exitCode=1: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:601); 	at org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.cont",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:15800,schedul,scheduler,15800,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['schedul'],['scheduler']
Energy Efficiency,nstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:8,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:1582,schedul,scheduler,1582,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,1,['schedul'],['scheduler']
Energy Efficiency,nstitute.hellbender.utils.MathUtils.normalizeLog10(MathUtils.java:1098); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeFromLog10ToLinearSpace(MathUtils.java:1074); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at or,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1436,Reduce,ReduceOps,1436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887,1,['Reduce'],['ReduceOps']
Energy Efficiency,"nt; > info for the following problem is that it is a ppc64le system. When I use; > HaplotypeCaller, I see the following messages on the screen:; >; > Running:; > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -jar /home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCaller -R ref.fa -I mybam.bam -O mycalls.vcf.gz -L snps.vcf -ip 100; >; > 16:17:04.377 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; >; > 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; >; > 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; >; > INFO: Failed to detect whether we are running on Google Compute Engine.; >; > 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------; >; > 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1; >; > 16:17:05.843 INFO HaplotypeCaller - For support and doc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600:1894,Power,Power,1894,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600,1,['Power'],['Power']
Energy Efficiency,ntProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:32216,schedul,scheduler,32216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"nted on [Thu May 05 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-217265362). It seems to me that a quick and sound solution is to reduce the number of alternative alleles at this point in HCGenotypeEngine code:. ```; HaplotypeCallerGenotypingEngine.java line 260:; final Map<Allele, List<Haplotype>> alleleMapper = createAlleleMapper(mergeMap, eventMapper);; ```. Haplotypes have associated score, as a pseudo-likelihood,that can be use to sort then and selectively remove those alternative alleles that are only supported by the less likely haplotypes. ---. @vruano commented on [Thu May 05 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-217266027). So the idea is simple, keep removing haplotypes from that map value lists one by one until enough allele's are emptied, so that the number of genotypes does not surpasses a maximum based on the largest ploidy amongst the input samples. Of course, one would need to create some temporary data-structure to make the operation more efficient. . ---. @vruano commented on [Thu May 05 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-217267297). Those haplotype scores have not been throughly analyzed but we are already using them to discard haplotypes beyond the maximum allowed per graph kmer size so I don't see the harm in using the for further reduction. . Certainly is a step forward from just throwing an exception back to the user. However, we should output a Warning every time we need to do such a reduction just to keep track. ---. @sooheelee commented on [Fri May 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-217443170). Is it possible for the user to mask this 45SrDNA locus for separate analysis? Assuming of course that this locus is of further interest to their aims. For example, either for more exact mapping then variant calling or separate variant calling. I say this because a quick glance at the literature",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2955:6296,efficient,efficient,6296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2955,1,['efficient'],['efficient']
Energy Efficiency,nterval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:144); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:362); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.invalidateSampleOrdering(LazyGenotypesContext.java:205); 	at ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:7122,schedul,scheduler,7122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,ntext.java:827) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.DuplicatedAltReadFilter.areAllelesArtifacts(DuplicatedAltReadFilter.java:26) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.HardAlleleFilter.calculateErrorProbabilityForAlleles(HardAlleleFilter.java:16) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2AlleleFilter.errorProbabilities(Mutect2AlleleFilter.java:86) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$0(ErrorProbabilities.java:27) ; ; at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321) ; ; at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:25) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:138) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:154) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:8017,Reduce,ReduceOps,8017,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3540:1252,adapt,adapter,1252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540,5,['adapt'],['adapter']
Energy Efficiency,"o how is it obsolete?. Reply by @SHUANG-Broad (also copied to update the ""TODO"" message; > this predicate is currently used in two places (excluding appearance in comments): `BreakpointComplications.IntraChrStrandSwitchBreakpointComplications`, where it is use to test if the input simple chimera indicates an inverse tandem duplication and trigger the logic for inferring duplicated region; and `BreakpointsInference.IntraChrStrandSwitchBreakpointInference`, where it is used for breakpoint inference. The problem is, the contig will not even be sent here, because `AssemblyContigWithFineTunedAlignments.hasIncompletePictureFromTwoAlignments()` defines a simple chimera that has strand switch and the two alignments overlaps on reference as ""incomplete"", so in practice the two uses are not going to be triggered. But when we come back later and see what can be extracted from such ""incomplete"" contigs, these code could be useful again. So it is kept. ------------; ### On the problem of writing out SAM records of ""Unknown"" contigs efficiently. First round comment by @cwhelan ; > This seems like a very inefficient way to write these three files. You end up calling collect on the RDD three different times and then traversing the local collection three times. Why not make a map of contig name to bam file, collect the rdd once, and then traverse the local collection once, writing each read to the appropriate bam file from the map?. Second round comment by @cwhelan ; > This is a better but you are still collecting the RDD and passing over the collection three times. What I meant by my original suggestion was this: Why not make the map go the other way, ie make a Map<String, ReasonForAlignmentClassificationFailure> that maps contig names to their reasons? Then make a Map<ReasonForAlignmentClassificationFailure, SAMFileWriter> with three entries. Then you only have to iterate over the collection of reads once to write everything out (you just look up the writer for each entry). Reply ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030:3703,efficient,efficiently,3703,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030,1,['efficient'],['efficiently']
Energy Efficiency,"o stage failure: Task 20 in stage 1.0 failed 1 times, most recent failure: Lost task 20.0 in stage 1.0 (TID 891, localhost, executor driver): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 131031 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); 	at org.apache.spark.api.java.Ja",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:2938,schedul,scheduler,2938,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['schedul'],['scheduler']
Energy Efficiency,"o.HiSeq.WGS.b37.NA12878.bam:142662628213169-142936511676415; 15/11/12 06:29:34 ERROR executor.Executor: Exception in task 519.0 in stage 0.0 (TID 562); java.lang.RuntimeException: found the bad record: 1,801305857; at org.broadinstitute.hellbender.tools.spark.pipelines.Utils.key(KeyReadsSpark.java:43); at org.broadinstitute.hellbender.tools.spark.pipelines.KeyReadsSpark.lambda$runTool$72eaf22$1(KeyReadsSpark.java:28); at org.broadinstitute.hellbender.tools.spark.pipelines.KeyReadsSpark$$Lambda$11/1228804001.call(Unknown Source); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1002); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1002); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:219); at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41); at org.apache.spark.scheduler.Task.run(Task.scala:64); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```. This start offset is 2176858951 (142662628213169L>>>16) - i.e. around 2GB in. I've managed to reproduce with a local program now. This reveals the following problem:. ```; Caused by: java.lang.IllegalArgumentException: Unrecognized CigarOperator: 11; at htsjdk.samtools.CigarOperator.binaryToEnum(CigarOperator.java:143); at htsjdk.samtools.BinaryCigarCodec.binaryCigarToCigarElement(BinaryCigarCodec.java:87); at htsjdk.samtools.BinaryCigarCodec.decode(BinaryCigarCodec.java:63); at htsjdk.samtools.BAMRecord.getCigar(BAMR",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1098#issuecomment-156150350:1300,schedul,scheduler,1300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1098#issuecomment-156150350,1,['schedul'],['scheduler']
Energy Efficiency,o.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:7746,schedul,scheduler,7746,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['schedul'],['scheduler']
Energy Efficiency,oadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:338); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:138); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:113); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.lambda$enqueueAndHandleVariant$0(Funcotator.java:502); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:504); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:399); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:109); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequenti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886:1292,Reduce,ReduceOps,1292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886,1,['Reduce'],['ReduceOps']
Energy Efficiency,oadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2385510400; java.lang.IllegalStateException: Duplicate key 7.395307178412063E-4; at java.util.stream.Collectors.lambda$throwingMerger$138(Collectors.java:133); at java.util.stream.Collectors$$Lambda$67/403388441.apply(Unknown Source); at java.util.HashMap.merge(HashMap.java:1245); at java.util.stream.Collectors.lambda$toMap$196(Collectors.java:1320); at java.util.stream.Collectors$$Lambda$69/854719230.accept(Unknown Source); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.<init>(ContaminationFilter.java:26); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.buildFiltersList(Mutect2FilteringEngine.java:290); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.<init>(Mutect2FilteringEngine.java:60); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.onTraversalStart(FilterMutectCalls.java:138); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6996:4301,Reduce,ReduceOps,4301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996,1,['Reduce'],['ReduceOps']
Energy Efficiency,ockManager.scala:811); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1661); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1649); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1648); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1648); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1882); 	at org.apa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:3682,schedul,scheduler,3682,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['schedul'],['scheduler']
Energy Efficiency,"odule_from_key; module = lnk.compile_cmodule(location); File ""/home/tintest/miniconda2/envs/aurexome/lib/python3.6/site-packages/theano/gof/cc.py"", line 1489, in compile_cmodule; preargs=preargs); File ""/home/tintest/miniconda2/envs/aurexome/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2294, in compile_str; p_out = output_subprocess_Popen(cmd); File ""/home/tintest/miniconda2/envs/aurexome/lib/python3.6/site-packages/theano/misc/windows.py"", line 77, in output_subprocess_Popen; p = subprocess_Popen(command, **params); File ""/home/tintest/miniconda2/envs/aurexome/lib/python3.6/site-packages/theano/misc/windows.py"", line 43, in subprocess_Popen; proc = subprocess.Popen(command, startupinfo=startupinfo, **params); File ""/home/tintest/miniconda2/envs/aurexome/lib/python3.6/subprocess.py"", line 707, in __init__; restore_signals, start_new_session); File ""/home/tintest/miniconda2/envs/aurexome/lib/python3.6/subprocess.py"", line 1267, in _execute_child; restore_signals, start_new_session, preexec_fn); OSError: [Errno 12] Cannot allocate memory. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.executeGermlineCNVCallerPythonScript(GermlineCNVCaller.java:454); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.doWork(GermlineCNVCaller.java:291); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); at org.broadinstitute.hellbender.cmdline.Co",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053:66905,allocate,allocate,66905,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053,1,['allocate'],['allocate']
Energy Efficiency,"ok, got it. sorry, i missed 'install' in that command. my initial impression is that VariantQC will be able to adapt fine to VariantEvalEngine. I wrote VariantEvalEngine with this is mind, but it's good to formally test it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759645374:111,adapt,adapt,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759645374,1,['adapt'],['adapt']
Energy Efficiency,"olders named ""SAMPLE_#""), and just check the sample_name.txt files at the PostprocessGermlineCNVCalls step. I don't think this should require GermlineCNVCaller code changes, right?. 4) We may require additional code at the WDL level if we want to both switch over to primarily using sample names but also get rid of bundling (i.e., by passing only the calls for each sample when needed). Locally, you can always just search all output for directories containing the appropriate sample_name.txt. But on the cloud, you'd want to make sure that the postprocessing step for a particular sample gets only its corresponding directories, which would have to happen at the WDL level; the check against sample_name.txt at the tool level would just be a formality. I can foresee headaches with globbing and funky sample names. I'm not sure I understand your point about extending PostprocessGermlineCNVCalls to run on all samples. The point of that tool is to take results from all genomic shards for a single sample and stitch them together, right? Even if we extend this to run on a batch of multiple samples (which would just be moving the loop over samples at the WDL level to some lower level, i.e., Java or python), we still need to see all shards for those samples. Perhaps I'm misunderstanding---can you clarify?. @mwalker174 can we once and for all clearly document the issue with the transpose? Perhaps by pointing to specific WGS runs that have issues with call caching? I think being able to pinpoint the exact issue will help us identify the right solution---whether that be choosing an appropriate bundling scheme, taking advantage of #5781 to reduce the number of shards, batching during the postprocessing step, removing unnecessary outputs, etc. Recall that we'd like to be able to use the same WDL locally (when you have easy access to all GermlineCNVCaller results from all genomic shards) and in the cloud, with minimal duplication of output from bundling when running locally, if possible.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765:2968,reduce,reduce,2968,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765,1,['reduce'],['reduce']
Energy Efficiency,"olicy; 18/04/24 17:55:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, xx.xx.xx.16, 49734, None); 18/04/24 17:55:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/1 is now RUNNING; 18/04/24 17:55:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/2 is now RUNNING; 18/04/24 17:55:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/3 is now RUNNING; 18/04/24 17:55:01 INFO BlockManagerMasterEndpoint: Registering block manager xx.xx.xx.16:49734 with 366.3 MB RAM, BlockManagerId(driver, xx.xx.xx.16, 49734, None); 18/04/24 17:55:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, xx.xx.xx.16, 49734, None); 18/04/24 17:55:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, xx.xx.xx.16, 49734, None); 18/04/24 17:55:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/4 is now RUNNING; 18/04/24 17:55:03 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0; 18/04/24 17:55:03 INFO GoogleHadoopFileSystemBase: GHFS version: 1.6.3-hadoop2; 18/04/24 17:55:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/5 is now RUNNING; 18/04/24 17:55:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 276.0 KB, free 366.0 MB); 00:10 DEBUG: [kryo] Write: SerializableConfiguration; 18/04/24 17:55:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.1 KB, free 366.0 MB); 18/04/24 17:55:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.16:49734 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:55:05 INFO SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:113; 18/04/24 17:55:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424175501-0004/0 is now RU",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:13659,Schedul,SchedulerBackend,13659,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,2,"['Schedul', 'schedul']","['SchedulerBackend', 'scheduling']"
Energy Efficiency,ollection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)** ; **at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)** ; **at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)** ; **at scala.Option.foreach(Option.scala:257)** ; **at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)** ; **at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)** ; **at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)** ; **at org.apache.spark.rdd.RDD.count(RDD.scala:1168)** ; **at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455)** ; **at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark.runTool(PathSeqPipelineSpark.java:245)** ; **at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:533)** ; **at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31)** ; **at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139)** ; **,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:47078,schedul,scheduler,47078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,"ollectionView'; already in composite transform.; 15/07/14 13:14:52 INFO spark.SparkPipelineRunner: Skipping 'CountReadsDataflowTransform/Globally/Combine.Globally/Create'; already in composite transform.; 15/07/14 13:14:52 INFO spark.SparkPipelineRunner: Skipping 'CountReadsDataflowTransform/Globally/Combine.Globally/AnonymousParDo'; already in composite transform.; 15/07/14 13:14:52 INFO spark.SparkPipelineRunner: Post-visiting directly-translatable composite transform: 'CountReadsDataflowTransform/Globally/Combine.Globally'; 15/07/14 13:14:52 INFO spark.SparkPipelineRunner: Evaluating Combine.Globally [Combine.Globally]; 15/07/14 13:14:52 INFO spark.SparkContext: Starting job: aggregate at TransformTranslator.java:183; 15/07/14 13:14:52 INFO scheduler.DAGScheduler: Got job 0 (aggregate at TransformTranslator.java:183) with 1 output partitions (allowLocal=false); 15/07/14 13:14:52 INFO scheduler.DAGScheduler: Final stage: Stage 0(aggregate at TransformTranslator.java:183); 15/07/14 13:14:52 INFO scheduler.DAGScheduler: Parents of final stage: List(); 15/07/14 13:14:52 INFO scheduler.DAGScheduler: Missing parents: List(); 15/07/14 13:14:52 INFO scheduler.DAGScheduler: Submitting Stage 0 (MapPartitionsRDD[4] at map at TransformTranslator.java:181), which has no missing parents; 15/07/14 13:14:52 INFO storage.MemoryStore: ensureFreeSpace(6656) called with curMem=0, maxMem=278019440; 15/07/14 13:14:52 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.5 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(3753) called with curMem=6656, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:65240 (size: 3.7 KB, free: 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerMaster: Updated info of block broadcast_0_pie",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:22108,schedul,scheduler,22108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['schedul'],['scheduler']
Energy Efficiency,ols.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:152); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:924); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680:3721,Reduce,ReduceOps,3721,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,omaticClusteringModel.java:203); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.uti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:11034,Reduce,ReduceOps,11034,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"omparison/1269d993-e13f-4635-a12a-e65fdaa4ed16/call-BenchmarkVCFControlSample/Benchmark/492b823a-1e34-46cd-b842-5f042bb31ee8/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-EXOME1SampleHeadToHead/BenchmarkComparison/1269d993-e13f-4635-a12a-e65fdaa4ed16/call-BenchmarkVCFTestSample/Benchmark/834b6562-65d7-4daf-857a-d9118a6456b7/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-NISTSampleHeadToHead/BenchmarkComparison/338d644e-3327-471e-9d17-1c103fa5e01e/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-NISTSampleHeadToHead/BenchmarkComparison/338d644e-3327-471e-9d17-1c103fa5e01e/call-BenchmarkVCFControlSample/Benchmark/145d88de-5810-47e1-972a-18ff0169fe27/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""92.82975"",; ""NIST evalHCsystemhours"": ""0.17177777777777778"",; ""NIST evalHCwallclockhours"": ""66.4404388888889"",; ""NIST evalHCwallclockmax"": ""3.325327777777778"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1193038382:19691,monitor,monitoring,19691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1193038382,1,['monitor'],['monitoring']
Energy Efficiency,"omparison/3b586c16-feb0-4cdd-8850-8426205cced2/call-BenchmarkVCFControlSample/Benchmark/31dfb54a-9ecc-4af2-9fcd-ea9af745342e/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-EXOME1SampleHeadToHead/BenchmarkComparison/3b586c16-feb0-4cdd-8850-8426205cced2/call-BenchmarkVCFTestSample/Benchmark/7c7e45ee-4fe9-48e6-b8ed-cd4372c9e726/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-NISTSampleHeadToHead/BenchmarkComparison/d1a60d2b-8100-459a-9b05-72a22afccb4a/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-NISTSampleHeadToHead/BenchmarkComparison/d1a60d2b-8100-459a-9b05-72a22afccb4a/call-BenchmarkVCFControlSample/Benchmark/9f6d4e85-981d-4607-8ff6-97495034807f/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""96.65376666666666"",; ""NIST evalHCsystemhours"": ""0.17881944444444442"",; ""NIST evalHCwallclockhours"": ""68.38394444444445"",; ""NIST evalHCwallclockmax"": ""3.8226138888888888"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1182703672:19704,monitor,monitoring,19704,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1182703672,1,['monitor'],['monitoring']
Energy Efficiency,"omparison/3ba68beb-5853-4beb-b31c-cbef12825001/call-BenchmarkVCFControlSample/Benchmark/18840f82-6653-4365-8e02-daf8790ea4f0/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875eab/call-EXOME1SampleHeadToHead/BenchmarkComparison/3ba68beb-5853-4beb-b31c-cbef12825001/call-BenchmarkVCFTestSample/Benchmark/194337cf-f57b-46fa-812c-e6510f51fd8d/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875eab/call-NISTSampleHeadToHead/BenchmarkComparison/a39481f5-0969-4891-a843-f3c3fd7437d1/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875eab/call-NISTSampleHeadToHead/BenchmarkComparison/a39481f5-0969-4891-a843-f3c3fd7437d1/call-BenchmarkVCFControlSample/Benchmark/0c99102a-bca1-4426-97c6-5a311ace93c1/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""95.62183055555556"",; ""NIST evalHCsystemhours"": ""0.18361111111111117"",; ""NIST evalHCwallclockhours"": ""64.22846111111112"",; ""NIST evalHCwallclockmax"": ""3.3683277777777776"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069766207:13477,monitor,monitoring,13477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069766207,1,['monitor'],['monitoring']
Energy Efficiency,"omparison/4803682b-a3c6-46d6-924b-dbc96a877e16/call-BenchmarkVCFControlSample/Benchmark/dd059ca4-251d-4793-bbff-10dd76123882/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-EXOME1SampleHeadToHead/BenchmarkComparison/4803682b-a3c6-46d6-924b-dbc96a877e16/call-BenchmarkVCFTestSample/Benchmark/e3563584-017d-476b-bbca-775128c80272/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-NISTSampleHeadToHead/BenchmarkComparison/ccdb901c-fb8f-49e4-b542-cf42e011a623/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-NISTSampleHeadToHead/BenchmarkComparison/ccdb901c-fb8f-49e4-b542-cf42e011a623/call-BenchmarkVCFControlSample/Benchmark/6d64f12a-ca50-4ecd-8608-93dc53d241bb/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""95.62183055555556"",; ""NIST evalHCsystemhours"": ""0.18361111111111117"",; ""NIST evalHCwallclockhours"": ""64.22846111111112"",; ""NIST evalHCwallclockmax"": ""3.3683277777777776"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815:13477,monitor,monitoring,13477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815,1,['monitor'],['monitoring']
Energy Efficiency,"omparison/5bf5f11a-64cb-4b50-8d05-b61b7f4c803c/call-BenchmarkVCFControlSample/Benchmark/c64dbce6-4a90-42c0-a84b-59857afb98a5/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be850d5/call-EXOME1SampleHeadToHead/BenchmarkComparison/5bf5f11a-64cb-4b50-8d05-b61b7f4c803c/call-BenchmarkVCFTestSample/Benchmark/d501a36a-a881-4e5c-9499-ef7dea22980f/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be850d5/call-NISTSampleHeadToHead/BenchmarkComparison/4ffa2353-b1bc-4960-a5a4-96291208a7eb/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be850d5/call-NISTSampleHeadToHead/BenchmarkComparison/4ffa2353-b1bc-4960-a5a4-96291208a7eb/call-BenchmarkVCFControlSample/Benchmark/8cf95ec9-48a7-4e20-a8fe-816dc3e652ae/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""100.56416111111112"",; ""NIST evalHCsystemhours"": ""0.19999166666666665"",; ""NIST evalHCwallclockhours"": ""74.00048055555555"",; ""NIST evalHCwallclockmax"": ""4.007605555555555"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1533946590:20364,monitor,monitoring,20364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1533946590,1,['monitor'],['monitoring']
Energy Efficiency,"omparison/688ca200-89b9-479b-b701-5fa0b0854778/call-BenchmarkVCFControlSample/Benchmark/59d8f8b1-1323-4e56-a1b1-0b1b2c8f2cc0/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-EXOME1SampleHeadToHead/BenchmarkComparison/688ca200-89b9-479b-b701-5fa0b0854778/call-BenchmarkVCFTestSample/Benchmark/1b8ccc58-1ead-4443-b6a8-64f767abfc70/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-NISTSampleHeadToHead/BenchmarkComparison/d1047505-b7bc-455d-851f-fbed8d81e895/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-NISTSampleHeadToHead/BenchmarkComparison/d1047505-b7bc-455d-851f-fbed8d81e895/call-BenchmarkVCFControlSample/Benchmark/5388d7b6-6bcd-451d-9a4e-925b386ecd0c/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""95.03499722222222"",; ""NIST evalHCsystemhours"": ""0.17304166666666665"",; ""NIST evalHCwallclockhours"": ""67.81165555555557"",; ""NIST evalHCwallclockmax"": ""3.691061111111111"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-b",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1194801748:19705,monitor,monitoring,19705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1194801748,1,['monitor'],['monitoring']
Energy Efficiency,"omparison/ba4f3a3f-c40c-4037-837a-0bf9a85d0ece/call-BenchmarkVCFControlSample/Benchmark/61548750-761a-42ff-8d40-c80f94866dcd/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-EXOME1SampleHeadToHead/BenchmarkComparison/ba4f3a3f-c40c-4037-837a-0bf9a85d0ece/call-BenchmarkVCFTestSample/Benchmark/476aa516-7233-4df2-8fc5-83b3f2df9eb6/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""95.8154"",; ""NIST controlHCsystemhours"": ""0.1727638888888889"",; ""NIST controlHCwallclockhours"": ""69.03862222222223"",; ""NIST controlHCwallclockmax"": ""3.457286111111111"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-BenchmarkVCFControlSample/Benchmark/9033775b-223e-4c4a-8dc8-28b281b3f2e1/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""102.1011388888889"",; ""NIST evalHCsystemhours"": ""0.20356111111111105"",; ""NIST evalHCwallclockhours"": ""74.47628888888889"",; ""NIST evalHCwallclockmax"": ""4.013952777777778"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535665125:20381,monitor,monitoring,20381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535665125,1,['monitor'],['monitoring']
Energy Efficiency,"omparison/efb51584-614a-4702-bc80-17a6a388e888/call-BenchmarkVCFControlSample/Benchmark/ea5e6517-663b-4cfb-b264-0dc933da9ae3/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8/call-EXOME1SampleHeadToHead/BenchmarkComparison/efb51584-614a-4702-bc80-17a6a388e888/call-BenchmarkVCFTestSample/Benchmark/086dd5e8-74c8-4603-b618-a70d77398545/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8/call-NISTSampleHeadToHead/BenchmarkComparison/ed0dc9e1-2d64-47e4-82e0-811971957020/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8/call-NISTSampleHeadToHead/BenchmarkComparison/ed0dc9e1-2d64-47e4-82e0-811971957020/call-BenchmarkVCFControlSample/Benchmark/8c516721-e955-41d1-907e-fcee92f592d3/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""100.56416111111112"",; ""NIST evalHCsystemhours"": ""0.19999166666666665"",; ""NIST evalHCwallclockhours"": ""74.00048055555555"",; ""NIST evalHCwallclockmax"": ""4.007605555555555"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535104202:20398,monitor,monitoring,20398,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535104202,1,['monitor'],['monitoring']
Energy Efficiency,"ompression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1. 16:17:05.843 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/. 16:17:05.843 INFO HaplotypeCaller - Executing as robert@powerlinux on Linux v4.4.0-184-generic ppc64le. 16:17:05.843 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-8u252-b09-1~16.04-b09. 16:17:05.843 INFO HaplotypeCaller - Start Date/Time: September 4, 2020 4:17:04 PM UTC. 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Version: 2.23.0. 16:17:05.844 INFO HaplotypeCaller - Picard Version: 2.22.8. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false. 16:17:05.844 INFO HaplotypeCaller - Deflater: JdkDeflater. 16:17:05.844 INFO ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794:2210,power,powerlinux,2210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794,1,['power'],['powerlinux']
Energy Efficiency,"on **data representation**:. @laserson: yes, I think it makes total sense to eventually move to a better format. The requirements seem to be: (a) efficient serialization/deserialization, and (b) can easily convert to a SAMRecord for compatibility with existing code. We can make things extra efficient by only deserializing things if they are needed (if a phase doesn't need the CIGAR-related structures, no need to deserialize that). We can achieve this by having the deserialization be lazy. The LazyBAMRecord is a step in that direction since it looks up the reference name only if we ask for it, but we could go a lot further in this direction. But before we do that, having an efficient coder for SAMRecords (I vote for @tomwhite's approach of using the BAMEncoder) will get us 80% of the way for 20% of the effort. Then we can introduce our OptimizedSAMRecord incrementally. . on **headers**:. I agree with @tomwhite that adding the header back after a shuffle is the right thing to do. We know where that happens and we control that code.; @davidadamsphd, you worry about newcomers. But we've already decided that we were going to provide our own API for them (one that does the Dataflow copying for them so they don't have to worry about it). This same API will provide them with header-filled reads, so they don't have to worry about this detail. This falls into the general category of ""the 3rd party devs won't have to even know about Dataflow/Spark: they just need to know our nice, simple interface and use that"". If they know more and want to do fancier things then more power to them, but those users will surely be able to fill in headers, too. We have library functions to use the reads without the headers, but the problem is that (at least for the sort of code I'm writing), I'm handing off a SAMRecord to a big black box and I can't force it to use the library functions - it's going to work on the SAMRecord directly. So at least in this case it's important to fill in the header ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141151451:146,efficient,efficient,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141151451,3,['efficient'],['efficient']
Energy Efficiency,on.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:14421,schedul,scheduler,14421,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,on.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81); 	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79); 	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133); 	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856); 	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387); 	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360); 	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239); 	at org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:789); 	at StudentAws$.delayedEndpoint$StudentAws$1(StudentAws.scala:36); 	at StudentAws$delayedInit$body.apply(StudentAws.scala:8); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at StudentAws$.main(StudentAws.scala:8); 	at StudentAws.main(StudentAws.scala); 23/11/16 12:09:10 INFO SparkContext: Invoking stop() from shutdown hook; 23/11/16 12:09:10 INFO SparkContext: SparkContext is stopping with exitCode 0.; 23/11/16 12:09:10 INFO SparkUI: Stopped Spark web UI at http://SRINIVASiNDRARAVI:4040; 23/11/16 12:09:10 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 23/11/16 12:09:10 INFO MemoryStore: MemoryStore cleared; 23/11/16 12:09:10 INFO BlockManager: BlockManager stopped; 23/11/16 12:09:10 INFO BlockManagerMaster: BlockManagerMaster stopped; 23/11/16 12:09:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 23/11/16 12:09:10 INFO SparkContext: Successfully stopped SparkContext; 23/11/16 12:09:10 INFO ShutdownHookManager: Shutdown ho,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8587:12992,adapt,adapted,12992,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8587,1,['adapt'],['adapted']
Energy Efficiency,"on.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81); 	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79); 	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133); 	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856); 	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387); 	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360); 	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239); 	at org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:789); 	at StudentAws$.delayedEndpoint$StudentAws$1(StudentAws.scala:36); 	at StudentAws$delayedInit$body.apply(StudentAws.scala:8); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at StudentAws$.main(StudentAws.scala:8); 	at StudentAws.main(StudentAws.scala); Exception in thread ""main"" java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z; 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method); 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793); 	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249); 	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454); 	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761); 	at org.apache.hadoop.fs.FileSystem.listS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8587:7349,adapt,adapted,7349,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8587,1,['adapt'],['adapted']
Energy Efficiency,on.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1026); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.reduce(RDD.scala:1008); 	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1128); 	at org.apache.spark.api.java.JavaRDDLike$class.treeAggregate(JavaRDDLike.scala:439); 	at org.apache.spark.api.java.AbstractJavaRDDLike.treeAggregate(JavaRDDLike.scala:45); 	at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.apply(BaseRecalibratorSparkFn.java:38); 	at org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark.runTool(BaseRecalibratorSpark.java:132); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.b,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:3049,reduce,reduce,3049,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['reduce'],['reduce']
Energy Efficiency,"onTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db21wYXJlSW50ZXJ2YWxMaXN0c0ludGVncmF0aW9uVGVzdC5qYXZh) | `100% <100%> (Ã¸)` | `4 <4> (?)` | |; | [...stitute/hellbender/tools/CompareIntervalLists.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db21wYXJlSW50ZXJ2YWxMaXN0cy5qYXZh) | `93.33% <93.33%> (Ã¸)` | `4 <4> (?)` | |; | [...broadinstitute/hellbender/utils/IntervalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzLmphdmE=) | `91.88% <0%> (+0.35%)` | `188% <0%> (+1%)` | :arrow_up: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (+0.47%)` | `33% <0%> (Ã¸)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (+1.21%)` | `42% <0%> (Ã¸)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3702?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3702?src=pr&el=footer). Last update [a74e571...8f85021](https://codecov.io/gh/broadinstitute/gatk/pull/3702?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3702#issuecomment-337303370:2898,Power,Powered,2898,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3702#issuecomment-337303370,1,['Power'],['Powered']
Energy Efficiency,"onfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 00:11:09.632 WARN TaskSetManager:66 - Lost task 15.0 in stage 1.0 (TID 519, localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculation",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:5626,Reduce,ReduceOps,5626,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Reduce'],['ReduceOps']
Energy Efficiency,ongoing effort to reduce dependency on dataflow packages. @lbergelson please have a look,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1765:18,reduce,reduce,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1765,1,['reduce'],['reduce']
Energy Efficiency,ons$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111); at org.apache.spark.rdd.RDD.withScope(RDD.scala:316); at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:381); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:381); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111); at org.apache.spark.rdd.RDD.withScope(RDD.scala:316); at org.apache.spark.rdd.PairRDDFunctions.countByKey(PairRDDFunctions.scala:380); at org.apache.spark.rdd.RDD$$anonfun$countByValue$1.apply(RDD.scala:1187); at org.apache.spark.rdd.RDD$$anonfun$countByValue$1.apply(RDD.scala:118,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2113:5572,reduce,reduceByKey,5572,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2113,1,['reduce'],['reduceByKey']
Energy Efficiency,ons$2.apply(RDD.scala:246); at scala.Option.getOrElse(Option.scala:121); at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); at scala.Option.getOrElse(Option.scala:121); at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); at scala.Option.getOrElse(Option.scala:121); at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:328); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:328); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:327); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:372); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:372); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.PairRDDFunctions.countByKey(PairRDDFunctions.scala:371); at org.apache.spark.rdd.RDD$$anonfun$countByValue$1.apply(RDD.scala:1175); at org.apache.spark.rdd.RDD$$anonfun$countByValue$1.apply(RDD.scala:117,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3360:10261,reduce,reduceByKey,10261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360,1,['reduce'],['reduceByKey']
Energy Efficiency,onsRDD2.compute(ZippedPartitionsRDD.scala:89); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). I don't understand why if the command is the same:; ```; $GATK_PATH BwaAndMarkDuplicatesPipelineSpark --bam-partition-size 64000000 or 4000000 \; --input hdfs://namenode:8020/$dir_prepro$ubam \; --reference hdfs://namenode:8020/hg19-ucsc/ucsc.hg19.2bit \; --bwa-mem-index-image /reference_image/ucsc.hg19.fasta.img \; --disable-sequence-dictionary-validation true \; --output hdfs://namenode:8020/$dir_prepro$output -- \; --spark-runner SPARK --spark-master spark://$SPARK_MASTER_HOST:7077 \; --driver-memory 20g --executor-cores 4 --executor-memory 8g; ```. Furthermore I have this problem with this version ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:5762,schedul,scheduler,5762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['schedul'],['scheduler']
Energy Efficiency,onsRDD2.compute(ZippedPartitionsRDD.scala:89); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); for more information:. - v4.0.2.0-4-gb59d863-SNAPSHOT; ```; /spark//bin/spark-submit --master spark://680776067ebd:7077 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:9159,schedul,scheduler,9159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['schedul'],['scheduler']
Energy Efficiency,opyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.AlleleFrequencyUtils.lambda$buildMaxMafRule$1(AlleleFrequencyUtils.java:30) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.lambda$checkFilter$0(FuncotationFilter.java:48) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:558) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.checkFilter(FuncotationFilter.java:49) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$null$0(FilterFuncotations.java:194) ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:176) ; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:3604,Reduce,ReduceOps,3604,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['Reduce'],['ReduceOps']
Energy Efficiency,"or contamination file. This seemed to fix the index out of bounds error, but the job then failed at the filtering step, with the following error:. ```; java.lang.IllegalArgumentException: log10p: Log10-probability must be 0 or less; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); 	at org.broadinstitute.hellbender.utils.MathUtils.log10BinomialProbability(MathUtils.java:934); 	at org.broadinstitute.hellbender.utils.MathUtils.binomialProbability(MathUtils.java:927); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:56); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098:5851,Reduce,ReduceOps,5851,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098,1,['Reduce'],['ReduceOps']
Energy Efficiency,or$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38346,schedul,scheduler,38346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,or.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:41028,schedul,scheduler,41028,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,or.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:41774,schedul,scheduler,41774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,or.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **Driver stacktrace:** ; **at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)** ; **at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)** ; **at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)** ; **at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)** ; **at scala.Option.foreach(Option.scala:257)** ; **at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)** ; **at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)** ; **at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)** ; **at org.apache.spark.rdd.RDD.count(R,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:46452,schedul,scheduler,46452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,"orSpark work fine on other bam files. Additionally, changing the number of threads still results in the same stacktrace. I've also tried running the BQSRPipelineSpark to see if that would suffer the same issue and it fails in the same manner. Additionally, I've run ValidateSamFile. There are some reads missing their mates, but this hasn't presented an issue in other tools (including vanilla BaseRecalibrator). Searching thru the forum, I found an old issue with a similar stacktrace, but that issue appears to occur in GATK 2.4: https://gatkforums.broadinstitute.org/gatk/discussion/3265/bqsrgatherer-exception. In the below stacktrace, I've bolded the error message that seems to occur in each of these samples. `Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:1499,schedul,scheduler,1499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['schedul'],['scheduler']
Energy Efficiency,"ored as bytes in memory (estimated size 23.6 KB, free 360.5 MB); 19/04/08 19:03:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ip-xx.xx.xx.xx.ec2.internal:38471 (size: 23.6 KB, free: 365.8 MB); 19/04/08 19:03:27 INFO SparkContext: Created broadcast 4 from newAPIHadoopFile at PathSplitSource.java:96; 19/04/08 19:03:28 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 36.9 MB, free 323.6 MB); 19/04/08 19:03:28 INFO SparkUI: Stopped Spark web UI at http://ip-xx.xx.xx.xx.ec2.internal:4040; 19/04/08 19:03:28 INFO YarnClientSchedulerBackend: Interrupting monitor thread; 19/04/08 19:03:28 INFO YarnClientSchedulerBackend: Shutting down all executors; 19/04/08 19:03:28 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 19/04/08 19:03:28 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 19/04/08 19:03:28 INFO YarnClientSchedulerBackend: Stopped; 19/04/08 19:03:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 19/04/08 19:03:28 INFO MemoryStore: MemoryStore cleared; 19/04/08 19:03:28 INFO BlockManager: BlockManager stopped; 19/04/08 19:03:28 INFO BlockManagerMaster: BlockManagerMaster stopped; 19/04/08 19:03:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 19/04/08 19:03:28 INFO SparkContext: Successfully stopped SparkContext; 19:03:28.389 INFO HaplotypeCallerSpark - Shutting down engine; [April 8, 2019 7:03:28 PM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 1.75 minutes.; Runtime.totalMemory()=941096960; Exception in thread ""main"" java.lang.StackOverflowError; 	at java.util.HashMap.putMapEntries(HashMap.java:501); 	at java.util.HashMap.<init>(HashMap.java:490); 	at com.esotericsoftware.kryo.Generics.<init>(Generics.java:47); 	at com.esotericsoftware.kryo.serializers.FieldSerializerGenericsUtil.buildGenericsScop",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869:17266,monitor,monitor,17266,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869,3,"['Schedul', 'monitor']","['SchedulerExtensionServices', 'monitor']"
Energy Efficiency,org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1661); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1649); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1648); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1648); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1882); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1831); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:3821,schedul,scheduler,3821,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['schedul'],['scheduler']
Energy Efficiency,org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); 18/10/17 19:23:59 ERROR Executor: Exception in task 518.0 in stage 0.0 (TID 518); java.io.FileNotFoundException: /home/data/WGS/F002/F002.sort.bam (Too many open files); 	at java.io.FileInputStream.open0(Native Method); 	at java.io.FileInputStream.open(FileInputStream.java:195); 	at java.io.FileInputStream.<init>(FileInputStream.java:138); 	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.<init>(RawLocalFileSystem.java:106); 	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:202); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:349,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:4345,schedul,scheduler,4345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,1,['schedul'],['scheduler']
Energy Efficiency,org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.m,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513:6480,schedul,scheduler,6480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513,1,['schedul'],['scheduler']
Energy Efficiency,"org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Caused by: htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: /local/scratch/rieder/spark-bb59423b-0368-4de5-85e0-e6641fb25380/userFiles-a91d5958-33f5-4685-bf9d-c8fc0924f7c6/Homo_sapiens_assembly38.known_indels.vcf: Too many open files, for input source: /local/scratch/rieder/spark-bb59423b-0368-4de5-85e0-e6641fb25380/userFiles-a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6578:5459,schedul,scheduler,5459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6578,1,['schedul'],['scheduler']
Energy Efficiency,org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:15021,schedul,scheduler,15021,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['schedul'],['scheduler']
Energy Efficiency,org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513:7207,schedul,scheduler,7207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513,1,['schedul'],['scheduler']
Energy Efficiency,org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:7218,schedul,scheduler,7218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['schedul'],['scheduler']
Energy Efficiency,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2221,Meter,MeteredStream,2221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,2,['Meter'],['MeteredStream']
Energy Efficiency,"orker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). 00:11:09.634 ERROR TaskSetManager:70 - Task 15 in stage 1.0 failed 1 times; aborting job; 00:11:09.810 WARN TaskSetManager:66 - Lost task 33.0 in stage 1.0 (TID 528, localhost): TaskKilled (killed intentionally); 00:11:24.786 INFO HaplotypeCallerSpark - Shutting down engine; [May 26, 2017 12:11:24 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 10.58 minutes.; Runtime.totalMemory()=16622026752; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 1.0 failed 1 times, most recent failure: Lost task 15.0 in stage 1.0 (TID 519; , localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:10098,Reduce,ReduceOps,10098,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Reduce'],['ReduceOps']
Energy Efficiency,orrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$transformToDuplicateNames$4992d4e$1(MarkDuplicatesSparkUtils.java:140); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:199); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.UnsupportedOperationException; 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.ImmutableMap.put(ImmutableMap.java:326); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:162); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:246); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$8.apply(TorrentBroadcast.scala:293); 	at org,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4775:1311,schedul,scheduler,1311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4775,1,['schedul'],['scheduler']
Energy Efficiency,"orted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935); at org.apache.spark.rdd.RD",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1775,schedul,scheduler,1775,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['schedul'],['scheduler']
Energy Efficiency,ory.java:530) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172) ; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857) ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651:5685,Reduce,ReduceOps,5685,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,ory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6774:4879,Reduce,ReduceOps,4879,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,ory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:907); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:861); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069:4057,Reduce,ReduceOps,4057,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"otFoundError: The following packages are not available from current channels:. - conda-forge::typing_extensions==4.1.1; - conda-forge::theano==1.0.4; - pkgs/main::tensorflow==1.15.0; - conda-forge::scipy==1.0.0; - conda-forge::scikit-learn==0.23.1; - conda-forge::python==3.6.10; - bioconda::pysam==0.15.3; - conda-forge::pymc3==3.1; - conda-forge::pip==21.3.1; - conda-forge::pandas==1.0.3; - conda-forge::numpy==1.17.5; - conda-forge::mkl-service==2.3.0; - conda-forge::mkl==2019.5; - conda-forge::matplotlib==3.2.1; - conda-forge::keras==2.2.4; - conda-forge::joblib==1.1.1; - pkgs/main::intel-openmp==2019.4; - conda-forge::h5py==2.10.0; - conda-forge::dill==0.3.4. Current channels:. - https://conda.anaconda.org/conda-forge/linux-64; - https://repo.anaconda.com/pkgs/main/linux-64; - https://repo.anaconda.com/pkgs/r/linux-64; - https://conda.anaconda.org/bioconda/linux-64; - https://conda.anaconda.org/bioconda; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - defaults; - defaults. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org. and use the search bar at the top of the page. bash:iscxf001:/data1/greenbab/users/ahunos/apps/gatk-4.5.0.0 1024 $ ; ```. software version; ```; bash:iscxf001:/data1/greenbab/users/ahunos/apps/gatk-4.5.0.0 1024 $ mamba --version; mamba 1.5.7; conda 24.3.0; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8838:2376,green,greenbab,2376,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8838,2,['green'],['greenbab']
Energy Efficiency,otFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:41108,schedul,scheduler,41108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,otFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:41854,schedul,scheduler,41854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,oud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 15 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:8501,Meter,MeteredStream,8501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['Meter'],['MeteredStream']
Energy Efficiency,oud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 47 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 50 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727:6795,Meter,MeteredStream,6795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727,1,['Meter'],['MeteredStream']
Energy Efficiency,oud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:209); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketI,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:10283,Meter,MeteredStream,10283,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['Meter'],['MeteredStream']
Energy Efficiency,"oups in a SAM/BAM/CRAM file with a single new read group; ApplyBQSR Applies the BQSR table to the input SAM/BAM/CRAM; BaseRecalibrator Generates recalibration table for BQSR; BuildBamIndex Generates a BAM index (.bai) file; CalculateReadGroupChecksum Creates a hash code based on the read groups (RG) in the SAM/BAM/CRAM header; CleanSam Cleans the provided SAM/BAM/CRAM, soft-clipping beyond-end-of-reference alignments and setting MAPQ to 0 for unmapped reads; ClipReads Clip reads in a SAM/BAM/CRAM file; CompareBaseQualities Compares base qualities of two input SAM/BAM/CRAM files; CompareSAMs Compares two input SAM/BAM/CRAM files; CountBases Count bases in a SAM/BAM/CRAM file; CountReads Count reads in a SAM/BAM/CRAM file; DownsampleSam Down-sample a SAM/BAM file to retain a random subset of the reads; EstimateLibraryComplexity Estimates library complexity from the sequence of read pairs; ExampleReadWalkerWithReference Print reads with reference context; ExampleReadWalkerWithVariants Print reads with overlapping variants; FastqToSam Converts a fastq file to an unaligned SAM/BAM file; FilterReads Creates a new SAM/BAM/CRAM file by including or excluding aligned reads; FixMateInformation Ensure that all mate-pair information is in sync between each read and its mate pair; FixMisencodedBaseQualityReads Fix Illumina base quality scores in a SAM/BAM/CRAM file; FlagStat A reimplementation of the 'samtools flagstat' subcommand; GatherBQSRReports Gathers scattered BQSR recalibration reports into a single file; GatherBamFiles Concatenates one or more BAM files together as efficiently as possible; LeftAlignIndels Left-aligns indels from reads in a SAM/BAM/CRAM file; MarkDuplicates Examines aligned records in the supplied SAM/BAM/CRAM file to locate duplicate molecules.; MergeBamAlignment Merges alignment data from a SAM/BAM with data in an unmapped SAM/BAM/CRAM file; MergeSamFiles Merges multiple SAM/BAM files into one file; PrintReads Print reads in the SAM/BAM/CRAM file; Reor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1669:5127,efficient,efficiently,5127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1669,1,['efficient'],['efficiently']
Energy Efficiency,"our cluster is centos7, but i could work with whatever you're able to most efficiently create. we really appreciate the help here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722660469:75,efficient,efficiently,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722660469,1,['efficient'],['efficiently']
Energy Efficiency,overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.ContigAlignmentsModifier.removeOverlap(ContigAlignmentsModifier.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.AssemblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [a85f28df-e6b8-4f64-bafb-c0f195dcd4d5] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:14276,schedul,scheduler,14276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,3,['schedul'],['scheduler']
Energy Efficiency,"p/pipelines/broad/annotation\_filtration/cromwell-executions/AnnotationFiltration/4e3bd06b-3018-4c94-ac98-feb78b924d1f/call-FilterFuncotations/shard-0/inputs/1333115969/104566-001-001.filtered.vcf.funcotated.vcf.gz \ ; --output 104566-001-001.filtered.vcf.filtered.vcf.gz \ ; --ref-version hg38 \ ; --allele-frequency-data-source gnomad --lenient true; ; ; ; ; . However, the command fails with the error message below:. ; ; ; ; [October 14, 2021 at 12:20:24 PM CEST] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 16.57 minutes. ; Runtime.totalMemory()=1134559232 ; java.lang.IllegalStateException: Duplicate key Gencode\_34\_annotationTranscript (attempted merging values ENST00000450305.2 and ENST00000456328.2) ; at java.base/java.util.stream.Collectors.duplicateKeyException(Collectors.java:133) ; at java.base/java.util.stream.Collectors.lambda$uniqKeysMapAccumulator$1(Collectors.java:180) ; at java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; at java.base/java.util.HashMap$KeySpliterator.forEachRemaining(HashMap.java:1603) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.AlleleFrequencyUtils.lambda$buildMaxMafRule$1(AlleleFrequencyUtils.java:30) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.lambda$checkFilter$0(FuncotationFilter.java:48) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:2353,Reduce,ReduceOps,2353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['Reduce'],['ReduceOps']
Energy Efficiency,"pPartitions$1$$anonfun$apply$23.apply(RDD.scala:796); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```; And I notice `gatk/src/main/java/org/broadinstitute/hellbender/utils/bwa/BwaMemAligner.java` doesn't exist, and there is no class file `gatk/build/classes/main/org/broadinstitute/hellbender/utils/bwa/BwaMemAligner.class` either. Is that causing this error?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186:3424,schedul,scheduler,3424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186,3,['schedul'],['scheduler']
Energy Efficiency,"pace(6656) called with curMem=0, maxMem=278019440; 15/07/14 13:14:52 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.5 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(3753) called with curMem=6656, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:65240 (size: 3.7 KB, free: 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerMaster: Updated info of block broadcast_0_piece0; 15/07/14 13:14:53 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:839; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MapPartitionsRDD[4] at map at TransformTranslator.java:181); 15/07/14 13:14:53 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 1 tasks; 15/07/14 13:14:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1435 bytes); 15/07/14 13:14:53 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0); 15/07/14 13:14:53 INFO executor.Executor: Fetching http://10.1.4.233:65239/jars/hellbender-all-GATK.4.alpha-413-g741d007-SNAPSHOT-spark.jar with timestamp 1436894092643; 15/07/14 13:14:53 INFO util.Utils: Fetching http://10.1.4.233:65239/jars/hellbender-all-GATK.4.alpha-413-g741d007-SNAPSHOT-spark.jar to /var/folders/xt/vq7wz8955r1401mv8w0f4zf9qbfwzl/T/louisb/spark-ccf49262-23e0-45d9-a273-0096f310c64a/userFiles-0909d070-1b0a-4cf7-8d86-e4144a2dd020/fetchFileTemp6888440563594800088.tmp; 15/07/14 13:14:53 INFO executor.Executor: Adding file:/var/folders/xt/vq7wz8955r1401mv8w0f4zf9qbfwzl/T/louisb/spark-ccf49262-23e0-45d9-a273-0096f310c64a/userFiles-0909d070-1b0a-4cf7-8d86-e4144a2dd020/hellbender-all-GATK.4.alpha-413-g741d007-SNAPSHOT-spark.jar to class loader; 13:14:53.486 [Executor task launch",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:23464,schedul,scheduler,23464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['schedul'],['scheduler']
Energy Efficiency,pache.spark.RangePartitioner$$anonfun$13.apply(Partitioner.scala:301); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:14824,schedul,scheduler,14824,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['schedul'],['scheduler']
Energy Efficiency,pache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1028); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7.apply$mcV$sp(PairRDDFunctions.scala:1204); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7.apply(PairRDDFunctions.scala:1203); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7.apply(PairRDDFunctions.scala:1203); 	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1348); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1211); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1190); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). **This is the stack I get when the test completes but fails (note that the expected line count appears to not match the line count of the expected output file in the repo): **. java.lang.AssertionError: line counts expected [2629] but found [507]; 	at org.testng.Assert.fail(Assert.java:94); 	at org.testng.Assert.failNotEquals(Assert.java:496); 	at org.testng.Assert.assertEquals(Assert.java:125); 	at org.testng.Assert.assertEquals(Assert.java:372); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:211); 	at org.broadinstitute.hellbender.utils.t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:2568,schedul,scheduler,2568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['schedul'],['scheduler']
Energy Efficiency,pache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:847); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:14923,schedul,scheduler,14923,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['schedul'],['scheduler']
Energy Efficiency,"parameterize TTL with defaults, reduce memory allocation",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7244:32,reduce,reduce,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7244,1,['reduce'],['reduce']
Energy Efficiency,"parison/113b01be-9124-41dd-acc0-5732ef2c7b38/call-BenchmarkVCFControlSample/Benchmark/7222f3cf-155c-423f-bc1e-8194e87ff05f/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.7573"",; ""EXOME1 evalindelPrecision"": ""0.6882"",; ""EXOME1 evalsnpF1Score"": ""0.9896"",; ""EXOME1 evalsnpPrecision"": ""0.9852"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e372bd14-cd1f-4563-8d8a-abf6b6ca7883/call-EXOME1SampleHeadToHead/BenchmarkComparison/113b01be-9124-41dd-acc0-5732ef2c7b38/call-BenchmarkVCFTestSample/Benchmark/e929ad45-5026-4630-8b85-19f6205f068c/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e372bd14-cd1f-4563-8d8a-abf6b6ca7883/call-NISTSampleHeadToHead/BenchmarkComparison/103cd89c-b177-4a0b-84fc-9553a1f8161f/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9843"",; ""NIST controlindelPrecision"": ""0.9895"",; ""NIST controlsnpF1Score"": ""0.9908"",; ""NIST controlsnpPrecision"": ""0.992"",; ""NIST controlsnpRecall"": ""0.9896"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e372bd14-cd1f-4563-8d8a-abf6b6ca7883/call-NISTSampleHeadToHead/BenchmarkComparison/103cd89c-b177-4a0b-84fc-9553a1f8161f/call-BenchmarkVCFControlSample/Benchmark/eaf4d582-e197-4e13-8122-5e1ec22591ae/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""73.06777222222223"",; ""NIST evalHCsystemhours"": ""0.1622555555555555"",; ""NIST evalHCwallclockhours"": ""46.65241388888888"",; ""NIST evalHCwallclockmax"": ""2.7461055555555554"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e372bd14-cd1f-4563-8d8a-ab",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069381494:13482,monitor,monitoring,13482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069381494,1,['monitor'],['monitoring']
Energy Efficiency,"parison/7b11647c-6643-4c47-8e1c-3f07bd97e371/call-BenchmarkVCFControlSample/Benchmark/086348b1-f09c-49b0-b830-587e28eec63d/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.7573"",; ""EXOME1 evalindelPrecision"": ""0.6882"",; ""EXOME1 evalsnpF1Score"": ""0.9896"",; ""EXOME1 evalsnpPrecision"": ""0.9852"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-EXOME1SampleHeadToHead/BenchmarkComparison/7b11647c-6643-4c47-8e1c-3f07bd97e371/call-BenchmarkVCFTestSample/Benchmark/47d80f67-4375-460f-9ce0-8186eec9fe5b/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-NISTSampleHeadToHead/BenchmarkComparison/8e62c1c2-cf9c-4530-846e-1e0d6c6d8acf/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-NISTSampleHeadToHead/BenchmarkComparison/8e62c1c2-cf9c-4530-846e-1e0d6c6d8acf/call-BenchmarkVCFControlSample/Benchmark/e71074a5-27ad-4a8b-a533-cdc111c0374f/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""73.06777222222223"",; ""NIST evalHCsystemhours"": ""0.1622555555555555"",; ""NIST evalHCwallclockhours"": ""46.65241388888888"",; ""NIST evalHCwallclockmax"": ""2.7461055555555554"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064:13480,monitor,monitoring,13480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064,1,['monitor'],['monitoring']
Energy Efficiency,park.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); Caused by: java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:16989,Reduce,ReduceOps,16989,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Reduce'],['ReduceOps']
Energy Efficiency,park.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(JavaPairRDD.scala:1037); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); at scala.collection.AbstractIterator.aggregate(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$27.apply(RDD.scala:1191); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$27.apply(RDD.scala:1191); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724:2571,schedul,scheduler,2571,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724,2,['schedul'],['scheduler']
Energy Efficiency,park.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:407); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:471); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6$$anonfun$apply$3.apply(Client.scala:470); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:470); at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$6.apply(Client.scala:468); at scala.collection.immutable.List.foreach(List.scala:318); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:468); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:727); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:142); at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:57); at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144); at org.apache.spark.SparkContext.<init>(SparkContext.scala:530); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbend,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1780:2002,schedul,scheduler,2002,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1780,2,['schedul'],['scheduler']
Energy Efficiency,park.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.sc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3679:3811,schedul,scheduler,3811,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679,1,['schedul'],['scheduler']
Energy Efficiency,park.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Generated by:. java -Xmx16g -jar /dsde/working/slee/CNV-1.5_HCC1143/resources/gatk-package-4.beta.5-97-g066c0b4-SNAPSHOT-local.jar SparkGenomeReadCounts \; --input /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-CollectReadCountsNormal/inputs/seq/picard_aggregation/G15511/HCC1143_BL/current/HCC1143_BL.bam \; --reference /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-Collec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3679:11642,schedul,scheduler,11642,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679,1,['schedul'],['scheduler']
Energy Efficiency,park.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:40680,schedul,scheduler,40680,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,park.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:41426,schedul,scheduler,41426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,park.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:40582,schedul,scheduler,40582,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['schedul'],['scheduler']
Energy Efficiency,park.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:41328,schedul,scheduler,41328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['schedul'],['scheduler']
Energy Efficiency,park.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:294); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:226); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 21 more; Caused by: java.lang.UnsupportedOperationException; 	at shaded.cloud_nio.com.google.common.collect.ImmutableMap.put(ImmutableMap.java:407); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:162); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	... 38 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545:9696,schedul,scheduler,9696,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545,1,['schedul'],['scheduler']
Energy Efficiency,parkRunner SPARK --sparkMaster yarn --javaOptions -Dmapr.library.flatclass; I got the following error!. > Driver stacktrace:; > 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1436); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1424); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); > 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); > 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); > 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1423); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); > 	at scala.Option.foreach(Option.scala:257); > 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1651); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1606); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1595); > 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); > 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); > 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); > 	at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); > 	at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); >,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936:1389,schedul,scheduler,1389,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936,1,['schedul'],['scheduler']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""050d2d6e-4a50-4145-a9da-8a39731ebdd2"",; ""eval_cromwell_job_id"": ""0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8"",; ""created_at"": ""2023-05-04T15:40:52.834692"",; ""created_by"": null,; ""finished_at"": ""2023-05-04T17:03:53.525"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8/call-CHMSampleHeadToHead/BenchmarkComparison/a332776f-175a-4595-bdeb-ab62e7f89921/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8/call-CHMSampleHeadToHead/BenchmarkComparison/a332776f-175a-4595-bdeb-ab62e7f89921/call-BenchmarkVCFControlSample/Benchmark/06cbfab4-17a7-4415-9118-d0ebbe156bfd/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""84.26158888888888"",; ""CHM evalHCsystemhours"": ""0.19243055555555555"",; ""CHM evalHCwallclockhours"": ""60.242008333333345"",; ""CHM evalHCwallclockmax"": ""3.176513888888889"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7f",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535104202:17391,monitor,monitoring,17391,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535104202,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""07271d7b-729d-4db9-862d-5f992a60a598"",; ""eval_cromwell_job_id"": ""89508d5f-29f1-4534-9fe1-220a80de17c4"",; ""created_at"": ""2022-07-22T17:23:11.546971"",; ""created_by"": null,; ""finished_at"": ""2022-07-23T02:09:23.327"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-CHMSampleHeadToHead/BenchmarkComparison/a2a2515a-b32a-44a6-a6d1-9a6d0d2199bb/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-CHMSampleHeadToHead/BenchmarkComparison/a2a2515a-b32a-44a6-a6d1-9a6d0d2199bb/call-BenchmarkVCFControlSample/Benchmark/2c4ad666-e885-4e23-bd5c-d54ca521ffbf/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""78.99195555555558"",; ""CHM evalHCsystemhours"": ""0.16168333333333337"",; ""CHM evalHCwallclockhours"": ""55.43875833333334"",; ""CHM evalHCwallclockmax"": ""2.913311111111111"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1193038382:16695,monitor,monitoring,16695,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1193038382,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""410a88f6-62ca-4745-89fd-df6e30aac65b"",; ""eval_cromwell_job_id"": ""bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9"",; ""created_at"": ""2022-03-16T19:53:45.833854"",; ""created_by"": null,; ""finished_at"": ""2022-03-17T00:11:38.702"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-CHMSampleHeadToHead/BenchmarkComparison/79d1a2a4-6b5e-424a-8528-9059bda6db1c/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-CHMSampleHeadToHead/BenchmarkComparison/79d1a2a4-6b5e-424a-8528-9059bda6db1c/call-BenchmarkVCFControlSample/Benchmark/3046acf7-ded7-40c8-9b7a-3826f480418f/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""67.35536666666667"",; ""CHM evalHCsystemhours"": ""0.1557166666666667"",; ""CHM evalHCwallclockhours"": ""42.53388888888889"",; ""CHM evalHCwallclockmax"": ""2.7197444444444443"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064:10472,monitor,monitoring,10472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""54997ade-421d-439f-acc9-abf50b3f9cb5"",; ""eval_cromwell_job_id"": ""6ea2705f-a3fa-41fc-8d17-a2c55d875eab"",; ""created_at"": ""2022-03-16T19:52:46.276978"",; ""created_by"": null,; ""finished_at"": ""2022-03-17T00:13:17.198"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875eab/call-CHMSampleHeadToHead/BenchmarkComparison/1fb97a8b-caee-4184-8e36-be21e6c43549/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875eab/call-CHMSampleHeadToHead/BenchmarkComparison/1fb97a8b-caee-4184-8e36-be21e6c43549/call-BenchmarkVCFControlSample/Benchmark/3b068fb2-7140-4c1e-8860-df8df21821ec/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""80.5165222222222"",; ""CHM evalHCsystemhours"": ""0.1713305555555555"",; ""CHM evalHCwallclockhours"": ""53.10978888888891"",; ""CHM evalHCwallclockmax"": ""2.7458416666666667"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875e",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069766207:10472,monitor,monitoring,10472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069766207,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""5e9a598e-1e80-4622-b153-78e97491a478"",; ""eval_cromwell_job_id"": ""f7eac327-c59c-43f7-a850-21bc3e0ccf52"",; ""created_at"": ""2022-07-12T17:28:58.385152"",; ""created_by"": null,; ""finished_at"": ""2022-07-13T02:47:47.016"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-CHMSampleHeadToHead/BenchmarkComparison/cd28fe49-1672-4321-a836-47f76419c1c8/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-CHMSampleHeadToHead/BenchmarkComparison/cd28fe49-1672-4321-a836-47f76419c1c8/call-BenchmarkVCFControlSample/Benchmark/d5df8455-36cf-4ecb-8dc2-ec35b974c0b7/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""78.23616944444446"",; ""CHM evalHCsystemhours"": ""0.16188333333333332"",; ""CHM evalHCwallclockhours"": ""55.167422222222214"",; ""CHM evalHCwallclockmax"": ""2.887522222222222"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1182703672:16707,monitor,monitoring,16707,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1182703672,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""5f0f8f34-cdc7-46ff-a59d-2368edcdf007"",; ""eval_cromwell_job_id"": ""e6f57e40-2025-46fd-9aa0-d591a3799007"",; ""created_at"": ""2022-03-16T14:20:46.087600"",; ""created_by"": null,; ""finished_at"": ""2022-03-16T17:21:08.639"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-CHMSampleHeadToHead/BenchmarkComparison/f65a7960-7b66-4a5d-a346-bd188a1b3830/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-CHMSampleHeadToHead/BenchmarkComparison/f65a7960-7b66-4a5d-a346-bd188a1b3830/call-BenchmarkVCFControlSample/Benchmark/8d0e47ca-66f5-42a0-8785-6aa8d2db2663/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""80.5165222222222"",; ""CHM evalHCsystemhours"": ""0.1713305555555555"",; ""CHM evalHCwallclockhours"": ""53.10978888888891"",; ""CHM evalHCwallclockmax"": ""2.7458416666666667"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a37990",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815:10472,monitor,monitoring,10472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""9886a710-334a-41eb-a495-6968d322730a"",; ""eval_cromwell_job_id"": ""9bc521dc-3c4c-4274-972c-9d1e4be850d5"",; ""created_at"": ""2023-05-03T15:51:41.295461"",; ""created_by"": null,; ""finished_at"": ""2023-05-04T01:24:02.606"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be850d5/call-CHMSampleHeadToHead/BenchmarkComparison/092bfb4f-d978-4964-a8ae-e5a7f7362f7c/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be850d5/call-CHMSampleHeadToHead/BenchmarkComparison/092bfb4f-d978-4964-a8ae-e5a7f7362f7c/call-BenchmarkVCFControlSample/Benchmark/6ab078fb-b668-452c-bbaa-8fb1fd8e25ba/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""84.26158888888888"",; ""CHM evalHCsystemhours"": ""0.19243055555555555"",; ""CHM evalHCwallclockhours"": ""60.242008333333345"",; ""CHM evalHCwallclockmax"": ""3.176513888888889"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be8",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1533946590:17367,monitor,monitoring,17367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1533946590,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""a8ee297d-9fd6-433f-ac22-14488a09b832"",; ""eval_cromwell_job_id"": ""2a8ce326-baa5-4052-bff9-bd684393ff6c"",; ""created_at"": ""2022-07-25T15:10:00.795227"",; ""created_by"": null,; ""finished_at"": ""2022-07-26T00:11:26.646"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-CHMSampleHeadToHead/BenchmarkComparison/a1db35b8-cc7b-4019-bdd0-9f423762542e/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-CHMSampleHeadToHead/BenchmarkComparison/a1db35b8-cc7b-4019-bdd0-9f423762542e/call-BenchmarkVCFControlSample/Benchmark/7195c554-534f-43ef-80c2-77bdafa1827f/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""78.10181666666668"",; ""CHM evalHCsystemhours"": ""0.16157500000000005"",; ""CHM evalHCwallclockhours"": ""55.006172222222226"",; ""CHM evalHCwallclockmax"": ""2.8554194444444443"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd68439",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1194801748:16707,monitor,monitoring,16707,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1194801748,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""d6f96a63-9657-4ff6-9934-fe1ab3cea617"",; ""eval_cromwell_job_id"": ""e372bd14-cd1f-4563-8d8a-abf6b6ca7883"",; ""created_at"": ""2022-03-16T14:19:54.192086"",; ""created_by"": null,; ""finished_at"": ""2022-03-16T17:26:08.529"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e372bd14-cd1f-4563-8d8a-abf6b6ca7883/call-CHMSampleHeadToHead/BenchmarkComparison/7ff0db7c-0871-4cda-95f3-fa75436cbb21/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8778"",; ""CHM controlindelPrecision"": ""0.8968"",; ""CHM controlsnpF1Score"": ""0.9813"",; ""CHM controlsnpPrecision"": ""0.9774"",; ""CHM controlsnpRecall"": ""0.9852"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e372bd14-cd1f-4563-8d8a-abf6b6ca7883/call-CHMSampleHeadToHead/BenchmarkComparison/7ff0db7c-0871-4cda-95f3-fa75436cbb21/call-BenchmarkVCFControlSample/Benchmark/16cd1efe-5cea-403e-8e85-aec15e71bd1d/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""67.35536666666667"",; ""CHM evalHCsystemhours"": ""0.1557166666666667"",; ""CHM evalHCwallclockhours"": ""42.53388888888889"",; ""CHM evalHCwallclockmax"": ""2.7197444444444443"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e372bd14-cd1f-4563-8d8a-abf6b6ca7",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069381494:10472,monitor,monitoring,10472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069381494,1,['monitor'],['monitoring']
Energy Efficiency,"plotypes in the sample contains the site-specific alternate allele at the site (ie. excluding `*` which represents variation that beings upstream of the current variant. NB that this results in cases where `PGT` is not the same as the phased `GT` field. For example, in the case of a spanned SNP site with REF allele `A` and alt alleles `C` and `*`, `GT` may be set to `1|2` to represent the spanned SNP, while PGT would be set to `1|0` to represent the fact that it is the first haplotype in the pair of phased haplotypes that contains the site-specific alt allele (in this case `C`). If reviewers agree with this interpretation, I think we should create a new ticket to clarify documentation around the PGT and PID tags to reflect it. . After discussions with @ldgauthier I believe that there may be downstream issues in preserving phasing after passing gVCFs through CombineGVCFs, GenomicsDBImport, and/or GenotypeGVCFs, especially if the gVCFs are emitted without GT fields. In that case, `GenotypeGVCFs` should probably have logic to reconstruct the phased genotype for each sample based on the PGT and PID tags when possible. I will create a new ticket describing the issue. There still may be cases where HaplotypeCaller does not emit phasing information for spanning deletions due to the presence of extra haplotypes that contradict diploid phasing, as in https://github.com/broadinstitute/gatk/issues/6845. A fix to that issue would likely reduce the number of those cases. The integration test result file `src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/withOxoGReadCounts.vcf` does not have any changes that have to do with this PR -- it was automatically updated by GenotypeGVCFsIntegrationTest, which included some new jitter in QUAL scores as described in https://github.com/broadinstitute/gatk/pull/6859, but never got checked in with that PR. I figure that it's best to update it now so that the results reflect the current expected behavior of the tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6937:1818,reduce,reduce,1818,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6937,1,['reduce'],['reduce']
Energy Efficiency,"point: Registering block manager com2:38568 with 530.0 MB RAM, BlockManagerId(1, com2, 38568); 17/10/11 14:19:25 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:38568 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:26 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:38568 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4180 ms on com2 (executor 1) (1/1); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.951 s; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: running: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: failed: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.1 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.3 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:34044 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244) (first 15 tasks are for partitions Vector(0)); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks; 17/10/11 14:19:27 INFO scheduler.TaskSetMa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:14134,schedul,scheduler,14134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"port 44818.; 17/10/13 18:11:42 INFO netty.NettyBlockTransferService: Server created on 10.131.101.159:44818; 17/10/13 18:11:42 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 17/10/13 18:11:42 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.131.101.159:44818 with 366.3 MB RAM, BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO storage.BlockManager: external shuffle service port = 7337; 17/10/13 18:11:42 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@544300a6{/metrics/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:42 INFO scheduler.EventLoggingListener: Logging events to hdfs://mg:8020/user/spark/spark2ApplicationHistory/application_1507856833944_0003; 17/10/13 18:11:42 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances; 17/10/13 18:11:43 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 17/10/13 18:11:43 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 286.0 KB, free 366.0 MB); 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 26.0 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.131.101.159:44818 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:14464,schedul,scheduler,14464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['schedul'],['scheduler']
Energy Efficiency,"pr&el=h1) Report; > Merging [#2548](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c8ede6ef810a3d9a05c7deb8052e27ca724ce8ba?src=pr&el=desc) will **increase** coverage by `0.003%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2548 +/- ##; ===============================================; + Coverage 76.279% 76.282% +0.003% ; - Complexity 10891 10893 +2 ; ===============================================; Files 752 752 ; Lines 39590 39590 ; Branches 6925 6925 ; ===============================================; + Hits 30199 30200 +1 ; Misses 6768 6768 ; + Partials 2623 2622 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9BbGxlbGVTdWJzZXR0aW5nVXRpbHMuamF2YQ==) | `85.185% <Ã¸> (Ã¸)` | `39 <0> (Ã¸)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=footer). Last update [c8ede6e...b79b75d](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2548#issuecomment-290305475:1792,Power,Powered,1792,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2548#issuecomment-290305475,1,['Power'],['Powered']
Energy Efficiency,"previously jbwaIntegrationTest was being skipped if running on ppc; this was a hold over from when we didn't yet have a ppc library for it; now it will always run and fail if it's on an unsupported system; it should be compatible with most linux, osx, and power systems now though",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2118:256,power,power,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2118,1,['power'],['power']
Energy Efficiency,ps://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F416C69676E6D656E74526567696F6E2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢ 60% | [...ute/hellbender/tools/spark/sv/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F4368696D65726963416C69676E6D656E742E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 72% | *new* [...llbender/tools/spark/sv/AssemblyAlignmentParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F417373656D626C79416C69676E6D656E745061727365722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [.../hellbender/tools/spark/sv/SVVariantCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F535656617269616E7443616C6C65725574696C732E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...tute/hellbender/tools/spark/sv/BreakpointAllele.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F427265616B706F696E74416C6C656C652E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...institute/hellbender/tools/spark/sv/SVConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F5356436F6E7374616E74732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cb48a6e...073dabb](https://codecov.io/gh/broadinstitute/gatk/compare/cb48a6e4d524355c8ed312a622cbfae69f8ce26b...073dabbdf1e44a0c76e6c64adcc7570c9f310cc0?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2285#issuecomment-263705162:3607,Power,Powered,3607,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2285#issuecomment-263705162,1,['Power'],['Powered']
Energy Efficiency,"ption in task 0.0 in stage 1.0 (TID 1); java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 16/11/16 23:25:11 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-0,5,main]; java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:12809,schedul,scheduler,12809,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,pushed new version; once tests are green I can squash and rebase.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2013#issuecomment-236696586:35,green,green,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2013#issuecomment-236696586,1,['green'],['green']
Energy Efficiency,"putStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). 11:00:53.977 INFO DAGScheduler - Job 1 failed: runJob at SparkHadoopWriter.scala:83, took 3.799268 s; 11:00:53.979 ERROR SparkHadoopWriter - Aborting job job_202408111100502620487673658411251_0021.; org.apache.spark.SparkException: Job aborted due to stage failure: Task serialization failed: java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; at java.base/jdk.internal.util.ArraysSupport.hugeLength(ArraysSupport.java:649); at java.base/jdk.internal.util.ArraysSupport.newLength(ArraysSupport.java:642); at java.base/java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:100); at java.base/java.io.ByteArrayOutputStream.write(ByteArrayOu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:8153,schedul,scheduler,8153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,putStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:12477,schedul,scheduler,12477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,putStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at or,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:31196,schedul,scheduler,31196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,putStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 11:00:54.334 INFO ShutdownHookManager - Shutdown hook called; 11:00:54.335 INFO ShutdownHookManager - Deleting directory /raid/tmp/d6/c66ba827e22dbc38625af1cbc85adc/tmp/spark-f9c7c336-4e98-4fcc-855b-ba8a5a29e074; ```. The first lines of the log file:; ```; vm.max_map_count = 2147483642; Using GATK jar /Public/Everythings/misc/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -XX:+UnlockDiagnosticVMOptions -XX:GCLockerRetryAllocationCount=96 -XX:+UseNUMA -XX:+UseZGC -Xmx1794G -jar /Public/Everythings/misc/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar SortSamSpark --input HG002-NA24385-GM24385.bam -,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:37067,schedul,scheduler,37067,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"q06.scc.bu.edu:39736 with 25.4 GB RAM, BlockManagerId(5, scc-q06.scc.bu.edu, 39736, None); 18/03/07 20:31:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.193:34094) with ID 1; 18/03/07 20:31:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q09.scc.bu.edu:38854 with 25.4 GB RAM, BlockManagerId(1, scc-q09.scc.bu.edu, 38854, None); 18/03/07 20:31:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.187:33854) with ID 4; 18/03/07 20:31:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.198:41138) with ID 7; 18/03/07 20:31:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q03.scc.bu.edu:35635 with 25.4 GB RAM, BlockManagerId(4, scc-q03.scc.bu.edu, 35635, None); 18/03/07 20:31:49 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 18/03/07 20:31:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q14.scc.bu.edu:36726 with 25.4 GB RAM, BlockManagerId(7, scc-q14.scc.bu.edu, 36726, None); 18/03/07 20:31:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.195:47862) with ID 6; 18/03/07 20:31:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q11.scc.bu.edu:46002 with 25.4 GB RAM, BlockManagerId(6, scc-q11.scc.bu.edu, 46002, None); 18/03/07 20:31:49 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 246.6 KB, free 8.4 GB); 18/03/07 20:31:50 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.3 KB, free 8.4 GB); 18/03/07 20:31:50 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:41567 (size: 25.3 KB, free: 8.4 GB); 18/03/07 20:31:50 INFO sp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:3818,Schedul,SchedulerBackend,3818,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,2,"['Schedul', 'schedul']","['SchedulerBackend', 'scheduling']"
Energy Efficiency,"quence id 1, start 2485550, span 40026, expected MD5 106b97c463c8a19ce0f92bbd488ac81d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:13:58 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0, scc-q16.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 9999, span 21707, expected MD5 059b07ed1e0589040ada9b236b88b509; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:5625,schedul,scheduler,5625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,r$$anonfun$4.apply(SparkHadoopWriter.scala:132); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); at org.apache.spark.internal.io.SparkHadoopWriter$.write,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:17054,schedul,scheduler,17054,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,r$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)** ; **at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)** ; **at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)** ; **at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)** ; **at scala.Option.foreach(Option.scala:257)** ; **at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)** ; **at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)** ; **at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)** ; **at org.apache.spark.rdd.RDD.count(RDD.scala:1168)** ; **at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455)** ; **at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark.runTool(PathSeqPipelineSpark.java:245)** ; **at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:533)** ; **at org.broadinstitute.hellbender.engine.spark.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:46905,schedul,scheduler,46905,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,"r&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21hZk91dHB1dC9NYWZPdXRwdXRSZW5kZXJlckNvbnN0YW50cy5qYXZh) | `99.01% <100%> (+0.04%)` | `1 <0> (Ã¸)` | :arrow_down: |; | [...der/tools/funcotator/metadata/TumorNormalPair.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21ldGFkYXRhL1R1bW9yTm9ybWFsUGFpci5qYXZh) | `63.63% <63.63%> (Ã¸)` | `5 <5> (?)` | |; | [...cotator/mafOutput/CustomMafFuncotationCreator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21hZk91dHB1dC9DdXN0b21NYWZGdW5jb3RhdGlvbkNyZWF0b3IuamF2YQ==) | `90% <90%> (Ã¸)` | `17 <17> (?)` | |; | [...tools/funcotator/metadata/SamplePairExtractor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21ldGFkYXRhL1NhbXBsZVBhaXJFeHRyYWN0b3IuamF2YQ==) | `95% <95%> (Ã¸)` | `9 <9> (?)` | |; | [...titute/hellbender/tools/funcotator/Funcotator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3IuamF2YQ==) | `86.18% <0%> (+0.65%)` | `43% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4917?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4917?src=pr&el=footer). Last update [9d8fdac...0e8a045](https://codecov.io/gh/broadinstitute/gatk/pull/4917?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4917#issuecomment-399122987:3627,Power,Powered,3627,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4917#issuecomment-399122987,1,['Power'],['Powered']
Energy Efficiency,"r&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvTG9jdXNXYWxrZXJTcGFyay5qYXZh) | `82.5% <83.33%> (+4.72%)` | `12 <2> (Ã¸)` | :arrow_down: |; | [...itute/hellbender/engine/spark/ReadWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvUmVhZFdhbGtlclNwYXJrLmphdmE=) | `72.22% <85.71%> (-5.2%)` | `8 <3> (-2)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (Ã¸)` | `2% <0%> (Ã¸)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `72.51% <0%> (+0.94%)` | `38% <0%> (+1%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `80% <0%> (+30%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5221?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5221?src=pr&el=footer). Last update [2ee7df3...e40ce5e](https://codecov.io/gh/broadinstitute/gatk/pull/5221?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5221#issuecomment-426308250:4497,Power,Powered,4497,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5221#issuecomment-426308250,1,['Power'],['Powered']
Energy Efficiency,r(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:68); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.uti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1719,Reduce,ReduceOps,1719,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,r(RDD.scala:270); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41); at org.apache.spark.scheduler.Task.run(Task.scala:89); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.io.IOException: bwa_idx_load failed; at com.github.lindenb.jbwa.jni.BwaIndex._open(Native Method); at com.github.lindenb.jbwa.jni.BwaIndex.<init>(BwaIndex.java:216); at org.broadinstitute.hellbender.tools.spark.bwa.BwaSparkEngine.lambda$null$1(BwaSparkEngine.java:109); ... 32 more,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2171:6953,schedul,scheduler,6953,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2171,3,['schedul'],['scheduler']
Energy Efficiency,"r.&lt;init&gt;(TribbleIndexedFeatureReader.java:127); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:120); at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:350); ... 14 more; Caused by: java.lang.IllegalStateException: Duplicate key 0; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1254); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec.readActualHeader(XsvLocatableTableCodec.java:341); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec.readActualHeader(XsvLocatableTableCodec.java:64); at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:79); at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:37); at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:261); ... 18 more; ```. java version:; ```; java -version; openjdk version ""1.8.0_222""; OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1~deb9u1-b10); OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode); ```; I added the cadd folder into data source folder like the structure ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223:3304,Reduce,ReduceOps,3304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,r.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:31687,adapt,adapted,31687,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['adapt'],['adapted']
Energy Efficiency,r.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3679:4814,schedul,scheduler,4814,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679,1,['schedul'],['scheduler']
Energy Efficiency,r.VCFWriter.add(VCFWriter.java:242); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:93); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:56); at org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil.write(SparkHadoopWriter.scala:358); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:132); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:16626,schedul,scheduler,16626,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,r.java:185); at org.broadinstitute.hellbender.utils.GenomeLocParser.createGenomeLoc(GenomeLocParser.java:169); at org.broadinstitute.hellbender.utils.GenomeLocParser.createGenomeLoc(GenomeLocParser.java:150); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager$SplitRead.setRead(OverhangFixingManager.java:402); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager$SplitRead.<init>(OverhangFixingManager.java:396); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.getSplitRead(OverhangFixingManager.java:467); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Collections$2.tryAdvance(Collections.java:4717); at java.util.Collections$2.forEachRemaining(Collections.java:4725); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.addReadGroup(OverhangFixingManager.java:207); at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.splitNCigarRead(SplitNCigarReads.java:259); at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.firstPassApply(SplitNCigarReads.java:180); at org.broadinstitute.hellbender.engine.TwoPassReadWalker.lambda$traverseReads$0(TwoPassReadWalker.java:62); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5293:3400,Reduce,ReduceOps,3400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5293,1,['Reduce'],['ReduceOps']
Energy Efficiency,r.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1862); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1875); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1952); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1144); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIH,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:34191,schedul,scheduler,34191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,r: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:33 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2685 KB). The maximum recommended task size is 100 KB.; 00:47:39.417 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 00:47:39 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:47:47.083 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 00:47:48.135 INFO StructuralVariationDiscoveryPipelineSpark - 23702 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 00:47:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:57 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:48:04 WARN org.apache.spark.scheduler.TaskSetManager: Stage 34 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:48:13.094 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 15964 variants.; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 6920; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 264; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 268; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4680; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 487; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - INS: 3345; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - INV: 0; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 00:48:13.107 INFO Structu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:2076,schedul,scheduler,2076,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,r: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:18 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2599 KB). The maximum recommended task size is 100 KB.; 02:20:24.460 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 02:20:24 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:32.040 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 02:20:33.079 INFO StructuralVariationDiscoveryPipelineSpark - 23841 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 02:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:42 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 34 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:58.973 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 15659 variants.; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 6920; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 264; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 268; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5019; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1793; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1395; 02:20:58.992 INFO StructuralVariationDiscoveryPipelineSpark - INV: 0; 02:20:58.992 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 02:20:58.992 INFO Struct,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:5942,schedul,scheduler,5942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,r: Stage 20 contains a task of very large size (2599 KB). The maximum recommended task size is 100 KB.; 02:20:24.460 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 02:20:24 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:32.040 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 02:20:33.079 INFO StructuralVariationDiscoveryPipelineSpark - 23841 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 02:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:42 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 34 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:58.973 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 15659 variants.; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 6920; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 264; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 268; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5019; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1793; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1395; 02:20:58.992 INFO StructuralVariationDiscoveryPipelineSpark - INV: 0; 02:20:58.992 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 02:20:58.992 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 02:21:46.603 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 1334 variants.; 02:21:46.604 INFO StructuralVari,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:6109,schedul,scheduler,6109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,r: Stage 20 contains a task of very large size (2685 KB). The maximum recommended task size is 100 KB.; 00:47:39.417 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 00:47:39 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:47:47.083 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 00:47:48.135 INFO StructuralVariationDiscoveryPipelineSpark - 23702 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 00:47:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:57 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:48:04 WARN org.apache.spark.scheduler.TaskSetManager: Stage 34 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:48:13.094 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 15964 variants.; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 6920; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 264; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 268; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4680; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 487; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - INS: 3345; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - INV: 0; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 00:48:47.955 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 1334 variants.; 00:48:47.956 INFO StructuralVaria,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:2243,schedul,scheduler,2243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,"r_000002_0' to file:/dev/shm/chr4_GL000008v2_random.g.vcf.gz.parts; 21/04/13 07:32:25 INFO SparkHadoopMapRedUtil: attempt_20210413073224_0026_r_000002_0: Committed; 21/04/13 07:32:25 INFO Executor: Finished task 2.0 in stage 5.0 (TID 107). 848 bytes result sent to driver; 21/04/13 07:32:25 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 107) in 279 ms on localhost (executor driver) (2/3); 21/04/13 07:32:25 WARN TaskSetManager: Lost task 0.0 in stage 5.0 (TID 105, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Sequence [VC HC @ chr4_GL000008v2_random:7168-7691 Q. of type=SYMBOLIC alleles=[T*, <NON_REF>] attr={END=7691} GT=[[NA12878 T*/T* GQ 0 DP 0 PL 0,0,0 {MIN_DP=0}]] filters= added out of order currentReferenceIndex: 25, referenceIndex:37; at htsjdk.tribble.index.tabix.AllRefsTabixIndexCreator.addFeature(AllRefsTabixIndexCreator.java:79); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:203); at htsjdk.variant.variantconte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:8955,schedul,scheduler,8955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,"ra commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-260494000). @vruano Are you currently working on this? Or can this be moved into the GATK4 repo for future work? . ---. @vruano commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-260503444). Working on it on GATK3 but I could merge it into GATK4 whenever is ready if you prefer. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-260509332). Ok great, totally fine to do in 3 but please do port to 4 when it's ready. Do you have an order of magnitude sense of when it might be ready? Meaning days/weeks/months (for release scheduling purposes). ---. @vruano commented on [Fri Mar 10 2017](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-285721454). In the last methods meeting I presented the results of our first effort to improve accuracy calling in STR. As far as unfiltered single and trio calls are concerned the recommendation is to apply the new model with PCR+ data. However, for PCR- dataset one either can choose not apply any correction or to apply the new model train on PCR- data... the latter seems to have slightly F1 values however for the sake of simplicity it might just make sense no to apply any correct; either way is good. The presentation I gave can be found [here](https://drive.google.com/open?id=0Bzt9p0vCNxlHWlZVUHZfdXR5MTg). ---. @vruano commented on [Fri Mar 10 2017](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-285722791). It seems that at some point Planatir will take a look and see whether it improves calls once filtered with VQSR. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-287822174). Is there a PR associated with this issue? Will there be a new feature to release? Need to know for release scheduling purposes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2519:2630,schedul,scheduling,2630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2519,1,['schedul'],['scheduling']
Energy Efficiency,"rage Diff @@; ## master #5539 +/- ##; ============================================; - Coverage 87.06% 87.06% -0.01% ; + Complexity 31324 31322 -2 ; ============================================; Files 1921 1921 ; Lines 144579 144579 ; Branches 15949 15949 ; ============================================; - Hits 125884 125880 -4 ; - Misses 12902 12906 +4 ; Partials 5793 5793; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (-0.61%)` | `42% <0%> (Ã¸)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (Ã¸)` | `2% <0%> (Ã¸)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=footer). Last update [10aa8c7...3aec594](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825:2315,Power,Powered,2315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825,1,['Power'],['Powered']
Energy Efficiency,"rage by `0.008%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2468 +/- ##; ===============================================; + Coverage 76.268% 76.275% +0.008% ; - Complexity 10876 10879 +3 ; ===============================================; Files 752 752 ; Lines 39583 39583 ; Branches 6922 6922 ; ===============================================; + Hits 30189 30192 +3 ; + Misses 6774 6772 -2 ; + Partials 2620 2619 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2468?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...4bebcdf005e9191206558f09e14f59d87324f1c8?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...4bebcdf005e9191206558f09e14f59d87324f1c8?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (Ã¸)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2468?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2468?src=pr&el=footer). Last update [c62914a...4bebcdf](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...4bebcdf005e9191206558f09e14f59d87324f1c8?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2468#issuecomment-288779580:1946,Power,Powered,1946,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2468#issuecomment-288779580,1,['Power'],['Powered']
Energy Efficiency,"rage is `100%`. ```diff; @@ Coverage Diff @@; ## master #2427 +/- ##; ===============================================; + Coverage 76.218% 76.221% +0.003% ; - Complexity 10819 10821 +2 ; ===============================================; Files 750 750 ; Lines 39420 39421 +1 ; Branches 6883 6883 ; ===============================================; + Hits 30045 30047 +2 ; Misses 6757 6757 ; + Partials 2618 2617 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2427?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...tute/hellbender/tools/spark/sv/ReadClassifier.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...fc95362d5a29cc5738032c43aa922b491b6accf5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkQ2xhc3NpZmllci5qYXZh) | `83.607% <100%> (+0.273%)` | `31 <4> (+1)` | :white_check_mark: |; | [.../hellbender/tools/spark/sv/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...fc95362d5a29cc5738032c43aa922b491b6accf5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `83.756% <0%> (+0.508%)` | `24% <0%> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2427?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2427?src=pr&el=footer). Last update [fcd103c...fc95362](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...fc95362d5a29cc5738032c43aa922b491b6accf5?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2427#issuecomment-282851101:1980,Power,Powered,1980,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2427#issuecomment-282851101,1,['Power'],['Powered']
Energy Efficiency,rapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.DoublePipeline.toArray(DoublePipeline.java:506); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.calculateLog10GP(GenotypeCopyNumberTriStateSegments.java:198); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.lambda$composeVariantContext$0(GenotypeCopyNumberTriStateSegments.java:125); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.composeVariantContext(GenotypeCopyNumberTriStateSegments.java:141); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.makeCalls(GenotypeCopyNumberTriStateSegments.java:104); at org.broadinstitute.hellbender.tools.exome.germlinehmm.CopyNumberTriStateSegmentCaller.doWork(CopyNumberTriStateSegmentCaller.java:121); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:108); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:166); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:185). ```. You can see all input files here:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2898:1971,Reduce,ReduceOps,1971,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2898,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,rce.java:324); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:304); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:256); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:230); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:214); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855:3039,Reduce,ReduceOps,3039,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855,1,['Reduce'],['ReduceOps']
Energy Efficiency,rce.java:383); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:335); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:222); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6578:3995,Reduce,ReduceOps,3995,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6578,1,['Reduce'],['ReduceOps']
Energy Efficiency,readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$transformToDuplicateNames$4992d4e$1(MarkDuplicatesSparkUtils.java:140); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:199); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.UnsupportedOperationException; 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.ImmutableMap.put(ImmutableMap.java:326); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:162); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:246); 	at org.apache.spark.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4775:1231,schedul,scheduler,1231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4775,1,['schedul'],['scheduler']
Energy Efficiency,"readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	... 18 more; 19/02/18 16:58:29 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 16:58:29.970 INFO PrintVariantsSpark - Shutting down engine; [February 18, 2019 4:58:29 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.34 minutes.; Runtime.totalMemory()=1106771968; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException; Serialization trace:; genotypes (htsjdk.variant.variantcontext.VariantContext); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821); 	at org.apache.spark.scheduler.DAGSchedulerEventProces",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:9517,schedul,scheduler,9517,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:330); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); 	at java.io.ObjectInputStream.readNonP,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:6226,schedul,scheduler,6226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['schedul'],['scheduler']
Energy Efficiency,readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:362); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.invalidateSampleOrdering(LazyGenotypesContext.java:205); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:353); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:46); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:134); 	at com.esotericsoftware.kryo.se,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:7415,schedul,scheduler,7415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,readOrdinaryObject(ObjectInputStream.java:1801); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1993); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1918); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1993); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1918); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:371); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:69); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:95); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:58); at org.apache.spark.scheduler.Task.run(Task.scala:70); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.reflect.InvocationTargetException; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at java.lang.invoke.SerializedLambda.readResolve(SerializedLambda.java:230); at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Meth,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1315:2342,schedul,scheduler,2342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1315,1,['schedul'],['scheduler']
Energy Efficiency,"reads=32 -Xmx128g \; -jar /gpfs/software/genomics/GATK/3.7/base/GenomeAnalysisTK.jar -T HaplotypeCaller \; -nct 8 -pairHMM VECTOR_LOGLESS_CACHING \ ; -R /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa \; -I NA12892.realigned.recal.bam -\ ; -emitRefConfidence GVCF \; --variant_index_type LINEAR \; --variant_index_parameter 128000 \; --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz \; -o NA12892.raw.snps.indels.g.vcf _. **This execution time for GATK 3.7 is: 18 Hours, 12 min**. I don't know, how to use multithreads (e.g. -nct) for GATK 4 version to reduce the execution time on the single node. Because, we have 32 cores per node with 512GB memory available for benchmarking. To parallelize the GATK 4 workload, I used the Spark version also. . I used **GATK 4 Beta2 Spark job on the cluster of 32 nodes** (32 nodes x 32 cores, totaling 1024 cores). The execution time is almost same as GATK 4 Beta2 ( 50 Hours, 21 min). Please help me, how to reduce the execution time for GATK 4 Beta2 HaplotypeCaller? . Please see this below Spark logs:. + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//bin/spark-submit --master spark://nsnode11:6311 --driver-java-options -Dsamjdk.use_async_io_read_samtools=false,-Dsamjdk.use_async_io_write_samtools=true,-Dsamjdk.use_async_io_write_tribble=false,-Dsamjdk.compression_level=1 --conf spark.io.compression.codec=snappy --conf spark.yarn.executor.memoryOverhead=6000 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.userClassPathFirst=true --conf spark.driver.maxResultSize=0 --conf spark.executor.cores=1024 --conf spark.reducer.maxSizeInFlight=100m --conf spark.shuffle.file.buffer=512k --conf spark.akka.frameSize=512 --conf spark.akka.threads=10 --conf spark.executor.memory=50g --conf spark.driver.memory=150g --conf spark.local.dir=/gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2Spark/1024cores/tmp --class org.broadinstitute.hellbender.Main /gpfs/software/genomics/GATK/4b.2/gatk/build/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3631:1870,reduce,reduce,1870,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631,1,['reduce'],['reduce']
Energy Efficiency,reamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1038); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:969); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:760); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230:3317,schedul,scheduler,3317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230,2,['schedul'],['scheduler']
Energy Efficiency,rebase+squash. Merge pending green tests.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/798#issuecomment-137863160:29,green,green,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/798#issuecomment-137863160,1,['green'],['green']
Energy Efficiency,reduce,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3272:0,reduce,reduce,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3272,1,['reduce'],['reduce']
Energy Efficiency,reduce memory allocation at calls using varargs on applyBQSR:. ```; real 4m11.298s; user 4m17.046s; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1056#issuecomment-152916828:0,reduce,reduce,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1056#issuecomment-152916828,1,['reduce'],['reduce']
Energy Efficiency,reduce non-deterministic WDL test failures,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4129:0,reduce,reduce,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4129,1,['reduce'],['reduce']
Energy Efficiency,reduce number of iterations in SplitNCigarReadsTests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/531:0,reduce,reduce,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/531,1,['reduce'],['reduce']
Energy Efficiency,reduced memory consumption: identified by profiling HC. ; - added a bunch of tests while I was there. note: the equals/hashcode changes are just for clean code - no perf improvements. @lbergelson can you have a look?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1892:0,reduce,reduced,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1892,2,"['consumption', 'reduce']","['consumption', 'reduced']"
Energy Efficiency,ree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...bender/tools/spark/pathseq/PathSeqFilterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFGaWx0ZXJTcGFyay5qYXZh) | `70.968% <Ã¸> (Ã¸)` | `7 <0> (Ã¸)` | :arrow_down: |; | [...itute/hellbender/tools/spark/pathseq/PSFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyLmphdmE=) | `92.617% <100%> (+0.531%)` | `33 <1> (+1)` | :arrow_up: |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <100%> (+1.429%)` | `2 <0> (Ã¸)` | :arrow_down: |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <92.857%> (Ã¸)` | `12 <12> (?)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <94.286%> (Ã¸)` | `11 <11> (?)` | |; | [...nstitute/hellbender/utils/clipping/ClippingOp.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jbGlwcGluZy9DbGlwcGluZ09wLmphdmE=) | `84.365% <0%> (+1.629%)` | `91% <0%> (+2%)` | :arrow_up: |; | [...stitute/hellbender/utils/clipping/ReadClipper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310:1867,Adapt,AdapterTrimTransformer,1867,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310,1,['Adapt'],['AdapterTrimTransformer']
Energy Efficiency,rg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); ERROR: (gcloud.dataproc.jobs.submit.spark) Job [3bae2377-4ae0-4a9d-af6a-c94cd1fcebc1] entered state [ERROR] while waiting for [DONE].; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:7173,schedul,scheduler,7173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,2,['schedul'],['scheduler']
Energy Efficiency,rg.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.lang.IllegalArgumentException: java.lang.IllegalArgumentException: A reference must be supplied that includes the reference sequence for chr12).; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at java.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:593); 	at java.util.concurrent.ForkJoinTask.reportException(ForkJoinTask.java:677); 	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:735); 	at java.util.stream.ReduceOps$ReduceOp.evaluateParallel(ReduceOps.java:714); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233); 	at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:546); 	at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.lambda$collectCaseStatsParallel$13(CalibrateDragstrModel.java:489); 	at java.util.concurrent.ForkJoinTask$AdaptedCallable.exec(ForkJoinTask.java:1424); 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289); 	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056); 	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692); 	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157); Caused by: java.lang.IllegalArgumentException: A reference must be supplied that includes the reference sequence for chr12).; 	at htsjdk.samtools.cram.ref.CRAMLazyReferenceSource.getReferenceBases(CRAMLazyReferenceSource.java:41); 	at htsjdk.samtools.cram.build.CRAMReferenceRegion.getReferenceBases(CRAMReferenceRegion.java:74); 	at htsjdk.samtools.cram.structure.Slice.normalizeCRAMRecords(Slice.java:450); 	at htsjdk.samtools.cram.structure.Contai,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7060:2930,reduce,reduce,2930,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7060,1,['reduce'],['reduce']
Energy Efficiency,"rg.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$26/353370312.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:242); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). 17/10/11 14:19:28 INFO scheduler.TaskSetManager: Starting task 0.1 in stage 1.0 (TID 2, com2, executor 1, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Disabling executor 1.; 17/10/11 14:19:28 INFO scheduler.DAGScheduler: Executor lost: 1 (epoch 1); 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.; 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, com2, 38568); 17/10/11 14:19:28 INFO storage.BlockManagerMaster: Removed 1 successfully in removeExecutor; 17/10/11 14:19:28 WARN cluster.YarnSchedulerBackend$YarnSched",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:16706,schedul,scheduler,16706,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"rg.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). 16/11/16 23:25:11 ERROR TaskSetManager: Task 0 in stage 1.0 failed 1 times; aborting job; 16/11/16 23:25:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 16/11/16 23:25:11 INFO TaskSchedulerImpl: Cancelling stage 1; 16/11/16 23:25:11 INFO DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:202) failed in 0.276 s; 16/11/16 23:25:11 INFO DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:202, took 1.029776 s; 16/11/16 23:25:11 INFO SparkContext: SparkContext already stopped.; [November 16, 2016 11:25:11 PM AST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elap",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:15870,schedul,scheduler,15870,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,rg.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGSchedu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:18132,schedul,scheduler,18132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,"rg.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 16/11/16 23:25:11 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-0,5,main]; java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:12881,schedul,scheduler,12881,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,"rg.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 16/11/16 23:25:11 INFO SparkContext: Invoking stop() from shutdown hook; 16/11/16 23:25:11 WARN TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1, localhost): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.sca",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:14361,schedul,scheduler,14361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,rg.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 16/11/16 23:25:11 INFO SparkUI: Stopped Spark web UI at http://172.32.65.22:4040; 16/11/16 23:25:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 16/11/16 23:25:11 INFO MemoryStore: MemoryStore cleared; 16/11/16 23:25:11 INFO BlockManager: BlockManager stopped; 16/11/16 23:25:11 INFO BlockManagerMaster: BlockManagerMaster stopped; 16/11/16 23:25:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 16/11/16 23:25:11 INFO SparkContext: Successfully stopped SparkContext; 16/11/16 23:25:11 INFO ShutdownHookManager: Shutdown hook called; 16/11/16 23:25:11 INFO ShutdownHookManager: Deleting directory /g,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:24518,schedul,scheduler,24518,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,rg.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.34 minutes.; Runtime.totalMemory()=1106771968; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException; Serialization trace:; genotypes (htsjdk.variant.variantcontext.VariantContext); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkConte,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:9869,schedul,scheduler,9869,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,rg.broadinstitute.hellbender.tools.walkers.mutect.filtering.DuplicatedAltReadFilter.areAllelesArtifacts(DuplicatedAltReadFilter.java:26) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.HardAlleleFilter.calculateErrorProbabilityForAlleles(HardAlleleFilter.java:16) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2AlleleFilter.errorProbabilities(Mutect2AlleleFilter.java:86) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$0(ErrorProbabilities.java:27) ; ; at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321) ; ; at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:25) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:138) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:154) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; ; at java.util.It,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:8055,Reduce,ReduceOps,8055,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['Reduce'],['ReduceOps']
Energy Efficiency,rging=ALL interval_padding=0 reference_sequence=human_g1k_v37.fasta nonDeterministicRandomSeed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=false never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=dbsnp_138.b37.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/home/unix/droazen/bundle_snippets/dbsnp_138.b37.20.21.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false keepOriginalDP=false mendelianViolation=false invertMendelianViolation=false mendelianViolationQualThreshold=0.0 selec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2269:1699,monitor,monitorThreadEfficiency,1699,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2269,1,['monitor'],['monitorThreadEfficiency']
Energy Efficiency,rializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:330); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); 	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1826); 	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:6405,schedul,scheduler,6405,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['schedul'],['scheduler']
Energy Efficiency,rializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:362); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.invalidateSampleOrdering(LazyGenotypesContext.java:205); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:353); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:46); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:134); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:40); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectFi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:7594,schedul,scheduler,7594,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,"rializer.read(CollectionSerializer.java:40); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	... 18 more; 19/02/18 16:58:29 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 16:58:29.970 INFO PrintVariantsSpark - Shutting down engine; [February 18, 2019 4:58:29 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.34 minutes.; Runtime.totalMemory()=1106771968; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException; Serialization trace:; genotypes (htsjdk.variant.variantcontext.VariantContext); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:9418,schedul,scheduler,9418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,"rintVariantsSpark - Done initializing engine; 17/11/15 19:43:11 INFO org.spark_project.jetty.util.log: Logging initialized @4976ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.Server: Started @5092ms; 17/11/15 19:43:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:12 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/15 19:43:13 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-8875b999-b609-4a3f-86ea-973b929fe662-m/10.240.0.18:8032; 17/11/15 19:43:17 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1510774921124_0001; 17/11/15 19:43:28 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 17/11/15 19:43:35 ERROR org.apache.spark.scheduler.TaskResultGetter: Exception while getting task result; com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:65); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:4563,schedul,scheduler,4563,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['schedul'],['scheduler']
Energy Efficiency,rk-master local[28] --conf spark.local.dir=/datatmp/ -I ./A.sort.bam -O ./A.sort.bam.Mdup.bam -M ./A.sort.bam.Md.metrics.txt --tmp-dir /datatmp/ --conf spark.network.timeout=200h --conf spark.executor.heartbeatInterval=100h --read-name-regex null`; It reports the error below.; `20/12/15 11:43:00 ERROR Executor: Exception in task 15.0 in stage 7.0 (TID 12538); java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$handleFragments$12(MarkDuplicatesSparkUtils.java:395); at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(Uns,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7001:1331,Reduce,ReduceOps,1331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001,1,['Reduce'],['ReduceOps']
Energy Efficiency,"rk.api.java.JavaRDDLike.$anonfun$mapPartitions$1(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858); 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:56); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:56); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:56); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93); 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166); 	at org.apache.spark.scheduler.Task.run(Task.scala:141); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620); 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64); 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:93); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635); 	at java.base/java.lang.Thread.run(Thread.java:833); ``` . #### Steps to reproduce; Run HaplotypeCallerSpark multiple times, it had a chance to fail.; Looks like the method ensureCapacity of GenotypesCache is not synchronized. So when multiple task threads run into this method, the new added cache is not fully initialized. #### Expected behavior; spark tasks success. ##",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8961:4028,schedul,scheduler,4028,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8961,1,['schedul'],['scheduler']
Energy Efficiency,rk.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$transformToDuplicateNames$4992d4e$1(MarkDuplicatesSparkUtils.java:140); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:199); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.UnsupportedOperationException; 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.ImmutableMap.put(ImmutableMap.java:326); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:162); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:246); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$8.apply(TorrentBroadcast.scala:293); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4775:1391,schedul,scheduler,1391,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4775,1,['schedul'],['scheduler']
Energy Efficiency,rk.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); 18/10/17 19:23:59 ERROR Executor: Exception in task 518.0 in stage 0.0 (TID 518); java.io.FileNotFoundException: /home/data/WGS/F002/F002.sort.bam (Too many open files); 	at java.io.FileInputStream.open0(Native Method); 	at java.io.FileInputStream.open(FileInputStream.java:195); 	at java.io.FileInputStream.<init>(FileInputStream.java:138); 	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.<init>(RawLocalFileSystem.java:106); 	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:20,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:4265,schedul,scheduler,4265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,1,['schedul'],['scheduler']
Energy Efficiency,rk.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111); at org.apache.spark.rdd.RDD.withScope(RDD.scala:316); at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:381); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:381); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111); at org.apache.spark.rdd.RDD.withScope(RDD.scala:316); at org.apache.spark.rdd.PairRDDFunctions.countByKey(PairRDDFunctions.scala:380); at org.apache.spark.rdd.RDD$$anonfun$countByVal,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2113:5473,reduce,reduceByKey,5473,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2113,1,['reduce'],['reduceByKey']
Energy Efficiency,rk.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); at scala.Option.getOrElse(Option.scala:121); at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); at scala.Option.getOrElse(Option.scala:121); at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); at scala.Option.getOrElse(Option.scala:121); at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:328); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:328); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:327); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:372); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:372); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.PairRDDFunctions.countByKey(PairRDDFunctions.scala:371); at org.apache.spark.rdd.RDD$$anonfun$countByVal,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3360:10162,reduce,reduceByKey,10162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360,1,['reduce'],['reduceByKey']
Energy Efficiency,rk.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3679:3890,schedul,scheduler,3890,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679,1,['schedul'],['scheduler']
Energy Efficiency,rk.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Generated by:. java -Xmx16g -jar /dsde/working/slee/CNV-1.5_HCC1143/resources/gatk-package-4.beta.5-97-g066c0b4-SNAPSHOT-local.jar SparkGenomeReadCounts \; --input /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-CollectReadCountsNormal/inputs/seq/picard_aggregation/G15511/HCC1143_BL/current/HCC1143_BL.bam \; --reference /dsde/working/slee/CNV-1.5_HCC1143/run/cromwell-executions/CNVSomaticPairWorkflow/859bdb60-ba9c-4cf8-98c7-0fb9847a7ee0/call-CollectReadCountsNormal/inputs/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3679:11721,schedul,scheduler,11721,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679,1,['schedul'],['scheduler']
Energy Efficiency,"rn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `75%`. ```diff; @@ Coverage Diff @@; ## master #2431 +/- ##; ==========================================; Coverage ? 42.757% ; Complexity ? 5801 ; ==========================================; Files ? 750 ; Lines ? 39425 ; Branches ? 6885 ; ==========================================; Hits ? 16857 ; Misses ? 20600 ; Partials ? 1968; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...s/recalibration/covariates/ReadGroupCovariate.java](https://codecov.io/gh/broadinstitute/gatk/compare/dc15e61a728ccd4e61b139332e48c05b57e4e88c...0d5d1b12d611725c80fa572e5ffba3bf8ea45ee4?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL2NvdmFyaWF0ZXMvUmVhZEdyb3VwQ292YXJpYXRlLmphdmE=) | `86.667% <100%> (Ã¸)` | `11 <0> (?)` | |; | [...dinstitute/hellbender/utils/report/GATKReport.java](https://codecov.io/gh/broadinstitute/gatk/compare/dc15e61a728ccd4e61b139332e48c05b57e4e88c...0d5d1b12d611725c80fa572e5ffba3bf8ea45ee4?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZXBvcnQvR0FUS1JlcG9ydC5qYXZh) | `40.196% <66.667%> (Ã¸)` | `16 <0> (?)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=footer). Last update [dc15e61...0d5d1b1](https://codecov.io/gh/broadinstitute/gatk/compare/dc15e61a728ccd4e61b139332e48c05b57e4e88c...0d5d1b12d611725c80fa572e5ffba3bf8ea45ee4?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2431#issuecomment-283404250:1815,Power,Powered,1815,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2431#issuecomment-283404250,1,['Power'],['Powered']
Energy Efficiency,roadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172) ; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857) ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; at java.util.Spliterators$,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651:5723,Reduce,ReduceOps,5723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651,1,['Reduce'],['ReduceOps']
Energy Efficiency,roadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6774:4917,Reduce,ReduceOps,4917,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774,1,['Reduce'],['ReduceOps']
Energy Efficiency,roadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:907); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:861); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069:4095,Reduce,ReduceOps,4095,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069,1,['Reduce'],['ReduceOps']
Energy Efficiency,"roadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 37.98 minutes.; Runtime.totalMemory()=23999283200; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 1.0 failed 1 times, most recent failure: Lost task 20.0 in stage 1.0 (TID 891, localhost, executor driver): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 131031 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkConte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:2751,schedul,scheduler,2751,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['schedul'],['scheduler']
Energy Efficiency,"roadinstitute/gsa-unstable/issues/855#issuecomment-174245406). @chandrans My other bug turned into a very long undertaking, but seems to be nearing completion. It might even be done already, pending Laura's confirmation that the output vcfs are what we want. Then I will move on to this one. ---. @chandrans commented on [Tue Jan 26 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-175192516). Ah wonderful. Thanks David. ---. @davidbenjamin commented on [Tue Apr 12 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-209080316). As discussed in support meeting today, this issue is high-effort, low-reward for now but will be much easier to revisit (if it's even necessary at all) once the exact AF calculation is replaced with something less baroque. ---. @vruano commented on [Thu May 05 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-217265362). It seems to me that a quick and sound solution is to reduce the number of alternative alleles at this point in HCGenotypeEngine code:. ```; HaplotypeCallerGenotypingEngine.java line 260:; final Map<Allele, List<Haplotype>> alleleMapper = createAlleleMapper(mergeMap, eventMapper);; ```. Haplotypes have associated score, as a pseudo-likelihood,that can be use to sort then and selectively remove those alternative alleles that are only supported by the less likely haplotypes. ---. @vruano commented on [Thu May 05 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-217266027). So the idea is simple, keep removing haplotypes from that map value lists one by one until enough allele's are emptied, so that the number of genotypes does not surpasses a maximum based on the largest ploidy amongst the input samples. Of course, one would need to create some temporary data-structure to make the operation more efficient. . ---. @vruano commented on [Thu May 05 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-217267",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2955:5416,reduce,reduce,5416,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2955,1,['reduce'],['reduce']
Energy Efficiency,rocessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:13500,schedul,scheduler,13500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"rp: 0; Hugepagesize: 2048 kB; DirectMap4k: 333160 kB; DirectMap2M: 14249984 kB; DirectMap1G: 121634816 kB. CPU:total 10 (initial active 3) (14 cores per cpu, 2 threads per core) family 6 model 79 stepping 1, cmov, cx8, fxsr, mmx, sse, sse2, sse3, ssse3, sse4.1, sse4.2, popcnt, avx, avx2, aes, clmul, erms, rtm, 3dnowpref, lzcnt, ht, tsc, tscinvbit, bmi1, bmi2, adx. /proc/cpuinfo:; processor	: 0; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 0; cpu cores	: 14; apicid		: 0; initial apicid	: 0; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts; bogomips	: 4788.74; clflush size	: 64; cache_alignment	: 64; address sizes	: 46 bits physical, 48 bits virtual; power management:. processor	: 1; vendor_id	: GenuineIntel; cpu family	: 6; model		: 79; model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz; stepping	: 1; microcode	: 0xb000021; cpu MHz		: 2799.937; cache size	: 17920 KB; physical id	: 0; siblings	: 14; core id		: 1; cpu cores	: 14; apicid		: 2; initial apicid	: 2; fpu		: yes; fpu_exception	: yes; cpuid level	: 20; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 cl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:43460,monitor,monitor,43460,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['monitor'],['monitor']
Energy Efficiency,rrentBroadcast.scala:96); 	at org.disq_bio.disq.impl.formats.sam.AnySamSinkMultiple.lambda$save$bddeb71b$1(AnySamSinkMultiple.java:91); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: com.esotericsoftware.kryo.KryoException: java.lang.UnsupportedOperationException; Serialization trace:; requestOptions (com.google.cloud.storage.BlobReadChannel); channel (com.google.cloud.storage.contrib.nio.CloudStorageReadChannel); channel (htsjdk.samtools.reference.IndexedFastaSequenceFile); rsFile (htsjdk.samtools.cram.ref.ReferenceSource); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:144); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at co,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545:1963,schedul,scheduler,1963,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545,2,['schedul'],['scheduler']
Energy Efficiency,"rs specific to PGEN extract. ### Large scale testing; All of my testing (with the exception of some very small scale stuff early on) has been done in the [GVS_AoU_PGEN_Extract_Development Terra workspace](https://app.terra.bio/#workspaces/allofus-drc-prod-auxiliary/GVS_AoU_PGEN_Extract_Development) and using data from the GVS Delta callset (aou-genomics-curation-prod.aou_wgs_fullref_v2). My test process (for the majority of tests) has been as follows:. 1. Select a list of sample names from aou_wgs_fullref_v2.sample_info (excluding control samples and sample 3224672 because of the data issue mentioned [here](https://broadinstitute.slack.com/archives/CJRLP6ZSA/p1699026273329339)).; 2. Use that list as an input to GvsPrepareRangesCallset to create a cohort of test data in a separate BigQuery dataset (aou-genomics-curation-prod.klydon_pgen_extract_test).; 3. Run GvsExtractCallsetPgen on the newly created cohort. (I would just run GvsExtractCallsetPgenMerged, but I like using Workflow Dashboard to monitor how the job is going and dig into it if there are any failures. Workflow Dashboard doesn't seem to let you dig into individual tasks for workflows with sub-workflows, so it wouldn't allow me to look at individual shards running ExtractTask if I ran GvsExtractCallsetPgenMerged. Job Manager would be an alternative for this, but it seems to be pretty much unusable for even moderately-sized jobs.); 4. Run GvsExtractCallset on the newly created cohort, making sure to use the same parameters, including scatter count. This will generate VCF files that we can use to compare to the PGEN files created during the previous step for validation.; 5. Run GvsExtractCallsetPgenMerged with the same parameters used to run GvsExtractCallsetPgen in Step 3. This will use call-caching for the extract steps and then merge the PGEN files by chromosome. (Running it this way is maybe not the ideal way to do this, but it's what I've been doing for reasons described in the parenthetical in Step 3).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708:10392,monitor,monitor,10392,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708,1,['monitor'],['monitor']
Energy Efficiency,"rtitionsToPair at PSScorer.java:68) finished in 0.185 s; 23/05/23 13:20:18 INFO DAGScheduler: looking for newly runnable stages; 23/05/23 13:20:18 INFO DAGScheduler: running: Set(); 23/05/23 13:20:18 INFO DAGScheduler: waiting: Set(ResultStage 16); 23/05/23 13:20:18 INFO DAGScheduler: failed: Set(); 23/05/23 13:20:18 INFO DAGScheduler: Submitting ResultStage 16 (ShuffledRDD[61] at reduceByKey at PSScorer.java:71), which has no missing parents; 23/05/23 13:20:18 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 4.7 KB, free 399.8 GB); 23/05/23 13:20:18 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.6 KB, free 399.8 GB); 23/05/23 13:20:18 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on d01.capitalbiotech.local:41352 (size: 2.6 KB, free: 399.8 GB); 23/05/23 13:20:18 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1163; 23/05/23 13:20:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 16 (ShuffledRDD[61] at reduceByKey at PSScorer.java:71) (first 15 tasks are for partitions Vector(0, 1)); 23/05/23 13:20:18 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks; 23/05/23 13:20:18 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 1966, localhost, executor driver, partition 0, PROCESS_LOCAL, 7662 bytes); 23/05/23 13:20:18 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 1967, localhost, executor driver, partition 1, PROCESS_LOCAL, 7662 bytes); 23/05/23 13:20:18 INFO Executor: Running task 0.0 in stage 16.0 (TID 1966); 23/05/23 13:20:18 INFO Executor: Running task 1.0 in stage 16.0 (TID 1967); 23/05/23 13:20:18 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks; 23/05/23 13:20:18 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks; 23/05/23 13:20:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms; 23/0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8339:39657,reduce,reduceByKey,39657,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8339,1,['reduce'],['reduceByKey']
Energy Efficiency,ry.java:281); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:338); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:138); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:113); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.lambda$enqueueAndHandleVariant$0(Funcotator.java:502); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:504); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:399); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:109); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$Fo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886:1254,Reduce,ReduceOps,1254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"s 30169 30168 -1 ; + Misses 6771 6768 -3 ; Partials 2620 2620; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2450?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `23.729% <100%> (Ã¸)` | `2 <0> (Ã¸)` | :x: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `84.211% <100%> (-0.164%)` | `53 <0> (Ã¸)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `66.316% <33.333%> (+2.03%)` | `28 <4> (Ã¸)` | :x: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2450?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2450?src=pr&el=footer). Last update [987e2f9...05211ec](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285652447:2323,Power,Powered,2323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285652447,1,['Power'],['Powered']
Energy Efficiency,"s for per-contig histograms):. ````; CONTIG_SET PLOIDY_STATE RELATIVE_PROBABILITY; (1) (2) 1.0; ...; (X,Y) (2,0) 1.0; (X,Y) (1,1) 1.0; (X,Y) (1,0) 0.01; (X,Y) (2,1) 0.01; (X,Y) (1,2) 0.01; (X,Y) (3,0) 0.01; ````. We then fit the per-contig coverage histograms across all samples with the appropriate negative-binomial distributions corresponding to a sparse mixture of genotypes, while accounting for 1) sample-specific depth (which determines the means of the negative-binomial distributions), 2) multiplicative contig-specific bias (which is mild, at least for WGS), and 3) additive sample-contig-specific mosaicism or bias (note that the above genotype priors imply that mosaicism/bias on top of a baseline of CN = 2 is the only deviation allowed for the autosomes, which is somewhat restrictive but greatly aids convergence). I put together a pure PyMC3 prototype that seems to work relatively well. Here are the per-contig coverage histograms (unfiltered bins in blue, bins retained after filtering in red, and negative-binomial fit in green) and a heatmap of per-contig ploidy probabilities. Both the panel (first 20) and case (remaining) samples are shown:. ![prototype-result](https://user-images.githubusercontent.com/11076296/37938642-e9fbd804-312c-11e8-8a6c-02ea4e4fa704.png). Although the prototype model is clearly a good fit to the filtered data, some care in choosing the optimizer and its learning parameters is required to achieve convergence to the correct solution. This is because the problem is inherently multimodal and thus there are many local minima. I found that using AdaMax with a naive strategy of warm restarts (to help kick us out of local minima) worked decently; we can achieve convergence in <10 minutes for 60 samples x 24 contigs x 250 count bins:. ![elbo](https://user-images.githubusercontent.com/11076296/37938658-fc176f12-312c-11e8-89e2-40c68e0f9953.png). I expect that @mbabadi's annealing implementation in the gcnvkernel package will handle the local minima",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:2149,green,green,2149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271,1,['green'],['green']
Energy Efficiency,"s users pulling from all docker repos (regardless of the tier for the owner of the repository being pulled from). This might or might not affect us since it looks like travis is pulling from our GCR repo for builds but we should be mindful of workflows that might rely on pulling hundreds of docker images from docker-hub through anonymous web VMs:; ```; On Monday, November 2, 2020 at 9am Pacific Standard Time, Docker will begin enforcing rate limits on container pulls for Anonymous and Free users. Anonymous (unauthenticated) users will be limited to 100 container image pulls every six hours, and Free (authenticated) users will be limited to 200 container image pulls every six hours, when enforcement is fully implemented. Docker Pro and Team subscribers can pull container images from Docker Hub without restriction, as long as the quantities are not excessive or abusive.; In addition, we are pausing enforcement of the changes to our image-retention policies until mid-2021, when we anticipate incorporating them into usage-based pricing. Two months ago, we announced an update to Docker image-retention policies. As originally stated, this change, which was set to take effect on November 1, 2020, would result in the deletion of images for free Docker account users after six months of inactivity. Today's announcement means Docker will not enforce image expiration on November 1, 2020.; ```; This is farther clarified on their FAQ https://www.docker.com/pricing/resource-consumption-updates:; ```; Rate limits for Docker image pulls are based on the account type of the user requesting the image - not the account type of the imageâ€™s owner. These are defined on the pricing page.; The highest entitlement a user has, based on their personal account and any orgs they belong to, will be used. Unauthenticated pull requests are â€œanonymousâ€ and will be rate limited based on IP address rather than user ID. For more information on authenticating image pulls, please see this docs page.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6922:1541,consumption,consumption-updates,1541,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6922,1,['consumption'],['consumption-updates']
Energy Efficiency,"s with the bam). They are all suffering from the same/similar stacktrace. We've had BaseRecalibratorSpark work fine on other bam files. Additionally, changing the number of threads still results in the same stacktrace. I've also tried running the BQSRPipelineSpark to see if that would suffer the same issue and it fails in the same manner. Additionally, I've run ValidateSamFile. There are some reads missing their mates, but this hasn't presented an issue in other tools (including vanilla BaseRecalibrator). Searching thru the forum, I found an old issue with a similar stacktrace, but that issue appears to occur in GATK 2.4: https://gatkforums.broadinstitute.org/gatk/discussion/3265/bqsrgatherer-exception. In the below stacktrace, I've bolded the error message that seems to occur in each of these samples. `Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProces",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:1401,schedul,scheduler,1401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['schedul'],['scheduler']
Energy Efficiency,s.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.correctGenotypePloidy(JointGermlineCNVSegmentation.java:701); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.prepareGenotype(JointGermlineCNVSegmentation.java:682); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.lambda$createDepthOnlyFromGCNVWithOriginalGenotypes$4(JointGermlineCNVSegmentation.java:666); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.ArrayList$Itr.forEachRemaining(ArrayList.java:1033); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.createDepthOnlyFromGCNVWithOriginalGenotypes(JointGermlineCNVSegmentation.java:667); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.apply(JointGermlineCNVSegmentation.java:280); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:133); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.afterTraverse(MultiVariantWalkerGroupedOnStart.java:193); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:166); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1095); at org.broadinstitute.hellbender.cmd,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8164:1577,Reduce,ReduceOps,1577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8164,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,s.iterators.PushToPullIterator.advanceToNextElement(PushToPullIterator.java:58); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.<init>(PushToPullIterator.java:37); 	at org.broadinstitute.hellbender.utils.variant.writers.GVCFBlockCombiningIterator.<init>(GVCFBlockCombiningIterator.java:14); 	at org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSink.lambda$writeVariantsSingle$516343c4$1(VariantsSparkSink.java:127); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745)`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994:4022,schedul,scheduler,4022,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994,2,['schedul'],['scheduler']
Energy Efficiency,"sPipelineSpark --bam-partition-size 64000000 or 4000000 \; --input hdfs://namenode:8020/$dir_prepro$ubam \; --reference hdfs://namenode:8020/hg19-ucsc/ucsc.hg19.2bit \; --bwa-mem-index-image /reference_image/ucsc.hg19.fasta.img \; --disable-sequence-dictionary-validation true \; --output hdfs://namenode:8020/$dir_prepro$output -- \; --spark-runner SPARK --spark-master spark://$SPARK_MASTER_HOST:7077 \; --driver-memory 20g --executor-cores 4 --executor-memory 8g; ```. Furthermore I have this problem with this version v4.0.4.0-23-g6e1cc8c-SNAPSHOT. > mark duplicate records objects corresponding to read with name, this could be the result of readnames spanning more than one partition; 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$null$0(MarkDuplicatesSpark.java:109); 	at java.util.HashMap.merge(HashMap.java:1253); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$mark$62928560$1(MarkDuplicatesSpark.java:109); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89); 	at org.apache.spark.rdd.RDD.comput",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:7244,Reduce,ReduceOps,7244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['Reduce'],['ReduceOps']
Energy Efficiency,"sa-unstable/issues/1425#issuecomment-232150240). Comparison using KB NA12878 on PCR+ PCR- data across 20:10M-25M:. <img width=""550"" alt=""screen shot 2016-07-12 at 3 15 45 pm"" src=""https://cloud.githubusercontent.com/assets/791104/16780183/9042fcda-4843-11e6-99e5-cb9b39e5dfdc.png"">. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-260494000). @vruano Are you currently working on this? Or can this be moved into the GATK4 repo for future work? . ---. @vruano commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-260503444). Working on it on GATK3 but I could merge it into GATK4 whenever is ready if you prefer. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-260509332). Ok great, totally fine to do in 3 but please do port to 4 when it's ready. Do you have an order of magnitude sense of when it might be ready? Meaning days/weeks/months (for release scheduling purposes). ---. @vruano commented on [Fri Mar 10 2017](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-285721454). In the last methods meeting I presented the results of our first effort to improve accuracy calling in STR. As far as unfiltered single and trio calls are concerned the recommendation is to apply the new model with PCR+ data. However, for PCR- dataset one either can choose not apply any correction or to apply the new model train on PCR- data... the latter seems to have slightly F1 values however for the sake of simplicity it might just make sense no to apply any correct; either way is good. The presentation I gave can be found [here](https://drive.google.com/open?id=0Bzt9p0vCNxlHWlZVUHZfdXR5MTg). ---. @vruano commented on [Fri Mar 10 2017](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-285722791). It seems that at some point Planatir will take a look and see whether it im",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2519:1398,schedul,scheduling,1398,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2519,1,['schedul'],['scheduling']
Energy Efficiency,"sbGJlbmRlci90b29scy9zcGFyay9zdi9EaXNjb3ZlclN0cnVjdHVyYWxWYXJpYW50c0Zyb21BbGlnbmVkQ29udGlnc1NBTVNwYXJrLmphdmE=) | `0% <0%> (Ã¸)` | `0 <0> (?)` | |; | [...oadinstitute/hellbender/tools/spark/sv/SvType.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdlR5cGUuamF2YQ==) | `100% <100%> (Ã¸)` | `5 <0> (Ã¸)` | :arrow_down: |; | [...e/hellbender/tools/spark/sv/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9DaGltZXJpY0FsaWdubWVudC5qYXZh) | `57.831% <33.333%> (Ã¸)` | `25 <1> (Ã¸)` | :arrow_down: |; | [...bender/tools/spark/sv/AssemblyAlignmentParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9Bc3NlbWJseUFsaWdubWVudFBhcnNlci5qYXZh) | `66.917% <66.667%> (Ã¸)` | `38 <1> (Ã¸)` | :arrow_down: |; | [...er/tools/spark/sv/SVVariantConsensusDiscovery.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlZhcmlhbnRDb25zZW5zdXNEaXNjb3ZlcnkuamF2YQ==) | `82.653% <73.913%> (Ã¸)` | `25 <1> (?)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=footer). Last update [d054e7a...4ffa301](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2567#issuecomment-291643361:4290,Power,Powered,4290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2567#issuecomment-291643361,1,['Power'],['Powered']
Energy Efficiency,scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:13702,schedul,scheduler,13702,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['schedul'],['scheduler']
Energy Efficiency,scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2281); at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83); ... 27 more; Caused by,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:32354,adapt,adapted,32354,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['adapt'],['adapted']
Energy Efficiency,scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:13800,schedul,scheduler,13800,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['schedul'],['scheduler']
Energy Efficiency,scala:797); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); 17:43:23.161 INFO FeatureManager - Using codec VCFCodec to read file file:///scratch/tmp/spark-ecd63991-68be-4879-b481-68e6789a2004/userFiles-b72d4821-5e36-4d36-aa79-aa6263768669/1000G_phase1.indels.hg19.sites.vcf; 20/01/05 17:43:23 INFO NewHadoopRDD: Input split: file:/panfs/roc/groups/6/clinicalmdl/shared/wgs_exome_v1.0/projects/BT_WGS_Flex_S1/data/exome_dedup_reads.bam:167436615680+33554432; 20/01/05 17:43:23 ERROR Executor: Exception in task 4990.0 in stage 0.0 (TID 4990); java.io.FileNotFoundException: /panfs/roc/groups/6/clinicalmdl/shared/v1.0/projects/BT_WGS_Flex_S1/data/exome_dedup_reads.ba,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855:4581,schedul,scheduler,4581,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855,1,['schedul'],['scheduler']
Energy Efficiency,"scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 00:11:09.632 WARN TaskSetManager:66 - Lost task 15.0 in stage 1.0 (TID 519, localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:192); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipelin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:5974,Reduce,ReduceOps,5974,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Reduce'],['ReduceOps']
Energy Efficiency,"scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at org.apache.spark.storage.BlockManager.reportAllBlocks(BlockManager.scala:217); at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:236); at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:522); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308); at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180); at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 18/03/09 09:22:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/09 09:22:08 INFO SparkContext: Successfully stopped SparkContext; 09:22:08.389 INFO BaseRecalibratorSpark - Shutting down engine; [March 9, 2018 9:22:08 AM UTC] org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark done. Elapsed time: 61.53 minutes.; Runtime.totalMemory()=16815489024; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 0.0 failed 1 times, most recent failure: Lost task 8.0 in stage 0.0 (TID 8, localhost): ExecutorLostFailure (executor driver exited caused by one ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515:2118,Schedul,ScheduledThreadPoolExecutor,2118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515,1,['Schedul'],['ScheduledThreadPoolExecutor']
Energy Efficiency,scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2281); at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83); ... 27 more; Caused by: java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; at java.base/jdk.internal.util.ArraysSupport.hugeLength(ArraysSupport.java:649); at java.base/jdk.internal.util.ArraysSupport.newLength(ArraysSupport.java:642); at java.base/java.io.ByteArrayOutputStream.en,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:32637,schedul,scheduler,32637,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:13052,adapt,adapted,13052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['adapt'],['adapted']
Energy Efficiency,"scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 00:11:09.632 WARN TaskSetManager:66 - Lost task 15.0 in stage 1.0 (TID 519, localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:192); at java.util.stream.ReferencePipeline$7$1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:5936,Reduce,ReduceOps,5936,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"se version [version?]; 4.0.8.1; - [ ] Latest master branch as of [date of test?]; Sep 10, 2018. ### Description ; 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 515, localhost, executor 1, partition 0, NODE_LOCAL, 5270 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 516, localhost, executor 2, partition 1, NODE_LOCAL, 5598 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 6.0 (TID 517, localhost, executor 1, partition 2, NODE_LOCAL, 5315 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 6.0 (TID 518, localhost, executor 2, partition 3, NODE_LOCAL, 5594 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 6.0 (TID 519, localhost, executor 1, partition 4, NODE_LOCAL, 5317 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 6.0 (TID 520, localhost, executor 2, partition 5, NODE_LOCAL, 5598 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 6.0 (TID 521, localhost, executor 1, partition 6, NODE_LOCAL, 5315 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 6.0 (TID 522, localhost, executor 2, partition 7, NODE_LOCAL, 5316 bytes); 18/09/08 10:32:49 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:37617 (size: 59.2 KB, free: 2004.5 MB); 18/09/08 10:32:49 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:45786 (size: 59.2 KB, free: 2004.5 MB); 18/09/08 10:32:50 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:37617 (size: 9.0 B, free: 2004.5 MB); 18/09/08 10:32:50 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 6.0 (TID 523, localhost, executor 1, partition 8, NODE_LOCAL, 5604 bytes); 18/09/08 10:32:50 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 6.0 (TID 524, localhost, executor 1, parti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5169:1164,schedul,scheduler,1164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5169,1,['schedul'],['scheduler']
Energy Efficiency,se(SAMRecordToGATKReadAdapter.java:264); 	at org.broadinstitute.hellbender.tools.walkers.annotator.CountNs.doesReadHaveN(CountNs.java:61); 	at org.broadinstitute.hellbender.tools.walkers.annotator.CountNs.lambda$annotate$1(CountNs.java:46); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:174); 	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948); 	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:270); 	at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); 	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); 	at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.LongPipeline.reduce(LongPipeline.java:438); 	at java.util.stream.LongPipeline.sum(LongPipeline.java:396); 	at java.util.stream.ReferencePipeline.count(ReferencePipeline.java:526); 	at org.broadinstitute.hellbender.tools.walkers.annotator.CountNs.annotate(CountNs.java:46); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:268); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:192); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:233); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:232); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.As,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6336:1449,Reduce,ReduceOps,1449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6336,1,['Reduce'],['ReduceOps']
Energy Efficiency,"se** coverage by `0.003%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2511 +/- ##; ===============================================; - Coverage 76.259% 76.256% -0.003% ; + Complexity 10865 10864 -1 ; ===============================================; Files 750 750 ; Lines 39543 39543 ; Branches 6915 6915 ; ===============================================; - Hits 30155 30154 -1 ; Misses 6771 6771 ; - Partials 2617 2618 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2511?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...er/tools/walkers/variantutils/VariantsToTable.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...1a7a561a7da5603a607f04cd982c62fb8491403b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGUuamF2YQ==) | `94.083% <Ã¸> (Ã¸)` | `73 <0> (Ã¸)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...1a7a561a7da5603a607f04cd982c62fb8491403b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `90% <0%> (-1.429%)` | `23% <0%> (-1%)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2511?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2511?src=pr&el=footer). Last update [724fbd0...1a7a561](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...1a7a561a7da5603a607f04cd982c62fb8491403b?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2511#issuecomment-288267091:1937,Power,Powered,1937,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2511#issuecomment-288267091,1,['Power'],['Powered']
Energy Efficiency,"semblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.TaskSetManager: Task 284 in stage 25.0 failed 4 times; aborting job; 18/01/12 20:38:37 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@23007ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(50,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(52,WrappedArray())",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:4543,schedul,scheduler,4543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,semblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:7919,schedul,scheduler,7919,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,"ser-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1339,schedul,scheduler,1339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['schedul'],['scheduler']
Energy Efficiency,set Spark reducer chunk size to 64MB by default - speeds up our pipelines,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1874:10,reduce,reducer,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1874,1,['reduce'],['reducer']
Energy Efficiency,"sing that the most relevant info for the following problem is that it is a ppc64le system. When I use HaplotypeCaller, I see the following messages on the screen:. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -jar /home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCaller -R ref.fa -I mybam.bam -O mycalls.vcf.gz -L snps.vcf -ip 100. 16:17:04.377 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1. 16:17:05.843 INFO HaplotypeCaller - For support and documentation go to https://sof",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794:1111,Power,Power,1111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794,1,['Power'],['Power']
Energy Efficiency,sion(s); - [x] Latest public release version 4.1.0.0; - [ ] Latest master branch as of [date of test?]. ### Description . ```; java.lang.IllegalArgumentException: Interval NC_007605:1-171823 not within the bounds of a contig in the provided dictionary; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.engine.Shard.divideIntervalIntoShards(Shard.java:87); 	at org.broadinstitute.hellbender.engine.Shard.divideIntervalIntoShards(Shard.java:66); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.lambda$runTool$0(ReadsPipelineSpark.java:221); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.runTool(ReadsPipelineSpark.java:222); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5644:1091,Reduce,ReduceOps,1091,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5644,1,['Reduce'],['ReduceOps']
Energy Efficiency,size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:11.779 INFO StructuralVariationDiscoveryPipelineSpark - 3946 contigs indicating MappedInsertionBkpt; 18/01/25 17:20:11 WARN org.apache.spark.scheduler.TaskSetManager: Stage 37 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:23.416 INFO StructuralVariationDiscoveryPipelineSpark - 853 contigs indicating Cpx; 18/01/25 17:20:23 WARN org.apache.spark.scheduler.TaskSetManager: Stage 41 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:34.830 INFO StructuralVariationDiscoveryPipelineSpark - 1521 contigs indicating Incomplete; 18/01/25 17:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 45 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:44.949 INFO StructuralVariationDiscoveryPipelineSpark - 5277 contigs indicating Ambiguous; 18/01/25 17:20:45 WARN org.apache.spark.scheduler.TaskSetManager: Stage 49 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:55.516 INFO StructuralVariationDiscoveryPipelineSpark - 15 contigs indicating MisAssemblySuspect; 18/01/25 17:20:55 WARN org.apache.spark.scheduler.TaskSetManager: Stage 53 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:21:06.632 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 14088 variants.; 17:21:06.647 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 6100; 17:21:06.647 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 240; 17:21:06.647 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 230; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4488; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1355; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1675; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - IN,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260:3437,schedul,scheduler,3437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260,1,['schedul'],['scheduler']
Energy Efficiency,"sk 0.0 in stage 0.0 (TID 0) in 403 ms on localhost (1/1); 15/07/14 13:14:53 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Stage 0 (aggregate at TransformTranslator.java:183) finished in 0.416 s; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at TransformTranslator.java:183, took 0.607813 s; 15/07/14 13:14:53 INFO spark.SparkPipelineRunner: Evaluating AnonymousParDo [ParDo]; 15/07/14 13:14:53 INFO spark.SparkPipelineRunner: Evaluating TextIO.Write [TextIO.Write]; 15/07/14 13:14:53 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at TransformTranslator.java:432; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Got job 1 (saveAsNewAPIHadoopFile at TransformTranslator.java:432) with 1 output partitions (allowLocal=false); 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Final stage: Stage 1(saveAsNewAPIHadoopFile at TransformTranslator.java:432); 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Parents of final stage: List(); 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Missing parents: List(); 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Submitting Stage 1 (MapPartitionsRDD[8] at mapToPair at TransformTranslator.java:405), which has no missing parents; 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(11824) called with curMem=10409, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.5 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(7006) called with curMem=22233, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.8 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:65240 (size: 6.8 KB, free: 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerMaster: Updated info of block br",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:26169,schedul,scheduler,26169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['schedul'],['scheduler']
Energy Efficiency,"sk 0.0 in stage 1.0 (TID 1, localhost): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). 16/11/16 23:25:11 ERROR TaskSetManager: Task 0 in stage 1.0 failed 1 times; aborting job; 16/11/16 23:25:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 16/11/16 23:25:11 INFO TaskSchedulerImpl: Cancelling stage 1; 16/11/16 23:25:11 INFO DAGScheduler: ResultStage 1 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:202) failed in 0.276 s; 16/11/16 23:25:11 INFO DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:202, took 1.029776 s; 16/11/16 23:25:11 INFO SparkContext: SparkContext already stopped.; [November 16, 2016 11:25:11 PM AST] org.br",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:15798,schedul,scheduler,15798,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,"sk 0.0 in stage 1.0 (TID 1, localhost): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$78/237665701.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:159); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418); 	at org.apache.spa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:18060,schedul,scheduler,18060,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,sk.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:8936,schedul,scheduler,8936,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,sk.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkConte,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:11112,schedul,scheduler,11112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,"son/fa676046-ddfe-4ce8-9193-87025fd9a49b/call-BenchmarkVCFControlSample/Benchmark/8c5c120e-b932-47b0-a592-a719021e6bf9/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-EXOME1SampleHeadToHead/BenchmarkComparison/fa676046-ddfe-4ce8-9193-87025fd9a49b/call-BenchmarkVCFTestSample/Benchmark/b683956e-cbfb-4550-978b-cd6a28bf12a4/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""103.80716111111109"",; ""NIST controlHCsystemhours"": ""0.20777777777777773"",; ""NIST controlHCwallclockhours"": ""76.1228972222222"",; ""NIST controlHCwallclockmax"": ""4.163775"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-NISTSampleHeadToHead/BenchmarkComparison/24ad1003-6862-4e29-9d4d-ea8e85bcc78b/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-NISTSampleHeadToHead/BenchmarkComparison/24ad1003-6862-4e29-9d4d-ea8e85bcc78b/call-BenchmarkVCFControlSample/Benchmark/7d69a7b4-2884-4b7e-9bce-fc2eab77b125/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""103.71990555555556"",; ""NIST evalHCsystemhours"": ""0.20632500000000004"",; ""NIST evalHCwallclockhours"": ""76.41897222222222"",; ""NIST evalHCwallclockmax"": ""4.163391666666667"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b48",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574622123:20340,monitor,monitoring,20340,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574622123,1,['monitor'],['monitoring']
Energy Efficiency,"specs/SAMv1.pdf, pg 5, item 5). It is defined in the range [0, 2^8-1]. The specific value 255 is reserved for when MAPQ is not available. Most MAPQs are well below 255. We consider the following process for assigning reads to each target. Pick a read ""k"" aligned to target ""t"" with a given MAPQ_k. By definition, it maps to the genomic position ""x"" with p_x = 1 - 10^{-MAPQ_k/10}, and to some other position with probability 1 - p_x. We refer to the alignment genomic position of read k as x_k, and the exome target(s) it overlaps with T_k. Let's assume we have T exome targets, and let z_{kt} be a 1-of-#T indicator variable for a read where t is a target and #T is the number of all exome targets. \pi_{kq} = P(z_{kq} = 1) =. p_k x O_{kq} if q \in T_k; (1 - p_k) / (#T - #T_k) if q \notin T_k. Here, O_{kq} is the fractional overlap of the read to an exome target q. Note that since we don't have the information about the next best alignment position, we take a flat prior. Finally, the number of reads belonging to target t, n_t, reads as:. n_t = \sum_k z_{kt}. Since there are many reads, n_t will be approximately Gaussian. It is an elementary calculation to calculate coverage mean E[n_t] and coverage variance var[n_t] in terms of \pi_{kq}. In the probabilistic target coverage model, var[n_t] will be added to the statistical noise. So, the read count collection will have two entries for each target: coverage mean, and coverage variance. ---. @mbabadi commented on [Wed Oct 19 2016](https://github.com/broadinstitute/gatk-protected/issues/748#issuecomment-254812286). @samuelklee @asmirnov239 ; The outcome of https://github.com/broadinstitute/gatk-protected/issues/746 will indicate whether or not we'll need this. Andrey already has a preliminary indication that a fair fraction (50%!) of reads have mapping quality < 20. This implies a very significant coverage variance. Feeding this information into the probabilistic target coverage modeler is guaranteed to significantly reduce FDR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2908:2501,reduce,reduce,2501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2908,1,['reduce'],['reduce']
Energy Efficiency,squash bug / add temp dir to monitoring logs collection script,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8921:29,monitor,monitoring,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8921,1,['monitor'],['monitoring']
Energy Efficiency,squashed + rebased. Will merge once tests are green.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2101#issuecomment-249293885:46,green,green,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2101#issuecomment-249293885,1,['green'],['green']
Energy Efficiency,"squashed, rebased, warnings removed. Ready to go as soon as green.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/595#issuecomment-115429008:60,green,green,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/595#issuecomment-115429008,1,['green'],['green']
Energy Efficiency,"ssembled breakpoints; 20:38:14.462 INFO StructuralVariationDiscoveryPipelineSpark - Called 662 imprecise deletion variants; 20:38:14.492 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 7234 variants.; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - INV: 184; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4486; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1170; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1394; 18/01/12 20:38:16 WARN org.apache.spark.scheduler.TaskSetManager: Stage 17 contains a task of very large size (2518 KB). The maximum recommended task size is 100 KB.; 18/01/12 20:38:22 WARN org.apache.spark.scheduler.TaskSetManager: Stage 18 contains a task of very large size (2307 KB). The maximum recommended task size is 100 KB.; 20:38:27.207 INFO StructuralVariationDiscoveryPipelineSpark - Processing 501267 raw alignments from 426041 contigs.; 18/01/12 20:38:27 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2518 KB). The maximum recommended task size is 100 KB.; 20:38:35.835 INFO StructuralVariationDiscoveryPipelineSpark - Primitive filtering based purely on MQ left 339065 contigs.; 20:38:37.378 INFO StructuralVariationDiscoveryPipelineSpark - 17574 contigs with chimeric alignments potentially giving SV signals.; 18/01/12 20:38:37 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 284.0 in stage 25.0 (TID 43189, cw-test-w-6.c.broad-dsde-methods.internal, executor 7): java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.ContigAlignmentsModifier.removeOverlap(ContigAlignmentsModifier.java:36); 	at org.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:2480,schedul,scheduler,2480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,"ssing parents; 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(11824) called with curMem=10409, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.5 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(7006) called with curMem=22233, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.8 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:65240 (size: 6.8 KB, free: 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerMaster: Updated info of block broadcast_1_piece0; 15/07/14 13:14:53 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:839; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MapPartitionsRDD[8] at mapToPair at TransformTranslator.java:405); 15/07/14 13:14:53 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 1 tasks; 15/07/14 13:14:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1296 bytes); 15/07/14 13:14:53 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1); 15/07/14 13:14:53 INFO storage.BlockManager: Removing broadcast 0; 15/07/14 13:14:53 INFO storage.BlockManager: Removing block broadcast_0; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_0 of size 6656 dropped from memory (free 277996857); 15/07/14 13:14:53 INFO storage.BlockManager: Removing block broadcast_0_piece0; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_0_piece0 of size 3753 dropped from memory (free 278000610); 15/07/14 13:14:53 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on localhost:65240 in memory (size: 3.7 KB, free: 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerMaster: Updated info of block broadcast_0_piece0; 15/07/14 13:14:53 INFO spark.Conte",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:27458,schedul,scheduler,27458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['schedul'],['scheduler']
Energy Efficiency,"st and there's no batch api for it? Multi layer docker builds are pretty standard from what I understand. . It sounds like your suggestions are talking about 2 slightly different issues to me. 1. Too many layers:. We typically have squashed the GATK docker images, but we recently switched to building our release images with google cloud build. Since squash is *STILL* an experimental feature in docker we've had trouble getting it to work there. Since the size reduction was pretty minimal from squashing we figured it would be ok to not prioritize it. It's definitely possible for us to consolidate various layers in the build. Or manually squash the images. We can take a look for our next release. Wide workflows on azure are something we need to support. 2. Docker size reduction:; I've spend a lot of time looking at this in the past. Our docker image is huge, but it's mostly due to the massive size of our python and R dependencies. I've done a bunch of work reducing temporary files in independent layers and using multiple stages to reduce the size. There's not much low hanging fruit left there. Similarly, moving to alpine is tricky an has limited benefit. GATK packages a number of C libraries which do not work out of the box on alpine due to the different C runtime. (At least that was the case the last time I investigated it a few years ago. ) I suspect there's a way to port things so they work on it, but it's not something we can do now. It also wouldn't be much of a help, the base image is completely dwarfed by piles of python and R dependencies which are very difficult to safely trim. Anyway, that's the state of things. We've considered a java only image for a while which would be much smaller than the current one. (although still fat by most docker standards...). We've never released one publicly because it seemed like it might cause confusion, but it's a reasonable possibility. . If you have any secret methods to reduce the size of python or R installations we're ha",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427:1239,reduce,reduce,1239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427,1,['reduce'],['reduce']
Energy Efficiency,"st(); 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Submitting Stage 1 (MapPartitionsRDD[8] at mapToPair at TransformTranslator.java:405), which has no missing parents; 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(11824) called with curMem=10409, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.5 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(7006) called with curMem=22233, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.8 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:65240 (size: 6.8 KB, free: 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerMaster: Updated info of block broadcast_1_piece0; 15/07/14 13:14:53 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:839; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MapPartitionsRDD[8] at mapToPair at TransformTranslator.java:405); 15/07/14 13:14:53 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 1 tasks; 15/07/14 13:14:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1296 bytes); 15/07/14 13:14:53 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1); 15/07/14 13:14:53 INFO storage.BlockManager: Removing broadcast 0; 15/07/14 13:14:53 INFO storage.BlockManager: Removing block broadcast_0; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_0 of size 6656 dropped from memory (free 277996857); 15/07/14 13:14:53 INFO storage.BlockManager: Removing block broadcast_0_piece0; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_0_piece0 of size 3753 dropped from memory (free 278000610); 15/07/14 13:14:53 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on localhost:65240 in memory (siz",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:27303,schedul,scheduler,27303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['schedul'],['scheduler']
Energy Efficiency,st): ; java.lang.IllegalArgumentException: String tag does not have length() == 2:. at htsjdk.samtools.SAMTagUtil.makeBinaryTag(SAMTagUtil.java:100); at htsjdk.samtools.SAMRecord.setAttribute(SAMRecord.java:1364); at htsjdk.samtools.SAMLineParser.parseTag(SAMLineParser.java:436); at htsjdk.samtools.SAMLineParser.parseLine(SAMLineParser.java:346); at htsjdk.samtools.SAMLineParser.parseLine(SAMLineParser.java:213); at org.broadinstitute.hellbender.tools.spark.bwa.BwaSparkEngine.lambda$alignWithBWA$464b6154$1(BwaSparkEngine.java:75); at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1015); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at org.apache.spark.util.random.SamplingUtils$.reservoirSampleAndCount(SamplingUtils.scala:42); at org.apache.spark.RangePartitioner$$anonfun$9.apply(Partitioner.scala:261); at org.apache.spark.RangePartitioner$$anonfun$9.apply(Partitioner.scala:259); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$22.apply(RDD.scala:745); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$22.apply(RDD.scala:745); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); at org.apache.spark.scheduler.Task.run(Task.scala:89); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```. I'm trying to isolate an offending read,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2039:1737,schedul,scheduler,1737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2039,2,['schedul'],['scheduler']
Energy Efficiency,"stTools$.getAst(AstTools.scala:263); 	at wdl.draft2.model.WdlNamespace$.$anonfun$load$1(WdlNamespace.scala:170); 	at scala.util.Try$.apply(Try.scala:213); 	at wdl.draft2.model.WdlNamespace$.load(WdlNamespace.scala:169); 	at wdl.draft2.model.WdlNamespace$.loadUsingSource(WdlNamespace.scala:161); 	at wdl.draft2.model.WdlNamespaceWithWorkflow$.load(WdlNamespace.scala:630); 	at womtool.graph.GraphPrint$.generateWorkflowDigraph(GraphPrint.scala:19); 	at womtool.WomtoolMain$.graph(WomtoolMain.scala:131); 	at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:54); 	at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:162); 	at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:167); 	at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:24); 	at scala.Function0.apply$mcV$sp(Function0.scala:39); 	at scala.Function0.apply$mcV$sp$(Function0.scala:39); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17); 	at scala.App.$anonfun$main$1$adapted(App.scala:80); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at scala.App.main(App.scala:80); 	at scala.App.main$(App.scala:78); 	at womtool.WomtoolMain$.main(WomtoolMain.scala:24); 	at womtool.WomtoolMain.main(WomtoolMain.scala); ```. for multi sample:; ```; Exception in thread ""main"" wdl.draft2.parser.WdlParser$SyntaxError: Unrecognized token on line 31, column 50:. <title>gatk/mutect2_multi_sample.wdl at master ? broadinstitute/gatk ? GitHub</title>; ^; 	at wdl.draft2.parser.WdlParser.unrecognized_token(WdlParser.java:6975); 	at wdl.draft2.parser.WdlParser.lex(WdlParser.java:7048); 	at wdl.draft2.model.AstTools$.getAst(AstTools.scala:263); 	at wdl.draft2.model.WdlNamespace$.$anonfun$load$1(WdlNamespace.scala:170); 	at scala.util.Try$.apply(Try.scala:213); 	at wdl.draft2.model.WdlNamespace$.load(WdlNamespace.scala:169); 	at wdl.draft2.model.WdlNamespace$.loadUsingSource(WdlNamespace.scala:161); 	at wdl.draft2.model.WdlNamespaceWithWorkflow$.load(WdlNamespace",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6261:1614,adapt,adapted,1614,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6261,1,['adapt'],['adapted']
Energy Efficiency,"stTools$.getAst(AstTools.scala:263); 	at wdl.draft2.model.WdlNamespace$.$anonfun$load$1(WdlNamespace.scala:170); 	at scala.util.Try$.apply(Try.scala:213); 	at wdl.draft2.model.WdlNamespace$.load(WdlNamespace.scala:169); 	at wdl.draft2.model.WdlNamespace$.loadUsingSource(WdlNamespace.scala:161); 	at wdl.draft2.model.WdlNamespaceWithWorkflow$.load(WdlNamespace.scala:630); 	at womtool.graph.GraphPrint$.generateWorkflowDigraph(GraphPrint.scala:19); 	at womtool.WomtoolMain$.graph(WomtoolMain.scala:131); 	at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:54); 	at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:162); 	at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:167); 	at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:24); 	at scala.Function0.apply$mcV$sp(Function0.scala:39); 	at scala.Function0.apply$mcV$sp$(Function0.scala:39); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17); 	at scala.App.$anonfun$main$1$adapted(App.scala:80); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at scala.App.main(App.scala:80); 	at scala.App.main$(App.scala:78); 	at womtool.WomtoolMain$.main(WomtoolMain.scala:24); 	at womtool.WomtoolMain.main(WomtoolMain.scala); ```. for pon; ```; Exception in thread ""main"" wdl.draft2.parser.WdlParser$SyntaxError: Unrecognized token on line 151, column 69:. gatk GenomicsDBImport --genomicsdb-workspace-path pon_db -R ~{ref_fasta} -V ~{sep=' -V ' input_vcfs} -L ~{intervals}; ^; 	at wdl.draft2.parser.WdlParser.unrecognized_token(WdlParser.java:6975); 	at wdl.draft2.parser.WdlParser.lex(WdlParser.java:7048); 	at wdl.draft2.model.AstTools$.getAst(AstTools.scala:263); 	at wdl.draft2.model.WdlNamespace$.$anonfun$load$1(WdlNamespace.scala:170); 	at scala.util.Try$.apply(Try.scala:213); 	at wdl.draft2.model.WdlNamespace$.load(WdlNamespace.scala:169); 	at wdl.draft2.model.WdlNamespace$.loadUsingSource(WdlNamespace.scala:161); 	at wdl.draft2.model.WdlNamespaceWithWorkf",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6261:3254,adapt,adapted,3254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6261,1,['adapt'],['adapted']
Energy Efficiency,"st_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:44818 (size: 2.1 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/13 18:11:44 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/13 18:11:44 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/13 18:11:44 INFO spark.SparkContext: Starting job: runJob at SparkHadoopMapReduceWriter.scala:88; 17/10/13 18:11:44 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Got job 0 (runJob at SparkHadoopMapReduceWriter.scala:88) with 1 output partitions; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.9 KB, free 366.0 MB); 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:44818 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:44",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:16666,schedul,scheduler,16666,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['schedul'],['scheduler']
Energy Efficiency,stacktrace:** ; **at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)** ; **at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)** ; **at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)** ; **at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)** ; **at scala.Option.foreach(Option.scala:257)** ; **at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)** ; **at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)** ; **at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)** ; **at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)** ; **at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)** ; **at org.apache.spark.rdd.RDD.count(RDD.scala:1168)** ; **at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455)** ; **at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:46703,schedul,scheduler,46703,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,"stage 5.0 failed 1 times; aborting job; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Cancelling stage 5; 21/04/13 07:32:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage cancelled; 21/04/13 07:32:25 INFO DAGScheduler: ResultStage 5 (runJob at SparkHadoopWriter.scala:78) failed in 0.353 s due to Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 105, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Sequence [VC HC @ chr4_GL000008v2_random:7168-7691 Q. of type=SYMBOLIC alleles=[T*, <NON_REF>] attr={END=7691} GT=[[NA12878 T*/T* GQ 0 DP 0 PL 0,0,0 {MIN_DP=0}]] filters= added out of order currentReferenceIndex: 25, referenceIndex:37; at htsjdk.tribble.index.tabix.AllRefsTabixIndexCreator.addFeature(AllRefsTabixIndexCreator.java:79); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:11830,schedul,scheduler,11830,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,"stitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(Sp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1590,schedul,scheduler,1590,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['schedul'],['scheduler']
Energy Efficiency,"strated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-CHMSampleHeadToHead/BenchmarkComparison/258eacc8-3768-44a8-86dc-1b2b0516a553/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-CHMSampleHeadToHead/BenchmarkComparison/258eacc8-3768-44a8-86dc-1b2b0516a553/call-BenchmarkVCFControlSample/Benchmark/b89e3e0d-4f93-4b2d-9008-041545f2764c/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""87.0306027777778"",; ""CHM evalHCsystemhours"": ""0.19828888888888896"",; ""CHM evalHCwallclockhours"": ""62.522422222222225"",; ""CHM evalHCwallclockmax"": ""3.293238888888889"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-CHMSampleHeadToHead/BenchmarkComparison/258eacc8-3768-44a8-86dc-1b2b0516a553/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-CHMSampleHeadToHead/BenchmarkComparison/258eacc8-3768-44a8-86dc-1b2b0516a553/call-BenchmarkVCFTestSample/Benchmark/6b8eb5cf-ee16-48e8-a24f-de149e2eded2/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574622123:18317,monitor,monitoring,18317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574622123,1,['monitor'],['monitoring']
Energy Efficiency,"strated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-CHMSampleHeadToHead/BenchmarkComparison/3609bc35-c943-4006-8b6f-9d71e6c68ef5/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-CHMSampleHeadToHead/BenchmarkComparison/3609bc35-c943-4006-8b6f-9d71e6c68ef5/call-BenchmarkVCFControlSample/Benchmark/96b872e8-26c0-4406-a7d0-addf04f4ad0e/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""78.10857222222224"",; ""CHM evalHCsystemhours"": ""0.28728055555555554"",; ""CHM evalHCwallclockhours"": ""52.84132777777778"",; ""CHM evalHCwallclockmax"": ""2.9151722222222225"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-CHMSampleHeadToHead/BenchmarkComparison/3609bc35-c943-4006-8b6f-9d71e6c68ef5/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-CHMSampleHeadToHead/BenchmarkComparison/3609bc35-c943-4006-8b6f-9d71e6c68ef5/call-BenchmarkVCFTestSample/Benchmark/a2486748-6d71-463f-bf78-84627e64f2d1/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8485#issuecomment-1684837497:18330,monitor,monitoring,18330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8485#issuecomment-1684837497,1,['monitor'],['monitoring']
Energy Efficiency,"strated/beb77715-227e-4dbd-803f-4458c83607c8/call-CHMSampleHeadToHead/BenchmarkComparison/f1b0b4cf-1a3f-47b3-84fa-529f118419ce/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-CHMSampleHeadToHead/BenchmarkComparison/f1b0b4cf-1a3f-47b3-84fa-529f118419ce/call-BenchmarkVCFControlSample/Benchmark/fb68536c-eb99-4d0d-a5c3-4f5accf94546/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""84.94748611111112"",; ""CHM evalHCsystemhours"": ""0.19002777777777768"",; ""CHM evalHCwallclockhours"": ""61.06326111111111"",; ""CHM evalHCwallclockmax"": ""3.2047833333333333"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-CHMSampleHeadToHead/BenchmarkComparison/f1b0b4cf-1a3f-47b3-84fa-529f118419ce/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-CHMSampleHeadToHead/BenchmarkComparison/f1b0b4cf-1a3f-47b3-84fa-529f118419ce/call-BenchmarkVCFTestSample/Benchmark/4353eabb-b85f-4cce-a275-4dba68f9d644/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1546478988:18355,monitor,monitoring,18355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1546478988,1,['monitor'],['monitoring']
Energy Efficiency,"strated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-CHMSampleHeadToHead/BenchmarkComparison/394f0e4c-4f60-420b-8477-3199ef269728/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-CHMSampleHeadToHead/BenchmarkComparison/394f0e4c-4f60-420b-8477-3199ef269728/call-BenchmarkVCFControlSample/Benchmark/2aec499d-c11f-4a23-912b-8a61f9982437/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""86.06659722222223"",; ""CHM evalHCsystemhours"": ""0.19141388888888877"",; ""CHM evalHCwallclockhours"": ""60.83952500000001"",; ""CHM evalHCwallclockmax"": ""3.1510444444444445"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-CHMSampleHeadToHead/BenchmarkComparison/394f0e4c-4f60-420b-8477-3199ef269728/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-CHMSampleHeadToHead/BenchmarkComparison/394f0e4c-4f60-420b-8477-3199ef269728/call-BenchmarkVCFTestSample/Benchmark/02bfdee5-dde8-4c1d-b628-b21e4512fd42/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535665125:18360,monitor,monitoring,18360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535665125,1,['monitor'],['monitoring']
Energy Efficiency,sv.DataLine.get(DataLine.java:452); 	at org.broadinstitute.hellbender.utils.tsv.DataLine.get(DataLine.java:581); 	at org.broadinstitute.hellbender.tools.walkers.contamination.PileupSummary$PileupSummaryTableReader.createRecord(PileupSummary.java:193); 	at org.broadinstitute.hellbender.tools.walkers.contamination.PileupSummary$PileupSummaryTableReader.createRecord(PileupSummary.java:188); 	at org.broadinstitute.hellbender.utils.tsv.TableReader.fetchNextRecord(TableReader.java:364); 	at org.broadinstitute.hellbender.utils.tsv.TableReader.access$200(TableReader.java:99); 	at org.broadinstitute.hellbender.utils.tsv.TableReader$1.hasNext(TableReader.java:472); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.utils.tsv.TableReader.toList(TableReader.java:532); 	at org.broadinstitute.hellbender.tools.walkers.contamination.PileupSummary.readFromFile(PileupSummary.java:139); 	at org.broadinstitute.hellbender.tools.walkers.contamination.CalculateContamination.doWork(CalculateContamination.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7707:4443,Reduce,ReduceOps,4443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7707,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"t called or alleleLikelihoodMap is null; 00:10:45.460 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:11:09.609 WARN TaskMemoryManager:381 - leak 166.6 MB memory from org.apache.spark.util.collection.ExternalAppendOnlyMap@60a3c432; 00:11:09.611 ERROR Executor:91 - Exception in task 15.0 in stage 1.0 (TID 519); java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:192); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipelin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:1912,Reduce,ReduceOps,1912,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Reduce'],['ReduceOps']
Energy Efficiency,"t can go faster when given more RAM: going from; the earlier experimental envelope of 192GB of RAM to 256GB instead, the; bcast version can go from 19 min to 10min (sharded takes 7min with the; small amount of memory). This is consistent with my earlier experiments; that also showed that increasing the RAM-per-core sped up the bcast; computation. I wouldn't worry about having found a configuration where sharded performs; poorly. My experiments so far have shown that there are lots of; configuration points where one or the other performs poorly; the onus is on; finding the good configuration values that result in better performance, or; identifying which algorithms may be performant for a larger range of; parameter choices. To maximize understanding I would suggest that we not change too many; parameters at a time. For example it seems unnecessary to have multiple; variants of the 128Mbp input. I found there can be significant (>50%) variation between identical runs.; One way to reduce this is to set spark.task.maxFailures=1 which I strongly; recommend for all experiments going forward. One concern I have is that our cluster memory is already far larger than; the input size. In fact here each machine can fit the whole input; comfortably in RAM. This is not going to be the case for the full input.; Since it would take too long to iterate using the full input, it seems wise; instead to reduce both the input size and to keep a close eye on the amount; of memory we're using to make sure we're not going down a path that would; not be able to cope with the full input. On Wed, Nov 18, 2015 at 11:08 AM, droazen notifications@github.com wrote:. > I did some additional runs on the Broad cluster on a 14 GB bam, twice as; > large as the bam used in the plot above. This was with 60 cores, 4 cores; > per executor, and 16 GB of memory per executor. Results:; > ; > Broadcast (3 runs): 10m52.020s, 11m46.975s, 10m17.274s; > Sharded (3 runs): 19m33.310s, 13m36.466s, (died from out-of-me",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/995#issuecomment-157838734:1021,reduce,reduce,1021,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/995#issuecomment-157838734,1,['reduce'],['reduce']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1832); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1845); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1922); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1144); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIH,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:19324,schedul,scheduler,19324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3659:3674,schedul,scheduler,3674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:9192,schedul,scheduler,9192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:15612,schedul,scheduler,15612,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1661); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1649); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1648); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1648); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1882); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1820); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:4510,schedul,scheduler,4510,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); 	at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78); 	... 87 more; Caused by: java.util.ConcurrentModificationException; 	at java.util.ArrayList.sort(ArrayList.java:1464); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAsse,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:11449,schedul,scheduler,11449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,"t java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$transformToDuplicateNames$17d832cf$1(MarkDuplicatesSparkUtils.java:123); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:199); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). #### Steps to reproduce; Run the MarkDuplicatesSpark in a local SPARK cluster. The following function return a null, which cause the exception. public static String getLibrary( final GATKRead read, final SAMFileHeader header, String defaultLibrary) {; final SAMReadGroupRecord readGroup = getSAMReadGroupRecord(read, header);; String library = readGroup != null ? readGroup.getLibrary() : null;; return library==null? defaultLibrary : library;; }. public EmptyFragment(GATKRead read, SAMFileHeader header, Map<String, Byte> headerLibraryMap) {; super(0, null);; this.R1R = read.isReverseStrand();; this.key = ReadsKey.getKeyForFragment(ReadUtils.getStrandedUnclippedStart(read),; i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5169:4111,schedul,scheduler,4111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5169,1,['schedul'],['scheduler']
Energy Efficiency,"t java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$transformToDuplicateNames$17d832cf$1(MarkDuplicatesSparkUtils.java:123); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:199); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). #### Steps to reproduce; Run the MarkDuplicatesSpark in a local SPARK cluster. The following function return a null, which cause the exception. public static String getLibrary( final GATKRead read, final SAMFileHeader header, String defaultLibrary) {; final SAMReadGroupRecord readGroup = getSAMReadGroupRecord(read, header);; String library = readGroup != null ? readGroup.getLibrary() : null;; return library==null? defaultLibrary : library;; }. public EmptyFragment(GATKRead read, SAMFileHeader header, Map<String, Byte> headerLibraryMap) {; super(0, null);; this.R1R = read.isReverseStrand();; thi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5169:4031,schedul,scheduler,4031,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5169,1,['schedul'],['scheduler']
Energy Efficiency,t org.apache.hadoop.util.Shell.run(Shell.java:504); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:33502,schedul,scheduler,33502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,t org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:229); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:207); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); > at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); > at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); > at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); > at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); > at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); > at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); > at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); > at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); > at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.Iterator.forEachRemaining(Iterator.jav,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708:20156,Reduce,ReduceOps,20156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,t scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:8503,schedul,scheduler,8503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,"t through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1242,schedul,scheduler,1242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['schedul'],['scheduler']
Energy Efficiency,"t true; ; ; ; ; . However, the command fails with the error message below:. ; ; ; ; [October 14, 2021 at 12:20:24 PM CEST] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 16.57 minutes. ; Runtime.totalMemory()=1134559232 ; java.lang.IllegalStateException: Duplicate key Gencode\_34\_annotationTranscript (attempted merging values ENST00000450305.2 and ENST00000456328.2) ; at java.base/java.util.stream.Collectors.duplicateKeyException(Collectors.java:133) ; at java.base/java.util.stream.Collectors.lambda$uniqKeysMapAccumulator$1(Collectors.java:180) ; at java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; at java.base/java.util.HashMap$KeySpliterator.forEachRemaining(HashMap.java:1603) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.AlleleFrequencyUtils.lambda$buildMaxMafRule$1(AlleleFrequencyUtils.java:30) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.lambda$checkFilter$0(FuncotationFilter.java:48) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:2704,Reduce,ReduceOps,2704,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['Reduce'],['ReduceOps']
Energy Efficiency,"t$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); `. Can you give me some advice?; Thanks,; sun",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7001:2375,schedul,scheduler,2375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001,3,['schedul'],['scheduler']
Energy Efficiency,t(KryoSerializer.scala:246); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$8.apply(TorrentBroadcast.scala:293); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:294); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:226); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 21 more; Caused by: java.lang.UnsupportedOperationException; 	at shaded.cloud_nio.com.google.common.collect.ImmutableMap.put(ImmutableMap.java:407); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:162); 	at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	... 38 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545:9557,schedul,scheduler,9557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545,1,['schedul'],['scheduler']
Energy Efficiency,"t.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ```; #### Steps to reproduce; /gatk-4.0.12.0/gatk CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:18764,schedul,scheduler,18764,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,2,['schedul'],['scheduler']
Energy Efficiency,t.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.disq_bio.disq.impl.formats.sam.AnySamSinkMultiple.lambda$save$bddeb71b$1(AnySamSinkMultiple.java:91); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: com.esotericsoftware.kryo.KryoException: java.lang.UnsupportedOperationException; Serialization trace:; requestOptions (com.google.cloud.storage.BlobReadChannel); channel (com.google.cloud.storage.contrib.nio.CloudStorageReadChannel); channel (htsjdk.samtools.reference.IndexedFastaSequenceFile); rsFile (htsjdk.samtools.cram.ref.ReferenceSource); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:144); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esoteric,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545:1891,schedul,scheduler,1891,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545,2,['schedul'],['scheduler']
Energy Efficiency,"tMissingTasks(DAGScheduler.scala:1501) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; 11:00:54.078 INFO AbstractConnector - Stopped Spark@2f829853{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}; 11:00:54.091 INFO SparkUI - Stopped Spark web UI at http://172.20.19.130:4040; 11:00:54.122 INFO MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!; 11:00:54.175 INFO MemoryStore - MemoryStore cleared; 11:00:54.175 INFO BlockManager - BlockManager stopped; 11:00:54.193 INFO BlockManagerMaster - BlockManagerMaster stopped; 11:00:54.211 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!; 11:00:54.302 INFO SparkContext - Successfully stopped SparkContext; 11:00:54.303 INFO S",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:23577,schedul,scheduler,23577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,tMissingTasks(DAGScheduler.scala:1523) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.SparkContext.runJob(SparkContext.scala:2228) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.SparkContext.runJob(SparkContext.scala:2249) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.SparkContext.runJob(SparkContext.scala:2281) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsNewAPIHadoopData,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:14645,schedul,scheduler,14645,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"tOutputStream.java:1572); at java.base/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1529); at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). 11:00:53.977 INFO DAGScheduler - Job 1 failed: runJob at SparkHadoopWriter.scala:83, took 3.799268 s; 11:00:53.979 ERROR SparkHadoopWriter - Aborting job job_202408111100502620487673658411251_0021.; org.apache.spark.SparkException: Job aborted due to stage failure: Task serialization failed: java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; at java.base/jdk.internal.util.ArraysSupport.h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:7887,schedul,scheduler,7887,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,tOutputStream.java:1572); at java.base/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1529); at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) ~[gatk-packa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:12211,schedul,scheduler,12211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,tOutputStream.java:1572); at java.base/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1529); at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:30930,schedul,scheduler,30930,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,tOutputStream.java:1572); at java.base/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1529); at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 11:00:54.334 INFO ShutdownHookManager - Shutdown hook called; 11:00:54.335 INFO ShutdownHookManager - Deleting directory /raid/tmp/d6/c66ba827e22dbc38625af1cbc85adc/tmp/spark-f9c7c336-4e98-4fcc-855b-ba8a5a29e074; ```. The first lines of the log file:; ```; vm.max_map_count = 2147483642; Using GATK jar /Public/Everythings/misc/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:36801,schedul,scheduler,36801,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"tReadsSpark - Inflater: IntelInflater; 13:13:13.004 INFO CountReadsSpark - GCS max retries/reopens: 20; 13:13:13.004 INFO CountReadsSpark - Requester pays: disabled; 13:13:13.005 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:13:13.005 INFO CountReadsSpark - Initializing engine; 13:13:13.005 INFO CountReadsSpark - Done initializing engine; 18/12/21 13:13:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/12/21 13:13:16 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 18/12/21 13:13:19 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; [Stage 0:> (0 + 2) / 155]18/12/21 13:13:57 WARN scheduler.TaskSetManager: Lost task 10.0 in stage 0.0 (TID 1, scc-q15.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 2485550, span 40026, expected MD5 106b97c463c8a19ce0f92bbd488ac81d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:11",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:4454,schedul,scheduler,4454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,"tanode:; image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - datanode:/hadoop/dfs/data; environment:; SERVICE_PRECONDITION: ""namenode:50070""; # depends_on:; # - namenode; env_file:; - ./hadoop.env; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50075. volumes:; datanode:; namenode:. networks:; workbench:; external: true; ```; the datanodes and namenode and spark master and workers are all working.; My hardware resources are:; 16 core and 1Tb memory ssd and 56Gb ram for 3 machines. I have this problem when I launch the version(GATK) v4.0.4.0 but not with this version v4.0.2.0-4-gb59d863-SNAPSHOT:. >java.lang.IllegalStateException: Duplicate key -1; 	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); 	at java.util.HashMap.merge(HashMap.java:1253); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$mark$2142e97f$1(MarkDuplicatesSpark.java:82); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89); 	at org.apache.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:3817,Reduce,ReduceOps,3817,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['Reduce'],['ReduceOps']
Energy Efficiency,"tasks have all completed, from pool; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Stage 0 (aggregate at TransformTranslator.java:183) finished in 0.416 s; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at TransformTranslator.java:183, took 0.607813 s; 15/07/14 13:14:53 INFO spark.SparkPipelineRunner: Evaluating AnonymousParDo [ParDo]; 15/07/14 13:14:53 INFO spark.SparkPipelineRunner: Evaluating TextIO.Write [TextIO.Write]; 15/07/14 13:14:53 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at TransformTranslator.java:432; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Got job 1 (saveAsNewAPIHadoopFile at TransformTranslator.java:432) with 1 output partitions (allowLocal=false); 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Final stage: Stage 1(saveAsNewAPIHadoopFile at TransformTranslator.java:432); 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Parents of final stage: List(); 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Missing parents: List(); 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Submitting Stage 1 (MapPartitionsRDD[8] at mapToPair at TransformTranslator.java:405), which has no missing parents; 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(11824) called with curMem=10409, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.5 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(7006) called with curMem=22233, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.8 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:65240 (size: 6.8 KB, free: 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerMaster: Updated info of block broadcast_1_piece0; 15/07/14 13:14:53 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:839; 15/07/14 13:14",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:26320,schedul,scheduler,26320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['schedul'],['scheduler']
Energy Efficiency,tationFactory.java:529); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.S,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036:9713,Reduce,ReduceOps,9713,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,tationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:152); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:924); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.S,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653:4749,Reduce,ReduceOps,4749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"te 2975,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3141,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3256,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3330,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3413,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3443,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3534,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3564,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3594,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3662,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3720,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3818,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 4256,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 297,249856 /BaseQRankSum.tdb. Note the following about the above I/O:. - The position (the 2nd number) is *NOT* changing, so each write seeks to a position and overwrites that block; - As a result the previous 34 writes are thrown away and are useless, only the 35th write makes it to the resulting file.; - Even the last IO of 4256 bytes, only moves the position up by 4096 bytes.; - This problem turns a relatively I/O friendly sequential workload turns into a bunch of tiny writes with seeks for each one. *TERRIBLE* for spinning disks. The solution I propose is just to have two 64KB buffers and only write 64KB when the first buffer is full with the overflow going into the second buffer. This would not only eliminate the seeks, but also reduce the IOP rate by a factor of 600-700 and change this random workload to a mostly sequential. I can write an example code that outputs 100 bytes into a buffer and then writes 64KB at a time if that's helpful.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6487#issuecomment-595367364:3889,reduce,reduce,3889,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6487#issuecomment-595367364,1,['reduce'],['reduce']
Energy Efficiency,"ted at http://10.131.101.159:4040; 17/10/13 18:11:34 INFO spark.SparkContext: Added JAR file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar at spark://10.131.101.159:45754/jars/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar with timestamp 1507889494965; 17/10/13 18:11:35 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances; 17/10/13 18:11:35 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/10/13 18:11:36 INFO client.RMProxy: Connecting to ResourceManager at mg/10.131.101.159:8032; 17/10/13 18:11:36 INFO yarn.Client: Requesting a new application from cluster with 3 NodeManagers; 17/10/13 18:11:36 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (164726 MB per container); 17/10/13 18:11:36 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/13 18:11:36 INFO yarn.Client: Setting up container launch context for our AM; 17/10/13 18:11:36 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/13 18:11:36 INFO yarn.Client: Preparing resources for our AM container; 17/10/13 18:11:37 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-c7e5eece-205e-4bce-a69b-4168c9b79045/__spark_conf__2918234914787361986.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507856833944_0003/__spark_conf__.zip; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing view acls groups to: ; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing modify acls groups to: ; 17/10/13 18:11:37 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); groups with view pe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:9962,allocate,allocate,9962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['allocate'],['allocate']
Energy Efficiency,"ter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more. Driver stacktrace:; 21/04/13 07:32:25 INFO DAGScheduler: Job 2 failed: runJob at SparkHadoopWriter.scala:78, took 0.365288 s; 21/04/13 07:32:25 ERROR SparkHadoopWriter: Aborting job job_20210413073224_0026.; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 105, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Sequence [VC HC @ chr4_GL000008v2_random:7168-7691 Q. of type=SYMBOLIC alleles=[T*, <NON_REF>] attr={END=7691} GT=[[NA12878 T*/T* GQ 0 DP 0 PL 0,0,0 {MIN_DP=0}]] filters= added out of order currentReferenceIndex: 25, referenceIndex:37; at htsjdk.tribble.index.tabix.AllRefsTabixIndexCreator.addFeature(AllRefsTabixIndexCreator.java:79); at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:203); at htsjdk.variant.variantconte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:14618,schedul,scheduler,14618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,"terator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at org.apache.spark.storage.BlockManager.reportAllBlocks(BlockManager.scala:217); 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:236); 	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:522); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); 	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308); 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180); 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 17/10/18 17:35:58 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/10/18 17:35:58 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-1,5,main]; java.lang.OutOfMemoryError: Java heap space; 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:208); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtoo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:5472,Schedul,ScheduledThreadPoolExecutor,5472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,2,['Schedul'],"['ScheduledFutureTask', 'ScheduledThreadPoolExecutor']"
Energy Efficiency,"ternal:8020/user/hadoop/.sparkStaging/application_1554748821802_0005/hive-site.xml; 19/04/08 19:01:48 INFO Client: Uploading resource file:/mnt/tmp/spark-ada67a34-2db0-488c-adf5-7e4607fe989f/__spark_conf__2453357125414211656.zip -> hdfs://ip-xx.xx.xx.xx.ec2.internal:8020/user/hadoop/.sparkStaging/application_1554748821802_0005/__spark_conf__.zip; 19/04/08 19:01:48 INFO SecurityManager: Changing view acls to: hadoop; 19/04/08 19:01:48 INFO SecurityManager: Changing modify acls to: hadoop; 19/04/08 19:01:48 INFO SecurityManager: Changing view acls groups to: ; 19/04/08 19:01:48 INFO SecurityManager: Changing modify acls groups to: ; 19/04/08 19:01:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hadoop); groups with view permissions: Set(); users with modify permissions: Set(hadoop); groups with modify permissions: Set(); 19/04/08 19:01:48 INFO Client: Submitting application application_1554748821802_0005 to ResourceManager; 19/04/08 19:01:48 INFO YarnClientImpl: Submitted application application_1554748821802_0005; 19/04/08 19:01:48 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1554748821802_0005 and attemptId None; 19/04/08 19:01:49 INFO Client: Application report for application_1554748821802_0005 (state: ACCEPTED); 19/04/08 19:01:49 INFO Client: ; 	 client token: N/A; 	 diagnostics: AM container is launched, waiting for AM container to Register with RM; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start time: 1554750108216; 	 final status: UNDEFINED; 	 tracking URL: http://ip-xx.xx.xx.xx.ec2.internal:20888/proxy/application_1554748821802_0005/; 	 user: hadoop; 19/04/08 19:01:50 INFO Client: Application report for application_1554748821802_0005 (state: ACCEPTED); 19/04/08 19:01:51 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-xx.xx.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869:8675,Schedul,SchedulerExtensionServices,8675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869,1,['Schedul'],['SchedulerExtensionServices']
Energy Efficiency,"tests are green, merging.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/913#issuecomment-144183847:10,green,green,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/913#issuecomment-144183847,2,['green'],['green']
Energy Efficiency,tests green; squished and rebased. Clear to merge as soon as tests turn green again.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/987#issuecomment-148558764:6,green,green,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/987#issuecomment-148558764,2,['green'],['green']
Energy Efficiency,"tests will now run as cloud, integration, and unit on travis; this reduces our wallclock time from 30ish -> 20ish minutes. cleaned up some wierdness in the way things were specified as well",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2399:67,reduce,reduces,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2399,1,['reduce'],['reduces']
Energy Efficiency,"th 1 tasks; 17/10/13 18:11:45 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1); 17/10/13 18:11:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.131.101.145:54024) with ID 1; 17/10/13 18:11:48 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1); 17/10/13 18:11:48 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 4877 bytes); 17/10/13 18:11:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:45501 with 366.3 MB RAM, BlockManagerId(1, com2, 45501, None); 17/10/13 18:11:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:45501 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:51 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:45501 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4638 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.668 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: running: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: failed: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.8 KB, free 365.9 MB); 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:18905,schedul,scheduler,18905,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['schedul'],['scheduler']
Energy Efficiency,thanks @jmthibault79 so it's a bug. ; @vdauwera why is this not scheduled for GATK3? Is it too hard to fix there?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/265#issuecomment-99308481:64,schedul,scheduled,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/265#issuecomment-99308481,1,['schedul'],['scheduled']
Energy Efficiency,"the number of reducers seems to be pretty irrelevant. I ran ReadsPipelineSpark on a 35GB file, with 60 executors, 1 CPU per exec, 7 GB per exec. 60 reducers -> 18 min first tree aggregate, > 12 mins on save, I killed it after that; 270 reducers -> 13 mins first tree aggregate, 5.5 min save; 1000 reducers -> 11 min first tree aggregate, 5.0 min save; 2000 reducers -> 11 min first tree aggregate, 5.1 min save; 3539 reducers -> 11 min first treeAgg, 5.9 min save",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1660#issuecomment-210267609:14,reduce,reducers,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1660#issuecomment-210267609,6,['reduce'],['reducers']
Energy Efficiency,the requirement is to make MD fully work in a tested way (all Picard integration tests must work - perhaps by comparing the sets of reads that got marked as 'duplicate'). Note: we'll migrate this code from genomics-pipeline and adapt it to our needs and style.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/488:228,adapt,adapt,228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/488,1,['adapt'],['adapt']
Energy Efficiency,"the same bam file on different machines. Additionally, vanilla BaseRecalibrator works just fine on these bams (so I don't think the issue is with the bam). They are all suffering from the same/similar stacktrace. We've had BaseRecalibratorSpark work fine on other bam files. Additionally, changing the number of threads still results in the same stacktrace. I've also tried running the BQSRPipelineSpark to see if that would suffer the same issue and it fails in the same manner. Additionally, I've run ValidateSamFile. There are some reads missing their mates, but this hasn't presented an issue in other tools (including vanilla BaseRecalibrator). Searching thru the forum, I found an old issue with a similar stacktrace, but that issue appears to occur in GATK 2.4: https://gatkforums.broadinstitute.org/gatk/discussion/3265/bqsrgatherer-exception. In the below stacktrace, I've bolded the error message that seems to occur in each of these samples. `Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:1262,schedul,scheduler,1262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['schedul'],['scheduler']
Energy Efficiency,"the single node. Because, we have 32 cores per node with 512GB memory available for benchmarking. To parallelize the GATK 4 workload, I used the Spark version also. . I used **GATK 4 Beta2 Spark job on the cluster of 32 nodes** (32 nodes x 32 cores, totaling 1024 cores). The execution time is almost same as GATK 4 Beta2 ( 50 Hours, 21 min). Please help me, how to reduce the execution time for GATK 4 Beta2 HaplotypeCaller? . Please see this below Spark logs:. + /gpfs/software/spark/spark-2.1.0-bin-hadoop2.7//bin/spark-submit --master spark://nsnode11:6311 --driver-java-options -Dsamjdk.use_async_io_read_samtools=false,-Dsamjdk.use_async_io_write_samtools=true,-Dsamjdk.use_async_io_write_tribble=false,-Dsamjdk.compression_level=1 --conf spark.io.compression.codec=snappy --conf spark.yarn.executor.memoryOverhead=6000 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.userClassPathFirst=true --conf spark.driver.maxResultSize=0 --conf spark.executor.cores=1024 --conf spark.reducer.maxSizeInFlight=100m --conf spark.shuffle.file.buffer=512k --conf spark.akka.frameSize=512 --conf spark.akka.threads=10 --conf spark.executor.memory=50g --conf spark.driver.memory=150g --conf spark.local.dir=/gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2Spark/1024cores/tmp --class org.broadinstitute.hellbender.Main /gpfs/software/genomics/GATK/4b.2/gatk/build/libs/hellbender-spark.jar HaplotypeCaller --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa --input /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4b2/bam//NA12892.recal.bam --dbsnp /gpfs/projects/NAGA/naga/SparkTest/SPARKCALLER/REF/dbsnp_138.vcf --emitRefConfidence GVCF --readValidationStringency LENIENT --nativePairHmmThreads 1024 --createOutputVariantIndex true --output NA12892.raw.snps.indels.g.vcf; [August 9, 2017 10:13:02 AM AST] HaplotypeCaller --nativePairHmmThreads 1024 --dbsnp /gpfs/projects/NAGA/naga/SparkTest/SPARKCALLER/REF/dbsnp_138.vcf --emitRefConfidence GVCF --o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3631:2500,reduce,reducer,2500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631,1,['reduce'],['reducer']
Energy Efficiency,this allows you to convert RAW_MQ -> MQ ; this is not a general port of the reducible annotation's reducers,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2524:99,reduce,reducers,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2524,1,['reduce'],['reducers']
Energy Efficiency,"this includes the new VCF2TileDB java API; replacing process builder calls to GenomicsDB binaries with usage of VCF2TileDB api in GenomicsDBTestUtils. these tests will likely now fail on power systems since GenomicsDB doesn't bundle a power library, power users should build genomics db and specify it's path on the LD_PATH",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2106:187,power,power,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2106,3,['power'],['power']
Energy Efficiency,"this is a script which can be used after running gradle installDist to run spark jobs; it can be used identically to ths build/install/bin/gatk script, but has extra features for dealing with spark. running a spark tool and supplying the option --sparkTarget with LOCAL, CLUSTER, or GCS has special behavior; LOCAL will run the tool in the in memory spark runner; CLUSTER along with an appropriate --sparkMaster will run on an accessible spark cluster using spark-submit; arguments to spark-submit may be specified before the arguments to GATK by separating them with a --; GCS will submit jobs to google dataproc using gcloud; common arguments for spark submit will be adapted to match the gcloud formating; this will fail if gcloud isn't installed. if GATK_GCS_STAGING is specified, the jar will be uploaded and cached in the specified bucket for rapid re-use. input files will not be autouploaded to the cloud. --dry-run may be specified before the --, this will only print the commands that will be run instead of actually running them. Adding DataProcArgumentReplace simple tool to convert spark-submit args into gcloud args.; This conversion is not guarenteed to translate all spark command line options to matching gcloud ones.; If you find options that are not translated or are miss-translated please file an issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1211:670,adapt,adapted,670,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1211,1,['adapt'],['adapted']
Energy Efficiency,this is also nice for viewing those logs: http://gceasy.io/diamondGC. I'm running ApplyBQSR here on a file >100GB. GATK4 has much smaller consumption (but I need to rerun with -Xmx3.5G because this run here had almost unlimited memory). Here's the GATK4 plot: note that peak is 2.38GB; ![image](https://cloud.githubusercontent.com/assets/1993519/13834462/ae6bffac-ebc5-11e5-80b3-7898022d1cea.png). and same for GATK3 - peak was almost 18GB. ; ![image](https://cloud.githubusercontent.com/assets/1993519/13834527/276910ca-ebc6-11e5-8061-9dda95e848be.png),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-197659822:138,consumption,consumption,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-197659822,1,['consumption'],['consumption']
Energy Efficiency,this will enable use of composite gradle builds which should reduce development pain,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2227:61,reduce,reduce,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2227,1,['reduce'],['reduce']
Energy Efficiency,those came up clearly on HaplotypeCaller profiles and allocated many megabytes of objects for now reason,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1795:54,allocate,allocated,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1795,1,['allocate'],['allocated']
Energy Efficiency,til.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:647); 	at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.lambda$apply$6ed74b3e$1(BaseRecalibratorSparkFn.java:33); 	at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn$$Lambda$635/777640102.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). I will be greateful for your help,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7796:3108,schedul,scheduler,3108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7796,3,['schedul'],['scheduler']
Energy Efficiency,"til/ChildFirstURLClassLoader) of the current class, org/broadinstitute/hellbender/tools/spark/pipelines/FlagStatSpark, and the class loader (instance of org/apache/spark/util/ChildFirstURLClassLoader) for the method's defining class, org/broadinstitute/hellbender/tools/FlagStat$FlagStatus, have different Class objects for the type org/broadinstitute/hellbender/utils/read/GATKRead used in the signature; at java.lang.invoke.MethodHandleNatives.resolve(Native Method); at java.lang.invoke.MemberName$Factory.resolve(MemberName.java:965); at java.lang.invoke.MemberName$Factory.resolveOrFail(MemberName.java:990); at java.lang.invoke.MethodHandles$Lookup.resolveOrFail(MethodHandles.java:1387); at java.lang.invoke.MethodHandles$Lookup.linkMethodHandleConstant(MethodHandles.java:1739); at java.lang.invoke.MethodHandleNatives.linkMethodHandleConstant(MethodHandleNatives.java:442); ... 41 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1273); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1264); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1263); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1263); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730); at scala.Option.foreach(Option.scala:236); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:730); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1457); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1315:5107,schedul,scheduler,5107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1315,1,['schedul'],['scheduler']
Energy Efficiency,"times, most recent failure: Lost task 8.0 in stage 1.0 (TID 345, localhost): java.lang.ArrayI; ndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:7398,schedul,scheduler,7398,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['schedul'],['scheduler']
Energy Efficiency,"titionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); 18/10/17 19:23:59 WARN TaskSetManager: Lost task 517.0 in stage 0.0 (TID 517, localhost, executor driver): org.broadinstitute.hellbender.exceptions.UserException$NoSuitableCodecs: Cannot read /dev/shm/gatktmp/spark-30e238e4-b1b7-41f9-b31e-844f16879051/userFiles-4621c82d-5f86-4b51-9321-ccc84ab49979/dbsnp_138.hg19.vcf because no suitable codecs found; 	at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:462); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:7609,schedul,scheduler,7609,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,1,['schedul'],['scheduler']
Energy Efficiency,titute.hellbender.tools.exome.cnlohcaller.CNLOHCaller.calculateResponsibilities(CNLOHCaller.java:538); 	at org.broadinstitute.hellbender.tools.exome.cnlohcaller.CNLOHCaller.lambda$makeCalls$cbed43a$1(CNLOHCaller.java:307); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1015); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); 	at scala.collection.Iterator$class.foreach(Iterator.scala:727); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273); 	at scala.collection.AbstractIterator.to(Iterator.scala:1157); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:927); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:927); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1858); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1858); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2972:2021,schedul,scheduler,2021,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2972,2,['schedul'],['scheduler']
Energy Efficiency,titute.hellbender.tools.funcotator.FuncotationMap.createAsAllTableFuncotationsFromVcf(FuncotationMap.java:224) ; ; Â  Â  at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.lambda$createAlleleToFuncotationMapFromFuncotationVcfAttribute$5(FuncotatorUtils.java:2256) ; ; Â  Â  at java.base/java.util.stream.Collectors.lambda$uniqKeysMapAccumulator$1(Collectors.java:178) ; ; Â  Â  at java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; ; Â  Â  at java.base/java.util.stream.IntPipeline$1$1.accept(IntPipeline.java:180) ; ; Â  Â  at java.base/java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:104) ; ; Â  Â  at java.base/java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:699) ; ; Â  Â  at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; ; Â  Â  at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; ; Â  Â  at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; ; Â  Â  at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; Â  Â  at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; ; Â  Â  at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createAlleleToFuncotationMapFromFuncotationVcfAttribute(FuncotatorUtils.java:2255) ; ; Â  Â  at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.ArHetvarFilter.buildArHetByGene(ArHetvarFilter.java:77) ; ; Â  Â  at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.ArHetvarFilter.firstPassApply(ArHetvarFilter.java:50) ; ; Â  Â  at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.firstPassApply(FilterFuncotations.java:161) ; ; Â  Â  at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:17) ; ; Â  Â  at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; ; Â  Â  at org.bro,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7865:8054,Reduce,ReduceOps,8054,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7865,1,['Reduce'],['ReduceOps']
Energy Efficiency,"titute/gatk/pull/2566?src=pr&el=h1) Report; > Merging [#2566](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/6859a1202a79c1b123eac73a3f70162c6a90783c?src=pr&el=desc) will **decrease** coverage by `0.015%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2566 +/- ##; ==============================================; - Coverage 76.386% 76.37% -0.015% ; + Complexity 10898 10895 -3 ; ==============================================; Files 754 754 ; Lines 39552 39552 ; Branches 6907 6907 ; ==============================================; - Hits 30212 30206 -6 ; - Misses 6727 6732 +5 ; - Partials 2613 2614 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...ellbender/utils/test/CommandLineProgramTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0NvbW1hbmRMaW5lUHJvZ3JhbVRlc3Rlci5qYXZh) | `85.714% <0%> (-4.762%)` | `7% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/GenomeLocParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2NQYXJzZXIuamF2YQ==) | `85.95% <0%> (-4.132%)` | `55% <0%> (-2%)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=footer). Last update [6859a12...1df1909](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2566#issuecomment-291909459:1766,Power,Powered,1766,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2566#issuecomment-291909459,1,['Power'],['Powered']
Energy Efficiency,"titute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `89.33% <50%> (+1.17%)` | `43 <3> (Ã¸)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.23% <0%> (-2.74%)` | `11% <0%> (Ã¸)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `89.27% <0%> (-0.39%)` | `73% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+3.22%)` | `39% <0%> (Ã¸)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+40%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=footer). Last update [e12034a...af94877](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4139#issuecomment-358285781:4584,Power,Powered,4584,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4139#issuecomment-358285781,1,['Power'],['Powered']
Energy Efficiency,tor$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:14381,schedul,scheduler,14381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,"tor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 779 bytes result sent to driver; 15/07/14 13:14:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 403 ms on localhost (1/1); 15/07/14 13:14:53 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Stage 0 (aggregate at TransformTranslator.java:183) finished in 0.416 s; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at TransformTranslator.java:183, took 0.607813 s; 15/07/14 13:14:53 INFO spark.SparkPipelineRunner: Evaluating AnonymousParDo [ParDo]; 15/07/14 13:14:53 INFO spark.SparkPipelineRunner: Evaluating TextIO.Write [TextIO.Write]; 15/07/14 13:14:53 INFO spark.SparkContext: Starting job: saveAsNewAPIHadoopFile at TransformTranslator.java:432; 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Got job 1 (saveAsNewAPIHadoopFile at TransformTranslator.java:432) with 1 output partitions (allowLocal=false); 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Final stage: Stage 1(saveAsNewAPIHadoopFile at TransformTranslator.java:432); 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Parents of final stage: List(); 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Missing parents: List(); 15/07/14 13:14:53 INFO scheduler.DAGScheduler: Submitting Stage 1 (MapPartitionsRDD[8] at mapToPair at TransformTranslator.java:405), which has no missing parents; 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(11824) called with curMem=10409, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.5 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.MemoryStore: ensureFreeSpace(7006) called with curMem=22233, maxMem=278019440; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.8 KB, free 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerInfo: Added broadcas",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:26044,schedul,scheduler,26044,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['schedul'],['scheduler']
Energy Efficiency,tor.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653:3277,Reduce,ReduceOps,3277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653,1,['Reduce'],['ReduceOps']
Energy Efficiency,"tor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:262); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615); 	at java.lang.Thread.run(Thread.java:745). Container exited with a non-zero exit code 1. 18/01/09 18:31:21 INFO storage.BlockManagerMaster: Removal of executor 9 requested; 18/01/09 18:31:21 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 9; 18/01/09 18:31:21 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 9 from BlockManagerMaster.; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms); 18/01/09 18:31:26 INFO server.AbstractConnector: Stopped Spark@283ab206{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/09 18:31:26 INFO ui.SparkUI: Stopped Spark web UI at http://192.168.1.4:4040; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/01/09 18:31:26 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/01/09 18:31:26 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/01/09 18:31:26 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/01/09 18:31:26 INFO memory.MemoryStore: MemoryStore cleared; 18/01/09 18:31:26 INFO storage.BlockManager: BlockManager stopped; 18/01/09 18:31:26 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:29694,Schedul,SchedulerBackend,29694,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,2,"['Schedul', 'schedul']","['SchedulerBackend', 'scheduling']"
Energy Efficiency,"torAllocationManager: New executor 1 has registered (new total is 1); 17/10/13 18:11:48 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 4877 bytes); 17/10/13 18:11:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:45501 with 366.3 MB RAM, BlockManagerId(1, com2, 45501, None); 17/10/13 18:11:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:45501 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:51 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:45501 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4638 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.668 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: running: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: failed: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.8 KB, free 365.9 MB); 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KB, free 365.8 MB); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:44818 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitt",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:19264,schedul,scheduler,19264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['schedul'],['scheduler']
Energy Efficiency,"toutput.bam` as the problem, but why that's causing a problem under yarn is mysterious. ```; caused by: java.io.IOException: Mkdirs failed to create file:/home/unix/louisb/writeable/testoutput.bam/_temporary/0/_temporary/attempt_201601291710_0020_r_000000_3 (exists=false, cwd=file:/mnt/disk10/yarn/nm/usercache/louisb/appcache/application_1452219145116_0780/container_1452219145116_0780_01_000002); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:442); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:428); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:917); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:898); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:795); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:784); at org.seqdoop.hadoop_bam.BAMRecordWriter.<init>(BAMRecordWriter.java:74); at org.seqdoop.hadoop_bam.KeyIgnoringBAMRecordWriter.<init>(KeyIgnoringBAMRecordWriter.java:49); at org.seqdoop.hadoop_bam.KeyIgnoringBAMOutputFormat.getRecordWriter(KeyIgnoringBAMOutputFormat.java:91); at org.seqdoop.hadoop_bam.KeyIgnoringBAMOutputFormat.getRecordWriter(KeyIgnoringBAMOutputFormat.java:79); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$SparkBAMOutputFormat.getRecordWriter(ReadsSparkSink.java:65); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1$$anonfun$12.apply(PairRDDFunctions.scala:1030); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1$$anonfun$12.apply(PairRDDFunctions.scala:1014); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); at org.apache.spark.scheduler.Task.run(Task.scala:88); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1451#issuecomment-176996853:1773,schedul,scheduler,1773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1451#issuecomment-176996853,2,['schedul'],['scheduler']
Energy Efficiency,tps://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F46696E6442616447656E6F6D69634B6D657273537061726B2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 71% | [...nder/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F46696E64427265616B706F696E7445766964656E6365537061726B2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 90% | *new* [...ellbender/tools/spark/sv/SVDUSTFilteredKmerizer.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53564455535446696C74657265644B6D6572697A65722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...broadinstitute/hellbender/tools/spark/sv/SVKmer.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53564B6D65722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...institute/hellbender/tools/spark/sv/SVConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F5356436F6E7374616E74732E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...dinstitute/hellbender/tools/spark/sv/SVKmerLong.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53564B6D65724C6F6E672E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [f72f9da...5782fa3](https://codecov.io/gh/broadinstitute/gatk/compare/f72f9dae42824175b047d9c46c89a9d919ea8dc1...5782fa36a142b2daceed6686d822f935cdb968c0?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2348#issuecomment-273320758:3461,Power,Powered,3461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2348#issuecomment-273320758,1,['Power'],['Powered']
Energy Efficiency,travis support recommended that we move to travis with sudo since the capacity problems have been fixed; the travis nodes with sudo are more powerful now and there shouldn't be long startup delays like there used to be; also moving to the newer ubuntu image,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1602:141,power,powerful,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1602,1,['power'],['powerful']
Energy Efficiency,tream.defaultReadFields(ObjectInputStream.java:2227); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2151); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2009); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1533); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:420); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:298); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:6161,schedul,scheduler,6161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['schedul'],['scheduler']
Energy Efficiency,tream.defaultReadFields(ObjectInputStream.java:2245); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:309); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:18960,schedul,scheduler,18960,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['schedul'],['scheduler']
Energy Efficiency,"tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `89.88% <66.66%> (-1.26%)` | `63 <3> (+3)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (Ã¸)` | `2% <0%> (Ã¸)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `81.09% <0%> (+0.6%)` | `42% <0%> (Ã¸)` | :arrow_down: |; | [...walkers/haplotypecaller/AssemblyRegionTrimmer.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseVJlZ2lvblRyaW1tZXIuamF2YQ==) | `62.72% <0%> (+2.72%)` | `20% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5442?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5442?src=pr&el=footer). Last update [9c4a27b...bf39362](https://codecov.io/gh/broadinstitute/gatk/pull/5442?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5442#issuecomment-440776502:3910,Power,Powered,3910,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5442#issuecomment-440776502,1,['Power'],['Powered']
Energy Efficiency,"ts header (either proactively or on demand), but transparently to ; application code that is running against the SAMRecord API.; This would allow SAM headers to be transmitted out-of-band in a way that ; depends on the execution environment. Depending on the environment, ; this might be done by proactive broadcast, or you could think of the ; header tag as a promise to retrieve the header if/when it is needed. ; The size and complexity of the header tag might also depend on the ; execution environment. If the execution environment only supports a ; small finite number of headers, the header tag could be a small integer, ; or in a different execution environment it could be; a unique hash of the header or something like that. Memory footprint in ; the receiver is minimized because many SAMRecords can all share the same ; header object.; This requires more work to support in each execution environment, but it ; seems like it could be efficient and allows application code written to ; operate on SAMRecords to be portable; across different execution environments without having to contend with ; the possible presence of headerless SAMRecords. -Bob. On 9/17/15 4:28 PM, droazen wrote:. > @davidadamsphd https://github.com/davidadamsphd, @lbergelson ; > https://github.com/lbergelson, and myself met for an hour or two ; > just now to discuss this issue, and after reviewing all the options I ; > think we were convinced by the following argument:; > ; > The |SAMRecord| class currently allows its header to be set to null, ; > so if there are cases where the class won't function properly or can ; > enter into an inconsistent state when a header is not present these ; > should be treated as bugs and patched, and we should add unit tests to ; > htsjdk to prove that headerless |SAMRecords| function properly. Then ; > in hellbender we can freely use headerless |SAMRecords| everywhere, ; > only restoring the header to the record when writing out the final bam ; > (since our bam writers",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518:2515,efficient,efficient,2515,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518,1,['efficient'],['efficient']
Energy Efficiency,tureInput(FeatureDataSource.java:324); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:304); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:256); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:230); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:214); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadChec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855:3001,Reduce,ReduceOps,3001,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,tworks:; workbench:; external: true; ```; the datanodes and namenode and spark master and workers are all working.; My hardware resources are:; 16 core and 1Tb memory ssd and 56Gb ram for 3 machines. I have this problem when I launch the version(GATK) v4.0.4.0 but not with this version v4.0.2.0-4-gb59d863-SNAPSHOT:. >java.lang.IllegalStateException: Duplicate key -1; 	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); 	at java.util.HashMap.merge(HashMap.java:1253); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$mark$2142e97f$1(MarkDuplicatesSpark.java:82); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:4234,Reduce,ReduceOps,4234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['Reduce'],['ReduceOps']
Energy Efficiency,"typeCallerSpark, we ran into an edge case where it will die on regions not containing any reads, with a empty collection error. It would be great if we could catch this cleanly and generate a VCF without any calls. Here is a small self contained test case which demonstrates the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_hcspark_noreads.tar.gz. and the full error message:; ```; java.lang.UnsupportedOperationException: empty collection; at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$apply$35.apply(RDD.scala:1004); at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$apply$35.apply(RDD.scala:1004); at scala.Option.getOrElse(Option.scala:121); at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1004); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.reduce(RDD.scala:984); at org.apache.spark.api.java.JavaRDDLike$class.reduce(JavaRDDLike.scala:384); at org.apache.spark.api.java.AbstractJavaRDDLike.reduce(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.callVariantsWithHaplotypeCaller(HaplotypeCallerSpark.java:229); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.callVariantsWithHaplotypeCallerAndWriteOutput(HaplotypeCallerSpark.java:182); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.runTool(HaplotypeCallerSpark.java:143); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:387); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.C",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4234:1050,reduce,reduce,1050,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4234,1,['reduce'],['reduce']
Energy Efficiency,"u.edu, 42456, None); 18/03/07 13:24:27 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 247.0 KB, free 8.4 GB); 18/03/07 13:24:28 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.5 KB, free 8.4 GB); 18/03/07 13:24:28 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:32895 (size: 25.5 KB, free: 8.4 GB); 18/03/07 13:24:28 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 13:24:28 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7164 for farrell on ha-hdfs:scc; 18/03/07 13:24:28 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7164 for farrell); 18/03/07 13:24:28 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 13:59:26 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 fr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:1845,schedul,scheduler,1845,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304,1,['schedul'],['scheduler']
Energy Efficiency,"u.edu, 46002, None); 18/03/07 20:31:49 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 246.6 KB, free 8.4 GB); 18/03/07 20:31:50 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.3 KB, free 8.4 GB); 18/03/07 20:31:50 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:41567 (size: 25.3 KB, free: 8.4 GB); 18/03/07 20:31:50 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 20:31:50 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7175 for farrell on ha-hdfs:scc; 18/03/07 20:31:50 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7175 for farrell); 18/03/07 20:31:50 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 20:31:51 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 629 output partitions; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.9 KB, free 8.4 GB); 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from b",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:5419,schedul,scheduler,5419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,1,['schedul'],['scheduler']
Energy Efficiency,"u.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```; 18/03/07 20:32:55 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at FlagStatSpark.java:73, took 64.566359 s; 1205535516 in total; 0 QC failure; 37791118 duplicates; 1157122594 mapped (95.98%); 1205535516 paired in sequencing; 602767758 read1; 602767758 read2; 1145853318 properly paired (95.05%); 1150449216 with itself and mate mapped; 6673378 singletons (0.55%); 4595898 with mate mapped to a different chr; 3316623 with mate mapped to a different chr (mapQ>=5); 18/03/07 20:32:55 INFO server.ServerConnector: Stopped ServerConnector@79f5a6ed{HTTP/1.1}{0.0.0.0:4041}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@221ca495{/stages/stage/kill,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:8607,schedul,scheduler,8607,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,1,['schedul'],['scheduler']
Energy Efficiency,"uence id 0, start 124511724, span 7265, expected MD5 cf58e0adc447a66b188474efc3c84a43; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:14:03 WARN scheduler.TaskSetManager: Lost task 23.0 in stage 0.0 (TID 6, scc-q15.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 2, start 93470412, span 157, expected MD5 56b7844faa4e0c4f61fd6774df454b09; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.col",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:10375,schedul,scheduler,10375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,"uence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:08 INFO TaskSetManager:54 - Starting task 3.1 in stage 0.0 (TID 4, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:08 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 3) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2, partition 9, NODE_LOCAL, 7992 bytes); 2019-0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:26529,schedul,scheduler,26529,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['schedul'],['scheduler']
Energy Efficiency,uld catch this cleanly and generate a VCF without any calls. Here is a small self contained test case which demonstrates the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_hcspark_noreads.tar.gz. and the full error message:; ```; java.lang.UnsupportedOperationException: empty collection; at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$apply$35.apply(RDD.scala:1004); at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$apply$35.apply(RDD.scala:1004); at scala.Option.getOrElse(Option.scala:121); at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1004); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.reduce(RDD.scala:984); at org.apache.spark.api.java.JavaRDDLike$class.reduce(JavaRDDLike.scala:384); at org.apache.spark.api.java.AbstractJavaRDDLike.reduce(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.callVariantsWithHaplotypeCaller(HaplotypeCallerSpark.java:229); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.callVariantsWithHaplotypeCallerAndWriteOutput(HaplotypeCallerSpark.java:182); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.runTool(HaplotypeCallerSpark.java:143); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:387); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinsti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4234:1200,reduce,reduce,1200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4234,1,['reduce'],['reduce']
Energy Efficiency,"uler.DAGScheduler: failed: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.8 KB, free 365.9 MB); 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KB, free 365.8 MB); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:44818 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244) (first 15 tasks are for partitions Vector(0)); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks; 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, com2, executor 1, partition 0, NODE_LOCAL, 4632 bytes); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:45501 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.131.101.145:54024; 17/10/13 18:11:53 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 135 bytes; 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on com2:45501 (size: 2.1 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 565 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88) finished in 0.566 ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:20505,schedul,scheduler,20505,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['schedul'],['scheduler']
Energy Efficiency,ultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1832); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1845); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1922); 	at org.apache.spark.rdd.PairRDDFunctions$$an,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:19068,schedul,scheduler,19068,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,ultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3659:3418,schedul,scheduler,3418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659,1,['schedul'],['scheduler']
Energy Efficiency,un$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); ... 10 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:17159,schedul,scheduler,17159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,un/data/CEUTrio.HiSeq.WEx.b37.NA12892.small.bam -O hdfs:///user/akiezun/data/CEUTrio.HiSeq.WEx.b37.NA12892.small.out.bam \; -- \; --sparkRunner SPARK --sparkMaster yarn-client \; --num-executors 5 --executor-cores 2 --executor-memory 4g \; --conf spark.yarn.executor.memoryOverhead=600; ```. blows up with . ```; java.lang.ClassCastException: org.apache.hadoop.fs.RawLocalFileSystem cannot be cast to org.apache.hadoop.fs.LocalFileSystem; at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:350); at org.apache.spark.deploy.yarn.Client$.org$apache$spark$deploy$yarn$Client$$getQualifiedLocalPath(Client.scala:1373); at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:329); at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:422); at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:635); at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:124); at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:56); at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144); at org.apache.spark.SparkContext.<init>(SparkContext.scala:523); at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:149); at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:81); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.hellbende,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1389:1156,schedul,scheduler,1156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1389,1,['schedul'],['scheduler']
Energy Efficiency,"unTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-02-17 16:25:50 INFO DAGScheduler:54 - Job 4 failed: collect at FindBreakpointEvidenceSpark.java:963, took 30.909355 s; 2019-02-17 16:25:50 INFO AbstractConnector:318 - Stopped Spark@7433ca19{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-02-17 16:25:50 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-02-17 16:25:50 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-02-17 16:25:50 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-02-17 16:25:50 INFO BlockManagerInfo:54 - Added taskresult_980 in memory on scc-q04.scc.bu.edu:41981 (size: 4.9 MB, free: 42.5 GB); 2019-02-17 16:25:50 ERROR TransportRequestHandler:210 - Error while invoking RpcHandler#receive() for one-way message.; org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.; at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:160); at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:140); at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:655); at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:208); at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:113); at org.apac",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:42340,monitor,monitor,42340,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,3,"['Schedul', 'monitor']","['SchedulerExtensionServices', 'monitor']"
Energy Efficiency,"uncher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. 17/10/11 14:19:28 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.; 17/10/11 14:19:28 INFO storage.BlockManagerMaster: Removal of executor 1 requested; 17/10/11 14:19:28 INFO cluster.YarnClientSchedulerBackend: Asked to remove non-existent executor 1; 17/10/11 14:19:28 INFO spark.ExecutorAllocationManager: Existing executor 1 has been removed (new total is 0); 17/10/11 14:19:35 INFO cluster.YarnClientSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (com2:35590) with ID 2; 17/10/11 14:19:35 INFO scheduler.TaskSetManager: Starting task 0.2 in stage 1.0 (TID 3, com2, executor 2, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:35 INFO spark.ExecutorAllocationManager: New executor 2 has registered (new total is 1); 17/10/11 14:19:35 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:46254 with 530.0 MB RAM, BlockManagerId(2, com2, 46254); 17/10/11 14:19:36 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:46254 (size: 32.3 KB, free: 530.0 MB); 17/10/11 14:19:37 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to com2:35590; 17/10/11 14:19:37 WARN scheduler.TaskSetManager: Lost task 0.2 in stage 1.0 (TID 3, com2, executor 2): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$14/1380582544.call(Ljava/lang/Object;)Ljava/lang/Iterable;; 	at org.apache.spark.api.java.JavaRDDLike$$an",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:21960,schedul,scheduler,21960,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"upported, using Java.util.zip.Inflater. 16:17:05.932 WARN IntelDeflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater. 16:17:06.503 INFO FeatureManager - Using codec VCFCodec to read file file:///home/robert/test/snps.vcf. 16:17:06.539 INFO IntervalArgumentCollection - Processing 61464 bp from intervals. 16:17:06.551 INFO HaplotypeCaller - Done initializing engine. 16:17:06.573 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes qui",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794:4475,Power,Power,4475,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794,1,['Power'],['Power']
Energy Efficiency,ureReader(FeatureDataSource.java:383); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:335); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:222); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadChec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6578:3957,Reduce,ReduceOps,3957,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6578,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,using linked or sorted data structures to reduce our dependency on the arbitrary changes in iterator orders (happens everytime you move from a jvm to another jvm),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1844:42,reduce,reduce,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1844,1,['reduce'],['reduce']
Energy Efficiency,"uster, the following exception occurs. The pipeline has been running fine on other cram files. **Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0**. Below is the stack and other details. . The pipeline looks like it is running through all the contigs and is not limited to chr1-chr22, ChrY, ChrX and ChrM. Would it help running the software if the extra 3000+ contig names in the GRCh38 reference are excluded? If so, what is the best way to exclude processing the extra contigs?. ```; 18/02/23 23:06:22 INFO scheduler.TaskSetManager: Finished task 24.0 in stage 15.0 (TID 29435) in 2906 ms on scc-q04.scc.bu.edu (executor 1) (48/70); 18/02/23 23:06:23 INFO scheduler.TaskSetManager: Finished task 52.0 in stage 15.0 (TID 29463) in 2354 ms on scc-q04.scc.bu.edu (executor 1) (49/70); 18/02/23 23:06:23 INFO scheduler.TaskSetManager: Finished task 37.0 in stage 15.0 (TID 29448) in 2653 ms on scc-q03.scc.bu.edu (executor 6) (50/70); 18/02/23 23:06:23 WARN scheduler.TaskSetManager: Lost task 27.0 in stage 15.0 (TID 29438, scc-q13.scc.bu.edu, executor 7): org.broadinstitute.hellbender.exceptions.GATKException: Erred when inferring breakpoint location and event type from chimeric alignment:; asm010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:1104,schedul,scheduler,1104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['schedul'],['scheduler']
Energy Efficiency,"ut allow NONE as input (#7206); - SA support and consistent naming for all GVS WDLs (#7205); - fix GvsExtractCallset inputs file (#7210); - add clustering to tables (#7207); - add vqsr cutoffs to GvsExtractCallset wdl; clean up dockstore yml (#7209); - Avro test (#7192); - Enable call caching of TSV generation in GvsImportGenomes (#7226); - 266 Clean up ExtractCohort -- remove query mode param (#7227); - 288 Add an excess alleles param (#7221); - take sample name as a param (#7236); - How to run GIAB comparisons (#7237); - Update GvsCreateFilterSet.wdl (#7239); - Use GatherVcfsCloud in GvsCreateFilterSet.wdl (#7241); - parameterize TTL with defaults, reduce memory allocation (#7244); - Addressing OOM in CohortExtract (#7245); - make outputs optional, change case in output (#7252); - Support for FORMAT/FT VQSLod Filtering and cohort-wide LowQual filter (#7248); - removed arrays code, renamed packages (#7260); - 279 labels (#7233); - add conda commands to GIAB readme (#7268); - remove gvs branch (#7263); - remove gvs branch (#7263); - upgrade bq libraries (#7264); - #299 - Sample list ease of use for cohort extracts (#7272); - check for duplicate ids (#7273); - Rc 274 passing sites only (#7275); - added default value to drop_state; broadinstitute/dsp-spec-ops#310 (#7278); - version bump for reliability (#7284); - add timestamp check to ExtractTask call https://github.com/broadinstitute/dsp-spec-ops/issues/320; - serial inserts for scaling prepare, factored out sample name (#7288); - Remove training sites only param from ExtractFeatures broadinstitute/dsp-spec-ops#261; - add param for mem for indels (#7282); - Ah prepare localize option (#7299); - Export sites only vcf STEP 1-- 317 add AC, AN, AF to the final VCF (#7279); - AoU GVS Cohort Extract wdl (#7242); - reliability (#7310); - bump to include FT tag filtering (#7316); - First pass at a Terra QuickStart (#7267); - Ah fix timestamp query (#7319); - 313 Cleanup Extract Cohort params (#7293); - bump bq storage versi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:14125,reduce,reduce,14125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['reduce'],['reduce']
Energy Efficiency,"ut=600 --conf spark.executor.heartbeatInterval=120 --conf spark.driver.userClassPathFirst=false; ```. It failed near the end of the pipeline. Here is the tail of the log:. ```; 20:38:14.368 INFO StructuralVariationDiscoveryPipelineSpark - Used 3549 evidence target links to annotate assembled breakpoints; 20:38:14.462 INFO StructuralVariationDiscoveryPipelineSpark - Called 662 imprecise deletion variants; 20:38:14.492 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 7234 variants.; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - INV: 184; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4486; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1170; 20:38:14.506 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1394; 18/01/12 20:38:16 WARN org.apache.spark.scheduler.TaskSetManager: Stage 17 contains a task of very large size (2518 KB). The maximum recommended task size is 100 KB.; 18/01/12 20:38:22 WARN org.apache.spark.scheduler.TaskSetManager: Stage 18 contains a task of very large size (2307 KB). The maximum recommended task size is 100 KB.; 20:38:27.207 INFO StructuralVariationDiscoveryPipelineSpark - Processing 501267 raw alignments from 426041 contigs.; 18/01/12 20:38:27 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2518 KB). The maximum recommended task size is 100 KB.; 20:38:35.835 INFO StructuralVariationDiscoveryPipelineSpark - Primitive filtering based purely on MQ left 339065 contigs.; 20:38:37.378 INFO StructuralVariationDiscoveryPipelineSpark - 17574 contigs with chimeric alignments potentially giving SV signals.; 18/01/12 20:38:37 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 284.0 in stage 25.0 (TID 43189, cw-test-w-6.c.broad-dsde-methods.internal, executor 7): java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	48",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:2196,schedul,scheduler,2196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,utFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:93); at org.disq_bio.disq.impl.formats.vcf.HeaderlessVcfOutputFormat$VcfRecordWriter.write(HeaderlessVcfOutputFormat.java:56); at org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil.write(SparkHadoopWriter.scala:358); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:132); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 21/04/13 07:32:24 ERROR SparkHadoopWriter: Task attempt_20210413073224_0026_r_000000_0 aborted.; 21/04/13 07:32:24 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 105); org.apache.spark.SparkException: Task failed while writing rows; at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:157); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWrite,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7199:4892,schedul,scheduler,4892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7199,1,['schedul'],['scheduler']
Energy Efficiency,"uteOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); 18/10/17 19:23:59 WARN TaskSetManager: Lost task 517.0 in stage 0.0 (TID 517, localhost, executor driver): org.broadinstitute.hellbender.exceptions.UserException$NoSuitableCodecs: Cannot read /dev/shm/gatktmp/spark-30e238e4-b1b7-41f9-b31e-844f16879051/userFiles-4621c82d-5f86-4b51-9321-ccc84ab49979/dbsnp_138.hg19.vcf because no suitable codecs found; 	at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:462); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:320); 	at org.broadinstitute.hellbender.engin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:7689,schedul,scheduler,7689,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,1,['schedul'],['scheduler']
Energy Efficiency,"utes.; Runtime.totalMemory()=16201547776; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 1.0 failed 1 times, most recent failure: Lost task 8.0 in stage 1.0 (TID 345, localhost): java.lang.ArrayI; ndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:7260,schedul,scheduler,7260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['schedul'],['scheduler']
Energy Efficiency,"utor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 15/07/14 13:14:53 ERROR util.SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-0,5,main]; java.lang.IncompatibleClassChangeError: Found class org.apache.hadoop.mapreduce.TaskAttemptContext, but interface was expected; at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getOutputFile(TemplatedTextOutputFormat.java:50); at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getDefaultWorkFile(TemplatedTextOutputFormat.java:46); at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:995); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:979); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61); at org.apache.spark.scheduler.Task.run(Task.scala:64); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 15/07/14 13:14:53 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1, localhost): java.lang.IncompatibleClassChangeError: Found class org.apache.hadoop.mapreduce.TaskAttemptContext, but interface was expected; at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getOutputFile(TemplatedTextOutputFormat.java:50); at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getDefaultWorkFile(TemplatedTextOutputFormat.java:46); at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:995); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:30453,schedul,scheduler,30453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['schedul'],['scheduler']
Energy Efficiency,"utor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 17/10/11 14:19:38 INFO spark.ExecutorAllocationManager: Existing executor 2 has been removed (new total is 0); 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203, took 19.909238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=98618",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:30913,monitor,monitor,30913,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['monitor'],['monitor']
Energy Efficiency,"utor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:35240,monitor,monitor,35240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,3,"['Schedul', 'monitor']","['SchedulerExtensionServices', 'monitor']"
Energy Efficiency,"utputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1572); at java.base/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1529); at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). 11:00:53.977 INFO DAGScheduler - Job 1 failed: runJob at SparkHadoopWriter.scala:83, took 3.799268 s; 11:00:53.979 ERROR SparkHadoopWriter - Aborting job job_202408111100502620487673658411251_0021.; org.apache.spark.SparkException: Job aborted due to stage failure: Task serialization failed: java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; java.la",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:7773,adapt,adapted,7773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['adapt'],['adapted']
Energy Efficiency,utputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1572); at java.base/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1529); at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607) ~[gatk-pack,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:12097,adapt,adapted,12097,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['adapt'],['adapted']
Energy Efficiency,utputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1572); at java.base/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1529); at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collecti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:30816,adapt,adapted,30816,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['adapt'],['adapted']
Energy Efficiency,utputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1572); at java.base/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1529); at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1438); at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181); at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 11:00:54.334 INFO ShutdownHookManager - Shutdown hook called; 11:00:54.335 INFO ShutdownHookManager - Deleting directory /raid/tmp/d6/c66ba827e22dbc38625af1cbc85adc/tmp/spark-f9c7c336-4e98-4fcc-855b-ba8a5a29e074; ```. The first lines of the log file:; ```; vm.max_map_count = 2147483642; Using GATK jar /Public/Everythings/misc/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; Running:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:36687,adapt,adapted,36687,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['adapt'],['adapted']
Energy Efficiency,"v"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-NISTSampleHeadToHead/BenchmarkComparison/ccdb901c-fb8f-49e4-b542-cf42e011a623/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-NISTSampleHeadToHead/BenchmarkComparison/ccdb901c-fb8f-49e4-b542-cf42e011a623/call-BenchmarkVCFControlSample/Benchmark/6d64f12a-ca50-4ecd-8608-93dc53d241bb/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""95.62183055555556"",; ""NIST evalHCsystemhours"": ""0.18361111111111117"",; ""NIST evalHCwallclockhours"": ""64.22846111111112"",; ""NIST evalHCwallclockmax"": ""3.3683277777777776"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-NISTSampleHeadToHead/BenchmarkComparison/ccdb901c-fb8f-49e4-b542-cf42e011a623/call-EVALRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-NISTSampleHeadToHead/BenchmarkComparison/ccdb901c-fb8f-49e4-b542-cf42e011a623/call-BenchmarkVCFTestSample/Benchmark/f0709402-e72d-4013-a781-e50d8d46e2c3/call-CombineSummaries/summary.csv""; }; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815:14475,monitor,monitoring,14475,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815,1,['monitor'],['monitoring']
Energy Efficiency,"vYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `73.109% <Ã¸> (-0.84%)` | `26% <Ã¸> (Ã¸)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.611% <Ã¸> (-0.694%)` | `36% <Ã¸> (-1%)` | |; | [...org/broadinstitute/hellbender/utils/GenomeLoc.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2MuamF2YQ==) | `67.797% <Ã¸> (-0.565%)` | `85% <Ã¸> (-1%)` | |; | [...lbender/tools/walkers/vqsr/VariantDataManager.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVmFyaWFudERhdGFNYW5hZ2VyLmphdmE=) | `66.228% <Ã¸> (-0.439%)` | `78% <Ã¸> (-1%)` | |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2399/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2399?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2399?src=pr&el=footer). Last update [3c10554...9d80a51](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2399#issuecomment-278182658:5027,Power,Powered,5027,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2399#issuecomment-278182658,1,['Power'],['Powered']
Energy Efficiency,va.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1832); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1845); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1922); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1144); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1074); 	at org.apache.spark.rdd.RDDOperationS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:19413,schedul,scheduler,19413,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3659:3763,schedul,scheduler,3763,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:9281,schedul,scheduler,9281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:15701,schedul,scheduler,15701,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1661); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1649); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1648); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1648); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1882); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1820); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:4599,schedul,scheduler,4599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); 	at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78); 	... 87 more; Caused by: java.util.ConcurrentModificationException; 	at java.util.ArrayList.sort(ArrayList.java:1464); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.<init>(ReadThreadingAssembler.java:81); 	at org.broadinstitute.hellbender.tools.wal,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:11538,schedul,scheduler,11538,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,"va.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615); 	at java.lang.Thread.run(Thread.java:745). Container exited with a non-zero exit code 1. 18/01/09 18:31:21 INFO storage.BlockManagerMaster: Removal of executor 9 requested; 18/01/09 18:31:21 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asked to remove non-existent executor 9; 18/01/09 18:31:21 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 9 from BlockManagerMaster.; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms); 18/01/09 18:31:26 INFO server.AbstractConnector: Stopped Spark@283ab206{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/09 18:31:26 INFO ui.SparkUI: Stopped Spark web UI at http://192.168.1.4:4040; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/01/09 18:31:26 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/01/09 18:31:26 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/01/09 18:31:26 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/01/09 18:31:26 INFO memory.MemoryStore: MemoryStore cleared; 18/01/09 18:31:26 INFO storage.BlockManager: BlockManager stopped; 18/01/09 18:31:26 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/01/09 18:31:26 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/01/09 18:31:26 INFO spark.SparkContext: Successfully stopped SparkContext; 18:31:26.896 INFO BwaAndMarkDuplicatesPipelineSpark - Shut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:30069,monitor,monitor,30069,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['monitor'],['monitor']
Energy Efficiency,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD.count(RDD.scala:1157); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tool,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:15200,schedul,scheduler,15200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['schedul'],['scheduler']
Energy Efficiency,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3679:5147,schedul,scheduler,5147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3679,1,['schedul'],['scheduler']
Energy Efficiency,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:50578,schedul,scheduler,50578,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['schedul'],['scheduler']
Energy Efficiency,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tool,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:39165,schedul,scheduler,39165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:14481,schedul,scheduler,14481,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,3,['schedul'],['scheduler']
Energy Efficiency,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1354); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rd,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:19641,schedul,scheduler,19641,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['schedul'],['scheduler']
Energy Efficiency,va:1145); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1925); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1938); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1951); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1965); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050:6842,schedul,scheduler,6842,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050,1,['schedul'],['scheduler']
Energy Efficiency,"va:157) finished in 8.951 s; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: running: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: failed: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.1 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.3 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:34044 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244) (first 15 tasks are for partitions Vector(0)); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks; 17/10/11 14:19:27 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, com2, executor 1, partition 0, NODE_LOCAL, 1990 bytes); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:38568 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to com2:35572; 17/10/11 14:19:27 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 134 bytes; 17/10/11 14:19:28 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1, com2, executor 1): java.lang.AbstractMethodError: org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$$Lambda$26/353370312",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:14812,schedul,scheduler,14812,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,va:203); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemain,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:11072,Reduce,ReduceOps,11072,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,1,['Reduce'],['ReduceOps']
Energy Efficiency,"va:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). 11:00:53.977 INFO DAGScheduler - Job 1 failed: runJob at SparkHadoopWriter.scala:83, took 3.799268 s; 11:00:53.979 ERROR SparkHadoopWriter - Aborting job job_202408111100502620487673658411251_0021.; org.apache.spark.SparkException: Job aborted due to stage failure: Task serialization failed: java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; java.lang.OutOfMemoryError: Required array length 2147483639 + 798 is too large; at java.base/jdk.internal.util.ArraysSupport.hugeLength(ArraysSupport.java:649); at java.base/jdk.internal.util.ArraysSupport.newLength(ArraysSupport.java:642); at java.base/java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:100); at java.base/java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:130); at org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:8248,schedul,scheduler,8248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,va:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607) ~[gatk-package-4.4,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:12572,schedul,scheduler,12572,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,va:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:31291,schedul,scheduler,31291,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,va:350); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 11:00:54.334 INFO ShutdownHookManager - Shutdown hook called; 11:00:54.335 INFO ShutdownHookManager - Deleting directory /raid/tmp/d6/c66ba827e22dbc38625af1cbc85adc/tmp/spark-f9c7c336-4e98-4fcc-855b-ba8a5a29e074; ```. The first lines of the log file:; ```; vm.max_map_count = 2147483642; Using GATK jar /Public/Everythings/misc/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -XX:+UnlockDiagnosticVMOptions -XX:GCLockerRetryAllocationCount=96 -XX:+UseNUMA -XX:+UseZGC -Xmx1794G -jar /Public/Everythings/misc/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar SortSamSpark --input HG002-NA24385-GM24385.bam --output HG002-NA24385-GM24385.sorted.bam --sort-order coordinate --tmp-dir . --spark-master loc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:37162,schedul,scheduler,37162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,va:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:558) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.checkFilter(FuncotationFilter.java:49) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$null$0(FilterFuncotations.java:194) ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:176) ; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$null$1(FilterFuncotations.java:196) ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; at java.base/java.util.stream.ForEac,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:4425,Reduce,ReduceOps,4425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,va:97)** ; **at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:709)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:134)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)** ; **20/03/05 09:28:58 INFO ShutdownHookManager: Shutdown hook called** ; **20/03/05 09:28:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-9e0e0327-45a3-46e8-872a-f5a63c3c7a98** ; **Using GATK jar /mnt/clinix1/Analysis/mongol/phenomata/Tools/Anaconda3/envs/gatk4/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar** ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:50964,schedul,scheduler,50964,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,"va:97)** ; **at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:709)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:134)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)** ; **20/03/05 09:28:58 INFO TaskSetManager: Starting task 40.0 in stage 0.0 (TID 40, localhost, executor driver, partition 40, PROCESS\_LOCAL, 7972 bytes)** ; **20/03/05 09:28:58 INFO Executor: Running task 40.0 in stage 0.0 (TID 40)** ; **20/03/05 09:28:58 WARN TaskSetManager: Lost task 34.0 in stage 0.0 (TID 34, localhost, ex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:28532,schedul,scheduler,28532,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,va:97)** ; **at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:709)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:134)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **20/03/05 09:28:58 ERROR TaskSetManager: Task 34 in stage 0.0 failed 1 times; aborting job** ; **20/03/05 09:28:58 INFO TaskSchedulerImpl: Cancelling stage 0** ; **20/03/05 09:28:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled** ; **20/03/05 09:28:58 INFO Executor: Executor is trying to kill ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:31980,schedul,scheduler,31980,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,"va:97)** ; **at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:709)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:134)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **Driver stacktrace:** ; **20/03/05 09:28:58 INFO DAGScheduler: Job 0 failed: count at PathSeqPipelineSpark.java:245, took 63.806676 s** ; **20/03/05 09:28:58 INFO SparkUI: Stopped Spark web UI at http://cm132:4040** ; **20/03/05 09:28:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!** ; **20/03",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:40594,schedul,scheduler,40594,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,va:97)** ; **at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:709)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:134)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35)** ; **at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78)** ; **at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:464)** ; **at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)** ; **at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)** ; **at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)** ; **at org.apache.spark.scheduler.Task.run(Task.scala:121)** ; **at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)** ; **at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **Driver stacktrace:** ; **at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)** ; **at org.apache.spark.scheduler.DAGScheduler$$anonfun$abo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:45021,schedul,scheduler,45021,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['schedul'],['scheduler']
Energy Efficiency,"variants; 17:13:31.570 INFO FilterMutectCalls - Shutting down engine; [February 17, 2019 5:13:31 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=845676544; java.lang.NumberFormatException: For input string: "".""; 	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65); 	at java.lang.Integer.parseInt(Integer.java:569); 	at java.lang.Integer.valueOf(Integer.java:766); 	at htsjdk.variant.variantcontext.CommonInfo.lambda$getAttributeAsIntList$1(CommonInfo.java:287); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Collections$2.tryAdvance(Collections.java:4717); 	at java.util.Collections$2.forEachRemaining(Collections.java:4725); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at htsjdk.variant.variantcontext.CommonInfo.getAttributeAsList(CommonInfo.java:273); 	at htsjdk.variant.variantcontext.CommonInfo.getAttributeAsIntList(CommonInfo.java:281); 	at htsjdk.variant.variantcontext.VariantContext.getAttributeAsIntList(VariantContext.java:738); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyReadPositionFilter(Mutect2FilteringEngine.java:223); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:529); 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:130); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.acc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5684:3772,Reduce,ReduceOps,3772,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5684,1,['Reduce'],['ReduceOps']
Energy Efficiency,"vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (Ã¸)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `40.469% <0%> (-18.009%)` | `28% <0%> (Ã¸)` | |; | ... and [96 more](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=footer). Last update [a85e0ff...1d6ce76](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-290039637:4188,Power,Powered,4188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-290039637,1,['Power'],['Powered']
Energy Efficiency,"versed.selfRef.shifted.homoplasmies.vcf.bgz \\ ; ; \--annotation StrandBiasBySample \\ ; ; \--mitochondria-mode \\ ; ; \--max-reads-per-alignment-start 75 \\ ; ; \--max-mnp-distance 0 \\ ; ; \-L chrM:8023-9140 \\ ; ; \--genotype-filtered-alleles \\ ; ; \--debug-assembly-variants-out /rej.vcf \\ ; ; \--bam-output bamout.bam. In this instance the variant in question is listed in the rej.vcf file obtained via `--debug-assembly-variants-out`. I have examined `bamout.bam` as well as the input bam and there appears to be ample coverage at the site of interest (the T at position 8316 is the position of interest, highlighted):. ![](https://gatk.broadinstitute.org/hc/user_images/aGbHKebG7Tb8Lgu33gGzXw.png). I have tried running this with some of the additional parameters in \[[https://gatk.broadinstitute.org/hc/en-us/articles/360043491652-When-HaplotypeCaller-and-Mutect2-do-not-call-an-expected-variant\](/hc/en-us/articles/360043491652-When-HaplotypeCaller-and-Mutect2-do-not-call-an-expected-variant)](https://gatk.broadinstitute.org/hc/en-us/articles/360043491652-When-HaplotypeCaller-and-Mutect2-do-not-call-an-expected-variant](/hc/en-us/articles/360043491652-When-HaplotypeCaller-and-Mutect2-do-not-call-an-expected-variant)) (namely `--linked-de-bruijn-graph` and `--recover-all-dangling-branches`) to no avail. Coverage is very deep at this position (>2000x). Notably if I edit the input to `--alleles` and change the allele of interest (8316:T>A) to anything else (8316:T>C or T>G) it appropriately shows up in the output VCF. What am I missing here? Let me know if you have any solutions or if you need any additional files. UPDATE: Adding `--disable-adaptive-pruning` now produces the variant of interest specified in --alleles, but also adds several other new calls, in case that is helpful in isolating where this force-call variant is being lost.<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/270138'>Zendesk ticket #270138</a>)<br> gz#270138</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7672:2858,adapt,adaptive-pruning,2858,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7672,1,['adapt'],['adaptive-pruning']
Energy Efficiency,veryPipelineSpark - BND_INV55: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/04/27 00:47:28 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:33 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2685 KB). The maximum recommended task size is 100 KB.; 00:47:39.417 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 00:47:39 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:47:47.083 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 00:47:48.135 INFO StructuralVariationDiscoveryPipelineSpark - 23702 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 00:47:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:57 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:48:04 WARN org.apache.spark.scheduler.TaskSetManager: Stage 34 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:48:13.094 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 15964 variants.; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 6920; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 264; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 268; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4680; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 487; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - INS: 3345; 00,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:1909,schedul,scheduler,1909,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,veryPipelineSpark - BND_INV55: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/04/27 02:20:12 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:18 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2599 KB). The maximum recommended task size is 100 KB.; 02:20:24.460 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 02:20:24 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:32.040 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 02:20:33.079 INFO StructuralVariationDiscoveryPipelineSpark - 23841 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 02:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:42 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 34 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:58.973 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 15659 variants.; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 6920; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 264; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 268; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5019; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1793; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1395; 0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:5775,schedul,scheduler,5775,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,"w total is 1); 17/10/11 14:19:23 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 2235 bytes); 17/10/11 14:19:23 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:38568 with 530.0 MB RAM, BlockManagerId(1, com2, 38568); 17/10/11 14:19:25 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:38568 (size: 6.9 KB, free: 530.0 MB); 17/10/11 14:19:26 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:38568 (size: 26.1 KB, free: 530.0 MB); 17/10/11 14:19:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4180 ms on com2 (executor 1) (1/1); 17/10/11 14:19:27 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.951 s; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: running: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: failed: Set(); 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.1 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.3 KB, free 529.6 MB); 17/10/11 14:19:27 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:34044 (size: 32.3 KB, free: 529.9 MB); 17/10/11 14:19:27 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004; 17/10/11 14:19:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9]",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:13933,schedul,scheduler,13933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,wHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:179); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:134); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:69); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4179:3180,schedul,scheduler,3180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4179,3,['schedul'],['scheduler']
Energy Efficiency,ware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:330); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.ClassNotFoundException: htsjdk.variant.variantcontext.LazyGenotypesContext; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:6121,schedul,scheduler,6121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['schedul'],['scheduler']
Energy Efficiency,ware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:362); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.invalidateSampleOrdering(LazyGenotypesContext.java:205); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:353); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:46); 	at com.esotericsoftware.kr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:7310,schedul,scheduler,7310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,"ware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); 	... 20 more; 17/11/15 19:43:35 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@5917b44d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/15 19:43:35 WARN org.apache.spark.ExecutorAllocationManager: No stages are running, but numRunningTasks != 0; 19:43:35.858 INFO PrintVariantsSpark - Shutting down engine; [November 15, 2017 7:43:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=823132160; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; Serialization trace:; genotypes (org.seqdoop.hadoop_bam.VariantContextWithHeader); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840:8561,schedul,scheduler,8561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840,1,['schedul'],['scheduler']
Energy Efficiency,"we need a simple abstract map/reduce tool that would just loop over data and call map, reduce in a sequence. It'll make it easier to migrate walkers that way.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/20:30,reduce,reduce,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/20,2,['reduce'],['reduce']
Energy Efficiency,what would increasing vcf size show that we dont already know? Of course it will fail because i only allocated 7GB per executor so if vcf is 30GB it will fail to broadcast. I'm still not sure how to measure % of wallclock time.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1675#issuecomment-210725355:101,allocate,allocated,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1675#issuecomment-210725355,1,['allocate'],['allocated']
Energy Efficiency,what's the action plan for this? How about the following subgoals for alpha-2:; - [ ] move picard to a specific tagged version of htsjdk from maven https://github.com/broadinstitute/picard/pull/542; - [ ] picard moves to using gradle broadinstitute/picard#554; - [ ] picard release numbers and schedule get decoupled from htsjdk ones https://github.com/broadinstitute/picard/issues/545,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1210#issuecomment-223071513:294,schedul,schedule,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1210#issuecomment-223071513,1,['schedul'],['schedule']
Energy Efficiency,"when the cluster is created. The default for this value is `false`, per [here](https://hadoop.apache.org/docs/r2.9.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml), which is the version of Hadoop used in Dataproc image version 1.3. If left as `false`, one keeps getting errors like below when requesting reference bases localized to the HDFS attached to the dataproc cluster, regardless if using *.fasta.gz or *.fasta.; ```; 19/07/26 20:15:43 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 20.5 in stage 50.0 (TID 45798, shuang-g94794-chmi-chmi3-wgs1-cram-bam-feature-w-2.c.broad-dsde-methods.internal, executor 44): htsjdk.samtools.SAMException: Unable to load chr14(100526932, 100526932) from /reference/Homo_sapiens_assembly38.fasta; 	at htsjdk.samtools.reference.AbstractIndexedFastaSequenceFile.getSubsequenceAt(AbstractIndexedFastaSequenceFile.java:207); 	at htsjdk.samtools.reference.IndexedFastaSequenceFile.getSubsequenceAt(IndexedFastaSequenceFile.java:49); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceHadoopSparkSource.getReferenceBases(ReferenceHadoopSparkSource.java:31); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.SvType.extractRefBases(SvType.java:161); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.SimpleSVType$DuplicationTandem.<init>(SimpleSVType.java:190); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.ContigChimericAlignmentIterativeInterpreter.inferSimpleTypeFromNovelAdjacency(ContigChimericAlignmentIterativeInterpreter.java:229); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.ContigChimericAlignmentIterativeInterpreter.lambda$discoverVariantsFromChimeras$610a78cb$1(ContigChimericAlignmentIterativeInterpreter.java:84); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6064:468,schedul,scheduler,468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6064,1,['schedul'],['scheduler']
Energy Efficiency,"when you run BwaSpark, a lot of logging info is produced, like this:. ```; [M::mem_pestat] analyzing insert size distribution for orientation RR...; [M::mem_pestat] (25, 50, 75) percentile: (37, 57, 86); [M::mem_pestat] low and high boundaries for computing mean and std.dev: (1, 184); [M::mem_pestat] mean and std.dev: (63.93, 37.92); [M::mem_pestat] low and high boundaries for proper pairs: (1, 233); [M::mem_process_seqs] Processed 1316 reads in 1.312 CPU sec, 0.182 real sec; [M::mem_process_seqs] Processed 1316 reads in 1.365 CPU sec, 0.188 real sec; [M::mem_process_seqs] Processed 1316 reads in 1.479 CPU sec, 0.204 real sec; [M::mem_process_seqs] Processed 1316 reads in 1.721 CPU sec, 0.237 real sec; [M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (272, 0, 0, 329); [M::mem_pestat] analyzing insert size distribution for orientation FF...; [M::mem_pestat] (25, 50, 75) percentile: (34, 57, 81); [M::mem_pestat] low and high boundaries for computing mean and std.dev: (1, 175); [M::mem_pestat] mean and std.dev: (59.82, 33.44); [M::mem_pestat] low and high boundaries for proper pairs: (1, 222); [M::mem_pestat] skip orientation FR as there are not enough pairs; [M::mem_pestat] skip orientation RF as there are not enough pairs; ```. this should be reduced or removed or controllable somehow",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2054:1276,reduce,reduced,1276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2054,1,['reduce'],['reduced']
Energy Efficiency,wing error!. > Driver stacktrace:; > 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1436); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1424); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); > 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); > 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); > 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1423); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); > 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); > 	at scala.Option.foreach(Option.scala:257); > 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1651); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1606); > 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1595); > 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); > 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); > 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); > 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); > 	at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); > 	at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); > 	at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936:1480,schedul,scheduler,1480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936,1,['schedul'],['scheduler']
Energy Efficiency,"x"": ""3.8036305555555554"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-NISTSampleHeadToHead/BenchmarkComparison/75625b9d-e48b-4859-803e-58989e3ccf62/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-NISTSampleHeadToHead/BenchmarkComparison/75625b9d-e48b-4859-803e-58989e3ccf62/call-BenchmarkVCFControlSample/Benchmark/21373bda-c620-4200-ad29-1e3886ea52ad/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""104.20126111111112"",; ""NIST evalHCsystemhours"": ""0.20587777777777783"",; ""NIST evalHCwallclockhours"": ""76.10080000000004"",; ""NIST evalHCwallclockmax"": ""3.949438888888889"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-NISTSampleHeadToHead/BenchmarkComparison/75625b9d-e48b-4859-803e-58989e3ccf62/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-NISTSampleHeadToHead/BenchmarkComparison/75625b9d-e48b-4859-803e-58989e3ccf62/call-BenchmarkVCFTestSample/Benchmark/b91bffd4-8057-453f-a8e2-4767648da91a/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1549231169:21366,monitor,monitoring,21366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1549231169,1,['monitor'],['monitoring']
Energy Efficiency,xecutor.execute(Shell.java:786); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:213); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799); 	at scala.Option.foreach(Option.scala:236); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1668); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1627); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1616); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:33600,schedul,scheduler,33600,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['schedul'],['scheduler']
Energy Efficiency,"xecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 18/03/09 09:22:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/09 09:22:08 INFO SparkContext: Successfully stopped SparkContext; 09:22:08.389 INFO BaseRecalibratorSpark - Shutting down engine; [March 9, 2018 9:22:08 AM UTC] org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark done. Elapsed time: 61.53 minutes.; Runtime.totalMemory()=16815489024; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 0.0 failed 1 times, most recent failure: Lost task 8.0 in stage 0.0 (TID 8, localhost): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 126542 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515:3283,schedul,scheduler,3283,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515,1,['schedul'],['scheduler']
Energy Efficiency,xt(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at org.seqdoop.hadoop_bam.BAMRecordReader.nextKeyValue(BAMRecordReader.java:225); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:182); 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:7536,Reduce,ReduceOps,7536,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['Reduce'],['ReduceOps']
Energy Efficiency,y large size (4378 KB). The maximum recommended task size is 100 KB.; 17:19:33.313 INFO StructuralVariationDiscoveryPipelineSpark - Processing 821484 raw alignments from 708052 contigs.; 18/01/25 17:19:33 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:19:46.133 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 573670 contigs.; 17:19:46.995 INFO StructuralVariationDiscoveryPipelineSpark - 23730 contigs with chimeric alignments potentially giving SV signals.; 17:19:47.546 INFO StructuralVariationDiscoveryPipelineSpark - 8559 contigs indicating InsDel; 18/01/25 17:19:47 WARN org.apache.spark.scheduler.TaskSetManager: Stage 29 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:00.012 INFO StructuralVariationDiscoveryPipelineSpark - 324 contigs indicating IntraChrStrandSwitch; 18/01/25 17:20:00 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:11.779 INFO StructuralVariationDiscoveryPipelineSpark - 3946 contigs indicating MappedInsertionBkpt; 18/01/25 17:20:11 WARN org.apache.spark.scheduler.TaskSetManager: Stage 37 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:23.416 INFO StructuralVariationDiscoveryPipelineSpark - 853 contigs indicating Cpx; 18/01/25 17:20:23 WARN org.apache.spark.scheduler.TaskSetManager: Stage 41 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:34.830 INFO StructuralVariationDiscoveryPipelineSpark - 1521 contigs indicating Incomplete; 18/01/25 17:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 45 contains a task of very large size (4041 KB). The maximum recommended task size is 100 KB.; 17:20:44.949 INFO StructuralVariationDiscoveryPipelineSpark - 5277 contigs indicat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260:2377,schedul,scheduler,2377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260,1,['schedul'],['scheduler']
Energy Efficiency,y(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); 	at org.apache.spark.internal.io.SparkHadoopW,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:11193,schedul,scheduler,11193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,"y, I've run ValidateSamFile. There are some reads missing their mates, but this hasn't presented an issue in other tools (including vanilla BaseRecalibrator). Searching thru the forum, I found an old issue with a similar stacktrace, but that issue appears to occur in GATK 2.4: https://gatkforums.broadinstitute.org/gatk/discussion/3265/bqsrgatherer-exception. In the below stacktrace, I've bolded the error message that seems to occur in each of these samples. `Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:1753,schedul,scheduler,1753,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['schedul'],['scheduler']
Energy Efficiency,y.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:8328,schedul,scheduler,8328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['schedul'],['scheduler']
Energy Efficiency,"yStore: MemoryStore started with capacity 530.0 MB; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering OutputCommitCoordinator; 17/10/11 14:19:11 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.; 17/10/11 14:19:11 INFO ui.SparkUI: Started SparkUI at http://10.131.101.159:4040; 17/10/11 14:19:11 INFO spark.SparkContext: Added JAR file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar at spark://10.131.101.159:43567/jars/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar with timestamp 1507702751615; 17/10/11 14:19:11 INFO client.RMProxy: Connecting to ResourceManager at mg/10.131.101.159:8032; 17/10/11 14:19:11 INFO yarn.Client: Requesting a new application from cluster with 2 NodeManagers; 17/10/11 14:19:12 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (164726 MB per container); 17/10/11 14:19:12 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/11 14:19:12 INFO yarn.Client: Setting up container launch context for our AM; 17/10/11 14:19:12 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/11 14:19:12 INFO yarn.Client: Preparing resources for our AM container; 17/10/11 14:19:12 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/10/11 14:19:12 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438/__spark_conf__8945422067005652415.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507683879816_0006/__spark_conf__8945422067005652415.zip; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:13 INFO yarn.Clie",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:5454,allocate,allocate,5454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['allocate'],['allocate']
Energy Efficiency,y_work/main-giab-joint-2017-10-02-100534.907/root/postprocess_alignment/2/align/NA24631/NA24631-sort-recal.bam -L /mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/gatk-haplotype/chr15/NA24631-chr15_68578892_84670250-block-regions.bed --interval_set_rule INTERSECTION --sparkMaster local[16] --conf spark.local.dir=/mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH --annotation ClippingRankSumTest --annotation DepthPerSampleHC --output /mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH/NA24631-chr15_68578892_84670250-block.vcf.gz --emitRefConfidence GVCF -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 60 -GQB 80; ```; and the full traceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3659:2410,schedul,scheduler,2410,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659,1,['schedul'],['scheduler']
Energy Efficiency,yo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:7826,schedul,scheduler,7826,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['schedul'],['scheduler']
Energy Efficiency,yo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	... 38 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.internal.io.SparkHadoopMapReduceWriter$.write(SparkHadoopMapReduceWriter.scala:88); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1085); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDatas,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545:10385,schedul,scheduler,10385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545,1,['schedul'],['scheduler']
Energy Efficiency,"ytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 6.0 (TID 520, localhost, executor 2, partition 5, NODE_LOCAL, 5598 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 6.0 (TID 521, localhost, executor 1, partition 6, NODE_LOCAL, 5315 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 6.0 (TID 522, localhost, executor 2, partition 7, NODE_LOCAL, 5316 bytes); 18/09/08 10:32:49 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:37617 (size: 59.2 KB, free: 2004.5 MB); 18/09/08 10:32:49 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:45786 (size: 59.2 KB, free: 2004.5 MB); 18/09/08 10:32:50 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:37617 (size: 9.0 B, free: 2004.5 MB); 18/09/08 10:32:50 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 6.0 (TID 523, localhost, executor 1, partition 8, NODE_LOCAL, 5604 bytes); 18/09/08 10:32:50 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 6.0 (TID 524, localhost, executor 1, partition 9, NODE_LOCAL, 5598 bytes); 18/09/08 10:32:50 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 6.0 (TID 515, localhost, executor 1): java.lang.NullPointerException; 	at org.broadinstitute.hellbender.utils.read.markduplicates.sparkrecords.EmptyFragment.<init>(EmptyFragment.java:35); 	at org.broadinstitute.hellbender.utils.read.markduplicates.sparkrecords.MarkDuplicatesSparkRecord.newEmptyFragment(MarkDuplicatesSparkRecord.java:37); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$null$0(MarkDuplicatesSparkUtils.java:114); 	at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5169:2026,schedul,scheduler,2026,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5169,1,['schedul'],['scheduler']
Energy Efficiency,"ytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 6.0 (TID 521, localhost, executor 1, partition 6, NODE_LOCAL, 5315 bytes); 18/09/08 10:32:49 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 6.0 (TID 522, localhost, executor 2, partition 7, NODE_LOCAL, 5316 bytes); 18/09/08 10:32:49 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:37617 (size: 59.2 KB, free: 2004.5 MB); 18/09/08 10:32:49 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:45786 (size: 59.2 KB, free: 2004.5 MB); 18/09/08 10:32:50 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:37617 (size: 9.0 B, free: 2004.5 MB); 18/09/08 10:32:50 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 6.0 (TID 523, localhost, executor 1, partition 8, NODE_LOCAL, 5604 bytes); 18/09/08 10:32:50 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 6.0 (TID 524, localhost, executor 1, partition 9, NODE_LOCAL, 5598 bytes); 18/09/08 10:32:50 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 6.0 (TID 515, localhost, executor 1): java.lang.NullPointerException; 	at org.broadinstitute.hellbender.utils.read.markduplicates.sparkrecords.EmptyFragment.<init>(EmptyFragment.java:35); 	at org.broadinstitute.hellbender.utils.read.markduplicates.sparkrecords.MarkDuplicatesSparkRecord.newEmptyFragment(MarkDuplicatesSparkRecord.java:37); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$null$0(MarkDuplicatesSparkUtils.java:114); 	at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5169:2177,schedul,scheduler,2177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5169,1,['schedul'],['scheduler']
Energy Efficiency,zBH --annotation ClippingRankSumTest --annotation DepthPerSampleHC --output /mnt/work/cwl/bcbio_validation_workflows/giab-joint/bunny_work/main-giab-joint-2017-10-03-104521.457/root/variantcall/8/variantcall_batch_region/16/bcbiotx/tmp7exzBH/NA24631-chr15_68578892_84670250-block.vcf.gz --emitRefConfidence GVCF -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 60 -GQB 80; ```; and the full traceback is:; ```; 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3659:2985,schedul,scheduler,2985,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3659,1,['schedul'],['scheduler']
Energy Efficiency,"zL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvbk1vZGVsLmphdmE=) | `92.39% <92.39%> (Ã¸)` | `39 <39> (?)` | |; | [.../walkers/contamination/ContaminationSegmenter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvblNlZ21lbnRlci5qYXZh) | `96.42% <96.42%> (Ã¸)` | `9 <9> (?)` | |; | [...lbender/utils/read/SAMRecordToGATKReadAdapter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL1NBTVJlY29yZFRvR0FUS1JlYWRBZGFwdGVyLmphdmE=) | `91.6% <0%> (-2.1%)` | `144% <0%> (+6%)` | |; | [...nder/tools/funcotator/TranscriptSelectionMode.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL1RyYW5zY3JpcHRTZWxlY3Rpb25Nb2RlLmphdmE=) | `89.71% <0%> (-1.87%)` | `1% <0%> (Ã¸)` | |; | [...tools/funcotator/DataSourceFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0RhdGFTb3VyY2VGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `86.95% <0%> (-1.68%)` | `17% <0%> (Ã¸)` | |; | ... and [23 more](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5413?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5413?src=pr&el=footer). Last update [864b180...1183b3d](https://codecov.io/gh/broadinstitute/gatk/pull/5413?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5413#issuecomment-438824631:4654,Power,Powered,4654,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5413#issuecomment-438824631,1,['Power'],['Powered']
Energy Efficiency,"zcGFyay9zdi9BbGlnbmVkQXNzZW1ibHlPckV4Y3VzZS5qYXZh) | `93.296% <100%> (+81.997%)` | `34 <2> (+30)` | :arrow_up: |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `76.994% <78.261%> (+36.525%)` | `44 <1> (+16)` | :arrow_up: |; | [.../sv/StructuralVariationDiscoveryPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5UGlwZWxpbmVTcGFyay5qYXZh) | `90.476% <90.476%> (Ã¸)` | `4 <4> (?)` | |; | [...tructuralVariationDiscoveryArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5QXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `95.833% <95.833%> (Ã¸)` | `0 <0> (?)` | |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `50.888% <0%> (-1.183%)` | `23% <0%> (-1%)` | |; | ... and [25 more](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=footer). Last update [bf993d8...dc817a8](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-293918558:4362,Power,Powered,4362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-293918558,1,['Power'],['Powered']
Energy Efficiency,"zdC5qYXZh) | `97.82% <100%> (+0.26%)` | `8 <1> (+1)` | :arrow_up: |; | [...er/tools/walkers/GenotypeGVCFsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `78.26% <100%> (+2.45%)` | `25 <6> (+6)` | :arrow_up: |; | [...bender/tools/walkers/variantutils/ReblockGVCF.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9SZWJsb2NrR1ZDRi5qYXZh) | `81.52% <100%> (+1.17%)` | `46 <0> (+3)` | :arrow_up: |; | [...der/tools/walkers/annotator/RMSMappingQuality.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9STVNNYXBwaW5nUXVhbGl0eS5qYXZh) | `83.6% <77.35%> (-10.21%)` | `41 <25> (+1)` | |; | [...der/tools/walkers/CombineGVCFsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0NvbWJpbmVHVkNGc0ludGVncmF0aW9uVGVzdC5qYXZh) | `87.44% <83.33%> (+0.15%)` | `24 <2> (Ã¸)` | :arrow_down: |; | ... and [19 more](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4969?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4969?src=pr&el=footer). Last update [868a32e...49c474d](https://codecov.io/gh/broadinstitute/gatk/pull/4969?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4969#issuecomment-401457112:4603,Power,Powered,4603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4969#issuecomment-401457112,1,['Power'],['Powered']
Energy Efficiency,ze(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:12735,schedul,scheduler,12735,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,ze(JavaSerializer.scala:115); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331); at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49). at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608); at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607); at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1523); at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332); at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331); at scala.collection.immutable.List.foreach(List.scala:431); at org.apac,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:31454,schedul,scheduler,31454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"zerInstance.serialize(JavaSerializer.scala:115) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1501) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1329) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5(DAGScheduler.scala:1332) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.$anonfun$submitStage$5$adapted(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at scala.collection.immutable.List.foreach(List.scala:431) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.submitStage(DAGScheduler.scala:1331) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; 11:00:54.078 INFO AbstractConnector - Stopped Spark@2f829853{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}; 11:00:54.091 INFO SparkUI - Stopped Spark web UI at http://172.20.19.130:4040; 11:00:54.122 INFO MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!; 11:00:54.175 INFO MemoryStore - MemoryStore cleared; 11:00:54.175 INFO BlockManager - BlockManager stopped; 11:00:54.193 INFO BlockManagerMaster - BlockManagerMaster stopped; 11:00:54.211 INFO OutputCommitCoordinator$OutputCommitCoor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:23438,schedul,scheduler,23438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['schedul'],['scheduler']
Energy Efficiency,"| [...g/broadinstitute/hellbender/engine/ReadWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZFdhbGtlci5qYXZh) | `100% <0%> (Ã¸)` | `27% <0%> (+13%)` | :arrow_up: |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `93.411% <0%> (+1.639%)` | `135% <0%> (+58%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `74.026% <0%> (+1.948%)` | `35% <0%> (Ã¸)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `93.75% <0%> (+2.083%)` | `7% <0%> (+1%)` | :arrow_up: |; | [.../broadinstitute/hellbender/engine/LocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTG9jdXNXYWxrZXIuamF2YQ==) | `92.188% <0%> (+2.714%)` | `26% <0%> (+12%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=footer). Last update [12c7a2d...7488ed4](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2593#issuecomment-293046056:3826,Power,Powered,3826,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2593#issuecomment-293046056,1,['Power'],['Powered']
Energy Efficiency,| `86.667% <83.333%> (-2.222%)` | `4 <1> (+1)` | |; | [...bender/tools/walkers/annotator/ReferenceBases.java](https://codecov.io/gh/broadinstitute/gatk/pull/5082/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SZWZlcmVuY2VCYXNlcy5qYXZh) | `87.5% <0%> (-12.5%)` | `9% <0%> (+4%)` | |; | [...institute/hellbender/utils/test/ReadTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5082/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRUZXN0VXRpbHMuamF2YQ==) | `94.34% <0%> (-2.803%)` | `5% <0%> (+2%)` | |; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/5082/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyLmphdmE=) | `87.273% <0%> (-2.013%)` | `35% <0%> (+17%)` | |; | [...ils/read/markduplicates/sparkrecords/Fragment.java](https://codecov.io/gh/broadinstitute/gatk/pull/5082/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL3NwYXJrcmVjb3Jkcy9GcmFnbWVudC5qYXZh) | `92% <0%> (-1.75%)` | `14% <0%> (+7%)` | |; | [...r/tools/spark/sv/utils/GATKSVVCFUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5082/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9HQVRLU1ZWQ0ZVdGlsc1VuaXRUZXN0LmphdmE=) | `91.379% <0%> (-1.644%)` | `18% <0%> (+5%)` | |; | [...ion/basicshortmutpileup/PowerCalculationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5082/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9Qb3dlckNhbGN1bGF0aW9uVXRpbHMuamF2YQ==) | `95.122% <0%> (-1.545%)` | `31% <0%> (+13%)` | |; | ... and [81 more](https://codecov.io/gh/broadinstitute/gatk/pull/5082/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5082#issuecomment-410074867:3741,Power,PowerCalculationUtils,3741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5082#issuecomment-410074867,1,['Power'],['PowerCalculationUtils']
Energy Efficiency,â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...bender/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F42617365526563616C69627261746F72537061726B536861726465642E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...lbender/tools/spark/pipelines/SortReadFileSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F706970656C696E65732F536F72745265616446696C65537061726B2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...nes/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F706970656C696E65732F6D6574726963732F436F6C6C65637442617365446973747269627574696F6E42794379636C65537061726B2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...dline/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F4741544B506C7567696E2F4741544B5265616446696C746572506C7567696E44657363726970746F722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [.../hellbender/tools/walkers/bqsr/BaseRecalibrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F627173722F42617365526563616C69627261746F722E6A617661) |; > [Review all 30 files changed](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare). > Powered by [Codecov](https://codecov.io?src=pr). Last update [c5851a0...517230c](https://codecov.io/gh/broadinstitute/gatk/compare/c5851a00f972bacaff751cbebad20ed1dc64ebbe...517230cca0aa73c4b9b935a94a8fc576aca7dedc?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2218#issuecomment-254678913:4105,Power,Powered,4105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2218#issuecomment-254678913,1,['Power'],['Powered']
Energy Efficiency,"â€¦al memory (as opposed to resident memory) under control. This solves (I think) a long-time problem for anyone using the GATK under SGE or any other scheduler that imposes hard limits on _virual_ memory. The posting at this link describes in detail what is going on:. https://www.ibm.com/developerworks/community/blogs/kevgrig/entry/linux_glibc_2_10_rhel_6_malloc_may_show_excessive_virtual_memory_usage?. TL;DR: there was a change in `malloc` in `glibc` several years ago that attempts to make memory allocation more efficient in multi-threaded apps on multi-core machines, by creating many memory pools (arenas) from which allocation requests are satisfied. On systems with lots of CPUs it can cause virtual memory usage to balloon up to many times the heap size (e.g. we see 30GB VIRT with -Xmx4G and < 4G resident). In some very limited testing I didn't see any significant performance change from limiting the number of arenas. My suspicion is that since Java is allocating fairly large blocks of memory using `malloc` and then allocating internal to the JVM this shouldn't have much if any affect on Java programs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5849:149,schedul,scheduler,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5849,2,"['efficient', 'schedul']","['efficient', 'scheduler']"
Integrability,	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); 	at com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); 	at com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); 	at com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:100); 	at com.luz.push.util,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:13973,protocol,protocol,13973,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,3,['protocol'],['protocol']
Integrability,	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnectio,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1509,wrap,wrapper,1509,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,[39m[0K. java.lang.IllegalStateException: Something went wrong: [0K. at org.broadinstitute.hellbender.tools.walkers.gnarlyGenotyper.GnarlyGenotyperEngine.finalizeGenotype(GnarlyGenotyperEngine.java:131). at org.broadinstitute.hellbender.tools.walkers.gnarlyGenotyper.GnarlyGenotyper.apply(GnarlyGenotyper.java:287). at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104). at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.Iterator.forEachRemaining(Iterator.java:116). at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801). at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482). at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472). at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151). at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174). at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234). at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418). at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102). at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210). at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163). at org.broadinstitute.hellbender.Main.instanceMain(Main.java:149). at org.broadinstitute.hellben,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6079#issuecomment-539518973:1545,wrap,wrapAndCopyInto,1545,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6079#issuecomment-539518973,1,['wrap'],['wrapAndCopyInto']
Integrability, /work/Analysis/wgs_chr19/callset.json; 15:00:38.849 INFO GenomicsDBImport - Complete VCF Header will be written to /work/Analysis/wgs_chr19/vcfheader.vcf; 15:00:38.850 INFO GenomicsDBImport - Importing to array - /work/Analysis/wgs_chr19/genomicsdb_array; 15:00:38.850 INFO ProgressMeter - Starting traversal; 15:00:38.850 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 15:00:39.771 INFO GenomicsDBImport - Importing batch 1 with 5 samples; Buffer resized from 28469bytes to 32688; Buffer resized from 28473bytes to 32630; Buffer resized from 28469bytes to 32745; Buffer resized from 28469bytes to 32717; Buffer resized from 28466bytes to 32648; Buffer resized from 32688bytes to 32758; Buffer resized from 32630bytes to 32726; Buffer resized from 32648bytes to 32703; Buffer resized from 32717bytes to 32751; Buffer resized from 32703bytes to 32765; Buffer resized from 32745bytes to 32768; Buffer resized from 32726bytes to 32763; Buffer resized from 32765bytes to 32767; Buffer resized from 32758bytes to 32765; Buffer resized from 32751bytes to 32762; Buffer resized from 32767bytes to 32769; Buffer resized from 32763bytes to 32768; Buffer resized from 32762bytes to 32768; Buffer resized from 32765bytes to 32767; Buffer resized from 32767bytes to 32769; Buffer resized from 32768bytes to 32769; Buffer resized from 32768bytes to 32769; Buffer resized from 32768bytes to 32769; terminate called after throwing an instance of 'VariantStorageManagerException'; what(): VariantStorageManagerException exception : Error while syncing array chr19$1$58617616 to disk; TileDB error message : [TileDB::utils] Error: Cannot sync file '/work/Analysis/wgs_chr19/chr19$1$58617616/.__a89fdd44-1241-43ba-9072-6fcf116fbc1d139627949156096_1538460040234'; File syncing error. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/13135/gatk-v4-0-8-1-genomicsdbimport-error-variantstoragemanagerexception-exception/p1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5342:4401,message,message,4401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5342,1,['message'],['message']
Integrability," 02:53:12,34] [info] Aborting all running workflows.; [2019-10-01 02:53:12,34] [info] JobExecutionTokenDispenser stopped; [2019-10-01 02:53:12,35] [info] WorkflowStoreActor stopped; [2019-10-01 02:53:12,35] [info] WorkflowLogCopyRouter stopped; [2019-10-01 02:53:12,35] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2019-10-01 02:53:12,35] [info] WorkflowManagerActor All workflows finished; [2019-10-01 02:53:12,35] [info] WorkflowManagerActor stopped; [2019-10-01 02:53:12,65] [info] Connection pools shut down; [2019-10-01 02:53:12,65] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] SubWorkflowStoreActor stopped; [2019-10-01 02:53:12,65] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2019-10-01 02:53:12,65] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2019-10-01 02:53:12,66] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2019-10-01 02:53:12,66] [info] KvWriteActor Shutting down: 0 queued messages to process; [2019-10-01 02:53:12,66] [info] JobStoreActor stopped; [2019-10-01 02:53:12,66] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2019-10-01 02:53:12,66] [info] CallCacheWriteActor stopped; [2019-10-01 02:53:12,66] [info] IoProxy stopped; [2019-10-01 02:53:12,66] [info] ServiceRegistryActor stopped; [2019-10-01 02:53:12,67] [info] DockerHashActor stopped; [2019-10-01 02:53:12,69] [info] Database closed; [2019-10-01 02:53:12,69] [info] Stream materializer shut down; [2019-10-01 02:53:12,69] [info] WDL HTTP import resolver closed; Workflow c55a06f3-abc1-4db1-8e0f-ea0303caab2c transitioned to state Failed; ```. Any help will be much appreciated. Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6189:10807,message,messages,10807,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6189,3,['message'],['messages']
Integrability," 16:25:50 INFO DAGScheduler:54 - Job 4 failed: collect at FindBreakpointEvidenceSpark.java:963, took 30.909355 s; 2019-02-17 16:25:50 INFO AbstractConnector:318 - Stopped Spark@7433ca19{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-02-17 16:25:50 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-02-17 16:25:50 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-02-17 16:25:50 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-02-17 16:25:50 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-02-17 16:25:50 INFO BlockManagerInfo:54 - Added taskresult_980 in memory on scc-q04.scc.bu.edu:41981 (size: 4.9 MB, free: 42.5 GB); 2019-02-17 16:25:50 ERROR TransportRequestHandler:210 - Error while invoking RpcHandler#receive() for one-way message.; org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.; at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:160); at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:140); at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:655); at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:208); at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:113); at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:43010,message,message,43010,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['message'],['message']
Integrability," 3 parts:; 1. The PGEN-JNI, a C++/JNI library that handles writing HTSJDK VariantContext objects to PGEN files,; 2. ExtractCohortToPgen, a GATK tool based on ExtractCohortToVcf that processes VariantContexts and passes them to PGEN-JNI for writing, and; 3. GvsExtractCallsetPgenMerged, a WDL workflow based on GvsExtractCallset that uses ExtractCohortToPgen to write a series of PGEN files and then merges them by chromosome. ### Part 1: PGEN-JNI; The PGEN-JNI library was written by Chris Norman of the GATK Engine Team and lives [here](https://github.com/broadinstitute/pgen-jni). It is written primarily in C++ for performance purposes and also compatibility with the pgenlib library (part of the [plink repo](https://github.com/chrchang/plink-ng/tree/master)). It builds on top of pgenlib to provide a writer for creating PGEN files and writing to them from HTSJDK VariantContext objects. PGEN-JNI is compatible with Linux and macOS. A build of this library is currently hosted on the Broad's artifactory repo, and that is being used as a dependency for GATK. Ownership of the PGEN-JNI library will stay with the GATK Engine Team and we will provide support for it if y'all encounter any issues with it. ### Part 2: ExtractCohortToPgen; ExtractCohortToPgen is a GATK tool that inherits from ExtractCohort and is based very closely on ExtractCohortToVcf. It produces 3-4 files:. 1. A `.pgen` file, which contains a mapping of samples and sites to variants,; 2. A `.psam` file, which contains a list of sample names,; 3. A `.pvar.zst` file, which is a zstd compressed list of sites with alleles, similar to a sites-only VCF, and; 4. Optionally (if specified by setting `write-mode` to `WRITE_SEPARATE_INDEX`), a `.pgi` file, which contains an index for the `.pgen` file. It has a few arguments that are specific to it that warrant explanation. #### pgen-chromosome-code; Plink defines a set of [chromosome codes](https://www.cog-genomics.org/plink/2.0/data#irreg_output) that correspond to differen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708:2664,depend,dependency,2664,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708,1,['depend'],['dependency']
Integrability, 45; 	at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.getBase(SAMRecordToGATKReadAdapter.java:264); 	at org.broadinstitute.hellbender.tools.walkers.annotator.CountNs.doesReadHaveN(CountNs.java:61); 	at org.broadinstitute.hellbender.tools.walkers.annotator.CountNs.lambda$annotate$1(CountNs.java:46); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:174); 	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948); 	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:270); 	at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); 	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); 	at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.LongPipeline.reduce(LongPipeline.java:438); 	at java.util.stream.LongPipeline.sum(LongPipeline.java:396); 	at java.util.stream.ReferencePipeline.count(ReferencePipeline.java:526); 	at org.broadinstitute.hellbender.tools.walkers.annotator.CountNs.annotate(CountNs.java:46); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:268); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:192); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:233); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:232); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processRea,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6336:1346,wrap,wrapAndCopyInto,1346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6336,1,['wrap'],['wrapAndCopyInto']
Integrability," 47.3 in stage 2.0 (TID 680, dataflow05.broadinstitute.org): java.lang.IllegalArgumentException: ; Invalid interval. Contig:20 start:62720124 end:62720123; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:34); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:46); at org.broadinstitute.hellbender.engine.spark.BroadcastJoinReadsWithVariants.lambda$join$3d1c3858$1(BroadcastJoinReadsWithVariants.java:27); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:30); at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.lambda$apply$26a6df3e$1(BaseRecalibratorSparkFn.java:28); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:156); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:156); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:706); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:706); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297); at org.apache.spark.rdd.RDD.iterator(RDD.scala:264); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297); at org.apache.spark.rdd.RDD.iterator(RDD.scala:264); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.sca",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1560:1274,Wrap,Wrappers,1274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1560,1,['Wrap'],['Wrappers']
Integrability," 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-07 11:34:12 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-07 11:34:12 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 9.293 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:34055,Wrap,Wrappers,34055,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability," : 8 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location.; Chromosome chr1 position 271413 (TileDB column 271412) has too many alleles in the combined VCF record : 7 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location.; Chromosome chr1 position 275583 (TileDB column 275582) has too many alleles in the combined VCF record : 7 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location.; Chromosome chr1 position 275664 (TileDB column 275663) has too many alleles in the combined VCF record : 7 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location.; Chromosome chr1 position 285109 (TileDB column 285108) has too many alleles in the combined VCF record : 7 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. 20:40:00.698 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.6447453060000009,Cpu time(s),0.6353685659999999; [January 14, 2022 8:40:00 PM MST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 1.40 minutes.; Runtime.totalMemory()=2523922432; java.lang.IllegalStateException: Genotype [1057-01 CTT*/* GQ 99 DP 67 AD 34,21,3,6,1,0,2,0 {SB=7,27,15,18}] does not contain likelihoods necessary to calculate posteriors.; ```. So in my case, it is also failing after a site where number of alt alleles (7) is exactly 1 more than --max-alternate-alleles (6), but not always on the first such variant with 7 alt alleles, depending on other command line options. If I revert GenotypeGVCFs to previous versions from 4.1.9.0 to 4.2.4.0 they all work (using the same GVCF database from GenomicsDBImport 4.2.4.1), so this apparent bug is new in GenotypeGVCFs 4.2.4.1.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1015835315:4687,depend,depending,4687,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1015835315,1,['depend'],['depending']
Integrability," DP=72;ECNT=2;MBQ=0,0;MFRL=0,0;MMQ=0,0;MPOS=0;POPAF=7.30;REF_BASES=GGTATACAAGGTTTGACATCT;SAAF=0.00,0.00,NaN;SAPP=0.025,0.025,0.950;TLOD=6.82 GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:P_PRIOR_RO:P_RO:ROF_TYPE 0|1:0,0:0.962:0:0,0:0,0:0|1:53302899_G_C:53302899:1.444e-05:2.931e-03:F2R1; ```. Stacktrace:; ```; java.lang.IllegalArgumentException: errorRateLog10 must be good probability but got NaN; at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleLog10ErrorRate(QualityUtils.java:321); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.lambda$applyGermlineVariantFilter$16(Mutect2FilteringEngine.java:286); at java.util.stream.DoublePipeline$3$1.accept(DoublePipeline.java:231); at java.util.Spliterators$DoubleArraySpliterator.forEachRemaining(Spliterators.java:1198); at java.util.Spliterator$OfDouble.forEachRemaining(Spliterator.java:822); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:286); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:519); at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:130); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpli",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452818901:1307,wrap,wrapAndCopyInto,1307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452818901,1,['wrap'],['wrapAndCopyInto']
Integrability, Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [2935907552.11](https://github.com/broadinstitute/gatk/runs/8042744893?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.11/tests/test/index.html) |; | cloud | 8 | [2935907552.10](https://github.com/broadinstitute/gatk/runs/8042744743?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.10/tests/test/index.html) |; | unit | 11 | [2935907552.13](https://github.com/broadinstitute/gatk/runs/8042745129?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.13/tests/test/index.html) |; | integration | 11 | [2935907552.12](https://github.com/broadinstitute/gatk/runs/8042744999?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.12/tests/test/index.html) |; | conda | 8 | [2935907552.3](https://github.com/broadinstitute/gatk/runs/8043019512?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.3/tests/test/index.html) |; | unit | 8 | [2935907552.1](https://github.com/broadinstitute/gatk/runs/8043019322?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.1/tests/test/index.html) |; | variantcalling | 8 | [2935907552.2](https://github.com/broadinstitute/gatk/runs/8043019429?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.2/tests/test/index.html) |; | integration | 8 | [2935907552.0](https://github.com/broadinstitute/gatk/runs/8043019196?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1228829876:1904,integrat,integration,1904,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1228829876,1,['integrat'],['integration']
Integrability, Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3002176541.11](https://github.com/broadinstitute/gatk/runs/8212856906?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.11/tests/test/index.html) |; | cloud | 8 | [3002176541.10](https://github.com/broadinstitute/gatk/runs/8212856796?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.10/tests/test/index.html) |; | unit | 11 | [3002176541.13](https://github.com/broadinstitute/gatk/runs/8212857102?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.13/tests/test/index.html) |; | integration | 11 | [3002176541.12](https://github.com/broadinstitute/gatk/runs/8212857016?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.12/tests/test/index.html) |; | unit | 8 | [3002176541.1](https://github.com/broadinstitute/gatk/runs/8213287905?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.1/tests/test/index.html) |; | integration | 8 | [3002176541.0](https://github.com/broadinstitute/gatk/runs/8213287794?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.0/tests/test/index.html) |; | variantcalling | 8 | [3002176541.2](https://github.com/broadinstitute/gatk/runs/8213288012?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.2/tests/test/index.html) |; | conda | 8 | [3002176541.3](https://github.com/broadinstitute/gatk/runs/8213288138?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1238473387:1429,integrat,integration,1429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1238473387,1,['integrat'],['integration']
Integrability," I failed to find hg19 host reference in the GATK resource bundle, first I created a BWA image file and a Kmer file originated from hg19 reference fasta with the command below. But for microbe-related files, I used ones that were contained in the bundle. Â . **'''** ; ; **gatk --java-options ""-Xmx50G"" BwaMemIndexImageCreator -I ./ref.fasta** ; **gatk --java-options ""-Xmx50G"" PathSeqBuildKmers --reference ./ref.fasta -O ref.hss** ; ; **'''**. Â . And then I ran PathSeq with the following command. Â . **'''** ; ; **gatk --java-options ""-Xmx200G"" PathSeqPipelineSpark \** ; **--input sample.bam \** ; **--filter-bwa-image ref.fasta.img \** ; **--kmer-file ref.hss \** ; **--is-host-aligned true \** ; **--min-clipped-read-length 70 \** ; **--microbe-fasta pathseq\_microbe.fa \** ; **--microbe-bwa-image pathseq\_microbe.fa.img \** ; **--taxonomy-file pathseq\_taxonomy.db \** ; **--output sample.pathseq.bam \** ; **--scores-output sample.pathseq.txt** ; ; ; **'''**. Â . and unfortunately it was shut down by this error message. **09:27:43.974 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/mnt/clinix1/Analysis/mongol/phenomata/Tools/Anaconda3/envs/gatk4/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so** ; **Mar 05, 2020 9:27:44 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine** ; **INFO: Failed to detect whether we are running on Google Compute Engine.** ; **09:27:44.733 INFO PathSeqPipelineSpark - ------------------------------------------------------------** ; **09:27:44.733 INFO PathSeqPipelineSpark - The Genome Analysis Toolkit (GATK) v4.1.4.1** ; **09:27:44.734 INFO PathSeqPipelineSpark - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/)** ; **09:27:44.734 INFO PathSeqPipelineSpark - Executing as phenomata@cm132 on Linux v2.6.32-573.18.1.el6.x86\_64 amd64** ; **09:27:44.734 INFO PathSeqPi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:1718,message,message,1718,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['message'],['message']
Integrability," INFO TaskSetManager: Lost task 0.1 in stage 2.0 (TID 6) on xx.xx.xx.16, executor 3: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 2]; 01:00 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:55 INFO TaskSetManager: Starting task 0.2 in stage 2.0 (TID 7, xx.xx.xx.23, executor 5, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:55:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.23:42535 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:55:55 INFO TaskSetManager: Lost task 0.2 in stage 2.0 (TID 7) on xx.xx.xx.23, executor 5: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 3]; 01:00 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:55 INFO TaskSetManager: Starting task 0.3 in stage 2.0 (TID 8, xx.xx.xx.24, executor 4, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:56:00 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.24:49966 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:56:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.24:49966 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:56:07 WARN TaskSetManager: Lost task 1.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 1): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSK",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:28752,Wrap,WrappedArray,28752,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Wrap'],['WrappedArray']
Integrability," Instructions. The github issue tracker is for bug reports, feature requests, and API documentation requests. General questions about how to use the GATK, how to interpret the output, etc. should be asked on the [official support forum](http://gatkforums.broadinstitute.org/gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Feature request. ### Tool(s) or class(es) involved. VariantRecalibrator. ### Description. VariantRecalibrator automatically runs the generated Rscript to produce recalibration plots. This is usually good and convenient, but it requires that all *R* dependencies must be installed in the same environment in the current running GATK environment. This is not necessarily the case for sandbox-based package managers e.g. docker or conda. A viable fix on the user's side is to include R dependencies with GATK in e.g. docker or conda. But I think I would prefer if my packages were as independent of each other as possible. It would be great if **VariantRecalibrator had an option to write but not run the Rscript for recalibration plots.** Then, the user can call the Rscript in an appropriate e.g. R conda environment or docker image.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7697:1420,depend,dependencies,1420,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7697,2,['depend'],['dependencies']
Integrability," IntelGKLUtils - Trying to load Intel GKL library from:; jar:file:/Users/daniel/workspaces/gatk4test/build/libs/shadowJar-0.0.1-SNAPSHOT-all.jar!/com/intel/gkl/native/libIntelGKL.dylib; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x0000000128c014d0, pid=31197, tid=5891; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libIntelGKL8818190486223479934.dylib+0xe4d0] _ZN7ContextIfEC2Ev+0x30; #; # Core dump written. Default location: /cores/core or core.31197; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/gatk4test/hs_err_pid31197.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; Abort trap: 6 (core dumped); ```. To fix it, I tried by excluding `com.intel.gkl` from GATK and add it as a dependency to my program, but it blows up anyway. In addition, I tried a sample program to load the PairHMM fastest implementation by `PairHMM.Implementation.FASTEST_AVAILABLE.makeNewHMM()`, and it also blows up. If I remove completely the dependency in my shadow jar, the command line blows up because the gkl `IntelDeflaterFactory` is not found. I guess that the error in the library is GKL-related, but in the case of the GATK framework I would like to have a way of using the library without assuming that the final user will have support for the native code or not. Could this be done? I prefer not to remove the faster code by intel because I know that some users will benefit from it. Just in case it is needed, my system is a Mac OS X (10.11.5) with Darwin Kernel Version 15.5.0 (root:xnu-3248.50.21~8/RELEASE_X86_64 x86_64). Thank you very much in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1985:1522,depend,dependency,1522,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1985,2,['depend'],['dependency']
Integrability," MB, free: 42.5 GB); 2019-02-17 16:25:50 WARN TaskSetManager:66 - Lost task 177.0 in stage 5.0 (TID 1127, scc-q10.scc.bu.edu, executor 14): java.lang.IllegalArgumentException: provided start is negative: -12; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:29293,Wrap,Wrappers,29293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['Wrap'],['Wrappers']
Integrability," MB, free: 42.5 GB); 2019-02-17 16:25:50 WARN TaskSetManager:66 - Lost task 178.0 in stage 5.0 (TID 1119, scc-q06.scc.bu.edu, executor 23): java.lang.IllegalArgumentException: provided start is negative: -26; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:36733,Wrap,Wrappers,36733,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['Wrap'],['Wrappers']
Integrability, Server VM warning: Insufficient space for shared memory file:; 30934; Try using the -Djava.io.tmpdir= option to select an alternate temp location. FAILURE: Build failed with an exception. * What went wrong:; Gradle could not start your build.; > Cannot create service of type DependencyLockingHandler using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyLockingHandler() as there is a problem with parameter #2 of type ConfigurationContainerInternal.; > Cannot create service of type ConfigurationContainerInternal using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createConfigurationContainer() as there is a problem with parameter #13 of type DefaultConfigurationFactory.; > Cannot create service of type DefaultConfigurationFactory using DefaultConfigurationFactory constructor as there is a problem with parameter #2 of type ConfigurationResolver.; > Cannot create service of type ConfigurationResolver using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyResolver() as there is a problem with parameter #1 of type ArtifactDependencyResolver.; > Cannot create service of type ArtifactDependencyResolver using method DependencyManagementBuildScopeServices.createArtifactDependencyResolver() as there is a problem with parameter #4 of type List<ResolverProviderFactory>.; > Could not create service of type VersionControlRepositoryConnectionFactory using VersionControlBuildSessionServices.createVersionControlSystemFactory().; > Failed to create parent directory '/home/jdjdj0202/gatk/.gradle' when creating directory '/home/jdjdj0202/gatk/.gradle/vcs-1'. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. BUILD FAILED in 754ms. FAILURE: Build failed with an exception. * What went wrong:; Could not update /home/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8346:1571,Depend,DependencyResolutionScopeServices,1571,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8346,1,['Depend'],['DependencyResolutionScopeServices']
Integrability, This issue is created from a forum bug report (https://gatkforums.broadinstitute.org/gatk/discussion/24511/error-in-readspipelinespark-version-4-1-4/p1). More information can be requested if necessary. Stack trace copied below:; > A USER ERROR has occurred: Couldn't write file hdfs://cloudera08/gatk-test2/WES2019-022_S4_out.vcf because writing failed with exception concat: target file /gatk-test2/WES2019-022_S4_out.vcf.parts/output is empty; > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInternal(FSNamesystem.java:2303); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInt(FSNamesystem.java:2257); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concat(FSNamesystem.java:2219); > at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.concat(NameNodeRpcServer.java:829); > at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.concat(AuthorizationProviderProxyClientProtocol.java:285); > at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.concat(ClientNamenodeProtocolServerSideTranslatorPB.java:580); > at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); > at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617); > at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2278); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2274); > at java.security.AccessController.doPrivileged(Native Method); > at javax.security.auth.Subject.doAs(Subject.java:422); > at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924); > at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2272); > ; > org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file hdfs://cloudera08/gatk-test2/WES2019-022_S4_out.vcf ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6218:1243,protocol,protocolPB,1243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6218,1,['protocol'],['protocolPB']
Integrability," ```; private static JavaSparkContext createTestSparkContext(Map<String, String> overridingProperties) {; determineSparkMaster();; final SparkConf sparkConf = setupSparkConf(""TestContext"", DEFAULT_SPARK_MASTER, DEFAULT_TEST_PROPERTIES, overridingProperties);; return new JavaSparkContext(sparkConf);; }. /**; * Determine the number of cores Spark master should use. Only used in Spark Test; * Read the specification from the environmental variable GATK_TEST_SPARK_CORES; * If the value is a valid positive integer, use it; * If the value is bogus (strings, etc), or the env. var. is not set, use all available cores, as in ""local[*]""; */. private static void determineSparkMaster() {; int foo = 0;; try {; foo = Integer.parseInt( System.getenv(""GATK_TEST_SPARK_CORES"") );; } catch ( NumberFormatException e ) {}; String numSparkCores;; if ( foo > 0 ) {; numSparkCores = String.format(""[%d]"", foo);; } else {; numSparkCores = ""[*]"";; }; DEFAULT_SPARK_MASTER = ""local"" + numSparkCores;; }. ```. Error messages:. ```; java.lang.NullPointerException at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:77); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:36); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:74); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:65); at org.broadinstitute.hellbender.utils.test.testers.SamFileTester.runTest(SamFileTester.java:263); at org.broadinstitute.hellbender.utils.test.testers.AbstractMarkDuplicatesComman",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1768:1326,message,messages,1326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1768,1,['message'],['messages']
Integrability," a better format. The requirements seem to be: (a) efficient serialization/deserialization, and (b) can easily convert to a SAMRecord for compatibility with existing code. We can make things extra efficient by only deserializing things if they are needed (if a phase doesn't need the CIGAR-related structures, no need to deserialize that). We can achieve this by having the deserialization be lazy. The LazyBAMRecord is a step in that direction since it looks up the reference name only if we ask for it, but we could go a lot further in this direction. But before we do that, having an efficient coder for SAMRecords (I vote for @tomwhite's approach of using the BAMEncoder) will get us 80% of the way for 20% of the effort. Then we can introduce our OptimizedSAMRecord incrementally. . on **headers**:. I agree with @tomwhite that adding the header back after a shuffle is the right thing to do. We know where that happens and we control that code.; @davidadamsphd, you worry about newcomers. But we've already decided that we were going to provide our own API for them (one that does the Dataflow copying for them so they don't have to worry about it). This same API will provide them with header-filled reads, so they don't have to worry about this detail. This falls into the general category of ""the 3rd party devs won't have to even know about Dataflow/Spark: they just need to know our nice, simple interface and use that"". If they know more and want to do fancier things then more power to them, but those users will surely be able to fill in headers, too. We have library functions to use the reads without the headers, but the problem is that (at least for the sort of code I'm writing), I'm handing off a SAMRecord to a big black box and I can't force it to use the library functions - it's going to work on the SAMRecord directly. So at least in this case it's important to fill in the header (unless I happen to know that the ""black box"" won't call any of the header-requiring methods).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141151451:1502,interface,interface,1502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141151451,1,['interface'],['interface']
Integrability," and capturing/resolving these BND's that are not suitable for _THIS PARTICULAR_ logic. I guess in general my personal preference is to put less algorithm-related information in VCF for analysts (less reading for them), and produce add on files for tool developers. What's your thoughts?. > Does this even have to be a spark tool? It looks like you are just reading the variants into a parallel spark context, filtering, and then collecting them to actually process them. Why not just make this a non-spark tool and process it all in memory on one node?. Answer: Agree. It doesn't have to be, at least in theory, and it probably is going to be faster as we don't need to incur the Spark overhead for such a typically small job. But (I'm saying too many buts....) up to this point all SV tools are under the package `hellbender.tools.spark.sv`, so I'm following suit here. Note the two classes's main interface methods mentions nothing about RDDs (that's on purpose). ; On the other hand, this is an engineering question I believe, and it depends on whether we want to put as much of discovery code as possible into `StructuralVariationDiscoveryPipelineSpark` (the last commit actually hooks the two classes into it, so a single invocation of the tool produces more variants), or we go wdl in pipelining the whole process. -------. All in all, I think the comments and critics are generally about the ""filtering""/""classifying"" part, and the most serious concern about it is false negatives. Am I understanding correctly? If so, given that the filtering step is only picking the BND's that are suitable to the linking logic, I can imagine the false negative problem be solved in the future by other logics (e.g. more relaxed requirement on pair matching, or not even requiring matching INV55/INV33 pairs, etc.) In fact, that's what I'm planning on.; Another part of the problem is how much I can accomplish in this single PR, and how large it should be&mdash;the forever existing problem for new tools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4789#issuecomment-406483929:6278,depend,depends,6278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4789#issuecomment-406483929,1,['depend'],['depends']
Integrability," and reading the right arrays. For example, if you wish to read (""chr2"", [ 50, 50M] ), then only the second array is queried.; - In the previous version of the tool, the array name was a constant - _genomicsdb_array_. The new version will be backward compatible with respect to reads. Hence, if a directory named _genomicsdb_array_ is found in the workspace directory, it's passed as the array for the _GenomicsDBFeatureReader_ otherwise the array names are generated from the directory entry names.; - Parallel import based on chromosome intervals. The number of threads to use can be specified as an integer argument to the [executeImport call](https://github.com/francares/gatk/blob/fmc_GenomicsDB_parallel_import/src/main/java/org/broadinstitute/hellbender/tools/genomicsdb/GenomicsDBImport.java#L535). If no argument is specified, the number of threads is determined by Java's ForkJoinPool (typically equal to the \#cores in the system). ; - The max number of intervals to import in parallel can be controlled by the command line argument --max-num-intervals-to-import-in-parallel (default 1); - Note that increasing parallelism increases the number of FeatureReaders opened to feed data to the importer. So, if you are using _N_ threads and your batch size is _B_, you will have _N*B_ feature readers open.; - Protobuf based API for import and read; - [Import](https://github.com/francares/gatk/blob/fmc_GenomicsDB_parallel_import/src/main/java/org/broadinstitute/hellbender/tools/genomicsdb/GenomicsDBImport.java#L522); - [Read](https://github.com/francares/gatk/blob/fmc_GenomicsDB_parallel_import/src/main/java/org/broadinstitute/hellbender/engine/FeatureDataSource.java#L405); - #3688 ; - Option to produce GT field; - [Option to produce GT for spanning deletion based on min PL value](https://github.com/Intel-HLS/GenomicsDB/issues/161); - https://github.com/broadinstitute/gatk/issues/2687; - Doesn't support #4541 or #3689 yet - next version; - Bug fixes; - #4716 ; - More error messages",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645:2656,message,messages,2656,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645,1,['message'],['messages']
Integrability, args to java side; major update to germline WDLs; all optional python args exposed to WDLs as optional args. commit 50cb6fd08de15469a9080cbb27ff30c8b7ee7e21; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:50:45 2017 -0500. missing serialVersionUID. commit 5f0f31eab63b0e6f6105708ded7f86c96c830781; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:35:33 2017 -0500. annotated intervals kebab case; updated germline WDL workflows. commit 29cc6234dbfb8db12559217a650c6ceb170c5797; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:15:28 2017 -0500. cleanup test files. commit 08a35bb4e65eceb735adcd41a91132e9a34d2b66; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:50:19 2017 -0500. update WDL scripts. commit 12bcfa192ee6fa6da21239ebf5b513633efe974f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:47:33 2017 -0500. significant updates to GermlineCNVCaller; integration tests for GermlineCNVCaller w/ sim data in both run modes. commit 151416a4af735ca721bd75e4b54a780c17ac9397; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 01:42:05 2017 -0500. hybrid ADVI abstract argument collection w/ flexible default values; hybrid ADVI argument collection for contig ploidy model; hybrid ADVI argument collection for germline denoising and calling model. commit 56e21bf955d3dc0c52aceb384f28cf6173959de0; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 23:18:39 2017 -0500. rewritten python-side coverage metadata table reader using pandas to fix the issues with comment line; change criterion for cohort/case based on whether a contig-ploidy model is provided or not; simulated test files for ploidy determination tool; proper integration test for ploidy determination tool and all edge cases; updated docs for ploidy determination tool. commit 7fa104b2e9170770cfc5b338835e41215d7fd39c; Author: Mehrtash Babadi <mehrtash@broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:6922,integrat,integration,6922,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,1,['integrat'],['integration']
Integrability," as a line. This is similar but not analogous to the current behavior for the existing gene lists where we take pains to exclude from the overlap counts bases that are intronic bases in the gene list. . Unfortunately, since the GFF3 format is hierarchical and supports a very large number of feature types it will be very difficult to extract the intron/exon boundaries without properly parsing the GFF3 format. The GFF3 format supports .obo files that lay out the feature hierarchy and through parsing of that format it would be possible to extract intron/exon boundaries but that is not currently supported by HTSJDK and would involve us merging https://github.com/kachulis/htsjdk/tree/ck_gff3_feature_evaluator first in order to support and then on top of that coming up with some rules for deciding what units exactly make up a gene that should be merged for coverage counting. . I see a few options going forwards:; - We could support GFF3 gene lists with hard coded genes/CDS features to be included. This is brittle given that there are a number of more specific names for CDS (coding sequence) exons in genes that might end up being excluded.; - We could support GFF3 format but ignore exon sequences which would mean that the behavior for counting the same genes will vary depending on which format the gene is provided.; - We could support GFF3 gene lists but allow the user to specify exactly what feature types they want to include. This would probably be the best stop-gap solution but we would have to think hard about how to have the user specify ""I want to count genes (with these possible sub-names for what a gene is) and here is a list of CDS elements that could possibly constitute gene exons."" seems complicated to implement correctly but it has the added advantage of probably allowing the user to do much more interesting/fancy analyses with DoC.; - We could wait for the .obo file to be implemented and attempt to parse intron/exon boundaries by reading the ontology provided.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6491#issuecomment-683963413:1905,depend,depending,1905,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6491#issuecomment-683963413,1,['depend'],['depending']
Integrability," at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:49 INFO TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:49 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 1, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:25174,Wrap,Wrappers,25174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability, at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:334); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:243); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1845); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1098); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:166); at org.broadinstitute.hellbender.Main.mainEntry(Main.jav,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8800:6360,wrap,wrapAndCopyInto,6360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8800,1,['wrap'],['wrapAndCopyInto']
Integrability," attr={AC=2, AF=0.500, AN=4, DP=155, ExcessHet=0.0000, FS=0.000, MLEAC=2, MLEAF=0.500, MQ=60.00, QD=27.97, SOR=1.204, VQSLOD=-3.754e-01, culprit=QD} GT=GT:AD:DP:GQ:PL 0/0:64,0:64:99:0,120,1800 1/1:0,89:89:99:2505,267,0 filters=; at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:145); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1845); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:136); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1098); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:166); at org.broadinstitute.hellbender.Main.mainEntr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8767:2429,wrap,wrapAndCopyInto,2429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8767,1,['wrap'],['wrapAndCopyInto']
Integrability," batch api for it? Multi layer docker builds are pretty standard from what I understand. . It sounds like your suggestions are talking about 2 slightly different issues to me. 1. Too many layers:. We typically have squashed the GATK docker images, but we recently switched to building our release images with google cloud build. Since squash is *STILL* an experimental feature in docker we've had trouble getting it to work there. Since the size reduction was pretty minimal from squashing we figured it would be ok to not prioritize it. It's definitely possible for us to consolidate various layers in the build. Or manually squash the images. We can take a look for our next release. Wide workflows on azure are something we need to support. 2. Docker size reduction:; I've spend a lot of time looking at this in the past. Our docker image is huge, but it's mostly due to the massive size of our python and R dependencies. I've done a bunch of work reducing temporary files in independent layers and using multiple stages to reduce the size. There's not much low hanging fruit left there. Similarly, moving to alpine is tricky an has limited benefit. GATK packages a number of C libraries which do not work out of the box on alpine due to the different C runtime. (At least that was the case the last time I investigated it a few years ago. ) I suspect there's a way to port things so they work on it, but it's not something we can do now. It also wouldn't be much of a help, the base image is completely dwarfed by piles of python and R dependencies which are very difficult to safely trim. Anyway, that's the state of things. We've considered a java only image for a while which would be much smaller than the current one. (although still fat by most docker standards...). We've never released one publicly because it seemed like it might cause confusion, but it's a reasonable possibility. . If you have any secret methods to reduce the size of python or R installations we're happy to take PRs!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427:1752,depend,dependencies,1752,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427,1,['depend'],['dependencies']
Integrability," burden. The parties interested in working on a specific architecture will contribute code directly to the respective architecture-specific repo and gatk will take occasional updates of those repos. The gatk repo will depend on the other two. The PPC repo will depend on the AVX repo (and any other native repos will depend on the AVX one). The avx and ppc repos will have their own build systems and unit tests against the new interface. The AVX repo will expose something like the following Java API (to be worked out in detail). ```; //Used to copy references to byteArrays to JNI from reads; public final class JNIReadDataHolderClass {; public byte[] readBases = null;; public byte[] readQuals = null;; public byte[] insertionGOP = null;; public byte[] deletionGOP = null;; public byte[] overallGCP = null;; }. //Used to copy references to byteArrays to JNI from haplotypes; public final class JNIHaplotypeDataHolderClass {; public byte[] haplotypeBases = null;; }. public interface NativePairHMMKernel extends AutoCloseable { . /**; * Function to initialize the fields of JNIReadDataHolderClass and JNIHaplotypeDataHolderClass from JVM.; * C++ code gets FieldIDs for these classes once and re-uses these IDs for the remainder of the program. Field IDs do not; * change per JVM session; *; * @param readDataHolderClass class type of JNIReadDataHolderClass; * @param haplotypeDataHolderClass class type of JNIHaplotypeDataHolderClass; */; void jniInitializeClassFields(Class<JNIReadDataHolderClass> readDataHolderClass, Class<JNIHaplotypeDataHolderClass> haplotypeDataHolderClass);. /**; * Real compute kernel; */; void jniComputeLikelihoods(int numReads, int numHaplotypes, JNIReadDataHolderClass[] readDataArray,; JNIHaplotypeDataHolderClass[] haplotypeDataArray, double[] likelihoodArray, int maxNumThreadsToUse);. /**; * Print final profiling information from native code. ; */; default void close() { jniClose(); }. void jniClose();; }; ```. and a class that implements those as native methods",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864:1650,interface,interface,1650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864,1,['interface'],['interface']
Integrability," changes relevant to gatk -; * Allow changes for allele specific and other annotations to vid file via GenomicsDBImporter without hardcoding them in genomicsdb. See [GenomicsDB Fix 39](https://github.com/GenomicsDB/GenomicsDB/pull/39). Thanks @mlathara.; * [Fix](https://github.com/GenomicsDB/GenomicsDB/pull/54) for ; BUGreportGATK-07-19-19 reported by @bshifaw where a large ploidy + number of genotypes was leading to math overflow. The overflow is now caught and GenomicsDB stops enumerating genotypes for this case. Thanks @kgururaj.; * [Fix](https://github.com/GenomicsDB/GenomicsDB/pull/66) for missing libcurl in the native GenomicsDB library - Issue #6122 ; * [Fix](https://github.com/GenomicsDB/GenomicsDB/pull/67) to avoid crashing when vcfbufferstream from htslib happens to be invalid. This check was put in response to the [Forum Issue 59667](https://gatkforums.broadinstitute.org/gatk/discussion/comment/59667#Comment_59667). Note that the test vcfs [sample2](https://github.com/broadinstitute/gatk/tree/master/src/test/resources/org/broadinstitute/hellbender/tools/mutect/createpon/sample2.vcf), [sample3](https://github.com/broadinstitute/gatk/tree/master/src/test/resources/org/broadinstitute/hellbender/tools/mutect/createpon/sample3.vcf) and [sample4](https://github.com/broadinstitute/gatk/tree/master/src/test/resources/org/broadinstitute/hellbender/tools/mutect/createpon/sample4.vcf) had to be changed to be htslib compliant for importing and to run `org.broadinstitute.hellbender.tools.walkers.mutect.CreateSomaticPanelOfNormalsIntegrationTest` successfully.; * Allow for native GenomicsDBExceptions to be propagated as java IOExceptions to allow gatk to gracefully handle the exception by printing out relevant information. See [GenomicsDB Fix 68](https://github.com/GenomicsDB/GenomicsDB/pull/68).; * [Fix](https://github.com/GenomicsDB/GenomicsDB/pull/70) for issues using vid protobuf interface to pass vid information and there is more than one config. Thanks @mlathara.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6188:1927,interface,interface,1927,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6188,1,['interface'],['interface']
Integrability," chr1_KI270708v1_random:2666 Q. of type=SNP alleles=[T*, A] attr={AS_FilterStatus=SITE, AS_SB_TABLE=[7, 9|3, 11], DP=30, ECNT=2, GERMQ=13, MBQ=[33, 37], MFRL=[317, 323], MMQ=[48, 47], MPOS=47, POPAF=7.30, ROQ=83, TLOD=47.80} GT=GT:AD:AF:DP:F1R2:F2R1:FAD:SB 0/1:16,14:0.486:30:8,9:5,4:15,14:7,9,3,11 filters=; at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:145); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:136); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:165); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1095); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Mai",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8221:11244,wrap,wrapAndCopyInto,11244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8221,1,['wrap'],['wrapAndCopyInto']
Integrability," current = Allele.create(e.getBase());; }; pralm.add(e, current, DEFAULT_FAKE_LIKELIHOOD);; }; return pralm;; }; ```. The solution that I found after looking at the class was this one, that it's very complicated:. ``` java; public static ReadLikelihoods<Allele> flatPerReadAlleleLikelihoodsFromPileup(final ReadPileup pileup, final Allele refAllele, final SAMFileHeader header) {; final Set<Allele> alleleSet = new TreeSet<Allele>();; final Map<String, List<GATKRead>> reads = new HashMap<>();; final byte ref = refAllele.getBases()[0];; alleleSet.add(refAllele);; for (final PileupElement e : pileup) {; if (e.isDeletion()) {; alleleSet.add(Allele.SPAN_DEL);; } else if (e.getBase() == ref) {; alleleSet.add(refAllele);; } else {; alleleSet.add(Allele.create(e.getBase()));; }; final String sample = ReadUtils.getSampleName(e.getRead(), header);; List<GATKRead> list = reads.getOrDefault(sample, null);; if(list == null) {; list = new ArrayList<>();; reads.put(sample, list);; }; list.add(e.getRead());; }; final ReadLikelihoods<Allele> likelihoods = new ReadLikelihoods<>(new IndexedSampleList(reads.keySet()), new IndexedAlleleList<Allele>(alleleSet), reads);; for(final PileupElement e: pileup) {; final String sample = ReadUtils.getSampleName(e.getRead(), header);; final LikelihoodMatrix<Allele> l = likelihoods.sampleMatrix(likelihoods.indexOfSample(sample));; final int alleleIndex;; if (e.isDeletion()) {; alleleIndex = likelihoods.indexOfAllele(Allele.SPAN_DEL);; } else if (e.getBase() != ref) {; alleleIndex = likelihoods.indexOfAllele(Allele.create(e.getBase());; } else {; alleleIndex = likelihoods.indexOfReference();; }. l.set(alleleIndex, l.indexOfRead(e.getRead()), DEFAULT_FAKE_LIKELIHOOD);; }; return likelihoods;; }; ```. This example is very simple, but in my case what I need its to assign an unique likelihood to each read after calling the variant for that read. I want to use the variant annotation engine for annotate this likelihood map because it is using this interface.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249930107:2622,interface,interface,2622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249930107,1,['interface'],['interface']
Integrability," due to stage failure: Task 12 in stage 0.0 failed 4 times, most recent failure: Lost task 12.3 in stage 0.0 (TID 14, scc-q09.scc.bu.edu, executor 1): java.lang.IllegalArgumentException: **Wrong FS: hdfs://scc:8020/user/farrell/adsp/bams/SRR990385.bai, expected: hdfs://scc**; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:105); at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302); at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298); at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766); at org.seqdoop.hadoop_bam.util.WrapSeekable.openPath(WrapSeekable.java:60); at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:142); at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:121); at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:178); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:177); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:134); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:69); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.R",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3909:1903,Wrap,WrapSeekable,1903,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3909,1,['Wrap'],['WrapSeekable']
Integrability," have to run it twice, first to combine the new cohort, then to combine the new cohort with older animals so that I have 1 file to feed to genotypegVCF. . As such I am now reverting back to GATK 3.6. It would be very nice if genomicDBimport allowed addition of new data to existing database, and/or genotypegVCF allowed multiple gVCFs."". ----; User Report; ----. This is the error message I am getting but it doesn't make much sense, given that I got it also on smaller datasets with large amounts of memory (larger than some of the specifications listed on this forum for genomicDBimport). Our IT people, after observing the job, seem to think this is a java-related bug as the process itself doesn't use anywhere near the memory specified. We have installed a new version of java and I will be re-running the analysis to see if this solved the issues. . I'm not sure if I should be creating a new thread for this, but I do have a general comment about genomicDBimport. The project I am involved with is in partnership with an industrial partner, who sequences a number of animals every few weeks. In the pipeline using GATK 3.6, the newly sequenced animals were combined using combinegVCF and multiple gVCFs were then fed into genotypeGVCFs. . Unless I am missing something, the current set up in GATK 4.0 is not ideal for routine sequencing. First, I need to combine all animals every time a new batch of data is added (rather than adding a batch to existing database). Second, if I decide to use combineGVCFs in GATK 4.0, I have to run it twice, first to combine the new cohort, then to combine the new cohort with older animals so that I have 1 file to feed to genotypegVCF. . As such I am now reverting back to GATK 3.6. It would be very nice if genomicDBimport allowed addition of new data to existing database, and/or genotypegVCF allowed multiple gVCFs. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/47819#Comment_47819",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4667:1645,rout,routine,1645,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4667,1,['rout'],['routine']
Integrability," is my command line:; `java -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar ${gatk4_jar} IndexFeatureFile --feature-file ${gvcf} --output ${gvcf}.idx 2>${LOGDIR}/index_candidates.log`. I tried this exact command line with another genome, which worked just fine with output progress report as following for a comparison of the multiple chromosomes processed:; ```; 12:50:38.871 INFO ProgressMeter - Starting traversal; 12:50:38.873 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 12:50:48.876 INFO ProgressMeter - N1:21408210 0.2 5669000 34010598.9; 12:50:58.876 INFO ProgressMeter - N2:13383863 0.3 11960000 35874618.8. ...... 12:55:58.884 INFO ProgressMeter - N19:50063133 5.3 208660000 39122405.2; 12:56:02.409 INFO ProgressMeter - N19:55994806 5.4 210940859 39119265.4; 12:56:02.409 INFO ProgressMeter - Traversal complete. Processed 210940859 total records in 5.4 minutes.; 12:56:02.429 INFO IndexFeatureFile - Successfully wrote index to /storage/ppl/yifang/20190225/data3/samtools_sorted_out/SNPs_candidates.g.vcf.idx; 12:56:02.429 INFO IndexFeatureFile - Shutting down engine; [April 25, 2019 12:56:02 PM CST] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 5.42 minutes.; Runtime.totalMemory()=5618270208; ```; Althought no warning/error messages was issued for the indexing of this big genome, I have tried to debug on 3 things I could think of:. 1. The chromosome and the coordinate are sorted ascendandly, although the chromosome names are not simply numeric continuous because of the A/B subgroup for each chromosome.; 2. The genome size difference, for which no clue was aboserved about the chromosome length limits. ; 3. The chromosome names for this big genome is quite long, but I tried the shorter names as A11 for chr1A_part1, A12 for chr1A_part2, ... B72 for chr7B_part2 (42 chromosomes in total), and the problem stayed exactly the same. Not sure what I may have missed. I appreciate any insight of this problem.; Yifang",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5917:5875,message,messages,5875,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5917,1,['message'],['messages']
Integrability," java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:42200,Wrap,Wrappers,42200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['Wrap'],['Wrappers']
Integrability," like this:. ##### ERROR MESSAGE: Invalid command line: No tribble type was provided on the command line and the type of the file could not be determined dynamically. Please add an explicit type tag :NAME listing the correct type from among the supported types:; ##### ERROR Name FeatureType Documentation; ##### ERROR BCF2 VariantContext (this is an external codec and is not documented within GATK); ##### ERROR VCF VariantContext (this is an external codec and is not documented within GATK); ##### ERROR VCF3 VariantContext (this is an external codec and is not documented within GATK); ##### ERROR ------------------------------------------------------------------------------------------. then I added a name like this:. --variant:VCF $NOW/w-91.raw.g.vcf \; --variant:VCF $NOW/w-92.raw.g.vcf \; --variant:VCF $NOW/w-93.raw.g.vcf \. also met a error like this:. ##### ERROR; ##### ERROR MESSAGE: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file; ##### ERROR ------------------------------------------------------------------------------------------. and I change the name like this:. --variant:VCF3 $NOW/w-91.raw.g.vcf \; --variant:VCF3 $NOW/w-92.raw.g.vcf \; --variant:VCF3 $NOW/w-93.raw.g.vcf \. also error:. ##### ERROR MESSAGE: Unable to parse header with error: Your input file has a malformed header: This codec is strictly for VCFv3 and does not support VCFv4.1, for input source: /gss1/home/hjb20181119/panyongpeng/NN1138-2/RIL_genotype/mapping/w-1.raw.g.vcf; ##### ERROR ------------------------------------------------------------------------------------------. I checked my GVCF file and the header is :. ##fileformat=VCFv4.1; ##ALT=<ID=NON_REF,Description=""Represents any possible alternative allele at this location"">; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FORMAT=<ID=AD,Number=.,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=DP,N",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7315:1468,MESSAGE,MESSAGE,1468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7315,1,['MESSAGE'],['MESSAGE']
Integrability," might be a hundred or so reads; and each cell is only contributing one to three reads. For other; mutations, maybe there's less than 10 reads corresponding to less than 10; cells, and it can vary pretty dramatically. The total number of cells; represented in a single sample can be thousands to tens of thousands,; usually - but could be many more as the tech advances. My hack for it at the moment is to encode both the cell barcode and the UMI; information into the read name. Then, for each variant, I query the reads; that overlap that variant in the bam file and analyze each read for; supporting the variant or the REF allele - then I can count the reads; according to the specific cells and also deal with any UMI redundancy per; cell. This works pretty well except for the cases where the HC reassembly; provides evidence for the variant and I can't track it to the originally; aligned reads. Also, mostly I think the difficulty here relates to indels; around homopolymers with our pacbio long isoform reads in our rna-seq; variant pipeline that leverages the gatk rna-seq protocol with HC. On Thu, Feb 29, 2024 at 8:58â€¯AM GÃ¶kalp Ã‡elik ***@***.***>; wrote:. > Since each cell has a barcode wouldn't it be nice to use them as their; > Read Group ID and Sample Name within the BAM so that variant callers will; > distinguish each cell from their Sample Name and produce a multisample VCF; > for that variant site. Once IDs and Sample Names are split per cell you may; > be able to color them differently in IGV to even visually observe those; > events.; >; > â€”; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971203108>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABZRKX6LYHUXDUMGDU3AIFLYV4ZZLAVCNFSM6AAAAABD4OZKJ6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSNZRGIYDGMJQHA>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >. -- ; --; Brian J. Haas; The Br",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971223953:1126,protocol,protocol,1126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971223953,1,['protocol'],['protocol']
Integrability," need to anticipate this; and existing code may need to be updated. In other words, headerless ; SAMRecords should become ""part of the spec"". Third, although I don't know in detail about the different execution ; environments you are trying to support, there is a general strategy that ; I haven't seen discussed in these threads.; Perhaps it's impractical, but I'll mention it anyway. It seems like ; another approach would be to create (internal to the implementation) a ; ""header tag"" that could be efficiently serialized; and passed as part of the SAMRecord when you need to distribute it. The ; header tag could be used by the receiver to reattach the SAMRecord to ; its header (either proactively or on demand), but transparently to ; application code that is running against the SAMRecord API.; This would allow SAM headers to be transmitted out-of-band in a way that ; depends on the execution environment. Depending on the environment, ; this might be done by proactive broadcast, or you could think of the ; header tag as a promise to retrieve the header if/when it is needed. ; The size and complexity of the header tag might also depend on the ; execution environment. If the execution environment only supports a ; small finite number of headers, the header tag could be a small integer, ; or in a different execution environment it could be; a unique hash of the header or something like that. Memory footprint in ; the receiver is minimized because many SAMRecords can all share the same ; header object.; This requires more work to support in each execution environment, but it ; seems like it could be efficient and allows application code written to ; operate on SAMRecords to be portable; across different execution environments without having to contend with ; the possible presence of headerless SAMRecords. -Bob. On 9/17/15 4:28 PM, droazen wrote:. > @davidadamsphd https://github.com/davidadamsphd, @lbergelson ; > https://github.com/lbergelson, and myself met for an hour or t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518:1811,Depend,Depending,1811,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518,1,['Depend'],['Depending']
Integrability," operation in Genome STRiP is to ask for the sample ; associated with a read. This requires the header, I would think.; Anyway, my main point was just to stimulate thinking about the value of ; implementing an efficient way to transmit the headers.; It also seems to me that this generalizes to efficient patterns to ; transmit any widely shared data (that is referenced by many serialized ; individual data items) out-of-band. -Bob. On 9/21/15 11:42 AM, droazen wrote:. > @bhandsaker https://github.com/bhandsaker Thanks for chiming in with ; > your thoughts/concerns.; > ; > Under this proposal, the various classes in htsjdk that read and ; > return |SAMRecords| (eg., |SAMReader| & co.) would continue to put the ; > header inside of the records, so we would not be imposing an ; > additional burden on direct clients of htsjdk to check for null ; > headers any more than they do currently. The only difference is that ; > if downstream consumers of |SAMRecords| (like hellbender) choose to ; > strip the header from the records, there would be an explicit contract ; > governing the behavior of headerless |SAMRecords| (as opposed to the ; > status quo, in which the header may be null but behavior is totally ; > undocumented and in some cases inconsistent -- eg., the reference name ; > and index in a headerless |SAMRecord| can get out-of-sync in some cases).; > ; > In additional to documenting/clarifying the behavior of headerless ; > |SAMRecords| and fixing any consistency-related bugs we find when ; > operating without a header, we would also make an effort to document ; > when a class in htsjdk that consumes |SAMRecords| requires that a ; > header be present in the records (such as the various writer classes).; > ; > Does this sound reasonable? It's actually a much more conservative ; > proposal than it may have initially sounded :); > ; > â€”; > Reply to this email directly or view it on GitHub ; > https://github.com/broadinstitute/hellbender/issues/900#issuecomment-142020109.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142402910:1496,contract,contract,1496,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142402910,1,['contract'],['contract']
Integrability, org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrappe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482:1478,wrap,wrapper,1478,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482,1,['wrap'],['wrapper']
Integrability," table creation and data loading in LoadData (#7056); - WIP; - tieout scripts; - notes files; - updated diff scripts; - fixed bug...; - add wdl and inputs file for warp pipeline; - reverting logging; - included top level WDL; - use gnarly with BQ extract cohort; - remove unused file; - cleaning up; - tidy; - tidy up before PR; - tidy up before PR; - PR comments; - merge conflict misfires; - added example SQL to create alt allele table from VET; - option to remove PLs; - fixed and enhanced unit test; - removing unused config, causing travis to fail; - add CreateVariantIngestFiles integration test (#7071); - add sampleName (instead of NULL) to error message (#7074); - Update To handle if no data error (#7084); - Memory improvement when writing missing positions to pet (#7098); - added support for loading QUALapprox into VET (#7101); - Add -m flag to gsutil step; add dockstore branch filters to facilitate development (#7104); - updates to ImportGenomes and LoadBigQueryData (#7112); - Add ngs to cohort extract Dockerfile; remove exception catching in extract python script (#7113); - remove problematic storage_location imports (#7119); - Reduce memory and CPU for CreateImportTsvs task, check for files before attempting load (#7121); - add -m flag to gsutil mv step (#7129); - ah_var_store : Add sample file argument to cohort extract (#7117); - Perform full WGS cohort extract scientific tieout for 35 ACMG59 samples (#7106); - Enable Read/Execution Project for BQ Queries (#7136); - ah - optional service account (#7140); - Add load lock file to prevent accidental re-loading of data to BQ (#7138); - #251 Address gvcf no-calls missing QUALapprox and other features (#7146); - Job Add labels to BQ operations from GATK (Issues-199) (#7115); - parse map to list to avoid brackets and spaces in vcf output (#7168); - #259 Inline schema for importgenomes.wdl (#7171); - Created AvroFileReader and unittest, Update ExtractCohort and ExtractCohortEngine (#7174); - #224 Import WDL: handle ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:11172,integrat,integration,11172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,"['integrat', 'message']","['integration', 'message']"
Integrability," that. Sincerely,; Emily. From: ldgauthier ***@***.***>; Sent: Monday, March 28, 2022 2:39 PM; To: broadinstitute/gatk ***@***.***>; Cc: Emily Elizabeth Puckett (puckett3) ***@***.***>; Mention ***@***.***>; Subject: Re: [broadinstitute/gatk] CombineGVCFs: ERROR input alleles must contain <NON_REF> (Issue #7737). CAUTION: This email originated from outside of the organization. Do not click links or open attachments unless you recognize the sender and trust the content is safe. If I'm reading the process correctly, I don't actually think this should work. CombineGVCFs is specifically for combining GVCFs and it expects GVCFs to have <NON_REF> alleles. If you've already run the data through GenotypeGVCFs then you can't use CombineGVCFs again because the <NON_REF> likelihoods have been applied and those alleles are gone. The vcfcombine tool from bcftools is quite fast if all you want to do is join the samples together. -; Reply to this email directly, view it on GitHub<https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fbroadinstitute%2Fgatk%2Fissues%2F7737%23issuecomment-1081062021&data=04%7C01%7CEmily.Puckett%40memphis.edu%7C51db6aa9f41b483e1ce408da10f2aa5d%7Cae145aeacdb2446ab05a7858dde5ddba%7C0%7C0%7C637840931685525269%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=Pxg8joQfE51l5e3cUUbKA9bQEYDZjp0AxdX0aqDG1MY%3D&reserved=0>, or unsubscribe<https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FALDFEHAXSKZ7YHSFGISLPUTVCIDGZANCNFSM5RZSK5PA&data=04%7C01%7CEmily.Puckett%40memphis.edu%7C51db6aa9f41b483e1ce408da10f2aa5d%7Cae145aeacdb2446ab05a7858dde5ddba%7C0%7C0%7C637840931685525269%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=6Dkb6rbHDZpS05bYUHhlIRHJitgVtR%2FPB5rNHHFMg%2FQ%3D&reserved=0>.; You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7737#issuecomment-1082170127:1992,Message,Message,1992,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7737#issuecomment-1082170127,1,['Message'],['Message']
Integrability," the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a TSV. However, we may run into trouble if we hit a case sample with very high depth. So some sort of sparse representation of the histogram might indeed be desirable, but I think it should be an exact representation of the full histogram. This would require us to sync up code to emit and consume the representation in both Java and python, so I'd like to avoid it if possible---I think I'd prefer just emitting the ragged matrix, in that case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:1529,integrat,integrate,1529,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522,1,['integrat'],['integrate']
Integrability," the inconsistency was introduced in the GermlineCNVCaller step. Itâ€™s possible that you could edit the files manually so that you donâ€™t have to rerun all GermlineCNVCaller shards; for example, you could check that all dictionaries in the output of the good shards (i.e., those that contain intervals that are correctly ordered with respect to either dictionary) are the correct dictionary used to generate the count files, reshard/reorder the intervals in the failing shards and rerun GermlineCNVCaller, then stitch everything back together with PostprocessGermlineCNVCalls. However, I think this will be a rather delicate surgery and it may be easy to mess up. I would just recommend fresh runs of GermlineCNVCaller with the correct dictionary and an appropriately ordered interval list. I would go so far as to recommend you delete and/or never use that dictionary againâ€”such incorrectly ordered dictionaries are a frequent source of heartbreak!. I would say that the code is working as intended and that the error message is sufficiently informative. However, we could certainly fail earlier, before the expensive GermlineCNVCaller step. As mentioned above, we will need to do some work to enable this; I would suggest:. 1) we enable passing of dictionaries from `-L` Picard interval lists at the engine level (and I would add consistency checks if multiple interval lists are provided here as well),; 2) we add checks to all relevant gCNV tools of read-count dictionaries against the intervals dictionary,; 3) we change the behavior of `CopyNumberArgumentValidationUtils.resolveIntervals` so that it fails if provided an unsorted IAC, rather than sorting the contained intervals w.r.t. the count dictionary upon creation of the returned `SimpleIntervalCollection` (this can be done independently of the first two items and would have caused the failing shard to fail earlier; however, the other two items are required to cause all shards to fail earlier),; 4) we revert the change made to Postproc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-719576249:1093,message,message,1093,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-719576249,1,['message'],['message']
Integrability," the last developer who left this in a reasonable state a beverage of their choice.; # (This may be yourself, and you'll appreciate that beverage while you tinker with dependencies!); #; # When changing dependencies or versions in this file, check to see if the ""supportedPythonPackages"" DataProvider; # used by the testGATKPythonEnvironmentPackagePresent test in PythonEnvironmentIntegrationTest needs to be updated; # to reflect the changes.; #; name: gatk; channels:; # if channels other than conda-forge are added and the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:1692,depend,dependencies,1692,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,1,['depend'],['dependencies']
Integrability," tool, MosaicHunter. The option you suggest looks great. Do you mean that I should establish the GATK 4 developing environment and develop the MosaicHunterFilter tool? I may do that when I have some time. I found the document of GATK 4 at https://github.com/broadinstitute/gatk. Do you have any further advices?. Best regards,; Adam Yongxin Ye; Center for Bioinformatics; Peking University. At 2018-07-07 01:43:05, ""Geraldine Van der Auwera"" <notifications@github.com> wrote:. Hi @Yyx2626, I'm Geraldine, you may remember me from the Beijing training. It was great visiting your team! I'm sorry it took me so long to follow up on this discussion, and I want to thank you again for reaching out to us about integrating the tool that you developed into GATK. We are certainly very interested in providing this enhancement to the research community, and we are now ready to talk about the next steps. After examining your paper and the source code in Github, we think that the most efficient way to integrate the functionality you developed would be to adapt the filtering parts of your tool to run on the output of Mutect2. So this would be a standalone tool that you would run after Mutect2, much like the current FilterMutectCalls tool. If the results are comparable to your current tool, then we would take that into the official distribution of GATK. If somehow that integration does not yield satisfactory results, then we would look at integrating the entire tool, though we're hoping it won't be necessary, so we can avoid maintaining duplicate functionality for some of the boilerplate data transformations. David @davidbenjamin can provide some advice on how to implement this in GATK4; in brief you would need to write some code that applies the filters you developed to a variant context. Let us know if this is an option you'd like to explore; we'd be happy to help. â€”; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404104349:1221,integrat,integrate,1221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404104349,3,['integrat'],"['integrate', 'integrating', 'integration']"
Integrability," tracks, trackers, builders etc., etc., is gone, replaced by about 4 core; > classes:; > FeatureContext, FeatureDataSource, FeatureInput, and FeatureManager.; > ; > FeatureContext: This is tool-facing interface (replaces; > RefMetaDataTracker).; > Allows particular sources of Features to be queried.; > ; > FeatureDataSource: Handles the low-level details of querying a source of; > Features.; > Uses a caching scheme optimized for the use case of queries over; > intervals with gradually increasing start/stop positions.; > ; > FeatureInput: This is used to declared Feature arguments in tools; > (replaces RodBinding).; > The engine discovers all FeatureInput arguments declared in the tool's; > class; > hierarchy, and initializes data sources for each one that was specified; > on the command line.; > ; > FeatureManager: Manages the pool of data sources, as well as codec and; > file format; > discovery and type checking.; > ; > -ReadWalker interface has changed: apply() now takes a FeatureContext; > argument; > (will be null if there are no sources of Features).; > ; > -Included an example tool PrintReadsWithVariants to demonstrate use of the; > new; > ReadWalker interface.; > ; > -Since Feature files must be indexed in order to query them, I have; > provided a; > tool IndexFeatureFile that can index any Feature-containing file.; > ; > -Made required changes to the argument-parsing system. Feature argument; > discovery; > is as de-coupled as possible from the main arg parser.; > ; > -Made required changes to BQSR, and eliminated the temporary; > HACKRefMetaDataTracker.; > ; > ## -Comprehensive tests; > ; > You can view, comment on, or merge this pull request online at:; > ; > https://github.com/broadinstitute/hellbender/pull/224; > Commit Summary; > - Feature support: stripped-down replacement for the old GATK ROD; > system; > ; > File Changes; > - _M_; > src/main/java/org/broadinstitute/hellbender/cmdline/ClassFinder.java; > https://github.com/broadinstitute/hellbender/p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/224#issuecomment-75657392:1191,interface,interface,1191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/224#issuecomment-75657392,1,['interface'],['interface']
Integrability," unnecessary copies of the data (now fixed: https://github.com/cloudera/spark-dataflow/pull/60), which caused OOM errors when trying to broadcast the 3GB reference data. With this fixed, I ran a [pipeline called JoinReferencesDataflow](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/tools/dataflow/pipelines/JoinReferencesDataflow.java) on a small cluster that broadcasts the reference as a dataflow view. The code is a modified version of CountReadsDataflow that simply sends the view, and then doesn't use it, so we can see the cost of doing a broadcast (See the rest of the code in this branch: https://github.com/tomwhite/hellbender/tree/hadoop-references). JoinReferencesDataflow took 2 min 25s to run, of which 18s were for reading the reference from the local filesystem in the driver. For comparison, CountReadsDataflow took 17s on the same cluster. So broadcasting the reference takes less than 2 minutes. Note that this was just for one task, but Spark has [an efficient protocol for sending broadcast variables](http://www.cs.berkeley.edu/~agearh/cs267.sp10/files/mosharaf-spark-bc-report-spring10.pdf), which scales well with the number of nodes, so the approach looks feasible. Having said all that, we might still want to use the sharding approach, in order to share more code between the Google and Spark dataflow implementations. One way this could work would be to generalize `RefAPISource` and `RefAPIMetadata` to support reading reference data from a [ReferenceHadoopSource](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/engine/dataflow/datasources/ReferenceHadoopSource.java), which is in line with @droazen's last comment. Am I right in thinking that the read pipeline work is being completed in https://github.com/broadinstitute/hellbender/tree/da_read_pipeline? Is that at a point where I could try with pipeline on Spark, or should I wait until it's merged?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353:1158,protocol,protocol,1158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353,1,['protocol'],['protocol']
Integrability, we are running on Google Compute Engine.; java.net.ConnectException: Connection refused (Connection refused); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.goo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:1594,protocol,protocol,1594,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843,1,['protocol'],['protocol']
Integrability," workflows.; [2019-02-22 23:50:02,53] [info] JobExecutionTokenDispenser stopped; [2019-02-22 23:50:02,53] [info] WorkflowStoreActor stopped; [2019-02-22 23:50:02,61] [info] WorkflowLogCopyRouter stopped; [2019-02-22 23:50:02,61] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2019-02-22 23:50:02,61] [info] WorkflowManagerActor All workflows finished; [2019-02-22 23:50:02,61] [info] WorkflowManagerActor stopped; [2019-02-22 23:50:02,61] [info] Connection pools shut down; [2019-02-22 23:50:02,61] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] SubWorkflowStoreActor stopped; [2019-02-22 23:50:02,61] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2019-02-22 23:50:02,61] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2019-02-22 23:50:02,61] [info] JobStoreActor stopped; [2019-02-22 23:50:02,61] [info] CallCacheWriteActor stopped; [2019-02-22 23:50:02,61] [info] KvWriteActor Shutting down: 0 queued messages to process; [2019-02-22 23:50:02,61] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2019-02-22 23:50:02,62] [info] DockerHashActor stopped; [2019-02-22 23:50:02,62] [info] IoProxy stopped; [2019-02-22 23:50:02,62] [info] ServiceRegistryActor stopped; [2019-02-22 23:50:02,65] [info] Database closed; [2019-02-22 23:50:02,65] [info] Stream materializer shut down; Workflow 098a389e-b298-4324-8a8c-9f46f05708b5 transitioned to state Failed; [2019-02-22 23:50:02,75] [info] Automatic shutdown of the async connection; [2019-02-22 23:50:02,75] [info] Gracefully shutdown sentry threads.; [2019-02-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:32143,message,messages,32143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,3,['message'],['messages']
Integrability, |; | [...tools/copynumber/ModelSegmentsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL01vZGVsU2VnbWVudHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `89.308% <100%> (+0.206%)` | `20 <0> (Ã¸)` | :arrow_down: |; | [...ools/copynumber/formats/records/LegacySegment.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9MZWdhY3lTZWdtZW50LmphdmE=) | `46.875% <46.875%> (Ã¸)` | `7 <7> (?)` | |; | [...r/formats/collections/LegacySegmentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvTGVnYWN5U2VnbWVudENvbGxlY3Rpb24uamF2YQ==) | `72.222% <72.222%> (Ã¸)` | `4 <4> (?)` | |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `90.909% <0%> (-3.209%)` | `2% <0%> (+1%)` | |; | [...te/hellbender/tools/spark/sv/utils/SVInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkludGVydmFsLmphdmE=) | `85.507% <0%> (-1.993%)` | `48% <0%> (+12%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `100% <0%> (Ã¸)` | `13% <0%> (+6%)` | :arrow_up: |; | [...spark/sv/evidence/BreakpointDensityFilterTest.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5048#issuecomment-407457135:2892,integrat,integration,2892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5048#issuecomment-407457135,1,['integrat'],['integration']
Integrability,""">; ##FILTER=<ID=orientation_bias,Description=""Orientation bias (in one of the specified artifact mode(s) or complement) seen in one or more samples."">; ##FILTER=<ID=panel_of_normals,Description=""Blacklisted site in panel of normals"">; ##FILTER=<ID=read_position,Description=""median distance of alt variants from end of reads"">; ##FILTER=<ID=str_contraction,Description=""Site filtered due to contraction of short tandem repeat region"">; ##FILTER=<ID=strand_artifact,Description=""Evidence for alt allele comes from one read direction only"">; ##FILTER=<ID=t_lod,Description=""Tumor does not meet likelihood threshold"">; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=AF,Number=A,Type=Float,Description=""Allele fractions of alternate alleles in the tumor"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=F1R2,Number=R,Type=Integer,Description=""Count of reads in F1R2 pair orientation supporting each allele"">; ##FORMAT=<ID=F2R1,Number=R,Type=Integer,Description=""Count of reads in F2R1 pair orientation supporting each allele"">; ##FORMAT=<ID=FT,Number=1,Type=String,Description=""Genotype-level filter"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=MBQ,Number=A,Type=Integer,Description=""median base quality"">; ##FORMAT=<ID=MFRL,Number=R,Type=Integer,Description=""median fragment length"">; ##FORMAT=<ID=MMQ,Number=A,Type=Integer,Description=""median mapping quality"">; ##FORMAT=<ID=MPOS,Number=A,Type=Integer,Description=""median distance from end of read"">; ##FORMAT=<ID=OBAM,Number=A,Type=String,Description=""Whether the variant can be one of the given REF/ALT artifact modes."">; ##FORMAT=<ID=OBAMRC,Number=A,Type=String,Description=""Whether the variant can be one of the given REF/ALT artifact mode complements."">; ##FORMAT=",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5158:1251,contract,contraction,1251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5158,1,['contract'],['contraction']
Integrability,"""D:\Program Files\Java\jdk1.8.0_121\bin\java.exe"" -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:62530,suspend=y,server=n -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -javaagent:C:\Users\Sweet\AppData\Local\JetBrains\IntelliJIdea2020.1\captureAgent\debugger-agent.jar -Dfile.encoding=UTF-8 -classpath ""D:\Program Files\Java\jdk1.8.0_121\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\rt.jar;C:\project\push\target\classes;E:\repository\org\springframework\boot\spring-boot-starter-jdbc\2.3.0.RELEASE\spring-boot-starter-jdbc-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter\2.3",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:629,bridg,bridge-,629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['bridg'],['bridge-']
Integrability,"# Summary. This PR adds a new flag to `HaplotypeCaller` called `--ploidy-regions` which allows the user to input a .bed or .interval_list with ""name"" column equal to a positive integer for the ploidy to use when calling variants in that region. The main use case is for calling haploid variants outside the PAR for XY individuals as required by the VCF spec, but this provides a much more flexible interface for other similar niche applications, like genotyping individuals with other known aneuploidies. The global `-ploidy` flag will still provide the background default (or the built-in ploidy of 2 for humans), but the user input value will supersede these in overlapping regions. Note that the overlap is checked against the active region, meaning variants near the boundary of the `--ploidy-regions` file may end up with GT fields having ploidy slightly differently than expected, for example if your custom region overlaps a given active region but the variant ends up being written to a location outside that interval. In this case the ploidy from the user input would be used rather than any other default. # Implementation Details. The key idea is to allow `HaplotypeCallerEngine` to initialize multiple genotyping engines based on the `--ploidy-regions` input. The intervals are first parsed to check for positive integer ploidy values, and then used to create hashmaps of ploidy -> genotyper. The engine uses two types of genotypers: one for active region determination and one for doing the actual genotyping. Both admit a ploidy paramter passed via `hcArgs`. This PR modifies the `HaplotypeCallerArgumentCollection` class to include a method for creating copies of this object with differing ploidy amounts. These then get fed to the constructors of the appropriate genotyper classes, which are organized into two hashmaps. In every situation where one of these genotypers is used, we instead begin the scope by calling a ""get local genotyper"" method that performs the logic of checking ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8464:398,interface,interface,398,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8464,1,['interface'],['interface']
Integrability,"## Bug Report. ### Affected tool(s) or class(es). FastaAlternateReferenceMaker. ### Affected version(s); - [x] Latest public release version 4.1.4.1; - [ ] Latest master branch as of [date of test?]. ### Description . A null pointer exception in . #### Steps to reproduce. We called variants with HaplotypeCaller & use resulting VCF with FastaAlternateReferenceMaker. See command below, but only reference fasta & HC vcf are given as input (no snp masking or interval list, though error also occurs when using interval list with multiple -L calls). #### Expected behavior. Alternate-adjusted reference file or at least a helpful error message. #### Actual behavior. ```; + latest-gatk/gatk-4.1.4.1/gatk FastaAlternateReferenceMaker -R /g/data/xe2/references/eucalyptus/emel_scott/Emelliodora_CSIROg1_SISH00000000.1.fasta -O consensus_sequences_gatk//CCA0704.fasta.tmp -V pergene_gatk/CCA0704/CCA0704.vcf.gz; Using GATK jar /g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar FastaAlternateReferenceMaker -R /g/data/xe2/references/eucalyptus/emel_scott/Emelliodora_CSIROg1_SISH00000000.1.fasta -O consensus_sequences_gatk//CCA0704.fasta.tmp -V pergene_gatk/CCA0704/CCA0704.vcf.gz; 15:43:14.276 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/g/data/xe2/users/stephen-rodgers/latest-gatk/gatk-4.1.4.1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 03, 2020 3:43:15 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 15:43:15.230 INFO FastaAlternateReferenceMaker - ------------------------------------------------------------; 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6434:635,message,message,635,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6434,1,['message'],['message']
Integrability,"## Bug Report. ### Affected tool(s) or class(es). ValidateVariants: `--fail-gvcf-on-overlap` / `-no-overlaps`. ### Affected version(s); - [x] Latest public release version: 4.2.6.1; - [ ] ~Latest master branch as of~ [did not test, but affected file hasn't changed since August 2021]. ### Description . If there are overlapping reference blocks when running ValidateVariants with the `-no-overlaps` option, a USER ERROR is outputted after the entire tool finishes running, as shown below:. ```; ***********************************************************************. A USER ERROR has occurred: This GVCF contained overlapping reference blocks. The first overlapping interval is [genomic coordinates here]. ***********************************************************************; ```. This error should be generally helpful, but it appears that the interval that is reported in the error message is the _last_ overlapping interval, not the _first_. I'm not super familiar with java, but I'm guessing that `firstOverlap` might be continuously replaced by `refInterval` if there are multiple overlaps, which is inconsistent with expected behavior. . Potentially relevant lines of code: ; - `-no-overlaps` argument description ([lines 192-201](; https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L192-L201)); - `firstOverlap = refInterval` ([line 275](https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L275)). #### Steps to reproduce. Running ValidateVariants with the `-no-overlaps` flag on a .g.vcf with overlapping intervals will cause this error. More specifically, we're running this within WARP's Exome Germline Single Sample v.3.1.7 WDL release. Our command is as follows:. ```; gatk --java-options ""-Xms6000m -Xmx6500m"" \; ValidateVariants ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103:888,message,message,888,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103,1,['message'],['message']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); ""gatk PostprocessGermlineCNVCalls"". ### Affected version(s); - docker (broadinstitute/gatk, 4.1.9.0 version). ### Description ; #### Steps to reproduce. This is my command line. ; gatk PostprocessGermlineCNVCalls \; --calls-shard-path CALLS_01 \; --model-shard-path MODEL_01 \; --allosomal-contig chrX \; --allosomal-contig chrY \; --autosomal-ref-copy-number 2 \; --contig-ploidy-calls contig-ploidy-calls \; --sample-index 9 \; --output-genotyped-intervals genotyped-intervals-2016001038.vcf.gz \; --output-genotyped-segments genotyped-segments-2016001038.vcf.gz \; --output-denoised-copy-ratios denoised_copy_ratios-2016001038.tsv. #### Error message ; ![image](https://user-images.githubusercontent.com/33537478/119120932-cab21b80-ba67-11eb-9cd3-bb0af7192799.png). #### Expected behavior; generation of following files; genotyped-intervals-2016001038.vcf.gz, genotyped-segments-2016001038.vcf.gz, denoised_copy_ratios-2016001038.tsv . #### Actual behavior; when making a ""genotyped-segments-2016001038.vcf.gz"" file, tool emits this error message. . ![image](https://user-images.githubusercontent.com/33537478/119120932-cab21b80-ba67-11eb-9cd3-bb0af7192799.png)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7266:696,message,message,696,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7266,2,['message'],['message']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); Build. ### Affected version(s); - [X] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; ```; =======================<phase: build >============================; ===> Building for gatk-4.2.6.1_1. Welcome to Gradle 7.5.1!. Here are the highlights of this release:; - Support for Java 18; - Support for building with Groovy 4; - Much more responsive continuous builds; - Improved diagnostics for dependency resolution. For more details see https://docs.gradle.org/7.5.1/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). FAILURE: Build failed with an exception. * Where:; Build file '/wrkdirs/usr/ports/biology/gatk/work/gatk-4.2.6.1/build.gradle' line: 15. * What went wrong:; Plugin [id: 'de.undercouch.download', version: '4.1.2'] was not found in any of the following sources:. - Gradle Core Plugins (plugin is not in 'org.gradle' namespace); - Plugin Repositories (could not resolve plugin artifact 'de.undercouch.download:de.undercouch.download.gradle.plugin:4.1.2'); Searched in the following repositories:; Gradle Central Plugin Repository; ```. #### Steps to reproduce; regular build. Version: 4.2.6.1; Java-17; FreeBSD 13.1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7984:503,depend,dependency,503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7984,1,['depend'],['dependency']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); FilterMutectCalls and possibly Mutect2. ### Affected version(s); GATK 4.1.7.0, still occurs in 4.1.8.1. ### Description ; User running Mutect2 in mitochondrial mode and ERC BP_RESOLUTION. Mutect2 is successful, however filter mutect calls has error message; `java.lang.IllegalArgumentException: alpha must be greater than 0 but got NaN`. Possible similar issue: #6202 ; Complete stack trace:. ```; Running:. java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx22G -Djava.io.tmpdir=/nobackup/lnsingh/MTRNA/tmp -jar /nobackupp16/swbuild/hsp/COVID19/anaconda3/envs/COVIRT_GATK/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar FilterMutectCalls --disable-read-filter MappingQualityReadFilter --disable-read-filter MappingQualityNotZeroReadFilter --disable-read-filter MappingQualityAvailableReadFilter --mitochondria-mode true -R /nobackup/lnsingh/MTRNA/lib/rCRS.fa -V /nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.gvcf.gz -L MT -O /nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.filtered.gvcf.gz. 07:33:14.927 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityReadFilter) is not enabled by this tool. 07:33:14.928 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityNotZeroReadFilter) is not enabled by this tool. 07:33:14.928 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityAvailableReadFilter) is not enabled by this tool. 07:33:15.003 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/nobackupp16/swbuild/hsp/COVID19/anaconda3/envs/COVIRT_GATK/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so. Sep 20, 2020 7:33:15 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6850:299,message,message,299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850,1,['message'],['message']
Integrability,## Bug Report. ### Affected tool(s) or class(es); GATK ReblockGVCF. ### Affected version(s); - 4.2.5.0 and 4.2.6.1. ### Description ; I am running ReblockGVCF on GVCF's that are haplotyped on version 4.0.1.4. About 1 out of 500 samples crash with the following error:; `ReblockGVCF fails by an exception:No shortest ALT at 464564654 across alleles: [*]`. Complete error message:. ```; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chr4::464564654[VC /bug.g.vcf.gz @ ; ```; redacted; ```. ] filters=; at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:145); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:136); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7961:370,message,message,370,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7961,1,['message'],['message']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); GATK installation. ### Affected version(s); - [x] Latest public release version 4.4.0.0; - [x] Latest master branch as of [11.12.2023]. ### Description ; Latest `conda` versions cannot install pip packages. #### Steps to reproduce; Create `gatk` `env` with `conda` version equal or newer than `23.10`. #### Expected behavior; ```sh; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda --version; conda 23.9.0; root@d12ac7710afc:/soft/gatk-4.4.0.0# ""$CONDA"" env create -n gatk -f ""$SOFT/gatk-${GATK_VERSION}/gatkcondaenv.yml""; ...; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Installing pip dependencies: - Ran pip subprocess with arguments:; ['/opt/miniconda/envs/gatk/bin/python', '-m', 'pip', 'install', '-U', '-r', '/soft/gatk-4.4.0.0/condaenv.vn0sukco.requirements.txt', '--exists-action=b']; Pip subprocess output:; Processing ./gatkPythonPackageArchive.zip; Building wheels for collected packages: gatkpythonpackages; Building wheel for gatkpythonpackages (setup.py): started; Building wheel for gatkpythonpackages (setup.py): finished with status 'done'; Created wheel for gatkpythonpackages: filename=gatkpythonpackages-0.1-py3-none-any.whl size=117686 sha256=8095375e139fa0729c7a41c8f5e8a43281fc1b6859b6d3951d3bfba7296ee349; Stored in directory: /tmp/pip-ephem-wheel-cache-ecx6e_m0/wheels/06/f7/e1/87cb7da6f705baa602256a58c9514b47dc313aade8809a01da; Successfully built gatkpythonpackages; Installing collected packages: gatkpythonpackages; Successfully installed gatkpythonpackages-0.1. done; #; # To activate this environment, use; #; # $ conda activate gatk; #; # To deactivate an active environment, use; #; # $ conda deactivate. ```. #### Actual behavior; ```sh; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda --version; conda 23.10.0; root@d12ac7710afc:/soft/gatk-4.4.0.0# ""$CONDA"" env create -n gatk -f ""$SOFT/gatk-${GATK_VERSION}/gatkcondaenv.yml""; ...; Preparing transaction: done; Verifying transactio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8618:675,depend,dependencies,675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8618,1,['depend'],['dependencies']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCFs with `-all-sites`. ### Affected version(s); - 4.2 through 4.6. ### Description ; We tried to run GenotypeGVCFs from GATK 4.5 with `-all-sites` on a dataset with 120 samples and GRCh37 as the reference. Each run was limited to a single chromosome. All of them failed after consuming 3 TB of memory. Subsequently, I tried a smaller subset of 8 samples limiting the memory to 32 GB and all the runs failed after 3-10 Mbp depending on the chromosome. Finally, I randomly picked chromosome 9 and used GATK versions from 4.1 to 4.6 and only 4.1 did not experience the problem. It finished the whole chromosome (141 Mbp) with the max memory usage of around 8 GB. All others failed after 3-6 Mbp (Sorry, I used different memory settings for 4.5, so I did not include it.). ![memory_usage](https://github.com/user-attachments/assets/df354842-d420-4a99-b3d3-01fec64d18fd). Time is in seconds, memory is in MB. If I run the same command without `-all-sites`, the maximum memory usage is around 1.6 GB. #### Steps to reproduce. GenomicDB was created using the corresponding GATK version as:. ```; gatk --java-options ""-Xmx12000m"" GenomicsDBImport --genomicsdb-workspace-path tmp/genomicsdb44/9 \; --genomicsdb-shared-posixfs-optimizations --batch-size 120 --verbosity DEBUG \; -L 9 -V data/gatk/gvcf/9/1.g.vcf.gz -V data/gatk/gvcf/9/2.vcf.gz -V data/gatk/gvcf/9/3.g.vcf.gz \; -V data/gatk/gvcf/9/4.g.vcf.gz -V data/gatk/gvcf/9/5.g.vcf.gz -V data/gatk/gvcf/9/6.g.vcf.gz \; -V data/gatk/gvcf/9/7.g.vcf.gz -V data/gatk/gvcf/9/8.g.vcf.gz; ```. GenotypeGVCFs was run as:. ```; gatk --java-options ""-Xmx12g"" GenotypeGVCFs -R data/ref/hs37d5.fa.gz \; -V gendb://tmp/genomicsdb44/9 -O data/gatk/variants/9/raw44.vcf.gz -L 9 \; --tmp-dir ./tmp/tmp -all-sites; ```. All runs were performed with resource_monitor and it was instructed to kill the process if it consumes more than 14000 MB of memory. Thus, at least 2 GB was allocated for reading GenomicsDB. Th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8989:482,depend,depending,482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8989,1,['depend'],['depending']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [?] Latest public release version [version?]; - [x] Latest master branch as of Sept 10, 2019. ### Description ; Contamination estimate doesn't appear to be taken into account for reference blocks in GVCFs. #### Steps to reproduce; I'm looking at expected integration test results with uncontaminated (src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.CEUTrio.HiSeq.WGS.b37.NA12878.calls.20.10100000-10150000.vcf) vs. 15% contaminated (src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.CEUTrio.HiSeq.WGS.b37.NA12878.CONTAMINATED.WITH.HCC1143.NORMALS.15PCT.20.10100000-10150000.postIndelRefConfUpdate.g.vcf). #### Expected behavior; Contaminated calls should have lower depth because the reads are being downsampled (in a biased way) by the contamination fraction. #### Actual behavior; In the expected HC integration test results I'm seeing for 0 contamination; 20 10132770 . A <NON_REF> . . END=10132770 GT:DP:GQ:MIN_DP:PL 0/0:57:99:57:0,120,1800. For 15% contamination:; 20 10132770 . A <NON_REF> . . END=10132770 GT:DP:GQ:MIN_DP:PL 0/0:56:99:56:0,120,1800. The pileup has 55 (I'm not going down the rabbit hole of the bonus reads), so I would expect the contaminated GVCF to have < 55 DP. The variants look good in some places and less good in others. Looking through the code, I don't see anywhere the contamination estimate would be used for reference confidence. I suspect @davidbenjamin has been harboring a desire to update the contamination model anyway.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6152:349,integrat,integration,349,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6152,2,['integrat'],['integration']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); No version information yet, [here is the forum link](https://gatk.broadinstitute.org/hc/en-us/community/posts/360075181171-HaplotypeCaller-Shutting-down-engine-Encountering-a-large-genome) for information. ### Description ; A user wrote into the forum with an error message while HaplotypeCaller was creating the output variant index with an issue of how many bins needed to be created. They have a large genome with long contig(s). We discussed at the GATK Office Hours meeting about adding a check to find this issue so that there is an error or warning before running HaplotypeCaller instead of at the end of the process. A snippet of the error message can be found at the forum post.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6992:358,message,message,358,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6992,2,['message'],['message']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); In the tutorial ""[(How to part I) Sensitively detect copy ratio alterations and allelic segments](https://gatk.broadinstitute.org/hc/en-us/articles/360035531092)"", users are asked to install R components using [install_R_packages.R](https://github.com/broadinstitute/gatk/blob/4.0.1.1/scripts/docker/gatkbase/install_R_packages.R). . ### Affected version(s); Latest public release version [4.5.0.0]. ### Description ; Running the script with `Rscript install_R_packages.R` results in the following error:. `Error in download.file(p, destfile, method, mode = ""wb"", ...) : ; cannot open URL 'http://cran.r-project.org/src/contrib/HMM_1.0.tar.gz'; In addition: Warning message:; In download.file(p, destfile, method, mode = ""wb"", ...) :; cannot open URL 'http://cran.r-project.org/src/contrib/HMM_1.0.tar.gz': HTTP status was '404 Not Found'`. This can be fixed by changing line [35 of install_R_packages.R](https://github.com/broadinstitute/gatk/blob/4.0.1.1/scripts/docker/gatkbase/install_R_packages.R#L35) from `hmmUrl = ""http://cran.r-project.org/src/contrib/HMM_1.0.tar.gz""` to `hmmUrl = ""http://cran.r-project.org/src/contrib/HMM_1.0.1.tar.gz""`. . The script runs as expected once this change is made. #### Steps to reproduce; Run `Rscript install_R_packages.R`. #### Expected behavior; Successfully installs all necessary R packages with the correct versions. #### Actual behavior; Fails to install the 'HMM' package.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8638:716,message,message,716,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8638,1,['message'],['message']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); IndexFeatureFile. ### Affected version(s); - [x] Latest master branch as of [1/6/2020]. ### Description ; When running IndexFeatureFile on a compressed vcf stored on GCS, tool fails, error message:. ```; A USER ERROR has occurred: Error while trying to create index for dir/file.vcf.gz. Error was: ; htsjdk.tribble.TribbleException.FeatureFileDoesntExist: Unable to open the input file, most ; likely the file doesn't exist., for input source: /dir/file.vcf.gz; ```; When running on an uncompressed vcf on GCS, the tool succeeds. I've traced the issue to `SeekableStreamFactory.getStreamFor` in htsjdk, which gets called from `IndexFactory.initIndexableBlockCompressedStream` (also in htsdjk), and doesn't appear to handle GCS paths correctly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6348:239,message,message,239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6348,1,['message'],['message']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); LeftAlignAndTrimVariants. ### Affected version(s); I've only tested with v4.2.2.0. ### Description ; When running LeftAlignAndTrimVariants the program exited with a message that said:; ""A USER ERROR has occurred: Input files reference and features have incompatible contigs: No overlapping contigs found.; reference contigs = [chr1, chr2, chr3, chr4, chr5, chr6, chr7, chr8, chr9, chr10, chr11, chr12, chr13, chr14, chr15, chr16, chr17, chr18, chr19, chr20, chr21, chr22, chrX, chrY, chrM, chr1_KI270706v1_random, chr1_KI270707v1_random, chr1_KI270708v1_random, chr1_KI270709v1_random, chr1_KI270710v1_random, chr1_KI270711v1_random, chr1_KI270712v1_random, chr1_KI270713v1_random, chr1_KI270714v1_random, chr2_KI270715v1_random, chr2_KI270716v1_random, chr3_GL000221v1_random, chr4_GL000008v2_random, chr5_GL000208v1_random, chr9_KI270717v1_random, chr9_KI270718v1_random, chr9_KI270719v1_random, chr9_KI270720v1_random, chr11_KI270721v1_random, chr14_GL000009v2_random, chr14_GL000225v1_random, chr14_KI270722v1_random, chr14_GL000194v1_random, chr14_KI270723v1_random, chr14_KI270724v1_random, chr14_KI270725v1_random, chr14_KI270726v1_random, chr15_KI270727v1_random, chr16_KI270728v1_random, chr17_GL000205v2_random, chr17_KI270729v1_random, chr17_KI270730v1_random, chr22_KI270731v1_random, chr22_KI270732v1_random, chr22_KI270733v1_random, chr22_KI270734v1_random, chr22_KI270735v1_random, chr22_KI270736v1_random, chr22_KI270737v1_random, chr22_KI270738v1_random, chr22_KI270739v1_random, chrY_KI270740v1_random, chrUn_KI270302v1, chrUn_KI270304v1, chrUn_KI270303v1, chrUn_KI270305v1, chrUn_KI270322v1, chrUn_KI270320v1, chrUn_KI270310v1, chrUn_KI270316v1, chrUn_KI270315v1, chrUn_KI270312v1, chrUn_KI270311v1, chrUn_KI270317v1, chrUn_KI270412v1, chrUn_KI270411v1, chrUn_KI270414v1, chrUn_KI270419v1, chrUn_KI270418v1, chrUn_KI270420v1, chrUn_KI270424v1, chrUn_KI270417v1, chrUn_KI270422v1, chrUn_KI270423v1, chrUn_KI270425v1, chrUn_KI270429v1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7538:215,message,message,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7538,1,['message'],['message']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - GATK v4.1.8.1. ### Description ; Hi, ; I am new to GATK so I hope this is not something trivial I overlooked. I called somatic variants using `Mutect2` (GATK v4.1.8.1) and wished to filter the results using `FilterMutectCalls`. I am running GATK via a docker container as described here: https://gatk.broadinstitute.org/hc/en-us/articles/360035889991--How-to-Run-GATK-in-a-Docker-container. ``` bash; ./gatk Mutect2 -I:tumor 1st.chr1.bam -I:normal 2nd.chr1.bam -O variants.vcf.gz --min-pruning 8 -R reference.chr1.fa; ```; I repeated this three times, the last time to make sure whether the .vcf.stats is being generated or not. This was a test run using the input filtered for chr1 using `samtools view -b`. I though this was the reason for getting the error message about Contig 2 not being present. ```bash; ...; 18:39:03.207 INFO ProgressMeter - 1:282722440 448.7 1529870 3409.8; 18:39:06.592 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 19.218222963000002; 18:39:06.592 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 5376.604473962; 18:39:06.593 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 12201.77 sec; 18:39:06.594 INFO Mutect2 - Shutting down engine; [August 25, 2020 6:39:06 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 448.75 minutes.; Runtime.totalMemory()=12349079552; ***********************************************************************. A USER ERROR has occurred: Contig 2 not present in the sequence dictionary [1]. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; Is there any way of getting around this and generating .vcf.stats without repeating a lengthy variant calling `Mutect2`? Is this a problem introdu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6768:846,message,message,846,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6768,1,['message'],['message']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); 4.1.8.1. ### Description ; A user is getting a java.lang.NullPointerException when running Mutect2. As discussed at GATK Office Hours 09/28/20, it seems to be an issue where the BAM contigs are not present in the reference sequence dictionary. We discussed an improvement with either the filter for this problem or the error message. Complete stack trace:; ```; Using GATK jar GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -jar /GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar Mutect2 -R ref/Homo_sapiens_assembly38.fasta -I SRR_MM10_2pass_recal.bam --germline-resource /af-only-gnomad.hg38.vcf.gz --panel-of-normals ref/1000g_pon.hg38.vcf.gz -O SRR_somatic_mutect.vcf.gz; 13:24:08.400 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Sep 25, 2020 1:24:08 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:24:08.556 INFO Mutect2 - ------------------------------------------------------------; 13:24:08.557 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.1; 13:24:08.557 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:24:08.557 INFO Mutect2 - Executing as xxx on Linux v3.10.0-1127.18.2.el7.x86_64 amd64; 13:24:08.557 INFO Mutect2 - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_192-b12; 13:24:08.557 INFO Mutect2 - Start Date/Time: September 25, 2020 1:24:08 PM BST; 13:24:08.557 INFO Mutect2 - ------------------------------------------------------------; 13:24:08.557 INFO Mu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6851:409,message,message,409,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851,1,['message'],['message']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); GATK version 4.2.5.0, run from the `us.gcr.io/broad-gatk/gatk:4.2.5.0` docker image. ### Description ; Rarely (~0.1%) within exomes that were sequenced at Broad (by GP), we encounter the error message whose stack trace is shown below. This occurs during batch processing, but it is specific to the .CRAM files: running Mutect2 on the same file produces the same error, and running Mutect2 on other files with the same arguments works fine. The files that trigger this error have contents that match the Broad GP-produced .md5 checksum, and they also pass `samtools quickcheck`. #### Steps to reproduce; (The variables are filled in as one might reasonably expect.); ```sh; /gatk/gatk --java-options ""-Xmx${RAM}G"" \; Mutect2 \; --input ${cram} \; --reference ${REFERENCE_FASTA} \; --panel-of-normals ${PON} \; --germline-resource ${GNOMAD} \; --intervals ${INTERVALS} \; --output ${unfiltered}; ```. #### Expected behavior; In all other cases, somatic variant calling proceeds successfully. #### Actual behavior; ```; 00:17:31.944 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 00:17:32.225 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.226 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.2.5.0; 00:17:32.226 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 00:17:32.227 INFO Mutect2 - Executing as root@8d398eecd56e on Linux v5.10.90+ amd64; 00:17:32.227 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 00:17:32.228 INFO Mutect2 - Start Date/Time: April 5, 2022 12:17:31 AM GMT; 00:17:32.228 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.228 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.229 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7755:277,message,message,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7755,1,['message'],['message']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); ReblockGVCF. ### Affected version(s); - [x ] Latest public release version [version?] _**GATK 4.2.6.1**_; - [ ] Latest master branch as of [date of test?]. ### Description ; We ran ReblockGVCF in 549 samples with the newest GATK (4.2.6.1). 8 of them returned the error similar to the message below . `org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chrM:1 [VC /tmp/scratch/prs-sabe-files/GRAR/2031812880_AJ.hard-filtered.gvcf.gz @ chrM:1 Q. of type=SYMBOLIC alleles=[G*, <NON_REF>] attr={END=1} GT=[[2031812880_AJ G*/G* DP 1691 AD 112,1579 {MIN_DP=1691, SQ=0}]] filters=weak_evidence`. and right below, we could find in all of them; `Caused by: org.broadinstitute.hellbender.exceptions.UserException$BadInput: Bad input: Homozygous reference genotypes must contain GQ or PL. Both are missing for hom ref genotype at chrM:1`. All the ""failed samples"" produced a broken output, in this case, missing the chrM (and the alt chr, such as HLA, chr1_alt etc)... It was weird because on WDL it returned as **_Success_** job... We need all the samples with a proper output to run the JointGenotype pipeline with the Reblocked Dragen samples output. #### Steps to reproduce; I'll share with you the chrM:1 from GVCF from a sample with no error; `chrM	1	.	G	<NON_REF>	.	PASS	END=72	GT:AD:DP:GQ:MIN_DP:PL:SPL:ICNT	0/0:2441,2:2443:99:1613:0,120,1800:0,255,255:40,13`. And now, the chrM:1 from a sample with the error; `chrM	1	.	G	<NON_REF>	.	weak_evidence	END=1	GT:AD:DP:SQ:MIN_DP	0/0:112,1579:1691:0:1691`. #### Expected behavior; No broken output. #### Actual behavior; Failing in a few samples, breaking the expected output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7797:334,message,message,334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7797,1,['message'],['message']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator. ### Affected version(s); - [X] Latest public release version [4.5.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; As of v1.3.0 the `scales` R package turns the use of deprecated values for the `space` parameter into a hard error, resulting in the VariantRecalibrator R-script terminating with the following message:. > The `space` argument of `pal_gradient_n()` only supports be ""Lab"" as of scales 0.3.0. This parameter is used repeatedly in the generated R-script via. ```R; scale_fill_gradient(high=""green"", low=""red"", space=""rgb""); ```. #### Steps to reproduce. ```shell; $ R --version; R version 4.1.2 (2021-11-01) -- ""Bird Hippie""; $ rm -rf ~/R; $ R; > install.packages(""ggplot2"", repos=""https://cloud.r-project.org/""); > packageVersion(""scales""); [1] â€˜1.3.0â€™; > quit(); $ gatk --version; The Genome Analysis Toolkit (GATK) v4.5.0.0; HTSJDK Version: 4.1.0; Picard Version: 3.1.1; $ gatk VariantRecalibrator [arguments omitted for brevity]; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.9339186078473502558';source('/path/to/rscript.r');; Stdout: ; Stderr: Error:; ! The `space` argument of `pal_gradient_n()` only supports be ""Lab"" as; of scales 0.3.0.; Backtrace:; â–†; 1. â”œâ”€base::source(""/path/to/rscript.r""); 2. â”‚ â”œâ”€base::withVisible(eval(ei, envir)); 3. â”‚ â””â”€base::eval(ei, envir); 4. â”‚ â””â”€base::eval(ei, envir); 5. â””â”€ggplot2::scale_fill_gradient(high = ""green"", low = ""red"", space = ""rgb""); 6. â”œâ”€ggplot2::continuous_scale(...); 7. â”‚ â””â”€ggplot2::ggproto(...); 8. â”‚ â””â”€rlang::list2(...); 9. â””â”€scales::seq_gradient_pal(low, high, space); 10. â””â”€scales::pal_gradient_n(c(low, high), space = space); 11. â””â”€lifecycle::deprecate_stop(""0.3.0"", ""pal_gradient_n(space = 'only supports be \""Lab\""')""); 12. â””â”€lifecycle:::deprecate_stop0(msg); 13. â””â”€rlang::cnd_signal(...); Execution halted; $ R; > install.packages(""remot",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664:404,message,message,404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664,1,['message'],['message']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; ; ### Affected version(s); -All versions after 4.1.4.1, including 4.1.9.0. ### Description ; A user on the forum reported an error message that does not give position information when reporting an allele problem in the reference. A similar issue in FilterVariantTranches was previously discussed at #6701 however the fix only changed FilterVariantTranches. We discussed adding a change with VariantRecalibrator that would also fix other GATK tools when this issue comes up. ; Forum Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360074618292-New-version-of-GATK-leads-to-VariantRecalibrator-error-. #### Command; `~/bin/gatk-4.1.9.0/gatk --java-options -Xms24g VariantRecalibrator -V temp/vartiant_germline/sites.only.vcf.gz -O temp/vartiant_germline/recaliberation.indel.vcf --tranches-file temp/vartiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz --use-allele-specific-annotations`. #### Error Message; ```; Using GATK jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms24g -jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.ja",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6963:202,message,message,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963,1,['message'],['message']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); _MarkDuplicatesSpark_. ### Affected version(s); - [ ] GATK version 4.1.9.0. ### Description ; Headers with another `@` character fail to create a valid bam using MarkDuplicatesSpark. The bam file is empty. But the header will work when using samtools markdup instead. The following example was found in one of many samples we found in ICGC datasets. Example header:; `@HWI-ST700660_163:1:1101:1243:1870#1@0/1`. Log:<br> (removed some content since it was too long); ```; 00:05 DEBUG: [kryo] Read: Object[]; 00:05 DEBUG: [kryo] Read: Object[]; 00:05 DEBUG: [kryo] Read: Object[]; 00:05 DEBUG: [kryo] Read: Object[]; 00:05 DEBUG: [kryo] Write: Object[]; 00:05 DEBUG: [kryo] Write: Object[]; 00:05 DEBUG: [kryo] Write: Object[]; ...; 01:22 DEBUG: [kryo] Read: CompressedMapStatus; 01:22 DEBUG: [kryo] Write: CompressedMapStatus; ...; 02:25 DEBUG: [kryo] Read: WrappedArray([]); 02:25 DEBUG: [kryo] Write: WrappedArray([]); 02:25 DEBUG: [kryo] Read: scala.Tuple3[]; 02:25 DEBUG: [kryo] Read: scala.Tuple3[]; 02:25 DEBUG: [kryo] Read: WrappedArray([]); 02:25 DEBUG: [kryo] Read: WrappedArray([]); 02:25 DEBUG: [kryo] Write: scala.Tuple3[]; ...; 02:42 DEBUG: [kryo] Write object reference 1941: HLA-A*24:152; 02:42 DEBUG: [kryo] Write object reference 1945: chrUn_JTFH01001224v1_decoy; 02:42 DEBUG: [kryo] Write object reference 1949: HLA-B*14:01:01; 02:42 DEBUG: [kryo] Write object reference 1953: chr5_GL949742v1_alt; ...; 02:42 DEBUG: [kryo] Write object reference 1942: SAMSequenceRecord(name=HLA-A*24:152,length=3176,dict_index=2919,assembly=null,alternate_names=[]); 02:42 DEBUG: [kryo] Write object reference 1946: SAMSequenceRecord(name=chrUn_JTFH01001224v1_decoy,length=1051,dict_index=2066,assembly=null,alternate_names=[]); 02:42 DEBUG: [kryo] Write object reference 1950: SAMSequenceRecord(name=HLA-B*14:01:01,length=3312,dict_index=2999,assembly=null,alternate_names=[]); 02:42 DEBUG: [kryo] Write object reference 1954: SAMSequenceRecord(name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8134:907,Wrap,WrappedArray,907,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8134,2,['Wrap'],['WrappedArray']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [x] Latest public release version 4.1.7.0. ### Description . The following error message is output:. A USER ERROR has occurred: Bad input: Is the input a file of segment variant contexts? Variant context does not represent a copy number segment: [VC null @ 6:4130448-4130544 Q. of type=SYMBOLIC alleles=[C*, <DEL>] attr={END=4130544, Num_Probes=1, Segment_Call=-, Segment_Mean=-30.018694} GT=[] filters=. The local info in the segment file is:; 5 176563624 180687750 618 -0.053122 0; 6 203183 4128317 205 0.046724 0; 6 4130448 4130544 1 -30.018694 -; 6 4130545 6168103 42 -0.085445 0; 6 6174562 17463556 490 0.022415 0; 6 17493361 25510885 347 0.080520 0. This is a bad error message. The minimum size for a segment to be processed is 150 bases and that variant is only 96 bases, so it's failing that validation. #### Expected behavior; Should process variant without producing error. Hat tip: @jonn-smith for figuring out the problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6575:201,message,message,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6575,2,['message'],['message']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); `Funcotator`. ### Affected version(s); GATK 4.1.0.0 release. ### Description . Functotator MAF output does not properly show genotypes from somatic multi-tumor VCF files produced using M2. It looks like only genotypes from the first tumor sample are shown, but there are no errors or messages to point the user to this fact. Only a single `tumor_sample` and `normal_sample` are reported in the MAF header:. ```; ##normal_sample=xxx; ##source=FilterMutectCalls; ##source=Funcotator; ##source=Mutect2; ##tumor_sample=xxx; ```. Conversely, instructing `Funcotator` to output VCF format properly adds the annotation to the INFO field while retaining the FORMAT-level genotypes works well. However, in this case the VCF header also only lists a single tumor_sample (take note: this is a separate bug, though mostly aesthetics) despite all tumor genotypes being included. #### Steps to reproduce; Run Funcotator with output format set to MAF on any multi-tumor VCF file. #### Expected behavior; Either one of:; 1. `Funcotator` should return an error when trying to process multi-tumor VCF to MAF output; 2. `Funcotator` MAF should output multiple lines per funcotation for each tumor sample, indicating the comparison in the `Tumor_Sample_Barcode` and `Normal_Sample_Barcode` columns.; 3. `Funcotator` should not output genotype information when processing multi-tumor VCF to MAF (this could also be an additional Funcotator parameter that must be switched on when requesting MAF output). #### Actual behavior; Funcotator runs without errors or warnings and the output file is missing genotypes for the other tumor samples",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5687:334,message,messages,334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5687,1,['message'],['messages']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); `SAMRecord` from `GATKRead`. ### Affected version(s); - [x] Latest master branch as of January 30, 2024. ### Description ; When I run a tool with a bam file as input, the following code will give me a null:; ```java; @Override; public void apply(GATKRead read, ReferenceContext referenceContext, FeatureContext featureContext) {. // Build sets of read IDs for each file.; final SAMRecord samRecord = read.convertToSAMRecord(getHeaderForReads());; final SAMFileSource fileSource = samRecord.getFileSource();; System.out.println(fileSource);; ```. Output:; (a long list of `null`). #### Steps to reproduce; Create a ReadWalker that takes in a bam file. Here is an integration test that will replicate the issue:. ```java; public class ReadConcordanceIntegrationTest extends CommandLineProgramTest {. @Test; public void testTwoCrams() throws IOException {; final File output = createTempFile(""testReadConcordanceOutputFile"", "".txt"");; final File input = new File(GATKBaseTest.largeFileTestDir, ""expected.K-562.splitNCigarReads.chr20.bam"");. final ArgumentsBuilder args = new ArgumentsBuilder();. args.addInput(input);; this.runCommandLine(args.getArgsArray());; }; }; ```. #### Expected behavior; Output should be the file used in the read data source (bam file) for each read. #### Actual behavior; I get nulls instead",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8671:712,integrat,integration,712,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8671,1,['integrat'],['integration']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); combine_tracks.wdl. ### Description ; PrototypeACSConversion has a bug when `model_segments_seg_pd['MINOR_ALLELE_FRACTION_POSTERIOR_90'` is NaN. On line:; ```; result[model_segments_seg_pd['MINOR_ALLELE_FRACTION_POSTERIOR_90'] > HAM_FIST_THRESHOLD] = 0.5; ```. ```; Traceback (most recent call last): File ""<stdin>"", line 114, in <module> File ""<stdin>"", line 74, in convert_model_segments_to_alleliccapseg File ""<stdin>"", line 55, in simple_determine_allelic_fraction File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/pandas/core/ops.py"", line 879, in wrapper res = na_op(values, other) ; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/pandas/core/ops.py"", line 783, in na_op result = _comp_method_OBJECT_ARRAY(op, x, y) ; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/pandas/core/ops.py"", line 763, in _comp_method_OBJECT_ARRAY result = lib.scalar_compare(x, y, op) ; File ""pandas/_libs/lib.pyx"", line 706, in pandas._libs.lib.scalar_compare TypeError: '>' not supported between instances of 'str' and 'float'; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5284:612,wrap,wrapper,612,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5284,1,['wrap'],['wrapper']
Integrability,"## Bug Report. ### Affected tool(s) or class(es); particularly _SelectVariants_, but really anything that writes out a vcf. ### Affected version(s); - [ ] Latest public release version [version?]; - [x] Latest master branch as of [2/6/2020]. ### Description ; There are minimal/inconsistent checks that variants added to vcfWriters are correctly ordered (an issue with htsjdk I think). This leads to an insidious bug, where a sorted vcf can be fed through SelectVariants, and depending on the flavor of output vcf, either crash, or succeed but output an incorrectly sorted vcf. The issue is that in some circumstances SelectVariants will trim alleles to their minimal representation, which can change the location of a variant record, and thus reorder them. However, SelectVariants does nothing to account for the potential order change. Since vcfWriter implementations in htsjdk seem to do minimal/inconsistent checks on the order of variants being added to them, this may write out an incorrectly sorted vcf, or throw an exception, depending on the flavor of vcfWriter. . #### Steps to reproduce; With attached (zipped because github) vcf, run ; `gatk SelectVariants -V test.input.vcf -sn SAMPLE_01 -O test.output.vcf`; Tool will succeed, but output vcf will be incorrectly sorted. Somehow, this incorrectly sorted vcf will also be accompanied by an index! Though if you try to run `IndexFeatureFile` on the output vcf separately, it will fail. . run ; `gatk SelectVariants -V test.input.vcf -sn SAMPLE_01 -O test.output.vcf.gz`; tool will throw exception w/ stack trace:; ```; java.lang.IllegalArgumentException: Features added out of order: previous (TabixFeature{referenceIndex=0, start=17148456, end=17148456, featureStartFilePosition=2460, featureEndFilePosition=-1}) > next (TabixFeature{referenceIndex=0, start=17148447, end=17148457, featureStartFilePosition=2509, featureEndFilePosition=-1}); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.addFeature(TabixIndexCreator.java:89); 	at htsjd",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6443:476,depend,depending,476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6443,2,['depend'],['depending']
Integrability,"## Bug Report. ### Affected tool(s); HaplotypeCaller. ### Affected version(s); GATK4.beta5. ### Description ; HaplotypeCaller does not make some calls depending on the padding size around the interval of interest. The variant calls should not be dependent on the interval size. For example,with -ip 50, I get 7 variant calls. But with -ip 150, I get only 2 variant calls. It seems to be an issue with the graph assembly (perhaps due to repeat regions), but adding --allowNonUniqueKmersInRef does not help. In the IGV screenshots below, the top is the original BAM file; the second is the bamout with -ip 50; the third is with -ip 100; the fourth is with -ip 150; the fifth is with -ip 200. <img width=""1440"" alt=""screen shot 2017-10-16 at 12 36 32 pm"" src=""https://user-images.githubusercontent.com/6998669/31624559-1c07304a-b271-11e7-8013-fafc13f928de.png"">. Notice the difference in calls between -ip 50 and -ip 150. The call should be made regardless of -ip. . #### Steps to reproduce; Files are here:; `/humgen/gsa-scr1/schandra/SkyWarrior_HCMissingCalls/GATK_Bugsubmit_10448_haplotypecaller-missing-snp-calls`. Commands:; `gatk-4.beta.5/gatk-launch HaplotypeCaller -R reference/hg19_ref-ym.fa -I MLC1_Exome_Depth208.bam -L region.bed -O Sheila.HaplotypeCaller.vcf`. `gatk-4.beta.5/gatk-launch HaplotypeCaller -R reference/hg19_ref-ym.fa -I MLC1_Exome_Depth208.bam -L region.bed -O Sheila.HaplotypeCaller.50.vcf -ip 50`. `gatk-4.beta.5/gatk-launch HaplotypeCaller -R reference/hg19_ref-ym.fa -I MLC1_Exome_Depth208.bam -L region.bed -O Sheila.HaplotypeCaller.100.vcf -ip 100`. `gatk-4.beta.5/gatk-launch HaplotypeCaller -R reference/hg19_ref-ym.fa -I MLC1_Exome_Depth208.bam -L region.bed -O Sheila.HaplotypeCaller.150.vcf -ip 150`. `gatk-4.beta.5/gatk-launch HaplotypeCaller -R reference/hg19_ref-ym.fa -I MLC1_Exome_Depth208.bam -L region.bed -O Sheila.HaplotypeCaller.200.vcf -ip 200`. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697:151,depend,depending,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697,2,['depend'],"['dependent', 'depending']"
Integrability,"## Bug Report. ### Affected tool(s); Mutect2. ### Affected version(s); 3.6. ### Description ; The AF field of MuTect2 is unpredictable depending on the input interval. For example, if I run with `-L chr7:140452736-140453536`, I get this at one site:; `chr7	140453136	.	A	T	.	PASS	ECNT=1;HCNT=27;MAX_ED=.;MIN_ED=.;NLOD=239.30;TLOD=243.81	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:1489,145:0.049:69:76:0.524:45565,4764:771:718	0/0:1094,0:0.00:0:0:.:34322,0:549:545`; But, if I run with `-L chr7:140452836-140453436`, I get this at the same site:; `chr7	140453136	.	A	T	.	PASS	ECNT=1;HCNT=15;MAX_ED=.;MIN_ED=.;NLOD=239.98;TLOD=245.96	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:1489,144:0.092:69:75:0.521:45567,4730:770:719	0/0:1097,0:0.00:0:0:.:34389,0:551:546`; Notice the major difference in AF between the two runs. Side note, the AF does not equal the alt count / (alt count + ref count)?. #### Steps to reproduce; Test files here:; `/humgen/gsa-scr1/schandra/micknudsen_MuTect2AF/bugreport_AF`. Command for interval size of 600:; `java -jar /humgen/gsa-hpprojects/GATK/bin/current/GenomeAnalysisTK.jar -T MuTect2 -R /humgen/gsa-hpprojects/GATK/bundle/2.8/hg19/ucsc.hg19.fasta -I:normal /humgen/gsa-scr1/schandra/micknudsen_MuTect2AF/bugreport_AF/normal_chr7.12.bam -I:tumor /humgen/gsa-scr1/schandra/micknudsen_MuTect2AF/bugreport_AF/tumor_chr7.12.bam -o Sheila.MuTect2.vcf -L chr7:140452836-140453436. Command for interval size of 800:; `java -jar /humgen/gsa-hpprojects/GATK/bin/current/GenomeAnalysisTK.jar -T MuTect2 -R /humgen/gsa-hpprojects/GATK/bundle/2.8/hg19/ucsc.hg19.fasta -I:normal /humgen/gsa-scr1/schandra/micknudsen_MuTect2AF/bugreport_AF/normal_chr7.12.bam -I:tumor /humgen/gsa-scr1/schandra/micknudsen_MuTect2AF/bugreport_AF/tumor_chr7.12.bam -o Sheila.MuTect2.400.vcf -L chr7:140452736-140453536`. ----. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/gatk/discussion/comment/33762#Comment_33762",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2295:135,depend,depending,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2295,1,['depend'],['depending']
Integrability,"## Bug Report. - OS: Arch Linux; - Java: 17. ### Affected version(s); - [x] Latest public release version [version?]. ### Description . Firstly, I run `./gradle localJar`. ```; Downloading https://services.gradle.org/distributions/gradle-7.5.1-bin.zip; ...........10%............20%...........30%............40%...........50%............60%...........70%............80%...........90%............100%. Welcome to Gradle 7.5.1!. Here are the highlights of this release:; - Support for Java 18; - Support for building with Groovy 4; - Much more responsive continuous builds; - Improved diagnostics for dependency resolution. For more details see https://docs.gradle.org/7.5.1/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; Executing: git lfs pull --include src/main/resources/large. FAILURE: Build failed with an exception. * Where:; Build file '/build/gatk/src/gatk/build.gradle' line: 104. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. BUILD FAILED in 17s; ```; However, I already install git-lfs; ```; git-lfs usr/; git-lfs usr/bin/; git-lfs usr/bin/git-lfs; git-lfs usr/share/; git-lfs usr/share/licenses/; git-lfs usr/share/licenses/git-lfs/; git-lfs usr/share/licenses/git-lfs/LICENSE; git-lfs usr/share/man/; git-lfs usr/share/man/man1/; git-lfs usr/share/man/man1/git-lfs-checkout.1.gz; git-lfs usr/share/man/man1/git-lfs-clean.1.gz; git-lfs usr/share/man/man1/git-lfs-clone.1.gz; git-lfs usr/share/man/man1/git-lfs-dedup.1.gz; git-lfs usr/share/man/man1/git-lfs-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8320:599,depend,dependency,599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8320,1,['depend'],['dependency']
Integrability,"## Bug Report. Hi there,; So I downloaded the gatk-4.4-0.0.zip and unzipped it for using gatk. I also created the conda env using the gatkcondaenv.yml and used conda to install java ""1.7.0_91"". But when I run ./gatk --list I got this error message: . `; ./gatk --list; Using GATK jar /home/athchu/bin/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/athchu/bin/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar --help; Error: Invalid or corrupt jarfile /home/athchu/bin/gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; `; Next, I moved on to git clone the gatk repository, trying to build gatk. Again, I stay in the java ""1.7.0_91"" gatk env that I already created. But I got this error msg this time:; `; ./gradlew localJar; Gradle 7.5.1 requires Java 1.8 or later to run. You are currently using Java 1.7.; `; When I switch back to the server default java (1.8.0_292-b10), i got another error msg.; `; java -version; openjdk version ""1.8.0_292""; OpenJDK Runtime Environment (build 1.8.0_292-b10); OpenJDK 64-Bit Server VM (build 25.292-b10, mixed mode). ./gradlew localJar. > Configure project :; Warning: using Java 1.8 but only Java 17 has been tested. FAILURE: Build failed with an exception. * Where:; Build file '/home/athchu/bin/gatk/build.gradle' line: 141. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > A Java 17 compatible (Java 17 or later) version is required to build GATK, but 1.8 was found. See https://github.com/broadinstitute/gatk#building for information on how to build GATK. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org; `; So to sum up, my issues are :; 1) downloaded gatk-4.4.0.0 but it contained invalid jar file and i ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8432:240,message,message,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8432,1,['message'],['message']
Integrability,"## Bug Report. Originally reported by @ldgauthier via slack. ### Affected tool(s) or class(es); CalibrateDragstrModel. ### Affected version(s); - [X ] Latest public release version [4.2.0.0]. ### Description ; An out-of-memory exception when running the aforementioned tool in at least one of many samples. Location where the error occur does not seem to be always the same but it was fixable by increasing memory over 15Gb. #### Steps to reproduce. Since I'm not sure the data is public I won't disclose its location nor ID in this issue. Let's call it the ""SAMPLE"" in ""SAMPLE.cram"":. ```; gatk --java-options ""-Dsamjdk.reference_fasta=Homo_sapiens_assembly38.fasta -Xmx2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" \; CalibrateDragstrModel \; -R Homo_sapiens_assembly38.fasta \; -I SAMPLE.cram \; -str Homo_sapiens_assembly38.str \; -O SAMPLE.final.cram.dragstr \; --parallel \; --verbosity DEBUG; ```. ```Homo_sapiens_assembly38.str``` depends only on the reference and ca be composed using this:. ```; gatk ComposeSTRFile -R Homo_sapiens_assembly38.fasta -O Homo_sapiens_assembly38.str; ```. #### Expected behavior; Completes without issues. #### Actual behavior; a Java Out-of-Memory error is throw and the execution finished without results.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7189:938,depend,depends,938,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7189,1,['depend'],['depends']
Integrability,"## Bug Report; ### Affected tool(s) or class(es); CombineGVCFs. ### Affected version(s); - version 4.1.0.8. ### Description ; I know this issue has been brought up before but I still cannot find a solution. When I run CombineGVCFs, the error indicates the first locus where there is a NON_REF allele. For example:. HiC_scaffold_2 12497 . T TC,* . My full process is as follows:; I run HaplotypeCaller on individual sample files using the -ERC GVCF command.; I combine the individual g.vcf files using CombineGVCFs. I do this separately for the three species I ultimately want to merge, although they are all mapped to the same reference genome.; I call multisample genotypes with GenotypeGVCFs, again for each species separately. At this point a sample that will fail the process in the future will look like:; HiC_scaffold_2 12497 . T TC,<NON_REF>. I now merge the multispecies genotyped files together using CombineGVCFs.; But then when I go to run GenotypeGVCFs, there is an error wherever there are more than two alleles. And as shown at the top of the message what was a <NON_REF> becomes a * and I get the message: ERROR input alleles must contain <NON_REF>. #### Expected behavior; I expected the g.vcf files to genotype across multiple samples so I can move forward with analyses. Is the problem that I'm running CombineGVCFs and GenotypeGVCFs twice? And somehow that is changing <NON_REF> into * ?. I appreciate any advice.; With thanks,; Emily",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7737:1057,message,message,1057,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7737,2,['message'],['message']
Integrability,"## Bug Report; ### Affected tool(s). MuTect2; ### Affected version(s). version 3.6; ### Description. A user reported that when he input a BAM file that has multiple sample names to MuTect2, the tool mseems to run fine but outputs an empty VCF. Because MuTect2 cannot run on multiple samples, there should be an error message that lets the user know he/she cannot have multiple samples in the BAM file.; #### Expected behavior. There should be an error message telling the user to input only single sample BAM files, and the run should fail.; #### Actual behavior. The tool runs to completion but outputs an empty VCF. [Original Forum Post](http://gatkforums.broadinstitute.org/gatk/discussion/comment/33336#Comment_33336). ---",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2203:317,message,message,317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2203,2,['message'],['message']
Integrability,"## Bug Report; Hi, we are using the dockstore version of the GATK variant calling pipeline that leverages mutect 2:; [github.com/broadinstitute/gatk/mutect2:4.1.8.1](https://dockstore.org/workflows/github.com/broadinstitute/gatk/mutect2:4.1.8.1). We're processing human glioma data, and currently we are making it through much of the pipeline, but failing on `GetPileupSummaries`. There's a thread about it on the discussion board [here] (https://gatk.broadinstitute.org/hc/en-us/community/posts/6179012337819-No-Pileup-Tables). . We are specifying a file for `variants_for_contamination`, and a file for `variants_for_contamination_idx` in the workflow, but the index is never passed to `GetPileupSummaries`, and it fails with this enigmatic error message:. ```; A USER ERROR has occurred: An index is required but was not found for file gs://bruce-processed-data/Prins_Cloughesy_Neoadjuvant/terra_reference_files/small_exac_common_3.hg38.vcf.gz. Support for unindexed block-compressed files has been temporarily disabled. Try running IndexFeatureFile on the input.; ```. If you check out the source code in [mutect2.wdl](https://github.com/broadinstitute/gatk/blob/4.1.8.1/scripts/mutect2_wdl/mutect2.wdl), you can see that that input variable `variants_for_contamination_idx`, which we have thoughtfully set and passed into the workflow, is never actually used in `GetPileupSummaries`. I'm not even sure there is an option to pass the index, from reading the [docs](https://gatk.broadinstitute.org/hc/en-us/articles/360037593451-GetPileupSummaries). Here is an example of how the command is being called within our workflow:. ```; gatk --java-options ""-Xmx149500m"" GetPileupSummaries -R gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://fc-d31bc4e7-6d10-4dc4-a585-5895ab2346f3/cfce2061-efd6-449e-bdc9-a7ff2b633644/PreProcessingForVariantDiscovery_GATK4/b4adf777-4f97-425c-b3e2-b37c9d927667/call-GatherBamFiles/SRR7588418.hg38.bam --interval-set-rule INTERSECTION ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7935:749,message,message,749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7935,1,['message'],['message']
Integrability,"## Bug Report; I run the CNNScoreVariants as tutorial, but it can't continue and always stuck as the following picture, and the programme isn't stop by any error. By the way I can't find gatkcondaenv.yml in anywhere. Can you upload it in the github, so that I can check ; whether the bug is caused by loss of some python dependencies. ### Affected tool(s) or class(es); CNNScoreVariants. ### Affected version(s); GATK4.3.0.0. ### Description ; ![image](https://github.com/broadinstitute/gatk/assets/92069388/be7c63ca-d64f-4689-86ad-b06f867cfd45)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8827:321,depend,dependencies,321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8827,1,['depend'],['dependencies']
Integrability,"## Bug Report; JDK8 is no longer available for the current stable Debian release (buster). Trying to run gatk with an OpenJDK11 install fails. I anticipate a WONTFIX since this is dependency related, but I figured it would be good to let people know. ### Affected tool(s) or class(es); GATKRead, probably others too. ### Affected version(s); - [x] Latest public release version [4.1.2.0]; - [ ] Latest master branch as of [didn't test]. ### Description ; ```; Exception in thread ""main"" java.lang.IncompatibleClassChangeError: Inconsistent constant pool data in classfile for class org/broadinstitute/hellbender/transformers/ReadTransformer. Method 'org.broadinstitute.hellbender.utils.read.GATKRead lambda$identity$d67512bf$1(org.broadinstitute.hellbender.utils.read.GATKRead)' at index 65 is CONSTANT_MethodRef and should be CONSTANT_InterfaceMethodRef; 	at org.broadinstitute.hellbender.transformers.ReadTransformer.identity(ReadTransformer.java:30); 	at org.broadinstitute.hellbender.engine.GATKTool.makePreReadFilterTransformer(GATKTool.java:345); 	at org.broadinstitute.hellbender.engine.GATKTool.getTransformedReadStream(GATKTool.java:374); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:93); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); ```. This error seems related to the JRE version. You can still install JDK8 manually but that's not ideal for many users. #### Steps to reproduce; Run GATK on OpenJDK11. ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6053:180,depend,dependency,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6053,1,['depend'],['dependency']
Integrability,"## Documentation request. ### Description ; I propose that installation of gcc be added to the instructions on the GATK Github README.md. If gcc is not installed, HaplotypeCaller complains that the AVX instruction set is not available, even when it is. It falls back to slower LOGLESS_CACHING PairHMM. The fault is missing libgomp1, which is a required dependency of gcc. Since this documentation request is related to a ""bug"" that comes about from not installing necessary libraries, I'll include the bug report format below, in case someone else searches for solutions to this problem, as suggested by @lbergelson. ### Affected tool(s) or class(es); _HaplotypeCaller_, or any other tool that uses _PairHMM_. ### Affected version(s); -I think all as of _2019-06-20_. I tested on release version _4.1.2.0_. #### Steps to reproduce; Run HaplotypeCaller from a released jar on an Ubuntu VM that supports the AVX instruction set. Critically, do *NOT* install gcc on the VM. Installing gcc fixes this problem. #### Expected behavior; If you install gcc, that results in the installation of libgomp1, which allows the Intel library to load and use AVX acceleration. You could probably install libgomp1 on its own, but I did not test that.; > 14:51:01.013 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/ubuntu/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; > 14:51:01.015 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/ubuntu/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; > 14:51:01.053 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; > 14:51:01.053 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; > 14:51:01.054 INFO IntelPairHmm - Available threads: 16; > 14:51:01.054 INFO IntelPairHmm - Requested threads: 8; > 14:51:01.054 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation. #### Actual b",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6012:353,depend,dependency,353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6012,1,['depend'],['dependency']
Integrability,"## Documentation request. ### Description ; I was unable to successfully follow the R setup instructions required to run integration tests locally. I don't know whether this is a general concern regarding initial setup on Mac OS X High Sierra 10.13.6, or the problem is specific to my system. . #### R installation itself; Expected: `brew install R` would install R with all necessary core functionality.; Actual: `brew install R` installed a version of R without X11 support. The binary I downloaded from [CRAN](https://cran.r-project.org/bin/macosx/) had the proper support. #### R package installation; Expected `sudo Rscript scripts/docker/gatkbase/install_R_packages.R` would install the necessary packages for R scripts needed.; Actual: Failure to compile source packages, with an error like `clang: error: unsupported option '-fopenmp'`. I made some attempts to update my local `clang` but was unsuccessful. Instead, I installed the packages at the R prompt:; ```; $ R; > install.packages('ggplot2'); > install.packages('reshape'); > install.packages('gplots'); > install.packages('gridExtra'); > install.packages('gsalib'); > install.packages('data.table'); > quit(); ```. After doing so, my test run `TEST_TYPE=integration ./gradlew shadowJar test` succeeded.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5389:121,integrat,integration,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5389,2,['integrat'],['integration']
Integrability,"## Feature request / documentation request. ### Tool(s) or class(es) involved; Reading files from non-public GCS paths. ### Description; I did not have Application Default Credentials set up when I tried to read from a private bucket. This failed, as expected. Could we add a comment explaining that running `gcloud auth application-default login` is the necessary step to making this work? I didn't see anything on the forum about how to solve this. The solution was in the comments to #2394. ### Observed; GATK errored out with a stack trace:; ```; code: 401; message: Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.; reason: required; location: Authorization; retryable: false; com.google.cloud.storage.StorageException: Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:220); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:415); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:198); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:195); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89); at com.google.cloud.RetryHelper.run(RetryHelper.java:74); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:195); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:673); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:429); at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); ```. ```; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 401 Unauthorized; {; ""code"" : 401,; ""errors"" : [ {; ""domain"" : ""global"",; ""location"" : ""Authoriza",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5468:562,message,message,562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5468,1,['message'],['message']
Integrability,"## Feature request. ### Tool(s) involved; VariantFiltration. ### Description; The tool throws a bunch of WARN messages when an annotation is missing a value. For example, when the RankSum annotations are not present in homozygous sites, the tool prints out a bunch of WARN messages that fill up the user's log file. Can this problematic WARN message be moved to be OneShotLogger?. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/42636#Comment_42636",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3828:110,message,messages,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3828,3,['message'],"['message', 'messages']"
Integrability,"## Feature request. ### Tool(s) or class(es) involved. (sv) VCF producing tool(s). ### Description. The VCF spec allows `POS` column to take value 0, when the suspected event is at a telomere.; The given example is in section 5.4.5 (see example event illustrated in Figure 6 and VCF records below the figure).; However, currently GATK writes VCF via `VariantContext`'s, which defines coordinate 0 as illegal.; I can of course push this feature request to htsjdk, if that is deemed more appropriate. **UPDATE**; Looking back at the error message, it is actually the `SimpleInterval` that I use for constructing the `VariantContext` throwing the error message.; Temporary workaround would be to ""hack"" the POS to be 1 or N, and warn using an INFO annotation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5915:537,message,message,537,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5915,2,['message'],['message']
Integrability,"## Feature request. ### Tool(s) or class(es) involved. Engine level argument. ### Description. This is a new capability. Presently tools like Mutect2 and HaplotypeCaller ignore; soft-clipping by default. In some sequencing products that use long reads relative; to the insert size, the reads often contain some amount of adapter. These reads; are typically soft-clipped by upstream tools like MergeBamAlignments. The result is an increase in false positive rates in somatic samples that have long read lengths compared to insert size. These false positives can be eliminated using the `-no-soft-clips` option, but this ignores all soft clips regardless of why the read was soft-clipped. The proposal here is to add a new engine level argument that will allow GATK tools to ignore soft-clips that occur at the start position of the reads mate. This will allow tools to utilize soft-clips that may contain evidence of indels without providing support for artifactual variants due to adapter sequence.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6346:321,adapter,adapter,321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6346,2,['adapter'],['adapter']
Integrability,"## Feature request. ### Tool(s) or class(es) involved; Funcotator. ### Description; Currently, if you attempt to specify more than one pair in an input VCF, there is no agreed protocol for such a thing. As a result, if Funcotator ever determines that there is more than one pair in an input VCF, it will fail. Please note that the current implementation is unlikely to find more than one pair in the wild. This is an issue being filed to allow more than one pair to be specified and to have a protocol for doing so in a VCF. -[ ] Determine protocol(s) for specifying more than one pair.; -[ ] Alter `MafOutputRenderer` to use the pair information to populate the sample fields correctly and grab the annotations only applicable to that pair. There are other concerns here, such as checking the genotype fields (why add an entry in the MAF for a tumor 0/0 genotype). This is probably not a trivial issue to address. FYI: @davidbenjamin and @jonn-smith",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4912:176,protocol,protocol,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4912,3,['protocol'],['protocol']
Integrability,"## Feature request. ### Tool(s) or class(es) involved; GenomicsDBImport(v4.1.8.1). ### Description; Hello, I was construct to genomicdb using GenomicDBImport and import gvcf file for update genomicdb(Command). but since my server was shut down, during GenomicDBImport process, process is broke down. After I tried to GenomicDBImport same command for overwrite genomicdb and encounter to error message(error message).; ; In this case, should genomicdb be recreated from scratch? How to update the gvcf file I want to update? what should I do?. ### Command. java -jar $GATK GenomicsDBImport \; -L chr${1} \; -V $File_PATH/4762/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4763/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4764/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4765/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4767/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; --genomicsdb-update-workspace-path $DB_PATH/test_database \; --genomicsdb-shared-posixfs-optimizations true \; --max-num-intervals-to-import-in-parallel 5 \; --reader-threads 10 \; --tmp-dir $Script_PATH/tmp. ### Error message. 10:49:12.018 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/mnt/mone/OMICS/Tools/Programs/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jun 18, 2021 10:49:12 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:49:12.231 INFO GenomicsDBImport - ------------------------------------------------------------; 10:49:12.232 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.8.1; 10:49:12.232 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:49:12.232 INFO GenomicsDBImport - Executing as chowoo1023@bdcm04 on Linux v3.10.0-514.2.2.el7.x86_64 amd64; 10:49:12.232 INFO GenomicsDBImport - Java runtim",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7324:393,message,message,393,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7324,2,['message'],['message']
Integrability,"## Feature request. ### Tool(s) or class(es) involved; GenomicsDBImport. ### Description; Users get confused by this error message: `A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader`; `Caused by: java.io.IOException: GenomicsDB JNI Error: VariantQueryProcessorException : Could not open array 1$1$249250621 at workspace: ...; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed`. In one of our [docs](https://gatk.broadinstitute.org/hc/en-us/articles/360035889971--How-to-Consolidate-GVCFs-for-joint-calling-with-GenotypeGVCFs), we offer this advice, but this is not a proper argument in the GATK tool docs yet:; _If youâ€™re working on a POSIX filesystem (e.g. Lustre, NFS, xfs, ext4 etc), you must set the environment variable TILEDB_DISABLE_FILE_LOCKING=1 before running any GenomicsDB tool. If you donâ€™t, you will likely see an error like Could not open array genomicsdb_array at workspace:[...]_. **This request is to add a proper argument to deal with this scenario in GenomicsDBImport and to document it in the tool docs.**",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6519:123,message,message,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6519,2,['message'],['message']
Integrability,"## Feature request. ### Tool(s) or class(es) involved; HaplotypeCaller, BaseRecalibrator. ### Description; We'd find it useful for HaplotypeCaller to be able to apply a recalibration table file (as it was able to in v3 with `-BQSR`) rather than have to apply it to the input BAM as a separate step. ### Rationale; We like to provide CRAM files with the guarantee that they contain all the basecalls and qualities from the instrument. We'd also like to make it easy for users of the CRAM files to use them with HaplotypeCaller with the recommended base quality recalibration - so we'd value the return of the `-BQSR` option to HaplotypeCaller to make the easy and avoid extra IO. N.b. we'd not want to go the route of putting original qualities in the `OQ` auxtag for fear of bloating our files too much.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6041:708,rout,route,708,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6041,1,['rout'],['route']
Integrability,"## Feature request. ### Tool(s) or class(es) involved; _FindBreakpointEvidenceSpark_, _StructuralVariationDiscoveryPipelineSpark_, when using _XGBoostEvidenceFilter.java_. ### Description; The SV pipeline filters BreakpointEvidence based on BreakpointDensityFilter, or optionally XGBoostEvidenceFilter. The XGBoostEvidenceFilter uses a saved classifier model trained with Python code external to the GATK. This poses two main problems:; 1) The external Python code was designed for proof-of-principle and method development, not maintainability or ease of use. Additionally, GATK users and developers are assumed to be familiar with Java, not necessarily Python.; 2) The external Python code must share heterogeneous data with Java for unit/integration tests (supplying test BreakpointEvidence, expected classifier features, and expected classifier probabilities). Currently this is done via JSON files organized to (invertibly) store Pandas or Numpy objects. The resulting code to load these JSON files in on the Java side is complex.; These problems can be resolved by; 1) Replacing external python code by porting to an **experimental** tool in the GATK.; 2) Replacing JSON files with a serialization strategy currently supported by the GATK (e.g. Kryo). Additional benefits can be obtained by ensuring that the classifier-training subroutines are sufficiently general to speed development for other projects that may want to use boosted decision trees for classification.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4922:741,integrat,integration,741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4922,1,['integrat'],['integration']
Integrability,"## Feature request. ### Tool(s) or class(es) involved; gatk-completion.sh in docker container. ### Description; When using the GATK docker for interactive work (eg in a workshop), currently we have to do `source gatk-completion.sh` to activate tab completion, or add something to that effect to the bash profile. Would be great to have that already set up in the docker by default (just like the gatk wrapper being in the PATH).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5550:401,wrap,wrapper,401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5550,1,['wrap'],['wrapper']
Integrability,"## Feature request. Make joint genotyping functionality available as a publicly accessible function to another class/program without passing through the GATK command line interface. ### Tool(s) or class(es) involved; VariantContext; GenotypeGVCFs; Underlying engine classes. ### Description; For various use cases where our pipelines produce in-memory VariantContext objects it would be faster and easier to pass these directly to a joint genotyping function and extract the results back into memory rather than writing to VCF, running the GenotypeGVCFs pipeline via the command line interface and then re-ingesting the resultant VCFs. From discussions during the GATK Working Group meetings it appears this request is similar in principle to existing functionality for the HaplotypeCaller that was implemented by ""extracting the engine"" from the HaplotypeCaller walkers so that it can be instantiated outside the command line utility. Ideally, this implementation should make it possible to instantiate any necessary engine classes pass VariantContext objects directly to the GenotypeGVCFs.apply or GenotypeGVCFs.regenotypeVC and receive the re-genotyped VariantContext objects back for further processing from Java code. . ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5910:171,interface,interface,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5910,2,['interface'],['interface']
Integrability,"## Feature request. Since CombineVariants will not be ported, we need equivalent functionality to its ability to annotate ""set"", ie which callset(s) a site is present in. Here is an excerpt from a tutorial that describes this functionality in action:. ----. To find out which set each variant belongs to, we can use CombineVariants. CombineVariants has a way to annotate each site with which set the site belongs to. For example, if a site is in GIAB and failed hard filtering but passed VQSR, CombineVariants will annotate the site with set=G-filterInH-V. The ""filterIn"" flag before the filtering method tells us the site failed the filtering method, hence it was ""filtered"" in the set. java -jar GenomeAnalysisTK.jar \; 	-T CombineVariants \; 	-R ref/human_g1k_b37_20.fasta \; 	-V:G truth_dataset/NA12878.GIAB.vcf \; 	-V:H vcfs/NA12878.hard.filtered.vcf \; 	-V:V vcfs/NA12878.VQSR.filtered.vcf \; 	-o sandbox/NA12878.Combined.vcf . The set-annotated VCF looks like this:. ````; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT INTEGRATION NA12878; 20 61795 rs4814683 G T 2034.16 PASS AC=2;AF=0.500;AN=4;(...);set=Intersectionâ€‹ â€‹ GT:AD:ADALL:DP :GQ:PL 0/1:218,205:172,169:769:99 0/1:30,30:.:60:99:1003,0,1027; ````. In this record, ""set=Intersectionâ€‹"" indicates this record was present and unfiltered in all callsets considered. Here is a key of all the possible combinations for this 3-way venn:. | Meaning | Annotation |; |:-|:-|; | In GIAB only | G |; | In GIAB and failed VQSR only | G-H-filterInV |; | In GIAB and failed both hard filtering and VQSR | G-filterInH-filterInV |; | In GIAB and failed hard filtering only | G-filterInH-V |; | In GIAB and passed both hard filtering and VQSR | Intersection |; | Not in GIAB and failed VQSR only | H-filterInV |; | Not in GIAB and failed both hard filtering and VQSR | FilteredInAll |; | Not in GIAB and failed hard filtering only | filterInH-V |; | Not in GIAB and passed both hard filtering and VQSR | H-V |",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2489:1026,INTEGRAT,INTEGRATION,1026,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2489,1,['INTEGRAT'],['INTEGRATION']
Integrability,"## Feature request; ### HaplotypeCaller; When running HaplotypeCaller, I get tens of thousands of lines like the following:; ```; 13:02:04.113 WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 13:02:04.113 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 13:02:04.113 WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 13:02:04.113 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; ```; The problem is they are not informative: you can't tell what position/region caused them. Resulting repetitive messages are redundant.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5912:758,message,messages,758,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5912,1,['message'],['messages']
Integrability,## Feature request; ### Tool(s) involved. VariantRecalibrator; ### Description. A user reported he gets an `##### ERROR MESSAGE: No data found.` from VariantRecalibrator when running with -an MQ twice. There should be a check for this and an error message letting the user know he/she has specified the same annotation twice. . [Original Forum Post](http://gatkforums.broadinstitute.org/gatk/discussion/comment/33592#Comment_33592). ---,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2221:120,MESSAGE,MESSAGE,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2221,2,"['MESSAGE', 'message']","['MESSAGE', 'message']"
Integrability,"## System. * GATK4 a1eee32e84c21c2f265d248c5f47789ae0ba2b37; * Mac OS X 10.11.6 x86_64; * machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 CX16 TPR PDCM SSE4.1 SSE4.2 POPCNT; * machdep.cpu.extfeatures: SYSCALL XD EM64T LAHF RDTSCP TSCI; * java version ""1.8.0_60""; * Java(TM) SE Runtime Environment (build 1.8.0_60-b27); * Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode). ## Error. When updating a downstream project with the latest master and running the integration/unit tests with gradle, it generates the following error. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x00000001236427f4, pid=4010, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7227189416687158431.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid4010.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Error report file: [hs_err_pid4010.log.txt](https://github.com/broadinstitute/gatk/files/1259963/hs_err_pid4010.log.txt). ## Forcing other GKL versions. * 0.5.2 (working); * 0.5.3 (failing); * 0.5.5 (failing); * 0.5.6 (failing); * 0.5.7 (failing); * 0.5.8 (failing)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3532:606,integrat,integration,606,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532,1,['integrat'],['integration']
Integrability,"## System; * Mac OS X 10.11.6 x86_64; * Java HotSpot(TM) 64-Bit Server VM 1.8.0_60-b27. ## Problem; I'm trying to update my project ([ReadTools](https://github.com/magicDGS/ReadTools)) to the latest version of GATK and this dependency throws the following error with some of my gradle tests and while running an uber-jar (using `--use_jdk_deflater false`):. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011d925644, pid=7088, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression8215566221555962564.dylib+0x1644] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid7088.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Find attached the log: [hs_err_pid7088.log.txt](https://github.com/broadinstitute/gatk/files/652421/hs_err_pid7088.log.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2315:224,depend,dependency,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2315,1,['depend'],['dependency']
Integrability,"## Update:. ### A [broad institute forum post](https://gatk.broadinstitute.org/hc/en-us/community/posts/360061666671/comments/360010377231) gave the solution:. #### If you paste this text into the `gatkcondaenv.yaml` file:. ```; # Conda environment for GATK Python Tools; #; # Only update this environment if there is a *VERY* good reason to do so!; # If the build is broken but could be fixed by doing something else, then do that thing instead.; # Ensuring the correct environment for canonical (or otherwise reasonable) usage of our standard Docker takes precedence over edge cases.; # If you break the environment, you are responsible for fixing it and also owe the last developer who left this in a reasonable state a beverage of their choice.; # (This may be yourself, and you'll appreciate that beverage while you tinker with dependencies!); #; # When changing dependencies or versions in this file, check to see if the ""supportedPythonPackages"" DataProvider; # used by the testGATKPythonEnvironmentPackagePresent test in PythonEnvironmentIntegrationTest needs to be updated; # to reflect the changes.; #; name: gatk; channels:; # if channels other than conda-forge are added and the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-for",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:833,depend,dependencies,833,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['depend'],['dependencies']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2101?src=pr) is 74.094% (diff: 32.595%). > Merging [#2101](https://codecov.io/gh/broadinstitute/gatk/pull/2101?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.345%**. ``` diff; @@ master #2101 diff @@; ==========================================; Files 706 711 +5 ; Lines 37972 38288 +316 ; Methods 0 0 ; Messages 0 0 ; Branches 8008 8057 +49 ; ==========================================; + Hits 28266 28369 +103 ; - Misses 7330 7537 +207 ; - Partials 2376 2382 +6 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2101/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | 0% | _new_ [.../hellbender/tools/examples/ExampleNioCountReads.java](https://codecov.io/gh/broadinstitute/gatk/pull/2101/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F6578616D706C65732F4578616D706C654E696F436F756E7452656164732E6A617661) |; | 0% | _new_ [...oadinstitute/hellbender/utils/nio/ReadsIterable.java](https://codecov.io/gh/broadinstitute/gatk/pull/2101/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6E696F2F52656164734974657261626C652E6A617661) |; | 0% | _new_ [...te/hellbender/utils/nio/ChannelAsSeekableStream.java](https://codecov.io/gh/broadinstitute/gatk/pull/2101/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6E696F2F4368616E6E656C41735365656B61626C6553747265616D2E6A617661) |; | 0% | [...broadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2101/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6763732F4275636B65745574696C732E6A617661) |; | 0% | _new_ [.../org/broadinstitute/hellbender/utils/nio/NioBam.java](,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2101#issuecomment-249299231:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2101#issuecomment-249299231,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2133?src=pr) is 75.711% (diff: 83.505%); > Merging [#2133](https://codecov.io/gh/broadinstitute/gatk/pull/2133?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.009%**. ```diff; @@ master #2133 diff @@; ==========================================; Files 728 729 +1 ; Lines 38451 38515 +64 ; Methods 0 0 ; Messages 0 0 ; Branches 8027 8040 +13 ; ==========================================; + Hits 29108 29160 +52 ; - Misses 6840 6847 +7 ; - Partials 2503 2508 +5 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2133/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 83% | *new* [...rg/broadinstitute/hellbender/utils/SATagBuilder.java](https://codecov.io/gh/broadinstitute/gatk/pull/2133/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F53415461674275696C6465722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...ellbender/tools/walkers/rnaseq/SplitNCigarReads.java](https://codecov.io/gh/broadinstitute/gatk/pull/2133/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F726E617365712F53706C69744E436967617252656164732E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [.../broadinstitute/hellbender/utils/read/ReadUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2133/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F726561642F526561645574696C732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [ffc26bb...36e06a7](https://codecov.io/gh/broadinstitute/gatk/compare/ffc26bbb4d89d995396ff7b025a798daf1061c9d...36e06a7d50089927fb966586c7e131fba99a534c?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2133#issuecomment-266102980:439,Message,Messages,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2133#issuecomment-266102980,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2154?src=pr) is 73.987% (diff: 89.286%). > Merging [#2154](https://codecov.io/gh/broadinstitute/gatk/pull/2154?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.452%**. ``` diff; @@ master #2154 diff @@; ==========================================; Files 706 706 ; Lines 37972 38008 +36 ; Methods 0 0 ; Messages 0 0 ; Branches 8008 8014 +6 ; ==========================================; - Hits 28266 28121 -145 ; - Misses 7330 7506 +176 ; - Partials 2376 2381 +5 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2154/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 72% | [...bender/utils/locusiterator/LocusIteratorByState.java](https://codecov.io/gh/broadinstitute/gatk/pull/2154/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6C6F6375736974657261746F722F4C6F6375734974657261746F72427953746174652E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 83% | [...rg/broadinstitute/hellbender/engine/LocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2154/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4C6F63757357616C6B65722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 87% | [...stitute/hellbender/tools/walkers/qc/CheckPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/2154/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F71632F436865636B50696C6575702E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 96% | [...oadinstitute/hellbender/utils/pileup/ReadPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/2154/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70696C6575702F5265616450696C6575702E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...broadinstitute/hellbender/engine/Ass,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2154#issuecomment-252230207:437,Message,Messages,437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2154#issuecomment-252230207,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2170?src=pr) is 74.268% (diff: 89.474%). > Merging [#2170](https://codecov.io/gh/broadinstitute/gatk/pull/2170?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.059%**. ``` diff; @@ master #2170 diff @@; ==========================================; Files 705 705 ; Lines 37924 37933 +9 ; Methods 0 0 ; Messages 0 0 ; Branches 8002 8005 +3 ; ==========================================; + Hits 28143 28172 +29 ; + Misses 7420 7396 -24 ; - Partials 2361 2365 +4 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2170/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 89% | [...r/tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2170/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F416C6C656C6553756273657474696E675574696C732E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...ellbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2170/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F76617269616E742F4741544B56617269616E74436F6E746578745574696C732E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [.../java/org/broadinstitute/hellbender/utils/Utils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2170/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F5574696C732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [491f7f2...3ac63b8](https://codecov.io/gh/broadinstitute/gatk/compare/491f7f2436421c53204be5c0fb5226bed2b4842a...3ac63b82465b1e7fe1ac8a3b0542e321286d217c?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2170#issuecomment-248102291:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2170#issuecomment-248102291,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2179?src=pr) is 74.416% (diff: 84.211%). > Merging [#2179](https://codecov.io/gh/broadinstitute/gatk/pull/2179?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.148%**. ``` diff; @@ master #2179 diff @@; ==========================================; Files 705 706 +1 ; Lines 37933 38012 +79 ; Methods 0 0 ; Messages 0 0 ; Branches 8005 8030 +25 ; ==========================================; + Hits 28172 28287 +115 ; + Misses 7396 7349 -47 ; - Partials 2365 2376 +11 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2179/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 82% | _new_ [...nder/tools/examples/ExampleAssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2179/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F6578616D706C65732F4578616D706C65417373656D626C79526567696F6E57616C6B65722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...nstitute/hellbender/engine/AssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2179/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F417373656D626C79526567696F6E57616C6B65722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [b4d9fb2...bdf6dc1](https://codecov.io/gh/broadinstitute/gatk/compare/b4d9fb2f6d9b487789bdd9405debdc260b58a229...bdf6dc1cb16f1d058575fec25667712974b46a96?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2179#issuecomment-248132733:440,Message,Messages,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2179#issuecomment-248132733,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2182?src=pr) is 75.950% (diff: 86.093%). > Merging [#2182](https://codecov.io/gh/broadinstitute/gatk/pull/2182?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.024%**. ``` diff; @@ master #2182 diff @@; ==========================================; Files 709 712 +3 ; Lines 38116 38241 +125 ; Methods 0 0 ; Messages 0 0 ; Branches 8009 8030 +21 ; ==========================================; + Hits 28940 29044 +104 ; - Misses 6711 6723 +12 ; - Partials 2465 2474 +9 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2182/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | â€¢â€¢â€¢â€¢ 40% | [...llbender/tools/walkers/vqsr/VariantRecalibrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2182/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F56617269616E74526563616C69627261746F722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 82% | _new_ [...titute/hellbender/engine/MultiVariantDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2182/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4D756C746956617269616E7444617461536F757263652E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 95% | _new_ [...dinstitute/hellbender/engine/MultiVariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2182/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4D756C746956617269616E7457616C6B65722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | _new_ [...adinstitute/hellbender/engine/VariantWalkerBase.java](https://codecov.io/gh/broadinstitute/gatk/pull/2182/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F56617269616E7457616C6B6572426173652E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2182#issuecomment-248405018:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2182#issuecomment-248405018,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2184?src=pr) is 74.446% (diff: 66.667%). > Merging [#2184](https://codecov.io/gh/broadinstitute/gatk/pull/2184?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.007%**. ``` diff; @@ master #2184 diff @@; ==========================================; Files 706 706 ; Lines 37972 37974 +2 ; Methods 0 0 ; Messages 0 0 ; Branches 8008 8009 +1 ; ==========================================; + Hits 28266 28270 +4 ; + Misses 7330 7328 -2 ; Partials 2376 2376 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2184/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | â€¢â€¢â€¢â€¢â€¢â€¢ 66% | [...calc/IndependentAllelesDiploidExactAFCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2184/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F616663616C632F496E646570656E64656E74416C6C656C65734469706C6F69644578616374414643616C63756C61746F722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [3e20270...54f8615](https://codecov.io/gh/broadinstitute/gatk/compare/3e202701dc55ab49857643926a86a79680c96fc8...54f86158d4d727fe97d266cb99957991ff823229?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2184#issuecomment-249189120:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2184#issuecomment-249189120,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2185?src=pr) is 75.926% (diff: 68.939%). > Merging [#2185](https://codecov.io/gh/broadinstitute/gatk/pull/2185?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.061%**. ``` diff; @@ master #2185 diff @@; ==========================================; Files 711 709 -2 ; Lines 38346 38116 -230 ; Methods 0 0 ; Messages 0 0 ; Branches 8066 8009 -57 ; ==========================================; - Hits 29138 28940 -198 ; + Misses 6731 6711 -20 ; + Partials 2477 2465 -12 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2185/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | 0% | [...ers/annotator/allelespecific/AS_StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/2185/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F616C6C656C6573706563696669632F41535F537472616E644F646473526174696F2E6A617661) |; | 0% | [...bender/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2185/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F47656E6F747970696E67456E67696E652E6A617661) |; | 0% | [...alkers/annotator/allelespecific/AS_FisherStrand.java](https://codecov.io/gh/broadinstitute/gatk/pull/2185/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F616C6C656C6573706563696669632F41535F466973686572537472616E642E6A617661) |; | â€¢â€¢â€¢â€¢ 40% | [...bender/tools/walkers/annotator/DepthPerSampleHC.java](https://codecov.io/gh/broadinstitute/gatk/pull/2185/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249258490:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249258490,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2186?src=pr) is 75.926% (diff: 100%). > Merging [#2186](https://codecov.io/gh/broadinstitute/gatk/pull/2186?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.003%**. ``` diff; @@ master #2186 diff @@; ==========================================; Files 712 712 ; Lines 38214 38219 +5 ; Methods 0 0 ; Messages 0 0 ; Branches 8022 8022 ; ==========================================; + Hits 29013 29018 +5 ; Misses 6726 6726 ; Partials 2475 2475 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2186/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...llbender/tools/walkers/vqsr/VariantRecalibrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2186/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F56617269616E74526563616C69627261746F722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...lbender/tools/walkers/vqsr/GaussianMixtureModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/2186/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F476175737369616E4D6978747572654D6F64656C2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...er/tools/walkers/vqsr/VariantRecalibratorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2186/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F56617269616E74526563616C69627261746F72456E67696E652E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...lbender/tools/walkers/vqsr/MultivariateGaussian.java](https://codecov.io/gh/broadinstitute/gatk/pull/2186/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F4D756C7469766172696174,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2186#issuecomment-249924338:433,Message,Messages,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2186#issuecomment-249924338,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2187?src=pr) is 75.892% (diff: 100%). > Merging [#2187](https://codecov.io/gh/broadinstitute/gatk/pull/2187?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.011%**. ``` diff; @@ master #2187 diff @@; ==========================================; Files 711 711 ; Lines 38290 38315 +25 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8066 +8 ; ==========================================; + Hits 29055 29078 +23 ; Misses 6765 6765 ; - Partials 2470 2472 +2 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2187/graphs/sunburst.svg?size=150&src=pr). > Powered by [Codecov](https://codecov.io?src=pr). Last update [c925d2c...30e9a42](https://codecov.io/gh/broadinstitute/gatk/compare/c925d2c3b53eb4e348b2bb3a852a708ef3fd724d...30e9a4244a26e00ae4d02b378f63dc30f6bb0e20?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2187#issuecomment-250553572:434,Message,Messages,434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2187#issuecomment-250553572,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2188?src=pr) is 75.894% (diff: 100%). > Merging [#2188](https://codecov.io/gh/broadinstitute/gatk/pull/2188?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.012%**. ``` diff; @@ master #2188 diff @@; ==========================================; Files 711 711 ; Lines 38290 38301 +11 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8058 ; ==========================================; + Hits 29055 29068 +13 ; + Misses 6765 6763 -2 ; Partials 2470 2470 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2188/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...itute/hellbender/utils/variant/GATKVCFConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/2188/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F76617269616E742F4741544B564346436F6E7374616E74732E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...ute/hellbender/utils/variant/GATKVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/2188/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F76617269616E742F4741544B5643464865616465724C696E65732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [c925d2c...3b78e79](https://codecov.io/gh/broadinstitute/gatk/compare/c925d2c3b53eb4e348b2bb3a852a708ef3fd724d...3b78e792b93605bfdaabe8db24219783d3df9209?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2188#issuecomment-249994221:434,Message,Messages,434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2188#issuecomment-249994221,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2189?src=pr) is 75.924% (diff: 58.123%). > Merging [#2189](https://codecov.io/gh/broadinstitute/gatk/pull/2189?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.034%**. ``` diff; @@ master #2189 diff @@; ==========================================; Files 711 718 +7 ; Lines 38303 38781 +478 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8120 +62 ; ==========================================; + Hits 29068 29444 +376 ; - Misses 6765 6845 +80 ; - Partials 2470 2492 +22 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2189/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | 0% | [...e/hellbender/tools/spark/sv/BreakpointAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/2189/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F427265616B706F696E74416C69676E6D656E742E6A617661) |; | 0% | [...broadinstitute/hellbender/utils/pairhmm/PairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/2189/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70616972686D6D2F50616972484D4D2E6A617661) |; | 0% | [...ender/tools/spark/sv/AlignAssembledContigsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2189/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F416C69676E417373656D626C6564436F6E74696773537061726B2E6A617661) |; | 0% | [...nder/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2189/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F46696E64427265616B706F696E7445766964656E6365537061726B2E6A617661) |; | 0% | [...r/tools/spark/sv/RunSGAVia,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2189#issuecomment-251449369:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2189#issuecomment-251449369,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2190?src=pr) is 76.076% (diff: 90.258%). > Merging [#2190](https://codecov.io/gh/broadinstitute/gatk/pull/2190?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.138%**. ``` diff; @@ master #2190 diff @@; ==========================================; Files 712 719 +7 ; Lines 38219 38560 +341 ; Methods 0 0 ; Messages 0 0 ; Branches 8022 8071 +49 ; ==========================================; + Hits 29023 29335 +312 ; - Misses 6721 6735 +14 ; - Partials 2475 2490 +15 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2190/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | â€¢â€¢ 25% | [...institute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2190/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F436F6D6D616E644C696E6550726F6772616D2E6A617661) |; | â€¢â€¢ 25% | [...dline/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/2190/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F4741544B506C7567696E2F4741544B5265616446696C746572506C7567696E44657363726970746F722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 83% | [...llbender/engine/spark/AddContextDataToReadSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2190/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F416464436F6E7465787444617461546F52656164537061726B2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 84% | _new_ [...titute/hellbender/engine/spark/LocusWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2190/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F4C6F63757357616C6B6572537061726B2E6A617661,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2190#issuecomment-250756828:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2190#issuecomment-250756828,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2194?src=pr) is 75.893% (diff: 0.000%). > Merging [#2194](https://codecov.io/gh/broadinstitute/gatk/pull/2194?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.003%**. ``` diff; @@ master #2194 diff @@; ==========================================; Files 711 711 ; Lines 38303 38300 -3 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8057 -1 ; ==========================================; - Hits 29068 29067 -1 ; + Misses 6765 6763 -2 ; Partials 2470 2470 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2194/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | 0% | [...bender/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2194/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F47656E6F747970696E67456E67696E652E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...genotyper/GenotypeCalculationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2194/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F47656E6F7479706543616C63756C6174696F6E417267756D656E74436F6C6C656374696F6E2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cdc484c...a7af494](https://codecov.io/gh/broadinstitute/gatk/compare/cdc484cc8978b28421e1beeddc4eeb97f44dbafd...a7af494115524062df232c7b0cfb59e07124184e?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2194#issuecomment-250791184:435,Message,Messages,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2194#issuecomment-250791184,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2205?src=pr) is 75.752% (diff: 100%); > Merging [#2205](https://codecov.io/gh/broadinstitute/gatk/pull/2205?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.013%**. ```diff; @@ master #2205 diff @@; ==========================================; Files 728 728 ; Lines 38433 38441 +8 ; Methods 0 0 ; Messages 0 0 ; Branches 8025 8026 +1 ; ==========================================; + Hits 29109 29120 +11 ; + Misses 6822 6820 -2 ; + Partials 2502 2501 -1 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2205/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...roadinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2205/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F526561647344617461536F757263652E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [dd7e19a...8a7c17f](https://codecov.io/gh/broadinstitute/gatk/compare/dd7e19a58fece8d165f5f8d2d17f88ad3ddf2666...8a7c17fad0808d6a40a07b4734f083d82951f136?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2205#issuecomment-257956634:432,Message,Messages,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2205#issuecomment-257956634,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2215?src=pr) is 75.903% (diff: 100%). > Merging [#2215](https://codecov.io/gh/broadinstitute/gatk/pull/2215?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.014%**. ``` diff; @@ master #2215 diff @@; ==========================================; Files 711 711 ; Lines 38303 38304 +1 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8058 ; ==========================================; + Hits 29068 29074 +6 ; + Misses 6765 6762 -3 ; + Partials 2470 2468 -2 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2215/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...ellbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2215/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F76617269616E742F4741544B56617269616E74436F6E746578745574696C732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cdc484c...d0ce3c9](https://codecov.io/gh/broadinstitute/gatk/compare/cdc484cc8978b28421e1beeddc4eeb97f44dbafd...d0ce3c966be8ba767c0da18c995c3be27b9af1d0?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2215#issuecomment-253694345:433,Message,Messages,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2215#issuecomment-253694345,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2218?src=pr) is 76.091% (diff: 98.734%); > Merging [#2218](https://codecov.io/gh/broadinstitute/gatk/pull/2218?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.004%**. ```diff; @@ master #2218 diff @@; ==========================================; Files 742 742 ; Lines 38819 38822 +3 ; Methods 0 0 ; Messages 0 0 ; Branches 8087 8091 +4 ; ==========================================; + Hits 29536 29540 +4 ; Misses 6719 6719 ; + Partials 2564 2563 -1 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2218/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | 0% | [...spark/sv/CallVariantsFromAlignedContigsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F43616C6C56617269616E747346726F6D416C69676E6564436F6E7469677353414D537061726B2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...institute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F4741544B537061726B546F6F6C2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...der/tools/walkers/genotyper/afcalc/AFCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F616663616C632F414643616C63756C61746F722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...lbender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F706970656C696E65732F42515352506970656C696,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2218#issuecomment-254678913:435,Message,Messages,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2218#issuecomment-254678913,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2220?src=pr) is 56.082% (diff: 76.119%). > Merging [#2220](https://codecov.io/gh/broadinstitute/gatk/pull/2220?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **45.285%**. ``` diff; @@ master #2220 diff @@; ==========================================; Files 719 717 -2 ; Lines 38566 38515 -51 ; Methods 0 0 ; Messages 0 0 ; Branches 8071 8070 -1 ; ==========================================; + Hits 4164 21600 +17436 ; + Misses 33820 14667 -19153 ; - Partials 582 2248 +1666 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2220/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | 0% | [...nsforms/bqsr/BaseRecalibratorEngineSparkWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/2220/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F7472616E73666F726D732F627173722F42617365526563616C69627261746F72456E67696E65537061726B577261707065722E6A617661) |; | 0% | [...ls/spark/sv/CallVariantsFromAlignedContigsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2220/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F43616C6C56617269616E747346726F6D416C69676E6564436F6E74696773537061726B2E6A617661) |; | 0% | [...ute/hellbender/tools/spark/sv/ContigsCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2220/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F436F6E74696773436F6C6C656374696F6E2E6A617661) |; | 0% | [...nder/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/2220/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F64617461,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-258497747:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-258497747,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2224?src=pr) is 76.531% (diff: 72.500%). > Merging [#2224](https://codecov.io/gh/broadinstitute/gatk/pull/2224?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.640%**. ``` diff; @@ master #2224 diff @@; ==========================================; Files 711 711 ; Lines 38304 41305 +3001 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 9401 +1343 ; ==========================================; + Hits 29069 31611 +2542 ; - Misses 6765 7086 +321 ; - Partials 2470 2608 +138 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2224/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | 0% | [.../org/broadinstitute/hellbender/utils/nio/NioBam.java](https://codecov.io/gh/broadinstitute/gatk/pull/2224/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6E696F2F4E696F42616D2E6A617661) |; | 0% | [...oadinstitute/hellbender/utils/nio/ReadsIterable.java](https://codecov.io/gh/broadinstitute/gatk/pull/2224/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6E696F2F52656164734974657261626C652E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 71% | [...collections/RequiredReadInputArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2224/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F617267756D656E74636F6C6C656374696F6E732F526571756972656452656164496E707574417267756D656E74436F6C6C656374696F6E2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 71% | [...collections/OptionalReadInputArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2224/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F617267756D656E74636F6C6C656374696F6E732F4F7074696F6E616C52656164496E707574417267756D656,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2224#issuecomment-257041772:439,Message,Messages,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2224#issuecomment-257041772,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2227?src=pr) is 75.906% (diff: 100%). > Merging [#2227](https://codecov.io/gh/broadinstitute/gatk/pull/2227?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.016%**. ``` diff; @@ master #2227 diff @@; ==========================================; Files 711 711 ; Lines 38304 38304 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8058 ; ==========================================; + Hits 29069 29075 +6 ; + Misses 6765 6762 -3 ; + Partials 2470 2467 -3 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2227/graphs/sunburst.svg?size=150&src=pr). > Powered by [Codecov](https://codecov.io?src=pr). Last update [13f88ae...7a4f692](https://codecov.io/gh/broadinstitute/gatk/compare/13f88aec9e10e76eb2445b7d2e430d33f24726ed...7a4f6927d2f4de11e24b2862a6223dd966ddc5c7?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2227#issuecomment-255795005:430,Message,Messages,430,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2227#issuecomment-255795005,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2228?src=pr) is 75.890% (diff: 100%). > Merging [#2228](https://codecov.io/gh/broadinstitute/gatk/pull/2228?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will not change coverage. ``` diff; @@ master #2228 diff @@; ==========================================; Files 711 711 ; Lines 38304 38304 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8058 ; ==========================================; Hits 29069 29069 ; Misses 6765 6765 ; Partials 2470 2470 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2228/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...picard/analysis/directed/RnaSeqMetricsCollector.java](https://codecov.io/gh/broadinstitute/gatk/pull/2228/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F7069636172642F616E616C797369732F64697265637465642F526E615365714D657472696373436F6C6C6563746F722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...gealignment/BestEndMapqPrimaryAlignmentStrategy.java](https://codecov.io/gh/broadinstitute/gatk/pull/2228/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F726561642F6D65726765616C69676E6D656E742F42657374456E644D6170715072696D617279416C69676E6D656E7453747261746567792E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...nstitute/hellbender/tools/picard/sam/SamToFastq.java](https://codecov.io/gh/broadinstitute/gatk/pull/2228/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F7069636172642F73616D2F53616D546F46617374712E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...a/org/broadinstitute/hellbender/utils/GenomeLoc.java](https://codecov.io/gh/broadinstitute/gatk/pull/2228/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F47656E6F6D654C6F632E6A617661,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2228#issuecomment-255478068:418,Message,Messages,418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2228#issuecomment-255478068,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2234?src=pr) is 56.038% (diff: 0.000%). > Merging [#2234](https://codecov.io/gh/broadinstitute/gatk/pull/2234?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.060%**. ``` diff; @@ master #2234 diff @@; ==========================================; Files 717 718 +1 ; Lines 38536 38579 +43 ; Methods 0 0 ; Messages 0 0 ; Branches 8073 8081 +8 ; ==========================================; + Hits 21618 21619 +1 ; - Misses 14670 14712 +42 ; Partials 2248 2248 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2234/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | 0% | _new_ [...alkers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/2234/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F76617269616E747574696C732F55706461746556434653657175656E636544696374696F6E6172792E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [5e17764...3107aa4](https://codecov.io/gh/broadinstitute/gatk/compare/5e17764f74fdf110d4ea09cc0b5508fbad9a1305...3107aa4310a538a66b41ddf19528787714a86a03?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2234#issuecomment-259310243:439,Message,Messages,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2234#issuecomment-259310243,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2235?src=pr) is 76.323% (diff: 95.082%). > Merging [#2235](https://codecov.io/gh/broadinstitute/gatk/pull/2235?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.431%**. ``` diff; @@ master #2235 diff @@; ==========================================; Files 711 711 ; Lines 38306 39012 +706 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8278 +220 ; ==========================================; + Hits 29071 29775 +704 ; + Misses 6765 6744 -21 ; - Partials 2470 2493 +23 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2235/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | 0% | [...er/tools/walkers/variantutils/FamilyLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/2235/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F76617269616E747574696C732F46616D696C794C696B656C69686F6F64732E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 83% | [...a/org/broadinstitute/hellbender/utils/MathUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2235/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F4D6174685574696C732E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...kers/genotyper/afcalc/AlleleFrequencyCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2235/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F616663616C632F416C6C656C654672657175656E637943616C63756C61746F722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...r/tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2235/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F416C6C656C655375,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2235#issuecomment-256761095:438,Message,Messages,438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2235#issuecomment-256761095,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2237?src=pr) is 76.001% (diff: 74.298%). > Merging [#2237](https://codecov.io/gh/broadinstitute/gatk/pull/2237?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.076%**. ``` diff; @@ master #2237 diff @@; ==========================================; Files 719 732 +13 ; Lines 38560 38926 +366 ; Methods 0 0 ; Messages 0 0 ; Branches 8071 8136 +65 ; ==========================================; + Hits 29335 29584 +249 ; - Misses 6735 6837 +102 ; - Partials 2490 2505 +15 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2237/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | 0% | _new_ [...der/tools/spark/utils/ReadTransformerSparkifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/2237/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F7574696C732F526561645472616E73666F726D6572537061726B69666965722E6A617661) |; | 0% | _new_ [...llbender/tools/spark/utils/ReadFilterSparkifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/2237/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F7574696C732F5265616446696C746572537061726B69666965722E6A617661) |; | 0% | _new_ [...llbender/tools/spark/pathseq/PathSeqFilterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2237/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F706174687365712F5061746853657146696C746572537061726B2E6A617661) |; | â€¢â€¢ 20% | [.../hellbender/engine/filters/ReadLengthReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2237/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F66696C746572732F526561644C656E6774685265616446696C74,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2237#issuecomment-256969944:442,Message,Messages,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2237#issuecomment-256969944,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2239?src=pr) is 75.932% (diff: 87.500%). > Merging [#2239](https://codecov.io/gh/broadinstitute/gatk/pull/2239?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.003%**. ``` diff; @@ master #2239 diff @@; ==========================================; Files 712 712 ; Lines 38201 38204 +3 ; Methods 0 0 ; Messages 0 0 ; Branches 8019 8018 -1 ; ==========================================; + Hits 29008 29009 +1 ; - Misses 6720 6722 +2 ; Partials 2473 2473 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2239/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 75% | [...bender/tools/walkers/annotator/DepthPerSampleHC.java](https://codecov.io/gh/broadinstitute/gatk/pull/2239/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F446570746850657253616D706C6548432E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [.../tools/walkers/annotator/DepthPerAlleleBySample.java](https://codecov.io/gh/broadinstitute/gatk/pull/2239/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F4465707468506572416C6C656C65427953616D706C652E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [028c361...9f7c142](https://codecov.io/gh/broadinstitute/gatk/compare/028c3610f7414279f454c6bb2c1404d5d6ca0403...9f7c14286c7abfc63eebb85961199359cd5db21f?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2239#issuecomment-257505571:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2239#issuecomment-257505571,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2242?src=pr) is 75.938% (diff: 35.714%). > Merging [#2242](https://codecov.io/gh/broadinstitute/gatk/pull/2242?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **65.051%**. ``` diff; @@ master #2242 diff @@; ==========================================; Files 712 712 ; Lines 38211 38214 +3 ; Methods 0 0 ; Messages 0 0 ; Branches 8019 8022 +3 ; ==========================================; + Hits 4160 29019 +24859 ; + Misses 33469 6721 -26748 ; - Partials 582 2474 +1892 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2242/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | â€¢â€¢â€¢ 35% | [...llbender/engine/datasources/ReferenceFileSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2242/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F64617461736F75726365732F5265666572656E636546696C65536F757263652E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [bc8318e...40072ed](https://codecov.io/gh/broadinstitute/gatk/compare/bc8318e1086f0ea9a6b67f0f658725baae6f0e90...40072ed1e8326e4698b2c6d0a06d3340ee298539?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2242#issuecomment-257627160:437,Message,Messages,437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2242#issuecomment-257627160,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2256?src=pr) is 75.861% (diff: 84.830%); > Merging [#2256](https://codecov.io/gh/broadinstitute/gatk/pull/2256?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.159%**. ```diff; @@ master #2256 diff @@; ==========================================; Files 729 742 +13 ; Lines 38506 38954 +448 ; Methods 0 0 ; Messages 0 0 ; Branches 8039 8123 +84 ; ==========================================; + Hits 29150 29551 +401 ; - Misses 6848 6858 +10 ; - Partials 2508 2545 +37 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2256/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢ 33% | [...er/engine/spark/datasources/VariantsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2256/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F64617461736F75726365732F56617269616E7473537061726B536F757263652E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 72% | *new* [...tute/hellbender/engine/spark/VariantWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2256/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F56617269616E7457616C6B6572537061726B2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 74% | *new* [...bender/tools/examples/ExampleVariantWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2256/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F6578616D706C65732F4578616D706C6556617269616E7457616C6B6572537061726B2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 75% | *new* [...ute/hellbender/engine/spark/IntervalWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2256/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F496E74657276616C57616C6B65,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2256#issuecomment-259098722:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2256#issuecomment-259098722,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2258?src=pr) is 75.976% (diff: 48.896%); > Merging [#2258](https://codecov.io/gh/broadinstitute/gatk/pull/2258?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **19.894%**. ```diff; @@ master #2258 diff @@; ==========================================; Files 717 734 +17 ; Lines 38515 39614 +1099 ; Methods 0 0 ; Messages 0 0 ; Branches 8070 8354 +284 ; ==========================================; + Hits 21600 30097 +8497 ; + Misses 14667 6969 -7698 ; - Partials 2248 2548 +300 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2258/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | 0% | [...spark/sv/CallVariantsFromAlignedContigsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2258/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F43616C6C56617269616E747346726F6D416C69676E6564436F6E7469677353414D537061726B2E6A617661) |; | 0% | [...ls/spark/sv/CallVariantsFromAlignedContigsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2258/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F43616C6C56617269616E747346726F6D416C69676E6564436F6E74696773537061726B2E6A617661) |; | 0% | *new* [...institute/hellbender/tools/spark/sv/SVVCFWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2258/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53565643465772697465722E6A617661) |; | â€¢â€¢â€¢â€¢ 40% | *new* [...ute/hellbender/tools/spark/sv/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/2258/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F4368696D6572696341,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2258#issuecomment-259324427:443,Message,Messages,443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2258#issuecomment-259324427,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2259?src=pr) is 75.907% (diff: 37.500%); > Merging [#2259](https://codecov.io/gh/broadinstitute/gatk/pull/2259?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.026%**. ```diff; @@ master #2259 diff @@; ==========================================; Files 731 731 ; Lines 38966 38994 +28 ; Methods 0 0 ; Messages 0 0 ; Branches 8151 8154 +3 ; ==========================================; + Hits 29588 29599 +11 ; - Misses 6855 6870 +15 ; - Partials 2523 2525 +2 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2259/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢ 22% | [...broadinstitute/hellbender/utils/pairhmm/PairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/2259/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70616972686D6D2F50616972484D4D2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢ 64% | [...e/hellbender/utils/pairhmm/VectorLoglessPairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/2259/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70616972686D6D2F566563746F724C6F676C65737350616972484D4D2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [7679749...558160e](https://codecov.io/gh/broadinstitute/gatk/compare/767974906e91c90079cefa4512b463138ca09f68...558160ea5bfde8be3b6e4bdd5283c529fb905fca?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2259#issuecomment-261320519:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2259#issuecomment-261320519,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2262?src=pr) is 76.058% (diff: 100%). > Merging [#2262](https://codecov.io/gh/broadinstitute/gatk/pull/2262?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **20.023%**. ``` diff; @@ master #2262 diff @@; ==========================================; Files 718 718 ; Lines 38581 38581 ; Methods 0 0 ; Messages 0 0 ; Branches 8081 8081 ; ==========================================; + Hits 21619 29344 +7725 ; + Misses 14714 6743 -7971 ; - Partials 2248 2494 +246 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2262/graphs/sunburst.svg?size=150&src=pr). > Powered by [Codecov](https://codecov.io?src=pr). Last update [bd8f1cb...e0d7613](https://codecov.io/gh/broadinstitute/gatk/compare/bd8f1cbc92b061132e1dc7332cc0f67e84044fee...e0d761361fb9deb1b0b02cd995b02f6fea37b3e9?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2262#issuecomment-260673866:431,Message,Messages,431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2262#issuecomment-260673866,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2263?src=pr) is 56.035% (diff: 100%). > Merging [#2263](https://codecov.io/gh/broadinstitute/gatk/pull/2263?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will not change coverage. ``` diff; @@ master #2263 diff @@; ==========================================; Files 718 718 ; Lines 38581 38581 ; Methods 0 0 ; Messages 0 0 ; Branches 8081 8081 ; ==========================================; Hits 21619 21619 ; Misses 14714 14714 ; Partials 2248 2248 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2263/graphs/sunburst.svg?size=150&src=pr). > Powered by [Codecov](https://codecov.io?src=pr). Last update [bd8f1cb...fb5f66b](https://codecov.io/gh/broadinstitute/gatk/compare/bd8f1cbc92b061132e1dc7332cc0f67e84044fee...fb5f66bd59c692950cf2c2a588685dd60888f10b?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2263#issuecomment-260673945:418,Message,Messages,418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2263#issuecomment-260673945,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2264?src=pr) is 56.035% (diff: 100%). > Merging [#2264](https://codecov.io/gh/broadinstitute/gatk/pull/2264?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will not change coverage. ``` diff; @@ master #2264 diff @@; ==========================================; Files 718 718 ; Lines 38581 38581 ; Methods 0 0 ; Messages 0 0 ; Branches 8081 8081 ; ==========================================; Hits 21619 21619 ; Misses 14714 14714 ; Partials 2248 2248 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2264/graphs/sunburst.svg?src=pr&size=150). > Powered by [Codecov](https://codecov.io?src=pr). Last update [bd8f1cb...6d8ef09](https://codecov.io/gh/broadinstitute/gatk/compare/bd8f1cbc92b061132e1dc7332cc0f67e84044fee...6d8ef0980f0294a65354d6376bdea2d44ff3aed0?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-260674364:418,Message,Messages,418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-260674364,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2271?src=pr) is 76.024% (diff: 75.000%). > Merging [#2271](https://codecov.io/gh/broadinstitute/gatk/pull/2271?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.028%**. ``` diff; @@ master #2271 diff @@; ==========================================; Files 731 731 ; Lines 38948 39102 +154 ; Methods 0 0 ; Messages 0 0 ; Branches 8146 8177 +31 ; ==========================================; + Hits 29599 29727 +128 ; - Misses 6840 6865 +25 ; - Partials 2509 2510 +1 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2271/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 75% | [...rg/broadinstitute/hellbender/utils/LoggingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2271/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F4C6F6767696E675574696C732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [a9e304f...e0bd30d](https://codecov.io/gh/broadinstitute/gatk/compare/a9e304fd7dd2ad854c2115f23eb507eb6c502324...e0bd30d79bf2b0831e731bc74c35c7796708c5bb?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2271#issuecomment-261380512:438,Message,Messages,438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2271#issuecomment-261380512,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2272?src=pr) is 75.941% (diff: 100%); > Merging [#2272](https://codecov.io/gh/broadinstitute/gatk/pull/2272?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.008%**. ```diff; @@ master #2272 diff @@; ==========================================; Files 731 731 ; Lines 38966 38966 ; Methods 0 0 ; Messages 0 0 ; Branches 8151 8151 ; ==========================================; + Hits 29588 29591 +3 ; + Misses 6855 6852 -3 ; Partials 2523 2523 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2272/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...stitute/hellbender/engine/spark/GATKRegistrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2272/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F4741544B5265676973747261746F722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [7679749...60902e5](https://codecov.io/gh/broadinstitute/gatk/compare/767974906e91c90079cefa4512b463138ca09f68...60902e55e33ebca62d204b7b5f808293e204e7f2?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2272#issuecomment-261381856:429,Message,Messages,429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2272#issuecomment-261381856,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2275?src=pr) is 75.937% (diff: 100%); > Merging [#2275](https://codecov.io/gh/broadinstitute/gatk/pull/2275?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.066%**. ```diff; @@ master #2275 diff @@; ==========================================; Files 731 731 ; Lines 38956 38961 +5 ; Methods 0 0 ; Messages 0 0 ; Branches 8147 8149 +2 ; ==========================================; - Hits 29608 29586 -22 ; - Misses 6838 6853 +15 ; - Partials 2510 2522 +12 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2275/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...dinstitute/hellbender/cmdline/CommandLineParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2275/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F436F6D6D616E644C696E655061727365722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [4d29cf7...9c8ec35](https://codecov.io/gh/broadinstitute/gatk/compare/4d29cf7a9e1d6c9ee936303d452aa2ca92febae0...9c8ec352770b67bd2cfd9203a86253b088875ed3?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2275#issuecomment-262073323:432,Message,Messages,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2275#issuecomment-262073323,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2279?src=pr) is 76.012% (diff: 100%); > Merging [#2279](https://codecov.io/gh/broadinstitute/gatk/pull/2279?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.008%**. ```diff; @@ master #2279 diff @@; ==========================================; Files 731 731 ; Lines 38948 39094 +146 ; Methods 0 0 ; Messages 0 0 ; Branches 8146 8176 +30 ; ==========================================; + Hits 29602 29716 +114 ; - Misses 6837 6867 +30 ; - Partials 2509 2511 +2 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2279/graphs/sunburst.svg?size=150&src=pr). > Powered by [Codecov](https://codecov.io?src=pr). Last update [4a844f0...c606f66](https://codecov.io/gh/broadinstitute/gatk/compare/4a844f03a080e68ccb2fd0bc0987f56fa2b7e6ed...c606f6695338bc38b01221760f26596ffe9a7fba?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2279#issuecomment-262013440:434,Message,Messages,434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2279#issuecomment-262013440,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2285?src=pr) is 56.143% (diff: 41.199%); > Merging [#2285](https://codecov.io/gh/broadinstitute/gatk/pull/2285?src=pr) into [sh_rewind_refactor](https://codecov.io/gh/broadinstitute/gatk/branch/sh_rewind_refactor?src=pr) will increase coverage by **0.098%**. ```diff; @@ sh_rewind_refactor #2285 diff @@; ====================================================; Files 722 723 +1 ; Lines 38556 38651 +95 ; Methods 0 0 ; Messages 0 0 ; Branches 8072 8105 +33 ; ====================================================; + Hits 21609 21700 +91 ; + Misses 14708 14701 -7 ; - Partials 2239 2250 +11 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2285/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | 0% | [...ls/spark/sv/CallVariantsFromAlignedContigsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F43616C6C56617269616E747346726F6D416C69676E6564436F6E74696773537061726B2E6A617661) |; | 0% | [.../hellbender/tools/spark/sv/GATKSVVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F4741544B53565643464865616465724C696E65732E6A617661) |; | 0% | *new* [...ellbender/tools/spark/sv/SVVariantConsensusCall.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F535656617269616E74436F6E73656E73757343616C6C2E6A617661) |; | â€¢â€¢â€¢â€¢ 45% | [...itute/hellbender/tools/spark/sv/AlignmentRegion.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2285#issuecomment-263705162:485,Message,Messages,485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2285#issuecomment-263705162,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2286?src=pr) is 75.922% (diff: 100%); > Merging [#2286](https://codecov.io/gh/broadinstitute/gatk/pull/2286?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **65.200%**. ```diff; @@ master #2286 diff @@; ==========================================; Files 731 731 ; Lines 38994 38994 ; Methods 0 0 ; Messages 0 0 ; Branches 8154 8154 ; ==========================================; + Hits 4181 29605 +25424 ; + Misses 34231 6866 -27365 ; - Partials 582 2523 +1941 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2286/graphs/sunburst.svg?src=pr&size=150). > Powered by [Codecov](https://codecov.io?src=pr). Last update [625ed04...5abaa38](https://codecov.io/gh/broadinstitute/gatk/compare/625ed042b6c6f4d9609e15064b494aa4bbd74f70...5abaa38b0a61d03626d57d625d459c259b1606a6?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2286#issuecomment-265002678:430,Message,Messages,430,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2286#issuecomment-265002678,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2293?src=pr) is 75.740% (diff: 56.410%); > Merging [#2293](https://codecov.io/gh/broadinstitute/gatk/pull/2293?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.164%**. ```diff; @@ master #2293 diff @@; ==========================================; Files 731 728 -3 ; Lines 38994 38433 -561 ; Methods 0 0 ; Messages 0 0 ; Branches 8154 8025 -129 ; ==========================================; - Hits 29598 29109 -489 ; + Misses 6871 6822 -49 ; + Partials 2525 2502 -23 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2293/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | 0% | [...llbender/tools/walkers/vqsr/VariantRecalibrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2293/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F56617269616E74526563616C69627261746F722E6A617661) |; | 0% | [...rg/broadinstitute/hellbender/engine/LocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2293/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4C6F63757357616C6B65722E6A617661) |; | 0% | [...lbender/tools/walkers/filters/VariantFiltration.java](https://codecov.io/gh/broadinstitute/gatk/pull/2293/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F66696C746572732F56617269616E7446696C74726174696F6E2E6A617661) |; | 0% | [...bender/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2293/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F47656E6F747970696E67456E67696E652E6A617661) |; | 0% | [...nstitute/hellbender/engine/AssemblyR,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2293#issuecomment-265198632:440,Message,Messages,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2293#issuecomment-265198632,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2305?src=pr) is 75.702% (diff: 95.652%); > Merging [#2305](https://codecov.io/gh/broadinstitute/gatk/pull/2305?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.036%**. ```diff; @@ master #2305 diff @@; ==========================================; Files 728 728 ; Lines 38435 38451 +16 ; Methods 0 0 ; Messages 0 0 ; Branches 8024 8027 +3 ; ==========================================; + Hits 29082 29108 +26 ; + Misses 6854 6840 -14 ; - Partials 2499 2503 +4 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2305/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢â€¢ 66% | [...argumentcollections/ReadInputArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2305/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F617267756D656E74636F6C6C656374696F6E732F52656164496E707574417267756D656E74436F6C6C656374696F6E2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...a/org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2305/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4741544B546F6F6C2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...collections/OptionalReadInputArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2305/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F617267756D656E74636F6C6C656374696F6E732F4F7074696F6E616C52656164496E707574417267756D656E74436F6C6C656374696F6E2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...roadinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2305/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F5265616473446,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2305#issuecomment-265868366:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2305#issuecomment-265868366,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2306?src=pr) is 75.760% (diff: 89.744%); > Merging [#2306](https://codecov.io/gh/broadinstitute/gatk/pull/2306?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.058%**. ```diff; @@ master #2306 diff @@; ==========================================; Files 728 729 +1 ; Lines 38451 38622 +171 ; Methods 0 0 ; Messages 0 0 ; Branches 8027 8073 +46 ; ==========================================; + Hits 29108 29260 +152 ; - Misses 6840 6847 +7 ; - Partials 2503 2515 +12 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2306/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 89% | [...lbender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/2306/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F64617461736F75726365732F5265616473537061726B53696E6B2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [ffc26bb...3381f1c](https://codecov.io/gh/broadinstitute/gatk/compare/ffc26bbb4d89d995396ff7b025a798daf1061c9d...3381f1c44a38f48a3a3d56358e41c57c3ef7396e?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-266849166:440,Message,Messages,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-266849166,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2307?src=pr) is 75.698% (diff: 80.000%); > Merging [#2307](https://codecov.io/gh/broadinstitute/gatk/pull/2307?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.008%**. ```diff; @@ master #2307 diff @@; ==========================================; Files 729 729 ; Lines 38515 38503 -12 ; Methods 0 0 ; Messages 0 0 ; Branches 8040 8039 -1 ; ==========================================; - Hits 29158 29146 -12 ; Misses 6849 6849 ; Partials 2508 2508 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2307/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 80% | [...broadinstitute/hellbender/utils/FisherExactTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2307/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F4669736865724578616374546573742E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [2e5a15a...3348b9e](https://codecov.io/gh/broadinstitute/gatk/compare/2e5a15ac4bc9774e853abb6d26c2acb60f2f9c20...3348b9ee3f9d12a2c6898f344ffa1c290f439f17?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266028932:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266028932,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2318?src=pr) is 75.706% (diff: 100%); > Merging [#2318](https://codecov.io/gh/broadinstitute/gatk/pull/2318?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.003%**. ```diff; @@ master #2318 diff @@; ==========================================; Files 729 729 ; Lines 38506 38507 +1 ; Methods 0 0 ; Messages 0 0 ; Branches 8039 8039 ; ==========================================; + Hits 29150 29152 +2 ; Misses 6848 6848 ; + Partials 2508 2507 -1 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2318/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...nder/tools/walkers/annotator/ReadPosRankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2318/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F52656164506F7352616E6B53756D546573742E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [.../hellbender/tools/walkers/annotator/RankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2318/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F52616E6B53756D546573742E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [.../annotator/allelespecific/AS_ReadPosRankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2318/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F616C6C656C6573706563696669632F41535F52656164506F7352616E6B53756D546573742E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [e1b4c8f...9a3e91c](https://codecov.io/gh/broadinstitute/gatk/compare/e1b4c8f4b781c6867e1eaea2dbb5587c6a6125a7...9a3e91c78ca9b0ce5f0da22a3cebd7199f255ff0?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2318#issuecomment-267388046:432,Message,Messages,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2318#issuecomment-267388046,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2320?src=pr) is 75.644% (diff: 70.923%); > Merging [#2320](https://codecov.io/gh/broadinstitute/gatk/pull/2320?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.494%**. ```diff; @@ master #2320 diff @@; ==========================================; Files 743 723 -20 ; Lines 38991 38841 -150 ; Methods 0 0 ; Messages 0 0 ; Branches 8120 8136 +16 ; ==========================================; - Hits 29687 29381 -306 ; - Misses 6734 6929 +195 ; + Partials 2570 2531 -39 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2320/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | 0% | [.../hellbender/tools/spark/sv/GATKSVVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/2320/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F4741544B53565643464865616465724C696E65732E6A617661) |; | 0% | [...spark/sv/CallVariantsFromAlignedContigsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2320/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F43616C6C56617269616E747346726F6D416C69676E6564436F6E7469677353414D537061726B2E6A617661) |; | 0% | [...er/utils/read/mergealignment/SamAlignmentMerger.java](https://codecov.io/gh/broadinstitute/gatk/pull/2320/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F726561642F6D65726765616C69676E6D656E742F53616D416C69676E6D656E744D65726765722E6A617661) |; | 0% | *new* [...institute/hellbender/tools/spark/sv/SVVCFWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2320/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53565643465772697465722E6A61766,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2320#issuecomment-267857623:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2320#issuecomment-267857623,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2323?src=pr) is 76.172% (diff: 100%); > Merging [#2323](https://codecov.io/gh/broadinstitute/gatk/pull/2323?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **65.997%**. ```diff; @@ master #2323 diff @@; ==========================================; Files 743 743 ; Lines 38960 38958 -2 ; Methods 0 0 ; Messages 0 0 ; Branches 8114 8114 ; ==========================================; + Hits 3964 29675 +25711 ; + Misses 34451 6711 -27740 ; - Partials 545 2572 +2027 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2323/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...lbender/tools/walkers/filters/VariantFiltration.java](https://codecov.io/gh/broadinstitute/gatk/pull/2323/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F66696C746572732F56617269616E7446696C74726174696F6E2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cf77bda...4a1a5e4](https://codecov.io/gh/broadinstitute/gatk/compare/cf77bdade1dfc64d5ae1d487dfe974508fa68b1f...4a1a5e4f9e909019226ac53ba1ab9d030a0c5463?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2323#issuecomment-268516777:433,Message,Messages,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2323#issuecomment-268516777,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2325?src=pr) is 76.365% (diff: 90.845%); > Merging [#2325](https://codecov.io/gh/broadinstitute/gatk/pull/2325?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.625%**. ```diff; @@ master #2325 diff @@; ==========================================; Files 729 743 +14 ; Lines 38479 40288 +1809 ; Methods 0 0 ; Messages 0 0 ; Branches 8036 8510 +474 ; ==========================================; + Hits 29144 30766 +1622 ; - Misses 6830 6887 +57 ; - Partials 2505 2635 +130 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2325/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 90% | [...oadinstitute/hellbender/utils/pileup/ReadPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/2325/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70696C6575702F5265616450696C6575702E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 90% | *new* [.../hellbender/tools/walkers/rnaseq/ASEReadCounter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2325/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F726E617365712F41534552656164436F756E7465722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [3eff9c1...d5f64bc](https://codecov.io/gh/broadinstitute/gatk/compare/3eff9c131f78bb80f55d1b27f7554d3b035af931...d5f64bceb32ac10ce42b09f6ff377cad0e446ced?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2325#issuecomment-268811473:442,Message,Messages,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2325#issuecomment-268811473,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2326?src=pr) is 76.019% (diff: 86.111%); > Merging [#2326](https://codecov.io/gh/broadinstitute/gatk/pull/2326?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.279%**. ```diff; @@ master #2326 diff @@; ==========================================; Files 729 729 ; Lines 38479 38505 +26 ; Methods 0 0 ; Messages 0 0 ; Branches 8036 8045 +9 ; ==========================================; + Hits 29144 29271 +127 ; + Misses 6830 6703 -127 ; - Partials 2505 2531 +26 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2326/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 86% | [...bender/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2326/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F47656E6F747970696E67456E67696E652E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [3eff9c1...f3d1e15](https://codecov.io/gh/broadinstitute/gatk/compare/3eff9c131f78bb80f55d1b27f7554d3b035af931...f3d1e158ca9dbf071e83a293e4e52bcae2be38c9?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2326#issuecomment-268849703:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2326#issuecomment-268849703,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2330?src=pr) is 76.012% (diff: 88.235%); > Merging [#2330](https://codecov.io/gh/broadinstitute/gatk/pull/2330?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.006%**. ```diff; @@ master #2330 diff @@; ==========================================; Files 729 729 ; Lines 38505 38506 +1 ; Methods 0 0 ; Messages 0 0 ; Branches 8045 8045 ; ==========================================; + Hits 29266 29269 +3 ; + Misses 6706 6704 -2 ; Partials 2533 2533 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2330/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢ 50% | [...ools/spark/sv/SVKmerizerWithLowComplexityFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2330/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53564B6D6572697A6572576974684C6F77436F6D706C657869747946696C7465722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [.../broadinstitute/hellbender/engine/FeatureWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2330/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4665617475726557616C6B65722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...org/broadinstitute/hellbender/engine/ReadWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2330/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F5265616457616C6B65722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...dinstitute/hellbender/tools/spark/sv/SVKmerizer.java](https://codecov.io/gh/broadinstitute/gatk/pull/2330/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53564B6D6572697A65722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...lbender/tools/spark/transforms/ApplyBQSRSparkF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2330#issuecomment-270462994:435,Message,Messages,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2330#issuecomment-270462994,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2331?src=pr) is 76.116% (diff: 72.222%); > Merging [#2331](https://codecov.io/gh/broadinstitute/gatk/pull/2331?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.023%**. ```diff; @@ master #2331 diff @@; ==========================================; Files 743 744 +1 ; Lines 38991 39038 +47 ; Methods 0 0 ; Messages 0 0 ; Branches 8120 8130 +10 ; ==========================================; + Hits 29687 29714 +27 ; - Misses 6734 6749 +15 ; - Partials 2570 2575 +5 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2331/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢â€¢ 66% | [...a/org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2331/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4741544B546F6F6C2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢ 68% | [...roadinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2331/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F526561647344617461536F757263652E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 73% | *new* [...broadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/2331/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F746573742F586F72577261707065722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [.../hellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/2331/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F5374616E64617264417267756D656E74446566696E6974696F6E732E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...lbender/utils/nio/SeekableByteChannelPrefetcher.java](https://codec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2331#issuecomment-271027025:439,Message,Messages,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2331#issuecomment-271027025,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2339?src=pr) is 76.230% (diff: 100%); > Merging [#2339](https://codecov.io/gh/broadinstitute/gatk/pull/2339?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **66.055%**. ```diff; @@ master #2339 diff @@; ==========================================; Files 743 743 ; Lines 38960 39112 +152 ; Methods 0 0 ; Messages 0 0 ; Branches 8114 8193 +79 ; ==========================================; + Hits 3964 29815 +25851 ; + Misses 34451 6719 -27732 ; - Partials 545 2578 +2033 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2339/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...oadinstitute/hellbender/utils/pileup/ReadPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/2339/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70696C6575702F5265616450696C6575702E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [.../hellbender/tools/walkers/rnaseq/ASEReadCounter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2339/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F726E617365712F41534552656164436F756E7465722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cf77bda...d0c671e](https://codecov.io/gh/broadinstitute/gatk/compare/cf77bdade1dfc64d5ae1d487dfe974508fa68b1f...d0c671e931c010f240af5c3a822af19052545b11?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2339#issuecomment-274917279:435,Message,Messages,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2339#issuecomment-274917279,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2340?src=pr) is 76.190% (diff: 56.098%); > Merging [#2340](https://codecov.io/gh/broadinstitute/gatk/pull/2340?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **66.015%**. ```diff; @@ master #2340 diff @@; ==========================================; Files 743 751 +8 ; Lines 38960 40319 +1359 ; Methods 0 0 ; Messages 0 0 ; Branches 8114 8477 +363 ; ==========================================; + Hits 3964 30719 +26755 ; + Misses 34451 6955 -27496 ; - Partials 545 2645 +2100 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2340/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | â€¢ 10% | [...rc/main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/2340/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F4D61696E2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...institute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2340/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F4741544B537061726B546F6F6C2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...institute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2340/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F436F6D6D616E644C696E6550726F6772616D2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...a/org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2340/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4741544B546F6F6C2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...adinstitute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2340#issuecomment-275000241:442,Message,Messages,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2340#issuecomment-275000241,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2342?src=pr) is 76.191% (diff: 100%); > Merging [#2342](https://codecov.io/gh/broadinstitute/gatk/pull/2342?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.001%**. ```diff; @@ master #2342 diff @@; ==========================================; Files 743 743 ; Lines 38962 38972 +10 ; Methods 0 0 ; Messages 0 0 ; Branches 8113 8118 +5 ; ==========================================; + Hits 29685 29693 +8 ; - Misses 6708 6710 +2 ; Partials 2569 2569 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2342/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...lbender/engine/filters/MappingQualityReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2342/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F66696C746572732F4D617070696E675175616C6974795265616446696C7465722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [29569a9...51e6426](https://codecov.io/gh/broadinstitute/gatk/compare/29569a9ffae87623e3eeffaae3effc965c8307a7...51e64264cb8ae0ce96b446eec9eea5e9c721a870?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2342#issuecomment-272990133:433,Message,Messages,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2342#issuecomment-272990133,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2348?src=pr) is 76.138% (diff: 67.133%); > Merging [#2348](https://codecov.io/gh/broadinstitute/gatk/pull/2348?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.037%**. ```diff; @@ master #2348 diff @@; ==========================================; Files 743 743 ; Lines 38960 38991 +31 ; Methods 0 0 ; Messages 0 0 ; Branches 8113 8120 +7 ; ==========================================; + Hits 29678 29687 +9 ; - Misses 6711 6734 +23 ; + Partials 2571 2570 -1 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2348/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | â€¢â€¢â€¢â€¢â€¢ 50% | [...roadinstitute/hellbender/tools/spark/sv/SVUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53565574696C732E6A617661) |; | â€¢â€¢â€¢â€¢â€¢ 50% | [...institute/hellbender/tools/spark/sv/SVKmerShort.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53564B6D657253686F72742E6A617661) |; | â€¢â€¢â€¢â€¢â€¢ 50% | [...dinstitute/hellbender/tools/spark/sv/SVKmerizer.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53564B6D6572697A65722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢ 55% | [...lbender/tools/spark/sv/FindBadGenomicKmersSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F46696E6442616447656E6F6D69634B6D657273537061726B2E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 71% | [...nder/tools/spark/sv/FindBreakpointEvidenceSpark.java](,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2348#issuecomment-273320758:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2348#issuecomment-273320758,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2374?src=pr) is 76.232% (diff: 0.000%); > Merging [#2374](https://codecov.io/gh/broadinstitute/gatk/pull/2374?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.161%**. ```diff; @@ master #2374 diff @@; ==========================================; Files 748 750 +2 ; Lines 39318 39401 +83 ; Methods 0 0 ; Messages 0 0 ; Branches 8196 8214 +18 ; ==========================================; Hits 30036 30036 ; - Misses 6686 6769 +83 ; Partials 2596 2596 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2374/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | 0% | *new* [...nstitute/hellbender/engine/MultiPassLocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2374/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4D756C7469506173734C6F63757357616C6B65722E6A617661) |; | 0% | *new* [...nder/tools/examples/ExampleMultiPassLocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2374/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F6578616D706C65732F4578616D706C654D756C7469506173734C6F63757357616C6B65722E6A617661) |; | â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢ 100% | [...a/org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2374/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4741544B546F6F6C2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [2c85e82...d7e18ea](https://codecov.io/gh/broadinstitute/gatk/compare/2c85e8241179f03f71a0b2442caa4ba68373c03d...d7e18eac4f0edcf1c0352861a49444cb597b40fb?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2374#issuecomment-275746509:438,Message,Messages,438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2374#issuecomment-275746509,1,['Message'],['Messages']
Integrability,"### Affected tool(s) or class(es). VariantFiltration. ### Affected version(s). Master 2021-01 onwards. ### Description . VariantFiltration's --invalidate-previous-filters prevent any output variant to be marked as PASS even if it passes the filters that are passed to that run of the filtration tool. What I would expect is that variants that pass the current set of filters will be marked as PASS regarless whether they were filtered or not filtered (PASS, or '.') in the input. . Perhaps the case is that this option is not meant.to be used with current/new filters being specified as to provide a way to revert previous filtration, but in that case it should fail if new filters are specified. #### Steps to reproduce. Just try it out with a VCF with some filters already applied and run VF with additional filters that will not result in all variants to be filtered. . You will see that no output variant is set To PASS but rather are kept as unknown '.' . #### Expected behavior. Either it does fail if a new filter is applied in the same tool run or passing variants filter are setlp to Pw. #### Actual behavior. Described above, no error message and no pass variants only ""."" ones.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7608:1145,message,message,1145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7608,1,['message'],['message']
Integrability,"### Affected tool(s) or class(es); GenotypeGVCFs is reporting:; ```. [TileDB::ArrayIterator] Error: Cannot advance iterator; Buffer overflow.; terminate called after throwing an instance of 'VariantStorageManagerException'; what(): VariantStorageManagerException exception : VariantArrayCellIterator increment failed; TileDB error message : [TileDB::ArrayIterator] Error: Cannot advance iterator; Buffer overflow; ```. ### Affected version(s); ```; Using GATK jar /home/xuql/miniconda3/share/gatk4-4.2.6.1-1/gatk-package-4.2.6.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/xuql/miniconda3/share/gatk4-4.2.6.1-1/gatk-package-4.2.6.1-local.jar --version; The Genome Analysis Toolkit (GATK) v4.2.6.1; HTSJDK Version: 2.24.1; Picard Version: 2.27.1. ```. ### Description ; Hi, I developed AnchorWave to call long indels(could be a couple of Mb). We are trying to connect the AnchorWave variant calling result with GATK to generate VCF files. We generated whole genome alignments for 26 maize accession via AnchorWave. And we wrote out own code to generate GVCF files from the outputs of AnchorWave. Those GVCF files works well with GATK GenomicsDBImport. While, the `GenotypeGVCFs` function is reporting `Buffer overflow` errors and could generate the complete VCF files. . Here is the command we used:. ```; gatk --java-options ""-Xmx100g"" GenotypeGVCFs -R Zm-B73-REFERENCE-NAM-5.0.fa -stand-call-conf 0 -ploidy 1 -V gendb:///home/xuql/NAM_anchorwave_song/NAM_out_gatk9 -O gatk9.vcf.gz --cloud-prefetch-buffer 10000 --cloud-index-prefetch-buffer 10000 --genomicsdb-max-alternate-alleles 110 --max-alternate-alleles 100 --tmp-dir /home/xuql/NAM_anchorwave_song/temp9 --gcs-max-retries 1000; ```; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7976:331,message,message,331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7976,1,['message'],['message']
Integrability,"### Affected tool(s) or class(es); HaplotypeCallerSpark. gatk HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I GatherBamFiles.bam -O g.vcf.gz. The HaplotypeCaller works, but not HaplotypeCallerSpark.; Tried to use the docker image, and different server; tried to build the newest gatk, same error message. ### Affected version(s); - [ x ] Latest public release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6750:318,message,message,318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750,2,['message'],['message']
Integrability,"### Background: jar dependency hell. Getting GATK to compile with the gcloud-java-nio dependency is already a little bit of a struggle because of conflicting versions of the com.google.protobuf class (see #2013). Running it on Dataproc results in a version conflict somewhere else, probably linked to the jars that are automatically included on Dataproc. Getting gcloud-java-nio to work on vanilla Spark runs into the exact same category of problems (dependency conflicts), see eg. [this question on StackOverflow](http://stackoverflow.com/questions/38536004/spark-java-noclassdeffounderror-when-adding-dependency/38575957#38575957). The root of the problem is that both Hadoop and GCloud-Java rely on the same core Google libraries (Guava, Protobuf), but they use different versions that are incompatible. Java is not currently able to have two different versions of the same library at once, so instead you end up forcing one version of the other. Neither version appears to work for all of our dependencies, so we have a problem.; ### Workaround. Barring improvements in Java, our only way forward may be to use a shaded ""fat jar"" version of gcloud-java-nio that (i) includes all of its dependencies in a single jar and (ii) renames the shared dependencies so they won't conflict with what eg. Hadoop brings in. Luckily, gcloud-java-nio already builds such a jar by default. However that jar is not published on Maven Central. So the solution is to download the gcloud-java-nio source code, compile it ourselves (without any modification), and use the resulting jar (target/gcloud-java-nio-0.2.7-SNAPSHOT-shaded.jar). . This solution works for both vanilla Spark and GATK. I suspect it would be acceptable for us to directly include that jar in our source tree so that our own users wouldn't have to take any special steps to use GATK: just compile and run, as usual. Let's discuss. CC: @droazen @lbergelson",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2044:20,depend,dependency,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2044,7,['depend'],"['dependencies', 'dependency']"
Integrability,"### Feature request. I would like to be able to pull out the indel allele only from mixed records. I'm told this would take the form of a flag that would modify the -selectType behavior to additionally reach into mixed records and subset alleles. If this feature will be addressed, then it also needs to be backported to gsa-unstable. Additionally, I would like to be able to pull out variants based on allele frequency cutoff, e.g. `-select ""AF> [#]""`. This is so I can pull out common and low-frequency variants to the exclusion of rare variants. Currently using this option with the Phase 3 1000 Genomes vcf this gives the following error:. ```; ##### ERROR MESSAGE: Invalid JEXL expression detected for select-0 with message ![0,10]: 'AF > 0.001;' > error; ```. Laura says this error has do with multiallelic sites. Searching the forum for ""JEXL, AF, multiallelic"" I find two relevant discussions (links below) that tell me to do things well beyond my abilities. E.g. first I need to subset for biallelic sites etc. http://gatkforums.broadinstitute.org/gatk/discussion/6526/selectvariants-af-with-multiallelic-variants; http://gatkforums.broadinstitute.org/gatk/discussion/comment/21120#Comment_21120",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1537#issuecomment-190920186:661,MESSAGE,MESSAGE,661,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1537#issuecomment-190920186,2,"['MESSAGE', 'message']","['MESSAGE', 'message']"
Integrability,"### Summary; A user running Mutect2 in GATK 4.1.9.0 was inputting an interval list using the -XL option and received an error message that did not illuminate the problem. Their intervals file was made using BedToIntervalList and was a picard-style interval list. The final solution they found was the [correct extension](https://gatk.broadinstitute.org/hc/en-us/articles/360035531852-Intervals-and-interval-lists), .interval_list. ### Example 1; Using .intervallist extension, the error message said the interval was not valid; `A USER ERROR has occurred: Badly formed genome unclippedLoc: Query interval ""combinedblacklist.intervallist"" is not valid for this input`. ### Example 2; Using .intervals extension, the error message said the interval list was badly formed and not valid; `A USER ERROR has occurred: Badly formed genome unclippedLoc: Query interval ""@HD VN:1.6 SO:coordinate"" is not valid for this input.`. <br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/113538'>Zendesk ticket #113538</a>)<br>gz#113538</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7095:126,message,message,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7095,3,['message'],['message']
Integrability,### Updates; Some GATK-SV VCFs contain MEI deletions with ALT in the format <DEL:ME:ALU> or <DEL:ME>. This change will allow SVAnnotate to recognize and annotate those records as deletions. ### Testing; * Added unit test with MEI DEL; * Ran all unit and integration tests for SVAnnotate,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8125:254,integrat,integration,254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8125,1,['integrat'],['integration']
Integrability,#1444 is several related issues. This is more specific. 1444 depends on this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1448#issuecomment-174704568:61,depend,depends,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1448#issuecomment-174704568,1,['depend'],['depends']
Integrability,"#1629 @akiezun @droazen @lbergelson. Added a substring search to `SWPairwiseAlignment.align`to avoid running the full Smith-Waterman when the query is found in the reference without any indels. The performance benefit of this code will be data dependent. In the current HaplotypeCaller test, >80% of the Smith-Waterman calls are filtered by the substring search. Added tests to cover all of the overhang strategies. **Note:** The substring search only works for the `SOFTCLIP`and `IGNORE`overhang strategies. The `INDEL`and `LEADING_INDEL`can result in more complicated CIGAR strings. See the `SWPairwiseAlignmentUnitTest.testSubstringMatchIndelLong` and `SWPairwiseAlignmentUnitTest.testSubstringMatchLeadingIndelLong` tests for examples.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1677:244,depend,dependent,244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1677,1,['depend'],['dependent']
Integrability,#2689 - Example code to mark fields that do not have a combination operation to avoid warnings such as 'No valid combination operation found for INFO field AN - the field will NOT be part of INFO fields in the generated VCF record'. We also have [GenomicsDB PR#85](https://github.com/GenomicsDB/GenomicsDB/pull/85) in the works that will log these types of messages only once per field.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6514:357,message,messages,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6514,1,['message'],['messages']
Integrability,"#3925 introduced a conda dependency on libgcc-ng=7.2.0, which works in Travis since its available or Ubuntu, but fails to resolve for osx. Its not clear to me what the options are, but we need to resolve this one way or another.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4074:25,depend,dependency,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4074,1,['depend'],['dependency']
Integrability,"#7931); - VS_492 - Beta User Jar release (#7934); - Cost WDL should throw on FISS API errors [VS-518] (#7942); - Fix bad check for missing workflow name [VS-520] (#7943); - Remove usage of service account from GvsValidateVAT.wdl (#7937); - refactoring for testablity (#7946); - More import retries [VS-532] (#7953); - A few last doc changes (#7927); - WDL to extract a single callset cost (BQ only, not Terra) (#7940); - Temporarily swap in Corretto for Temurin as we can't download Temurin. (#7969); - GL-548 - Update CreateVat code to handle samples that do not contain all population groups. (#7965); - Restore Temurin 11 [VS-570] (#7972); - Add table size check to quickstart integration test [VS-501] (#7970); - Consolidate various docs for AoU callset generation into one to rule them all [VS-553] (#7971); - VS-567. Removing usage of ServiceAccount from CreateVat related WDLs (#7974); - WDL to extract Avro files for Hail import [VS-579] (#7981); - Removed usage of service account from WDLs (#7985); - Document steps for GVS cleanup for base use case [VS-586] (#7989); - Change backticks to single quotes in several error messages - causing shell to attempt to execute. (#7995); - VS-598 - Minor update to AoU Documentation. (#7994); - Allow for incremental addition of data to alt_allele [VS-52] (#7993); - Minor AoU Documentation Update (#7999); - Batch population of alt_allele table from vet_ tables [VS-265] (#7998); - Change drop_state to NONE for Ingest/Extract [VS-607] (#8000); - python -> python3 (#8001); - Generate Hail import/export script [VS-605] (#8002); - clearer error when values are missing (#7939); - Ah [VS-565] output intervals and sample list (#8010); - make CreateAltAlleleTable task volatile (#8011); - Restore withdrawn [VS-581] (#8006); - Km gvs add storage cost and cleanup doc (#8012); - Updating documentation to reflect the changed outputs [VS-565] (#8014); - File of callset samples -> samples marked as 'withdrawn' in GVS [VS-436] (#8009); - fix quota guide",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:27348,message,messages,27348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['message'],['messages']
Integrability,"' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/resources/main'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/tmp/sparkJar/MANIFEST.MF'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; ```. ```; Deprecated Gradle features were used in this build, making it incompatible with Gradle 8.0. You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins. See https://docs.gradle.org/7.3.2/userguide/command_line_interface.html#sec:command_line_warnings. Execution optimizations have been disabled for 4 invalid unit(s) of work during this build to ensure correctness.; Please consult deprecation warnings for more details.; ```; The warnings show up in at least these tasks: gatkTabComplete, installDist, gatkDoc, shadowJar, sparkJar. Seems like it should be easy to fix, I'm not sure how we didn't see them when doing the upgrade.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7625:1556,depend,depending,1556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7625,1,['depend'],['depending']
Integrability,(Host unreachable); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); at sha,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417:1534,protocol,protocol,1534,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417,3,['protocol'],['protocol']
Integrability,"(Linked to #7988); Feature additions (and integration tests) for CompareReferences tool, including:; * ability to run base-level comparison modes on specified sequences (not just detected mismatching sequences) using ""sequences-to-align"" option ; * changed wording for missing MD5 compatibility status ('COMPATIBLE' to 'MAYBE_COMPATIBLE,' or something similar) in compatibility tool ; * option to ignore case level differences in base level comparison modes . NOTE: integration test on using an equivalent sequences input file with more than one line (ie. specifying more than one sequences) not yet tested, and can probably do some refactoring to clean up the code for the equivalent sequence comparisons",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8163:42,integrat,integration,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8163,2,['integrat'],['integration']
Integrability,(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); [TileDB::FileSystem] Error: hdfs: Error getting hdfs connection; [TileDB::StorageManagerConfig] Error: Error getting hdfs connection: Conne,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6522:6583,Message,MessageHubBackedObjectConnection,6583,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6522,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,"(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:14:00 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 0.0 (TID 3, scc-q16.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 124511724, span 7265, expected MD5 cf58e0adc447a66b188474efc3c84a43; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.r",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:9731,Wrap,Wrappers,9731,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['Wrap'],['Wrappers']
Integrability,(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Failed to read bam header from /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; Caused by:File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:237); 	at org.broadinstitute.hellbender.engine.spark.GAT,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:2951,protocol,protocolPB,2951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocolPB']
Integrability,"(added here for easier tracking). In bwajni.c; - [ ] lift `(*env)->GetArrayLength(env,baseArray)` out of loops; - [ ] pass pointers directly not wrapped in classes, eg. BwaIndex could be passed as a pointer; - [ ] cache all fieldIDs, methodIDs and classes; - [ ] pass in data directly without the ShortRead; - [ ] batch multiple calls to align (1 read) ; - [ ] pass in a struct for the native code to fill rather then allocate a new AlnRgn everytime",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1857:145,wrap,wrapped,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1857,1,['wrap'],['wrapped']
Integrability,"(only non-trivial remaining requests are to do the rename of the IntegrationTest classes now rather than later, and to provide stats in this thread on test file size so we can make sure nothing is inappropriately large)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/176#issuecomment-75090134:65,Integrat,IntegrationTest,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/176#issuecomment-75090134,1,['Integrat'],['IntegrationTest']
Integrability,"(this is mainly relevant for Picard tools, which often have lots of log.info() calls). CommandLineProgram's VERBOSITY is set to INFO by default, which is reasonable when you're actually interacting with a tool, but quickly gets spammy when running unit tests. I propose injecting VERBOSITY=ERROR (the strictest setting) into CommandLineProgramTest to avoid this. This would fix https://github.com/broadinstitute/hellbender/issues/134",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/147:270,inject,injecting,270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/147,1,['inject'],['injecting']
Integrability,) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.6/tests/test/index.html) |; | python | openjdk8 | [29984.5](https://travis-ci.com/broadinstitute/gatk/jobs/317851323) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.5/tests/test/index.html) |; | integration | oraclejdk8 | [29984.12](https://travis-ci.com/broadinstitute/gatk/jobs/317851330) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.12/tests/test/index.html) |; | integration | openjdk11 | [29984.13](https://travis-ci.com/broadinstitute/gatk/jobs/317851331) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.13/tests/test/index.html) |; | cloud | openjdk8 | [29984.1](https://travis-ci.com/broadinstitute/gatk/jobs/317851319) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.1/tests/test/index.html) |; | cloud | openjdk11 | [29984.15](https://travis-ci.com/broadinstitute/gatk/jobs/317851333) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.15/tests/test/index.html) |; | unit | openjdk11 | [29984.14](https://travis-ci.com/broadinstitute/gatk/jobs/317851332) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.14/tests/test/index.html) |; | integration | openjdk8 | [29984.2](https://travis-ci.com/broadinstitute/gatk/jobs/317851320) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29984.4](https://travis-ci.com/broadinstitute/gatk/jobs/317851322) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.4/tests/test/index.html) |; | unit | openjdk8 | [29984.3](https://travis-ci.com/broadinstitute/gatk/jobs/317851321) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611695380:1674,integrat,integration,1674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611695380,1,['integrat'],['integration']
Integrability,) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.6/tests/test/index.html) |; | integration | oraclejdk8 | [29988.12](https://travis-ci.com/broadinstitute/gatk/jobs/317861697) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.12/tests/test/index.html) |; | python | openjdk8 | [29988.5](https://travis-ci.com/broadinstitute/gatk/jobs/317861683) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.5/tests/test/index.html) |; | integration | openjdk11 | [29988.13](https://travis-ci.com/broadinstitute/gatk/jobs/317861698) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.13/tests/test/index.html) |; | cloud | openjdk11 | [29988.15](https://travis-ci.com/broadinstitute/gatk/jobs/317861700) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.15/tests/test/index.html) |; | cloud | openjdk8 | [29988.1](https://travis-ci.com/broadinstitute/gatk/jobs/317861676) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.1/tests/test/index.html) |; | unit | openjdk11 | [29988.14](https://travis-ci.com/broadinstitute/gatk/jobs/317861699) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.14/tests/test/index.html) |; | integration | openjdk8 | [29988.2](https://travis-ci.com/broadinstitute/gatk/jobs/317861680) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29988.4](https://travis-ci.com/broadinstitute/gatk/jobs/317861682) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.4/tests/test/index.html) |; | unit | openjdk8 | [29988.3](https://travis-ci.com/broadinstitute/gatk/jobs/317861681) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611710351:1674,integrat,integration,1674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611710351,1,['integrat'],['integration']
Integrability,) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.6/tests/test/index.html) |; | integration | oraclejdk8 | [29990.12](https://travis-ci.com/broadinstitute/gatk/jobs/317870159) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.12/tests/test/index.html) |; | python | openjdk8 | [29990.5](https://travis-ci.com/broadinstitute/gatk/jobs/317870152) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.5/tests/test/index.html) |; | cloud | openjdk8 | [29990.1](https://travis-ci.com/broadinstitute/gatk/jobs/317870147) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.1/tests/test/index.html) |; | cloud | openjdk11 | [29990.15](https://travis-ci.com/broadinstitute/gatk/jobs/317870162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.15/tests/test/index.html) |; | integration | openjdk11 | [29990.13](https://travis-ci.com/broadinstitute/gatk/jobs/317870160) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.13/tests/test/index.html) |; | integration | openjdk8 | [29990.2](https://travis-ci.com/broadinstitute/gatk/jobs/317870149) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.2/tests/test/index.html) |; | unit | openjdk11 | [29990.14](https://travis-ci.com/broadinstitute/gatk/jobs/317870161) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29990.4](https://travis-ci.com/broadinstitute/gatk/jobs/317870151) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.4/tests/test/index.html) |; | unit | openjdk8 | [29990.3](https://travis-ci.com/broadinstitute/gatk/jobs/317870150) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629:1467,integrat,integration,1467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629,1,['integrat'],['integration']
Integrability,) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.6/tests/test/index.html) |; | python | openjdk8 | [29992.5](https://travis-ci.com/broadinstitute/gatk/jobs/317887705) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.5/tests/test/index.html) |; | integration | oraclejdk8 | [29992.12](https://travis-ci.com/broadinstitute/gatk/jobs/317887712) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.12/tests/test/index.html) |; | integration | openjdk11 | [29992.13](https://travis-ci.com/broadinstitute/gatk/jobs/317887713) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.13/tests/test/index.html) |; | cloud | openjdk8 | [29992.1](https://travis-ci.com/broadinstitute/gatk/jobs/317887701) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.1/tests/test/index.html) |; | cloud | openjdk11 | [29992.15](https://travis-ci.com/broadinstitute/gatk/jobs/317887715) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.15/tests/test/index.html) |; | integration | openjdk8 | [29992.2](https://travis-ci.com/broadinstitute/gatk/jobs/317887702) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.2/tests/test/index.html) |; | unit | openjdk11 | [29992.14](https://travis-ci.com/broadinstitute/gatk/jobs/317887714) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29992.4](https://travis-ci.com/broadinstitute/gatk/jobs/317887704) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.4/tests/test/index.html) |; | unit | openjdk8 | [29992.3](https://travis-ci.com/broadinstitute/gatk/jobs/317887703) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611733065:1467,integrat,integration,1467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611733065,1,['integrat'],['integration']
Integrability,"), I'm not able to compile gatk with gradlew.; Here the logs:; ```bash; axverdier@spark:~/Tools/GATK4/git/gatk$ ./gradlew clean; :clean. BUILD SUCCESSFUL. Total time: 2.031 secs; axverdier@spark:~/Tools/GATK4/git/gatk$ ./gradlew --stacktrace --info; Initialized native services in: /home/axverdier/.gradle/native; Connected to daemon DaemonInfo{pid=32687, address=[a73e45df-d609-43d0-9385-508a26a328d4 port:39221, addresses:[/0:0:0:0:0:0:0:1, /127.0.0.1]], state=Idle, lastBusy=1516787326803, context=DefaultDaemonContext[uid=7e8a7a6d-190b-445f-9873-f0329477e561,javaHome=/usr/lib/jvm/java-8-oracle,daemonRegistryDir=/home/axverdier/.gradle/daemon,pid=32687,idleTimeout=10800000,daemonOpts=-XX:MaxPermSize=256m,-XX:+HeapDumpOnOutOfMemoryError,-Xmx1024m,-Dfile.encoding=US-ASCII,-Duser.country=US,-Duser.language=en,-Duser.variant]}. Dispatching request Build{id=16e78f98-b0ed-404d-bf38-965d87be7924.1, currentDir=/home/axverdier/Tools/GATK4/git/gatk}.; Received result org.gradle.launcher.daemon.protocol.BuildStarted@5495333e from daemon DaemonInfo{pid=32687, address=[a73e45df-d609-43d0-9385-508a26a328d4 port:39221, addresses:[/0:0:0:0:0:0:0:1, /127.0.0.1]], state=Idle, lastBusy=1516787326803, context=DefaultDaemonContext[uid=7e8a7a6d-190b-445f-9873-f0329477e561,javaHome=/usr/lib/jvm/java-8-oracle,daemonRegistryDir=/home/axverdier/.gradle/daemon,pid=32687,idleTimeout=10800000,daemonOpts=-XX:MaxPermSize=256m,-XX:+HeapDumpOnOutOfMemoryError,-Xmx1024m,-Dfile.encoding=US-ASCII,-Duser.country=US,-Duser.language=en,-Duser.variant]} (build should be starting).; The client will now receive all logging from the daemon (pid: 32687). The daemon log file: /home/axverdier/.gradle/daemon/3.1/daemon-32687.out.log; Starting 7th build in daemon [uptime: 5 mins 24.778 secs, performance: 92%, GC rate: 0.11/s, tenured heap usage: 12% of 716.2 MB]; Executing build with daemon context: DefaultDaemonContext[uid=7e8a7a6d-190b-445f-9873-f0329477e561,javaHome=/usr/lib/jvm/java-8-oracle,daemonRegistryDir=/ho",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4248:1052,protocol,protocol,1052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4248,1,['protocol'],['protocol']
Integrability,); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextIterator(SamReaderQueryingIterator.java:129); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:111); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:27); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:13); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellb,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6475:1797,wrap,wrapAndCopyInto,1797,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6475,1,['wrap'],['wrapAndCopyInto']
Integrability,"); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.NotSerializableException: java.nio.HeapByteBuffer; Serialization stack:; **\- object not serializable (class: java.nio.HeapByteBuffer, value: java.nio.HeapByteBuffer[pos=0 lim=775456500 cap=775456500])**; - field (class: org.bdgenomics.adam.util.TwoBitFile, name: bytes, type: class java.nio.ByteBuffer); - object (class org.bdgenomics.adam.util.TwoBitFile, org.bdgenomics.adam.util.TwoBitFile@863c31e); - field (class: org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource, name: twoBitFile, type: class org.bdgenomics.adam.util.TwoBitFile); - object (class org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource, org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource@3c82e6f4); - field (class: org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource, name: referenceSource, type: interface org.broadinstitute.hellbender.engine.datasources.ReferenceSource); - object (class org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource, org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource@78eac8f2); - element of array (index: 1); - array (class [Ljava.lang.Object;, size 2); - field (class: java.lang.invoke.SerializedLambda, name: capturedArgs, type: class [Ljava.lang.Object;); - object (class java.lang.invoke.SerializedLambda, SerializedLambda[capturingClass=class org.broadinstitute.hellbender.engine.spark.ShuffleJoinReadsWithRefBases, functionalInterfaceMethod=org/apache/spark/api/java/function/PairFlatMapFunction.call:(Ljava/lang/Object;)Ljava/lang/Iterable;, implementation=invokeStatic org/broadinstitute/hellbender/engine/spark/ShuffleJoinReadsWithRefBases.lambda$addBases$cff38836$1:(Lorg/broadinstitute/hellbender/utils/SerializableFunction;Lorg/broadinstitute/hellbender/engine/datasources/ReferenceMultiSource;Lscala/Tu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2216:3826,interface,interface,3826,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2216,1,['interface'],['interface']
Integrability,"); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:07 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 3, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:07 WARN TaskSetManager:66 - Lost task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:25885,Wrap,Wrappers,25885,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,); at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:85); at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:101); at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51); at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:244); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846); at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131); at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511); at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468); at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382); at i,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1491:4023,Message,MessageToMessageDecoder,4023,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1491,1,['Message'],['MessageToMessageDecoder']
Integrability,* A log message in SortSamSpark was using the wrong placeholder for inserting text so the message was printing; the literal characters %d instead inserting the correct value. Now it puts in a number.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6636:8,message,message,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6636,2,['message'],['message']
Integrability,* A previouus change left a reference to an uninitialized property in build.gradle.; This caused a crash when trying to produce an error message warning that the JDK was not found. Ex: Caused by: groovy.lang.MissingPropertyException: Could not get unknown property 'requiredJavaVersion' for root project 'gatk' of type org.gradle.api.Project; * Fix the crash by removing the reference to the missing property.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6676:137,message,message,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6676,1,['message'],['message']
Integrability,* Add contig and start position to error message in setMatePosition; * Extract the check to a shared method with setPosition so it's not inconsistent; * Improves the unhelpful error reported in https://github.com/broadinstitute/gatk/issues/6776,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6779:41,message,message,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6779,1,['message'],['message']
Integrability,"* Added support for annotating 5'/3' flanks via new FIVE_PRIME_FLANK and THREE_PRIME_FLANK funcotations. * Added --five-prime-flank-size and --three-prime-flank-size arguments to control the size of each flanking region. * Refactored datasource classes to allow for padded/custom queries to make this feature possible. * We now emit IGR funcotations in more cases (in particular, when a gene has no basic transcripts, and when the basic transcripts do not fully span a gene and the flank size is small). * Added comprehensive unit tests, and updated integration test data. Resolves #4771",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5403:550,integrat,integration,550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5403,1,['integrat'],['integration']
Integrability,* Centralizes Docker image versioning to top-level WDLs; * Does away with GATK override jar in all cases except integration tests (override jar can still be specified during feature development and/or for emergencies); * Docker image versions can be captured as the inputs to tasks; * Freshens Variants Docker image. Integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/815ef8ea-8cfe-47b6-be80-54250d1f180b),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8457:112,integrat,integration,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8457,2,"['Integrat', 'integrat']","['Integration', 'integration']"
Integrability,* Change extract so that when we filter at the genotype level (with FT) the VCF header has the FT filter definition in the comment/unspecified field.; * Also minor renaming of ExtractCohort argument.; * Point to updated truth.; ; [Here's](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/94129da8-6faf-419b-ab75-a46c228b1bbe) an integration test run. Passing everything except ValidateVDS because `reference_data` not being written due to issues beyond my control.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8850:352,integrat,integration,352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8850,1,['integrat'],['integration']
Integrability,* Extracting a new interface from the existing class ReadsDataSource; * the new interface is called ReadsDataSource; * ReadsDataSource has been renamed to ReadsPathDataSource; * This is to support the introduction of a new ReadsDataSource implementation using Htsget,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633:19,interface,interface,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633,2,['interface'],['interface']
Integrability,"* Fixing a non-deterministic point in HaplotypeCaller's KBestHaplotypeFinder; * It uses a priority queue to compare scores, if there are ties the tie breaking is arbitrary and seems to be different depending on circumstances of the run.; * For some as of yet unknown reason reading from a gs path vs a local path can cause this to be triggered.; * Adding a tie breaker which uses the entirety of the bases in the Path in cases where the score is tied, this is unique per path.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6104:198,depend,depending,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6104,1,['depend'],['depending']
Integrability,* Fixing an obscure error in an error message in GATKAnnotationPluginDescription.; * entrySet was called instead of values as a result everything was always filtered from the error message. Noticed this one completely by chance.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5444:38,message,message,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5444,2,['message'],['message']
Integrability,* Have GvsCreateVATfromVDS.wdl take sites-only-vcf as an optional input.; * Added logic to allow/disallow CopyFile to overwrite. [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/bb8906d4-7111-4fd1-a723-b5616b354c23) is a passing run using an existing sites-only VCF.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/9c8be4d5-f707-4c54-bde5-18d9d23cde66) is a run where it tried to generate the sites-only VCF. Failing because of Echo issues with creating VDS.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/8f8cc493-b0ff-4d8c-8813-6c463dbf17c0) is an integration test. It's failing in ValidateVDS on two paths (the ones that create VDSes) since this is based off of EchoCallset branch - this is expected,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8866:671,integrat,integration,671,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8866,1,['integrat'],['integration']
Integrability,* NioBam and ExampleNioCountReads was a useful experiment and demonstration but we have not moved it past that stage in multiple years.; * We adopted Disq instead of persuing this route.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6479:180,rout,route,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6479,1,['rout'],['route']
Integrability,* Replacing some cases of NPE with IllegalArgumentException with a clear message. This should help clarify the issue we talked about at the meeting today if it comes up again. I can't remember what the ticket was to link to though.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6781:73,message,message,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6781,1,['message'],['message']
Integrability,* Successful run in PMI land that finds nothing to clean up [here](https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20Echo%20First%20Look/job_history/ba861882-96ee-4635-b522-2fe9489b0076).; * Successful run in Integration land that finds loads to clean up [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/01667ae7-fd85-4a12-abcb-69e892500fa3).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8644:225,Integrat,Integration,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8644,1,['Integrat'],['Integration']
Integrability,* The UserException when failing to open a FeatureReader now includes the message from the underlying TribbleException.; * It was previously hard to understand WHY we had failed to open a reader.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7375:74,message,message,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7375,1,['message'],['message']
Integrability,"* The performance should be fine - TileDB/GenomicsDB stores each field in a separate file (columnar storage) and so adding MIN_DP file to the list of queried fields (~5-10 INFO fields) should be fine.; * One possible source of performance improvement - I was querying the PL field in the sites only query (not producing it in the output VariantContext objects). I think it can be dropped from the query. I was assuming that the PL field would be needed to correctly handle spanning deletions (spanning deletion corresponds to deletion allele with min PL). However, for spanning deletions, all INFO fields are dropped. Hence, any INFO fields that depend on the allele order (allele specific annotations) would be dropped for the spanning deletion. Hence, the exact deletion allele corresponding to the spanning deletion is irrelevant making it possible to drop the PL field from the query as well. Is that correct?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3688#issuecomment-377305568:646,depend,depend,646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3688#issuecomment-377305568,1,['depend'],['depend']
Integrability,"* _Large number of open file handles_: this was an issue in TileDB which got fixed as part of the restructuring that @nalinigans did for supporting HDFS/S3/GCS (#5017). I was too lazy to fix this again. If it's going to take some time for PR #5017 to be merged, I can submit a separate fix for this. This would fix any crashes/termination issues.; * _Performance of a single import process with a large number of intervals_; * Restating the obvious, but this is a single process (and by default, a single thread) with many intervals to import. As you increase the number of samples, this will become a performance pain point.; * More important than the number of intervals is the amount of data imported per interval. Each interval import involves opening the VCF files (loading index structures while creating FeatureReader objects), writing to TileDB/GenomicsDB. and closing the VCF file handles (destroying FeatureReader objects). If the amount of data written for each interval is sufficiently large, the cost of opening/closing the VCF files (creating/destroying FeatureReaders) is small relative to the total time taken.; * In the test cases I and Chris were trying, the amount of data written per interval was small (or 0 in many cases). The time taken in opening/closing the VCF files (and loading/destroying the index) dominates the total time.; * For a single import process (single thread), creating a large interval is better (or no worse) than passing several small intervals. TileDB/GenomicsDB has 0 overhead for regions with no data (for example, WES gVCFs). Having larger intervals will likely avoid issues described above. Hence, an advisory message will be beneficial.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5066#issuecomment-410576757:1659,message,message,1659,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5066#issuecomment-410576757,1,['message'],['message']
Integrability,* `JointVariantCalling` [does set](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f3f98f0e-2a7f-460b-886f-3442551140a8) `tighter_gcp_quotas`.; * Integration tests [do not set](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/51213d40-7583-49f1-a101-1842180a6470) `tighter_gcp_quotas`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8540:170,Integrat,Integration,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8540,1,['Integrat'],['Integration']
Integrability,* fix dependabot alert for jetty-xml; * bom version -> 9.4.56.v2024082,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9016:6,depend,dependabot,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9016,1,['depend'],['dependabot']
Integrability,* moved a log message about creating the python bundle during build so it only triggers when the python bundle is actually being built; * previously it was emitted on every build,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4147:14,message,message,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4147,1,['message'],['message']
Integrability,* removing the dataflow dependencies; * bumping the genomics api dependencies to modern versions; * removing auth holder and unthreading it from the code base. fixes https://github.com/broadinstitute/gatk/issues/954; fixes https://github.com/broadinstitute/gatk/issues/963; fixes https://github.com/broadinstitute/gatk/issues/1786; fixes https://github.com/broadinstitute/gatk/issues/2402,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3990:24,depend,dependencies,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3990,2,['depend'],['dependencies']
Integrability,* update gradle wrapper 8.2.1 -> 8.10.2; * remove 'versions' plugin because we don't use it; * update gradle plugins to new versions; * shadow plugin changed maintainers and coordinates com.github.johnrengelman.shadow:8.1.1 -> com.gradleup.shadow:8.3.3; * git-version 0.5.1 -> 3.1.0; * sonatype scan 2.6.1 -> 2.8.3; * download 5.4.0 -> 5.6.0; * use tasks.register() which is the newer style,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8998:16,wrap,wrapper,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8998,1,['wrap'],['wrapper']
Integrability,* updating Intel-GKL from 8.5 -> 8.6; * this is a very minor update that only changes a log message; * fixes https://github.com/broadinstitute/gatk/issues/5393,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5463:92,message,message,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5463,1,['message'],['message']
Integrability,"**After** we've ported reduce support for allele-specific annotations in https://github.com/broadinstitute/gatk/issues/1893 (and not as we're porting!), we should refactor the relevant interfaces to clean them up a bit.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3293:185,interface,interfaces,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3293,1,['interface'],['interfaces']
Integrability,"**Initial integration of GKL**; - Removed native build related items from `build.gradle`; - Removed native code from src tree; - Refactored `PairHMM.java` and `VectorLoglessPairHMM.java` to use GKL; - Updated `VectorPairHMMUnitTest.java` to use GKL; - Added integration tests to `IntelDeflaterIntegrationTest.java`. **Notes**; - PairHMM has been tested in HaplotypeCaller and GVCF output is md5sum equivalent to the PairHMM currently in GATK; - PairHMM in GKL is still single threaded, but about **_1.4x faster**_ than existing PairHMM, due to fixing a performance issue in the native code; - Next steps are captured in #1903 #1946",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1935:10,integrat,integration,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1935,2,['integrat'],['integration']
Integrability,"**Spanning Deletion Changes**. 1. Created a new SpanningDeletionRecord as a subclass of ReferenceRecord but allows us to store GT and GQ; 2. in handlePotentialSpanningDeletion when processing a deletion, we create a new SpanningDeletionRecord with the correct GT and GQ based on the deletion; 3. When processing reference data at a variant site, return ReferenceRecords/SpanningDeletionRecord instead of just a string ""state"" since we need more than just state now; 4. Because of the above, we are now returning an object for the inferred state instead of just a string. Since the inferred state is so, so common a singleton InferredReferenceRecord was created; 5. Processing of spanning deletions beyond. **Ugly**; 1. The construction of the singleton is ugly because it _requires_ a location even though we don't for this case. We could go to an tagging interface (like Cloneable) these all implement, but that seems ugly also. *Refactoring Changes*; One of the challenges with this PR was testing as the work is really done in the lower-level methods and it would be nice to have this as a unit test rather than an integration/end-to-end test. This motivated the following changes:. 1. don't write to VCF directly, instead have take a Consumer<VariantContext> to emit VariantContexts. This let's us provide a different consumer in unit tests to collect our result.; 2. we previously had a chain of calls createVariantsFromSortedRanges -> processSampleRecordsForLocation -> finalizeCurrentVariant that returned void and as a side effect wrote to VCF. These deeper methods now return a VariantContext and the writing (via consumer) is done higher up in the call stack; 3. made some private methods package-private so we could call them from tests. **Thinking Out Loud**. We have three different sets of datastructures for the same data, some of this is history, some is performance/memory, but could use some rethinking; 1. GenericRecord (pulling from BQ); 2. ReferenceRecord/SpanningDeletionRecord (",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7857:856,interface,interface,856,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7857,1,['interface'],['interface']
Integrability,**increase** coverage by `0.139%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5251 +/- ##; ===============================================; + Coverage 86.903% 87.042% +0.139% ; - Complexity 30311 32163 +1852 ; ===============================================; Files 1849 1974 +125 ; Lines 140507 147466 +6959 ; Branches 15475 16232 +757 ; ===============================================; + Hits 122105 128358 +6253 ; - Misses 12793 13189 +396 ; - Partials 5609 5919 +310; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5251?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...spark/ReadsPreprocessingPipelineSparkTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvUmVhZHNQcmVwcm9jZXNzaW5nUGlwZWxpbmVTcGFya1Rlc3REYXRhLmphdmE=) | `0% <0%> (-94.03%)` | `0% <0%> (-11%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-89.583%)` | `0% <0%> (-12%)` | |; | [...adinstitute/hellbender/engine/ReadContextData.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5251#issuecomment-426437671:1303,Integrat,IntegrationUtils,1303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5251#issuecomment-426437671,1,['Integrat'],['IntegrationUtils']
Integrability,"*before*: GATK crashes with a stack trace. The stack trace contains useful; info, but:; * it's hard to read; * it doesn't include the name of the file we cannot access. *now*, a better message that addresses both issues:; > A USER ERROR has occurred: Couldn't read file gs://(...). Error was:; > 401: Anonymous users does not have storage.objects.get access to object (...). Additional information (including a stack trace) is displayed if the; user specifies `--verbosity=DEBUG`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2417:185,message,message,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2417,1,['message'],['message']
Integrability,*increase** coverage by `0.104%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5040 +/- ##; ==============================================; + Coverage 86.38% 86.485% +0.104% ; - Complexity 28640 29299 +659 ; ==============================================; Files 1782 1791 +9 ; Lines 132603 135334 +2731 ; Branches 14761 15341 +580 ; ==============================================; + Hits 114543 117043 +2500 ; - Misses 12740 12841 +101 ; - Partials 5320 5450 +130; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5040?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...walkers/bqsr/AnalyzeCovariatesIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5040/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQW5hbHl6ZUNvdmFyaWF0ZXNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `93.846% <100%> (+1.783%)` | `24 <0> (+2)` | :arrow_up: |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5040/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `90.909% <0%> (-1.399%)` | `2% <0%> (+1%)` | |; | [...lignment/AssemblyContigAlignmentsConfigPicker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5040/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0Fzc2VtYmx5Q29udGlnQWxpZ25tZW50c0NvbmZpZ1BpY2tlci5qYXZh) | `92.857% <0%> (-0.658%)` | `125% <0%> (+30%)` | |; | [.../AssemblyContigAlignmentsConfigPickerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5040/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0Fzc2VtYmx5Q29udGlnQWxpZ25tZW50c0NvbmZpZ1BpY2tlclVuaXRUZXN0LmphdmE=) | `99.279% <0%> (-0.326%)` | `42% <0%> (+22,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-406636430:1279,integrat,integration,1279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-406636430,1,['integrat'],['integration']
Integrability,"+1 to @lbergelson's point. It seems the header is really only involved when reading or writing a bam file. Would be great to eliminate it entirely except on the ""external interface"" when writing files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141155734:171,interface,interface,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141155734,1,['interface'],['interface']
Integrability,"- Add a CLI flag `--exclude-field-name` which can be specified multiple times.; For example `... --exclude-field-name Clinvar_bar --exclude-field-name Clinvar_foo ...`. We will specify the column names with the full field name: `<datasourcename>_<fieldname>`. For now, we specify via an `exclude`. If nothing is specified, then show everything. - Make sure that this new parameter is integrated into the config file framework as implemented by #4581",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943:384,integrat,integrated,384,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943,1,['integrat'],['integrated']
Integrability,- Add more detail to error message so that it will be more usful for â€¦,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4498:27,message,message,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4498,1,['message'],['message']
Integrability,"- Adds the â€œgatkâ€ conda environment, with dependencies defined by the file scripts/gatkcondaenv.yml.; - Updates the docker image to include the activated conda environment.; - Adds a new entry to the travis test matrix for running tests that depend on Python and the conda environment.; - Adds a â€œpythonâ€ test group. Any tests for tools or functionality that are dependent on Python should be put into this group. Tests in this group will be executed in a docker container on travis in the python build matrix entry only.; - The existing WDL tests are unchanged; so although they execute in the context of the docker container and conda environment, there are no tests (yet) that are actually dependent on the conda environment and run through cromwell.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912:42,depend,dependencies,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912,4,['depend'],"['depend', 'dependencies', 'dependent']"
Integrability,- Creating PR for update to Funcotator documentation and to show off CARROT integration.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6920:76,integrat,integration,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6920,1,['integrat'],['integration']
Integrability,"- DF_BaseRecalibrator tool, can be called from the command line. Same syntax as BaseRecalibrator.; - BaseRecalibrator's integration tests ported to this Dataflow version.; - Small changes to make types serializable.; - Note that this pull request is an intermediate step as it only works for local computations. (this depends on [PR#522](https://github.com/broadinstitute/hellbender/pull/522))",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/523:120,integrat,integration,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/523,2,"['depend', 'integrat']","['depends', 'integration']"
Integrability,- Deprecated FuncotatorUtils.getCodingSequence (until its fixed).; - Added a more descriptive error message when the reference does not contain sequence information for a given position.; - Fixed all args to be kabob case.; - Fixed high-level Funcotator documentation. Fixes #4021,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4063:100,message,message,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4063,1,['message'],['message']
Integrability,- Disable default read filter with arguments does not longer blows up but log a warning (fixes #2357); - Improved help message for read filter (fixes #2358 and #2398); - `--disableAllReadFilters` changed to `--disableToolDefaultReadFilters` and `isDisabledFilter()` honor this behavior (fixes #2361 and #2363); - Add test for exercise the path of logging a warning when disabling a not enabled filter (as proposed in #2377); - Disabling a non-existent read filter throws a `CommandLineException` (fixes #2397),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2401:119,message,message,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2401,1,['message'],['message']
Integrability,- Extracted the order validation for GVCF files into a separate method and included; a check to reset the counter when a new contig is found. Contigs have to; occur in continuous blocks; validation for files in which contigs occur; alternatingly is not supported.; - Added a set of integration tests for GVCF files with two and three contigs. Fixes #6023,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6028:282,integrat,integration,282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6028,1,['integrat'],['integration']
Integrability,"- Fixes https://github.com/broadinstitute/gatk/issues/4696, https://github.com/broadinstitute/gatk/issues/4342, https://github.com/broadinstitute/gatk/issues/4443, https://github.com/broadinstitute/gatk/issues/4444.; - Use a second FIFO for command acknowledgement instead of relying on prompt synchronization.; - Add a Python module for managing the Python side of GATK/Python interaction.; - Removed all timeouts.; - Install a Python exception handler for handling uncaught Python exceptions.; - Update CNNScoreVariants to use the new protocol.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4757:294,synchroniz,synchronization,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4757,2,"['protocol', 'synchroniz']","['protocol', 'synchronization']"
Integrability,"- I changed some capitalization depending on what a google search brought up for terms, e.g. Fisher's Exact Test --> Fisher's exact test. But I only did so for the summary and did not touch the rest of the doc.; - Again, I did not touch any other portion of the annotation docs. ---; ### Examining the gatkDocs via a browser:. - [ ] StrandOddsRatio equations looking odd with `$$` surrounding them, e.g.; ```; Odds Ratios in the 2x2 contingency table below are; $$ R = \frac{X[0][0] * X[1][1]}{X[0][1] * X[1][0]} $$; ```; - Docs with minimal content and author showing (DavidB or TakutoS):; - [ ] BaseQuality; - [ ] FragmentLength; - [ ] MappingQuality; - [ ] ReadPosition; - [ ] ReferenceBases; - [ ] StrandArtifact; - Docs with just minimal content; - ExcessHet; - SampleList; - [ ] OxoGReadCounts hypertext link at bottom should include a doi, title should be italicized not quoted and hypertext should be limited to title.; - Some of the docs have a ""Caveat"" section while others have ""Related annotations"" and others neither. This seems inconsistently applied.; - [ ] UniqueAltReadCount's content is one giant long paragraph that could use formatting. Also, again, not sure if UniqueAltReadCount.java's acronym is actually UNIQ_ALT_READ_COUNT.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344711871:32,depend,depending,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344711871,1,['depend'],['depending']
Integrability,"- I sneaked in another change where I pass in a single file containing a list of input_vcfs instead of an array of input_vcfs. I made this because Terra couldn't save my inputs when I passed in 700 samples.; - Most of the logic was moved into `CreateTables`, including the determination for what files to load. It would have been cleaner to move all of the file loading logic into `LoadTable` but the current approach cuts down the on the number of `gsutil ls` calls made and more importantly, only spins up a shard if there are files to load.; - I pushed the logic into a separate workflow because I wanted to refactor it as two tasks and I couldn't find a way to get a Task to call another Task without wrapping it in a workflow.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7056:705,wrap,wrapping,705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7056,1,['wrap'],['wrapping']
Integrability,- Move command line parser integration of read filters up to GATKTool (https://github.com/broadinstitute/gatk/issues/2175); - Added fromList method to ReadFilter and CountingReadFilter (https://github.com/broadinstitute/gatk/issues/2198); - Minor change/rationalization of naming and implementation of BQSR filter methods to match the rest of the framework; - Made a small change to the implementation of the base read filter class to improve clarity/testability; - Opportunistic removal of extraneous imports in unrelated classes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2218:27,integrat,integration,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2218,1,['integrat'],['integration']
Integrability,"- Moved tools to ""Metagenomics"" program group; - Updated tool docs; - Changed tool arguments to kebab-case; - Defined argument strings as static variables that are cross-referenced in integration tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3918:184,integrat,integration,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3918,1,['integrat'],['integration']
Integrability,"- Now will detect variants on mitochondrial contigs and will use the; correct, alternate coding sequence to create protein change strings for; such variants.; - Added MT sequences to Gencode data source.; - Added tests for MT protein change strings.; - Now `FuncotatorUtils::getMitochondrialAminoAcidByCodon` has more; complete tests and handles special cases for known initiation site; differences by genus.; - Updated scripts to detect the directory in which the scripts are run.; - Added MT variants to integration tests.; - Added MT genes to gencode testing data source. Fixes #4863",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5361:506,integrat,integration,506,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5361,1,['integrat'],['integration']
Integrability,"- Push to `gvs` repo in `broad-dsde-methods` rather than `variantstore`.; - Fix the way image IDs are discovered.; - Support both `alpine` and non-`alpine` image types, setting up support for plink2. Successful integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/c1c2fc65-104b-46af-a536-882d7c1e8954).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8791:211,integrat,integration,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8791,1,['integrat'],['integration']
Integrability,- Relaxes restrictions for allowed samples in SVConcordance: the tool can now accept eval/truth VCFs with arbitrary sample sets and will have genotype concordance metrics computed on the intersection of the sample sets. All available samples are still used for AF/AC annotations. Integration tests added for cases when the samples sets are overlapping but not equal.; - Small additional improvements for sites-only VCFs: concordance annotations will now be `.` instead of `NaN` for example. Integration test added for this case.; - Improved behavior for eval AF annotations: these will not be recalculated if they already exist.; - Improved behavior for truth AF annotations: these will now only be recalculated if they don't exist in the input truth VCF.; - Updated tool doc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8211:280,Integrat,Integration,280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8211,2,['Integrat'],['Integration']
Integrability,- Remove some unused VCF header fields from ExtractFeatures; - Renamed VQSR Lite fields to their original naming (e.g. AS_VQS_SENS becomes CALIBRATION_SENSITIVITY). Passing integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/67a00690-5b74-40fd-a0fb-5ab2b0407a4d) - uses updated truth. Example outputs can be found in [this](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/22134bb6-e4b5-4252-b674-860a1168fb6c) Extract run.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8412:173,integrat,integration,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8412,1,['integrat'],['integration']
Integrability,- Removed positive-negative training from TrainVariantAnnotationsModel along with associated integration and WDL tests.; - Added ability to run positive-unlabeled training by passing unlabeled annotations to a custom python backend (although no example backend or tests were added).; - Cleaned up some WDL arguments to allow distinct training and scoring python scripts.; - Removed the `useAlleleSpecificAnnotations` argument; we instead infer whether to run in allele-specific mode from the VCF header.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8131:93,integrat,integration,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8131,1,['integrat'],['integration']
Integrability,- Tool creates histograms to reflect differences in the composition reference blocks in GVCF files; - Integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6802:102,Integrat,Integration,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6802,1,['Integrat'],['Integration']
Integrability,- [x] Mount the large files rather than copying into the docker image when running the tests.; - [x] Cleanup the build directory before publishing. We only need the jar.; - [ ] Remove native dependencies that are not required for the docker image.; - [ ] Uninstall gcc and clean the ubuntu image a bit.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2720:191,depend,dependencies,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2720,1,['depend'],['dependencies']
Integrability,- error message was not updated when arguments were changed....,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5969:8,message,message,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5969,1,['message'],['message']
Integrability,"- error messages will now include all the missing arguments when applicable; - error messages should be more readable; old style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument output was missing: Argument 'output' is required. ***********************************************************************; ```. new style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred:. Invalid command line:; required argument --input was not specified; required argument --output was not specified. Rerun with --help to see more information on available options. ***********************************************************************; ```; - fixed a bug in CommandLineParser; - collection arguments that had a mutual exclusion field would be reported as missing even if one of the mutex arguments was present; - adding tests for this case; - some refactoring on CommandLineParser. fixes #418. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1144). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1144:8,message,messages,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1144,2,['message'],['messages']
Integrability,- fixup for problem with fully specified `file:///` names that I introduced in #1450 ; - adding test for fully specified `file:///` url; - adding additional tests to `ReadSparkSink` for HDFS; - tests for writing to HDFS using `MiniDFSCluster`; - tests for overwriting existing HDFS paths; - fixed instance of Wrong FileSystem exception in `ReadSparkSink`; - refactored `ReadSparkSink` to remove duplication; - adding `MiniClusterUtils`; - revising existing code using `MiniDFSCluster` to go through `MiniClusterUtils`; - had to make the minicluster dependency a compile time instead of test dependency so downstream projects can make use of MiniClusterUtils.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1461:549,depend,dependency,549,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1461,2,['depend'],['dependency']
Integrability,"- improved baits count annotator (""lazy"" post processing); - included bait counts as a multiplicative bias in TargetCoverageSexGenotypeCalculator; - improved info and warn log messages in TargetCoverageSexGenotyper; - interval exclusion via CLI args for TargetCoverageSexGenotyper; - soft target filtering using masks; - more extensive unit/integration tests for TargetCoverageSexGenotyper; - integration test for annotate targets w/ bait counts; - missing test resource files from gatk-protected repo; - address PR review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3183:176,message,messages,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3183,3,"['integrat', 'message']","['integration', 'messages']"
Integrability,"- new ""lazy"" annotation mode in TargetAnnotator (a hack for generating annotations that can not be done with a state-less FeatureWalker); - baits count target annotation; - included bait count as a multiplicative bias in TargetCoverageSexGenotypeCalculator; - improved info and warn log messages in TargetCoverageSexGenotyper; - interval exclusion via CLI args for TargetCoverageSexGenotyper (PAR regions can not be blacklisted via CLI arguments); - soft target filtering using masks; - more extensive unit/integration tests for TargetCoverageSexGenotyper; - integration test for annotate targets w/ bait counts",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2813:287,message,messages,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2813,3,"['integrat', 'message']","['integration', 'messages']"
Integrability,"- reduced retries for task calling write API because if it fails more than once, chances are it will continue to fail because the import process was stopped before completion; - hopefully made the error message less scary, also included table number for easier cleanup. Closes https://broadworkbench.atlassian.net/browse/VS-267",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7680:203,message,message,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7680,1,['message'],['message']
Integrability,- restore job stats collection to create_ranges_cohort_extract_data_table.py; - add writing of cost info to BigQuery table to create_ranges_cohort_extract_data_table.py and populate_alt_allele_table.py; - add task to GvsQuickstartIntegration.wdl that checks that expected cost data was written to BigQuery table; - tweaked schema for cost_observability table to include descriptions; ; Integration test run: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/30a2d8ee-13dd-4829-b3a8-4e6a67409705; Closes https://broadworkbench.atlassian.net/browse/VS-480,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7915:386,Integrat,Integration,386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7915,1,['Integrat'],['Integration']
Integrability,"- updated integration test (removed that argument so it defaults to the same thing); - tested that using ""NONE"" as an argument works",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7206:10,integrat,integration,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7206,1,['integrat'],['integration']
Integrability,"- uses GvsExtractCohortFromSampleNames.wdl to generate VCFs for calculating P & S all in one WDL; - allows for use of an interval_list in P & S; - updates to docs; - Successful run here: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/2537ea7b-f635-4609-8fbb-7eaec41a6df8; - integration run, since I touched the bulk ingest and extract VCF WDLs: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f71941ba-f02f-4472-a04c-aedff24fdd14",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8707:316,integrat,integration,316,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8707,1,['integrat'],['integration']
Integrability,"-------------------------------. a) GATK version used. _The Genome Analysis Toolkit (GATK) v4.1.4.1_. b) Exact GATK commands used. _/usr/bin/time -v gatk --java-options ""-Xmx10G"" Mutect2 -R ../reference/indices\_010920/GRCh38.d1.vd1.fa -L chr4.bed -I chr4.bam --max-mnp-distance 0 --interval-padding 100 -O chr4.vcf.gz_. c) The entire error log if applicable. _java.lang.IllegalArgumentException: Need one or two reads to construct a fragment_ ; _at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:725)_ ; _at org.broadinstitute.hellbender.utils.read.Fragment.create(Fragment.java:43)_ ; _at org.broadinstitute.hellbender.utils.read.Fragment.createAndAvoidFailure(Fragment.java:58)_ ; _at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)_ ; _at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1376)_ ; _at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)_ ; _at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)_ ; _at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)_ ; _at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)_ ; _at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)_ ; _at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.groupEvidence(AlleleLikelihoods.java:589)_ ; _at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:93)_ ; _at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:251)_ ; _at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:320)_ ; _at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308)_ ; _at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:281)_ ; _at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048)_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6419:1622,wrap,wrapAndCopyInto,1622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6419,1,['wrap'],['wrapAndCopyInto']
Integrability,"----. ## Bug Report. ### Affected tool(s) or class(es); Mutect2, Haplotypecaller. ### Affected version(s); 4.1.0. ### Description ; It is not an actual accuracy bug but I wanted to share it with you in case you are not aware of it. If you look at BaseGraph.java. There are 4 places that you use ""Collectors.toSet()"". This converts a stream to an unordered set. The final order is dependant on the memory address that each element occupies so the order of result unordered set is not deterministic and can differ from run to run. . This behavior is not problematic as long as we do not traverse the set in order. But let's look at MergeDiamonds.java as an example; ` final Set<SeqVertex> middles = getGraph().outgoingVerticesOf(top);; `; ` for ( final SeqVertex mi : middles ) {; `; First, we make unordered set ""middles"" and then traverse it. Merging diamonds is actually really sensitive which diamond you merge first and can result in different graphs if you change the order. This was not that important before but it seems that with the new chain pruning functionality that you put in mutect2. Sensitivity went up. and now we can actually see different results every time we run the mutect2. I was wondering if it makes sense to change this? The way that we fixed it for ourselves was to change it to linkedHashSet to preserve the order. _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6003:380,depend,dependant,380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6003,1,['depend'],['dependant']
Integrability,--|; | [...ender/tools/walkers/annotator/StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `94.737% <Ã¸> (Ã¸)` | `8 <0> (Ã¸)` | :arrow_down: |; | [...s/annotator/allelespecific/AS\_StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `80% <Ã¸> (Ã¸)` | `4 <0> (Ã¸)` | :arrow_down: |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | [...titute/hellbender/engine/TwoPassVariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVHdvUGFzc1ZhcmlhbnRXYWxrZXIuamF2YQ==) | `69.231% <0%> (-26.007%)` | `6% <0%> (+2%)` | |; | [...itute/hellbender/utils/runtime/ScriptExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961:1934,Integrat,IntegrationUtils,1934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961,1,['Integrat'],['IntegrationUtils']
Integrability,-00004__CG0000-1789.GMKF2.cram:23488102400+33554432; 19/02/01 21:28:28 ERROR Executor: Exception in task 698.0 in stage 5.0 (TID 4403); **java.lang.IllegalArgumentException: provided start is negative: -24**; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5647:2058,Wrap,Wrappers,2058,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5647,1,['Wrap'],['Wrappers']
Integrability,-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); [2018-04-15T03:55Z] ip-10-0-0-57: 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1038); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1029); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:969); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1029); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:760); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.rdd.MapPartiti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661:4145,Wrap,Wrappers,4145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661,1,['Wrap'],['Wrappers']
Integrability,"-Converted the core of the hellbender codebase to use common interfaces; (GATKRead and MutableGATKRead) for working with reads, whether they; happen to be SAMRecords or Google model reads. -Wrote necessary coders, etc., to allow the new interface types to work with; Google dataflow, and ported the dataflow portion of the codebase to use them. -Picard tools and utilities were not converted, as they proved too tricky; to adjust to the new semantics of the GATKRead interface.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/601:61,interface,interfaces,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/601,3,['interface'],"['interface', 'interfaces']"
Integrability,-ERC BP_RESOLUTION mode in HaplotypeCaller needs an integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6833:52,integrat,integration,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6833,1,['integrat'],['integration']
Integrability,"-Hooked up a new PositionalDownsampler to AssemblyRegionWalker controlled; via an argument --maxReadsPerAlignmentStart (tool sets the default value). -As a side effect, exposed the ""assigned"" position of a read in the; GATKRead interface. This lets us query the nominal positions of unmapped; reads that have been assigned a position for sorting purposes. -As a second side effect, modified ReadCoordinateComparator to sort; unmapped reads with positions in the correct bam/sam file order. Resolves #1642; Resolves #1911",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1972:228,interface,interface,228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1972,1,['interface'],['interface']
Integrability,"-Published a jbwa snapshot to the Broad artifactory, which we now depend on; via gradle. This snapshot contains builds of the native jbwa code for both; Mac and Linux. -Added utility methods to NativeUtils to load this library at runtime,; and a test proving that it can be loaded successfully. Also switched; to the new NativeUtils methods for loading the PairHMM, and confirmed; that it loads successfully with the HaplotypeCaller in protected. -Included a gradle script to publish a new jbwa snapshot, should it; become necessary, along with instructions on how to do so. Resolves #1838",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1847:66,depend,depend,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1847,1,['depend'],['depend']
Integrability,"-ReferenceContext and FeatureContext are now guaranteed to be non-null in ReadWalker.apply(),; and simply return empty Collections/iterators when there is no backing data source (previously,; these were wrapped in Optional objects, and would be Optional.empty() if there was no source; of reference and/or Feature data). This spares tool authors from having to explicitly check for the existence of reference/Feature; contextual data before using it. -For tools that care about the distinction between the ""no data source"" case and the ""no records; overlapping the current interval"" case, there is now a hasBackingDataSource() method in both; ReferenceContext and FeatureContext. Requested by Valentin!. Resolves #244",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/249:203,wrap,wrapped,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/249,1,['wrap'],['wrapped']
Integrability,"-Require that the reference dictionary be a superset of the reads dictionary; only when there is at least one CRAM input. -When determining whether a superset relationship exists, do not take extended; attributes (like the sequence MD5) into account; only consider the contig names; and lengths. -Do not require common contigs to occur at the same absolute indices across; dictionaries (but do require that they occur in the same relative order).; Contig indices were an issue for GATK3, but since hellbender relies on contig; names for queries we can afford to disable this annoying check. If we later find; that we need to turn it back on, we can easily do so. -Updated tests appropriately:; -Added test cases showing that extended attributes are ignored when checking; for a superset. ```; -Added test cases for various combinations of the new boolean options; requireSuperset and checkContigIndices. -The existing integration test CRAMSupportIntegrationTest.testWrongRef(); shows that we throw when a CRAM is provided as input with a reference; that does not contain all of its contigs.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/877:918,integrat,integration,918,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877,1,['integrat'],['integration']
Integrability,"-We've decided to develop SimpleInterval in hellbender for now so that we don't; have to deal with the tricky politics of standardization across htsjdk (though; we will eventually address this when we're ready). -Locatable interface remains in htsjdk, so a small victory there. -Added overlaps()/contains()/size() methods to SimpleInterval. -Removed support for zero-length intervals for now, since none of our current; query interfaces support it, and it complicates basic interval operations.; Will open a ticket to investigate whether support for zero-length intervals; will be needed given GA4GH query interfaces, future representation of; insertions, etc. Resolves #305",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/316:223,interface,interface,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/316,3,['interface'],"['interface', 'interfaces']"
Integrability,"-Will now look for both shadow and spark jars in the same directory; as the gatk-launch script, and use them if found. Also checks; BIN_PATH for jars. -Environment variable overrides GATK_SHADOW_JAR and GATK_SPARK_JAR; take precedence over everything. -Wrapper script is used if found and GATK_SHADOW_JAR is not set. Resolves #1693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2090:253,Wrap,Wrapper,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2090,1,['Wrap'],['Wrapper']
Integrability,"-listing-perl libfile-mimeinfo-perl libfile-stripnondeterminism-perl; libfont-afm-perl libfontenc1 libgcc-5-dev libgdbm3 libgettextpo-dev; libgettextpo0 libgfortran-5-dev libgfortran3 libgomp1 libhtml-form-perl; libhtml-format-perl libhtml-parser-perl libhtml-tagset-perl; libhtml-tree-perl libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl; libhttp-message-perl libhttp-negotiate-perl libio-html-perl; libio-socket-ssl-perl libipc-system-simple-perl libisc-export160 libisl15; libitm1 libjpeg-dev libjpeg-turbo8-dev libjpeg8-dev liblapack-dev liblapack3; liblsan0 liblwp-mediatypes-perl liblwp-protocol-https-perl liblzma-dev; libmail-sendmail-perl libmailtools-perl libmnl0 libmpc3 libmpfr4 libmpx0; libncurses5-dev libnet-dbus-perl libnet-http-perl libnet-smtp-ssl-perl; libnet-ssleay-perl libpaper-utils libpaper1 libpcre16-3 libpcre3-dev; libpcre32-3 libpcrecpp0v5 libperl5.22 libpipeline1 libpng12-dev libquadmath0; libreadline-dev libreadline6-dev libsigsegv2 libstdc++-5-dev; libsys-hostname-long-perl libtcl8.6 libtext-iconv-perl libtie-ixhash-perl; libtimedate-perl libtinfo-dev libtk8.6 libtsan0 libubsan0 libunistring0; liburi-perl libwww-perl libwww-robotrules-perl libx11-protocol-perl libxaw7; libxcb-shape0 libxft2 libxml-parser-perl libxml-twig-perl; libxml-xpathengine-perl libxmu6 libxmuu1 libxpm4 libxss1 libxtables11 libxv1; libxxf86dga1 linux-libc-dev m4 make man-db manpages manpages-dev netbase; patch perl perl-modules-5.22 po-debconf python-pkg-resources python-scour; python-six r-base-core r-base-dev r-doc-html rename tzdata x11-utils; x11-xserver-utils xdg-utils zip zlib1g-dev```. -Not sure if moving the R install to the conda environment (which is not in the base image) will increase Travis time, but it doesn't appear to from the limited number of builds that have run so far. At some point we may want to move conda into the base image. However, I think that this would require that the base be rebuilt with every python code change, which is not optimal.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954:3144,protocol,protocol-perl,3144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954,1,['protocol'],['protocol-perl']
Integrability,. ```; org.broadinstitute.hellbender.exceptions.GATKException: Unable to query the database for geneName: null; 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.cosmic.CosmicFuncotationFactory.createFuncotations(CosmicFuncotationFactory.java:244); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:404); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:316); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4413:1186,wrap,wrapAndCopyInto,1186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4413,1,['wrap'],['wrapAndCopyInto']
Integrability,"..... . 12:38:08.377 INFO KnownSitesCache - Number of variants read: 60200001; 12:38:09.341 INFO KnownSitesCache - Number of variants read: 60300001; 12:38:10.131 INFO KnownSitesCache - Number of variants read: 60400001; 12:38:10.940 INFO KnownSitesCache - Number of variants read: 60500001; 12:38:11.719 INFO KnownSitesCache - Number of variants read: 60600001; 12:38:12.568 INFO KnownSitesCache - Number of variants read: 60700001; 12:38:13.432 INFO KnownSitesCache - Number of variants read: 60800001; 12:38:14.137 INFO KnownSitesCache - Number of variants read: 60900001; 12:38:14.833 INFO KnownSitesCache - Number of variants read: 61000001; 12:39:23.200 INFO BaseRecalibrationEngine - The covariates being used here: ; 12:39:23.200 INFO BaseRecalibrationEngine - 	ReadGroupCovariate; ```; Based on the time stamps, the observation is that it took 10 min to read the KnowSites.vcf file (about 10GB), for the code which is a filtering and copy operation:. ```java; private static List<GATKVariant> wrapQueryResults(final Iterator<VariantContext> queryResults ) {; final List<GATKVariant> wrappedResults = new ArrayList<>();; long count = 0;; while ( queryResults.hasNext() ) {; if (count++ % 100000 == 0) {; log.info(""Number of variants read: "" + count);; }; wrappedResults.add(VariantContextVariantAdapter.sparkVariantAdapter(queryResults.next()));; }; return wrappedResults;; }. ```; Seems to me this is awfully slow. The vcf file resides on HDFS (with a 100Gbps switch and backed up by a NVMe storage with over 1GBps bandwidth). Assuming we can achieve a persistent 100MBps bandwidth (which IMO is quite modest), it would take 100 sec to fetch the file. Added the overhead, it should take only 2 to 3 minutes to finish this process. If it turns out that IO performance cannot be improved, I have the impression that knownSites file is relatively stable. Would it make sense to convert the KnownSites into an intermediate format which can be read much faster? Or smaller than the 2GB threshold?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4264:1749,wrap,wrapQueryResults,1749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4264,4,['wrap'],"['wrapQueryResults', 'wrappedResults']"
Integrability,"...I didn't run the spark version for quite some time, and it might also depend on the size of the BAM file being processed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6578#issuecomment-621277739:73,depend,depend,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6578#issuecomment-621277739,1,['depend'],['depend']
Integrability,"...because it does the following:; - makes it appear no variants were left-aligned when in fact many were left-aligned. ; - In addition, because the tool emits an INFO message for sites that it skips (due to reference allele being too long), it appears doubly confusing as if the tool skips sites that could use left-alignment and only these types of skipped sites are present.; - Finally, for my file, it drops 66,568 variant sites (I did not check alleles) for me silently and without any warning. ## Two suggestions for improvement for LeftAlign's stdout:; 1. A count of variants/sites that were left-aligned OR at least NOT the confusing `0 variants were aligned` message.; 2. The length of the longest reference allele that the tool skipped.; 3. At least the number if not the sites of dropped variant records. My workaround in the meanwhile: I had to `md5` headerless VCFs to confirm the input is different from the output of the tool. . ---; ## Here's how I came to the above; Quick note because I use GATK3.7's LeftAlignAndTrimVariants below. I am using LeftAlignAndTrimVariants from GATK3.7. ### Command; I am using a grch37-->grch38 liftedover (via Picard) VCF as input. It would be more ideal if Picard LiftoverVcf would left-align variants but we cannot have everything we want when we want it. So here I am asking for a better LeftAlign. The output file is for use with GATK4-Mutect2. ```; java -jar $GATK -T LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V zeta_af-only-gnomad_Hg19toGRCh38.vcf.gz -o eta_af-only-gnomad_Hg19toGRCh38.vcf.gz; ```. ### Portions of stdout; ```; INFO 17:39:56,364 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 17:39:56,365 HelpFormatter - The Genome Analysis Toolkit (GATK) v3.7-0-gcfedb67, Compiled 2016/12/12 11:21:18 ; INFO 17:39:56,366 HelpFormatter - Copyright (c) 2010-2016 The Broad Institute ; INFO 17:39:56,366 HelpFormatter - For support and documentation go",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487:168,message,message,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487,2,['message'],['message']
Integrability,..llbender/tools/genomicsdb/GenomicsDBConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJDb25zdGFudHMuamF2YQ==) | `0% <0%> (Ã¸)` | `0% <0%> (Ã¸)` | :arrow_down: |; | [...r/tools/walkers/annotator/ClippingRankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9DbGlwcGluZ1JhbmtTdW1UZXN0LmphdmE=) | `100% <0%> (Ã¸)` | `4% <0%> (Ã¸)` | :arrow_down: |; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `77.027% <0%> (+0.676%)` | `33% <0%> (+1%)` | :arrow_up: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `69.485% <0%> (+0.825%)` | `61% <0%> (+1%)` | :arrow_up: |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `0.862% <0%> (+0.862%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `73.118% <0%> (+1.075%)` | `25% <0%> (Ã¸)` | :arrow_down: |; | ... and [588 more](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4970#issuecomment-401503431:3926,Integrat,IntegrationTestSpec,3926,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4970#issuecomment-401503431,1,['Integrat'],['IntegrationTestSpec']
Integrability,".8 MB, free: 42.5 GB); 2019-02-17 16:25:49 WARN TaskSetManager:66 - Lost task 186.0 in stage 5.0 (TID 1121, scc-q03.scc.bu.edu, executor 9): java.lang.IllegalArgumentException: provided start is negative: -5; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:18595,Wrap,Wrappers,18595,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['Wrap'],['Wrappers']
Integrability,".9 MB, free: 42.5 GB); 2019-02-17 16:25:48 WARN TaskSetManager:66 - Lost task 179.0 in stage 5.0 (TID 1108, scc-q03.scc.bu.edu, executor 9): java.lang.IllegalArgumentException: provided start is negative: -2; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:11435,Wrap,Wrappers,11435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['Wrap'],['Wrappers']
Integrability,".; # Ensuring the correct environment for canonical (or otherwise reasonable) usage of our standard Docker takes precedence over edge cases.; # If you break the environment, you are responsible for fixing it and also owe the last developer who left this in a reasonable state a beverage of their choice.; # (This may be yourself, and you'll appreciate that beverage while you tinker with dependencies!); #; # When changing dependencies or versions in this file, check to see if the ""supportedPythonPackages"" DataProvider; # used by the testGATKPythonEnvironmentPackagePresent test in PythonEnvironmentIntegrationTest needs to be updated; # to reflect the changes.; #; name: gatk; channels:; # if channels other than conda-forge are added and the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled(",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:1434,depend,dependencies,1434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,1,['depend'],['dependencies']
Integrability,".Main.main(Main.java:292); ```. ## Cases when the error does not occur; * If I rename `test a` folder in `test-a` as previously said.; * If I copy my current `test a` in the `/tmp/` directory (`/tmp/test a/`). This may suggest that the path length plays a role.; * If I renamed the VCF files (first VCF becomes `a.vcf.gz`, second `b.vcf.gz`) (`gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O out.vcf.gz`).; * If I rename the first VCF file with as many `a` character as characters found in the original filename. (aaaaaaaaaaaaaaaaaa.vcf.gz).; * If I rename the first VCF by replacing all alphabetical character with a (aaaa_aaaa2.aa_a7_1.vcf.gz); * If I introduce random `_` in the file name (aaaa_aaa_aaaa_aaaa.vcf.gz).; * If I rename the first VCF file by removing the first character (`cerc_prod2.SM_V7_1.vcf.gz` -> `erc_prod2.SM_V7_1.vcf.gz`); * If I rename the first VCF file by introducing a letter at the beginning (`cerc_prod2.SM_V7_1.vcf.gz` -> `ccerc_prod2.SM_V7_1.vcf.gz`). It really seems that the combination of the path lengh, white space and particular filename triggers this. I cannot get my head around this. I don't think this is coming from the content of the VCF as it works well in some cases. Let me know if you need me to make other tests. Fred. ----. ## Update. I investigated a little further after thinking about the tests I did. Because modifying the VCF filename did not trigger the issue and because of the presence of `tabix` related modules in the traces, I decided to see if removing `tbi` file will avoid having the error message. And it did!. After recreating the `tbi` file (`tabix data/calling/cerc_prod2.SM_V7_1.vcf.gz`), the error message appeared again. So it does not seem related to malformed index file. However, index file seems part of the problem. After renaming `test a` folder in `test-a` with the old or new index file, I did not get any error (as usual). Here is my tabix version in case:; ```bash; $ tabix -h. Version: 1.10.2; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241:8630,message,message,8630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241,2,['message'],['message']
Integrability,.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180:7206,protocol,protocol,7206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180,1,['protocol'],['protocol']
Integrability,.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:558) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.checkFilter(FuncotationFilter.java:49) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$null$0(FilterFuncotations.java:194) ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:176) ; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$null$1(FilterFuncotations.java:196) ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:4350,wrap,wrapAndCopyInto,4350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['wrap'],['wrapAndCopyInto']
Integrability,".com/protocolbuffers/protobuf/commit/8a60b6527a976cfd0028153da3ad8e4ed280e0de""><code>8a60b65</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.23.4...v3.25.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ign",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:2800,Depend,Dependabot,2800,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,1,['Depend'],['Dependabot']
Integrability,.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.he,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:2535,Wrap,Wrappers,2535,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,3,['Wrap'],['Wrappers']
Integrability,".executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:50 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 4, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:50 WARN TaskSetManager:66 - Lost task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:26944,Wrap,Wrappers,26944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,".java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 5.0 failed 1 times, most recent failure: Lost task 1.0 in stage 5.0 (TID 12, localhost, executor driver): java.util.ConcurrentModificationException; 	at java.util.ArrayList.sort(ArrayList.java:1464); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.re",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:7173,Message,MessageHubBackedObjectConnection,7173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,".java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:5482,Message,MessageHubBackedObjectConnection,5482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); at com.sun.proxy.$Proxy2.stop(Unknown Source); at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360); at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: htsjdk.tribble.TribbleException: Exception encountered in worker thread.; at htsjdk.tribble.readers.AsynchronousLineReader.checkAndThrowIfWorkerException(AsynchronousLineReader.java:61); at htsjdk.tribble.readers.AsynchronousLineReader.readLine(AsynchronousLineReader.java:43); at htsjdk.tribble.readers.LineIteratorImpl.advance(LineIteratorImpl.java:24); at htsjdk.tribble.readers.LineIteratorImpl.advance(LineIteratorImpl.java:11); at htsjdk.samtools.util.AbstractIterator.hasNext(AbstractIterator.java:44); at htsjdk.tribble.AsciiFeatureCodec.isDone(AsciiFe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:4135,Message,MessageHub,4135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,1,['Message'],['MessageHub']
Integrability,.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:436); 2019-01-04T14:02:27.236174900Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:120); 2019-01-04T14:02:27.236322702Z 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); 2019-01-04T14:02:27.237171464Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-01-04T14:02:27.237239651Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-01-04T14:02:27.237250455Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-01-04T14:02:27.237256726Z 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 2019-01-04T14:02:27.237294098Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-01-04T14:02:27.237302853Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-01-04T14:02:27.237308231Z 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 2019-01-04T14:02:27.237342232Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 2019-01-04T14:02:27.237377382Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-01-04T14:02:27.237384696Z 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 2019-01-04T14:02:27.237442143Z 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverseVariants(TwoPassVariantWalker.java:74); 2019-01-04T14:02:27.237452377Z 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverse(TwoPassVariantWalker.java:27); 2019-01-04T14:02:27.237457367Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 2019-01-04T14:02:27.237461597Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 2019-01-04T14:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451464446:2923,wrap,wrapAndCopyInto,2923,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451464446,1,['wrap'],['wrapAndCopyInto']
Integrability,.open(DistributedFileSystem.java:312); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.seqdoop.hadoop_bam.util.SAMHeaderReader.readSAMHeaderFrom(SAMHeaderReader.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:235); 	... 15 more; Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at org.apache.hadoop.ipc.Client.call(Client.java:1475); 	at org.apache.hadoop.ipc.Client.call(Client.java:1412); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoke,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:9109,protocol,protocolPB,9109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocolPB']
Integrability,".samuel.k@gmail.com>; Date: Fri Dec 8 00:55:14 2017 -0500. updated somatic PoNs for PreprocessIntervals drop Ns. commit cff64984d9fb42364001bda4c73d54cf68d85a5c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 00:37:24 2017 -0500. sudo travis yml. commit 89025941febd2089d426cfa1e0f0aa6a6712e2a9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 00:23:22 2017 -0500. travis/Docker config update (g++-6, Miniconda3); python test group assignment. commit 31f96398106c2b8577b8c25d110abea3ebe7f836; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:44:53 2017 -0500. WDL test bugfix. commit 9b2fb820536ec355bea0256471bd093d547f5c99; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:20:36 2017 -0500. update WDL test JSON files. commit e3d97644d1a2c40a5c364a96f8b67246154179c9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:18:14 2017 -0500. assertions in inference task base; removed a ASCII > 128 character in log messages. commit 526cf92e623a3bbd5f9d375132b6ca046fc47620; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:03:04 2017 -0500. redirect tqdm progress bar to python logger. commit 2e45bd30968b921fae225de3901fb97ece690b0c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 19:45:49 2017 -0500. more arg related fixes. commit bb89a3bb338d88199881e8aca65f656f2acd7c0a; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 19:41:20 2017 -0500. arg related bugfixes in WDL, python, and java CLIs. commit 23569787ee2c8cc6c9227a44170cbbd02fe4427f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 17:21:05 2017 -0500. fixed issue with python boolean argparse (they use weird semantics). commit ae841c9ed4cd9b2ca1ac0e9082d175ff8ea98298; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 16:44:02 2017 -0500. shorter gCNV WDL tests. commit 5466b806e36df16cad2d045be074e7f",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:4813,message,messages,4813,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,1,['message'],['messages']
Integrability,.utils.recalibration.BaseRecalibrationEngine.calculateSkipArray(BaseRecalibrationEngine.java:324); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:139); at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:185); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.m,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807#issuecomment-691600264:4038,wrap,wrapAndCopyInto,4038,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807#issuecomment-691600264,1,['wrap'],['wrapAndCopyInto']
Integrability,"/05/05 06:03:53 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool ; 17/05/05 06:03:53 INFO DAGScheduler: ResultStage 2 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:202) finished in 10.796 s; 17/05/05 06:03:53 INFO DAGScheduler: Job 1 finished: saveAsNewAPIHadoopFile at ReadsSparkSink.java:202, took 17.010114 s; 17/05/05 06:03:53 INFO SparkUI: Stopped Spark web UI at http://172.30.0.122:35794; 17/05/05 06:03:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/05/05 06:03:53 INFO MemoryStore: MemoryStore cleared; 17/05/05 06:03:53 INFO BlockManager: BlockManager stopped; 17/05/05 06:03:53 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/05/05 06:03:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/05/05 06:03:53 INFO SparkContext: Successfully stopped SparkContext; [May 5, 2017 6:03:53 AM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=799080448; 17/05/05 06:03:53 INFO ApplicationMaster: Final app status: FAILED, exitCode: 16, (reason: Shutdown hook called before final status was reported.); 17/05/05 06:03:53 INFO ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: Shutdown hook called before final status was reported.); 17/05/05 06:03:53 INFO ApplicationMaster: Deleting staging directory hdfs://ip-172-30-0-86.ec2.internal:8020/user/hadoop/.sparkStaging/application_1493961816416_0002; 17/05/05 06:03:53 INFO ShutdownHookManager: Shutdown hook called; 17/05/05 06:03:53 INFO ShutdownHookManager: Deleting directory /mnt1/yarn/usercache/hadoop/appcache/application_1493961816416_0002/spark-23bc1c26-8133-475d-8418-1def58e976fd; 17/05/05 06:03:53 INFO ShutdownHookManager: Deleting directory /mnt/yarn/usercache/hadoop/appcache/application_1493961816416_0002/spark-edb79d30-a7d3-4ed2-ad61-2dc8ea95c5b1; ```. Thanks in helping me solve this issue!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2666:4550,message,message,4550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2666,1,['message'],['message']
Integrability,"/7,(-A<<=B?A*9:(-2.<<=:@;C-)76?C8<MC:Z:45S106MMD:Z:24PG:Z:MarkDuplicates.1FRG:Z:HK35M.3NM:i:0MQ:i:37OQ:Z:,AFAFKKKFKKAAF<; A,7AKAFK,,7,AF,77FFF<A,7AKKK,,FFKKKFFFKKKK7,F<,,,,,77,,,FAFFAFK,A7(,7,A<AAAFF,,77FK7F###################################################UQ:i; :0AS:i:24. at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:91); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:246); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:493); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1326(HaplotypeCallerSpark.java:223); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:213); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866); at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926); at org.apache.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149:2259,Wrap,WrappingSpliterator,2259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149,1,['Wrap'],['WrappingSpliterator']
Integrability,/broadinstitute/gatk/jobs/317870153) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.6/tests/test/index.html) |; | integration | oraclejdk8 | [29990.12](https://travis-ci.com/broadinstitute/gatk/jobs/317870159) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.12/tests/test/index.html) |; | python | openjdk8 | [29990.5](https://travis-ci.com/broadinstitute/gatk/jobs/317870152) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.5/tests/test/index.html) |; | cloud | openjdk8 | [29990.1](https://travis-ci.com/broadinstitute/gatk/jobs/317870147) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.1/tests/test/index.html) |; | cloud | openjdk11 | [29990.15](https://travis-ci.com/broadinstitute/gatk/jobs/317870162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.15/tests/test/index.html) |; | integration | openjdk11 | [29990.13](https://travis-ci.com/broadinstitute/gatk/jobs/317870160) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.13/tests/test/index.html) |; | integration | openjdk8 | [29990.2](https://travis-ci.com/broadinstitute/gatk/jobs/317870149) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.2/tests/test/index.html) |; | unit | openjdk11 | [29990.14](https://travis-ci.com/broadinstitute/gatk/jobs/317870161) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29990.4](https://travis-ci.com/broadinstitute/gatk/jobs/317870151) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.4/tests/test/index.html) |; | unit | openjdk8 | [29990.3](https://travis-ci.com/broadinstitute/gatk/jobs/317870150) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/mast,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629:1253,integrat,integration,1253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629,1,['integrat'],['integration']
Integrability,/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:29138,integrat,integration,29138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['integrat'],['integration']
Integrability,"/github.com/broadinstitute/gatk-protected/issues/914#issuecomment-280820307). @yfarjoun, thanks for your comments. On the first two points, I agree. Let me clarify: I was going to use the bait-length and insert-length as _hyperparameters_ of the pdf, where the pdf itself gives the probability of having an insert in a certain configuration relative to the bait. I think the parametrization you proposed, i.e. the distance between nearest ends of insert and bait, is very reasonable since the PDF is going to be reflection-symmetric once averaged over all baits; and you're right, the bait length is constant (77bp for ICE) so we can drop it from the analysis. If the fragment capture efficiency is insensitive to the relative position of the bait sequence in the fragment, we expect the pdf to be approximately uniform (save for boundary effects at the scale of bait length), with the 0.5 x (insert length - bait length) setting the upper bound of the distribution. However, some dependency on the position of the bait is expected: e.g. if the bait sequence is on the dangling end of a fragment, it is less likely to stay bound than if it is in the middle of the fragment. I'm curious to see what comes out (who knows -- maybe another 6-bp periodicity!). Regarding GC bias -- I agree with what you said; I guess I had a different point, though. To find the GC curve, one needs to regress the _coverage depth_ wrt. the _GC content_ in some way. Now, all we have is a collection of baits, along with the number of inserts pulled by each bait (let's call it the bait pileup). So, we have to designate a measure of _GC content_ to each bait pileup in order to regress the pileup size against it. A reasonable choice is to use the expected value of the GC content of the pulled fragments for each bait:. effective GC of a bait = \sum_{all inserts} GC(insert) x Pr(insert) x Pr(insert is pulled by bait). Alternatively, we can calculate the average GC content of each bait pileup, for each sample, as we ca",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2947:7048,depend,dependency,7048,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2947,1,['depend'],['dependency']
Integrability,"/imkl/2020.1.217/mkl/lib/intel64']; define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]; include_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/include', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib']; blas_opt_info:; libraries = ['mkl_rt', 'pthread']; library_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib/intel64']; define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]; include_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/include', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib']; lapack_mkl_info:; libraries = ['mkl_rt', 'pthread']; library_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib/intel64']; define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]; include_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/include', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib']; lapack_opt_info:; libraries = ['mkl_rt', 'pthread']; library_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib/intel64']; define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]; include_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/include', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib']. -----. Is it possible to have an up-to-date dependency list for me to have a functional gcnvkernel module?. Thanks for your help,. HÃ©lÃ¨ne",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8387:8272,depend,dependency,8272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8387,1,['depend'],['dependency']
Integrability,"/native/HDF5-prefix/src/HDF5/src/H5Fio.c line 120 in H5F_block_read(; ): read through metadata accumulator failed; major: Low-level I/O; minor: Read failed; #009: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Faccum.c line 263 in H5F__accum_r; ead(): driver read request failed; major: Low-level I/O; minor: Read failed; #010: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5FDint.c line 204 in H5FD_read(): ; driver read request failed; major: Virtual File Layer; minor: Read failed; #011: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5FDsec2.c line 725 in H5FD_sec2_re; ad(): file read failed: time = Wed Apr 14 11:52:33 2021; , filename = '/SCRATCH-BIRD/users/lindenbaum-p/work/NEXTFLOW/20210411.GRCh37.gatkcnv.brs/work/92/579e5a48aa9e52cd0; e1df603266809/B00HOTD.counts.hdf5', file descriptor = 250, errno = 121, error message = 'Remote I/O error', buf = ; 0x2b6ebddf38e8, total read size = 384, bytes this sub-read = 384, bytes actually read = 18446744073709551615, offs; et = 712120; major: Low-level I/O; minor: Read failed; HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5D.c line 826 in H5Dvlen_reclaim(); : invalid dataspace; major: Invalid arguments to routine; minor: Inappropriate type; 11:52:33.796 INFO GermlineCNVCaller - Shutting down engine; [April 14, 2021 11:52:33 AM CEST] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed t; ime: 0.90 minutes.; Runtime.totalMemory()=2374500352; Exception in thread ""main"" java.lang.InternalError: H5DreadVL_str: failed to read variable length strings; 	at ncsa.hdf.hdf5lib.H5.H5DreadVL(Native Method); 	at org.broadinstitute.hdf5.HDF5File.lambda$readStringArray$0(HDF5File.java:161); 	at org.broadinstitute.hdf5.HDF5File.readDataset(HDF5File.java:349); 	at org.broadinstitute.hdf5.HDF5File.readStringArray(HDF5File.java:150); 	at org.broadinstitute.hel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7202:3031,message,message,3031,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7202,1,['message'],['message']
Integrability,/spark/sv/evidence/BreakpointDensityFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9CcmVha3BvaW50RGVuc2l0eUZpbHRlci5qYXZh) | `97.183% <100%> (Ã¸)` | `27 <0> (Ã¸)` | :arrow_down: |; | [...ute/hellbender/tools/spark/utils/IntHistogram.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay91dGlscy9JbnRIaXN0b2dyYW0uamF2YQ==) | `91.2% <100%> (+0.291%)` | `19 <0> (Ã¸)` | :arrow_down: |; | [...spark/sv/evidence/BreakpointDensityFilterTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9CcmVha3BvaW50RGVuc2l0eUZpbHRlclRlc3QuamF2YQ==) | `100% <100%> (Ã¸)` | `17 <0> (Ã¸)` | :arrow_down: |; | [...te/hellbender/tools/spark/sv/utils/SVInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkludGVydmFsLmphdmE=) | `89.362% <100%> (+6.383%)` | `33 <1> (+1)` | :arrow_up: |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `94.118% <100%> (+1.81%)` | `1 <1> (Ã¸)` | :arrow_down: |; | [...er/tools/spark/sv/evidence/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `78.86% <57.303%> (-2.985%)` | `20 <4> (+8)` | |; | ... and [40 more](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-395889530:3554,integrat,integration,3554,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-395889530,1,['integrat'],['integration']
Integrability,"/xx.xx.xx.xx:4040; 18/04/24 17:42:02 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/24 17:42:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/24 17:42:02 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/gatk-package-4.0.3.0-spark.jar, byteCount=138618122, body=FileSegmentManagedBuffer{file=/scratch/home/int/eva/username/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-spark.jar, offset=0, length=138618122}} to /xx.xx.xx.25:57139; closing connection; java.io.IOException: Connection reset by peer; at sun.nio.ch.FileChannelImpl.transferTo0(Native Method); at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428); at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493); at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608); at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139); at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121); at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287); at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237); at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314); at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802); at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319); at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637); at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566); at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442); at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(Defaul",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:37235,Message,MessageWithHeader,37235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Message'],['MessageWithHeader']
Integrability,0 + 6 java.net.Inet6AddressImpl.lookupAllHostAddr; 0.0% 0 + 6 java.util.zip.Deflater.deflateBytes; 0.0% 6 + 0 org.apache.spark.util.collection.TimSort.sort; 0.0% 5 + 0 org.apache.spark.util.collection.TimSort$SortState.mergeHi; 0.0% 0 + 4 java.net.SocketInputStream.socketRead0; 0.0% 4 + 0 org.apache.spark.util.collection.ExternalSorter.insertAll; 0.0% 4 + 0 org.apache.spark.util.collection.TimSort$SortState.mergeLo; 0.0% 2 + 0 com.twitter.chill.ScalaCollectionsRegistrar.apply; 0.0% 0 + 1 java.net.PlainSocketImpl.socketAvailable; 0.0% 0 + 1 java.lang.Class.getDeclaredMethods0; 0.0% 0 + 1 java.io.FileOutputStream.writeBytes; 0.0% 1 + 0 java.nio.HeapCharBuffer.<init>; 0.0% 1 + 0 java.nio.HeapIntBuffer.<init>; 0.0% 1 + 0 org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto.newBuilder; 0.0% 1 + 0 java.util.IdentityHashMap$Values.size; 0.0% 1 + 0 org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.<clinit>; 0.0% 1 + 0 org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto.<clinit>; 0.0% 1 + 0 org.bdgenomics.adam.models.SingleReadBucketSerializer.<init>; 0.0% 1 + 0 java.util.regex.Pattern$Branch.<init>; 0.0% 1 + 0 hbparquet.hadoop.util.ContextUtil.getConfiguration; 0.0% 1 + 0 sun.reflect.generics.visitor.Reifier.reifyTypeArguments; 0.0% 1 + 0 scala.collection.immutable.Map$Map3.<init>; 0.0% 1 + 0 sun.reflect.ByteVectorImpl.trim; 0.6% 62 + 27 Total interpreted (including elided). Compiled + native Method ; 9.5% 1441 + 0 com.ning.compress.lzf.impl.UnsafeChunkEncoderLE.tryCompress; 2.0% 304 + 0 htsjdk.samtools.util.BlockCompressedOutputStream.write; 1.8% 275 + 0 com.ning.compress.lzf.impl.UnsafeChunkDecoder.decodeChunk; 1.2% 176 + 2 htsjdk.samtools.BinaryTagCodec.readTags; 1.2% 176 + 0 org.broadinstitute.hellbender.relocated.com.google.common.collect.Multimaps.index; 1.1% 174 + 1 htsjdk.samtools.SAMUtils.bytesToCompressedBases; 0.6% 82 + 2 htsjdk.samtools.BAMRecordCodec.encode; 0.5% 83 + 0 org.broad,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1702#issuecomment-210127581:1770,protocol,protocol,1770,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1702#issuecomment-210127581,1,['protocol'],['protocol']
Integrability,0-29T18:18:04.001673083Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.00,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6237:1800,wrap,wrapAndCopyInto,1800,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6237,1,['wrap'],['wrapAndCopyInto']
Integrability,0-29T18:18:04.001673083Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.00,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1800,wrap,wrapAndCopyInto,1800,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300,1,['wrap'],['wrapAndCopyInto']
Integrability,0-30T13:35:51.792736667Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-30T13:35:51.795082090Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-30T13:35:51.795253632Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.79,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1801,wrap,wrapAndCopyInto,1801,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227,1,['wrap'],['wrapAndCopyInto']
Integrability,"0-length intervals open up a huge can of worms (not much code is designed to be able to handle them, and none of the `htsjdk` query interfaces we rely on work properly with them). Modifying `ReadWalker` to set `readInterval` to null for these reads is a more conservative fix for the problem at hand that allows these reads to be processed without trying to query overlapping reference/feature data for them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/373#issuecomment-97498008:132,interface,interfaces,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/373#issuecomment-97498008,1,['interface'],['interfaces']
Integrability,"000); eden space 946688K, 10% used [0x000000066ab00000,0x0000000670bff978,0x00000006a4780000); from space 56832K, 99% used [0x00000006a5900000,0x00000006a9076d70,0x00000006a9080000); to space 85504K, 0% used [0x00000006a9b80000,0x00000006a9b80000,0x00000006aef00000); ParOldGen total 1497088K, used 20019K [0x00000003c0000000, 0x000000041b600000, 0x000000066ab00000); object space 1497088K, 1% used [0x00000003c0000000,0x00000003c138ceb0,0x000000041b600000); Metaspace used 36791K, capacity 37258K, committed 37504K, reserved 1081344K; class space used 5023K, capacity 5176K, committed 5248K, reserved 1048576K. Card table byte_map: [0x00002b5f67df9000,0x00002b5f69dfa000] byte_map_base: 0x00002b5f65ff9000. Marking Bits: (ParMarkBitMap*) 0x00002b5f57e71fa0; Begin Bits: [0x00002b5f6b656000, 0x00002b5f7b656000); End Bits: [0x00002b5f7b656000, 0x00002b5f8b656000). Polling page: 0x00002b5f56e61000. CodeCache: size=245760Kb used=5233Kb max_used=5233Kb free=240526Kb; bounds [0x00002b5f58a39000, 0x00002b5f58f59000, 0x00002b5f67a39000]; total_blobs=2060 nmethods=1583 adapters=391; compilation: enabled. Compilation events (10 events):; Event: 4.330 Thread 0x000056487672d800 1579 1 java.lang.ThreadLocal::getMap (5 bytes); Event: 4.330 Thread 0x000056487672d800 nmethod 1579 0x00002b5f58f55ed0 code [0x00002b5f58f56020, 0x00002b5f58f56130]; Event: 4.333 Thread 0x000056487672d800 1580 3 java.io.FileOutputStream::write (12 bytes); Event: 4.333 Thread 0x000056487672d800 nmethod 1580 0x00002b5f58f56550 code [0x00002b5f58f566c0, 0x00002b5f58f56848]; Event: 4.333 Thread 0x000056487672d800 1582 3 java.io.FilterInputStream::read (9 bytes); Event: 4.333 Thread 0x000056487672d800 nmethod 1582 0x00002b5f58f56910 code [0x00002b5f58f56a80, 0x00002b5f58f56ca8]; Event: 4.344 Thread 0x000056487672d800 1583 3 java.util.Formatter$Flags::<init> (10 bytes); Event: 4.344 Thread 0x000056487672d800 nmethod 1583 0x00002b5f58f56d50 code [0x00002b5f58f56ec0, 0x00002b5f58f57070]; Event: 4.344 Thread 0x000056487672",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:15516,adapter,adapters,15516,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['adapter'],['adapters']
Integrability,010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at or,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:2345,Wrap,WrappingSpliterator,2345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,3,['Wrap'],['WrappingSpliterator']
Integrability,"019-01-07 11:34:05 INFO BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on scc-q12.scc.bu.edu:38418 (size: 25.4 KB, free: 365.9 MB); 2019-01-07 11:34:05 INFO BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on scc-q12.scc.bu.edu:38418 (size: 113.9 KB, free: 365.8 MB); 2019-01-07 11:34:06 INFO TaskSetManager:54 - Starting task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:06 WARN TaskSetManager:66 - Lost task 1.0 in stage 0.0 (TID 1, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:24150,Wrap,Wrappers,24150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"019-01-09 13:35:46 INFO BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on scc-q01.scc.bu.edu:41129 (size: 25.4 KB, free: 365.9 MB); 2019-01-09 13:35:46 INFO BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on scc-q01.scc.bu.edu:41129 (size: 113.9 KB, free: 365.8 MB); 2019-01-09 13:35:48 INFO TaskSetManager:54 - Starting task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:48 WARN TaskSetManager:66 - Lost task 1.0 in stage 0.0 (TID 0, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:23437,Wrap,Wrappers,23437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,"02 59335904 target_189887_IL9R NaN; Y 59335905 59336289 target_189888_IL9R NaN; Y 59336290 59336776 target_189889_IL9R NaN; Y 59336840 59337486 target_189890_IL9R NaN; Y 59337698 59338400 target_189891_IL9R NaN; Y 59338503 59339109 target_189892_IL9R NaN; Y 59339943 59340528 target_189893_IL9R NaN; Y 59342236 59343330 target_189894_IL9R NaN. ---. @mbabadi commented on [Fri Aug 26 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-242767764). @davidbenjamin could you please take a look? it sounds like it could be a problem with the reference missing these regions. ---. @mbabadi commented on [Fri Aug 26 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-242774747). OK it turns out that the reference is hard masked and has ""N"" in that region. Nevertheless, we shouldn't get NaNs. In my opinion, the correct behavior is to drop targets on which GC percentage can not be defined + emit informative error messages. ---. @davidbenjamin commented on [Sun Sep 11 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-246177779). I will address this. ---. @mbabadi commented on [Tue Sep 27 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-250018497). @davidbenjamin also, CorrectGCBias produces NaNs when a sample has very low coverage. I think the correct behavior is this:. (1) when annotating targets, it is OK to produce NaNs on targets whose GC bias can not be determined. When correcting for GC bias, those targets must be removed altogether. (2) if the bias curve can not be determined (let's say because of low coverage), the tool should remove that sample from the collection and emit appropriate warning messages. If all samples are removed, the tool should produce a bad input error. ---. @mbabadi commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-302466279). @asmirnov239 can you review and if the issue is resolved, close?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2882:4762,message,messages,4762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2882,1,['message'],['messages']
Integrability,"06834861e7ae) [duplicate 3]; 2019-01-07 11:34:12 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-07 11:34:12 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 9.293 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:34089,Wrap,Wrappers,34089,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"08); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 18/04/24 17:40:52 INFO TaskSetManager: Lost task 0.0 in stage 2.0 (TID 3) on xx.xx.xx.25, executor 2: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 01:33 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:40:52 INFO TaskSetManager: Starting task 0.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 4, partition 0, PROCESS_LOCAL, 6010 bytes); 01:33 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:40:52 INFO TaskSetManager: Starting task 1.1 in stage 2.0 (TID 6, xx.xx.xx.24, executor 1, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:41:19 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.24:49115 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:41:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.24:49115 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:41:31 WARN TaskSetManager: Lost task 0.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 4): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:26752,Wrap,WrappedArray,26752,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Wrap'],['WrappedArray']
Integrability,"09/08 10:32:50 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 6.0 (TID 524, localhost, executor 1, partition 9, NODE_LOCAL, 5598 bytes); 18/09/08 10:32:50 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 6.0 (TID 515, localhost, executor 1): java.lang.NullPointerException; 	at org.broadinstitute.hellbender.utils.read.markduplicates.sparkrecords.EmptyFragment.<init>(EmptyFragment.java:35); 	at org.broadinstitute.hellbender.utils.read.markduplicates.sparkrecords.MarkDuplicatesSparkRecord.newEmptyFragment(MarkDuplicatesSparkRecord.java:37); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$null$0(MarkDuplicatesSparkUtils.java:114); 	at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$transformToDuplicateNames$17d832cf$1(MarkDuplicatesSparkUtils.java:123); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:199); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5169:2990,wrap,wrapAndCopyInto,2990,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5169,1,['wrap'],['wrapAndCopyInto']
Integrability,"1 2016](https://github.com/broadinstitute/gatk-protected/issues/806). An issue encountered with gatk-protected ""SparkGenomeReadCounts"" tool is a non-helpful ""null"" error message. A non-helpful error ""null"" message was printed by gatk-protected with the command-line below; during the course of trying to use it on/in FireCloud:. ```; + java -Xmx48g -jar fc-7ac504fc-7fe4-4bc1-89d3-7f16317b8ff4/eddie.jar SparkGenomeReadCounts --outputFile this.entity_id.coverage.tsv --reference fc-e2421839-93d5-4ed5-8861-593f00364e54/Homo_sapiens_assembly19.fasta --input firecloud-tcga-open-access/tutorial/bams/C835.HCC1143_BL.4.bam --binsize 5000; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp; .....; ......; ......; proceeding with flushing remote transports.; ***********************************************************************. null. ***********************************************************************; ```. To try to make a more helpful error message appear I added a ""catch"" block after a call to runTool in instanceMainPostParseArgs in file CommandLineProgram.java and got a more helpful message about a missing dictionary file: . try {; return runTool();; } ; catch(Exception e) {; e.getStackTrace();; }. java.lang.RuntimeException: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:204); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:152); Caused by: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2922:994,message,message,994,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2922,1,['message'],['message']
Integrability,1-4/p1). More information can be requested if necessary. Stack trace copied below:; > A USER ERROR has occurred: Couldn't write file hdfs://cloudera08/gatk-test2/WES2019-022_S4_out.vcf because writing failed with exception concat: target file /gatk-test2/WES2019-022_S4_out.vcf.parts/output is empty; > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInternal(FSNamesystem.java:2303); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInt(FSNamesystem.java:2257); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concat(FSNamesystem.java:2219); > at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.concat(NameNodeRpcServer.java:829); > at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.concat(AuthorizationProviderProxyClientProtocol.java:285); > at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.concat(ClientNamenodeProtocolServerSideTranslatorPB.java:580); > at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); > at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617); > at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2278); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2274); > at java.security.AccessController.doPrivileged(Native Method); > at javax.security.auth.Subject.doAs(Subject.java:422); > at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924); > at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2272); > ; > org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file hdfs://cloudera08/gatk-test2/WES2019-022_S4_out.vcf because writing failed with exception concat: target file /gatk-test2/WES2019-022_S4_out.vcf.parts/output is empty; > at org.apache.hadoop.hdfs.se,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6218:1390,protocol,protocol,1390,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6218,1,['protocol'],['protocol']
Integrability,"1. AF in the FORMAT column can be used to represent heteroplasmy levels. ; 2. Currently the genotype is always reported as het (0/1). There is a request to change this but it hasn't been implemented yet: https://github.com/broadinstitute/gatk/issues/6257 If you'd like to fix this feel free to make a PR and I'd be happy to review it.; 3. Mitochondria mode in Mutect alone does not automatically shift the reference. However, you can use the full pipeline which does the shift automatically. You can find the WDL here: https://github.com/broadinstitute/gatk/blob/master/scripts/mitochondria_m2_wdl/MitochondriaPipeline.wdl or the Terra workspace here: https://app.terra.bio/#workspaces/help-gatk/Mitochondria-SNPs-Indels-hg38 Depending on the coverage of your data, if you don't need high sensitivity over the region with the breakpoint it also might not be worth doing the full realignment. You'll still be able to make calls on the edges of the linearized reference, you just might not have the full sensitivity you would if you realigned. I hope that helps!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7350#issuecomment-880714297:726,Depend,Depending,726,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7350#issuecomment-880714297,1,['Depend'],['Depending']
Integrability,"1. Add new arg `genomicsdb-shared-posixfs-optimizations` to help with shared posix filesystems like NFS and Lustre. This turns on `disable file locking` and for GenomicsDB import it minimizes writes to disks. The performance on some of the gatk datasets for the import of about 10 samples went from 23.72m to 6.34m on NFS which was comparable to importing to a local filesystem. Hopefully this helps with Issue #6487 and #6627. Also, fixes Issue #6519.; 2. This version of GenomicsDB also uses pre-compression filters for offset and compression files for new workspaces and genomicsdb arrays. The total sizes for a GenomicsDB workspace using the same dataset as above and the 10 samples went from 313MB to 170MB with no change in import and query times. Smaller GenomicsDB arrays also help with performance on distributed and cloud file systems.; 3. This version has added support to handle MNVs similar to deletions as described in Issue #6500. See [GenomicsDB PR 88](https://github.com/GenomicsDB/GenomicsDB/pull/88). Thanks @kgururaj.; 4. There is added support in the GenomicsDBImporter to have multiple contigs in the same GenomicsDB partition/array. This will hopefully help import times in cases where users have many thousands of contigs. See [GenomicsDB PR 91](https://github.com/GenomicsDB/GenomicsDB/pull/91). Changes will be needed from the gatk side to avail this support. Thanks @mlathara.; 5. Logging has been improved somewhat with the native C/C++ code using [spdlog](https://github.com/gabime/spdlog) and [fmt](https://github.com/fmtlib/fmt) and the Java layer using apache log4j and log4j.properties provided by the application. Also, info messages like `No valid combination operation found for INFO field AA - the field will NOT be part of INFO fields in the generated VCF records` will only be output once for the operation. Also see open PR #6514 for code to actually suppress these warnings for known fields.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6654:1659,message,messages,1659,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6654,1,['message'],['messages']
Integrability,"1. After removing `chr` the tool output still indicates 0 bp from the interval.; 2. I tried omitting the `--sequence-dictionary` argument but the tool output still indicates 0 bp from the interval.; 3. If I check my command by which I generated the vcf files. I used the following mutext2 (in tumor only mode) command for normal samples:; ` $gatk Mutect2 --native-pair-hmm-threads 8 -R /refs/ucsc.hg19.fasta -I normal1.bam -tumor normal1 --disable-read-filter MateOnSameContigOrNoMappedMateReadFilter -O nornam1.vcf.gz`; The above command worked well for all 80 normals. Please let me know if I missed anything here to make vcf files compatible with the GenomicDB module. Other than using the hg19 fasta file from gatk resources, I also tried the same UCSC hg19 (both fasta and dict) but GenomeDB indicates the same 0 bp message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7037#issuecomment-760677622:821,message,message,821,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037#issuecomment-760677622,1,['message'],['message']
Integrability,1. Allow for using separate threads for reading / processing / writing (max 3); 2. Use NM SAM tag instead of edit distance; 3. Perform likelihood scoring on trimmed read. Additional changes include:; 1. CachingIndexedFastaSequenceFile is enhanced to be thread safe and allow for adjusting its cache size. The change involved synchronizing the main query method (getSubsequenceAt) and deriving the cache size from a settable variable rather than from a constant.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8982:325,synchroniz,synchronizing,325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8982,1,['synchroniz'],['synchronizing']
Integrability,"1. Why can't standard tools operate on the distributed workspaces? You could run `GenotypeGVCFs` on these workspaces in a distributed fashion and then concatenate the results together if you want. I think you were initially considering this route - and still think it would be more performant. 2. Again, you can process/query a whatever set of intervals you want -- in a distributed fashion, right?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-640791782:241,rout,route,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-640791782,1,['rout'],['route']
Integrability,"1. Wrap `SeekablePathStream` in the tribble feature readers with a `Function<SeekableByteChannel, SeekableByteChannel>`. 2. Mirror what was done in https://github.com/broadinstitute/gatk/pull/2331 for `FeatureDataSource`: propagate cloud prefetching buffer sizes from `GATKTool` down to `FeatureDataSource`, create wrapper functions within `FeatureDataSource`, and pass down to htsjdk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2375:3,Wrap,Wrap,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2375,2,"['Wrap', 'wrap']","['Wrap', 'wrapper']"
Integrability,"1. line coverage is 89% for this class. Uncovered code is for a) read without bases, b) IO exception when writing the report, c) plotting code. So i'm not too worried about this.; 2. agreed in principle. To make this doable though we need a testing framework that would make it easy to manufacture reads en bulk. Right now we'd need to make them one by one - integration test has a nice property of being portable across picard/gatk and it's easy to plug in because it has an input with many reads. I'm assuming that 'looks fine' is equivalent to 'LGTM' and will merge when tests pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1013#issuecomment-149761535:359,integrat,integration,359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1013#issuecomment-149761535,1,['integrat'],['integration']
Integrability,137); 	at org.broadinstitute.hellbender.utils.variant.writers.GVCFBlockCombiner.submit(GVCFBlockCombiner.java:200); 	at org.broadinstitute.hellbender.utils.variant.writers.GVCFWriter.add(GVCFWriter.java:91); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ReblockGVCF.apply(ReblockGVCF.java:229); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1058); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7334:5766,wrap,wrapAndCopyInto,5766,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7334,1,['wrap'],['wrapAndCopyInto']
Integrability,14810448Z Runtime.totalMemory()=407896064; 2019-01-04T14:02:27.215613324Z java.lang.IllegalArgumentException: errorRateLog10 must be good probability but got NaN; 2019-01-04T14:02:27.216082142Z 	at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleLog10ErrorRate(QualityUtils.java:321); 2019-01-04T14:02:27.216288993Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.lambda$applyGermlineVariantFilter$10(Mutect2FilteringEngine.java:207); 2019-01-04T14:02:27.216482786Z 	at java.util.stream.DoublePipeline$3$1.accept(DoublePipeline.java:231); 2019-01-04T14:02:27.216675396Z 	at java.util.Spliterators$DoubleArraySpliterator.forEachRemaining(Spliterators.java:1198); 2019-01-04T14:02:27.216858104Z 	at java.util.Spliterator$OfDouble.forEachRemaining(Spliterator.java:822); 2019-01-04T14:02:27.217027544Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-01-04T14:02:27.234512924Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-01-04T14:02:27.234886181Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); 2019-01-04T14:02:27.235138770Z 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 2019-01-04T14:02:27.235509109Z 	at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); 2019-01-04T14:02:27.235661751Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:207); 2019-01-04T14:02:27.235931663Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:436); 2019-01-04T14:02:27.236174900Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:120); 2019-01-04T14:02:27.236322702Z 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); 2019-01-04T14:02:27.2371714,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451464446:1329,wrap,wrapAndCopyInto,1329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451464446,1,['wrap'],['wrapAndCopyInto']
Integrability,"1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:14:03 WARN scheduler.TaskSetManager: Lost task 23.0 in stage 0.0 (TID 6, scc-q15.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 2, start 93470412, span 157, expected MD5 56b7844faa4e0c4f61fd6774df454b09; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:11348,Wrap,Wrappers,11348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['Wrap'],['Wrappers']
Integrability,"2); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadinstitute.hellbender.Main.main(Main.java:275); Caused by: java.net.SocketTimeoutException: connect timed out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:158); 	at com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:489); 	at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:206); 	... 31 more; ```; Followed by repetitions of the following stacktrace:; ```; Feb 07, 2018 12:41:59 PM com.google.api.client.http.HttpRequest execute; WARNING: except",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369:4211,protocol,protocol,4211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369,1,['protocol'],['protocol']
Integrability,"2019-02-17 16:25:50 WARN TaskSetManager:66 - Lost task 177.0 in stage 5.0 (TID 1127, scc-q10.scc.bu.edu, executor 14): java.lang.IllegalArgumentException: provided start is negative: -12; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkCont",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:29327,Wrap,Wrappers,29327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['Wrap'],['Wrappers']
Integrability,"2019-02-17 16:25:50 WARN TaskSetManager:66 - Lost task 178.0 in stage 5.0 (TID 1119, scc-q06.scc.bu.edu, executor 23): java.lang.IllegalArgumentException: provided start is negative: -26; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkCont",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:36767,Wrap,Wrappers,36767,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['Wrap'],['Wrappers']
Integrability,"232994 0.2 1000 4676.9; 09:10:51.253 INFO ProgressMeter - 1:688469 0.4 2000 4890.4; 09:11:01.889 INFO ProgressMeter - 1:809005 0.6 3000 5117.3; 09:11:13.838 INFO ProgressMeter - 1:818424 0.8 5000 6366.2; 09:11:16.811 INFO CombineGVCFs - Shutting down engine; [September 3, 2020 at 9:11:16 AM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.20 minutes.; Runtime.totalMemory()=107374182400; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1624); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.makeRawAnnotationString(StrandBiasUtils.java:46); 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_StrandBiasTest.combineRawData(AS_StrandBiasTest.java:115); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:210); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); 	at ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6790:2348,wrap,wrapAndCopyInto,2348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790,1,['wrap'],['wrapAndCopyInto']
Integrability,"3 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 13.012444101000002; 14:17:59.043 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 45.65 sec; 14:17:59.043 INFO Mutect2 - Shutting down engine; [May 15, 2020 2:17:59 PM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 36.79 minutes.; Runtime.totalMemory()=3793223680; java.lang.IndexOutOfBoundsException: Index: 0, Size: 0; at java.util.ArrayList.rangeCheck(ArrayList.java:657); at java.util.ArrayList.get(ArrayList.java:433); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.lambda$getGermlineAltAlleleFrequencies$27(SomaticGenotypingEngine.java:351); at java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:244); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:546); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.DoublePipeline.toArray(DoublePipeline.java:508); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getGermlineAltAlleleFrequencies(SomaticGenotypingEngine.java:353); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getNegativeLogPopulationAFAnnotation(SomaticGenotypingEngine.java:336); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:155); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:252); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:299); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:200); at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6605:2495,wrap,wrapAndCopyInto,2495,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6605,1,['wrap'],['wrapAndCopyInto']
Integrability,"30.861 INFO ProgressMeter - chr21:48065662 88.1 10112630 114731.5; 22:45:30.976 INFO HaplotypeCaller - 0 read(s) filtered by: MappingQualityReadFilter; 0 read(s) filtered by: MappingQualityAvailableReadFilter; 0 read(s) filtered by: MappedReadFilter; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter; 0 read(s) filtered by: NotDuplicateReadFilter; 0 read(s) filtered by: PassesVendorQualityCheckReadFilter; 0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter; 0 read(s) filtered by: GoodCigarReadFilter; 0 read(s) filtered by: WellformedReadFilter; 0 total reads filtered; 22:45:30.976 INFO ProgressMeter - chr21:48129366 88.1 10112861 114731.7; 22:45:30.976 INFO ProgressMeter - Traversal complete. Processed 10112861 total regions in 88.1 minutes.; 22:45:31.288 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.864119336; 22:45:31.288 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 115.66789462000001; 22:45:31.288 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 90.73 sec; 22:45:31.289 INFO HaplotypeCaller - Shutting down engine; [August 31, 2020 10:45:31 PM CDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 88.19 minutes.; Runtime.totalMemory()=2630352896. And now the header looks like:; ```; @SQ SN:chr1 LN:249250621; @SQ SN:chr2 LN:243199373; @SQ SN:chr3 LN:198022430; @SQ SN:chr4 LN:191154276; @SQ SN:chr5 LN:180915260; @SQ SN:chr6 LN:171115067; @SQ SN:chr7 LN:159138663; @SQ SN:chr8 LN:146364022; @SQ SN:chr9 LN:141213431; @SQ SN:chr10 LN:135534747; @SQ SN:chr11 LN:135006516; @SQ SN:chr12 LN:133851895; @SQ SN:chr13 LN:115169878; @SQ SN:chr14 LN:107349540; @SQ SN:chr15 LN:102531392; @SQ SN:chr16 LN:90354753; @SQ SN:chr17 LN:81195210; @SQ SN:chr18 LN:78077248; @SQ SN:chr20 LN:63025520; @SQ SN:chr19 LN:59128983; @SQ SN:chr22 LN:51304566; @SQ SN:chr21 LN:48129895; ```. So I still think it is the header in BAM that is causing the error message.; Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684831011:2311,message,message,2311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684831011,1,['message'],['message']
Integrability,"330180 59330708 target_189885_IL9R NaN; Y 59333828 59334429 target_189886_IL9R NaN; Y 59335302 59335904 target_189887_IL9R NaN; Y 59335905 59336289 target_189888_IL9R NaN; Y 59336290 59336776 target_189889_IL9R NaN; Y 59336840 59337486 target_189890_IL9R NaN; Y 59337698 59338400 target_189891_IL9R NaN; Y 59338503 59339109 target_189892_IL9R NaN; Y 59339943 59340528 target_189893_IL9R NaN; Y 59342236 59343330 target_189894_IL9R NaN. ---. @mbabadi commented on [Fri Aug 26 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-242767764). @davidbenjamin could you please take a look? it sounds like it could be a problem with the reference missing these regions. ---. @mbabadi commented on [Fri Aug 26 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-242774747). OK it turns out that the reference is hard masked and has ""N"" in that region. Nevertheless, we shouldn't get NaNs. In my opinion, the correct behavior is to drop targets on which GC percentage can not be defined + emit informative error messages. ---. @davidbenjamin commented on [Sun Sep 11 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-246177779). I will address this. ---. @mbabadi commented on [Tue Sep 27 2016](https://github.com/broadinstitute/gatk-protected/issues/651#issuecomment-250018497). @davidbenjamin also, CorrectGCBias produces NaNs when a sample has very low coverage. I think the correct behavior is this:. (1) when annotating targets, it is OK to produce NaNs on targets whose GC bias can not be determined. When correcting for GC bias, those targets must be removed altogether. (2) if the bias curve can not be determined (let's say because of low coverage), the tool should remove that sample from the collection and emit appropriate warning messages. If all samples are removed, the tool should produce a bad input error. ---. @mbabadi commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/6",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2882:4002,message,messages,4002,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2882,1,['message'],['messages']
Integrability,3348> (a java.net.SocksSocketImpl); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.Stor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1377,protocol,protocol,1377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.util.ConcurrentModificationException; 	at java.util.Vector$Itr.checkForComodification(Vector.java:1184); 	at java.util.Vector$Itr.next(Vector.java:1137); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:92); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:40); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); 	... 120 more; ```. @jamesemery @tomwhite I've seen,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5680:10974,Message,MessageHub,10974,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680,1,['Message'],['MessageHub']
Integrability,35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstan,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:1892,Message,MessageHub,1892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858,1,['Message'],['MessageHub']
Integrability,3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGUuamF2YQ==) | `93.333% <0.000%> (-0.063%)` | :arrow_down: |; | [...itute/hellbender/tools/LocalAssemblerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7926/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Mb2NhbEFzc2VtYmxlclVuaXRUZXN0LmphdmE=) | `92.448% <0.000%> (Ã¸)` | |; | [...s/variantutils/VariantsToTableIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7926/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGVJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `100.000% <0.000%> (Ã¸)` | |; | [...s/solver/SynchronizedUnivariateSolverUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7926/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvU3luY2hyb25pemVkVW5pdmFyaWF0ZVNvbHZlclVuaXRUZXN0LmphdmE=) | | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/broadinstitute/gatk/pull/7926/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvVW5pdmFyaWF0ZVNvbHZlclNwZWNpZmljYXRpb25zLmphdmE=) | | |; | [...r/utils/solver/UnivariateSolverJobDescription.java](https://codecov.io/gh/broadinstitute/gatk/pull/7926/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvY,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7926#issuecomment-1170548167:4307,Synchroniz,SynchronizedUnivariateSolverUnitTest,4307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7926#issuecomment-1170548167,1,['Synchroniz'],['SynchronizedUnivariateSolverUnitTest']
Integrability,3Zxc3IvVHJhbmNoZS5qYXZh) | `62.921% <0%> (-7.349%)` | `18% <0%> (Ã¸)` | |; | [.../hellbender/tools/walkers/vqsr/TrancheManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVHJhbmNoZU1hbmFnZXIuamF2YQ==) | `67.347% <0%> (-2.983%)` | `18% <0%> (+3%)` | |; | [...ols/walkers/contamination/ContaminationRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvblJlY29yZC5qYXZh) | `87.302% <0%> (-2.698%)` | `9% <0%> (+4%)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <0%> (Ã¸)` | `11% <0%> (?)` | |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <0%> (Ã¸)` | `12% <0%> (?)` | |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <0%> (+1.429%)` | `2% <0%> (Ã¸)` | :arrow_down: |; | [...s/spark/pathseq/PSBuildReferenceTaxonomyUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTQnVpbGRSZWZlcmVuY2VUYXhvbm9teVV0aWxzLmphdmE=) | `90.541% <0%> (+1.579%)` | `80% <0%> (+41%)` | :arrow_up: |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054:3054,Adapter,AdapterTrimTransformer,3054,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054,1,['Adapter'],['AdapterTrimTransformer']
Integrability,"4 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] KvWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] ServiceRegistryActor stopped; [2020-07-14 05:09:55,58] [info] Database closed; [2020-07-14 05:09:55,58] [info] Stream materializer shut down; [2020-07-14 05:09:55,58] [info] WDL HTTP import resolver closed; Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 transitioned to state Failed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:10084,message,messages,10084,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,2,['message'],['messages']
Integrability,"4); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:14:00 WARN scheduler.TaskSetManager: Lost task 16.0 in stage 0.0 (TID 2, scc-q15.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:8181,Wrap,Wrappers,8181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['Wrap'],['Wrappers']
Integrability,"4.2 KB, free 366.0 MB); 00:45 DEBUG: [kryo] Write: byte[]; 18/04/24 17:40:04 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KB, free 366.0 MB); 18/04/24 17:40:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.xx:42081 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:40:04 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 18/04/24 17:40:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[19] at mapToPair at PSFilter.java:125) (first 15 tasks are for partitions Vector(0, 1)); 18/04/24 17:40:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks; 00:45 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:40:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3, xx.xx.xx.25, executor 2, partition 0, PROCESS_LOCAL, 6010 bytes); 00:45 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:40:04 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 4, xx.xx.xx.23, executor 5, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:40:21 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (xx.xx.xx.24:44437) with ID 1; 18/04/24 17:40:21 INFO BlockManagerMasterEndpoint: Registering block manager xx.xx.xx.24:44322 with 366.3 MB RAM, BlockManagerId(1, xx.xx.xx.24, 44322, None); 18/04/24 17:40:27 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (xx.xx.xx.24:44439) with ID 4; 18/04/24 17:40:27 INFO BlockManagerMasterEndpoint: Registering block manager xx.xx.xx.24:49115 with 366.3 MB RAM, BlockManagerId(4, xx.xx.xx.24, 49115, None); 18/04/24 17:40:50 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.25:39218 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:40:50 INFO BlockManagerInfo: Added broadcas",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:22951,Wrap,WrappedArray,22951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Wrap'],['WrappedArray']
Integrability,"4.2 KB, free 366.0 MB); 00:59 DEBUG: [kryo] Write: byte[]; 18/04/24 17:55:54 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KB, free 366.0 MB); 18/04/24 17:55:54 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.16:49734 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:55:54 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 18/04/24 17:55:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[19] at mapToPair at PSFilter.java:125) (first 15 tasks are for partitions Vector(0, 1)); 18/04/24 17:55:54 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks; 00:59 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:54 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3, xx.xx.xx.25, executor 2, partition 0, PROCESS_LOCAL, 6010 bytes); 00:59 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:55:54 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 4, xx.xx.xx.16, executor 3, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:55:54 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.16:39037 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:55:54 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.25:41354 (size: 6.4 KB, free: 366.3 MB); **18/04/24 17:55:54 WARN TaskSetManager: Lost task 1.0 in stage 2.0 (TID 4, xx.xx.xx.16, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFil",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:24355,Wrap,WrappedArray,24355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Wrap'],['WrappedArray']
Integrability,"4/24 17:42:02 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/24 17:42:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/24 17:42:02 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/gatk-package-4.0.3.0-spark.jar, byteCount=138618122, body=FileSegmentManagedBuffer{file=/scratch/home/int/eva/username/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-spark.jar, offset=0, length=138618122}} to /xx.xx.xx.25:57139; closing connection; java.io.IOException: Connection reset by peer; at sun.nio.ch.FileChannelImpl.transferTo0(Native Method); at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428); at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493); at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608); at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139); at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121); at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287); at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237); at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314); at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802); at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319); at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637); at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566); at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442); at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:37264,Message,MessageWithHeader,37264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Message'],['MessageWithHeader']
Integrability,"44139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	... 15 more; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; {; ""code"" : 403,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi."",; ""reason"" : ""forbidden""; } ],; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi.""; }; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4592:3705,message,message,3705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4592,1,['message'],['message']
Integrability,4668988887 Oct 4 11:27 /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; ```. Here is SPARK information. ```; A USER ERROR has occurred: Failed to read bam header from; /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; Caused by:File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Failed to read bam header from /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; Caused by:File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:1445,protocol,protocol,1445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocol']
Integrability,"47:27.292 INFO CalculateTargetCoverage - Shutting down engine; [June 22, 2017 5:47:27 PM EDT] org.broadinstitute.hellbender.tools.exome.CalculateTargetCoverage done. Elapsed time: 2.87 minutes.; Runtime.totalMemory()=10377756672; htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248681942, span 176823, expected MD5 4b8526e90896b01860301e5a1ef4988b; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:601); at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.hasNext(SAMRecordToReadIterator.java:24); at java.util.Iterator.forEachRemaining(Iterator.java:115); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:779); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); at org.broadinstitute.hellbender.Main.ma",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154:2137,wrap,wrapAndCopyInto,2137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154,1,['wrap'],['wrapAndCopyInto']
Integrability,"4:08 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 3) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2, partition 9, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 0, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:28076,Wrap,Wrappers,28076,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `77.477% <Ã¸> (+0.901%)` | `38% <Ã¸> (+2%)` | :white_check_mark: |; | [...tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9BbGxlbGVTdWJzZXR0aW5nVXRpbHMuamF2YQ==) | `87.037% <Ã¸> (+0.926%)` | `40% <Ã¸> (+1%)` | :white_check_mark: |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZWFuUXVhbGl0eUJ5Q3ljbGVTcGFyay5qYXZh) | `91.667% <Ã¸> (+1.042%)` | `10% <Ã¸> (Ã¸)` | :x: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `74.194% <Ã¸> (+1.075%)` | `26% <Ã¸> (+1%)` | :white_check_mark: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2404/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2404?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Î” = absolute <relative> (impact)`, `Ã¸ = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2404?src=pr&el=footer). Last update [30365e7...09a6f24](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2404#issuecomment-279082842:4367,Integrat,IntegrationTestSpec,4367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2404#issuecomment-279082842,1,['Integrat'],['IntegrationTestSpec']
Integrability,"51_recalibration_plots.pdf'; 22:13:30.518 INFO AnalyzeCovariates - Shutting down engine; [August 7, 2023 at 10:13:30 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=113246208; org.broadinstitute.hellbender.utils.R.RScriptExecutorException:; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.10708586791705723928';source('/tmp/BQSR.12372590345390592260.R'); /tmp/AnalyzeCovariates13996065741193890473.csv /attach/data/vinit/human_exome/test/./sample_analysis/SRR25308851/SRR25308851_before_recal_data.table /attach/data/vinit/human_exome/test/./sample_analysis/SRR25308851/SRR25308851_recalibration_plots.pdf; Stdout:; Stderr:; Attaching package: â€˜gplotsâ€™. The following object is masked from â€˜package:statsâ€™:. lowess. Error in names(x) <- value :; 'names' attribute [6] must be the same length as the vector [1]; Calls: source ... finishTable -> .gsa.assignGATKTableToEnvironment -> colnames<-; In addition: Warning messages:; 1: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 2: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 3: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 4: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; 5: In type.convert.default(d[, i]) :; 'as.is' should be specified by the caller; using TRUE; Execution halted. at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:79); at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:18); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:112); at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:125); at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.generatePlots(RecalUt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8456:3770,message,messages,3770,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8456,1,['message'],['messages']
Integrability,"594.9; 14:36:53.704 INFO ProgressMeter - chr1:235080870 4.3 494000 114959.0; 14:37:03.729 INFO ProgressMeter - chr1:244961323 4.5 518000 116032.5; 14:37:09.228 INFO CalibrateDragstrModel - Shutting down engine; [April 17, 2021 2:37:09 PM EDT] org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel done. Elapsed time: 4.58 minutes.; Runtime.totalMemory()=2153775104; java.lang.IllegalArgumentException: Start cannot exceed end.; at htsjdk.samtools.util.IntervalTree.put(IntervalTree.java:74); at htsjdk.samtools.util.IntervalTree.merge(IntervalTree.java:137); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel$ShardReadBuffer.add(CalibrateDragstrModel.java:949); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel$1.tryAdvance(CalibrateDragstrModel.java:798); at java.util.Spliterator.forEachRemaining(Spliterator.java:326); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.collectCaseStatsSequencial(CalibrateDragstrModel.java:459); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.traverse(CalibrateDragstrModel.java:159); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1058); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitut",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182#issuecomment-821876394:5480,wrap,wrapAndCopyInto,5480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182#issuecomment-821876394,1,['wrap'],['wrapAndCopyInto']
Integrability,"5:33.396 INFO ProgressMeter - Starting traversal; 13:55:33.396 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 13:55:42.364 INFO CalibrateDragstrModel - Shutting down engine; [April 4, 2021 1:55:42 PM EDT] org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=2384986112; java.lang.IllegalArgumentException: Start cannot exceed end.; at htsjdk.samtools.util.IntervalTree.put(IntervalTree.java:74); at htsjdk.samtools.util.IntervalTree.merge(IntervalTree.java:137); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel$ShardReadBuffer.add(CalibrateDragstrModel.java:949); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel$1.tryAdvance(CalibrateDragstrModel.java:798); at java.util.Spliterator.forEachRemaining(Spliterator.java:326); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.collectCaseStatsSequencial(CalibrateDragstrModel.java:459); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.traverse(CalibrateDragstrModel.java:159); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1058); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182:1408,wrap,wrapAndCopyInto,1408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182,3,['wrap'],['wrapAndCopyInto']
Integrability,"5:51 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 4) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 6, scc-q01.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:52 WARN TaskSetManager:66 - Lost task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 2, start 131325815, span 181534, expected MD5 c240a972d49aa89fb57dae94d1d90d36; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:29101,Wrap,Wrappers,29101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,"5:53.390 INFO ProgressMeter - Starting traversal; 09:15:53.390 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:15:53.479 INFO SelectVariants - Shutting down engine; [June 27, 2019 9:15:53 AM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2131755008; htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 3433: The VCF specification does not allow for whitespace in the INFO field; . Offending field value was ""AC=1;AF=9.671e-04;AN=1034;AS_BaseQRankSum=-1.550;AS_FS=8.334;AS_InbreedingCoeff=-0.3147;AS_MQ=31.69;AS_MQRankSum=-0.200;AS_QD=28.73;AS_ReadPosR; ankSum=nul;AS_SOR=2.235;BaseQRankSum=-1.381e+00;DP=40368;ExcessHet=160.0000;FS=8.334;InbreedingCoeff=-0.3147;MLEAC=7;MLEAF=6.770e-03;MQ=37.13;MQRankSum=0.126;QD=2.46;SOR=2.; 235 GT:AD:DP:GQ:PGT:PID:PL:PS 0/0:75,0:75:0:.:.:0,0,1525; `. However, from the error message I cannot see any whitespace in the INFO field. The /dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR/ExcessHet_joint525_c1_22.SNP.VQSR.g.vcf.gz is the output of following command:. `gatk4.1.0.0 --java-options '-Xmx100g -Xmx100g' ApplyVQSR \; -R /dsgmnt/llfs2/masterdata/geno/hg38/resources_broad_hg38_v0_Homo_sapiens_assembly38.fasta \; -V ${SNPPath}/joint525_chr1_ExcessHet_filter.SNP.g.vcf.gz \; -V ${SNPPath}/joint525_chr2_ExcessHet_filter.SNP.g.vcf.gz \; ....; -V ${SNPPath}/joint525_chr22_ExcessHet_filter.SNP.g.vcf.gz \; -O /dsgmnt/seq5_llfs/work/xhong/v4100/ApplyVQSR//ExcessHet_joint525_c1_22.SNP.VQSR.g.vcf.g; z \; --truth-sensitivity-filter-level 97 \; --tranches-file /dsgmnt/seq5_llfs/work/xhong/v4100/VQSR//ExcessHet_joint525_c1_22.snp.tranches \; --recal-file /dsgmnt/seq5_llfs/work/xho; ng/v4100/VQSR//ExcessHet_joint525_c1_22.snp.recal \; -mode SNP`. There is no error or warning in the standard error and standard output of this step. I have tried to apply VQSR SNP model to ${SNPPath}/joint525_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6021:3790,message,message,3790,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6021,1,['message'],['message']
Integrability,"5</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/4a197e78ad2430e22e992c5a7727b61ae220f727""><code>4a197e7</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/18387"">#18387</a> from protocolbuffers/cp-lp-25</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b5a7cf7cf4b7e39f6b02205e45afe2104a7faf81""><code>b5a7cf7</code></a> Remove RecursiveGroup test case which doesn't exist in 25.x pre-Editions</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/f000b7e18fd6921ca02ea4b87608e8cadcb7b64f""><code>f000b7e</code></a> Fix merge conflict by adding optional label to proto2 unittest_lite.proto</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/4728531c162f2f9e8c2ca1add713cfee2db6be3b""><code>4728531</code></a> Add recursion check when parsing unknown fields in Java.</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/850fcce9176e2c9070614dab53537760498c926b""><code>850fcce</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b7044987de77f1dc368fee558636d0b56d7e75e1""><code>b704498</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/e67347986eaf7d777a6ee34367fa99f4912423ab""><code>e673479</code></a> Fix cord handling in DynamicMessage and oneofs. (<a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/18375"">#18375</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/8a60b6527a976cfd0028153da3ad8e4ed280e0de""><code>8a60b65</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:1269,protocol,protocolbuffers,1269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,1,['protocol'],['protocolbuffers']
Integrability,"6 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 104.303087949; 23:24:11.546 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 78.48 sec; 23:24:11.553 INFO Mutect2 - Shutting down engine; [October 5, 2021 11:24:11 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 172.32 minutes.; Runtime.totalMemory()=4052746240; java.lang.IndexOutOfBoundsException: Index: 0, Size: 0; at java.util.ArrayList.rangeCheck(ArrayList.java:657); at java.util.ArrayList.get(ArrayList.java:433); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.lambda$getGermlineAltAlleleFrequencies$27(SomaticGenotypingEngine.java:352); at java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:244); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:546); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.DoublePipeline.toArray(DoublePipeline.java:530); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getGermlineAltAlleleFrequencies(SomaticGenotypingEngine.java:354); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getNegativeLogPopulationAFAnnotation(SomaticGenotypingEngine.java:337); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:155); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:259); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:306); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:200); at org.broadinstitute.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-936771625:1228,wrap,wrapAndCopyInto,1228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-936771625,1,['wrap'],['wrapAndCopyInto']
Integrability,6); 	at java.util.Arrays.sort(Arrays.java:1507); 	at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:302); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:513); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.utils.Utils.getMedianValue(Utils.java:1137); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:277); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:101); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.endPreviousStates(CombineGVCFs.java:340); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.createIntermediateVariants(CombineGVCFs.java:189); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.apply(CombineGVCFs.java:134); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:73); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase$$Lambda$87/908435478.accept(Unknown Source); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); .......,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4633:2599,wrap,wrapAndCopyInto,2599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4633,1,['wrap'],['wrapAndCopyInto']
Integrability,6); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.regenotypeVC(GenotypeGVCFs.java:222); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:201); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:151); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase$$Lambda$91/1033850902.accept(Unknown Source); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:149); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:984); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); Using GATK jar /gatk/gatk-package-4.0.6.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-612103255:3658,wrap,wrapAndCopyInto,3658,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-612103255,1,['wrap'],['wrapAndCopyInto']
Integrability,"636d0b56d7e75e1""><code>b704498</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/e67347986eaf7d777a6ee34367fa99f4912423ab""><code>e673479</code></a> Fix cord handling in DynamicMessage and oneofs. (<a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/18375"">#18375</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/8a60b6527a976cfd0028153da3ad8e4ed280e0de""><code>8a60b65</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.23.4...v3.25.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:2452,Depend,Dependabot,2452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,64); 	at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.WellformedReadFilter.test(WellformedReadFilter.java:77); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.lambda$getReads$e4b35a40$1(GATKSparkTool.java:213); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool$$Lambda$93/2063469002.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:2067,Wrap,Wrappers,2067,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['Wrap'],['Wrappers']
Integrability,"673 INFO FilterMutectCalls - Done initializing engine; 10:00:21.734 INFO ProgressMeter - Starting traversal; 10:00:21.734 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 10:00:22.290 INFO FilterMutectCalls - Shutting down engine; [March 7, 2018 10:00:22 AM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=934805504; org.broadinstitute.hellbender.exceptions.GATKException: INFO annotation 'MFRL' contains a non-int value '2.1472e+08'; 	at org.broadinstitute.hellbender.utils.GATKProtectedVariantContextUtils.lambda$attributeValueToIntArray$1(GATKProtectedVariantContextUtils.java:134); 	at java.util.stream.ReferencePipeline$4$1.accept(ReferencePipeline.java:210); 	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 	at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); 	at org.broadinstitute.hellbender.utils.GATKProtectedVariantContextUtils.attributeValueToIntArray(GATKProtectedVariantContextUtils.java:154); 	at org.broadinstitute.hellbender.utils.GATKProtectedVariantContextUtils.getAttributeAsIntArray(GATKProtectedVariantContextUtils.java:81); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.getIntArrayTumorField(Mutect2FilteringEngine.java:235); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyMedianFragmentLengthDifferenceFilter(Mutect2FilteringEngine.java:106); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:228); 	at org.broadinstitute.hellbender.tools.walkers.mu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787:3702,wrap,wrapAndCopyInto,3702,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787,1,['wrap'],['wrapAndCopyInto']
Integrability,"6913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scratch space available for temporary directory and around 500GB of storage space available to hold outputs of GenomicsDBImport outputs. #### Actual behavior; Above error message indicating that disk quota has exceeded. I'm not exactly sure what's going on here as I am directing the outputs of the GenomicsDBImport runs to directories",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6950:1970,message,message,1970,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950,1,['message'],['message']
Integrability,6ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482:1236,Wrap,WrapperExecutor,1236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482,1,['Wrap'],['WrapperExecutor']
Integrability,7 <0> (Ã¸)` | :arrow_down: |; | [...bender/tools/walkers/annotator/PossibleDeNovo.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9Qb3NzaWJsZURlTm92by5qYXZh) | `73.214% <61.905%> (-2.976%)` | `23 <5> (+9)` | |; | [...er/tools/walkers/annotator/PedigreeAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9QZWRpZ3JlZUFubm90YXRpb24uamF2YQ==) | `89.189% <84.211%> (-6.463%)` | `13 <4> (+5)` | |; | [...ct/CreateSomaticPanelOfNormalsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `3.448% <0%> (-96.552%)` | `2% <0%> (-1%)` | |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | ... and [220 more](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462850860:3541,Integrat,IntegrationUtils,3541,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462850860,1,['Integrat'],['IntegrationUtils']
Integrability,78 INFO ProgressMeter - Starting traversal; 01:25:02.078 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File writing error; path=/lustre/scratch118/malaria/team112/personal/vr6/pf8-update/work/8e/c9ed494e9cd5d45835890fff4fa34c/Pf3D7_08_v3_33.bed.gdb/vidmap.json; errno=5(Input/output error); 01:25:43.661 INFO GenomicsDBImport - Starting batch input file preload; 01:26:19.244 INFO GenomicsDBImport - Finished batch preload; 01:26:19.244 INFO GenomicsDBImport - Importing batch 1 with 2 samples; 01:30:20.226 INFO ProgressMeter - unmapped 5.3 1 0.2; 01:30:20.226 INFO GenomicsDBImport - Done importing batch 1/1; 01:30:20.227 INFO ProgressMeter - unmapped 5.3 1 0.2; 01:30:20.227 INFO ProgressMeter - Traversal complete. Processed 1 total batches in 5.3 minutes.; 01:30:20.227 INFO GenomicsDBImport - Import of all batches to GenomicsDB completed!; 01:30:20.227 INFO GenomicsDBImport - Shutting down engine; [10 December 2021 01:30:20 UTC] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 7.76 minutes.; Runtime.totalMemory()=16078340096; ```. #### Steps to reproduce. Not sure if it reproducible with any particular imput... it seems that one has to simulate the IO errors for example by using a nearly full storage for the output or create some read-only conflicting file s. #### Expected behavior. No low-level error messages as the ones above... and that the output can be use for genotype-gvcfs without issue . #### Actual behavior. Error messages coming from the jni dependency. The tool finishes succesfully in apperance but the output file is missing some content render it unusable for VCF calling.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7598:5652,message,messages,5652,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7598,3,"['depend', 'message']","['dependency', 'messages']"
Integrability,"8.2; 23:10:12.683 INFO CountReadsSpark - Picard Version: 2.18.25; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:10:12.684 INFO CountReadsSpark - Deflater: IntelDeflater; 23:10:12.684 INFO CountReadsSpark - Inflater: IntelInflater; 23:10:12.684 INFO CountReadsSpark - GCS max retries/reopens: 20; 23:10:12.684 INFO CountReadsSpark - Requester pays: disabled; 23:10:12.684 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 23:10:12.685 INFO CountReadsSpark - Initializing engine; 23:10:12.685 INFO CountReadsSpark - Done initializing engine; 19/02/05 23:10:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/02/05 23:10:15 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 19/02/05 23:10:18 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(6,WrappedArray()); 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(13,WrappedArray()); 23:11:51.429 INFO CountReadsSpark - Shutting down engine; [February 5, 2019 11:11:51 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 1.67 minutes.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:6011,Wrap,WrappedArray,6011,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912,2,['Wrap'],['WrappedArray']
Integrability,"834861e7ae) [duplicate 3]; 2019-01-09 13:35:56 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-09 13:35:56 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 12.543 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:33839,Wrap,Wrappers,33839,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,"87608e8cadcb7b64f""><code>f000b7e</code></a> Fix merge conflict by adding optional label to proto2 unittest_lite.proto</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/4728531c162f2f9e8c2ca1add713cfee2db6be3b""><code>4728531</code></a> Add recursion check when parsing unknown fields in Java.</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/850fcce9176e2c9070614dab53537760498c926b""><code>850fcce</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b7044987de77f1dc368fee558636d0b56d7e75e1""><code>b704498</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/e67347986eaf7d777a6ee34367fa99f4912423ab""><code>e673479</code></a> Fix cord handling in DynamicMessage and oneofs. (<a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/18375"">#18375</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/8a60b6527a976cfd0028153da3ad8e4ed280e0de""><code>8a60b65</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.23.4...v3.25.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:1849,protocol,protocolbuffers,1849,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,1,['protocol'],['protocolbuffers']
Integrability,"8cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1225,wrap,wrapper,1225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,"92a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-09 13:35:56 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-09 13:35:56 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 12.543 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:33805,Wrap,Wrappers,33805,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,93YWxrZXJzL3Zxc3IvVHJhbmNoZU1hbmFnZXIuamF2YQ==) | `67.347% <0%> (-2.983%)` | `18% <0%> (+3%)` | |; | [...hellbender/utils/haplotype/HaplotypeBAMWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvSGFwbG90eXBlQkFNV3JpdGVyLmphdmE=) | `97.531% <0%> (-0.546%)` | `15% <0%> (+5%)` | |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `68.595% <0%> (-0.092%)` | `29% <0%> (+5%)` | |; | [...r/transformers/BaseQualityClipReadTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQmFzZVF1YWxpdHlDbGlwUmVhZFRyYW5zZm9ybWVyLmphdmE=) | `100% <0%> (Ã¸)` | `19% <0%> (+5%)` | :arrow_up: |; | [...hellbender/utils/haplotype/SAMFileDestination.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvU0FNRmlsZURlc3RpbmF0aW9uLmphdmE=) | `100% <0%> (Ã¸)` | `6% <0%> (+3%)` | :arrow_up: |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <0%> (Ã¸)` | `11% <0%> (?)` | |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <0%> (Ã¸)` | `12% <0%> (?)` | |; | ... and [14 more](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3398#issuecomment-319512377:3668,Adapter,AdapterTrimTransformer,3668,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3398#issuecomment-319512377,1,['Adapter'],['AdapterTrimTransformer']
Integrability,"944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:14:00 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 0.0 (TID 3, scc-q16.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 124511724, span 7265, expected MD5 cf58e0adc447a66b188474efc3c84a43; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:9765,Wrap,Wrappers,9765,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['Wrap'],['Wrappers']
Integrability,"96/76560439-85638880-6477-11ea-8d8d-f0f9a11d70a6.png). We can compare against the new workflow, in which we run SegmentJointSamples to jointly segment on the two mixtures. This yields a joint-sample segmentation with 162 segments, which can be passed as an additional input to individual ModelSegments runs on the two mixtures. It is used as the initial segmentation for both runs, after which the usual modelling and smoothing steps are performed. For the 75% tumor + 25% normal mixture, this yields 122 segments (up from 83):; ![N-25-T-75-SJS modeled](https://user-images.githubusercontent.com/11076296/76558618-015bd180-6474-11ea-996a-48d39770149b.png). For the 25% tumor + 75% normal mixture, this yields 105 segments (up from 50):; ![N-75-T-25-SJS modeled](https://user-images.githubusercontent.com/11076296/76560726-34a05f80-6478-11ea-9027-a54726c46b9e.png). One could imagine that smoothing could be disabled (so that all samples retain the common segmentation after modeling) or made more aggressive (so that private events don't get inadvertently introduced into other samples due to noise, perhaps), depending on the use case. It looks like the joint segmentation allows some additional events to be resolved, although I haven't done any rigorous evaluations. We could probably cook up some evaluations using simulated toy data or in silico mixtures, but there's really no reason why this shouldn't work decently well, especially if the kernel-segmentation method works well on a single sample for your data. It would also be interesting to understand at which point changing segmentation parameters on a single sample can no longer yield the same performance as joint segmentation on a fixed number of samples; however, this is probably a function of various S/N ratios, and it might not be easy to characterize this behavior outside of toy data. The segmentation parameter space is big enough to make this unwieldy even for toy data, too. Perhaps we can get some feedback from test users-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598386823:1859,depend,depending,1859,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598386823,1,['depend'],['depending']
Integrability,: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1435,wrap,wrapper,1435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,":+1: on this one from me, although I think we should eventually move away from use of `IntegrationTestSpec`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-245957788:87,Integrat,IntegrationTestSpec,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-245957788,1,['Integrat'],['IntegrationTestSpec']
Integrability,":00.557 INFO SplitNCigarReads - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:31:00.557 INFO SplitNCigarReads - Defaults.USE_CRAM_REF_DOWNLOAD : false; 15:31:00.558 INFO SplitNCigarReads - Deflater IntelDeflater; 15:31:00.558 INFO SplitNCigarReads - Initializing engine; 15:31:00.659 INFO SplitNCigarReads - Done initializing engine; 15:31:00.679 INFO ProgressMeter - Starting traversal; 15:31:00.679 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 15:31:05.088 INFO SplitNCigarReads - Shutting down engine; [July 20, 2016 3:31:05 PM EDT] org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=1011875840; Exception in thread ""main"" java.lang.NoClassDefFoundError: org/xerial/snappy/LoadSnappy; at htsjdk.samtools.util.SnappyLoader.<init>(SnappyLoader.java:86); at htsjdk.samtools.util.SnappyLoader.<init>(SnappyLoader.java:52); at htsjdk.samtools.util.TempStreamFactory.getSnappyLoader(TempStreamFactory.java:42); at htsjdk.samtools.util.TempStreamFactory.wrapTempOutputStream(TempStreamFactory.java:74); at htsjdk.samtools.util.SortingCollection.spillToDisk(SortingCollection.java:223); at htsjdk.samtools.util.SortingCollection.add(SortingCollection.java:166); at htsjdk.samtools.SAMFileWriterImpl.addAlignment(SAMFileWriterImpl.java:192); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:36); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:16); at htsjdk.samtools.util.AbstractAsyncWriter$WriterRunnable.run(AbstractAsyncWriter.java:117); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.ClassNotFoundException: org.xerial.snappy.LoadSnappy; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); ... 11 more; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2026:3828,wrap,wrapTempOutputStream,3828,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2026,1,['wrap'],['wrapTempOutputStream']
Integrability,:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); 18/10/17 19:23:59 ERROR Executor: Exception in task 518.0 in stage 0.0 (TID 518); java.io.FileNotFoundException: /home/data/WGS/F002/F002.sort.bam (Too many open files); 	at java.io.FileInputStream.open0(Native Method); 	at java.io.FileInputStream.open(FileInputStream.java:195); 	at java.io.FileInputStream.<init>(FileInputStream.java:138); 	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.<init>(RawLocalFileSystem.java:106); 	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:202); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:349); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.seqdoop.hadoop_bam.util.WrapSeekable.openPath(WrapSeekable.java:60); 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:147); 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:222); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:187); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:186); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:141); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:70); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:5448,Wrap,WrapSeekable,5448,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,1,['Wrap'],['WrapSeekable']
Integrability,":117,56,0,457,73,134,457,73,134,134 0/1:13,11,0,0:24:40:.:.:62,0,40,369,546,409,369,546,409,409 0/1:12,7,0,0:19:40:.:.:47,0,40,281,489,321,281,489,321,321 0/1:17,7,0,0:25:40:.:.:54,0,40,280,678,320,280,678,320,320 0/0:34,0,0,0:34:60 1/1:0,18,0,0:19:55:.:.:118,55,0,800,55,118,800,55,118,118 1/1:0,; ```; ```. at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:145); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:136); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8054:6525,wrap,wrapAndCopyInto,6525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8054,1,['wrap'],['wrapAndCopyInto']
Integrability,":16: error: 'isinf' was not declared in this scope; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:16: note: suggested alternative:; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/template.h:4,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/avx_function_instantiations.cc:3:; /usr/local/Cellar/gcc/5.3.0/include/c++/5.3.0/cmath:853:5: note: 'std::isinf'; isinf(_Tp __f); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/template.h:86:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/avx_function_instantiations.cc:3:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:38: error: 'isinf' was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive]; if (isinf(small) == -1 || isinf(big) == -1); ^; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:16: note: 'isinf' declared here, later in the translation unit; if (isinf(small) == -1 || isinf(big) == -1); ^. In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:2:0:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h: In instantiation of 'static NUMBER ContextBase<NUMBER>::approximateLog10SumLog10(NUMBER, NUMBER) [with NUMBER = double]':; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:57:5: required from 'NUMBER compute_full_prob(testcase*, NUMBER*) [with NUMBER = double]'; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:115:72: required from here; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:16: error: 'isinf' was not declared in this scope, and no decla",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343:4586,depend,dependent,4586,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343,1,['depend'],['dependent']
Integrability,":34:09 INFO TaskSetManager:54 - Lost task 3.1 in stage 0.0 (TID 4) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 1]; 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 7, scc-q12.scc.bu.edu, executor 2, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 WARN TaskSetManager:66 - Lost task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 3, start 97885291, span 192458, expected MD5 ef90368731b6e0be845bc82cd92b0c6a; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:30265,Wrap,Wrappers,30265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,":38 2023 -0500. minor pymc/pytensor version upgrades, fix 2-interval edge case, update some theano docs. commit 9c9d0c570dd2712631739e0a9d41e90c4ccd3456; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 23:36:55 2023 -0500. update VETS expected, verbose conda env create, pin torch CPU MKL, add pysam, fixed more tests. commit c0a17dfcf9fa1139927570d2f16125bc15a2c19f; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 20:07:08 2023 -0500. fix CNV plotting. commit dd2dd503a92e6fbb5a49be6a88d2e813eb8bf85b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 15:14:08 2023 -0500. update gCNV expected results, generated on WSL Ubuntu 20.04.2. commit 27d76e8f22d61df90eeb337e033ae128ce07ab90; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 14:53:04 2023 -0500. update python env integration tests. commit 348df9192235f7d1ea941d0b31e5c96acc0d6491; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 10:59:23 2023 -0500. disable CNN tests, add deprecation message. commit ed59372b4be226785af1d3fb1b1a39a9ad3b4f6a; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 09:55:24 2023 -0500. clean up rebase. commit 18e530db26f803ee46a0006843cb36d4ed4194b4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 11:31:46 2023 -0500. postprocess fixed. commit f510c2e9f10d7066c15f1835669d676964b8a4cb; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 10:13:01 2023 -0500. fix deprecated np.int in optimizer. commit 939a032f356f2f8f67b5aae426fc427d1d1ea6c4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:50:57 2023 -0500. remove unnecessary seeding in cohort denoising script. commit cf82ea5c99250f1784f8b1a9279e7dbb8841fa89; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:38:08 2023 -0500. add back setup.py files. commit 8348f546de6b3d32e1f02f6851730226c0dbffc9; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:37:09 2023 -0500. update pymc version in init. commit 85",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322:1622,message,message,1622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322,1,['message'],['message']
Integrability,":39:44 INFO org.spark_project.jetty.server.Server: Started @3988ms; 17/11/27 20:39:44 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@7fbe38a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/27 20:39:44 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/27 20:39:45 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at droazen-test-cluster-m/10.240.0.10:8032; 17/11/27 20:39:47 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1511814592376_0002; 17/11/27 20:39:52 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@7fbe38a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 20:39:52.363 INFO CountReadsSpark - Shutting down engine; [November 27, 2017 8:39:52 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=630718464; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:340); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89); 	at com.google.cloud.RetryHelper.run(RetryHelper.java:74); 	at com.google.cloud.RetryHelper.runWithRetries(Ret",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:5672,message,message,5672,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,1,['message'],['message']
Integrability,":45.460 WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:10:45.460 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 00:11:09.609 WARN TaskMemoryManager:381 - leak 166.6 MB memory from org.apache.spark.util.collection.ExternalAppendOnlyMap@60a3c432; 00:11:09.611 ERROR Executor:91 - Exception in task 15.0 in stage 1.0 (TID 519); java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:1810,wrap,wrapAndCopyInto,1810,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['wrap'],['wrapAndCopyInto']
Integrability,":49.226 INFO GenomicsDBImport - Done importing batch 2/5; 23 Feb 2022 18:26:19,107 DEBUG: 	18:26:19.105 INFO GenomicsDBImport - Done importing batch 3/5; 23 Feb 2022 19:20:18,500 DEBUG: 	19:20:18.478 INFO GenomicsDBImport - Done importing batch 4/5; 24 Feb 2022 16:51:19,017 DEBUG: 	[TileDB::utils] Error: (gzip_handle_error) Cannot decompress with GZIP: inflateInit error: Z_MEM_ERROR; 24 Feb 2022 16:51:19,048 DEBUG: 	[TileDB::Codec] Error: Could not decompress with GZIP.; 24 Feb 2022 16:51:19,056 DEBUG: 	[TileDB::ReadState] Error: Cannot decompress tile for /home/exacloud/gscratch/prime-seq/workDir/0950f56b-7565-103a-a738-f8f3fc8675d2/Job2.work/WGS_1852_consolidated.gdb/2$1$196197964/__e7217c9e-767d-4295-b75a-9162c22c6996139785909643008_1613563029631/END.tdb.; 24 Feb 2022 16:51:51,388 DEBUG: 	16:51:51.388 erro NativeGenomicsDB - pid=225263 tid=225739 VariantStorageManagerException exception : Error while consolidating TileDB array 2$1$196197964; 24 Feb 2022 16:51:51,405 DEBUG: 	TileDB error message : ; 24 Feb 2022 16:51:51,412 DEBUG: 	terminate called after throwing an instance of 'VariantStorageManagerException'; 24 Feb 2022 16:51:51,419 DEBUG: 	 what(): VariantStorageManagerException exception : Error while consolidating TileDB array 2$1$196197964; 24 Feb 2022 16:51:51,427 DEBUG: 	TileDB error message : ; 24 Feb 2022 16:52:27,478 WARN : 	process exited with non-zero value: 134; ```. Does that give anything to suggest troubleshooting steps?. The full command is:; ```; /home/exacloud/gscratch/prime-seq/java/java8/bin/java \; 	Xmx497g -Xms497g -Xss2m \; 	-jar /home/exacloud/gscratch/prime-seq/bin/GenomeAnalysisTK4.jar \; 	GenomicsDBImport \; 	-V 25780.g.vcf.gz \; 	-V <total of 92 gVCFs> \; 	--genomicsdb-update-workspace-path WGS_1852_consolidated.gdb \; 	--batch-size 10 \; 	--reader-threads 12 \; 	--consolidate \; 	--genomicsdb-shared-posixfs-optimizations \; 	--bypass-feature-reader \; 	-R 128_Mmul_10.fasta; ```. this is GATK v4.2.5.0. Thanks i advance for any ideas.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1050434022:2063,message,message,2063,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1050434022,2,['message'],['message']
Integrability,":745). 18/12/21 13:14:09 ERROR scheduler.TaskSetManager: Task 16 in stage 0.0 failed 4 times; aborting job; 13:14:09.675 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 1:14:09 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.97 minutes.; Runtime.totalMemory()=937426944; org.apache.spark.SparkException: Job aborted due to stage failure: Task 16 in stage 0.0 failed 4 times, most recent failure: Lost task 16.3 in stage 0.0 (TID 11, scc-q16.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). D",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:13341,Wrap,Wrappers,13341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['Wrap'],['Wrappers']
Integrability,; 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). **This is the stack I get when the test completes but fails (note that the expected line count appears to not match the line count of the expected output file in the repo): **. java.lang.AssertionError: line counts expected [2629] but found [507]; 	at org.testng.Assert.fail(Assert.java:94); 	at org.testng.Assert.failNotEquals(Assert.java:496); 	at org.testng.Assert.assertEquals(Assert.java:125); 	at org.testng.Assert.assertEquals(Assert.java:372); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:211); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:190); 	at org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.testExampleAssemblyRegionWalker(ExampleAssemblyRegionWalkerSparkIntegrationTest.java:29); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateR,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:3618,Integrat,IntegrationTestSpec,3618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['Integrat'],['IntegrationTestSpec']
Integrability,; 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.util.concurrent.ExecutionException: org.broadinstitute.hellbender.exceptions.GATKException: Expected message of length 3 but only found 0 bytes; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.waitForAck(StreamingProcessController.java:228); 	... 26 more; Caused by: org.broadinstitute.hellbender.exceptions.GATKException: Expected message of length 3 but only found 0 bytes; 	at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.getBytesFromStream(StreamingProcessController.java:261); 	at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.lambda$waitForAck$0(StreamingProcessController.java:208); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). but if I change memory as below: it works. ; qlogin -l s_vmem=20G -l mem_req=20G,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147:3928,message,message,3928,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147,1,['message'],['message']
Integrability,; 	at org.broadinstitute.hellbender.engine.ReferenceContext.getBases(ReferenceContext.java:197); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:236); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at org.broadinstitute.hellbender.engine.VariantWalker$$Lambda$76/1710491273.accept(Unknown Source); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:4926,wrap,wrapAndCopyInto,4926,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['wrap'],['wrapAndCopyInto']
Integrability,; 	at org.broadinstitute.hellbender.tools.walkers.variantutils.VariantsToTable.extractFields(VariantsToTable.java:362); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.VariantsToTable.apply(VariantsToTable.java:263); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); 	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEnt,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6897:5630,wrap,wrapAndCopyInto,5630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897,1,['wrap'],['wrapAndCopyInto']
Integrability,"; (...); [August 17, 2015 2:04:43 PM PDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=412090368; java.lang.IllegalArgumentException: end must be >= start. start:2801961 end:2801960; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$19(ReadWalker.java:64); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$50/1094674892.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:63); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:370); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:97); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:150); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.main(Main.java:86); jpmartin@hiseq:~/prog/GitHub/hellbender-main$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/828:1254,wrap,wrapAndCopyInto,1254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/828,1,['wrap'],['wrapAndCopyInto']
Integrability,"; - 317 remove excess header values in VCF extract (#7786); - correct auth in split intervals (#7790); - Add code to (optionally) zero pad the vcf filename. (#7783); - LoadData `maxRetries` parameterized, default increased [VS-383] (#7791); - Update to latest version of ah_var_store gatk override jar (#7793); - GvsUnified WDL to wrap the 6 core GVS WDLs [VS-382] (#7789); - Pinned typing_extensions python package to 4.1.1 to fix conda environment. (#7802); - WeightedSplitInterval fixes [VS-384] [VS-332] (#7795); - Replace Travis with GithubActions (#7754); - Docker build only lfs pulls main/src/resources/large (#7727); - Clean up gatk jars -- looks like we are not passing them properly in the extract (#7788); - Fix typo that broke git lfs pull (#7806); - Document AoU SOP (up to the VAT) [VS-63] (#7807); - Incident VS 365 clinvar classification fix (#7769); - VS-390. Add precision and sensitivity wdl (#7813); - Quickstart based integration test [VS-357] (#7812); - 365 vat python testing additions (#7756); - VS 396 clinvar grabs too many values (#7823); - Added a test to validate WDLs in the scripts directory. (#7826) (#7829); - VAT Performance / Reliability Improvements (#7828); - VAT naming conventions [VS-410] (#7827); - Rc remove ad from vat (#7832); - bugfix, we were trying to grep a binary file (#7837); - Cleanup scripts/variantstore [VS-414] (#7834); - Merge VAT TSV files into single bgzipped file [VS-304] (#7848); - Handle fully and partially loaded samples [VS-262] [VS-258] (#7843); - Ingest Error Handling Fixes [VS-261] (#7841); - First cut at a python notebook to validate inputs. (#7845); - Compute filter scatter [VS-392] (#7852); - remove withdrawn req (#7844); - Improve import error message [VS-437] (#7855); - Fix Input Validation python notebook (#7853); - Add VAT Validation check that aa_change and exon_number are consistently set. (#7850); - Ingest 10K [VS-344] (#7860); - X/Y chromosome reweighting for better extract shard runtime balance [VS-389] (#7868",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:23797,integrat,integration,23797,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['integrat'],['integration']
Integrability,"; 13:16:10.652 INFO gcnvkernel.tasks.inference_task_base -; Stderr: Traceback (most recent call last):; File ""/tmp/die9s/cohort_determine_ploidy_and_depth.861556744637254264.py"", line 106, in <module>; gcnvkernel.io_ploidy.PloidyModelWriter(ploidy_config, ploidy_workspace,; AttributeError: module 'gcnvkernel.io.io_ploidy' has no attribute 'PloidyModelWriter'. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.executeDeterminePloidyAndDepthPythonScript(DetermineGermlineContigPloidy.java:365); at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.doWork(DetermineGermlineContigPloidy.java:263); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. I also know that I should post errors in the GATK forum, but when I do this I get the following error message :; ``` { ""Code"": 403, ""Exception"": ""You need the Garden.Community.Manage permission to do that."", ""Class"": ""Gdn_UserException"" }```. Thanks in advance; Stefan",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4679:2256,message,message,2256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4679,1,['message'],['message']
Integrability,"; 2019-02-17 16:25:48 WARN TaskSetManager:66 - Lost task 179.0 in stage 5.0 (TID 1108, scc-q03.scc.bu.edu, executor 9): java.lang.IllegalArgumentException: provided start is negative: -2; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkCont",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:11469,Wrap,Wrappers,11469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['Wrap'],['Wrappers']
Integrability,"; 2019-02-17 16:25:48 WARN TaskSetManager:66 - Lost task 181.0 in stage 5.0 (TID 1113, scc-q03.scc.bu.edu, executor 9): java.lang.IllegalArgumentException: provided start is negative: -1; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkCont",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:5110,Wrap,Wrappers,5110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['Wrap'],['Wrappers']
Integrability,"; 2019-02-17 16:25:49 WARN TaskSetManager:66 - Lost task 186.0 in stage 5.0 (TID 1121, scc-q03.scc.bu.edu, executor 9): java.lang.IllegalArgumentException: provided start is negative: -5; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkCont",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:18629,Wrap,Wrappers,18629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['Wrap'],['Wrappers']
Integrability,"; Date: Wed Dec 13 00:14:34 2023 -0500. staged base rc1. commit 74f8fa724dfac142ccd7ac79a757c0e5ac3bb06c; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 13 00:01:38 2023 -0500. minor pymc/pytensor version upgrades, fix 2-interval edge case, update some theano docs. commit 9c9d0c570dd2712631739e0a9d41e90c4ccd3456; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 23:36:55 2023 -0500. update VETS expected, verbose conda env create, pin torch CPU MKL, add pysam, fixed more tests. commit c0a17dfcf9fa1139927570d2f16125bc15a2c19f; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 20:07:08 2023 -0500. fix CNV plotting. commit dd2dd503a92e6fbb5a49be6a88d2e813eb8bf85b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 15:14:08 2023 -0500. update gCNV expected results, generated on WSL Ubuntu 20.04.2. commit 27d76e8f22d61df90eeb337e033ae128ce07ab90; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 14:53:04 2023 -0500. update python env integration tests. commit 348df9192235f7d1ea941d0b31e5c96acc0d6491; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 10:59:23 2023 -0500. disable CNN tests, add deprecation message. commit ed59372b4be226785af1d3fb1b1a39a9ad3b4f6a; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 09:55:24 2023 -0500. clean up rebase. commit 18e530db26f803ee46a0006843cb36d4ed4194b4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 11:31:46 2023 -0500. postprocess fixed. commit f510c2e9f10d7066c15f1835669d676964b8a4cb; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 10:13:01 2023 -0500. fix deprecated np.int in optimizer. commit 939a032f356f2f8f67b5aae426fc427d1d1ea6c4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:50:57 2023 -0500. remove unnecessary seeding in cohort denoising script. commit cf82ea5c99250f1784f8b1a9279e7dbb8841fa89; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:38:08 2023 -0500. add back setup.py file",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322:1436,integrat,integration,1436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322,1,['integrat'],['integration']
Integrability,"; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31_01_20050601_V5.2, LmjF32_01_20050601_V5.3, LmjF33_01_20050601_V5.2, LmjF34_01_20050601_V5.2, LmjF35_01_20050601_V5.2, LmjF36_01_20050601_V5.2, LmjF07_01_20050601_V5.2, LmjF08_01_20050601_V5.2, LmjF09_01_20050601_V5.2, LmjF06_01_20050601_V5.2, LmjF12_01_20050601_V5.2, L",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:3508,MESSAGE,MESSAGE,3508,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,1,['MESSAGE'],['MESSAGE']
Integrability,"; and indicate how each API function is affected by this. If certain ; methods behave differently, then people writing code against SAMRecord ; need to anticipate this; and existing code may need to be updated. In other words, headerless ; SAMRecords should become ""part of the spec"". Third, although I don't know in detail about the different execution ; environments you are trying to support, there is a general strategy that ; I haven't seen discussed in these threads.; Perhaps it's impractical, but I'll mention it anyway. It seems like ; another approach would be to create (internal to the implementation) a ; ""header tag"" that could be efficiently serialized; and passed as part of the SAMRecord when you need to distribute it. The ; header tag could be used by the receiver to reattach the SAMRecord to ; its header (either proactively or on demand), but transparently to ; application code that is running against the SAMRecord API.; This would allow SAM headers to be transmitted out-of-band in a way that ; depends on the execution environment. Depending on the environment, ; this might be done by proactive broadcast, or you could think of the ; header tag as a promise to retrieve the header if/when it is needed. ; The size and complexity of the header tag might also depend on the ; execution environment. If the execution environment only supports a ; small finite number of headers, the header tag could be a small integer, ; or in a different execution environment it could be; a unique hash of the header or something like that. Memory footprint in ; the receiver is minimized because many SAMRecords can all share the same ; header object.; This requires more work to support in each execution environment, but it ; seems like it could be efficient and allows application code written to ; operate on SAMRecords to be portable; across different execution environments without having to contend with ; the possible presence of headerless SAMRecords. -Bob. On 9/17/15 4:28 PM, dr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518:1773,depend,depends,1773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518,1,['depend'],['depends']
Integrability,"; at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:50 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 4, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:50 WARN TaskSetManager:66 - Lost task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:26910,Wrap,Wrappers,26910,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,"; chr8; chr9; chr10; chr11; chr12; chr13; chr14; chr15; chr16; chr17; chr18; chr20; chr19; chr22; chr21; ```; and my reference file:; ```; zcat hg19.fa.gz|grep '>'; >chr1; >chr2; >chr3; >chr4; >chr5; >chr6; >chr7; >chrX; >chr8; >chr9; >chr10; >chr11; >chr12; >chr13; >chr14; >chr15; >chr16; >chr17; >chr18; >chr20; >chrY; >chr19; >chr22; >chr21; >chr6_ssto_hap7; >chr6_mcf_hap5; >chr6_cox_hap2; >chr6_mann_hap4; >chr6_apd_hap1; >chr6_qbl_hap6; >chr6_dbb_hap3; >chr17_ctg5_hap1; >chr4_ctg9_hap1; >chr1_gl000192_random; >chrUn_gl000225; >chr4_gl000194_random; >chr4_gl000193_random; >chr9_gl000200_random; >chrUn_gl000222; >chrUn_gl000212; >chr7_gl000195_random; >chrUn_gl000223; >chrUn_gl000224; >chrUn_gl000219; >chr17_gl000205_random; >chrUn_gl000215; >chrUn_gl000216; >chrUn_gl000217; >chr9_gl000199_random; >chrUn_gl000211; >chrUn_gl000213; >chrUn_gl000220; >chrUn_gl000218; >chr19_gl000209_random; >chrUn_gl000221; >chrUn_gl000214; >chrUn_gl000228; >chrUn_gl000227; >chr1_gl000191_random; >chr19_gl000208_random; >chr9_gl000198_random; >chr17_gl000204_random; >chrUn_gl000233; >chrUn_gl000237; >chrUn_gl000230; >chrUn_gl000242; >chrUn_gl000243; >chrUn_gl000241; >chrUn_gl000236; >chrUn_gl000240; >chr17_gl000206_random; >chrUn_gl000232; >chrUn_gl000234; >chr11_gl000202_random; >chrUn_gl000238; >chrUn_gl000244; >chrUn_gl000248; >chr8_gl000196_random; >chrUn_gl000249; >chrUn_gl000246; >chr17_gl000203_random; >chr8_gl000197_random; >chrUn_gl000245; >chrUn_gl000247; >chr9_gl000201_random; >chrUn_gl000235; >chrUn_gl000239; >chr21_gl000210_random; >chrUn_gl000231; >chrUn_gl000229; >chrM; >chrUn_gl000226; >chr18_gl000207_random; ```; So there is no contig in the SAM file itself that is not included in the reference. But I pre-filtered my SAM file using samtools, but there are some contigs in the header of SAM that does not exist in the reference. So it seems that this message comes from the header? I can also use the original reference used for mapping, which also contains e. coli genome.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684119509:2035,message,message,2035,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684119509,1,['message'],['message']
Integrability,"</a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b7044987de77f1dc368fee558636d0b56d7e75e1""><code>b704498</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/e67347986eaf7d777a6ee34367fa99f4912423ab""><code>e673479</code></a> Fix cord handling in DynamicMessage and oneofs. (<a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/18375"">#18375</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/8a60b6527a976cfd0028153da3ad8e4ed280e0de""><code>8a60b65</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.23.4...v3.25.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR aft",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:2347,protocol,protocolbuffers,2347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,1,['protocol'],['protocolbuffers']
Integrability,"</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:3132,Depend,Dependabot,3132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,<https://github.com/broadinstitute/gatk/issues/3853> is dependent on this issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-346106885:56,depend,dependent,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-346106885,1,['depend'],['dependent']
Integrability,"<img width=""745"" alt=""Screenshot 2023-11-14 at 12 44 24 AM"" src=""https://github.com/broadinstitute/gatk/assets/6863459/8390c9a8-f343-4c9b-9636-15b4dfc5aefa"">. Integration run:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/3aa1545f-7f11-4919-9ecf-8b3a5900441a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8581:159,Integrat,Integration,159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8581,1,['Integrat'],['Integration']
Integrability,"<ul>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/9d0ec0f92b5b5fdeeda11f9dcecc1872ff378014""><code>9d0ec0f</code></a> Updating version.json and repo version numbers to: 25.5</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/4a197e78ad2430e22e992c5a7727b61ae220f727""><code>4a197e7</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/18387"">#18387</a> from protocolbuffers/cp-lp-25</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b5a7cf7cf4b7e39f6b02205e45afe2104a7faf81""><code>b5a7cf7</code></a> Remove RecursiveGroup test case which doesn't exist in 25.x pre-Editions</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/f000b7e18fd6921ca02ea4b87608e8cadcb7b64f""><code>f000b7e</code></a> Fix merge conflict by adding optional label to proto2 unittest_lite.proto</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/4728531c162f2f9e8c2ca1add713cfee2db6be3b""><code>4728531</code></a> Add recursion check when parsing unknown fields in Java.</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/850fcce9176e2c9070614dab53537760498c926b""><code>850fcce</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b7044987de77f1dc368fee558636d0b56d7e75e1""><code>b704498</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/e67347986eaf7d777a6ee34367fa99f4912423ab""><code>e673479</code></a> Fix cord handling in DynamicMessage and oneofs. (<a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/18375"">#18375</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/8a60b6527a976cfd0028153da3ad8e4ed280e0de""><code>8a60b65</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:1075,protocol,protocolbuffers,1075,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,1,['protocol'],['protocolbuffers']
Integrability,====================; Files 1058 1057 -1 ; Lines 59682 59712 +30 ; Branches 9712 9723 +11 ; ===============================================; + Hits 46584 46879 +295 ; + Misses 9349 9078 -271 ; - Partials 3749 3755 +6; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4152?src=pr&el=tree) | Coverage Î” | Complexity Î” | |; |---|---|---|---|; | [...hellbender/utils/linalg/FourierLinearOperator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9saW5hbGcvRm91cmllckxpbmVhck9wZXJhdG9yLmphdmE=) | `78.378% <Ã¸> (Ã¸)` | `12 <0> (Ã¸)` | :arrow_down: |; | [...bender/utils/GATKProtectedVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HQVRLUHJvdGVjdGVkVmFyaWFudENvbnRleHRVdGlscy5qYXZh) | `65.746% <0%> (Ã¸)` | `61 <0> (Ã¸)` | :arrow_down: |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `95.238% <100%> (Ã¸)` | `5 <0> (Ã¸)` | :arrow_down: |; | [...bender/tools/walkers/annotator/StrandArtifact.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRBcnRpZmFjdC5qYXZh) | `100% <100%> (Ã¸)` | `29 <0> (Ã¸)` | :arrow_down: |; | [...llbender/tools/walkers/annotator/ReadPosition.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SZWFkUG9zaXRpb24uamF2YQ==) | `100% <100%> (Ã¸)` | `8 <2> (Ã¸)` | :arrow_down: |; | [...s/copynumber/models/AlleleFractionLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4152#issuecomment-357485658:1571,Integrat,IntegrationUtils,1571,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4152#issuecomment-357485658,1,['Integrat'],['IntegrationUtils']
Integrability,"=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/broadinstitute/gatk/network/alerts). </details>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:3768,depend,dependabot,3768,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,11,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,> * `gatk_override`. this will need to be a parameter (but can be optional and have a default) in order to have our integration tests run `GvsJointVariantCalling.wdl` anyway. > * `interval_list`. this will need to be a parameter (but can be optional and have a default) in order to have our integration tests run `GvsJointVariantCalling.wdl` on exomes. > * `use_VQSR_lite`; > * `extract_do_not_filter_override`. these two will need to be a parameter (but can be optional and have a default) in order to have our integration tests run `GvsJointVariantCalling.wdl` with VQSR classic anyway. > * `filter_set_name`; > * `extract_table_prefix`. these two can just default to the `call_set_identifier` with weird characters parsed out,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1634174283:116,integrat,integration,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1634174283,3,['integrat'],['integration']
Integrability,"> > I've manually kicked off our integration tests on this branch. If that passes (it should take a couple of hours), I'll give this a thumb.; > ; > SG! I also pushed this to Agora and will test it out using our genomic extraction workflow. our error is resolved with this PR",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9023#issuecomment-2447390883:33,integrat,integration,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9023#issuecomment-2447390883,1,['integrat'],['integration']
Integrability,"> @Siadjeu Don't worry about the ""Failed to detect"" message. It indicates some internal state in one of the google libraries but not an error we need to worry about. Generally you shouldn't worry about INFO messages if everything else is going fine and they don't say something particular about what you're doing. A WARNING or ERROR message would indicate a problem. This should maybe be downgraded to be a DEBUG level message or something but it's in a third library and convincing them to change it might be a hassle. Although there are results, but the size of the results is wrong, the results are too small.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-1598239834:52,message,message,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-1598239834,4,['message'],"['message', 'messages']"
Integrability,"> @colinhercus I was able to re-run your command successfully on the latest master branch (not in a release yet). I believe PR #6240 fixed the issue. @Rohit-Satyam @danielecook there's a good chance the errors you encountered are also fixed. If not, please let me know. In reference to your reply, I wish to inform you the problem still stands. > java.lang.IllegalArgumentException: Cannot construct fragment from more than two reads; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:725); at org.broadinstitute.hellbender.utils.read.Fragment.create(Fragment.java:36); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1376); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.groupEvidence(AlleleLikelihoods.java:595); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:93); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:251); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:320); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:281); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLinePro",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595805643:860,wrap,wrapAndCopyInto,860,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595805643,1,['wrap'],['wrapAndCopyInto']
Integrability,"> Can has! Please ignore the confusingness of the branch name ðŸ™ˆ; > https://job-manager.dsde-prod.broadinstitute.org/jobs/245e1b69-a628-41c0-8e64-ebd3ae37ce30. Sorry if this is a dumb question, but how do I verify that the new image is being used since we can't see the WDLs of the subworkflows that are being called by the integration WDL?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8085#issuecomment-1307363971:323,integrat,integration,323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8085#issuecomment-1307363971,1,['integrat'],['integration']
Integrability,"> Chris Norman. >Well, its a fair amount of work to do in the current htsjdk (there are some details in the ticket.). We recently have been discussing some possible options, but right now there is no work scheduled. If its an isue for you Iâ€™d suggest updating the ticket so we can keep track of how much demand there is for it. Consider this me updating the ticket because my key software depends on parsing VCFs with this API.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2602#issuecomment-476776569:389,depend,depends,389,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2602#issuecomment-476776569,1,['depend'],['depends']
Integrability,"> GATK depends on gradle 3.1.: download shaw256. It currently works with gradle-4.6, no need to go back to 3.1.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444210781:7,depend,depends,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444210781,1,['depend'],['depends']
Integrability,"> Hey @ccartermices. Looking at that error message it appears that the genotype given alleles has tried to insert a '*' allele into an assembled haplotype. (""TTTTGAC*TTCGC"" in the error message). I suspect this is because the code is missing a check to filter symbolic alleles out of GGA inputs. Can you check your input `db_raw_call_bbe_6largest.vcf` for `\*` alleles? It should be possible to filter those out of your input file. Thanksï¼Œif i want to make a filter on it, should i use which tool? VQSR?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6260#issuecomment-553776381:43,message,message,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6260#issuecomment-553776381,2,['message'],['message']
Integrability,"> How can I install GATK4 successful?. If you just want to install (as opposed to build), you can download a [release .zip or .tar](https://github.com/broadinstitute/gatk/releases) directly. If you want to build, then as @magicDGS suggested, you need to have git-lfs installed. If you already have that, I would try manually running the command `git lfs pull --include src/main/resources/large` from the root of the repo clone and see if you get a more detailed failure message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4669#issuecomment-382363528:470,message,message,470,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4669#issuecomment-382363528,1,['message'],['message']
Integrability,> I also encounter this error when most samples have been imported. I ran importing in batches '--batch-size 50 --consolidate '. The error occured at the last batch. Can I reuse some of the imported data files or have to rerun the whole importing again?. ...; 13:13:26.069 INFO GenomicsDBImport - Done importing batch 21/22; 13:13:26.069 INFO GenomicsDBImport - Starting batch input file preload; 13:13:27.440 INFO GenomicsDBImport - Finished batch preload; 13:13:27.440 INFO GenomicsDBImport - Importing batch 22 with 22 samples; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; terminate called after throwing an instance of 'VariantStorageManagerException'; what(): VariantStorageManagerException exception : Error while consolidating TileDB array chrY$1$57227415; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6519#issuecomment-641091886:890,message,message,890,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6519#issuecomment-641091886,1,['message'],['message']
Integrability,"> I have no objection to these changes, especially since this is just bringing us back to where we were in genomicsDB in the last release. We should spawn a ticket to track reintroducing these improvements and perhaps we should also add a macos test to our travis array so we can catch this kind of issue in the future? I think there is a macOS VM availible on travis that we could rerun some of the integration tests on. Yes, travis has macOS VM. It is very slow, so would recommend only sanity checks on it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6204#issuecomment-539574124:400,integrat,integration,400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6204#issuecomment-539574124,1,['integrat'],['integration']
Integrability,"> I've manually kicked off our integration tests on this branch. If that passes (it should take a couple of hours), I'll give this a thumb. SG! I also pushed this to Agora and will test it out using our genomic extraction workflow",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9023#issuecomment-2447173093:31,integrat,integration,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9023#issuecomment-2447173093,1,['integrat'],['integration']
Integrability,"> In case mode you already have the filtered intervals, so why collect coverage over the full set?. Since coverage collection is relatively expensive, it's better to collect coverage over the same set of intervals for all samples just once and call it a day. Then we can run these samples in whatever mode we please, adjust filtering parameters, etc. in subsequent analyses without having to go back and recollect coverage at any point. > Also, in cnv_germline_case_workflow.wdl it really doesn't look like ploidy determination uses the filtered intervals. Are the intervals wrapped into the model tar there too? If that's true, then that should be documented somewhere. Yup, that's correct. Added some more docs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5307#issuecomment-431494002:575,wrap,wrapped,575,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5307#issuecomment-431494002,1,['wrap'],['wrapped']
Integrability,"> In this case, allele-specific annotations are outputted to GVCFs files by 'HaplotypeCaller -ERC GVCF -G AS_StandardAnnotation' command.; > ; > Although some warning message of 'HaplotypeCaller -ERC GVCF -G AS_StandardAnnotation' command.; > ; > ```; > WARN:StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; > ```; > ; > This warning message does not happen in all of my cases, but the FORMAT/AD error happen in all of my cases. hello , i met the warning message:; `DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null`; `WARN:StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null`. could you help me ? i just am a fresh . So i don't know what should i do next step and why it reported some warning messages. ; Thank you very much !",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4691#issuecomment-727523636:167,message,message,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4691#issuecomment-727523636,4,['message'],"['message', 'messages']"
Integrability,"> Is it possible to add an integration test to this? Since the change did not fail any test, it seems that the integrationtest is missing. Unit test fixed to include checking of variant type (which it did not include before - hence the non-failure). Test data adjusted accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8442#issuecomment-1806779412:27,integrat,integration,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8442#issuecomment-1806779412,2,['integrat'],"['integration', 'integrationtest']"
Integrability,> Is there a successful integration run?. yes [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/6c033078-f6d3-47c8-926a-07176478823d),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8915#issuecomment-2245636330:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8915#issuecomment-2245636330,1,['integrat'],['integration']
Integrability,"> It gives us the ability to easily aggregate records across multiple FeatureInputs, and (potentially, if we wanted) to retrieve records by type rather than by source. Regardless of doing full injection FeatureContext seems rather unnecessary to me; the query ability that you mention is provided by FeatureManger on which the FeatureContext delegates on given the genomeLoc of the locus or read.... I don't see why the tool cannot be exposed to FeatureManager directly. Is this done to make sure that walkers are of the right type? I mean if you are working on aread walker and you need to look for information beyond the read's genomeLoc that means that you must consider a different walker type or develop a new one?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76763116:193,inject,injection,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76763116,1,['inject'],['injection']
Integrability,"> Looks good. Have you run the integration tests. I didn't run the integration test because it didn't seem necessary (no changes that effect the data, just the table(s) TTL). If you think I should, happy to kick it off.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8595#issuecomment-1834388772:31,integrat,integration,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8595#issuecomment-1834388772,2,['integrat'],['integration']
Integrability,"> One final thing: i'm happy to try to debug this, and was going to write a test case based on the existing GenomicsDB integration tests. However, when I try to run any integration test involving genomicsdb, I get an exception like the following. I am on windows, so perhaps this is the issue?; > ; > 09:03:37.460 FATAL GenomicsDBLibLoader -; > java.io.FileNotFoundException: File /tiledbgenomicsdb.dll was not found inside JAR.; > at org.genomicsdb.GenomicsDBLibLoader.loadLibraryFromJar(GenomicsDBLibLoader.java:118) ~[genomicsdb-1.3.2.jar:?]; > at org.genomicsdb.GenomicsDBLibLoader.loadLibrary(GenomicsDBLibLoader.java:55) [genomicsdb-1.3.2.jar:?]; > at org.genomicsdb.GenomicsDBUtilsJni.(GenomicsDBUtilsJni.java:30) [genomicsdb-1.3.2.jar:?]; > at org.genomicsdb.GenomicsDBUtils.createTileDBWorkspace(GenomicsDBUtils.java:46) [genomicsdb-1.3.2.jar:?]; > at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.overwriteCreateOrCheckWorkspace(GenomicsDBImport.java:1005) [classes/:?]; > at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.onTraversalStart(GenomicsDBImport.java:661) [classes/:?]; > at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1056) [classes/:?]. Yes, Windows is not supported by GenomicsDB. This is mentioned obliquely in the requirements for gatk too -; ```; Operating system. The GATK runs natively on most if not all flavors of UNIX, which includes MacOSX, Linux and BSD. It is possible to get it ; running on some recent versions of Windows, but we don't provide any support nor instructions for that. If you need to run on; a Windows machine, consider using Docker.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7005#issuecomment-754106359:119,integrat,integration,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7005#issuecomment-754106359,2,['integrat'],['integration']
Integrability,"> Since the reads come off the aligner sorted by name, this would spare us at least one shuffle (the group by name). We could then probably get away with just a single join on position (either individual position or the concatenation of position + mate position, depending on whether each read is paired) to make the rest of the existing algorithm work. Over in https://github.com/broadinstitute/hellbender/pull/889 I was suggesting that the treatment of fragments and pairs could be unified to remove a shuffle, so it looks like we could get down to one shuffle overall for MD, which would be great.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/863#issuecomment-140135545:263,depend,depending,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/863#issuecomment-140135545,1,['depend'],['depending']
Integrability,"> The point of the singleton pattern is for testing: tests can substitute their own instance instead of the default one. They put in a mock that doesn't need to call out to the internet - this way it's both faster and self-contained (as unit tests are supposed to be). Using a singleton should not be needed, since mocks are sufficient in this case. I think the difficulty is that there are two objects, `RefAPISource` and `RefAPIMetadata`, which need managing separately. The need for a singleton disappears if the objects are combined into one, e.g. by subsuming `RefAPIMetadata` into `RefAPISource`. Then the issue may be that you want to ensure that the lookup table is not recreated too often (since it is expensive), but I think that can be solved by ensuring that there is a single instance in a test (by using TestNG's `@BeforeClass`). > We still need some way to stub, because there are places deep in the code that call RefApiSource.getInstance(). This goes away if you remove the need for a singleton, like in this PR. > We could have a getDataflowInstance() and a getSparkInstance() - the former would normally return the code formerly known as RefApiSource, except if tests set up the mock. . I think it's better to have a uniform interface to get references, so that callers don't need to know if the reference is being retrieved via the Google API, a file on HDFS, or a local file. This is what `ReadsDataflowSource` does for reads; `ReferenceHadoopSource` from this PR does a similar thing for references.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/804#issuecomment-130827161:1244,interface,interface,1244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/804#issuecomment-130827161,1,['interface'],['interface']
Integrability,> Those warning messages are totally fine. Not all variant contexts contain those 2 annotations therefore they are not counted against those sites but other parameters are counted. The results also shows that your filtering is working and variants are marked as expected. Thank you very much!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8964#issuecomment-2312349275:16,message,messages,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8964#issuecomment-2312349275,1,['message'],['messages']
Integrability,"> Your solution doesn't address your third listed drawback to the current; approach. Ah, but I believe it does if you're careful. We have this code:; ```; for ( final AssemblyResult result : assemble(correctedReads, refHaplotype, givenHaplotypes, header, aligner) ) {; if ( result.getStatus() == AssemblyResult.Status.ASSEMBLED_SOME_VARIATION ) {; // do some QC on the graph; sanityCheckGraph(result.getGraph(), refHaplotype);; // add it to graphs with meaningful non-reference features; assemblyResultByGraph.put(result.getGraph(),result);; nonRefGraphs.add(result.getGraph());; }; }. findBestPaths(nonRefGraphs, refHaplotype, refLoc, activeRegionExtendedLocation, assemblyResultByGraph, resultSet, aligner);; ```; If assembly fails eg due to cycles at every kmer then there's nothing to iterate over in the `for` loop but it still reaches `findBestPaths` (this puts assembled haplotypes into `resultSet` as a side effect, and it forces the reference haplotype in by fiat if there are no graphs). As long as the new GGA haplotypes are added after `findBestPaths` and not anywhere inside the `assemble` method or in that `for` loop it should be okay. Would you like me to write an integration test for this case?. > It's not obvious to me why we wanted the given alleles in the graph; originally. . . Regardless of the reason, I think the new proposal captures any benefit of putting them in the graph, because if they *are* in the graph it leaves them alone. If they're not in the graph, then we get a haplotype that's as close to the reference as possible, which is what the current code does. In such a case there's nothing gained by putting it in the graph. > I'd feel better if we had a better guess at what the original method was trying to do. Despite my optimism about theoretically beautiful things, me too. Who wrote the original GGA code?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479931906:1181,integrat,integration,1181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479931906,1,['integrat'],['integration']
Integrability,"> actually it looks like there are legit failing tests. Yup, it looks like a hunk of the integration tests are operating in TSV mode (which we don't officially support any longer... but I suppose they can stay). So in order to make those pass, I had to put some things behind an explicit check for BQ being set as the output type",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2457960879:89,integrat,integration,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2457960879,1,['integrat'],['integration']
Integrability,"> do you have a run of the integration test for this branch?. Yup, [this run](https://app.terra.bio/#workspaces/broad-firecloud-dsde/VS-415%20GVS%20Quickstart%20Default%20Extract%20Scatter/job_history/ff9d7466-79f1-4c96-a7b9-dd2354dc1c76) utilized this `vs_464_update_quickstart_integration` branch to test the `vs_415_default_extract_scatter_width` changes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7881#issuecomment-1150403388:27,integrat,integration,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7881#issuecomment-1150403388,1,['integrat'],['integration']
Integrability,">--af_of_alleles_not_in_resource: is this allele frequency used only in certain contexts, e.g. with matched normal analyses, or towards tumor sample variant alleles, etc.? I need to add to the doc details how this argument factors into calculations. This is the population AF assigned to a variant not found in the germline resource and is inversely proportional to the number of samples used to create that resource. For example, gnomAD contains about 16,000 wgs samples, or 32,000 homologs per locus. Thus the AF of an allele not found in gnomAD is probably 1/32,000 or less. This is useful because it lets us use absence from the germline resource as evidence that an allele is *not* a germline variant. >I need a sentence or two describing the new algorithmic improvement on the new Mutect2 integration over uncertainty. Since allele depths (ADs) are subject to statistical error -- i.e. the exact number of reads for an allele is a random variable -- alleles' allele fractions are not known. Previously, M2 estimated allele fractions ffrom the ADs and proceeded with the likelihoods calculation. Now M2 uses nifty math to account for the uncertainty in the allele fraction when calculating likelihoods. In statistical language (which *will* be familiar to a decent-sized minority of users) we marginalize over allele fractions instead of using a maximum likelihood estimate. >The WDLs do not include use of a contamination.table and so I did not include it in the commands. Is this something we want to nudge users to use, i.e. should I put in a sentence in the documentation section about the new tool CalculateContamination?. `CalculateContamination` is invoked inside the `Filter` task in mutect2.wdl. We want users to use the new tool. You might mention that in the interest of speed you can pass it `-L 1` to use only variants on chromosome 1, which gives a very good estimate in a couple of minutes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2816#issuecomment-306107618:795,integrat,integration,795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2816#issuecomment-306107618,1,['integrat'],['integration']
Integrability,">> interval_list. > this will need to be a parameter (but can be optional and have a default) in order to have our integration tests run GvsJointVariantCalling.wdl on exomes. Genomes too, the integration test specifies a 20/X/Y interval list. >> filter_set_name; >> extract_table_prefix. > these two can just default to the call_set_identifier with weird characters parsed out. Yeah I think that would work for the integration test(s), each variation goes into a different BQ dataset anyway. @RoriCremer can correct me if I'm wrong, but I thought the raison d'Ãªtre of the beta WDL was specifically to hardcode away as many parameters as possible (even optional ones with defaults) to present a simplified interface for non-expert users. I agree we'll probably have to allow some additional parameters for testability (`gatk_override` at a minimum), but do we really want to add all of these?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1634248008:115,integrat,integration,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1634248008,4,"['integrat', 'interface']","['integration', 'interface']"
Integrability,">Integration test plz. Hmm, the existing integration test does not exercise `process_vcf_headers` so it wouldn't test these changes. However, in the spirit of ""the VDS integration tests should exercise what we intend to use for AoU"", perhaps at least the VDS integration tests should be modified to exercise this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8533#issuecomment-1739135880:1,Integrat,Integration,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8533#issuecomment-1739135880,4,"['Integrat', 'integrat']","['Integration', 'integration']"
Integrability,"@DanishIntizar Hello! Thank you for this pr. This is great to see an official plugin from amazon available. I appreciate that you took the time to make it an optional include. I think if we're going to include it we might as well just add it as one of our normal dependencies though. Assuming there aren't any dependency conflicts it **should** (always a risky statement) be independent from everything else. . Thanks also for identifying the different issues you mentioned. It's expected that it won't work with most picard tools as you discovered, but we're actively in the process of updating more of them too support Paths instead of Files so that will slowly improve. The second issue is more worrisome. We regularly use an equivalent provider with google to read reference files through the exact same code, so I suspect there is either some sort of mismatched assumptions in the way they are handling things. Maybe something strange with the Path.resolve methods or the like. (Or in in the much worse potential case a bug in their look ahead caching.). I'd like to look into that before we'd merge this. Ideally we would have tests for this. Are there any public AWS paths we could read from without any secret authentication?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8672#issuecomment-1930094721:263,depend,dependencies,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8672#issuecomment-1930094721,2,['depend'],"['dependencies', 'dependency']"
Integrability,@DonFreed Both of these changes look more correct than what we were doing before. But as louis pointed out two of the integration tests failed on parsing the header. You should fix these tests.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324062155:118,integrat,integration,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324062155,1,['integrat'],['integration']
Integrability,"@DonFreed, I agree with @magicDGS's assessment about it. This feels like a fix that was applied to Gatk3 but doesn't translate to 4? Of course, there could be implementations of GATKRead that don't obey the given contract about copying, but it's worth fixing those since we were more careful to think about copy/no copy when we wrote the new interface. . Of note: if you haven't seen it, `GATKRead` provides a set of unsafe `getBaseQualitiesNoCopy()` methods for times when the copy is a performance bottleneck and you can guarantee safe use of the underlying array. . I'm going to close this. Feel free to reopen if you disagree / can provide a unit test that demonstrates the issue still exists.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4926#issuecomment-399219562:213,contract,contract,213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4926#issuecomment-399219562,2,"['contract', 'interface']","['contract', 'interface']"
Integrability,"@EdwardDixon Isn't this a dupe of https://github.com/broadinstitute/gatk/pull/5142? Have you addressed our original concerns from that PR's discussion thread, some of which I've reproduced below?. ```; droazen commented on Aug 30; @EdwardDixon We have a fair number of GATK users who are stuck with older hardware (including; university clusters that they have no power to upgrade), and we can't just cut these users off by ; imposing such a minimum hardware requirement. The best we can do is to use AVX when it's ; available, and fall back to slower codepaths when it's not. Also, actual crashes in native code impose a significant support burden on our comms team, as they; are often hard to diagnose and deal with. Things like SIGSEGV or SIGILL are a nightmare for our ; support staff. At a minimum we'd need a graceful failure with an easy-to-understand error message; when AVX is not present rather than a crash, before we could make this the default in GATK. ldgauthier commented on Aug 30; Aside from the users with old hardware, very few of the GCS zones guarantee processors that ; support AVX, which would lead to sporadic failures except in central-1f, for example.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-428265950:865,message,message,865,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-428265950,1,['message'],['message']
Integrability,"@EdwardDixon Thanks for trying this - it would be great if we were able to have a single conda env, but a couple of questions:. - We'd need to understand the affect of this change on our build times. It looks like the travis builds are failing because the dependency downloads are resulting in so many progress messages that we're exceeding the allowable log length, probably because the download is either large or slow. I'm not sure if thats transient or not.; - We try to carefully control the size of our (already sizable) docker image. We'll need to understand how this impacts that.; - @lucidtronix Any thoughts on moving from tensorflow 1.4 to 1.9 ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-416943910:256,depend,dependency,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-416943910,2,"['depend', 'message']","['dependency', 'messages']"
Integrability,"@EdwardDixon We have a fair number of GATK users who are stuck with older hardware (including university clusters that they have no power to upgrade), and we can't just cut these users off by imposing such a minimum hardware requirement. The best we can do is to use AVX when it's available, and fall back to slower codepaths when it's not. Also, actual crashes in native code impose a significant support burden on our comms team, as they are often hard to diagnose and deal with. Things like `SIGSEGV` or `SIGILL` are a nightmare for our support staff. At a minimum we'd need a graceful failure with an easy-to-understand error message when AVX is not present rather than a crash, before we could make this the default in GATK.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417383038:630,message,message,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417383038,1,['message'],['message']
Integrability,"@EdwardDixon Well, you'd be surprised at some of the hardware we have to deal with. Even some machines here at the Broad don't have AVX. In general, our policy with hardware-dependent optimizations in GATK has been to insist on having a transparent fallback mechanism when the required hardware isn't present -- I'd really prefer not to start making exceptions to that rule. Could the Intel-optimized Tensorflow be patched to fall back to vanilla tensorflow when AVX is not present? Is that an option? Or could it at least be patched to not actually crash in that case?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417073151:174,depend,dependent,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417073151,1,['depend'],['dependent']
Integrability,"@Emmalynchen I wouldn't worry about the `log4j:WARN` messages discussed in this thread---they're just harmless annoyances that pop up because we haven't gotten around to making sure the HDF5Library dependency uses the same logger as the rest of the GATK. Looking at your initial post (before you edited it), it looks like DenoiseReadCounts is failing because the panel of normals contains different intervals than those in the read-count collection you are trying to denoise:. ```; 22:50:58.635 INFO SVDDenoisingUtils - Validating sample intervals against original intervals used to build panel of normals...; 22:50:59.487 INFO DenoiseReadCounts - Shutting down engine; [May 7, 2019 10:50:59 PM UTC] org.broadinstitute.hellbender.tools.copynumber.DenoiseReadCounts done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=894959616; java.lang.IllegalArgumentException: Sample intervals must be identical to the original intervals used to build the panel of normals.; ```. You might try asking for more pointers over in the GATK Forums (https://gatkforums.broadinstitute.org/gatk), if you need them. Good luck!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3763#issuecomment-491473550:53,message,messages,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3763#issuecomment-491473550,2,"['depend', 'message']","['dependency', 'messages']"
Integrability,"@Ismaelfermir The message about ""Flush-to-zero"" is normal, and not an error. The problem is likely that your BAM doesn't have read groups in its header, or if it does, those read groups may lack sample names.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4665#issuecomment-486384034:18,message,message,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4665#issuecomment-486384034,1,['message'],['message']
Integrability,@LeeTL1220 Added in a specific integration test for the `FILTER` field. Also rebased on master to fix the unrelated R test failures.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341:31,integrat,integration,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341,1,['integrat'],['integration']
Integrability,"@LeeTL1220 Can you review, or appoint someone to review, the Mutect2 WDL and the tools/exome and tools/picard/analysis/artifacts packages part of this. Basically, I replaced most of the classes in the artifacts package with their Picard analogs, which also affected some embedded class names in metrics files (SequencingArtifactMetrics IIRC). The are multiple commits in here that delete various things, but the substantive changes are the last commit (""Integrate actual Picard tools via Picard""). Also, once this is in, we'll probably want to do [this](https://github.com/broadinstitute/gatk/issues/3625) separately as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3620#issuecomment-332637122:454,Integrat,Integrate,454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3620#issuecomment-332637122,1,['Integrat'],['Integrate']
Integrability,@LeeTL1220 Does GATK have a dependency on this change ? If so this will definitely need to be made in Picard as well since these GATK copies of the Picard tool are soon to be obsoleted.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3250#issuecomment-315760322:28,depend,dependency,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3250#issuecomment-315760322,1,['depend'],['dependency']
Integrability,"@LeeTL1220 I have a fast python implementation of the above. It'll take a little bit of additional code to make it output segment files. I can add that and start running some validation data, or I can just go ahead and start coding up the Java implementation, depending on how long you think it'll take to put together some validation runs up through DenoiseReadCounts. Do we want to improve the ReCapSegCaller behind CallSegments while we're at it? @davidbenjamin perhaps you can briefly remind me of the idea behind your initial caller and of the issues it had.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324128827:260,depend,depending,260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324128827,1,['depend'],['depending']
Integrability,@LeeTL1220 I will merge now and open a separate ticket to update the multi sample wdl and all wdls that depend on it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3386#issuecomment-319074608:104,depend,depend,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3386#issuecomment-319074608,1,['depend'],['depend']
Integrability,"@LeeTL1220 Just noticed integration tests are failing...perhaps I should continue reviewing, and you can address comments and the tests at the same time?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4205#issuecomment-358979126:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4205#issuecomment-358979126,1,['integrat'],['integration']
Integrability,"@LeeTL1220 OK, tweaked the message a bit. I think I'm OK with this going in for the next point release. This is the sort of thing for which it will be nice to have the automatic validations, as a sanity check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979:27,message,message,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979,1,['message'],['message']
Integrability,"@LeeTL1220 This consists of a lot of trivial changes where the commit message is self-explanatory, most of which (eg indentation) yield big diffs. Basically it comes down to:; * M2 wdls have better formatting; * autoval works in the cloud; * gatk launch script and docker jar are used properly in all M2 wdls, including the unsupported ones.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4132:70,message,message,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4132,1,['message'],['message']
Integrability,@LeeTL1220 This fixes the bug preventing Beri from updating to 4.0.8.0. I will put in an integration test but could you start looking at it now?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5121:89,integrat,integration,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5121,1,['integrat'],['integration']
Integrability,"@LeeTL1220 This fixes the issue. I tested it on SGE and the M2 integration tests now have a DREAM bam where I switched the sample to ""tumor sample"".",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4360:63,integrat,integration,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4360,1,['integrat'],['integration']
Integrability,"@LeeTL1220 commented on [Mon Feb 01 2016](https://github.com/broadinstitute/gatk-protected/issues/343). In `CreatePanelOfNormals` make anonymize a flag that defaults to `false`. (i.e. `--anonymize`) In other words, by default, we do _not_ produce an anonymized PoN. We could also use a separate tool that takes a pre-existing PoN and anonymizes it. . To anonymize a PoN:; - [ ] Determine which fields are private. At the very least: `fnt_control_matrix`, `log_normals`, and `log_normals_pinv`. _There may be others -- please investigate as part of this issue_; - [ ] Have `CreatePanelOfNormals` delete the fields as the last step.; - [ ] Make sure that `HDF5PoN` produces reasonable error messages if one of these fields is accessed in an anonymized PoN.; - [ ] Create CLI that can take existing PoN and delete the fields. ---. @LeeTL1220 commented on [Mon Feb 01 2016](https://github.com/broadinstitute/gatk-protected/issues/343#issuecomment-178022285). This is necessary since we may want to share PoNs and the PoN files cannot have any private data. ---. @LeeTL1220 commented on [Wed Mar 02 2016](https://github.com/broadinstitute/gatk-protected/issues/343#issuecomment-191420153). Moving this to later milestone, unless it becomes more urgent.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2835:689,message,messages,689,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2835,1,['message'],['messages']
Integrability,@LeeTL1220 commented on [Thu Jan 21 2016](https://github.com/broadinstitute/gatk-protected/issues/316). How does the performance look?; This may also include having to troubleshoot adding a `sparkJar` artifact to `build.gradle`. ---. @LeeTL1220 commented on [Fri Jan 22 2016](https://github.com/broadinstitute/gatk-protected/issues/316#issuecomment-173938780). Dependent on issue https://github.com/broadinstitute/gatk-protected/issues/317,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2834:361,Depend,Dependent,361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2834,1,['Depend'],['Dependent']
Integrability,"@LeeTL1220 commented on [Wed Sep 21 2016](https://github.com/broadinstitute/gatk-protected/issues/712). https://hub.docker.com/r/broadinstitute/gatk-protected/tags/. Most are due to the base image being used. We may want to consider upgrading the ubuntu version. If we do this, hdfview will have to be removed. This should be fine, since the GATK now packages this dependency. Not sure about the effect on R. ---. @LeeTL1220 commented on [Wed Sep 21 2016](https://github.com/broadinstitute/gatk-protected/issues/712#issuecomment-248659967). Upgrading the ubuntu will not eliminate all vulnerabilities. ---. @LeeTL1220 commented on [Wed Sep 21 2016](https://github.com/broadinstitute/gatk-protected/issues/712#issuecomment-248679073). `emacs` makes this image much larger",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2897:365,depend,dependency,365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2897,1,['depend'],['dependency']
Integrability,"@LeeTL1220 do you have any opinions on making the somatic CNV workflow scatter by contig? This could allow WGS to complete basically ~20x faster and could allow us to avoid issues such as #4734. A few issues:. 1) Do we want a single WDL that can optionally scatter, depending on WES vs. WGS? It would be nicer to have just one workflow, but I haven't thought about how an optional scatter might look in WDL. 2) For segmentation and modeling, scattering should have little impact on the final result (although there are a few global-level quantities in the models that would be reduced to contig-level quantities, which might slightly affect the quality of their inference). However, we'd want to concatenate all per-contig results for both plotting and segment calling. It'd be relatively easy to either have a separate tool to concatenate AbstractLocatableCollections (there is already a method to do this that is used for the gCNV pipeline), or to make the plotting and calling tools take in parallel inputs and combine them. I'd tend towards the former, just so we don't have to deliver per-contig files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386268150:266,depend,depending,266,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386268150,1,['depend'],['depending']
Integrability,"@LeeTL1220 done. I put it in the M2 integration test because it is part of a bigger potential issue, that of phantom alleles from the likelihoods that don't make it into the variant call. Back to you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3636#issuecomment-333874263:36,integrat,integration,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3636#issuecomment-333874263,1,['integrat'],['integration']
Integrability,@LeeTL1220 reminds me that there is also some code for reading/writing intervals that I introduced that probably belongs in the wrapper as well.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317834727:128,wrap,wrapper,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317834727,1,['wrap'],['wrapper']
Integrability,"@MartonKN I've labeled the update of the caller as a ""reach"", so I'm not expecting that it gets done before release. However, I expect that the tutorial data should be updated well before release. The tutorial data runs quickly (~1 hr for coverage collection, which is mostly limited by the slowest samples or cloud preemptions, and then ~minutes once collection has been call cached), so we should have plenty of time. Whether or not the actual tutorial itself will be ready depends on whether @sooheelee has available bandwidth and if it is a high priority for comms.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3826#issuecomment-353730988:476,depend,depends,476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826#issuecomment-353730988,1,['depend'],['depends']
Integrability,"@MartonKN One more thing: the PR title is currently not very informative, so when you merge, be sure to write a descriptive commit message. These are very useful when we come out with release notes, among other things.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5489#issuecomment-444951052:131,message,message,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5489#issuecomment-444951052,1,['message'],['message']
Integrability,@NeginValizadegan For some reason you appear to be running very old Picard versions. This most recent error message you posted is coming from an even older version of Picard (`2.9.0-1-gf5b9f50-SNAPSHOT`) than the first one you posted (which you said was `2.10.1`). I would suggest upgrading to [2.27.5](https://github.com/broadinstitute/picard/releases).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419101274:108,message,message,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419101274,1,['message'],['message']
Integrability,"@NeginValizadegan Thanks for looking into it, and sorry you're still seeing the issue. . Is that error message from the 2.10.1 version? It doesn't line up with the code in 2.27.1 so either you're posting your original error, or you're not getting the version of picard you expect. Would it be possible to include the entire program log, and the command line to run it here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414024739:103,message,message,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414024739,1,['message'],['message']
Integrability,"@SHuang-Broad . Nice hack using the cluster name. I don't see any other way to pass an arg to an initialization action. I have one suggestion to consider, but if you think it's too much work or not worth it feel free to skip: what if we separated out the reference bundle to copy from the data by specifying them both in the cluster name? That way we could, say, load either the hg19 or hg38 reference depending on the data we might be working with. So you could say ""cluster-hg38"" or ""cluster-hg19"" or ""cluster-hg19-na12878"". . Carrying it further, if we had a special convention for specifying data, like ""data-$SAMPLE"", we could just map $SAMPLE to a subdirectory on the bucket. That would provide a ton of flexibility. One minor note while you are messing with these scripts: the createCluster.sh script comment says ""This script deletes a Google Dataproc cluster used for running the GATK-SV pipeline."" Could you change to say it creates rather than deletes a cluster?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2456#issuecomment-286876038:402,depend,depending,402,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2456#issuecomment-286876038,1,['depend'],['depending']
Integrability,"@SHuang-Broad ; I have addressed comments and changed the SSRAligner interface to make it more general in terms of the type of inputs (base sequence providers) and the type of outputs that it will generate. . Also I added and example as to how to address your SVFastqUtil.FastqRead to SAMRecord realigner may look like but is untested. perhaps you can take on that commit and add the test, . does not need to be part of this PR push though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4780#issuecomment-390809079:69,interface,interface,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4780#issuecomment-390809079,1,['interface'],['interface']
Integrability,@SHuang-Broad looks good. I still think you should rename that integration test though.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2452#issuecomment-288187411:63,integrat,integration,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2452#issuecomment-288187411,1,['integrat'],['integration']
Integrability,"@SebastianHollizeck I believe the bug is not in `FilterMutectCalls` but upstream in `LearnReadOrientationModel` in the edge case of 3-base contexts that have no data in some of the samples. It's strange because we have an integration test for this already, and I would appreciate getting your input files to `LearnReadOrientationModel` for debugging. I think the following quick fix will work: untar your artifact priors, delete all but sample b, and re-tar, then run `FilterMutectCalls` as before. Is there a reason why all samples except b have very little data, and have no data at all for most 3-base contexts? To be clear, we want to fix the bug even if the data are weird, but I want to double-check that this is expected.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-597735514:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-597735514,1,['integrat'],['integration']
Integrability,"@Siadjeu Could you try running the latest 4.1.9.0 release and reporting whether you get the same error? We updated a number of our dependencies for that release, including the Google cloud NIO library that the error is coming from.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707916225:131,depend,dependencies,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707916225,1,['depend'],['dependencies']
Integrability,"@Siadjeu Don't worry about the ""Failed to detect"" message. It indicates some internal state in one of the google libraries but not an error we need to worry about. Generally you shouldn't worry about INFO messages if everything else is going fine and they don't say something particular about what you're doing. A WARNING or ERROR message would indicate a problem. This should maybe be downgraded to be a DEBUG level message or something but it's in a third library and convincing them to change it might be a hassle.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-708443156:50,message,message,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-708443156,4,['message'],"['message', 'messages']"
Integrability,"@TearsWillFall @LRFreeborn I suspect that the environment you're running in has the wrong tensorflow version for some reason. The keras issue is a known TF/keras version incompatibility (see for example [this explanation](https://tensorexamples.com/2020/08/02/Keras.backend-has-no-attribute-get_session.html)). I'd guess that somehow you're getting TF 2.x as opposed to the TF 1.15 that GATK uses. I would recommend against directly modifying the python code - we use that same code and conda environment every day in our CI environment and on our docker, and it works there, so I suspect this is a dependency issue that is somewhat platform dependent. You might try checking the tensorflow version in your activated conda environment as a place to start - you can see the versions our current dependencies [here](https://github.com/broadinstitute/gatk/blob/master/scripts/gatkcondaenv.yml.template). Also @LRFreeborn - are you certain your issue is exactly the same as the original report (do you see the `AttributeError: module 'keras.backend' has no attribute 'clear_session'`) ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-941031682:599,depend,dependency,599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-941031682,3,['depend'],"['dependencies', 'dependency', 'dependent']"
Integrability,"@TedBrookings which formats are you using, in particular? If there is a format out there that nicely fits our needs, we should adopt it. In the CNV package, I've taken pains to unify how tabular data are represented in Java, depending on whether each record is Locatable or whether the collection of records can be associated with a sample name or sequence dictionary. This allows us to represent records that extend Locatable with *multidimensional numerical or non-numerical annotations* along with some metadata (sample name and sequence dictionary) with a minimum of boilerplate. There are also base methods for producing interval trees, etc. This pretty much satisfies all of the CNV team's needs (and is, in my opinion, a necessary improvement over the horrowshow of read/write utility methods for each file format that we had previously...). However, this unification effort was a quick push I made before release, so some polishing or redesigning may be warranted. We may also want to add more forms of metadata, etc. if other teams would require more features. Another downside is that this code lacks the indexing, NIO support, etc. that some of the other standardized/Tribble formats enjoy. For CNV data, this isn't a huge issue, but I think it would be nice to unify how we represent such data GATK-wide. As I said above, I don't think VCF is the correct answer, but certainly it could fit into whatever framework we adopt or come up with.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385656468:225,depend,depending,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385656468,1,['depend'],['depending']
Integrability,"@TianJin297 commented on [Fri May 26 2017](https://github.com/broadinstitute/gatk-protected/issues/1108). The command is gatk-protected HaplotypeCallerSpark -I XX_BQSRappliedspark.bam -O XX_spark.vcf -R /curr/data/humann_g1k_v37.2bit --emitRefConfidence GVCF --TMP_DIR tmp. And it is run on an Amazon m4.2xlarge instance. The error messages are like below.; 04:39:06.415 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; 05:09:00.269 ERROR Executor:91 - Exception in task 8.0 in stage 1.0 (TID 345); java.lang.ArrayIndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 05:09:00.455 WARN TaskSetManager:66 - Lost task 8.0 in stage 1.0 (TID 345, localhost): java.lang.ArrayIndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:332,message,messages,332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['message'],['messages']
Integrability,"@Unip0rn Thank you for the pr. I'm not sure I understand what you're trying to do here though. currently when I run `./gatk --list` it prints the list of gatk tools. ex:; ```; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Base Calling: Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the --",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:442,adapter,adapters,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030,1,['adapter'],['adapters']
Integrability,"@Zepeng-Mu You say the original mapping contained contigs not in your reference but you filtered it with samtools to remove those contigs? I wonder if somehow some mappings to other contigs remain. I opened a PR ( #6781 ) to improve the error message. If you wanted to debug it further and ( have the time and inclination) you could build that commit and rerun with it to get the new error message. Alternatives to proceed would be to use the original reference you mapped it with, or run HaplotypeCaller with an intervals file that only contains the contigs that match the hg19 reference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684130877:243,message,message,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684130877,2,['message'],['message']
Integrability,"@adamjorr We'd like to support newer versions of Java, but have historically been held back by our Apache Spark dependency. We'll take another look at our dependency situation, however, and see if an upgrade is possible at this point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6053#issuecomment-514364684:112,depend,dependency,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6053#issuecomment-514364684,2,['depend'],['dependency']
Integrability,"@aderzelle The CNN tool requires some Python packages - you may not have the correct set of dependencies. There are instructions [here](https://github.com/broadinstitute/gatk#requirements) on how to establish the required environment via the Conda package manager. See the 3rd bullet point in the ""Optional but recommended"" section. Hope that helps.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4591#issuecomment-376503318:92,depend,dependencies,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4591#issuecomment-376503318,1,['depend'],['dependencies']
Integrability,"@ahaessly I've asked @jamesemery to review, as this touches some of his code. In the mean time, though, could you please add at least one good integration test for the new `ShiftFasta` tool?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6694#issuecomment-773489477:143,integrat,integration,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6694#issuecomment-773489477,1,['integrat'],['integration']
Integrability,"@ahaessly This error message indicates a corrupt .crai index file - you should see the same message if you try to read the file with any other GATK tool. Regenerating the index should fix it. Also, let me know if you happen to know what software/version created the index.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804045945:21,message,message,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804045945,2,['message'],['message']
Integrability,"@ahwanpandey the way I've worked around this in my workflows is to filter very large REF/ALT lengths. However from what I can tell the critical length is inconsistent, somewhere between 100-150 from memory, depending on the variant/data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8699#issuecomment-2403844997:207,depend,depending,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8699#issuecomment-2403844997,1,['depend'],['depending']
Integrability,"@akiezun & I were just discussing whether we could change the MD algorithm in any way to cut down on the number of shuffles, and one promising option (suggested by @cwhelan) would be to run MD a little earlier in the pipeline: after alignment, but before the reads are sorted by position. Since the reads come off the aligner sorted by name, this would spare us at least one shuffle (the group by name). We could then probably get away with just a single join on position (either individual position or the concatenation of position + mate position, depending on whether each read is paired) to make the rest of the existing algorithm work. Also, since BQSR doesn't require coordinate-sorted reads either, we could probably defer the sorting until just before the `HaplotypeCaller` runs, unless there's some metric out there that requires coordinate-sorted input",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/863#issuecomment-139656911:550,depend,depending,550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/863#issuecomment-139656911,1,['depend'],['depending']
Integrability,"@akiezun . I don't have anything against porting the classes that are ported except `MostLikelyAllele` which is only reference by testing code (or perhaps I'm missing something?) It might need to be ported eventually but not at this time. Coverage is poor for PairHMM instances and this seems due to the fact that there are no unit test for PairHMM's computeLikelihoods and it was covered just by integration test back in GATK3. Can you add some unit-testing here? That would require to include an implementor of LikelihoodMatrix also in the pull request. Apart from that please correct code formatting issues (finals, missing {} and so forth).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/543#issuecomment-109616565:397,integrat,integration,397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/543#issuecomment-109616565,1,['integrat'],['integration']
Integrability,"@akiezun @lindenb I can help. It's probably going to be a slightly complicated process though, especially actually building the cross platform jar. I assume we're targeting OSX and x86-64 to start with, and then hopefully expanding to POWER8 in the future? . The general idea is to prebuild the c code for whatever platforms we want to support. Then package that in a structured way into a jar, and write some java code which will detect the platform at runtime and extract the correct executable into a temporary location. Then we can publish that jar as a maven artifact. We have an example of how to do the extraction in the `VectorLoglessPairHMM` constructor. It's not perfect and probably needs a bit of refactoring to make it more general but it's the right idea. Other libraries that package native code have similar examples. I.e. Snappy-java https://github.com/xerial/snappy-java. We're going to be performing similar packaging for other native dependencies that we have, so standardizing it is a good idea.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-215820135:954,depend,dependencies,954,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-215820135,1,['depend'],['dependencies']
Integrability,"@akiezun A few comments. Some of it is just my personal taste, but I think we should at least reverse the ordering of the help and the error message so it's not hidden.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1970#issuecomment-230605194:141,message,message,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1970#issuecomment-230605194,1,['message'],['message']
Integrability,@akiezun A few documentation issues. I think the default methods should be have the contract that they must match the behavior of the default implementations but may be implemented differently for performance reasons. . Either remove `getBaseCounts` or replace `getLength` with it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1477#issuecomment-182546660:84,contract,contract,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1477#issuecomment-182546660,1,['contract'],['contract']
Integrability,@akiezun Addressed your comment about mutable vs nonmutable by merging the two read interfaces into one.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/601#issuecomment-119316816:84,interface,interfaces,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/601#issuecomment-119316816,1,['interface'],['interfaces']
Integrability,"@akiezun Can you determine whether you're using the HDFS -> GCS adapter in your test case? The adapter historically did have performance problems of this magnitude. As @jean-philippe-martin mentioned, we should benchmark the new NIO -> GCS support as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1755#issuecomment-213097025:64,adapter,adapter,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1755#issuecomment-213097025,2,['adapter'],['adapter']
Integrability,@akiezun Do you think we should move the various variant context test routines out of BaseTest? It seems weird that they live there.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1906#issuecomment-225286963:70,rout,routines,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1906#issuecomment-225286963,1,['rout'],['routines']
Integrability,@akiezun I believe that CollectTargetedPcrMetrics integration test... fails due to its inability to output min_normalized_coverage when using the PER_TARGET_COVERAGE option.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/996#issuecomment-149579546:50,integrat,integration,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/996#issuecomment-149579546,1,['integrat'],['integration']
Integrability,@akiezun I disagree with having an optional flag that must be specified or the program crashes. . A few nitpicks otherwise. :+1: Update or ignore depending on how you feel about them.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1126#issuecomment-157417751:146,depend,depending,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1126#issuecomment-157417751,1,['depend'],['depending']
Integrability,"@akiezun I don't think we should add yet another Frankenstein monster step to our build process like this. I recommend instead that we package the library in Broad artifactory (after obtaining the author's permission), and depend on it from there.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-220138064:223,depend,depend,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-220138064,1,['depend'],['depend']
Integrability,"@akiezun I have switched a lot so far; currently I'm stuck on `GenotypeLikelihoodCalculator`, which relies on `GenotypeLikelihoods` in htsjdk, which is log10. I could write a simple wrapper class to present a natural log interface. Is there a better solution?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/917#issuecomment-149321469:182,wrap,wrapper,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/917#issuecomment-149321469,2,"['interface', 'wrap']","['interface', 'wrapper']"
Integrability,@akiezun I removed a few more things. Up to you where you think AdapterPair and the newly extracted IlluminaAdapatorPair should live.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/470#issuecomment-97517175:64,Adapter,AdapterPair,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/470#issuecomment-97517175,1,['Adapter'],['AdapterPair']
Integrability,"@akiezun Instead of adding these overloads would we see the same speedup if we cached the result of isUnmapped and isPaired in the adapter? That would have the downside of complicating the adapter but it might avoid adding these strange methods to the interface. . If caching seems like a bad alternative, I think maybe these methods should have names that make it clear that they're some sort of performance hack and you should generally prefer the standard ones. 'getContigUnsafe` for instance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235101307:131,adapter,adapter,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235101307,3,"['adapter', 'interface']","['adapter', 'interface']"
Integrability,"@akiezun Is there a reason these are `LinkedLists`? It seems like it should be List instead. I tried to find usages that depend on the linkedlistness of it, but the only thing I see is that one private method relies on it being a `Deque`, but that could be trivially rewritten. It seems like you'd avoid even more allocation by switching it to use List and then using the non-allocating `Collections.emptyList()`. `getBetween` uses the linkedness of it to use `addFirst`. This could be rewritten to either build the list in the reverse order and reverse it, or maybe provide a guava `Lists.reverse` view.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1795#issuecomment-216362302:121,depend,depend,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1795#issuecomment-216362302,1,['depend'],['depend']
Integrability,"@akiezun It has to do with the code, one part laziness in avoiding to implement a bona fide `GATKRead` adapter for `AlignmentRecord`, and one part due to the interval filter operating only on `SAMRecord`s (`samRecordOverlaps`). Assuming ADAM does become a more important use case to support, we can refactor to improve this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1067#issuecomment-152358785:103,adapter,adapter,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1067#issuecomment-152358785,1,['adapter'],['adapter']
Integrability,"@akiezun It's a tempting option, provided it's done in a generic way (arg of type `Deflater` and not `IntelDeflater`) and the existing global properties in `Defaults` are removed. It might cause problems for Picard, however, as it would make it difficult to enforce that the Intel deflater be used across all Picard tools (since Picard lacks a centralized engine). Is the IntelDeflater currently on globally in Picard?. Another possibility is that we could create a branch of htsjdk in which the deflater is turned back on (easily done, all the code is still there), depend on snapshots of that branch temporarily in GATK until GKL is in maven central, and update the branch as needed with fixes from master. If it's only a few weeks this might be bearable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1867#issuecomment-223070297:567,depend,depend,567,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1867#issuecomment-223070297,1,['depend'],['depend']
Integrability,"@akiezun Looks good, needs some explanation for confused future people I think. We want it to be discoverable when the test suit has slightly different numbers of tests depending on where it runs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1760#issuecomment-213594256:169,depend,depending,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1760#issuecomment-213594256,1,['depend'],['depending']
Integrability,@akiezun Or we can just wait a few weeks and depend on a snapshot of htsjdk in the mean time?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1867#issuecomment-223079000:45,depend,depend,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1867#issuecomment-223079000,1,['depend'],['depend']
Integrability,"@akiezun These changes are not compatible with the walker interface / engine, and should not be merged into the walker version of BQSR, in my opinion. Eg., the only non-trivial code here finds the skip intervals that overlap the current read, which is something the walker engine already does for you (via the `FeatureContext` passed to `apply()`).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/511#issuecomment-101330952:58,interface,interface,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511#issuecomment-101330952,1,['interface'],['interface']
Integrability,@akiezun This should pass. The issue was that `test` didn't depend on `extractIntelDeflater` and was correctly failing when it wasn't found.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1742#issuecomment-212593861:60,depend,depend,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1742#issuecomment-212593861,1,['depend'],['depend']
Integrability,"@akiezun Yes, it's true that there's no way to prevent that, short of doing deep copies every time a read is wrapped in an adapter. But we can make it clear in the GATKRead contract that the backing reads should not be directly modified after wrapping within an adapter, and if they are they need to be re-wrapped in a new adapter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235291718:109,wrap,wrapped,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235291718,7,"['adapter', 'contract', 'wrap']","['adapter', 'contract', 'wrapped', 'wrapping']"
Integrability,"@akiezun Yes, the task is to add more integration tests that use `--joinStrategy BROADCAST`. Currently almost all of the tests use `SHUFFLE`, even though that's no longer the default.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1140#issuecomment-157802235:38,integrat,integration,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1140#issuecomment-157802235,1,['integrat'],['integration']
Integrability,"@akiezun back to you with a comment. <!-- Reviewable comment -K2OCrEDRCLfJof_Cdgp:-1160907455 -->. ---. Reviewed 2 of 2 files at r1.; Review status: all files reviewed at latest revision, 2 unresolved discussions. ---. <sup>**[src/main/java/org/broadinstitute/hellbender/engine/datasources/ReferenceAPISource.java, line 155 [r1]](https://reviewable.io:443/reviews/broadinstitute/gatk/1058#-K2OAVk5uR5BT7DB8ujU)** ([raw file](https://github.com/broadinstitute/gatk/blob/a5c03b9e93125bf1acd9e9969a81f236a128ee6d/src/main/java/org/broadinstitute/hellbender/engine/datasources/ReferenceAPISource.java#L155)):</sup>; Should this be a `UserException`? It seems like it's probably a bug in the calling code if it's going off the end of a contig, unless you think the likely path is that they've specified the wrong reference. In either case, I think the message should mention that fewer bases were retrieved than requested in addtion to displaying the interval. It might be worth making this a more specific exception subclass too, I can imagine potential situations where people would want to catch and handle this differently. . <!-- Reviewable comment -K2OAVk5uR5BT7DB8ujV:-2111080668 -->. ---. <sup>**[src/test/java/org/broadinstitute/hellbender/engine/datasources/ReferenceAPISourceUnitTest.java, line 170 [r1]](https://reviewable.io:443/reviews/broadinstitute/gatk/1058#-K2OCQKoj0hZv86WbYXu)** ([raw file](https://github.com/broadinstitute/gatk/blob/a5c03b9e93125bf1acd9e9969a81f236a128ee6d/src/test/java/org/broadinstitute/hellbender/engine/datasources/ReferenceAPISourceUnitTest.java#L170)):</sup>; It would be nice if this were more specific so we can be sure the test isn't passing accidentally due to a failed authentication or downed webserver. <!-- Reviewable comment -K2OCQKpe3Ja-0PPUKjV:775526476 -->. ---. Comments from the [review on Reviewable.io](https://reviewable.io:443/reviews/broadinstitute/gatk/1058). <!-- Sent from Reviewable.io -->",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1058#issuecomment-154172680:847,message,message,847,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1058#issuecomment-154172680,1,['message'],['message']
Integrability,"@akiezun the main change to existing code is the updated argument passing in Picard integration tests. The only modifications to non-Picard files were added methods in MathUtils, as mentioned above, and removing unused imports.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/347#issuecomment-89317171:84,integrat,integration,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347#issuecomment-89317171,1,['integrat'],['integration']
Integrability,"@apete Thanks for the PR! That's really helpful to update and any svd improvements are definitely something we want. . It's failing to build though, because it can't locate `ojalgo-extensions-1.0.0`. I get the following error:; ```; Build file '/Users/louisb/Workspace/gatk/build.gradle' line: 511. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Could not resolve all dependencies for configuration ':runtime'.; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; Required by:; project :; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; > Could not parse POM https://repo1.maven.org/maven2/org/ojalgo/ojalgo-commons-math3/1.0.0/ojalgo-commons-math3-1.0.0.pom; > Could not find org.ojalgo:ojalgo-extensions:1.0.0.; Searched in the following locations:; https://repo1.maven.org/maven2/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; https://repo1.maven.org/maven2/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; https://jcenter.bintray.com/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; https://jcenter.bintray.com/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; file:/Users/louisb/.m2/repository/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; file:/Users/louisb/.m2/repository/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; > Could not parse POM https://jcenter.bintray.com/org/ojalgo/ojalgo-commons-math3/1.0.0/ojalgo-commons-math3-1.0.0.pom; > Could not find org.ojalgo:ojalgo-extensions:1.0.0.; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; > Could not parse POM https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/o",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3970#issuecomment-351825206:395,depend,dependencies,395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3970#issuecomment-351825206,1,['depend'],['dependencies']
Integrability,"@asmirnov239 Thanks for implementing this. After our conversation, I realized that the GATK3 version of the `--force-active` argument works a bit differently: it sets all of the individual per-locus probabilities of being active to 1.0, rather than preserving the true probabilities and just setting every region's `isActive` flag to true, as you're doing here. Ie., GATK3 does this:. ```; private void addIsActiveResult(final ActiveRegionWalker<M, T> walker,; final RefMetaDataTracker tracker, final ReferenceContext refContext,; final AlignmentContext locus) {; // must be called, even if we won't use the result, to satisfy walker contract; final ActivityProfileState state = walker.isActive( tracker, refContext, locus );; if ( walker.forceActive) state.isActiveProb = 1.0;; if ( ! walkerHasPresetRegions ) {; activityProfile.add(state);; }; }; ```. I'm not convinced that the GATK3 behavior is actually better. It almost seems preferable to me to keep the true ""is active"" probabilities intact (so that you get realistic region boundaries), and just tell the `HaplotypeCallerEngine` to treat all of the resulting regions as active, as you're doing in this branch, instead of overwriting all of the isActive probabilities with 1.0 as GATK3 did. But maybe there is a good argument in favor of the GATK 3 behavior. Let's see what other people think -- @ldgauthier @davidbenjamin could you please weigh in as to which of the two `--force-active` implementations described above you'd prefer? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5635#issuecomment-461577642:634,contract,contract,634,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5635#issuecomment-461577642,1,['contract'],['contract']
Integrability,"@asmirnov239 commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1063). Due to a bug in Nd4j library, INDArray.get() method does not work correctly for row or column vectors (that we work with when number of samples is 1). In these cases a call to `getNDArrayByIndices(array, indX, indY, int)` is made.; Note that this bug was fixed in later version of Nd4j (currently used version is 0.5.0), so the method can be removed when the dependency is updated",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3000:466,depend,dependency,466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3000,1,['depend'],['dependency']
Integrability,"@asmirnov239 commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1065). ---. @asmirnov239 commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1065#issuecomment-302528347). @mbabadi could you do it?. ---. @sooheelee commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1065#issuecomment-302564888). Is the test <src/test/java/org/broadinstitute/hellbender/tools/coveragemodel/germline/GermlineCNVCallerIntegrationTest.java> not the integration test?. ---. @asmirnov239 commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1065#issuecomment-302565368). @sooheelee It's a collection of different tests, but it's missing some use cases. ---. @mbabadi commented on [Mon May 22 2017](https://github.com/broadinstitute/gatk-protected/issues/1065#issuecomment-303249272). @asmirnov239 it covers PoN creation and calling (from the created PoN, and from the ""exact"" PoN). It certainly does not cover all combination of all advanced arguments, and we do not intend to do that either. Perhaps we should extend the test to include w/ and w/o ARD, and w/ and w/o bias covariates. I'm open to suggestions. ---. @asmirnov239 commented on [Wed May 24 2017](https://github.com/broadinstitute/gatk-protected/issues/1065#issuecomment-303858968). @mbabadi What I meant is to write an extra test for a use case of calling events on a single sample (as it is a requirement for our workflows). Just a single test with most generic arguments should suffice I think.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3002:535,integrat,integration,535,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3002,1,['integrat'],['integration']
Integrability,@asmirnov239 commented on [Thu Sep 29 2016](https://github.com/broadinstitute/gatk-protected/issues/727). Here is the stack trace:. ```; java.lang.IllegalArgumentException: the 'to' index must be between 'from' and the length of the data/position sequence; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:609); at org.broadinstitute.hellbender.utils.param.ParamUtils.inRange(ParamUtils.java:80); at org.broadinstitute.hellbender.utils.hmm.ForwardBackwardAlgorithm$Result.logProbability(ForwardBackwardAlgorithm.java:141); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.lambda$calculateLog10GP$6(GenotypeCopyNumberTriStateSegments.java:197); at java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:244); at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.DoublePipeline.toArray(DoublePipeline.java:506); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.calculateLog10GP(GenotypeCopyNumberTriStateSegments.java:198); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.lambda$composeVariantContext$0(GenotypeCopyNumberTriStateSegments.java:125); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSeq,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2898:979,wrap,wrapAndCopyInto,979,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2898,1,['wrap'],['wrapAndCopyInto']
Integrability,"@asmirnov239 commented on [Tue Apr 18 2017](https://github.com/broadinstitute/gatk-protected/issues/987). Replace the `AllelicCountCollector` with the implementation using LocusWalker. ---. @LeeTL1220 commented on [Wed Apr 19 2017](https://github.com/broadinstitute/gatk-protected/issues/987#issuecomment-295366237). Actually, I have to replace ``CollectAllelicCounts`` and ``AllelicCountCollector``. ---. @LeeTL1220 commented on [Fri May 12 2017](https://github.com/broadinstitute/gatk-protected/issues/987#issuecomment-301082304). Dependent on: . https://github.com/broadinstitute/gatk/pull/2661",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2968:533,Depend,Dependent,533,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2968,1,['Depend'],['Dependent']
Integrability,"@asmirnov239 commented on [Wed Oct 19 2016](https://github.com/broadinstitute/gatk-protected/issues/751). Things that we discussed with @samuelklee that can be done to aid it:. -I think that all files we generate for individual case samples---""ReadCountCollection"" files for coverage profiles, ""AllelicCountCollection"" files for het pulldowns, and segment files---should contain the sample name as metadata in a header comment with a common tag (e.g., #sampleName = ...). Currently, these sample names are stored in column headers, in the fields of a SAMPLE column, or not at all, depending on the type of file. This would drastically simplify the use of the SampleNameFinder class, which would basically only contain a single method to parse this header comment and return the name. -CLIs that generate a file from an input BAM (CalculateTargetCoverage, GetHetCoverage, etc.) should take the sample name from that BAM by default. Since these are the first steps in our workflows, we could also optionally allow the user to specify a sample name different from that in the BAM. -Subsequent CLIs should then take the sample name from the header comment. -CLIs that take multiple non-BAM input files should check for consistency of the sample names as part of the argument validation step. -CLIs that output the sample name in plots should derive these from the header comment. -For files that contain data from multiple samples (e.g., the output of CombineReadCounts), we can probably leave the sample names in the column headers, but it would be nice to output the type of data stored in a header comment as well (e.g., PCOV or RAW). At some point I think we should restrict to RAW output only, see https://github.com/broadinstitute/gatk-protected/issues/615. -Entity names specified by the input file for the WDLs can be separate from the BAM sample names by default. However, if we do allow the user to optionally specify sample names as described in the first bullet point, we can set up the WDL to",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2910:581,depend,depending,581,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2910,1,['depend'],['depending']
Integrability,"@bbimber - here some answers:. * The `LocusWalker` in the GATK4 framework provides the traversal over each locus, and provides the information for the reference (`ReferenceContext`) and the pileup (`AlignmentContext`). I guess that this is similar to a rod-walker in the previous framework if a `FeatureInput` is present (accessed by the `FeatureContext`); * The apply function params are never null, but they may be empty. The reference context could be tested if it is empty by using `hasBackingDataSource()`. Other contexts can be tested with other methods to check if they are empty.; * For auto-discovery of feature inputs, mark the field with `FeatureInput<>` for the type of feature that you want; if you require more than one, a list of `FeatureInput` can be provided. Then, the features for the feature class can be retrieved from the `FeatureContext` on the apply function.; * For argument exceptions, use the ones in `UserException` or `CommandLineProgramException`, depending on which one fits better on your use case... If you wanna check an example of a locus walker with features, see [`ExampleLocusWalker`](https://github.com/broadinstitute/gatk/blob/4ef87ca10c3b57af76d829995e532c279b17cff2/src/main/java/org/broadinstitute/hellbender/tools/examples/ExampleLocusWalker.java). I hope that it helps!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-337598527:978,depend,depending,978,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-337598527,1,['depend'],['depending']
Integrability,"@bbimber - using the `FeatureContext` to get the overlapping BED/VCF records should do the job (for the first message, second part). Regarding the `PluginManager`, I am not familiar with the GATK3's concept. If you are talking about the plugins like `ReadFilter`s, you can retrieve them by using: `getCommandLineParser().getPluginDescriptor(RequiredStratification.class)`. This will get the plugin descriptor already parsed by the command line. But for that, you need to have a `RequiredStratification` plugin...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-343678198:110,message,message,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-343678198,1,['message'],['message']
Integrability,"@bbimber File locking doesn't work on all the filesystems GenomicsDB supports (hdfs/cloud, for instance) and is a pain on others (NFS, for instance -- painful enough that we've sometimes had to recommend users disable the existing file locking). For that reason, I wouldn't want users to depend on file locking for correctness. Unfortunately, I think the cleanest approach is for the user to ensure correctness by avoiding the read/write conflicts themselves.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6558#issuecomment-617448100:288,depend,depend,288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6558#issuecomment-617448100,1,['depend'],['depend']
Integrability,"@bbimber I believe we resolve it from jcenter. There were some issues around it because we removed jcenter resolution from our build at one point when it was slated to shut down. Testing didn't see any issue because it was being silently mirrored through our artifactory instance and we didn't realize that. Jcenter changed their plans from shutting down to going into indefinite read only mode, so we re-added it. . I think if you're seeing problems it's either because:; 1. You are building on a version of gatk which removed jcenter; 2. Your custom build doesn't resolve from jcenter; 3. We have a new issue I don't know about yet. . Can you rule out 1 and 2 before we start debugging 3? . In your build.gradle you should should see ` jcenter()` in your `repositories {}` block. It's very possible that we're relying on an outdated version and maybe we should update to a new one which isn't on the ill fated Jcenter only. @TedBrookings any thoughts about that? I think this is your dependency.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7839#issuecomment-1122757145:986,depend,dependency,986,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7839#issuecomment-1122757145,1,['depend'],['dependency']
Integrability,"@bbimber I don't think `IntegrationTestSpec` has any provisions for this, and it has a number of other limitations around output files as well. We mostly only keep it around to make it easier to port GATK3 test - I'd recommend writing new tests using `ArgumentsBuilder` and `runCommandLine`, and checking results manually, perhaps by delegating to the static assert* methods in `IntegrationTestSpec`. Take a look at `HaplotypeCallerIntegrationTest` as an example. For the case of multiple outputs, create a temporary directory and specify that for the prefix input.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5446#issuecomment-441636281:24,Integrat,IntegrationTestSpec,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5446#issuecomment-441636281,2,['Integrat'],['IntegrationTestSpec']
Integrability,"@bbimber Just so you're aware, I expect this PR to be merged in the next couple of weeks - we're mostly just waiting on a couple of downstream dependencies. If you're still using Barclay docgen, there were some pretty significant [changes to the doclets](https://github.com/broadinstitute/barclay/pull/188) - not sure if that will affect your code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1430413869:143,depend,dependencies,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1430413869,1,['depend'],['dependencies']
Integrability,"@bbimber This issue is caused by an incompatibility between the version of snappy htsjdk uses and the versions that the rest of the world use. The workaround was to add the system property`-Dsnappy.disable=true` which is set automatically by gatk-launch. However, we just fixed the underlying problem in htsjdk and upgraded to use new version of snappy there, so it's a better idea to update to a newer gatk version that incorporates the newest htsjdk. . Annoyingly, we've been unable to publish the newer beta releases to maven central because they rely on snapshot builds of dependencies that aren't in central. We're working to fix that issue, but until then, we publish continuous snapshots of every commit on our artifactory https://broadinstitute.jfrog.io/. If you're using gradle you can add our repository to your project by adding this in your `repositories` block of the build file. ```; maven {; url ""https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/"" ; }; ```; (this url was updated to address the comment below) . Then you can add a newer gatk dependency to your project:. ```; compile(group: 'org.broadinstitute', name: 'gatk', version: '4.beta.5-53-g0598843-20170929.153234-1'); ```. There should be a similar solution if you use maven or a different build tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333627036:577,depend,dependencies,577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333627036,2,['depend'],"['dependencies', 'dependency']"
Integrability,"@bbimber Yes, most of those travis jobs are unique and do not overlap in terms of coverage. The unit and integration tests are each run in two separate jobs, one on Java 8 and one on Java 11, but the other jobs run python tools, cloud tests, WDL tests, etc. and do not overlap.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827951442:105,integrat,integration,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827951442,1,['integrat'],['integration']
Integrability,"@bbimber question for you - what is the primary motivation for wanting to merge the scattered workspaces back into a single workspace here? I'm assuming the scatter is because you have a large enough dataset that you need multiple nodes to run the import in parallel. (side note: we're planning on enabling reading vcfs through native htslib in GenomicsDBImport which should drive down memory usage for cases that are able to take advantage of that route. This might make it more feasible to use `--max-intervals-to-import-in-parallel` for multiple threads on a single node ). If the large dataset is the primary reason, wouldn't you want the benefits of distributed processing on the query side as well? You mentioned in the previous thread that you saw the fact that a single workspace is a valid GenomicsDB workspace as a benefit...and that's certainly true - but if performance is the driving factor then it might be worth it to keep the workspace separate. @droazen Could you elaborate on what you envision we should do here? This approach should work as long as the same command line is used for each import with a different/unique interval list each time. Are you asking for a test case to be run just for sanity? Or add test cases to GATK? Or add a tool to do this...?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-635081015:449,rout,route,449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-635081015,1,['rout'],['route']
Integrability,"@bbimber, sorry that the import with consolidate did not complete. If you are amenable to using a native tool, please download the tool from [here](https://github.com/GenomicsDB/GenomicsDB/releases/download/v1.4.3/consolidate_genomicsdb_array) for consolidation. This executable will consolidate a given array in a GenomicsDB workspace, it has been instrumented to output memory stats to help tune the segment size. Note that the executable is for Centos 7, if you find any unresolved shared library dependencies during usage, please let me know and I will work on getting another one to you. For usage from a bash shell:; ```; ~/GenomicsDB: ./consolidate_genomicsdb_array; Usage: consolidate_genomicsdb_array [options]; where options include:; 	 --help, -h Print a usage message summarizing options available and exit; 	 --workspace=<GenomicsDB workspace URI>, -w <GenomicsDB workspace URI>; 		 Specify path to GenomicsDB workspace; 	 --array-name=<Array Name>, -a <Array Name>; 		 Specify name of array that requires consolidation; 	 --segment-size=<Segment Size>, -z <Segment Size>; 		 Optional, default is 10M. Specify a buffer size for consolidation; 	 --shared-posixfs-optimizations, -p; 		 Optional, default is false. If specified, the array folder is not locked for read/write and file handles are kept open until a final close for write; 	 --version Print version and exit; ```. ```; ~/GenomicsDB.: ./consolidate_genomicsdb_array -w /Users/xxx/WGS.gdb/ -a ""1\$1\$249250621"" -z 1048576 -p; 21:09:47.100 info consolidate_genomicsdb_array - pid=30881 tid=30881 Starting consolidation of 1$1$249250621 in ws; Using buffer_size=1048576 for consolidation; 21:9:47 Memory stats(pages) beginning consolidation size=45821 resident=18998 share=1824 text=3530 lib=0 data=16810 dt=0; 21:9:47 Memory stats(pages) after alloc for attribute=END size=45821 resident=19009 share=1835 text=3530 lib=0 data=16810 dt=0; 21:9:48 Memory stats(pages) after alloc for attribute=REF size=46788 resident=19743 share=18",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1057680354:500,depend,dependencies,500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1057680354,2,"['depend', 'message']","['dependencies', 'message']"
Integrability,"@bhandsaker In hellbender we do already ship the header around ""out-of-band"" much as you described (via the spark broadcast mechanism and the dataflow ""side input"" mechanism), and use that header singleton for operations such as looking up the sample, library, platform, etc. We wrote utility methods in hellbender that take both a read and a separate header for all operations that previously required a header within the read, to avoid having to actually restore the header into the reads themselves after every operation that involves a shuffle over the network. Our goal is just to ensure that `SAMRecord` behaves in a consistent, well-documented way when it lacks a header without imposing any additional burden on other users of htsjdk. The only code that would have to be ""headerless-aware"" as a result of this effort would be code that has explicitly opted-in to stripping the headers (eg., hellbender itself, or projects that depend on hellbender).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142410461:935,depend,depend,935,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142410461,1,['depend'],['depend']
Integrability,"@bhandsaker Thanks for chiming in with your thoughts/concerns. Under this proposal, the various classes in htsjdk that read and return `SAMRecords` (eg., `SAMReader` & co.) would continue to put the header inside of the records, so we would not be imposing an additional burden on direct clients of htsjdk to check for null headers any more than they do currently. The only difference is that if downstream consumers of `SAMRecords` (like hellbender) choose to strip the header from the records, there would be an explicit contract governing the behavior of headerless `SAMRecords` (as opposed to the status quo, in which the header may be null but behavior is totally undocumented and in some cases inconsistent -- eg., the reference name and index in a headerless `SAMRecord` can get out-of-sync in some cases). . In addition to documenting/clarifying the behavior of headerless `SAMRecords` and fixing any consistency-related bugs we find when operating without a header, we would also make an effort to document when a class in htsjdk that consumes `SAMRecords` requires that a header be present in the records (such as the various writer classes). Does this sound reasonable? It's actually a much more conservative proposal than it may have initially sounded :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142020109:523,contract,contract,523,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142020109,1,['contract'],['contract']
Integrability,"@bhanugandham This message itself is harmless and won't affect results directly, but it can mask warning/error messages coming from Jexl (such as missing variable names!). I wouldn't expect a user to see it when running from a normal installation, and I'm not sure why it seems to be intermittent. I'll need to do some debugging.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4637#issuecomment-439434139:19,message,message,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4637#issuecomment-439434139,2,['message'],"['message', 'messages']"
Integrability,@biovia-rohit Thanks for reporting this! We'll look at our Apache Commons dependency and see if we can upgrade to a version not affected by this vulnerability.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8060#issuecomment-1289491679:74,depend,dependency,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8060#issuecomment-1289491679,1,['depend'],['dependency']
Integrability,"@chandrans I'm not sure if this is related or not, but I would love to get a test case from them. That's an unhelpful error message at the very least.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2116#issuecomment-410702793:124,message,message,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2116#issuecomment-410702793,1,['message'],['message']
Integrability,"@chandrans commented on [Mon May 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1382). ## Feature request. A user has reported ASEReadCounter counts homozygous sites as having potential ASE. This should not be the case, as only heterozygous sites should be counted. The user should input a VCF sites file with only heterozygous sites, but sometimes that doesn't happen, so there should be an error message when he or she does not. ; ### Tool(s) involved. ASEReadCounter; ### Description. There needs to be an error message telling the user he/she needs to subset the sites VCF to only heterozygous sites. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1382#issuecomment-260490723). May want to move this to GATK4, waiting for @meganshand to opine. . ---. @meganshand commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1382#issuecomment-260648100). Yeah, let's move it to GATK4 and incorporate porting it in the first place.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2265:414,message,message,414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2265,2,['message'],['message']
Integrability,"@cmnbroad - I am not concern about the methods, because they are perfectly configurable, and actually this issue is not that important for some of my projects (e.g., `ReadTools`), which does not use the base walker clases from GATK. Nevertheless, I guess that what @droazen is suggesting is quite important and I appreciate the interest for making better the downstream toolkits integration. Here, a real use case: I've just started to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still n",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:379,integrat,integration,379,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646,2,"['integrat', 'message']","['integration', 'messages']"
Integrability,"@cmnbroad . 1. We could write tests for some parts of the python package, e.g. those relating to I/O. The code also contains a number of stand-alone compiled theano functions that could be tested (e.g. forward-backward algorithm). Beyond that, most of the code juggle symbolic tensors that ultimately get compiled by theano into one giant _step function_. It is going to be hard to write surgical unit tests for such a code (and possibly unnecessary/wasteful). The ultimate requirement from the computational core is to (1) make correct inferences on simulated data, (2) pass certain sensitivity/specificity requirements on real data.; I vote for _not_ unit testing the python package (except for I/O), and to treat it as a black box with certain required specifications. The java-side integration tests can test most of the relevant cases. 2. Regarding logging, the scripts log both to console and optionally to a logfile at specified verbosity levels. At the moment, I am using the following formatter `%(asctime)s %(name)-12s %(levelname)-8s %(message)s`. We can easily change it to match GATK-style logs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-345778623:786,integrat,integration,786,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-345778623,2,"['integrat', 'message']","['integration', 'message']"
Integrability,"@cmnbroad @droazen Didn't realize that I accidentally omitted the `fullName` when specifying the sequence-dictionary argument for PlotModeledSegments:. @Argument(; doc = PlottingUtils.SEQUENCE_DICTIONARY_DOC_STRING,; shortName = StandardArgumentDefinitions.SEQUENCE_DICTIONARY_NAME; ); private File inputSequenceDictionaryFile;. This works when called in WDL tests using the fullName `--sequenceDictionary` (which is why it slipped by me--I would've thought this should fail):. java -Xmx${command_mem}m -jar $GATK_JAR PlotModeledSegments \; --denoised-copy-ratios ${denoised_copy_ratios} \; --allelic-counts ${het_allelic_counts} \; --segments ${modeled_segments} \; --sequence-dictionary ${ref_fasta_dict} \; --minimum-contig-length ${default=""1000000"" minimum_contig_length} \; --output ${output_dir_} \; --output-prefix ${entity_id}. However, the argument names appear in the documentation as:. --inputSequenceDictionaryFile,-sequence-dictionary:File. And if the argument is not specified, this gives the error message:. A USER ERROR has occurred: Argument inputSequenceDictionaryFile was missing: Argument 'inputSequenceDictionaryFile' is required. Is this intended behavior? If so, please close, but it seems a little unexpected to me.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4049:1014,message,message,1014,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4049,1,['message'],['message']
Integrability,@cmnbroad @droazen will there be any action on this? I'm not sure if #5714 might be related (although I'm not sure why we get a ulimit message there instead of a permission denied)?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-467113459:135,message,message,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-467113459,1,['message'],['message']
Integrability,"@cmnbroad After looking more, I have two comments: . 1) I agree that override of toString() was awkward. @ldgauthier or someone else at GATK might have more comments, but I think it can be dropped. 2) Some kind of getSimpleName() method directly on the interface, defaulting to getClass().getSimpleName() would be reasonable; however, it needs to be on Annotation, not VariantAnnotation, to be useful. . In this updated PR, I remoted the override of toString(), removed AbstractInfoFieldAnnotation, and left just the two interfaces: InfoFieldAnnotation and GenotypeAnnotation. The results in a relatively minor overall change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7041#issuecomment-767872455:253,interface,interface,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041#issuecomment-767872455,2,['interface'],"['interface', 'interfaces']"
Integrability,"@cmnbroad Any further thoughts on this? when removing the toString() override (which did not appear to do anything so far as I could see), this Class -> Interface change ends up being fairly minor.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7041#issuecomment-774234474:153,Interface,Interface,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041#issuecomment-774234474,1,['Interface'],['Interface']
Integrability,@cmnbroad Can you have a look at this when you get a chance and provide high-level feedback related to eventual integration with the `PythonScriptExecutor` and any dependency-related issues? Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344692455:112,integrat,integration,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344692455,2,"['depend', 'integrat']","['dependency-related', 'integration']"
Integrability,"@cmnbroad Could you make this bug your top priority, if possible? This appears to be a rather serious issue with GATK4/htsjdk cram support. Depends on the merge of https://github.com/broadinstitute/gatk/pull/1670 for the `PrintReads` test case and test file, but this problem existed before that patch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1673#issuecomment-203660996:140,Depend,Depends,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1673#issuecomment-203660996,1,['Depend'],['Depends']
Integrability,"@cmnbroad Depending on whether you like my changes in VariantEvalEngine.createVariantStratifier() and createVariantEvaluator() or not, I think I just committed changes for all your comments. I actually have not built another project using a local GATK JAR - would you mind saying a little more on that? I agree that would be important here to make sure our VariantQC tool can work with this VariantEvalEngine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759118836:10,Depend,Depending,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759118836,1,['Depend'],['Depending']
Integrability,@cmnbroad Great - thanks for working with us on this. One related question: our VariantQC tool is a separate project (gradle) that depends on GATK4. Is there a way to depend on some kind of dev version of GATK4 that will include the VariantEval code?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440739574:131,depend,depends,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440739574,2,['depend'],"['depend', 'depends']"
Integrability,"@cmnbroad I [tried to convince you](https://github.com/broadinstitute/gatk/pull/5378#issuecomment-443382334) that a test on jimfs was better than an integration test, because it exercises the same code (from the parts we want to test, I assume we're not interested in testing GCS itself) but runs faster. Since you insist, I can certainly do the same as an actual integration test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455658014:149,integrat,integration,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455658014,2,['integrat'],['integration']
Integrability,"@cmnbroad I figured I'd bump an old issue rather than create a new one, but my group would also appreciate if more gatk tools supported stdin / stdout. I've noticed that several of the Picard versions of tools support reading from stdin, but the Spark gatk replacements do not. MarkDuplicates is a big one, MarkDuplicates accepts /dev/stdin as input, but MarkDuplicateSpark does not. For the spark tools, this may be more work because they are chunking the file and splitting it across threads / processes, but it would be great if there were a solution for GATKPath / HtsPath to identify that we're operating on stdin / stdout and not use Files.newInputStream, and instead did something like wrap System.in in a BufferedReader if that's more appropriate. I realize that not all tools will be able to do this, because clearly you can't get random I/O to a file through a pipe, but there are plenty of tools that just read a single large file once through. There's a collection of older issues around better stdin/stdout support or at the least documentation around this:; https://github.com/broadinstitute/gatk/issues/5779; https://github.com/broadinstitute/gatk/issues/2236",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6749#issuecomment-1092237787:693,wrap,wrap,693,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6749#issuecomment-1092237787,1,['wrap'],['wrap']
Integrability,@cmnbroad I moved this message so it runs during the actual task execution rather than at configuration time.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4147#issuecomment-357371881:23,message,message,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4147#issuecomment-357371881,1,['message'],['message']
Integrability,"@cmnbroad I put in a test in GATK that should fail if the dependency is moved to Picard. So, you are 100% correct that these changes will need to go into Picard.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3250#issuecomment-316558645:58,depend,dependency,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3250#issuecomment-316558645,1,['depend'],['dependency']
Integrability,"@cmnbroad I refactored the training java wrapper into separate wrappers to write tensors (CNNVariantWriteTensors.java) and to train (CNNVariantTrain.java) I think this simplified the meaning/necessity of many of the arguments, which was unclear when all those tools were rolled together. . I'm working on a release-style integration test that chains all the tools together, like @droazen discussed a few meetings ago, but for this PR I think I will have to do something simpler. Because of some issues with the GSA5 environment and GPU, I still have to write in a Python2/3 agnostic way, which precludes the use of type hints. I would like to update, but I'm blocked by BITs in the short term.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432:41,wrap,wrapper,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432,3,"['integrat', 'wrap']","['integration', 'wrapper', 'wrappers']"
Integrability,"@cmnbroad I think this proposal is good provided that the error message people get clearly explains what they need to do to resolve things when this happens (eg., explains which dependencies have changed and how to mark the changes as ""ok"")",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2592#issuecomment-300897729:64,message,message,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2592#issuecomment-300897729,2,"['depend', 'message']","['dependencies', 'message']"
Integrability,"@cmnbroad I understand that I could have retained a bunch of single-use text files, but it seemed like the more permutations one adds, the less it makes sense to have a separate, very redundant, static text file to check each scenario. There's a ton of VariantContext-related tests that parse the output VCF to test some feature as opposed to checking in a bunch of VCF text files.... While I'll grant the 4th test case I added (where we pass chr 2) isnt especially compelling over just testing chr 1, one could argue more breadth is a good thing here. if you want clarity, pulling that VariantEval report parsing code into a method called extractUniqueContigsFromEvalReport(), or simply adding a comment line, supports this goal. Anyway, I'm checking in slightly clarified version of this now, simply to get tests running. If you respond to the above, maybe we go with that. In the interest of time, I'll stage and check in the version which restores the text files and goes that route.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7238#issuecomment-831459741:981,rout,route,981,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7238#issuecomment-831459741,1,['rout'],['route']
Integrability,"@cmnbroad Looks good, just kill that file that snuck back in and assure me that the progress logger actually outputs messages and not some variant of `StringArray[10929123@asdfa]` :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/612#issuecomment-126799547:117,message,messages,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/612#issuecomment-126799547,1,['message'],['messages']
Integrability,"@cmnbroad OK, considerable progress here. I was able to adjust behavior such that only two tests have changed behavior from GATK4/master. I think this is now correct. One instance of changed behavior is the Snpeff/overlap one we discussed above. The second is the one where we now provide the full genome as REF, not the truncated genome. I think this difference is justified since the tool now requires a reference, and the prior version was arguably too lenient on validation of contigs. Anyway, this branch now also removes by debugging code and comments. I think it is ready for a review. To some other questions you had above:. 1) The HashMap<FeatureInput<VariantContext>, HashMap<String, Collection<VariantContext>>> can be wrapped in a class with just a couple of methods, so we don't have to manifest that long type all over the place. I realize that's non-optimal, but this isnt anything I introduced here. I would really like to keep this PR as limited as we can, and address some larger refactoring in a different PR, once we've migrated to MultiVariantWalkerGroupedOnStart. 2) I know this PR still in an interim state, but passing the VariantWalker in as an argument to the comp methods doesn't seem like a step forward to me. If we can't solve that problem completely in this PR (which is fine, I'm all for trying to contain this), are those changes necessary ? Perhaps that part should just wait for the next round. As noted above, I'd like to propose this as iterative, with a second PR coming soon. I did this b/c it moved us toward not needing to pass around the walker. It minimizes the code that has access to the walker (as opposed to setting it after creating the instance of the Evaluator, etc. Yes, it exposes it for two methods, but those classes no longer hang on to it. I would like to ultimately remove this entirely. 3) To re-iterate testEvalTrackWithoutGenotypesWithSampleFields: the input file, noGenotypes.vcf, has a header dictionary with the full set of contigs, and a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-747619130:730,wrap,wrapped,730,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-747619130,1,['wrap'],['wrapped']
Integrability,"@cmnbroad OK, so I see that I can supply a custom --gatk-config file on the command line, and I suppose I would also provide my other JAR on the classpath with my additional VariantAnnotation classes? That is useful, but also a little unclean given I am already building our DISCVRseq JAR, which includes the GATK4 dependency. I'm still inclined to make our tool that extends GATK's VariantAnnotation, and override makeVariantAnnotations(). I could either manipulate GATKAnnotationPluginDescriptor, or make my own to scan the expected package(s). It seems pretty surgical and less would be required of the user to run it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6929#issuecomment-720610784:315,depend,dependency,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6929#issuecomment-720610784,1,['depend'],['dependency']
Integrability,"@cmnbroad On these blocking PRs. The core point is to provide a way to link FeatureInput to VariantContext. The existing PRs stash FeatureInput name as the VariantContext source. I dont know if there are internal deliberations or anything holding up getting those done, or blocking my offer to try to implement that. However, I wonder what you think about a possible alternate approach. The driving use for this feature is MultiVariantWalkers and their subclasses. Another way to tackle this might be to hook into MultiVariantDataSource. One could create a wrapper class:. ```; public class VariantContextWithSource {; VariantContext variant;; FeatureInput source;; }. ```; And the iterator layer would wrap the VariantContext objects with this class, making a non-text link to FeatureInput. And perhaps either a) apply() would get called with this wrapper instead of VariantContext, or b) MultiVariantWalker might be able to get converted into MultiVariantWalker<T> where T is the class provided to apply(). I havent fully explored this, but it might be a more convenient way to share implementations. I could try to make this more concrete and propose something, but I dont want to spend work if the concept of wrapping VariantContext into something like VariantContextWithSource isnt going to go anywhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-795835307:557,wrap,wrapper,557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-795835307,4,['wrap'],"['wrap', 'wrapper', 'wrapping']"
Integrability,"@cmnbroad Sorry I should have been clearer. I meant unzipping the gatk release file. Unzipping the gatk release file places both files in the sample directory as below. I tried to create the gatk conda environment in the directory, which was failed due to the path issue.; ```; $ unzip src/gatk-4.0.0.0.zip; Archive: src/gatk-4.0.0.0.zip; creating: gatk-4.0.0.0/; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-local.jar; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-spark.jar; inflating: gatk-4.0.0.0/gatk; inflating: gatk-4.0.0.0/README.md; inflating: gatk-4.0.0.0/gatk-completion.sh; inflating: gatk-4.0.0.0/gatkcondaenv.yml; inflating: gatk-4.0.0.0/gatkPythonPackageArchive.zip; $ cd gatk-4.0.0.0; $ conda env create -n gatk -f gatkcondaenv.yml; ```. It appears simpler to have conda manage both Python and R dependencies. I am not sure if it's easily possible to move away from R-3.2.5 though. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267:811,depend,dependencies,811,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267,1,['depend'],['dependencies']
Integrability,@cmnbroad That is correct. Once upon a time it was waiting on the VariantAnnotator to be integrated before advancing on it but now its being held in place by newtons first law. I will take a look at updating the branch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4604#issuecomment-376909187:89,integrat,integrated,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4604#issuecomment-376909187,1,['integrat'],['integrated']
Integrability,"@cmnbroad The path to the c++ compiler can be specifically provided to theano by setting `theano.config.cxx` in python scripts, or by creating a `.theanorc` in the home directory, or by setting the environmental variable `THEANO_FLAGS=cxx=<path_to_g++>,...`. If a working c++ compiler exists and provided to theano, it is fair to assume that the graph _will_ compile. If the c++ compiler is not explicitly specified, theano will try to discover it. It first tries to execute `g++ -v` in the present environment and if it succeeds, it resolves the absolute path to the executable. On darwin, it further searches for `clang++` and on Win32, it looks for a working mingw gcc setup. We could _enforce_ the presence of a c++ compiler at the beginning of all python scripts and throw an exception and an informative message instead of numpy/python fallback. If we do so, the integration tests (and all gCNV CLI tools) will fail and will force the user to install a c++ compiler. In your opinion, is this fail-fast strategy a better approach, given that python fallback runs 2~3 orders of magnitude slower?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350193484:810,message,message,810,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350193484,2,"['integrat', 'message']","['integration', 'message']"
Integrability,"@cmnbroad and I were looking yesterday at the process for building GATK4 protected with a custom htsjdk snapshot, and we found that we couldn't get the htsjdk snapshot to propagate all the way through to protected unless we excluded htsjdk from our GenomicsDB dependency:. ```; - compile 'com.intel:genomicsdb:0.3.0'; + compile ('com.intel:genomicsdb:0.3.0') {; + exclude module: 'htsjdk'; + }; ```. Without this, htsjdk gets pulled in transitively via GenomicsDB. @lbergelson @kgururaj @kdatta Can you think of any reason why we shouldn't make this change?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2578:260,depend,dependency,260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2578,1,['depend'],['dependency']
Integrability,"@cmnbroad commented on [Mon Apr 10 2017](https://github.com/broadinstitute/gatk-protected/issues/982). By default, Gradle resolves version dependency conflicts amongst transitive dependencies by choosing the newest version of any particular module that has conflicts. GATK public overrides this and forces resolution to specific versions for some modules like htsjdk and protobuf, but gatk-protected doesn't. So gatk-protected can wind up using a different version of a dependent module than GATK uses. This is currently happening with protobuf, but it could happen with htsjdk or other modules. Short term, we probably want to use ""force"" resolution for htsjdk and protobuf in gatk-protected (ideally to force them to be resolved to the ones pulled in via the gatk dependency). Longer term, we should probably use a resolution policy of ""failOnVersionConflict"" in both gatk and protected, which will force us to manually resolve any conflicts as they arise, rather than depending on Gradle to do the resolution for us. ---. @droazen commented on [Mon Apr 10 2017](https://github.com/broadinstitute/gatk-protected/issues/982#issuecomment-293032625). Let's treat this one as high priority -- we really need to fix this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2967:139,depend,dependency,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2967,5,['depend'],"['dependencies', 'dependency', 'dependent', 'depending']"
Integrability,@cmnbroad ignore the previous message -- I managed to add MKL to the docker.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350290589:30,message,message,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350290589,1,['message'],['message']
Integrability,"@cmnbroad rebasing is done. To summarize changes since your last review:. - I backed out the earlier changes to FeatureInput/FeatureDataSource in favor of those from #7219 ; - I dont entirely know why this didnt hit before, but I made an update to VariantStratifiers to make tests pass. See: https://github.com/broadinstitute/gatk/pull/6973/commits/1569a909d3dc2301337e46441cc0cd969843c8d1. The gist is that we now instantiate those classes and pass VariantEvalEngine. Two of these classes had validation in their constructors, and could throw a CommandLineException if the tool was executed with bad arguments. This exception was getting caught and re-thrown as GATKException with the misleading message ""Problem making an instance of ...."". This proposal is to make a separate VariantStratifier.validateArgs() method, with a default no-op validation, and to call this only after instantiation. This was already exercised under the tests, such as testMultipleEvalTracksAlleleCountWithoutMerge(). VariantEval tests pass locally for me. With luck, tests will pass here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827805993:697,message,message,697,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827805993,1,['message'],['message']
Integrability,"@cmnbroad yes, was literally just checking that in. I agree it's probably better to rethrow and preserve the stack than preserving the original class like my first commit did. Do you expect that so few of the travisci suites seem to actually run these integration tests? only three actually failed?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827938856:252,integrat,integration,252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827938856,1,['integrat'],['integration']
Integrability,"@cmnbroad, I'm thinking about a use case for no filters allowed for the user of the tool. Imagine that you want to pull down some evidence for discordant read pairs (for instance, for SV), and the user provides a read filter which removes this kind of signatures. Could it be possible to generate an interface for the `ReadFilterArgumentCollection` and implementations for no-exposed/exposed to the final user?. This will be similar to the optional/required arguments for reads, reference and so on...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1900#issuecomment-225941325:300,interface,interface,300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1900#issuecomment-225941325,1,['interface'],['interface']
Integrability,"@cmnbroad, that's not wholly unreasonable, but i'd like to push back on a number of these points. . 1) First - would GATK consider simply letting us take over VariantEval and maintain as a GATK4-based tool in another repo? My understanding from GATK4 issues is that plan was to never migrate VariantEval (i think in favor of other picard/gatk QC tools). There is a bit of a conflict between keeping a lean core engine and having all these tools built off it. I would think there's an argument for keeping your core engine and the many tools built off it separated (GATK3 seemed to include some dead tools, for example). I appreciate we're the ones pushing this migration, but I hope on the other side you can appreciate the bar is pretty significant on our time. . 2) What new plugins are you talking about? VariantStratification and VariantEvaluator are part of GATK3's VariantEval? Yeah, I wrote a base PluginDescriptor class patterned on how ReadFilters work. It probably should exist in a more core position in code. While there's some good ideas in the argument-parsing/plugin code of GATK/Barlcay, frankly seems like much of it isnt fully developed yet, which is why I kept this separated at the moment. . 3) Be aware, the GATK3 tests depend on ~30GB of files. I dont know the limits of git lfs, but I did not currently have plans to check those in. I assumed I would convert these to use GATK4 chr20/21 data for a final commit, but felt there was a lot of value in using unaltered GATK3 data to confirm parity (and it was during the migration).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407123968:1241,depend,depend,1241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407123968,1,['depend'],['depend']
Integrability,"@cwhelan & @ldgauthier sorry for the delay on getting back this issue. Firstly, I just grabbed the new release (4.0.12.0) and re-ran with that to generate both gVCF and VCF. The VCF output still generates the 1/1 genotype unfortunately. What's interesting though is that the gVCF is capturing the spanning allele! So it looks like `GenotypeGVCFs` is causing the problem. Here are the rows from the gVCF and VCF respectively (with INFO elided for compactness):. ```; # gVCF; chr6 42932200 . GGC TGT,<NON_REF> 1623.73 . GT:AD:DP:GQ:PL:SB 0/1:39,44,0:83:99:1661,0,1458,1778,1591,3369:10,29,14,30; chr6 42932202 . C T,*,<NON_REF> 3439.77 . GT:AD:DP:GQ:PL:SB 1/2:1,37,44,0:82:99:3468,1802,1661,1518,0,1449,3406,1802,1577,3436:0,1,24,57. # VCF; chr6 42932200 . GGC TGT 1632.77 . GT:AD:DP:GQ:PL 0/1:39,44:83:99:1661,0,1458; chr6 42932202 . C T 3439.77 . GT:AD:DP:GQ:PL 1/1:1,37:82:99:1807,141,0; ```. For completeness I also ran HaplotypeCaller going direct to VCF without making a gVCF first. The results are fairly similar to the VCF above, except for some AD/DP differences:. ```; # Direct to VCF; chr6 42932200 . GGC TGT 1623.73 . GT:AD:DP:GQ:PL 0/1:39,44:83:99:1661,0,1458; chr6 42932202 . C T 3439.77 . GT:AD:DP:GQ:PL 1/1:1,50:51:99:1807,141,0; ```. Going back to what's the right representation - I think I largely agree with @nh13 and @ldgauthier that long term it would be nice, when running with MNP support, to integrate the two haplotypes into a single variant output. But that sounds like it might be a big project and not happening any time soon? In the meantime if there's an easier fix to have the `*`/spanning allele called in the VCF propagated into the genotyped VCF that would really help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-449758576:1415,integrat,integrate,1415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-449758576,1,['integrat'],['integrate']
Integrability,"@cwhelan , addressed comments in 4 commits, with the first 3 addressing requested changes in main and the last dealing with integration test.; Please review again. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2621#issuecomment-298986792:124,integrat,integration,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2621#issuecomment-298986792,1,['integrat'],['integration']
Integrability,"@cwhelan @tedsharpe please review. There are 4 new classes here:. 1. LongHopscotchSet - based on HopscotchCollection/Set but adapted to store primitive longs instead of objects. The most significant bit is used to tell if a bucket is null or not, so the longs being stored must be non-negative. This works for use with k-mers, which we are assume are odd-length up to 31 and thus consume up to 62 bits.; 2. LargeLongHopscotchSet - for sets of longs greater than ~2 billion (the max Java array size) using a List of LongHopscotchSets.; 3. LongBloomFilter - Bloom filter for long's; 4. LargeLongBloomFilter - Bloom filter when the filter index size exceeds 2GB using a List of LongBloomFilters. - LongIterator and QueryableLongSet interfaces for convenience.; - Minor change to HopscotchSet max legal size, which was higher than the actual allowed Java array size. PS I just had a thought that the Bloom filters could use long instead of byte buckets to expand the max index size 8-fold. Could maybe be done for the Hopscotch sets as well, but with considerably more difficulty. Thoughts? On the other hand, the performance is already adequate so perhaps I'll save this idea for later.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2729:729,interface,interfaces,729,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2729,1,['interface'],['interfaces']
Integrability,@cwhelan I've addressed the comments in the separate commits. The commit messages decribes what was done in each push.. Please take another look. Thanks!. The tests are failing because of travis. They run successfully when manually rebooted but the status here don't get updated...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2567#issuecomment-292063168:73,message,messages,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2567#issuecomment-292063168,1,['message'],['messages']
Integrability,"@cwhelan I've been thinking about this a lot more since we were looking at your integration test results. The PGT calls are inconsistent between HaplotypeCaller/CombineGVCFs and GenotypeGVCFs since we correct hom vars with 0|1 PGT in GGVCFs: https://github.com/broadinstitute/gatk/blob/851c8408d11042a402debf183d4fb69048a16c0e/src/main/java/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFsEngine.java#L436; but I like the idea that the PGT is still showing that there are two different haplotypes at that site. I'm leaning towards removing that ""cleanup"", which will mean a lot of hom var sites will have PGTs that are ""inconsistent"" as the user was complaining about, but I will add some documentation. What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-705613003:80,integrat,integration,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-705613003,1,['integrat'],['integration']
Integrability,"@cwhelan It seems like this is resolved, closing it unless you think there's something we should do here. Fixing yarn to give a sane error message when executors die is outside of our scope I think :/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1491#issuecomment-333233948:139,message,message,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1491#issuecomment-333233948,1,['message'],['message']
Integrability,"@danxmoran This is the bug you're seeing too. I haven't gotten a chance to try any of the suggestions above yet, but I'm hoping to start this afternoon. Also, just for completeness I saw a new error message today that I think Dan saw too (this time from PrintReads):. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -Xms2g -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar PrintReads -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-GatherBamFiles/CHMI_CHMI3_WGS2.bam --interval_padding 500 -L /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/1scattered.interval_list -O local.sharded.bam; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.l7eTB5; [July 21, 2017 6:20:54 PM UTC] PrintReads --output local.sharded.bam --intervals /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/1scattered.interval_list --interval_padding 500 --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-GatherBamFiles/CHMI_CHMI3_WGS2.bam --interval_set_rule UNION --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:199,message,message,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564,1,['message'],['message']
Integrability,"@david-wb @popboy126 I'm having trouble reproducing the shutdown issue on our own cluster, I sometimes get the message `Shutdown hook called before final status was reported.` but the job status is SUCCEEDED. This happens if I run with the System.exit(0) or not. Could one of you test with this branch and let me know if it solves your issue? I think my cluster configuration must be different then yours in some way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319778125:111,message,message,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319778125,1,['message'],['message']
Integrability,"@david-wb Interesting... what version of spark / spark submit are you using? I was pretty sure that at the point where setMaster() was called by gatk the spark context was already created by yarn and setup with the appropriate master. I wonder if it changed from a previous version of spark... Alternatively, I may be misremembering and relying on the fact that our wrapper script supplies `--sparkMaster yarn` as a gatk argument which would probably override what's being set. Could you try:; ```; spark-submit \; --deploy-mode client \; --class org.broadinstitute.hellbender.Main \; --master yarn \; /home/hadoop/gatk-package-4.alpha.2-269-gdce8abc-SNAPSHOT-spark.jar BwaSpark \; --bwamemIndexImage /var/tmp/hs38DH-V.fasta.img \; -I hdfs:///unaligned.bam \; -O hdfs:///aligned.bam \; -R hdfs:///hg38/hs38DH-V.fasta \; --disableSequenceDictionaryValidation true \; --sparkMaster yarn; ```. or with the wrapper: ; ```; GATK_SPARK_JAR_ENV_VARIABLE=/home/hadoop/gatk-package-4.alpha.2-269-gdce8abc-SNAPSHOT-spark.jar. ./gatk-launch \; --bwamemIndexImage /var/tmp/hs38DH-V.fasta.img \; -I hdfs:///unaligned.bam \; -O hdfs:///aligned.bam \; -R hdfs:///hg38/hs38DH-V.fasta \; --disableSequenceDictionaryValidation true \; -- \; --sparkRunner SPARK \; --sparkMaster yarn; ```. Our wrapper script sets a number of properties which we think are important for running our spark tools. If running directly on spark you might want to set them explicitly. Things like `-Dsamjdk.compression_level=1` have MAJOR performance implications. . Also, be aware the BwaSpark is not in the best health at the moment may have issues. If you're running it you may want to run the version that's in this branch which is currently under review https://github.com/broadinstitute/gatk/pull/2494.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2718#issuecomment-301925138:366,wrap,wrapper,366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2718#issuecomment-301925138,3,['wrap'],['wrapper']
Integrability,"@davidadamsphd Sure, here is a quick guide to the code:. -`BaseRecalibratorSpark` is the standalone BQSR tool, and calls into the `BaseRecalibratorSparkFn` (which is also called from `ReadsPipelineSpark`). -`ApplyBQSRSpark` is the standalone ApplyBQSR tool, and calls into the `ApplyBQSRSparkFn` (also called from `ReadsPipelineSpark`). -Integration tests for the above are in `BaseRecalibratorSparkIntegrationTest` and `ApplyBQSRSparkIntegrationTest`. -Almost all other changes in the branch are related to the BQSR engine refactoring, which I summarize below:; - We pulled out the guts of the walker `BaseRecalibrator` tool, combined it with all of the code from the former `RecalibrationEngine` class (now deleted) to make a new `BaseRecalibrationEngine` class under `utils/recalibration`.; - We stripped out all copies of the code in `BaseRecalibrationEngine` from the walker, dataflow, and spark versions of BQSR, and modified them to call into `BaseRecalibrationEngine`.; - We moved all auxiliary classes needed by the `BaseRecalibrationEngine` (eg., the covariates, etc.) into `utils/recalibration`.; - We refactored the argument collections. Now there is a single shared `RecalibrationArgumentCollection` that contains **only** the parameters for the `BaseRecalibrationEngine` itself, and this argument collection is exposed by all 3 versions of the tool. Input/output arguments have been removed from this argument collection and put into the individual implementations of BQSR, since they vary between the walker, dataflow, and spark versions of the tool. This eliminates awkward problems such as having both a `knownSites` argument AND a `BQSRKnownVariants` exposed at the same time, with only 1 of them usable for a given version of a tool. The dataflow-only `BaseRecalibrationArgumentCollection` has been deleted completely as no longer needed.; - We tweaked the names of some tool arguments to enforce consistency between the 3 versions of the tool as well as the rest of hellbender (eg.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142340073:338,Integrat,Integration,338,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142340073,1,['Integrat'],['Integration']
Integrability,"@davidadamsphd passing through would work, but it's going to take some work. And if we have to do this for every single object that may be different between Spark and Dataflow, we may have more interface-redefining ahead of us. There may be another way. Perhaps we can use the name of the ""referenceset"" to distinguish the cases, as ReferenceDataflowSource has started doing. It's already the case that if you're using RefAPI, your reference name is going to be gg://reference/_some_id_. This is easy to distinguish from e.g. a Hadoop DFS path. We could use a similar mechanism for the mocks: perhaps have a special case in ReferenceDataflowSource that if the referenceset name is ""mock"", then it returns the static ReferenceDataflowSource.mockInstance member (that the test would then have to set up, naturally, just like it calls setInstance today). This is closer to what @tomwhite wrote, and may satisfy all of the goals of point (1). What do you both think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/804#issuecomment-130905343:194,interface,interface-redefining,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/804#issuecomment-130905343,1,['interface'],['interface-redefining']
Integrability,"@davidbenjamin Can you implement a simple integration test for this arg, to ensure it doesn't break again?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4128#issuecomment-357045030:42,integrat,integration,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4128#issuecomment-357045030,1,['integrat'],['integration']
Integrability,"@davidbenjamin Can you tell me whether this is a straight-up port of the GATK3 version of this code, or whether you've made any changes in the process of porting?. I will test out this change, in combination with a change from @samuelklee / @ronlevine, in a branch in protected, and craft passing integration tests there before merging this here in public.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2710#issuecomment-301086407:297,integrat,integration,297,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2710#issuecomment-301086407,1,['integrat'],['integration']
Integrability,"@davidbenjamin Discovered that importing hellbender as a dependency fails now that we have add spark dependencies. This is easily fixed by including the following (or it's non-gradle equivalent) in your build file, but it shouldn't be necessary. ```; maven {; url ""https://repository.cloudera.com/artifactory/cloudera-repos/"" // spark-dataflow; }; ```. We should update our artifact so that it includes the necessary information to download the spark dependencies.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/779:57,depend,dependency,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/779,3,['depend'],"['dependencies', 'dependency']"
Integrability,"@davidbenjamin I added the AF thresholding and limited it to just the NON_REF allele. There's a mildly awkward check in the integration test for it. If you can formulate an elegant unit test that makes for nice round numbers I'm happy to add it, but that's beyond me. I lost the new Twist exome, but once I can get ahold of it I'll make a GVCF and see what happens.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-449127402:124,integrat,integration,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-449127402,1,['integrat'],['integration']
Integrability,"@davidbenjamin I checked with our diagnostic lab director about which data can be put on the public repo (anonymized of course). The only file that cannot be used is the one labeled ""Exome_NBPF16_SNP.bam"", the other bam files I shared with you are from control samples and can be used in the integration test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-453800471:292,integrat,integration,292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-453800471,1,['integrat'],['integration']
Integrability,"@davidbenjamin I figured out that particular case we talked about earlier. The case (`depth = 0` but `PileupElement` is not empty) happens when all the reads have deletion at the locus. Instead of logging a message, now I simply skip such a locus.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3721#issuecomment-348321755:207,message,message,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3721#issuecomment-348321755,1,['message'],['message']
Integrability,"@davidbenjamin I think that is a bit of a cop out. I would have been happy to use a provided resource but there was none to be found for hg38. I had to do a liftover for the gnomAD data and that introduced subtle changes to the VCF that invoked this bug in <20% of my samples after hours of processing without any sensible error message to lead me onto what was the cause of the problem. I have wasted many days on debugging this issue and creating a bug report and I was considering switching to GATK3 or some other variant caller because of it. I think someone else reported a very similar issue on the forum and went back to using GATK3. . Maybe Mutect2 should, by default, run a filter on the pop resource VCF to get rid of unnecessary or erroneous lines. When users get more familiar with the algorithm, they could disable this filtering to save time and provide a pre-filtered VCF (--germline-resource or --germline-filtered-resource).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5391#issuecomment-435840613:329,message,message,329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5391#issuecomment-435840613,1,['message'],['message']
Integrability,"@davidbenjamin I've spun this off into a separate ticket. I think this might be serious/widespread enough that we'll want a 4.1.6.1 release once we have a working fix. I recommend that we manually do full-scale test runs of both HaplotypeCaller and Mutect2 to confirm that the issue is resolved rather than relying on the integration tests, which are not large-scale enough to catch edge cases like this, unfortunately.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-606748607:322,integrat,integration,322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-606748607,1,['integrat'],['integration']
Integrability,"@davidbenjamin Just added an additional automated test thanks to @sooheelee , but please ignore commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3538#issuecomment-326306087:103,message,message,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3538#issuecomment-326306087,1,['message'],['message']
Integrability,"@davidbenjamin LODs are fixed, but I'm not super happy with them. They fluctuate a lot, making for a big GVCF. How easy would it be to modify the likelihood calculation to integrate over all AFs greater than some threshold of interest? I'm hoping that would produce more stability. Just to give you an idea of the fluctuation, below are some lines from my integration test VCF where I block anything less than -2 and between -2 and 0. I tried a few other thresholds, but it's just a lot of variability. I have a hunch it has to do with the minimum base quality in the pileup. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT NA12878; chrM 1 . G <NON_REF> . . END=4 GT:DP:MIN_DP:TLOD 0/0:67:48:-1.958e+00; chrM 5 . A <NON_REF> . . END=5 GT:DP:MIN_DP:TLOD 0/0:107:107:-2.033e+00; chrM 6 . C <NON_REF> . . END=6 GT:DP:MIN_DP:TLOD 0/0:123:123:-1.603e+00; chrM 7 . A <NON_REF> . . END=8 GT:DP:MIN_DP:TLOD 0/0:135:135:-2.138e+00; chrM 9 . G <NON_REF> . . END=9 GT:DP:MIN_DP:TLOD 0/0:138:138:-1.975e+00; chrM 10 . T <NON_REF> . . END=13 GT:DP:MIN_DP:TLOD 0/0:178:154:-2.226e+00; chrM 14 . T <NON_REF> . . END=15 GT:DP:MIN_DP:TLOD 0/0:208:205:-1.974e+00; chrM 16 . A <NON_REF> . . END=23 GT:DP:MIN_DP:TLOD 0/0:259:218:-2.424e+00; chrM 24 . A <NON_REF> . . END=25 GT:DP:MIN_DP:TLOD 0/0:312:310:-8.945e-01; chrM 26 . C <NON_REF> . . END=26 GT:DP:MIN_DP:TLOD 0/0:317:317:-2.509e+00; chrM 27 . C <NON_REF> . . END=27 GT:DP:MIN_DP:TLOD 0/0:335:335:-1.962e+00; chrM 28 . A <NON_REF> . . END=50 GT:DP:MIN_DP:TLOD 0/0:492:343:-2.821e+00; chrM 51 . T <NON_REF> . . END=51 GT:DP:MIN_DP:TLOD 0/0:700:700:-3.808e-01; chrM 52 . T <NON_REF> . . END=63 GT:DP:MIN_DP:TLOD 0/0:822:722:-2.943e+00; chrM 64 . C <NON_REF> . . END=64 GT:DP:MIN_DP:TLOD 0/0:909:909:-1.492e+00; chrM 65 . T <NON_REF> . . END=86 GT:DP:MIN_DP:TLOD 0/0:1064:938:-3.065e+00; chrM 87 . A C,<NON_REF> . . DP=942;ECNT=8;POP_AF=5.000e-08,5.000e-08;TLOD=-2.463e+00,-2.668e+00 GT:AD:AF:DP:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:ORIGINAL_CONTIG_MISMATCH:SA_MAP_AF:SA_PO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-437501517:172,integrat,integrate,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-437501517,2,['integrat'],"['integrate', 'integration']"
Integrability,"@davidbenjamin OK, we have a utility method in `AbstractLocatableCollection` that essentially enables this for our particular use case (sorting and concatenating sharded tables, which are themselves non-overlapping and sorted, and returning the sort order; no reason why we couldn't just return the resulting concatenated table, either). These sorts of methods can be easily made generic if we have good base classes for individual locatable records that implement the appropriate interfaces.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-480968991:481,interface,interfaces,481,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-480968991,1,['interface'],['interfaces']
Integrability,"@davidbenjamin Sorry I've been out and just got around to looking at this. Given that this test appears to run just fine in the Java 11 job (which is not run on our docker), I suspect the failure may have something to do with the jar file we use to test on the docker (which is not the same jar we use on the non-docker tests). . I pulled your branch and all of the generation tasks (gatk doc, wdl gen, javadoc) seem to work fine, so given how much time it looks like this has taken up, I think it would make sense to either disable this test (on the docker only - see below - since we want it to still run in the other CI integration test job), or else remove the variantcalling package from the test package list (if thats the one thats causing the failure ?). And then create a ticket for me with whatever data you have, which I'll follow up on. If you restore everything to its natural state, you should be able to add this to the `DocumentationGenerationIntegrationTest.documentationSmokeTest` method and then it will be skipped only when running on the docker:. ```; final DocumentationGenerationIntegrationTest dt = new DocumentationGenerationIntegrationTest();; if (dt.isGATKDockerContainer()) {; throw new SkipException(""See gatk issue #..."");; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1216668361:623,integrat,integration,623,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1216668361,1,['integrat'],['integration']
Integrability,"@davidbenjamin The bug here is that we misinterpreted what a TreeSet in java does. The actual behavior for this method was that it only took the FRIST variant at each start position that it saw from the ordering of the haplotypes it saw. This meant if a SNP and INDEL started at the same position then there was a chance that site only looks like a SNP to the subsequent trimming code and we trim incorrectly. . See the TreeSet docs:; ```; <p>Note that the ordering maintained by a set (whether or not an explicit; * comparator is provided) must be <i>consistent with equals</i> if it is to; * correctly implement the {@code Set} interface. (See {@code Comparable}; * or {@code Comparator} for a precise definition of <i>consistent with; * equals</i>.) This is so because the {@code Set} interface is defined in; * terms of the {@code equals} operation, but a {@code TreeSet} instance; * performs all element comparisons using its {@code compareTo} (or; * {@code compare}) method, so two elements that are deemed equal by this method; * are, from the standpoint of the set, equal. The behavior of a set; * <i>is</i> well-defined even if its ordering is inconsistent with equals; it; * just fails to obey the general contract of the {@code Set} interface.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-645528965:630,interface,interface,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-645528965,4,"['contract', 'interface']","['contract', 'interface']"
Integrability,"@davidbenjamin The message ""Flush-to-zero (FTZ) is enabled when running PairHMM"" is completely normal and not a sign of any problem. The ticket does not have enough detail for us to determine why the output file was empty.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4788#issuecomment-590928031:19,message,message,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4788#issuecomment-590928031,1,['message'],['message']
Integrability,@davidbenjamin We should chat about this in person -- have some questions for you. Some of the functionality you removed from the downsampler interface is needed by code that is not yet ported.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314200383:142,interface,interface,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314200383,1,['interface'],['interface']
Integrability,"@davidbenjamin as we just discussed, back from vacation now and modulo other circumstances (which we also just discussed) should be able to get this back to you in a week. If you could squash the commits after the last review, that might actually be a little cleaner for me to review---perhaps comment a copy of the squashed commit messages here if you'd like to keep them for posterity. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1112295304:332,message,messages,332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1112295304,1,['message'],['messages']
Integrability,"@davidbenjamin commented on [Thu Mar 31 2016](https://github.com/broadinstitute/gatk-protected/issues/432). Before integrating this with probabilistic segmentation, which is more complicated for somatic than for germline, we can simply replace the current tangent normalization step with the mode of the likelihood (as a function of copy ratio) resulting from the generative coverage model. This requires issues https://github.com/broadinstitute/gatk-protected/issues/429 and https://github.com/broadinstitute/gatk-protected/issues/430 to be completed. ---. @davidbenjamin commented on [Thu Mar 31 2016](https://github.com/broadinstitute/gatk-protected/issues/432#issuecomment-204015562). Also, this should only be attempted if we get good results from doing the equivalent in the germline code, issue https://github.com/broadinstitute/gatk-protected/issues/431. After it is done somatic and germline will share a PoN and all associated code, including tangent normalization. ---. @LeeTL1220 commented on [Mon Jun 06 2016](https://github.com/broadinstitute/gatk-protected/issues/432#issuecomment-223992660). This only needs to be done if we stick with CBS for segmentation. . At the very least, we need to implement this for checking performance against HMM.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2842:115,integrat,integrating,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2842,1,['integrat'],['integrating']
Integrability,"@davidbenjamin mutect2_pon.wdl and mutect2.wdl worked great without docker installed. Thanks!. @samuelklee @sooheelee As a user, I found a json template useful for two reasons, though it may be up to how a wdl is written.; 1) womtool generates inputs from all the dependent wdls including unnecessary ones for the workflow. (e.g. mutect2_pon.wdl); 2) womtool didn't provide default values. Looking at mutect_resources.wdl, I wondered what the good value for minimum_allele_frequency is (or what GATK team used for creating the resource bundle). In addition, I thought a test to validate every wdl would be helpful. (womtool validate [a wdl])",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256:264,depend,dependent,264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256,1,['depend'],['dependent']
Integrability,"@davidbenjamin thank you for your work and thank you for the clarification. Is this going to be code shared by the HaplotypeCaller as well? A lot of the analyses I do are dependent on the variance of the AD counts to be properly modeled, so I look forward to this improvement being implemented.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-524372694:171,depend,dependent,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-524372694,1,['depend'],['dependent']
Integrability,"@davidbenjamin, @fleharty agree with the implementation of PR #7003. ; I'm running that version comparing to samples previously reported 0 contamination and 0 std error.; will update here. One concern on the math Eq37 - Eq.42 calculate std (chi).; the math not taking into account the sample size (n) i.e number of homs.; note that we are starting with GetPileupSummaries output ~5k loci , ; filterSitesByCoverage keep ~300 loci ; filter segments + MAF keep variable number of loci depend on panel size etc. this number can vary and the question should the implementation will take it into account? i.e. reject the sample if n<NUM_LOCI (5,10,50???). **Thinking on the end user observing the Pair( contamination,stdError) and his interpretation on that...** . Probably adding the number of homs sites + strategy to final output as well as listing the pileups for the homsites will let the end user better understand the sample contamination output or even to find contaminant of a batch. **suggesting the following update to output file:**; sample	contamination	error; TUMOR	0.019245855721094312	0.0036809520099731763. sample, **strategy, n_loci,** contamination, error; TUMOR,HOM_ALT,M. list of homosites used; **contig	position	ref_count	alt_count	other_alt_count	allele_frequency**; PileupSummary1; PileupSummary2; ...; PileupSummaryM",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7177#issuecomment-833821730:482,depend,depend,482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7177#issuecomment-833821730,1,['depend'],['depend']
Integrability,"@ddrichel @jhl667 @schelhorn @xiucz I have a theory that, depending on the answers to the following questions, I may pursue further. 1. What are you using for a panel of normals in both WES and WGS?; 2. What reference assembly are you using?; 3. Were the new false positives present in the unfiltered Mutect2 VCF before version 4.1.9.0 (and then flagged by FilterMutectCalls) or absent entirely?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1202001839:58,depend,depending,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1202001839,1,['depend'],['depending']
Integrability,@drifty914 Do you encounter the ulimit message when you run a *single* shard (covering say 5000 intervals) of GermlineCNVCaller?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468308508:39,message,message,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468308508,1,['message'],['message']
Integrability,"@droazen , We made fixes for the vulnerabilities after java17 which was release last week. . Can you help to integrate this into GATK so that we can have new release. We have the files with patch ready. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2222021256:109,integrat,integrate,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2222021256,1,['integrat'],['integrate']
Integrability,"@droazen - Still some questions about integration tests (on the comment with your suggestion, but here too):. * I am not sure if the test that you are proposing will work with all the implementations of `createTempFile`: depends on how it is handle, as a `File` or as a `Path`; * I think that this depends a lot on the parts of the codebase that we are looking at, so maybe before accepting this a pass should be done for the usages and how the `java.io.tmpdir` is used. Waiting for your feedback before doing something that does not make sense...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269:38,integrat,integration,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269,3,"['depend', 'integrat']","['depends', 'integration']"
Integrability,"@droazen - That won't be solved by the current #3447, because there is no way of fine-tune the codecs: I require to being able to add/remove concrete classes, and exclude codecs from a concrete package. An example is a custom codec implementation for some feature, to provide extra-validation for the downstream toolkit. This would be even more useful if HTSJDK is moving to an interface-based library...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-337622596:378,interface,interface-based,378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-337622596,1,['interface'],['interface-based']
Integrability,"@droazen - a proposal for that, which will be great for my toolkit too, is to make `GATKTool` params an argument collection which defaults to the ones in the tool now, but can be change in a tool-basis. For example, if I have a `VariantWalker` which does not use any read-source, disabling all params for reads will be nice for re-use the `VariantWalker` interface without allowing the user to pass something that it is not used at all. It is not enough to provide a way to require or not a source, but to completely remove from the command line the ability to get that argument. I guess that's what it is required also for the CNV tools (correct me if I am wrong, @samuelkle), to be able to change that behaviour and to being able to provide custom documentation/arguments (re-factor the reads input `-I` to be other kind of input). I did something similar for the `ReadFilter` plugin to change the documentation and hide some arguments in my tools using it. Let me know if I can help with something in this direction, because it will be useful for me too...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358254662:355,interface,interface,355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358254662,1,['interface'],['interface']
Integrability,"@droazen - please, clarify how the tests should be done. I'm going to be on vacation next week, so feel free to add them to this branch if you would like to speed up the process (taking into account that #3998 depends on this now). Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-377577797:210,depend,depends,210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-377577797,1,['depend'],['depends']
Integrability,"@droazen - this is prepared from the next pass. Maybe you can answer the following questions before doing a full second pass:. * Your comment about ""Assert that you get the correct number of shards back"" is tested implicitly, by iterating over the expected shards. Should I really make it explicit?; * Does realistic size reads adds something to the unit test itself? The integration test for the real data (and probably a future PR with other sliding-window implementations) might be enough for the purpose of real data...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-389185267:372,integrat,integration,372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-389185267,1,['integrat'],['integration']
Integrability,@droazen :man_facepalming: I wish we had thought of this ahead of time so we could have done the appropriate commit message rewrites...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2814#issuecomment-306012234:116,message,message,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2814#issuecomment-306012234,1,['message'],['message']
Integrability,"@droazen ; * A field is imported into TileDB/GenomicsDB from the input VCF/gVCF files irrespective of whether the combine operation exists or doesn't exist.; * During the query phase, when GenomicsDBFeatureReader is executed, if the combine operation isn't specified (either in the source or in the vid JSON) for an INFO field, it will not be available in the combined VariantContext objects (warning message showed up front).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293997495:401,message,message,401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293997495,1,['message'],['message']
Integrability,@droazen @KevinCLydon If one of you wants to take a look at this that would be great. It updates a bunch of build and housekeeping stuff. It doesn't resolve all the dependency vulnerabilities yet.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8998#issuecomment-2414941314:165,depend,dependency,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8998#issuecomment-2414941314,1,['depend'],['dependency']
Integrability,"@droazen @cmnbroad @mbabadi I generally agree with the sentiments expressed in #4127, except that I think it's OK to require a conda environment (or even use of the Docker) for these particular tools. How we should validate this requirement is another question. We can discuss more with @vdauwera. @stefandiederich Hopefully once you get the conda environment set up you will be able to run the tools. We would definitely appreciate any feedback you might be able to provide. Note that the gCNV model is relatively sophisticated, so there may be some parameters (which control the priors for the model as well as how inference is performed) that you will need to adjust for your data. Depending on the number of intervals/bins you are using and your memory constraints, you may also need to scatter across multiple GermlineCNVCaller runs; see how things are done in the WDLs here: https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/germline. As you noted, this pipeline is still in beta. We are currently running several evaluations and hope to soon release some Best Practices recommendations for the aforementioned parameter values that should work well for various data types generated at the Broad. We will also have some blog or forum posts that explain the new CNV pipelines in more detail coming soon---stay tuned!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364:685,Depend,Depending,685,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364,1,['Depend'],['Depending']
Integrability,"@droazen @davidbenjamin any thoughts regarding the last bullet above in https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471 on possible integration tests? Started looking at this today and was wondering if you might have any suggestions. Ideally, we'd want to test that the exposure was done correctly through the 3 affected tools: HaplotypeCaller, Mutect2, and FilterAlignmentArtifacts. I can certainly take the approach outlined above and 1) on master, pick one or more integration tests for each tool, then generate results by changing the original unexposed constants and running on the relevant test data, 2) on this branch, commit those new results, then add corresponding versions of the integration tests that change the exposed inputs and check against the results. However, not sure if we'll want to clutter the repo with more test files just for this sort of exposing of constants, and such tests don't really feel complete anyway. So alternatively, I could probably write a script to do essentially the same thing and just check consistency between the branches for a bunch of randomly generated SW parameter values, perhaps also running on more substantial test files for each tool. I can document this process and then we can move on without committing any new tests or test files once we're satisfied that the exposure was done correctly. Or if you guys have additional suggestions, would be glad to hear them!. Finally, it looks like FilterAlignmentArtifacts doesn't have any integration tests for correctness---let me know if there are auxiliary tests we'd want to run there. Anyway, probably overthinking things, but the exposure was enough of a headache that I want to make sure I did it right. But would also rather fully hash out what to do beforehand, so I don't end up having to redo things after review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896314077:156,integrat,integration,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896314077,4,['integrat'],['integration']
Integrability,"@droazen @lbergelson, in the new changes, I throw an illegal arugment exception if FeatureReader is null in the sampleToReaderMap. Also, if the sample name in the sampleToReaderMap does not match with the one in the header, I print a warning message. Let me know if these two changes will fix this issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2715#issuecomment-302257170:242,message,message,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2715#issuecomment-302257170,1,['message'],['message']
Integrability,"@droazen @samuelklee this is a duplicate PR, I close the previous one. Travis was behaving strangely on the previous PR (oddly not picking up the correct commit for `continuous-integration/travis-ci/pr` test).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3183#issuecomment-311481750:177,integrat,integration,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3183#issuecomment-311481750,1,['integrat'],['integration']
Integrability,@droazen After wrangling with this for a few hours I couldn't quite even get rid of the chr20-21 b37 mini references. There are too many integration tests of deep parts of the engine that I don't feel comfortable messing with. I'm throwing in the towel.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5313#issuecomment-451712041:137,integrat,integration,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5313#issuecomment-451712041,1,['integrat'],['integration']
Integrability,@droazen An existing integration test already tested the full pipeline including merging VCFs with GenomicsDB and creating the panel. I modified the input VCFs to contain multiallelic sites that previously failed.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6871#issuecomment-705910895:21,integrat,integration,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6871#issuecomment-705910895,1,['integrat'],['integration']
Integrability,"@droazen Changes to the native code include removing SSE code, ifdef'ed code for profiling, and unused sandbox code. The goal is to reduce the amount of C code we need to maintain. Let me know if you have any concerns. We can have a code review after integrating into HaplotypeCaller. @lbergelson Thanks for helping debug the build. I doubt the code will build as is with clang, it currently uses gcc intrinsics to test machine capabilities. I added support for GATK_SKIP_NATIVE_BUILD env variable. Submitting changes to get debug info from Travis soon.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-185850134:251,integrat,integrating,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-185850134,1,['integrat'],['integrating']
Integrability,"@droazen Do we still even need `LeftAlignIndels`? It seems to duplicate behavior of `LeftAlignAndTrimVariants`, which does have an integration test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/150#issuecomment-577852333:131,integrat,integration,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/150#issuecomment-577852333,1,['integrat'],['integration']
Integrability,@droazen FYI I made a snapshot and pointed gatk-protected to it. All HaplotypeCaller-related unit tests and integration tests pass.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1918#issuecomment-232558536:108,integrat,integration,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1918#issuecomment-232558536,1,['integrat'],['integration']
Integrability,"@droazen I didn't get a chance to do this yet. Once I do (most likely during next week), I will post here about any progress. However, as per @mlathara's message (https://github.com/broadinstitute/gatk/issues/6667#issuecomment-646167430), I do expect this to fix the issue. This potential fix has already been implemented by the bcbio_nextgen guys, so I'm going to be testing that precisely (https://github.com/bcbio/bcbio-nextgen/commit/336920a630d7f50b341eeeb4bad4ea6ab213f995). For what it's worth, I do think that setting up the VCF codec as default (instead of BCF) makes sense, at least until this bug is fixed. https://github.com/broadinstitute/gatk/issues/6667#issuecomment-646232210",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6548#issuecomment-646706502:154,message,message,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6548#issuecomment-646706502,1,['message'],['message']
Integrability,"@droazen I don't really have much of an opinion about the loggers. I think we chose log4j2 pretty arbitrarily and because it seemed popular. We don't have very complex logging needs so any logger pretty much satisfied our needs. . If there's a good reason to switch to SLF4J with a log4j backend that seems fine to me. It makes sense to use the more general solution so that people can use whatever backend they want. . I do know that we've encountered a lot of issues with having multiple copies of different logging frameworks included as transitive dependencies on spark. So there may be some hassle switching over, we'd have to run tests on google cloud to make sure we don't start crashing all of a sudden for logger related classpath issues. . @magicDGS I don't think anyone here cares that much about which logger we're using as long as it doesn't get in our way. If you want to do the switchover I think we'd be happy to accept a pull request as long as it didn't cause problems with our spark tools. Are you able to run our spark tools on gcloud dataproc?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259003257:552,depend,dependencies,552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259003257,1,['depend'],['dependencies']
Integrability,"@droazen I investigated working in the other direction: i.e. refining the shading in google-cloud-java to remove the conflict. Unfortunately, I can't get it to work either. What I did was to shade less in google-cloud-java (see [this branch](https://github.com/tomwhite/google-cloud-java/tree/nio-bigquery)). With this change I could successfully run `ExampleBigQueryReader` from [this GATK branch](https://github.com/broadinstitute/gatk/tree/tw_jts_bigquery_spark_example): . ```; $ ./gradlew clean localJar; $ export GOOGLE_APPLICATION_CREDENTIALS=...; $ ./gatk ExampleBigQueryReader; ...; 14:16:43.468 INFO BigQueryUtils - Query returned 10 results.; ...; ```. However, the mini cluster for testing doesn't work any more:. ```; $ ./gradlew test -Dtest.single=ReadsSparkSinkUnitTest; org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSinkUnitTest.setupMiniCluster FAILED; java.lang.NoSuchMethodError: com.google.common.base.Objects.toStringHelper(Ljava/lang/Object;)Lcom/google/common/base/Objects$ToStringHelper;; ```. It seems that the Guava conflict can't be resolved either way, since the fundamental problem is that the internals of Hadoop (used for the mini cluster) depend on an older, incompatible version of Guava than BigQuery does.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-494393817:1190,depend,depend,1190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-494393817,1,['depend'],['depend']
Integrability,@droazen I plugged this into the `HaplotypeCaller` integration tests and it looks really good. The concordance tests fail due to a handful of false positives but these are _all_ obvious true positive multiallelics that the old qual model behaves stupidly on. I'm not sure who the right reviewer for this is but I'm guessing it's @ldgauthier and/or @vruano.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2098:51,integrat,integration,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2098,1,['integrat'],['integration']
Integrability,@droazen I profiled a lot and did some unit test experiments and basically there's no difference. Depending on average depths one or the other can be faster by up to 15 seconds per billion sites. I really just wanted to cull the list of open issues and had nothing against the old downsampler code. How about we close this PR *and* close Adam's GATK issue?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5074#issuecomment-433994089:98,Depend,Depending,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5074#issuecomment-433994089,1,['Depend'],['Depending']
Integrability,"@droazen I ran the latest version but the message about google is still there!. 14:08:05.607 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cm/shared/unil/software/8.3/GATK/4.1; .9.0-GCCcore-8.3.0-Java-8/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 14, 2020 2:08:06 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-708360241:42,message,message,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-708360241,1,['message'],['message']
Integrability,@droazen I think this one is irrelevant now that we are recommending using the gradle wrapper,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/337#issuecomment-195045672:86,wrap,wrapper,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/337#issuecomment-195045672,1,['wrap'],['wrapper']
Integrability,"@droazen I'm not sure this is an improvement. We want the fundamental unit of spark tool to be the transform, not the cli wrapper around it. If we do this then we're pushing more of the contract of the transform outside of itself, i.e. see the newly duplicated bqsr code. I think that it was a deliberate decision to lift all reads into the initial rdd and then filter them in the transforms to what was needed by that transform. This is paying some performance cost in multi-stage pipelines which will potentially apply the same filters over and over again, but it simplifies the code because the filters can be baked into the transform and the pipeline writer doesn't have to think about them. It would be nice if we had a mechanism for adding metadata to an RDD so we can say ""this is a sorted RDD filtered with X,Y,and Z filters"", so we could intelligently avoid re-filtering.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1159#issuecomment-158168856:122,wrap,wrapper,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1159#issuecomment-158168856,2,"['contract', 'wrap']","['contract', 'wrapper']"
Integrability,@droazen If we're willing to pay the cost of always calculating those fields on initialization and certain updates then we can just use a `boolean` and avoid the null check on read. Probably depends on the balance of reads/updates (although I would think that read is much more more common than update).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235103083:191,depend,depends,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235103083,1,['depend'],['depends']
Integrability,@droazen Integration tests went from ~58 minutes to ~50 minutes as a result of this branch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4992#issuecomment-403528803:9,Integrat,Integration,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4992#issuecomment-403528803,1,['Integrat'],['Integration']
Integrability,@droazen OK - the tests in `DataSourceUtilsUnitTest` pass for me locally. I had to substantially refactor the tests and I added some log messages and some `final` modifiers to clean up some other Intellij warnings.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6807#issuecomment-694956600:137,message,messages,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6807#issuecomment-694956600,1,['message'],['messages']
Integrability,"@droazen Per our discussion about whether the default stringency should be SILENT or STRICT, I re-ran the BaseRecalibrator integration tests (remember these were the only tests that failed with STRINGENCY=STRICT, at least non-Spark tests which is all that are affected by this PR) to see why they failed. There are about 15 tests, totalling about 10 bams used there that fail validation. Based on Picard validation, some have >100 errors, some have a handful; the most common errors are:. -Mate not found for paired read; -Mate Alignment start should be 0 because reference name = *; -Mapped mate should have mate reference name. There are also a handful of missing NM tags. I have the file-by-file breakdown if you want to see it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1439#issuecomment-174663312:123,integrat,integration,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1439#issuecomment-174663312,1,['integrat'],['integration']
Integrability,@droazen Should this be a gatk-protected ticket instead since it depends on GenotypeGVCFs?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2017#issuecomment-250468170:65,depend,depends,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2017#issuecomment-250468170,1,['depend'],['depends']
Integrability,"@droazen Thank you for the confirmation that HaplotypeCaller performs separate filtering passes on the read mapping qualities, and that the code on line 729 of HaplotypeCallerEngine.java (method ```filterNonPassingReads()``` ) is indeed executing subsequent to the ```MappingQualityReadFilter```. May I suggest, however, that MAPQ values less than 20 might not necessarily lead to an increase in FP variant calls? My understanding is that HaplotypeCaller uses MAPQ values only in a nonparametric rank sum test, in which case MAPQ is treated as an ordinal. This seems appropriate since the magnitude of a MAPQ value depends both on the data and on the computational model the read aligner uses to calculate it. With this in mind, a set of mappings with MAPQ in a lower range (e.g., ```--minimum-mapping-quality 10``` and a correspondingly lower ```--maximum-mapping-quality``` as well) might very well be appropriate for variant calling. So changing the semantics of ```MappingQualityReadFilter``` or parameterizing the currently-hardwired MAPQ range would enable additional control without affecting performance. @jamesemery I will watch for the HaplotypeCaller update that implements that functionality. And if you have a moment, could you please point me to the code that might be adversely affected by decreasing the low-end MAPQ threshold? I might have some ideas about that (or not!)... Thanks again!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6854#issuecomment-701512278:615,depend,depends,615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6854#issuecomment-701512278,1,['depend'],['depends']
Integrability,@droazen Thank you for the thorough explanation. That makes sense. For now I've changed `presorted = false` and that integration test is now passing (meaning the output now matches GATK3). Back to you!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1853#issuecomment-224706860:117,integrat,integration,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1853#issuecomment-224706860,1,['integrat'],['integration']
Integrability,"@droazen This does not affect any of the integration tests or unit tests in gatk-protected, except insofar as `InfiniteRandomMatingPopulationModel` must be renamed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1855#issuecomment-222225770:41,integrat,integration,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1855#issuecomment-222225770,1,['integrat'],['integration']
Integrability,@droazen This improves the error message we talked about in the meeting.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6779#issuecomment-683955730:33,message,message,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6779#issuecomment-683955730,1,['message'],['message']
Integrability,"@droazen This is a straight-up port -- it was copy and paste except I had to update some method names, like `alleleCount()` -> `numberOfAlleles()` and `sampleIndex` -> `indexOfSample`. And of course I couldn't port the changes to integration tests md5s.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2710#issuecomment-301089484:230,integrat,integration,230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2710#issuecomment-301089484,1,['integrat'],['integration']
Integrability,@droazen This submits our dependencies so that dependabot can analyze them in the background. . It's from https://github.com/marketplace/actions/build-with-gradle#the-dependency-submission-action,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9002:26,depend,dependencies,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9002,3,['depend'],"['dependabot', 'dependencies', 'dependency-submission-action']"
Integrability,@droazen We are still on hold for update the Funcotator datasources. Especially getting new versions of gencode would be desirable and does not work with the current scripts. We already started looking for alternatives for our routine diagnostics workflow.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1231327112:227,rout,routine,227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1231327112,1,['rout'],['routine']
Integrability,"@droazen When we finally remove CNNScoreVariants, don't forget that you can put an entry in the [DeprecatedToolsRegistry](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/cmdline/DeprecatedToolsRegistry.java#L22-L24) with a helpful message about the replacement.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2121083870:278,message,message,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2121083870,1,['message'],['message']
Integrability,@droazen Would you mind opening an issue that includes the old code as well as the error message so we can have a record if we see it again?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1028#issuecomment-150235517:89,message,message,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1028#issuecomment-150235517,1,['message'],['message']
Integrability,"@droazen Yeah, what @ronlevine mentioned could possibly do it, depending on where the data flows to next, i.e., if the header lines are then put back into a header, the contig line list in the new header should be correct if retrieved via getMetadataInSortedOrder() though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2753#issuecomment-304047071:63,depend,depending,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2753#issuecomment-304047071,1,['depend'],['depending']
Integrability,"@droazen Yes, the user has confirmed there are contigs in their eval VCF that are not in the truth VCF. This bug report is to improve the error message for this case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7562#issuecomment-969320338:144,message,message,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7562#issuecomment-969320338,1,['message'],['message']
Integrability,"@droazen Yes, this is because the native PairHMM is using single precision floating point and Flush To Zero (FTZ), while the Java PairHMM is using double precision and not using FTZ. I planned to address this when we integrate native PairHMM into HaplotypeCaller. It looks like the time is here. For now, you can configure native PairHMM to use double precision and not use FTZ. With the diff below, the VCFs from native and Java PairHMM are exactly the same. In the future, we need to enable FTZ in the Java PairHMM and provide the option to use single precision or double precision in native PairHMM. ``` diff; --- i/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc; +++ w/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc; @@ -23,7 +23,7 @@ LoadTimeInitializer::LoadTimeInitializer() //will be called when library is loa; //Very important to get good performance on Intel processors; //Function: enabling FTZ converts denormals to 0 in hardware; //Denormals cause microcode to insert uops into the core causing big slowdown; - _MM_SET_FLUSH_ZERO_MODE(_MM_FLUSH_ZERO_ON);; + // _MM_SET_FLUSH_ZERO_MODE(_MM_FLUSH_ZERO_ON);. //Profiling: times for compute and transfer (either bytes copied or pointers copied); m_compute_time = 0;; diff --git i/src/main/cpp/VectorLoglessPairHMM/org_broadinstitute_hellbender_utils_pairhmm_VectorLoglessPairHMM.cc w/src/main/cpp/VectorLoglessPairH; index f45153e..70cf54f 100644; --- i/src/main/cpp/VectorLoglessPairHMM/org_broadinstitute_hellbender_utils_pairhmm_VectorLoglessPairHMM.cc; +++ w/src/main/cpp/VectorLoglessPairHMM/org_broadinstitute_hellbender_utils_pairhmm_VectorLoglessPairHMM.cc; @@ -6,7 +6,7 @@. using namespace std;. -bool use_double = false;; +bool use_double = true;. //Should be called only once for the whole Java process - initializes field ids for the classes JNIReadDataHolderClass; //and JNIHaplotypeDataHolderClass; diff --git i/src/main/java/org/broadinstitute/hellbender/utils/pairhmm/VectorLoglessPairHMM.java w/src/main/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1572#issuecomment-195496083:217,integrat,integrate,217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1572#issuecomment-195496083,1,['integrat'],['integrate']
Integrability,"@droazen any thoughts how we should proceed here, if at all? @ldgauthier reminded me that this story was unfinished and is getting a little stale. @fleharty take note if we want to report progress on this front to our MalariaGEN collaborators. On my end, there are a couple of things to do:; - [x] rebase and resolve conflicts; - [x] change TSV input as discussed above; - [x] add doc strings for new arguments; - [x] add integration tests to make absolutely sure exposure was done correctly, perhaps? I'm open to discussion about how this should be done. Complete coverage here will be difficult and perhaps not worth the effort, but I can probably put in a few tests that make sure changing the hard-coded values in master and doing the same via the exposed parameters in this branch have the same effect on a few existing test cases. However, while I'm doing the last three, I wonder if we could run whatever canonical evaluations/optimizations we have to see whether it's worth consolidating some of the parameter sets at this stage? I think there's an argument for having at least two sets (haplotype-to-reference + read-to-haplotype), but I'm not sure how to justify having a separate set for dangling heads/tails. But also not sure which set the latter should be consolidated with---@jamesemery thoughts? Again, let me reiterate that it seems that many of these parameter values were chosen arbitrarily (or, if not, that the procedure for choosing them has been lost). As a start, you can see the results of some optimizations I did on the CHM mix on slide 15 at https://docs.google.com/presentation/d/1zGuquAZWSUQ-wNxp8D6HhGNjIaFcV0_X9WAS4LODbEo/edit?usp=sharing Here, I optimized over haplotype-to-reference + read-to-haplotype SW parameters on various metrics after variant normalization using vcfeval. These optimizations were done using the Bayesian optimization framework I prototyped long ago (see https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer and http",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471:422,integrat,integration,422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471,1,['integrat'],['integration']
Integrability,"@droazen do we still care about this? Given that we've been moving to non-exact match integration tests and fuzzy comparisons in production, maybe this isn't worth the effort.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1572#issuecomment-590346422:86,integrat,integration,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1572#issuecomment-590346422,1,['integrat'],['integration']
Integrability,"@droazen exactly, the artifact will depend on `BigQueryUtils` which would be in a `gvs` package to hopefully make clear that the contents are currently fairly specific to GVS and probably not ideal for more general use in their present form.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8375#issuecomment-1604900043:36,depend,depend,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8375#issuecomment-1604900043,1,['depend'],['depend']
Integrability,"@droazen here are the error messages with gatk4.1.8.1 and gatk4.1.4.1:. 15:01:44.424 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cm/shared/unil/software/8.3/GATK/4.1.4.1-GCCcore-8.3.0-Java-8/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 09, 2020 3:01:45 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine. 14:28:22.786 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cm/shared/unil/software/8.3/GATK/4.1.8.1-GCCcore-8.3.0-Java-8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 09, 2020 2:28:23 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707085229:28,message,messages,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707085229,1,['message'],['messages']
Integrability,"@droazen just for context, I punted on this in the linked PR (I'm not too familiar with the annotation interfaces, and it wasn't immediately obvious to me how to implement the required methods for ExcessHet). So @ldgauthier asked me to file this on the off chance that someone else wants to look at it in the future, but I think it's probably low priority. Seems like someone might have taken a previous unsuccessful stab at it; there were a few vestigial, commented-out `//@Override` lines.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7564#issuecomment-969270587:103,interface,interfaces,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7564#issuecomment-969270587,1,['interface'],['interfaces']
Integrability,"@droazen or anyone else from GATK: are you able to comment on the status of this bug, and any conversations that might be happening outside github? I posted earlier that #7962 (which is admittedly just a workaround), seems to side-step this exception. Do you foresee some other route to fix this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7966#issuecomment-1208692561:278,rout,route,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7966#issuecomment-1208692561,1,['rout'],['route']
Integrability,@droazen please re-review. I replaced Covariate[] with a dedicated data structure and removed most of the hard-wired dependencies on the order.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/258#issuecomment-78060650:117,depend,dependencies,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/258#issuecomment-78060650,1,['depend'],['dependencies']
Integrability,@droazen sorry for a late response. I agree moving to java 17 would help. I do see that GATK itself is using the newer version of log4j but then its the transitive dependencies for the libraries used that bring in the older version of log4j. . this creates situations that the final compiled jar has both version of the log4j and this could create problems. . Gatk being a very useful tool gets integrated in multiple other tools and pipelines so in a way affecting the security posture of where its being used. The risk might be low being a standalone cli tool but its a very hard conversation with info security :) . May I ask for a ballpark ETA for the new version? Appreciate the work thats gone into this tool.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1448897264:164,depend,dependencies,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1448897264,2,"['depend', 'integrat']","['dependencies', 'integrated']"
Integrability,"@droazen sure. This PR updates both `BucketUtils.getPathOnGcs` and `IOUtils.getPath` (the latter indirectly) to create a Google Cloud Storage filesystem with a default reopen set to 3. Anyone opening the given `Path` (or even a `Path` derived from it, e.g. via `subpath`) will have the retries enabled. `addPrefetcher` wraps an existing `Path`, so it inherits the underlying `Path`'s retry behavior. Classes within htsjdk that create a `Path` from a String, without using our utility code, would indeed not set retries and errors on those files would not get the benefit of our extra retry. The exception to that is the Spark code path with `NioBam`: this goes via `ReadsIterable`, which also sets the retries. My understanding is that the normal way to open BAMs for tools always creates the `Path` object when parsing the command line, as in e.g. `ReadInputArgumentCollection::GetReadIndexPaths()`. That code path that calls `IOUtils.getPath` (and thus sets the retries). I would expect that the added support for VCF follows the same style, though it looks like it doesn't. If there's a code path that I missed where you think we need retries then please let me know so I can add it!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-289585791:319,wrap,wraps,319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-289585791,1,['wrap'],['wraps']
Integrability,"@droazen thanks for the quick response! Just to be clear, my concerns were about testing that I didn't somehow screw up the original behavior through the exposure, not just testing that *some* behavior was exposed. But message received---will keep things on the simple side!. Also, please see the plots in #5564 to get an idea of the effect on outputs, if you haven't already. Would appreciate any thoughts you might have on that thread!. Will try to get this done in the next day or two, thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896328697:219,message,message,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896328697,1,['message'],['message']
Integrability,"@droazen the bam that I added was aligned with minimap2. However, it is a really small BAM, so I could not run it through the integration tests. It sounds useful to add minimap2-aligned bam to HaplotypeCallerIntegrationTest. Can you or @jamesemery point me to a suitable BAM for that?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1558588144:126,integrat,integration,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1558588144,1,['integrat'],['integration']
Integrability,"@droazen there are 3 minor changes here that were left over after the other branch got merged. The only controversial one might be unforcing the protobuff version, but I think it makes sense to just let it float at whatever the other dependencies require since that's what everything else does.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6736#issuecomment-840053329:234,depend,dependencies,234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6736#issuecomment-840053329,1,['depend'],['dependencies']
Integrability,"@droazen this branch wasn't STRICTLY dependent on #5607, so I removed it from this branch to make reviewing easier. Its worth noting that the performance numbers and observed speedup were seen when this branch did hang off of #5607.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-460423597:37,depend,dependent,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-460423597,1,['depend'],['dependent']
Integrability,@droazen what do you think about passing the deflater to the sam-writer factory and removing GLK as a htsjdk dependency altogether?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1867#issuecomment-223066940:109,depend,dependency,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1867#issuecomment-223066940,1,['depend'],['dependency']
Integrability,"@droazen, I updated the PR message to describe the changes, because I tried to get all the code referring to test resources packaged in src/test. Now it should pass the tests too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324295384:27,message,message,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324295384,1,['message'],['message']
Integrability,"@droazen, could you review this PR? Before I implement the integration test I would be important that you check if it is possible the change of the `ReadShard` contract (null `ReadsDataSource` are now allowed, and I don't know if this will affect other parts of GATK. Thank you very much in advance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-219990301:59,integrat,integration,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-219990301,2,"['contract', 'integrat']","['contract', 'integration']"
Integrability,"@droazen, if it's true we can merge the headers then I suppose that may be a possibility. I'm a little bit dubious, though, because one of the pieces of information is the reference index to reference name mapping, and I didn't think we required those to match. Or do we?. Keep in mind however that static variables aren't serialized, so we'd still have to include some fancy code to make sure that every worker has the header. And since workers may be added dynamically by Dataflow's auto-tuning, we may have to call that code at the beginning of every transform... just like addHeaders. . So we would have some ""action-at-a-distance"" type of code, with statics that may or may not have different values depending on which computer you're on. This sounds like it may be just as error-prone and headache-causing as the other approach. At this point I'm still leaning towards manually putting the headers back. I think this makes the code less surprising than using globals (statics are a form of global variable after all) and so less likely to confuse someone new to the codebase.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141155796:705,depend,depending,705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141155796,1,['depend'],['depending']
Integrability,"@droazen, just to make sure I understand...you are suggesting that we keep doing the wrong things in GATK4 just so the integration tests match their results in GATK3?. Wouldn't it be better to have a GATK3_EQUIVALENCE_MODE flag and create new tests that do the right thing?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3680#issuecomment-342985499:119,integrat,integration,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3680#issuecomment-342985499,1,['integrat'],['integration']
Integrability,"@droazen, the SAMRecord interface exposes getReferenceIndex and getMateReferenceIndex, so there is no question that the index has to be there. . What I was talking about what the optimization where when serializing, the [BAMRecordCodec only saves the index](https://github.com/samtools/htsjdk/blob/master/src/java/htsjdk/samtools/BAMRecordCodec.java#L131), and not the name. That is because if we have the header then we can go from the index to the name. If there is no header, then we can't do that optimization anymore and instead have to save those two fields for every read.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141251365:24,interface,interface,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141251365,1,['interface'],['interface']
Integrability,"@droazen, we have fixed all issues in genomicsdb code. the test now fails giving this message:. java.lang.AssertionError: Attribute MIN_DP expected [27.0] but found [27]; Expected :27.0; Actual :27. As I told you before I am using VariantContextTestUtils.assertVariantContextsAreEqual() to compare two feature reader iterators. is this the correct method to use?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-292376903:86,message,message,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-292376903,1,['message'],['message']
Integrability,"@droazen, yes despite the message about Google gatk4 runs well and I got an output file. Thanks for your support! I will run the latest version and see if it does not provide the Google message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-708305495:26,message,message,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-708305495,2,['message'],['message']
Integrability,"@droazen, yes, I built the dylib with all dependencies statically linked. That's why I am a little confused why these transitive dependencies are coming up. I am regenerating the dylib in my local environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294233601:42,depend,dependencies,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294233601,2,['depend'],['dependencies']
Integrability,"@dwuab which issue/error are you specifically referring to? As indicated in the last message before you posted, the previous user was able to use GenomicsDBImport and GenotypeGVCFs after following our suggestions to break up large chromosomes into smaller intervals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-900456302:85,message,message,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-900456302,1,['message'],['message']
Integrability,"@eddiebroad commented on [Thu Dec 01 2016](https://github.com/broadinstitute/gatk-protected/issues/806). An issue encountered with gatk-protected ""SparkGenomeReadCounts"" tool is a non-helpful ""null"" error message. A non-helpful error ""null"" message was printed by gatk-protected with the command-line below; during the course of trying to use it on/in FireCloud:. ```; + java -Xmx48g -jar fc-7ac504fc-7fe4-4bc1-89d3-7f16317b8ff4/eddie.jar SparkGenomeReadCounts --outputFile this.entity_id.coverage.tsv --reference fc-e2421839-93d5-4ed5-8861-593f00364e54/Homo_sapiens_assembly19.fasta --input firecloud-tcga-open-access/tutorial/bams/C835.HCC1143_BL.4.bam --binsize 5000; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp; .....; ......; ......; proceeding with flushing remote transports.; ***********************************************************************. null. ***********************************************************************; ```. To try to make a more helpful error message appear I added a ""catch"" block after a call to runTool in instanceMainPostParseArgs in file CommandLineProgram.java and got a more helpful message about a missing dictionary file: . try {; return runTool();; } ; catch(Exception e) {; e.getStackTrace();; }. java.lang.RuntimeException: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:204); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:152); Caused by: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2922:205,message,message,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2922,2,['message'],['message']
Integrability,@eitanbanks and @vdauwera I heard from @droazen that you guys are working on the BadCigarFilter in GATK3. Can you summarize the work? we need to synchronize the changes/improvements across the 2 codebases.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/380#issuecomment-94912682:145,synchroniz,synchronize,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/380#issuecomment-94912682,1,['synchroniz'],['synchronize']
Integrability,@erniebrau I don't think we can exclude log4j 1.x. A lot of our dependencies use it. This branch is failing with various ClassNotFound errors. ex: https://storage.googleapis.com/hellbender/test/build_reports/11489.3/tests/test/classes/org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSourceUnitTest.html#testReadFromFileAndHDFS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279:64,depend,dependencies,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279,1,['depend'],['dependencies']
Integrability,"@erniebrau, the mesage and log file corresponds to the latest master (GKL 0.5.8); for the GKL 0.5.3 the error message is the following:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011dc557f4, pid=20586, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression1417468606951982528.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid20586.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. And the log file: [hs_err_pid20586.log.txt](https://github.com/broadinstitute/gatk/files/1264191/hs_err_pid20586.log.txt). Let me know if you need more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152:110,message,message,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152,1,['message'],['message']
Integrability,"@felixm3 The bioconda environment doesn't actually configure the gatk conda environment (it installs gatk, but not the python dependencies required for CNNScoreVariants). You need to set up the gatk conda environment, as described in the Python Dependencies section in the README.md file: https://github.com/broadinstitute/gatk#readme.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1275000632:126,depend,dependencies,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1275000632,2,"['Depend', 'depend']","['Dependencies', 'dependencies']"
Integrability,"@fi1d18 It looks to me like the error message is correct. The input file you specified (`--INPUT NG-27280_CLTSS_LTS_001A_lib506241_7636_2_MarkedDup.bam`) is in fact not in the folder from which you're running, which you can see from the results of the `ls` command you provided:. ```; (gatk) root@34684eaa046e:/gatk/data/Continuum/WES/vcf# ls; GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz; ```. You can see that `NG-27280_CLTSS_LTS_001A_lib506241_7636_2_MarkedDup.bam` is not included in the `ls` output. If the input file is in another location, you'll need to specify it using either an absolute or relative pathname. If the problem persists after that, feel free to reopen this ticket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8462#issuecomment-1677320234:38,message,message,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8462#issuecomment-1677320234,1,['message'],['message']
Integrability,"@fleharty @avalind ; Sorry, something happened with my previous message.; But what I wrote previously was that I couldn't reproduce the same error message using Picard ValidateSamFile. I tried validating my bam file and I don't see any errors. Even the samtools flagstat option works fine on my bam file.; Please find the attached screenshots,. <img width=""704"" alt=""picard"" src=""https://user-images.githubusercontent.com/6302819/88064375-8023f200-cb6b-11ea-960e-bab93f79ff22.png"">. <img width=""289"" alt=""flagstst"" src=""https://user-images.githubusercontent.com/6302819/88064447-9631b280-cb6b-11ea-86ee-6c49f9111507.png"">. Do you still think my bam file is malformatted?. PS: @fleharty used Picard version (2.20.4-SNAPSHOT), whereas I used v.2.23.2; for running Picard ValidateSamFile.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-661884614:64,message,message,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-661884614,2,['message'],['message']
Integrability,"@fnothaft Thanks for the cleanup. I've seen that annotations take on different types depending on whether they were added during the current traversal or read in from a file, but I haven't run into any issues with the strand bias annotations so far. Do you have a specific use case for the int[] version?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367345646:85,depend,depending,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367345646,1,['depend'],['depending']
Integrability,"@gaze-abyss Can you check your `.table` input files to see whether they have a header that looks like this:. ```; #<METADATA>SAMPLE=sample; contig position ref_count alt_count other_alt_count allele_frequency; ```. The error message indicates that the tool is not finding the ""contig"" column for some reason, and a malformed header line is one possiblity.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7707#issuecomment-1061039784:225,message,message,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7707#issuecomment-1061039784,1,['message'],['message']
Integrability,"@gbrandt6 So now the protocol is that you wait for tests to pass (although it's unlikely this could break them...) and then you can merge with ""squash and merge"". You can edit the commit message in the browser to make sure it is clear. `Fix typo in --tmp-dir argument in GenomicsDB docs` is a pretty good description for this one though :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6785#issuecomment-684939263:21,protocol,protocol,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6785#issuecomment-684939263,2,"['message', 'protocol']","['message', 'protocol']"
Integrability,"@gevro The `HaplotypeCaller` adds padding to the intervals on its own. This is controlled by the `--assembly-region-padding` argument, which defaults to 100 bases on either side. Note that this controls both padding around user-provided intervals, as well as padding around each individual assembly region that the `HaplotypeCaller` discovers. Typically a single user interval will get divided into many assembly regions, depending on where variant activity is located.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517371918:422,depend,depending,422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517371918,1,['depend'],['depending']
Integrability,"@gokalpcelik This isn't an insane request, but it's probably not going to happen very quickly. . I don't think it's a trivial change to just exclude log4j, we'd need a compatible replacement or you'd end up with crashes in weird places when a transitive dependency tries to log with it. We can (and might) do it, but it's not super high priority at the moment. I think there's internal interest in changing out the logger but at the moment our strategy is to patch to the newest version as they become available. . That said, if you find a way to build a log4j free version without weird issues please let us know :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7626#issuecomment-1005810220:254,depend,dependency,254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7626#issuecomment-1005810220,1,['depend'],['dependency']
Integrability,"@gspowley Can you take a look? This problem started happening with https://github.com/broadinstitute/gatk/commit/dfa9cf1a420490285b7be7917082222a07e2b042. I can pretty reliably move back to the previous commit and it goes away. It always surfaces in the VariantSparkSinkUnitTests, but it seems to be the result of a cumulative effect since AFAICT it only happens when running the full test suite via ""./gradlew clean test"". I tried changing the default values of useJdkInflater and useJdkDeflater to true, and I still get the same problem. Interestingly, disabling all of the tests in IntelInflaterDeflaterIntegrationTest seems to reliably fix it (even with useJdkInflater/Deflater set to false), so I'd start there. If thats the culprit, it might explain why we don't see this in travis since we run the unit tests and integration tests separately there.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-288098956:820,integrat,integration,820,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-288098956,1,['integrat'],['integration']
Integrability,@gspowley Could you route this bug report to whoever is able to deal with this nowadays?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-465238238:20,rout,route,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-465238238,1,['rout'],['route']
Integrability,@gspowley Looks like integration tests are failing?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282054550:21,integrat,integration,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282054550,1,['integrat'],['integration']
Integrability,"@heuermh Thanks for your input, we'll look into those options. I think the use case most of us are imagining is for narrow tables with ~1M-1B records or fewer (sometimes far fewer). For the CNV pipeline, Tribble support is a much higher priority than Hadoop integration, efficient compression, etc., and it's very unlikely we'll need to do out-of-core computations that won't be enabled by Tribble. However, that might not be true of more general use cases, so it's certainly worth investigating more robust formats. @SHuang-Broad For all current CNV use cases, we use separate columns for each annotation. Not sure how much VCF code actually needs to be shared if all we care about is extracting parsing and Tribble indexing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481408414:258,integrat,integration,258,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481408414,1,['integrat'],['integration']
Integrability,@iAMSe What's the error? `Shutting down engine` is a normal message that shows up in normal runs. Is it producing output that seems correct?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8204#issuecomment-1432199784:60,message,message,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8204#issuecomment-1432199784,1,['message'],['message']
Integrability,"@ilyasoifer I don't know why it's using so much more memory now than it used to. I did notice you're not running with all of the options we usually specify for spark though. There are a few options we set via the `gatk` wrapper script. I'm not 100% sure if they're all still important but we set them for a reason in the distant past. I would try adding them as --conf options. I think it's possible that they have significant impact on the memory usage.; ```; ""spark.kryoserializer.buffer.max"" : ""512m"",; ""spark.driver.maxResultSize"" : ""0"",; ""spark.driver.userClassPathFirst"" : ""false"",; ""spark.io.compression.codec"" : ""lzf"",; ""spark.executor.memoryOverhead"" : ""600"",; ""spark.driver.extraJavaOptions"" : EXTRA_JAVA_OPTIONS_SPARK,; ""spark.executor.extraJavaOptions"" : EXTRA_JAVA_OPTIONS_SPARK; ```. EXTRA_JAVA_OPTIONS_SPARK is; ```; ""-DGATK_STACKTRACE_ON_USER_EXCEPTION=true "" \; ""-Dsamjdk.use_async_io_read_samtools=false "" \; ""-Dsamjdk.use_async_io_write_samtools=false "" \; ""-Dsamjdk.use_async_io_write_tribble=false "" \; ""-Dsamjdk.compression_level=2 ""; ```. Now, David was suggesting that you try running using spark-submit and specify explicit memory commands for the driver/executors. I'm not convinced this will help, but it's worth trying. that this will help, but it's worth trying. ; If you have spark-submit on your path you can either call it directly with `--master local[24]` or use `gatk --spark-runner SPARK --spark-master local[24] ... [the rest of the arguments]` which will construct the appropriate call. . ```; gatk \; MarkDuplicatesSpark \; --spark-runner SPARK \; --spark-master ""local[24]"" \; --input in.bam \; --output out.bam \; --create-output-bam-index true \; --spark-verbosity WARN \; --verbosity WARNING; --driver-memory 8G \; --executor-memory 4G ; ```. Something like that. I'm honestly not sure how it will handle those memory requests in local mode though since it all runs in the same process. I suspect it will just add them up and set xmx using the sum. . The oth",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8307#issuecomment-1564851825:220,wrap,wrapper,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8307#issuecomment-1564851825,1,['wrap'],['wrapper']
Integrability,"@imneuro The easiest thing to do is to use the GATK docker image, however, if you like you can install R and then run the R script found [here](https://github.com/broadinstitute/gatk/blob/master/scripts/docker/gatkbase/install_R_packages.R) to get the required R dependencies. Also, these kinds of questions can be best handled by posting on the GATK forum - github issues are for bugs/feature requests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2199#issuecomment-484250130:263,depend,dependencies,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2199#issuecomment-484250130,1,['depend'],['dependencies']
Integrability,"@jamesemery - i will also look into whether this file is somehow created by subsetting another during tests. in the meantime, would it be possible to also get these? i'm pretty confident this is the final list:. gsa-hpprojects\GATK\data\Comparisons\Validated\HapMap\3.3\genotypes_r27_nr.b37_fwd.vcf. and the following are in privateTestDir:. overlapTest.bed; PhaseByTransmission/PhaseByTransmission.IntegrationTest.goodFamilies.ped; PhaseByTransmission/PhaseByTransmission.IntegrationTest.TP.vcf; NA12878.HiSeq.WGS.b37_decoy.indel.recalibrated.vcf; yri.trio.gatk.ug.head.vcf; NA12878.HiSeq.WGS.b37_decoy.indel.recalibrated.vcf; Mills_and_1000G_gold_standard.indels.b37.sites.vcf; validationReportComp.vcf; validationReportComp.noGenotypes.vcf",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-366799537:399,Integrat,IntegrationTest,399,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-366799537,2,['Integrat'],['IntegrationTest']
Integrability,"@jamesemery - sorry to keep bothering you on this, but is there any chance you could upload the files above? I have GATK4 VariantEval passing using all the GATK3 tests, except for the handful of ones depending on these files. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-370491290:200,depend,depending,200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-370491290,1,['depend'],['depending']
Integrability,"@jamesemery : i have run all integration tests, and I think this is a complete list of the remaining files I can hopefully get:. /private/gatk-tools-private/src/test/resources/withSymbolic.b37.vcf; /private/gatk-tools-private/src/test/resources/PhaseByTransmission/PhaseByTransmission.IntegrationTest.TP.vcf ; /private/gatk-tools-private/src/test/resources/yri.trio.gatk_glftrio.intersection.annotated.filtered.chr1.vcf ; /private/gatk-tools-private/src/test/resources/NA12878.HiSeq.WGS.b37_decoy.indel.recalibrated.vcf ; /private/gatk-tools-private/src/test/resources/validationReportEval.noGenotypes.vcf ; /private/gatk-tools-private/src/test/resources/validationReportEval.vcf ; /private/gatk-tools-private/src/test/resources/ac0.vcf ; /humgen/gsa-hpprojects/GATK/data/Comparisons/Validated/HapMap/3.3/genotypes_r27_nr.b37_fwd.vcf; /humgen/gsa-hpprojects/GATK/data/Validation_Data/snpEff2.0.5.AFR.unfiltered.VariantAnnotator.output.vcf. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-366146129:29,integrat,integration,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-366146129,2,"['Integrat', 'integrat']","['IntegrationTest', 'integration']"
Integrability,"@jamesemery @cmnbroad This fixes a personal pet peeve of mine, which is that we're packaging a bunch of test classes as a runtime dependency. It splits out a new test artifact which contains just the classes in utils.test and allows it to be published and consumed separately from the rest of the gatk. This allows us to make testng and minicluster no longer compile dependencies",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5112#issuecomment-413011677:130,depend,dependency,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5112#issuecomment-413011677,2,['depend'],"['dependencies', 'dependency']"
Integrability,"@jamesemery @droazen I've updated this branch to ensure all read and write paths to shared state in `GenotypeLikelihoodCalculators` is synchronized. I then wrote a little [test](https://github.com/broadinstitute/gatk/commit/3bb178746b1dd286f55ba77e6939e2104ced98d0) using `AlleleSubsettingUtils` to access `GenotypeLikelihoodCalculators` 10^6 times to see the effect of adding synchronization. R session (times are in millis):; ```; > without_sync = c(10166, 10049, 10306, 10059, 10165); > with_sync = c(10700, 10384, 9923, 10097, 10190); > t.test(without_sync, with_sync, paired=TRUE). 	Paired t-test. data: without_sync and with_sync; t = -0.70447, df = 4, p-value = 0.52; alternative hypothesis: true difference in means is not equal to 0; 95 percent confidence interval:; -542.5421 322.9421; sample estimates:; mean of the differences ; -109.8 ; ```. The p-value is not less than 0.05, so we can't reject the null hypothesis (that the mean times are the same). So adding synchronization doesn't seem to make any difference in this test. BTW, I noticed that `GenotypeLikelihoods` has synchronization, so there is some precedent for thread-safety using this means.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-426338479:135,synchroniz,synchronized,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-426338479,4,['synchroniz'],"['synchronization', 'synchronized']"
Integrability,@jamesemery Could you also add an integration test with the pipeline above? You'll need to run bash using `ProcessController` or similar,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358108007:34,integrat,integration,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358108007,1,['integrat'],['integration']
Integrability,"@jamesemery Hey James. Is it possible to add an error message stating that the user needs to set --TMP_DIR to a bigger disk? Another user posted ""It would be nice some warning about low disk space instead of crashing after running for so many hours.""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4487#issuecomment-398159225:54,message,message,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4487#issuecomment-398159225,1,['message'],['message']
Integrability,"@jamesemery I agree - all access (read and write) to `GenotypeLikelihoodCalculators` instance variables needs to be synchronized to make it safe. I think it would be sufficient to make `getInstance()` and `calculateGenotypeCountUsingTables()` synchronized. @droazen, are you concerned about performance for the Spark case? For the walker version, presumably the access is single-threaded, and hence [uncontended, which is very cheap](https://books.google.co.uk/books?id=mzgFCAAAQBAJ&pg=PA230&lpg=PA230&dq=java+uncontended+synchronization+goetz&source=bl&ots=7W4J807faW&sig=YALE1qdWoAUELPqLRhIedz-bZ20&hl=en&sa=X&ved=2ahUKEwj4jJeko8zdAhXVFsAKHazkBrcQ6AEwB3oECAIQAQ#v=onepage&q=java%20uncontended%20synchronization%20goetz&f=false). Another option would be to maintain a separate instance of `GenotypeLikelihoodCalculators` per genotyping engine. The size of the table is ploidy * alleles, so not too large?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-423546586:116,synchroniz,synchronized,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-423546586,3,['synchroniz'],"['synchronization', 'synchronized']"
Integrability,"@jamesemery I think this is because the annotation plugin, which has the pedigree arg, hasn't been integrated with the tools yet (second part of https://github.com/broadinstitute/gatk/issues/3287) ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4604#issuecomment-376905093:99,integrat,integrated,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4604#issuecomment-376905093,1,['integrat'],['integrated']
Integrability,@jamesemery Looks good to me. Could you add those warning messages Megan asked for and fix the compile error and then I think it's good to merge.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2021#issuecomment-241818815:58,message,messages,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2021#issuecomment-241818815,1,['message'],['messages']
Integrability,"@jamesemery This depended on #5416, which has since been merged. What's the status of this PR now?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5451#issuecomment-582715942:17,depend,depended,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5451#issuecomment-582715942,1,['depend'],['depended']
Integrability,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7041:191,inject,inject,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041,4,"['inject', 'interface']","['inject', 'interface', 'interfaces']"
Integrability,"@jamesemery This was the first pass where I reviewed the tests, so there are a bunch of new comments, and also some issues with the founder id integration.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3851#issuecomment-361723540:143,integrat,integration,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3851#issuecomment-361723540,1,['integrat'],['integration']
Integrability,"@jamesemery What about supporting an initialize() method on VariantAnnotation? This is GATK3-like, and would be non-disruptive to existing code, since the interfaces could have a default no-op implementation? . /**; * Provides an opportunity to set up context; */; public void initialize(VariantAnnotatorEngine engine) {. }. Then we could address whether any context is appropriate to expose via methods on VariantAnnotatorEngine?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-754274008:155,interface,interfaces,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-754274008,1,['interface'],['interfaces']
Integrability,"@jamesemery You should include a `Resolves #issuenumber` line in your commit message, so that the linked issue will be auto-closed on merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3350#issuecomment-317537842:77,message,message,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3350#issuecomment-317537842,1,['message'],['message']
Integrability,"@jamesemery in order to get the tests to pass I had to regenerate one of the expected output vcf's for a GenotypGvcfs integration test, which makes sense because I'm changing the way we annotate variant id's. Can I just get a quick thumbs up if you are comfortable with this additional change before I merge, assuming tests now pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-639121904:118,integrat,integration,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-639121904,1,['integrat'],['integration']
Integrability,"@jamesemery sorry to bug on this topic, but I'm hoping to make a push early this year to fully migrate my lab off GATK3 . I looked more closely at the specific annotations we need to migrate. I decided that I will implement our walker, 'DiscvrVariantAnnotator', which is basically a light wrapper around VariantAnnotation. This will make it easier to spike in custom annotations. In that walker, I will override makeVariantAnnotations(). I will make a new marker interface for EngineAwareAnnotation, and test that on all the Annotation classes, and use this to inject FeatureManager. So no core GATK changes needed. I did find one thing I'd like to propose. You probably know PedigreeAnnotation is special-cased in GATK. Annotations that use it have automatic argument validation and have the SampleDB injected. Currently, PedigreeAnnotation is a subclass of InfoFieldAnnotation, so isnt available to GenotypeAnnotations. There doesnt appear to be a solid reason why. I tried to fix that and my best idea is the proposal here: #7041 . The core idea is to convert InfoFieldAnnotation and GenotypeAnnotation to interfaces. This is generally a trivial switch in existing code. With that, it becomes possible for classes that currently extend PedigreeAnnotation (which I switched to no longer extend InfoFieldAnnotation) to simply PedigreeAnnotation and implement InfoFieldAnnotation. This makes it possible for future classes to extend PedigreeAnnotation and implement GenotypeAnnotation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-760424063:289,wrap,wrapper,289,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-760424063,5,"['inject', 'interface', 'wrap']","['inject', 'injected', 'interface', 'interfaces', 'wrapper']"
Integrability,"@jamesemery, yes, I've opened #5248 with the isolated fix (and unit test). I'll leave this open for the `CollectAllelicCountsSpark` changes, which I'll update when the other changes it depends on are merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5222#issuecomment-426317398:185,depend,depends,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5222#issuecomment-426317398,1,['depend'],['depends']
Integrability,"@jason-weirather Interesting. I have no trouble accessing the FTP site from outside the Broad. What kind of error message are you getting?. There is a new version from 3/29 that has several fixes in it, in addition you'll need to make sure you have the latest GATK code (you may need to pull the source code rather than a release - I'm not sure when the last release was and some fixes required both data source changes and code changes). If you can wait a few days we're planning on doing another minor / bugfix release this week. In general it's probably not worth trying to fix errors in the data sources - you may find yourself going down a rabbit hole. That said, one of the things that was fixed was that data source line in the gencode file. There shouldn't be very many __UNKNOWN__ fields (if any at all) - at least there aren't when running with the latest version of everything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016:114,message,message,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016,1,['message'],['message']
Integrability,@jberghout If you post your actual output we might be able to track down your variant of the problem (the error message in the original post looks to me somewhat like a corrupt gradle cache: error reading /vsc-hard-mounts/leuven-user/304/vsc30484/.gradle/caches/modules-2/files-2.1/org.spire-math/spire_2.11/0.11.0/998b1c1d841baf4fc5d1b119ea55f165f6684ef5/spire_2.11-0.11.0.jar; error in opening zip file). Is it the `gatkTabComplete` task that is failing for you as well ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345:112,message,message,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345,1,['message'],['message']
Integrability,"@jean-philippe-martin , I actually think the current approach Tom is taking because it would work great for Spark too. I'll just make a class that also satisfies the interface (which will be easy). I also have a few concerns about using ""referenceset"" to tell which one is backing the interface; (1) For Spark, we'll still be using the Google Genomics API, so the pattern will be the same as the current Dataflow version; (2) We'd have lazy initiation for the Dataflow one since it needs state (minor).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/804#issuecomment-131102575:166,interface,interface,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/804#issuecomment-131102575,2,['interface'],['interface']
Integrability,"@jean-philippe-martin Agree that we probably shouldn't refactor `IntegrationTest` as part of this PR, but it looks like some other tests are failing now. The PR build failures are [here](https://travis-ci.com/broadinstitute/gatk/builds/97887212). There are some CRAN mirror problems that are affecting all builds at the moment, but there are also some failures that are fallout from the `IntegrationTest` changes. See [this](https://travis-ci.com/broadinstitute/gatk/jobs/171535202). The previous (`XReadLines`) code was gzip aware, but the new code is not, which is causing the test failures.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-456645889:65,Integrat,IntegrationTest,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-456645889,2,['Integrat'],['IntegrationTest']
Integrability,@jean-philippe-martin Any thoughts on the cause of the failure to load class `org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos` in travis? Do tests pass for you if you run them locally using `./gradlew test`?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1994#issuecomment-232406786:101,protocol,protocol,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1994#issuecomment-232406786,1,['protocol'],['protocol']
Integrability,@jean-philippe-martin Are you seeing this issue in Intellij or on the command line? I'm seeing a similar issue in intellij and it has to do with dependency ordering. Intellij sometimes gets the ordering different than gradle and ends up with an old version of guava.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/866#issuecomment-135524805:145,depend,dependency,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866#issuecomment-135524805,1,['depend'],['dependency']
Integrability,@jean-philippe-martin Are your jars properly set up? I'm seeing the Travis build fail the following way:. ```; ...; Gradle suite > Gradle test > org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSourceUnitTest.testReadFromFileAndHDFS FAILED; org.apache.hadoop.ipc.RemoteException(java.lang.NoClassDefFoundError): Could not initialize class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos; at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.getDescriptor(ClientNamenodeProtocolProtos.java); at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.getDescriptorForType(ClientNamenodeProtocolProtos.java); at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:598); ...; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1994#issuecomment-232254552:378,protocol,protocol,378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1994#issuecomment-232254552,3,['protocol'],['protocol']
Integrability,"@jean-philippe-martin Can you comment on this one? It looks like `google-cloud-java` recently bumped their `google-auth-library-credentials` and `google-auth-library-oauth2-http` dependencies to `0.8.0` -- was there some change that would require us to modify our authentication-related code in GATK, and/or the permissions setup in our Google Cloud project, that could explain the error:. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001:179,depend,dependencies,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001,1,['depend'],['dependencies']
Integrability,"@jean-philippe-martin Could you request a dot release? If they say no, we'll go the custom jar route.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-257688566:95,rout,route,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-257688566,1,['rout'],['route']
Integrability,"@jean-philippe-martin I can wrap the `CloudStorageFileSystemProvider.checkAccess()` method in a retry, but can you think of any other methods *outside* of `CloudStorageReadChannel` that might also require a retry?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314891599:28,wrap,wrap,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314891599,1,['wrap'],['wrap']
Integrability,"@jean-philippe-martin I had assumed that there were already CRAM tests in ReadUtilsUnitTest for the old createSAMWriter method, but there aren't (there are integration tests that exercise the cram code path through PrintReadsIntegrationTest.) In general you have to just know which reference goes with which cram. The canonical file we use is print_reads.cram/print_reads.fasta (in the tools test folder). You should probably copy them into the ReadUtils test folder to use it in those tests. If you do,you'll have to also copy print_reads.fasta.fai, or you'll get misleading CRAM errors. Also note that you won't be able to use iterator comparison when comparing an Iterator<CRAMRecord> with Iterator<BAMRecord>.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332212832:156,integrat,integration,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332212832,1,['integrat'],['integration']
Integrability,"@jean-philippe-martin I like your counter proposal in general for testing path integration. I think writing to GCS over NIO is an important enough feature that we should have at least 1 test in gatk that actually writes to a real GCS bucket in case there's ever an issue specifically with GCS (authentication issues are one potential problem I can imagine). . It seems like we should be able to design in a way that avoids collisions. What does `Files.createTempFile()` do with gcs? My guess is that it probably doesn't do the right thing, but maybe we could fix it so it would? Or use some sort of scheme with random UUID's like the methods in BucketUtils that we have already.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332235140:79,integrat,integration,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332235140,1,['integrat'],['integration']
Integrability,"@jean-philippe-martin It looks like it works fine on the cloud. I provided the `HELLBENDER_TEST_APIKEY`, and then removed the `cloud` group - from being excluded in `test` - from within `build.gradle` to look like this:. ```; test {; // enable TestNG support (default is JUnit); useTestNG{; excludeGroups 'bucket'; }; ...; ```. And then ran the following integration test, which finished successfully:. ```; $ gradle test -Dtest.single=BaseRecalibratorDataflowIntegrationTest --stacktrace; ...; Runtime.totalMemory()=1541406720. BUILD SUCCESSFUL. Total time: 32.277 secs. This build could be faster, please consider using the Gradle Daemon: http://gradle.org/docs/2.4/userguide/gradle_daemon.html; $; ```. How are you getting the error to show up?. Thanks,; Paul",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/580#issuecomment-113953068:355,integrat,integration,355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/580#issuecomment-113953068,1,['integrat'],['integration']
Integrability,"@jean-philippe-martin Possibly we were using the GCS<->HDFS adapter previously, and something changed in the code to make us use NIO here instead? (possibly https://github.com/HadoopGenomics/Hadoop-BAM/pull/111?)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265002735:60,adapter,adapter,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265002735,1,['adapter'],['adapter']
Integrability,"@jean-philippe-martin Sorry, the baby was not very asleep last night so I may be slightly less coherent than usual... . I see how you heard that, but it wasn't what I meant. What I mean was that we should eventually move the information about how to set -DSTACK_TRACE_ON_USEREXCEPTION into the top level UserException message to make it discoverable, and remove it from the comment it's in now. Lets do that in a different PR though since it's sort of orthogonal and the best thing to do might be to integrate it as a regular commandline option instead of an environment variable. Separately from that, I was wondering if we should catch StorageExceptions at the top level and handle them specially. If we're going to do that I think we could just add them to the UserException catch block and have them be treated the same way, no need for special handling.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-285152468:318,message,message,318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-285152468,2,"['integrat', 'message']","['integrate', 'message']"
Integrability,"@jean-philippe-martin Thanks for adding the additional test, but by ""integration test"", I meant something that exercises an actual tool (which is why I mentioned SelectVariants) with a non-default provider, not another unit test that uses GCS. I suggested SelectVariants since I thought it would be easy:. > all the previous comments have been addressed with the exception of adding a SelectVariants integration test. It should be pretty easy to clone an existing case and change it use a non-default nio provider. I think this last test is redundant with the one you already added. My apologies if that was confusing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455668135:69,integrat,integration,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455668135,2,['integrat'],['integration']
Integrability,@jean-philippe-martin That's great news. Unfortunately we can't easily update the NIO dependency until we have some solution to https://github.com/googleapis/google-cloud-java/issues/5884,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516442831:86,depend,dependency,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516442831,1,['depend'],['dependency']
Integrability,"@jean-philippe-martin Will there be a gcloud release with this change within the next ~week? We're rather urgently in need of a short-term fix, unfortunately. If a gcloud release isn't imminent, would it be an option to move GATK to depend on a gcloud snapshot?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-304124941:233,depend,depend,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-304124941,1,['depend'],['depend']
Integrability,"@jean-philippe-martin has added support for requester pays to gcloud. ; See https://github.com/GoogleCloudPlatform/google-cloud-java/pull/3406 . I've set up a new fork of the project at https://github.com/broadinstitute/google-cloud-java. I have a branch https://github.com/broadinstitute/google-cloud-java/tree/lb_update_pom_to_publish_to_orgbroad which I believe should make the changes necessary to run on dataproc and avoid https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2453. However, if you rollback the dependencies the project no longer compiles. You can compile the nio-subproject, but the parent project can no longer build against the old dependencies. That makes me very nervous because it seems likely that we will encounter runtime errors if we substitute them. . JP created a small test case to reproduce the error and it seems like the dataproc team is looking at it. Hopefully they can resolve the issue and we can switch to the base library instead of needing to publish an additional sketchy version of it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4828#issuecomment-404322757:527,depend,dependencies,527,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4828#issuecomment-404322757,2,['depend'],['dependencies']
Integrability,"@jean-philippe-martin, we want to expose a walker-like interface, but we also care about the general ease of writing programs using the tools we and the user wrote (in native Dataflow/Spark). This is a point that @droazen, has emphasized to me several times. I'll let him add more detail on this if needed. I agree that the static approach won't work for Dataflow when workers are added, but I think I have a solution for Spark that works even when workers are added.; We'd create a new class (like I suggested above), but this would have a `Broadcast<SAMFileHeader>`, which is basically a lazy-loader for headers. We'd only load the header when needed.; I think this may be the best of all solution as it could also support several headers.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141177047:55,interface,interface,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141177047,1,['interface'],['interface']
Integrability,"@jean-philippe-martin, when you have a chance could you please take a look at the stack trace above and give your thoughts? Our NIO library dependency was not upgraded between 4.0.11.0 and 4.0.12.0 (it was last upgraded in 4.0.9.0), so it's not clear what it is about 4.0.12.0 that is leading to this higher failure rate. . We've already tried a custom build of 4.0.12.0 that included the version of htsjdk from 4.0.11.0, but that didn't help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085:140,depend,dependency,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085,1,['depend'],['dependency']
Integrability,"@jfarrell Do you recognize ""scc"" as a local host name ? ""hdfs:///project/casa/gcad/adsp.cc/sv"" looks reasonable enough as a file URI, except that the hadoop file system provider requires an authority component (the part of the uri between the second and third slash: ""hdfs://authority-component/..."") be provided in such URIs. Since you didn't include one as part of the hdfs path on the command line, it looks like transform along the way resulted in one being added (the authority component looks like ""host:port""), resulting in the port number -1. So I'm not clear if its a configuration issue, or a bad code code path, or both. But I would suggest trying an hdfs path with a valid authority component (one that works with the hadoop shell). @SHuang-Broad I do see some code paths in `StructuralVariationDiscoveryPipelineSpark` that call `Paths.get directly`, rather than `IOUtils.getPath()`. I would also suggest replacing the direct calls to `makeSAMOrBAMWriter` in `SVFileUtils` with the GATK wrapper code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-493980166:999,wrap,wrapper,999,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-493980166,1,['wrap'],['wrapper']
Integrability,"@jingydz The error message; `Feature inputs must be unique: /data/users/zhanglei/species/Medicago/result/SRR340103.HC.g.vcf.gz` says exactly what the problem is, which is that you have a duplicate input:. /data/users/zhanglei/species/Medicago/result/SRR340102.HC.g.vcf.gz --variant /data/users/zhanglei/species/Medicago/result/**SRR340103.HC.g.vcf.gz** --variant /data/users/zhanglei/species/Medicago/result/**SRR340103.HC.g.vcf.gz** --variant /data/users/zhanglei/species/Medicago/result/SRR340104.HC.g.vcf.gz --variant",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-493674150:19,message,message,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-493674150,1,['message'],['message']
Integrability,@jjfarrell Thanks for the update. This error message indicates an invalid index file - older versions of GATK/HTSJDK didn't report these. Reindexing is the correct remedy.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7076#issuecomment-779851653:45,message,message,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7076#issuecomment-779851653,1,['message'],['message']
Integrability,"@jjfarrell That error message usually indicates that the reference supplied isn't the same (exact) same one that was used to create the cram. Can you try using `samtools view` on the same file/ref pair, and see if that works.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449485244:22,message,message,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449485244,1,['message'],['message']
Integrability,"@jjfarrell You don't need splitting index for cram. The index works around a bam specific problem which makes it hard to find good split points in the file. Cram is designed in a way that makes it easier to find the split points so the index is unnecessary. . I don't have good numbers for how long it takes to find the split points for bam. It depends on your filesystem. If you have a low latency file system like a local disk or hdfs setup than finding split points takes very little time (~seconds), but if you have a high latency file system like something backed by google object store then finding split points may take a long time (on the order of minutes to tens of minutes depending on latency and file size).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371224015:345,depend,depends,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371224015,2,['depend'],"['depending', 'depends']"
Integrability,@jmthibault79 This fails with a compiler error: . ```; :compileTestJava/home/travis/build/broadinstitute/gatk/src/test/java/org/broadinstitute/hellbender/engine/spark/datasources/VariantsSparkSinkUnitTest.java:240: error: cannot find symbol; return inferFromUncompressedData(IOUtil.isGZIPInputStream(bis) ? new GZIPInputStream(bis) : bis);; ^; symbol: method isGZIPInputStream(BufferedInputStream); location: class IOUtil; 1 error; FAILED; ```. I think you perhaps need to update the htsjdk dependency to a release that includes this change?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265:491,depend,dependency,491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265,1,['depend'],['dependency']
Integrability,"@jonn-smith - I think that it is a good idea to have a codec interface for non-locatables, but `Tribble` is designed for working with indexed data sources __by coordinate__ (the same as `Tabix`). I think that the proposal that you are making here for HTSJDK should be a different implementation, without messing up with the tribble code. Otherwise, tribble will lose the sense of working with coordinate-sorted data...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3760#issuecomment-340693533:61,interface,interface,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3760#issuecomment-340693533,1,['interface'],['interface']
Integrability,"@jonn-smith @LeeTL1220 @droazen Thanks for sharing the information above, and I looked at it. It seems to me that once we have a chain file for one reference and another reference, the remaining steps are straightforward. I also noticed the following Picard utility [Picard LiftoverVcf]( https://broadinstitute.github.io/picard/command-line-overview.html#LiftoverVcf ) that can Lift over a VCF file from one reference to another. ; Therefore, creating the chain file between a pair of references (and limiting ourselves to cases where both references are from the same species, mouse/human) is the key. To that end, according to the following post [List of chain file creators](https://www.biostars.org/p/65558/) most of the chain file creation tools are available as a web interface. However, the UCSC one seems to be more popular, and fortunately, they have the utilities as open source and to some degree explain their steps in the [LiverOver_Howto](http://genomewiki.ucsc.edu/index.php/LiftOver_Howto) link you sent. With this approach, they first BLAT the pairwise contigs in the reference files and then use the utility DoSameSpeciesLiftOver.pl. . Based on this, it appears to me I should think about the following steps:; a) First, try out their code (UCSC) and make sure it works to produce chain files for two references successfully.; b) Design/propose a solution putting the logic in DoSameSpeciesLiftOver.pl into GATK, which also might need a BLAT run . Let me know what you think of this or have any suggestions about how I should proceed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6837#issuecomment-804188470:774,interface,interface,774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6837#issuecomment-804188470,1,['interface'],['interface']
Integrability,@jonn-smith I'll add that it would be good to include an end-to-end integration test here as well to prove that the tool can successfully run to completion when the bounds-checking gets triggered.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7513#issuecomment-948797839:68,integrat,integration,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7513#issuecomment-948797839,1,['integrat'],['integration']
Integrability,@jonn-smith This should be good to go now. I added a non-regenerated integration test for the specific problem.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6178#issuecomment-538132773:69,integrat,integration,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6178#issuecomment-538132773,1,['integrat'],['integration']
Integrability,"@jsotobroad The version I pushed up should be good for you to test with. There are some more bells and whistles that need to be added around user interface, but the fundamental of fixing the sample assignment should be good.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3675#issuecomment-334882135:146,interface,interface,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3675#issuecomment-334882135,1,['interface'],['interface']
Integrability,@jsotobroad Would you mind reviewing this? Earlier I brought aspects of your mutect2_opt wdl into the public m2 wdl. Now I am bringing all the changes from the public wdl into the opt wdl while keeping your NIO-dependent code.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4306:211,depend,dependent,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4306,1,['depend'],['dependent']
Integrability,"@kcibul Can you try re-running with a build of https://github.com/broadinstitute/gatk/pull/2417, and paste the (hopefully) more detailed error message here?. Can you also try with a few different files in different buckets, and see whether you get the same error in every case?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281521368:143,message,message,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281521368,1,['message'],['message']
Integrability,"@kcibul My reasoning for doing it in WDL is to better integrate with the process that creates the VAT table, and therefore make sure that the person running it has access (and knows the location of) not only to the VAT table but also the intermediary steps (e.g. the annotation JSON files that are output from NIRVANA). Not all of the validation steps need to be all bash; the first one was because it's literally just a call to make sure a table exists and has rows with `vid` values in it. Other rules (e.g. [rule #2](https://github.com/broadinstitute/dsp-spec-ops/issues/365)) will most likely need either python or jq to run.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7352#issuecomment-883457790:54,integrat,integrate,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7352#issuecomment-883457790,1,['integrat'],['integrate']
Integrability,@kdatta Can you build GenomicsDB with static linkage of dependencies to guard against this sort of thing? That is what we do for the GKL.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294233248:56,depend,dependencies,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294233248,1,['depend'],['dependencies']
Integrability,@kdatta How's the integration test coming? Any issues writing it? Will it be pushed soon? Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-290445381:18,integrat,integration,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-290445381,1,['integrat'],['integration']
Integrability,"@kdatta I think the reason its failing is because the dylib has an unresolved transitive dependency on openssl (and possibly other things). When I debug locally, I can see that it has streamed the dylib out to a local folder and its trying to load it, but then I get this (see the highlighted text):. /private/var/folders/cr/16ghvyfj5lvfwxx01rt1k4tdl04sy3/T/libtiledbgenomicsdb2535884808429708562.dylib: dlopen(/private/var/folders/cr/16ghvyfj5lvfwxx01rt1k4tdl04sy3/T/libtiledbgenomicsdb2535884808429708562.dylib, 1): Library not loaded: **/usr/local/opt/openssl/lib/libssl.1.0.0.dylib**; Referenced from: /private/var/folders/cr/16ghvyfj5lvfwxx01rt1k4tdl04sy3/T/libtiledbgenomicsdb2535884808429708562.dylib; Reason: image not found. It looks TileDB does have such a dependency ([here](https://github.com/Intel-HLS/TileDB/blob/master/CMakeLists.txt#L79)). Do you know if thats new ? I think we need to figure out how many of these there are and resolve them somehow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294230131:89,depend,dependency,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294230131,2,['depend'],['dependency']
Integrability,@kdatta Is the version of protobuffs that gatk depends on compatible with the version that genomicsDB needs?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2588#issuecomment-292757482:47,depend,depends,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2588#issuecomment-292757482,1,['depend'],['depends']
Integrability,"@kdatta Looks like the integration tests passed on travis after clearing the cache! Once you address comments, squash, and rebase onto the latest gatk master the unit tests should pass as well, since you just need the TestNG fix that got merged into master. This means we can merge this today in all likelihood!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-296301829:23,integrat,integration,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-296301829,1,['integrat'],['integration']
Integrability,"@kdatta Thanks for the update -- we do need to get these tests passing with our `assertVariantContextsAreEqual()` comparison routine, rather than your diffing tool, but we can relax this routine to be agnostic to allele ordering. About the `MIN_DP` issue: can you explain what was causing it? Why was it working with a `VCFCodec` and not a `BCF2Codec`? I still don't understand. Does it work now with our comparison routine and using a `BCF2Codec` internally, or does it still require a `VCFCodec` to pass? . And what was the ""ExcessHet problem"" (don't see a description of it above)? Was it just the ""no combination operation"" warning? What did the output look like before and after the fix for this annotation?. @cmnbroad has volunteered to have a look at the tests in this branch this afternoon, so we should be able to give you some more feedback soon!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293978277:125,rout,routine,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293978277,3,['rout'],['routine']
Integrability,"@kdatta The Spark build broke last time because of a jar signature file from the `gnu.getopt` dependency that made it into our final GATK jar, not because of `protobuf-java-format`. We've now excluded these signature files from our jar. When will `genomicsdb-0.6.0` be released?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2634#issuecomment-297980594:94,depend,dependency,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2634#issuecomment-297980594,1,['depend'],['dependency']
Integrability,"@kdatta We'd prefer it if the tool could accept intervals and vcfs, and create whatever internal objects it needs to talk to GenomicsDB. This way, when you do the overhaul you're talking about, the command-line interface to this tool (and therefore pipeline scripts that invoke it) won't have to change. This would also enable it to be a more-standard `GATKTool` rather than a raw `CommandLineProgram`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277331110:211,interface,interface,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277331110,1,['interface'],['interface']
Integrability,"@kew24 Thanks for the bug report! Would you be satisfied if we just changed the text of the error message to read ""The last overlapping interval is ....""?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329723947:98,message,message,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329723947,1,['message'],['message']
Integrability,"@kguraj It looks like there are existing integration tests that use intervals that cover a pretty wide genomic range. It should be easy to write a test that programmatically generates a large set of (10000) or so very small intervals (1bp) with small (1bp) gaps between them (the gaps are necessary since otherwise the intervals will be merged together by the engine) that fails without this change and passes with it. It doesn't necessarily have to verify the results, just successfully complete.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407056469:41,integrat,integration,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407056469,1,['integrat'],['integration']
Integrability,"@kguraj Thanks for the response(s). The test in the PR was super useful as a temporary test, but as you mentioned it runs pretty slowly, and as it stands the test passes on current master anyway. It seems to require on the order of 9000-1000 intervals instead rather than 1000 to actually hit stack overflow. Since that would be a very slow running test, I'm inclined to back it out. Also, the user who originally reported the issue was using 11k intervals, and it seems that the stack overflow fix is unlikely to help in that case. Is there any guidance for users on what is a reasonable number of intervals per process ? It sounds like the intention was that it be used with pretty small intervals. Should we issue a warning message in GenomicsDBImport at some threshold number of intervals ?. Are you planning to produce a jar with the error messages suppressed for this PR?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407867902:727,message,message,727,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407867902,2,['message'],"['message', 'messages']"
Integrability,"@kgururaj @francesperry There's a [thread on the GATK forum](https://gatkforums.broadinstitute.org/gatk/discussion/comment/48287) where people are reporting a number of issues running GenomicsDB. There are a few different issues but they all seem to be edge cases with the file system. . 1. Report of the following error when trying to read from a GenomicsDB that is marked as read only. Is there a reason that the workspace must be writeable in order to read it? Can we avoid that requirement?; ```; terminate called after throwing an instance of 'VariantQueryProcessorException'; 2018-01-10T12:15:04.154547266Z what(): VariantQueryProcessorException : Could not open array genomicsdb_array at workspace: /keep/d22f668d4f44631d98bc650d582975ca+1399/chr22_db; ```. 2. `Could not open array genomicsdb_array at workspace` when working with a small disk. Changing to a larger disk fixed the problem. Possibly we need a better error message for the case where we are out of disk space?. 3. Reports of similar errors using a Lustre filesystem with file locking disabled. Can GenomicsDB run without file locking? If not, can we emit a clear error message when we hit that problem?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4753:930,message,message,930,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4753,2,['message'],['message']
Integrability,"@kgururaj @ldgauthier I'd propose that we add defensive code to detect this, as @kgururaj proposed above. Maybe throw with a message identifying the name of the field and the issue ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-408081250:125,message,message,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-408081250,1,['message'],['message']
Integrability,@kgururaj Can you please add a good integration test for this branch?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3982#issuecomment-357057167:36,integrat,integration,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3982#issuecomment-357057167,1,['integrat'],['integration']
Integrability,@kgururaj Can you take a look and see if we can issue a more informative error message.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5064#issuecomment-408492983:79,message,message,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5064#issuecomment-408492983,1,['message'],['message']
Integrability,"@kgururaj Do those first messages originate [here](https://github.com/Intel-HLS/TileDB/blob/33ad0355db215cb528162a74c16b706a059b0346/core/src/storage_manager/storage_manager.cc#L1168) ? I'm not sure what GenomicsDB code path leads there, but it looks like TileDB considers them to be an error that results in a short-circuit return. I'd be concerned that masking them would hide some underlying error. Are there any tests that verify that data round-trips though GDB when an interval list large enough to trigger these messages is encountered ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407394879:25,message,messages,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407394879,2,['message'],['messages']
Integrability,"@kgururaj I ran the commands you suggested. . > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.so; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: ./libtiledbgenomicsdb.so: No such file or directory; > + md5sum libtiledbgenomicsdb.so; > md5sum: libtiledbgenomicsdb.so: No such file or directory. I'm using a compute canada server, so I don't have root access. The version of gatk4 I'm using was installed by their support team, and I load it using 'module load gatk'. I had that module loaded when I ran this test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071:310,depend,dependencies,310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071,4,['depend'],['dependencies']
Integrability,"@kgururaj I think we just need to check the catch blocks in `GenomicsDBImport.getFeatureReadersInParallel()`, and get them to propagate the underlying exceptions properly (instead of just the top-level exception), so that we don't lose useful error messages like this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4592#issuecomment-376597795:249,message,messages,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4592#issuecomment-376597795,1,['message'],['messages']
Integrability,@kgururaj Is it possible to include information about the lock disabling in the lock error messages?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4753#issuecomment-439982616:91,message,messages,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4753#issuecomment-439982616,1,['message'],['messages']
Integrability,"@kgururaj Thanks for adding the test. Running it locally on my laptop (without your fix) succeeds though - I have to bump it up from 1000 intervals to 9000 to reproduce the stack overflow. But if I do that, it takes a long time to run, since it appears to be creating lots of small partitions. Is there any way to get it to use fewer partitions in a case like this where there are lots of intervals ?. Somewhat more concerning is that when with 8000 intervals, I see a different failure mode. First I see lots (thousands) of these messages:. `[GenomicsDB::VariantStorageManager] INFO: ignore message ""[TileDB::StorageManager] Error: Cannot list TileDB directory; Directory buffer overflow."" in the previous line`. followed by a failure that ends like this:. `[TileDB::StorageManager] Error: Cannot store schema; Too many open files in system.; libc++abi.dylib: terminating with uncaught exception of type LoadOperatorException: LoadOperatorException : Could not define TileDB array; TileDB error message : [TileDB::StorageManager] Error: Cannot store schema; Too many open files in system`. Can you reproduce that ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407214031:531,message,messages,531,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407214031,3,['message'],"['message', 'messages']"
Integrability,@kgururaj We should definitely add a defensive check to emit an error message when there's a mismatch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5113#issuecomment-413289512:70,message,message,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5113#issuecomment-413289512,1,['message'],['message']
Integrability,@knight2015 There's no specific schedule. The hope is to switch to spark 3.0.0 soon after it's officially released but it depends on some other factors like google cloud dataproc supporting 3.0 images. We're still essentially using the spark 1.x RDD API so as far as I can tell there isn't a ton of stuff coming that is going to be a big benefit to gatk in spark 3 (other than the official java 11+ support which is a very good thing.),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6644#issuecomment-641325396:122,depend,depends,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644#issuecomment-641325396,1,['depend'],['depends']
Integrability,"@laserson If you're running spark with the local[*] runner you need the wrapper script, since the spark jar doesn't include a copy of spark.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1331#issuecomment-163659981:72,wrap,wrapper,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1331#issuecomment-163659981,1,['wrap'],['wrapper']
Integrability,"@laserson the `SAMRecord` vs. Google `Read` is a loooooong story.; The super-short version:; We had a bunch of utilities written for `SAMRecord` that @droazen refactored over months to take the GATKRead interface. As it happens, the SAM spec and the GA4GH spec are not 100% compatible. So, it's not possible to losslessly convert from A -> B -> A (where A is `SAMRecord` or Google `Read`). The cases where it doesn't work are edge cases, but they exist. Second, @jean-philippe-martin found that converting to Google `Read` was fairly expensive. Between those two points, I think we're probably better off with SAM-backed reads. (Also, right now the Google `Read` is serialized via JSON, so it's not that small anyway.). @tomwhite and @jean-philippe-martin, I think adding the header back will be fine for us engineers working on the engine, but it will make for a poorer user experience for newcomers and Comp Bios to burden them with having to care about what happens with shuffles (when they just want to prototype something). . That said, I think this is probably the best approach we have at our disposal. If we do, we need to do an excellent job of throwing errors if users try to perform actions that would require the header. The error message should explain what really happened and ideally point to some documentation we write explaining the stripping of the header and how to fix it. If this error occurs, it needs to be simple for anyone to fix it. @droazen @lbergelson, what do you two think? (also @laserson, do you have any ideas or thoughts on the header since we're probably stuck with `SAMRecord`?)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141086025:203,interface,interface,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141086025,2,"['interface', 'message']","['interface', 'message']"
Integrability,"@lbergelson , 1 is not impossible, but it could turn out to be a bigger-than-expected project, because the bwa code, as I understand it, is accumulated through the years. For this specify error message we saw, the abort call is actually made by some low level code in bwa that once modified could throw away many other parts as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2123#issuecomment-243288136:194,message,message,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2123#issuecomment-243288136,1,['message'],['message']
Integrability,"@lbergelson , as we discussed, I made the mistake of not using the returned RDD when calling `cache()`, after I fixed it, [here](http://dataflow01.broadinstitute.org:18088/history/application_1464285223085_0460/jobs/) is the runtime, running the following code:. ```; 148 final JavaPairRDD<Long, SGAAssemblyResult> cachedResults = results.cache(); // cache because Spark doesn't have an efficient RDD.split(predicate) yet; 149 // results.count(); // ugly hack to make the actual computation happen, so later filtering step will be based on what has been actually computed; 150 ; 151 // save fasta file contents or failure message; 152 final JavaPairRDD<Long, SGAAssemblyResult> success = cachedResults.filter(entry -> entry._2().assembledContigs!=null);; 153 final JavaPairRDD<Long, SGAAssemblyResult> failure = cachedResults.filter(entry -> entry._2().assembledContigs==null);; 154 ; 155 if(!success.isEmpty()){; 156 success.map(entry -> entry._1().toString() + ""\n"" + entry._2().assembledContigs.toString()); 157 .saveAsTextFile(outputDir+""_0"");; 158 }; 159 ; 160 if(!failure.isEmpty()){; 161 failure.map(entry -> entry._1().toString() + ""\n"" + entry._2().collectiveRuntimeInfo.toString()); 162 .saveAsTextFile(outputDir+""_1"");; 163 }; ```. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1877#issuecomment-225641452:622,message,message,622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1877#issuecomment-225641452,1,['message'],['message']
Integrability,"@lbergelson - regarding the single implementation of `GATKRead`, I would like to maintain the interface because I have some custom implementations. Although if it is true that HTSJDK will move to a version 3 based on interfaces, I can change my code to use the HTSJDK interfaces instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358264778:94,interface,interface,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358264778,3,['interface'],"['interface', 'interfaces']"
Integrability,"@lbergelson @KevinCLydon This branch now passes all tests, is rebased onto the latest master, and is (finally) using the official GATK Python environment rather than the custom NVIDIA-provided one. I had to add two additional Python dependencies to our environment, and make some small modifications to the Python code to account for a newer version of pytorch-lightning that was required. The final outstanding issue in this PR is that I had to temporarily comment out the Jacoco coverage report code in our build.gradle and dockertest.gradle files, due to a bizarre problem where Jacoco was attempting to read/parse the new Pytorch model files added in this branch. This will have to be resolved before we can merge (or we might have to permanently disable Jacoco if it can't be...). After this is merged, there will have to be a second PR that adds the CNN tools to the `DeprecatedToolsRegistry`, and actually removes the legacy tools. When we do this, we need to be careful not to remove the expected CNN output files used by the new NVScoreVariants integration tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-2402661408:233,depend,dependencies,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-2402661408,2,"['depend', 'integrat']","['dependencies', 'integration']"
Integrability,"@lbergelson @droazen @kgururaj ; 1. I was playing around with the test codes in GATK and did not push GenomicsDB tests in this PR. Will push it in the next commit.; 2. This is at the top of our discussion list for next week. GenomicsDB interfaces use these JSON files today which contain input configuration, list of samples, mapping between sample IDs and TileDB row indexes and stream ids for the input VCFs. If this tool takes the list of VCFs and intervals as input, we'd have to recreate JSON files internally and pass it to GenomicsDB. I wanted to avoid this for now as we are thinking about overhauling the input methodology completely in GenomicsDB with protocol buffers, but this is going to take a while. Also, we need to decide what's the best way to maintain the callset mappings.; 3. Will let you know asap. -Kushal.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277320579:236,interface,interfaces,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277320579,2,"['interface', 'protocol']","['interfaces', 'protocol']"
Integrability,@lbergelson Do we actually have any tests that depend on R besides the RScriptExecutor tests (which don't do much). Also wondering if there would be inconsistencies with Picard R requirements.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359096527:47,depend,depend,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359096527,1,['depend'],['depend']
Integrability,"@lbergelson Do you have an opinion on the best way to pip install the gcnvkernel python package and dependencies for Travis testing? I've verified that the pip install works within a basic conda environment with python=3.6. We'll need to load this environment both for unit/integration tests as well as WDL tests. As long as this is the only python environment we need, I think we can simply use the base environment in the Docker. If more environments are required (e.g., for @lucidtronix), then maybe we'll need to be more clever for unit/integration tests, but we can still load them manually in the scripts that kick off the WDL tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-348073948:100,depend,dependencies,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-348073948,3,"['depend', 'integrat']","['dependencies', 'integration']"
Integrability,"@lbergelson I added an integration test that writes to GCS... it doesn't work for me (""com.google.cloud.storage.StorageException (...) does not have storage.objects.get access to (...)""). This may be due to a misconfiguration on my end. I wonder if it'll work with Travis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-334877523:23,integrat,integration,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-334877523,1,['integrat'],['integration']
Integrability,"@lbergelson I added the ClassLoader fallback code in to `GATKPathSpecifier`. In doing so, I expected some of the `PathSpecifier` negative unit tests to produce different exceptions, but they didn't. This was because the tests were all using the `PathSpecifier` base class (because I took them from htsjdk-next which has only the base implementation). So I updated the tests to use `GATKPathSpecifier` (they all passed), then integrated the fallback code and changed 3 negative tests that went from FileSystemNotFoundException to ProviderNotFoundException. Finally I renamed the test class file to correctly reflect the class being tested. Sorry this was such a pain.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714:425,integrat,integrated,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714,1,['integrat'],['integrated']
Integrability,"@lbergelson I moved the ""disable"" toggle to the `ProgressMeter` constructors, and made it `final` so that it won't change over the lifetime of the object. I agree that extracting an interface, etc., would be nicer, but I think such a larger refactor can wait for a future PR. For now, this fixes the currently-broken `disableProgressMeter()` method in a way that involves the least-invasive changes to the tools / traversals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7354#issuecomment-881711125:182,interface,interface,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7354#issuecomment-881711125,1,['interface'],['interface']
Integrability,"@lbergelson I think most use cases for this would be for post-arg-parsing problems, so it would make sense to add an Advanced, common command line argument for it. Much easier to use, and as you say we could include instructions in the exception message itself for how to enable it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285197345:246,message,message,246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285197345,1,['message'],['message']
Integrability,"@lbergelson I think the idea of the BlockCompressedIntervalStream is a sound one, and will be quite useful. The code around it -- trying to integrate it with the Feature system -- is a stinky mess, and I'm trying to clean it up.; I'm close to having a major update. Let's think about it more at that point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-840054226:140,integrat,integrate,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-840054226,1,['integrat'],['integrate']
Integrability,"@lbergelson I used Maven because it's what they taught me at the university to download Spark dependencies, so I'm a novice too; I'm sorry to bothering you with new errors (I promise that tomorrow I see how to do it with Gradle and stop bothering you), but adding even the repository to the pom.xml generated this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Failed to collect dependencies at org.broadinstitute:gatk:jar:4.beta.6-18-g2ee7724-20171025.162137-1 ; -> com.google.cloud.genomics:google-genomics-dataflow:jar:v1beta2-0.15 ; -> com.google.cloud.genomics:google-genomics-utils:jar:v1beta2-0.30 ; -> io.grpc:grpc-all:jar:0.7.1 -> io.grpc:grpc-auth:jar:0.7.1 ; -> com.google.auth:google-auth-library-oauth2-http:jar:0.1.0: ; Failed to read artifact descriptor for com.google.auth:google-auth-library-oauth2-http:jar:0.1.0: ; Could not find artifact com.google.auth:google-auth-library:pom:0.1.0 in snapshots (https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot) -> [Help 1]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339755211:94,depend,dependencies,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339755211,3,['depend'],['dependencies']
Integrability,"@lbergelson I was a little surprised too, but the unit test that's failing is a dumb test. The header description had been copied into the test itself, so I extracted it as a static constant. The integration test for GVCFs checks headers, which, after some internal debate, I think is fair. And there's David's handy exact match update, so fixing it is super easy.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6431#issuecomment-581435478:196,integrat,integration,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6431#issuecomment-581435478,1,['integrat'],['integration']
Integrability,"@lbergelson I was able to get the auth set up right for the integration test (locally). It fails in a few places because some combinations are not supported.; *edit* I spoke too soon, that was a bug in the test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-336530831:60,integrat,integration,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-336530831,1,['integrat'],['integration']
Integrability,"@lbergelson I was referring more to the middle part of the StackOverflow by Daniel Chapman - specifically the [4.1 The ObjectStreamClass Class](http://docs.oracle.com/javase/8/docs/platform/serialization/spec/class.html#a5082) and [4.6 Stream Unique Identifiers](http://docs.oracle.com/javase/8/docs/platform/serialization/spec/class.html#a4100):. _If not specified by the class, the value returned is a hash computed from the class's name, interfaces, methods, and fields using the Secure Hash Algorithm (SHA) as defined by the National Institute of Standards._. Now when I look at the `java.io.ObjectStreamClass.java` file for 64-bit JDK7 and JDK8 - from src.zip - both have the same code for the following parts after performing a `diff` - I didn't list all of the lines of code since they are quite long:. ```; public long getSerialVersionUID() {; // REMIND: synchronize instead of relying on volatile?; if (suid == null) {; suid = AccessController.doPrivileged(; new PrivilegedAction<Long>() {; public Long run() {; return computeDefaultSUID(cl);; }; }; );; }; return suid.longValue();; }; ... private static long computeDefaultSUID(Class<?> cl) {; ...very long code which can be inspected via the src.zip file...; }; ```. So looking at the code portions of `computeDefaultSUID()` and I notice in our instance `ReadFilter` is a interface, which gets defined later via [ReadFilterLibrary.java](https://github.com/broadinstitute/hellbender/blob/62ef76ba60951c562a0d4c39189aa3f01f27f8d3/src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilterLibrary.java) or via `new ReadsFilter(readFilter, header)`, in either of these instances the fields would be different, based on this portion of `computeDefaultSUID` when looking at declared fields:. ```; Field[] fields = cl.getDeclaredFields();; MemberSignature[] fieldSigs = new MemberSignature[fields.length];; for (int i = 0; i < fields.length; i++) {; fieldSigs[i] = new MemberSignature(fields[i]);; }; ```. Therefore the `SUID` would be ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107730499:441,interface,interfaces,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107730499,2,"['interface', 'synchroniz']","['interfaces', 'synchronize']"
Integrability,@lbergelson I'm looking into this some more; I wonder if the ADAM bump is bringing in some dependency conflict. I'll report back.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356133180:91,depend,dependency,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356133180,1,['depend'],['dependency']
Integrability,"@lbergelson If you query for output after you've terminated the process, the query will fail immediately because the Futures will have been completed with a CancellationException when the pipes were broken by the termination. But I think even that might be subject to a race condition. Previously we were dependent on stdout/stderr for synchronization and error detection, but with the ack fifo and the python exception handler installed, we really aren't anymore. We do need to fix https://github.com/broadinstitute/gatk/issues/5100, and have a better logging integration strategy, but in general I think we should seek to eliminate all use of stdout/stderr except for advisory purposes. On a separate tangent, what I'd really like to do is unify the two PythonExecutors into a single one. All of these features I'm adding like profiling, version checking, logging integration etc., will have to be done in both of them otherwise.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5097#issuecomment-413575698:305,depend,dependent,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5097#issuecomment-413575698,4,"['depend', 'integrat', 'synchroniz']","['dependent', 'integration', 'synchronization']"
Integrability,"@lbergelson In your opinion, how likely is this feature to cause problems? We do still call `QueryInterval.optimizeIntervals()` to merge intervals in `ReadsDataSource` before starting an iteration, and I think that's the main example of an HTSJDK query interface that can't handle overlapping intervals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567634113:253,interface,interface,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567634113,1,['interface'],['interface']
Integrability,"@lbergelson It looks like it did indeed still work to only download the gradle dependencies once, i'm going to squash and merge this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5155#issuecomment-418753777:79,depend,dependencies,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5155#issuecomment-418753777,1,['depend'],['dependencies']
Integrability,@lbergelson Looks like we have a failure in `BigQueryUtilsUnitTest`:. ```; testQueryWithStorageAPI; java.lang.IllegalStateException: getTransportChannel() called when needsExecutor() is true; 	at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel(InstantiatingGrpcChannelProvider.java:194); 	at com.google.api.gax.rpc.ClientContext.create(ClientContext.java:241); 	at com.google.cloud.bigquery.storage.v1beta1.stub.EnhancedBigQueryStorageStub.create(EnhancedBigQueryStorageStub.java:108); 	at com.google.cloud.bigquery.storage.v1beta1.BigQueryStorageClient.<init>(BigQueryStorageClient.java:144); 	at com.google.cloud.bigquery.storage.v1beta1.BigQueryStorageClient.create(BigQueryStorageClient.java:125); 	at com.google.cloud.bigquery.storage.v1beta1.BigQueryStorageClient.create(BigQueryStorageClient.java:116); 	at org.broadinstitute.hellbender.utils.bigquery.StorageAPIAvroReader.<init>(StorageAPIAvroReader.java:51); 	at org.broadinstitute.hellbender.utils.bigquery.StorageAPIAvroReader.<init>(StorageAPIAvroReader.java:45); 	at org.broadinstitute.hellbender.utils.bigquery.BigQueryUtils.executeQueryWithStorageAPI(BigQueryUtils.java:394); 	at org.broadinstitute.hellbender.utils.bigquery.BigQueryUtils.executeQueryWithStorageAPI(BigQueryUtils.java:370); 	at org.broadinstitute.hellbender.utils.bigquery.BigQueryUtilsUnitTest.testQueryWithStorageAPI(BigQueryUtilsUnitTest.java:74); ```. I suspect we need to bump our BigQuery dependency in this PR as well -- I'll attempt it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1051025679:1456,depend,dependency,1456,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1051025679,1,['depend'],['dependency']
Integrability,"@lbergelson Now that https://github.com/broadinstitute/gatk/pull/6759 is merged, can you rebase this branch onto master to reconcile it with the extensive dependency changes in that PR?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6736#issuecomment-702906315:155,depend,dependency,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6736#issuecomment-702906315,1,['depend'],['dependency']
Integrability,"@lbergelson Our stuff runs fine using Dataproc image 1.3 and the current GATK dependencies, so I guess it's not crucial, but it's probably something we should investigate doing?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5125#issuecomment-417720868:78,depend,dependencies,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5125#issuecomment-417720868,1,['depend'],['dependencies']
Integrability,"@lbergelson Right, that what I was thinking. It's a very commonly occurring issue for gCNV, so it would be a very useful message for users.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6362#issuecomment-572682056:121,message,message,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6362#issuecomment-572682056,1,['message'],['message']
Integrability,"@lbergelson So, the test failures are in `ScoreVariantAnnotationsIntegrationTest` and `TrainVariantAnnotationsModelIntegrationTest`, when run within the conda environment in the new docker image. I've confirmed that they happen with both Ubuntu 22.04 and 20.04. They are assertion failures from `h5diff` indicating that the actual outputs did not match the expected outputs, so there are likely actual numerical differences here. Most likely the newer Ubuntu releases are shipping with newer versions of native libraries that HDF5 (or some other GATK dependency) depends on, and there was some breaking change somewhere along the line. . I think our only option is to capture the outputs of these tests, and ask @samuelklee to confirm that the differences do not indicate an actual regression.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8610#issuecomment-1848740833:551,depend,dependency,551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8610#issuecomment-1848740833,2,['depend'],"['dependency', 'depends']"
Integrability,"@lbergelson Sorry to be unclear---this isn't a GATK issue. For Cromwell, you can configure various options for each backend. For example, if you are running on a local backend with Docker, you can set a `submit-docker` attribute to specify the string that runs the Docker container; so to solve the above problem, you'd set this to include `--shm-size` and set it accordingly. However, according to @jsotobroad, you're not allowed such an attribute when submitting to Google cloud. If that's the case, then this is more of an issue with the Cromwell/Google Pipelines interface than the data.table package (although, as the discussion in the GitHub issue above shows, it'd be a simple fix on the data.table end, so I'm not sure why it's not addressed yet...) Changing the R script to get around the issue in this particular case is not unacceptably ugly, but you could imagine we might run into a similar problem in the future if anything else exceeds the 64MB /dev/shm limit and also cannot specify tmpfs. So perhaps we should take a look at the underlying issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691:567,interface,interface,567,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691,1,['interface'],['interface']
Integrability,"@lbergelson Thank you for reviewing. `FeatureDataSource.getGenomicsDBFeatureReader()` passes the default vcf header name to `GenomicsDBFeatureReader()` - and I've updated the GenomicsDB integration tests for clarity. If I've misunderstood your previous comment and other changes to `FeatureDataSource.getGenomicsDBFeatureReader()` are required, I can make these updates.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3994#issuecomment-354856711:186,integrat,integration,186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3994#issuecomment-354856711,1,['integrat'],['integration']
Integrability,@lbergelson Thank you for your response. I tried this version of Spark and it did not change the error message. Please tell me what information you may need to reproduce the error.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306963267:103,message,message,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306963267,1,['message'],['message']
Integrability,"@lbergelson The problem with `StandardArgumentDefinitions` is that it's an awkward transplant from picard that isn't really well integrated into the codebase. Check out the class comment for it, which is totally inaccurate:. ```; A set of String constants in which the name of the constant (minus the _SHORT_NAME suffix); is the standard long Option name, and the value of the constant is the standard shortName.; ```. As it stands, we've generally only put the most common args into `StandardArgumentDefinitions`, not specialized args like `--disableSequenceDictionaryValidation`. We can change this policy, but we should do it in a separate ticket, and implement the policy throughout the codebase.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1145#issuecomment-157515433:129,integrat,integrated,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1145#issuecomment-157515433,1,['integrat'],['integrated']
Integrability,"@lbergelson The stats file is not optional, but the *argument* is optional because by default `FilterMutectCalls` looks for the stats file produced automatically by `Mutect2` in the same directory as the output vcf. @andrewrech The official best practices pipeline -- that is, mutect2.wdl in this repo and hosted on Terra (formerly Firecloud) -- handles this automatically. We generally discourage users from writing their own pipelines because it takes very long and can easily yield inferior results. Is the official pipeline missing a feature that you need?. As for backwards compatibility, while we can guarantee that `Mutect2` and `FilterMutectCalls` from the same GATK release will always work together we do not make any promises about the interoperability of different releases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6124#issuecomment-527621821:747,interoperab,interoperability,747,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6124#issuecomment-527621821,1,['interoperab'],['interoperability']
Integrability,@lbergelson The trouble with the large tests is that they can be automatically generated and have lots of output so it's hard to check the details. Do you have an example of where this was causing an error before? If so we can build a unit or integration test out of that variant to ensure this doesn't regress. If you can provide that kind of a locus I could go in and add in a test for it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6178#issuecomment-534637031:243,integrat,integration,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6178#issuecomment-534637031,1,['integrat'],['integration']
Integrability,"@lbergelson There aren't too many incompatible changes between Spark 1.x and Spark 2.x, but there are some, and that required us to further parameterize our build and release. Feel free to borrow from our scripts if you go down that route. I'll keep an eye out for your new patch to review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-261284201:233,rout,route,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-261284201,1,['rout'],['route']
Integrability,"@lbergelson These changes are dependent on a Barclay [PR](https://github.com/broadinstitute/barclay/pull/17) that is not merged yet, so we should at least wait for that snapshot. Ideally, the other two (tiny) Barclay PRs in the queue should also be reviewed/merged, then we could do a release and upgrade to that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-271991891:30,depend,dependent,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-271991891,1,['depend'],['dependent']
Integrability,@lbergelson We were just talking about this. Thanks to @skwalker's HaplotypeCaller tie out I think it's close. Question for the engine team: this is going to break several integration tests. What would you suggest doing?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-377359265:172,integrat,integration,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-377359265,1,['integrat'],['integration']
Integrability,"@lbergelson Yes - this test is a leftover artifact of the original implementation, but we're no longer dependent on the features tested it so its fine to remove.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-451021915:103,depend,dependent,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-451021915,1,['depend'],['dependent']
Integrability,"@lbergelson You are correct. Let us do a bit more research to see if we can get GKL to log properly to both GATK 3 and 4. If not, we might have to go the route of having a GKL specific to GATK 3. Can we leave this PR open for now?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320745313:154,rout,route,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320745313,1,['rout'],['route']
Integrability,"@lbergelson counter-proposal: since writing to a temp location in GCS would risk collisions if multiple people run the test, how about writing to JimFS instead? It's a RAM filesystem so each test machine gets its own, and it still requires the code to use the Path objects correctly since any conversion to File would fail. As a bonus, we do not incur Cloud charges and the test is much faster, so we can keep it as a unit test instead of an integration test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332078512:442,integrat,integration,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332078512,1,['integrat'],['integration']
Integrability,@lbergelson here is the new version of the tool with all of the integration tests hand-verified verses the old version of the tool. The output now consistently passes validation and there is now an option to turn on (it is off by default) the N-splitting of secondary alignments.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2021#issuecomment-239503282:64,integrat,integration,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2021#issuecomment-239503282,1,['integrat'],['integration']
Integrability,"@lbergelson please review. I chose to add a master ""disable"" toggle to the `ProgressMeter` class itself rather than requiring all traversals / tools to wrap ProgressMeter calls in if statements.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7354#issuecomment-881695208:152,wrap,wrap,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7354#issuecomment-881695208,1,['wrap'],['wrap']
Integrability,@lbergelson thank you for the comment and sorry for my bit late response. I excluded the dependency to the jsr203-s3a and tested that both local- and spark-gatk can access s3a files by dynamically loading it. I also added a new directory `scripts/s3a` for documentation and simple tests for s3a demonstration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6698#issuecomment-665484597:89,depend,dependency,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698#issuecomment-665484597,1,['depend'],['dependency']
Integrability,"@lbergelson you beat me because I was stuck trying to actually run a Picard tool in the integration test. (For future reference, that needs a workaround because the test running adds the ERROR level logging to all command lines and Barclay can't parse that for Picard tools for some reason.). The big reason I was using this instead of IntervalListTools is because the Picard version creates a terrible output file structure that I was having trouble capturing with a simple glob in WDL. I agree that the functionality here is largely redundant, but it was helping me get my workflow working faster at the moment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5392#issuecomment-435894196:88,integrat,integration,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5392#issuecomment-435894196,1,['integrat'],['integration']
Integrability,"@lbergelson, @droazen are you OK with adding a SNAPSHOT dependency for Hadoop-BAM so we can commit this (and also the GVCF PR)?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3369#issuecomment-325704254:56,depend,dependency,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3369#issuecomment-325704254,1,['depend'],['dependency']
Integrability,"@lbergelson, I don't think that this solution will help in this case, because another error when trying to use `CommandLineProgramTest`is that it extends `BaseTest`, which loads directly a `GenomeLocParser` for a reference that is not present and it blows up in every test. Regarding the `Main` class, because you point it out here, I would like to have some control over `Main` and how it manages things like errors or logging header. Basically all the things that I'm facing at the moment are, apart of this error using the testing framework, is that the framework have tons of mentions to the GATK itself (error messages pointing to the GATK manual page or bundle tools), and little control over which of them should be expose to the final user. Only as an example, I would like to output a line with the name and version of my software and a short notice about the usage of the GATK framework and which version I'm using (for easier maintenance, and contribution if a bug is found).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-242802278:615,message,messages,615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-242802278,1,['message'],['messages']
Integrability,"@lbergelson, just want to discuss some issues here-. 1. We currently have to use `--avoid-nio` with `--sample-name-map` and `--bypass-feature-reader` to get `GenomicsDBImport` to work with azure URIs. Why don't we just merge the `--avoid-nio` functionality with `--bypass-feauture-reader`, that is allow GenomicsDB to process the URIs by default?; 2. Noticed that the only way to use azure URIs for vcf names is by using `--sample-name-map`. Directly specifying vcfs with the `-V` option is not possible because `--avoid-nio` cannot be used in conjunction. Should this be supported?; 3. @lbergelson, w.r.t malformed Azure URIs, GenomicsDB does put out an error -; ```; 11:10:12.658 error NativeGenomicsDB - pid=30608 tid=2980282 htslib_plugin could not open file az://genomicsdb@oda/vcfs/t0.vcf.gz [TileDB::StorageManagerConfig] Error: Azure Storage Blob initialization failed for home=az://genomicsdb@container/vcfs/sample.vcf.gz; ; Azure Blob URI does not seem to have either an account or a container: Protocol error; [E::hts_open_format] Failed to open file ""az://genomicsdb@container/vcfs/sample.vcf.gz"" : Input/output error; ```; Is this not sufficient? These are the acceptable azure URIs currently; ```; az://<container_name>@<account_name>.blob/<folder>/<file> # for default endpoints; az://<container_name>@<account_name>.blob.core.windows.net/<folder>/<file> # if the endpoint is blob.core.windows.net; azb://<container_name>/<folder>/<file> # following java.nio for azure URIs; azb://<container_name>/<folder>/<file>?account=<account_name>&endpoint=<endpoint>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8632:1005,Protocol,Protocol,1005,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8632,1,['Protocol'],['Protocol']
Integrability,"@lbergson's instructions above are good, but somehow they did not work for me. I was able to follow the [application default credentials](https://developers.google.com/identity/protocols/application-default-credentials) instructions, though. Here are the steps I took:. 1. create a new service account on the Google Cloud web page and download the JSON key file.; 2. gcloud auth activate-service-account --key-file ""$PATH_TO_THE_KEY_FILE""; 3. export GOOGLE_APPLICATION_CREDENTIALS=""$PATH_TO_THE_KEY_FILE"". I cleared my credentials first to make sure that the access worked because of the above steps, not because of other credentials. After those steps, gatk was able to run from my desktop and access files using the service account credentials. `gsutil ls` worked as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2425#issuecomment-282900470:177,protocol,protocols,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2425#issuecomment-282900470,1,['protocol'],['protocols']
Integrability,"@ldgauthier & @droazen I've done as you've suggested. There is now a check in `GenomicsDBImport`, by wrapping the FeatureReader. It's a little ugly but it gets the job done. I've also added a simple test for GenotypeGVCFs to genotype a GVCF that has an MNP in it. I _think_ this is probably now ready for review. Let me know if you think further tests are needed!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5182#issuecomment-422989371:101,wrap,wrapping,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5182#issuecomment-422989371,1,['wrap'],['wrapping']
Integrability,@ldgauthier @davidbenjamin please take a look. . Don't allow the number of lines changed intimidate you... (most are in test resource files). The first commit contains the actual main code changes. . The second and third commits update the test resources (where most of the changed lines come from) and test code. . The very last commit changes the default radius to 2... I was planning to set it to 0 since it is more parsimonious (less complex configuration) but it may well affect sensitivity and certainly changes the PL/QUAL values so I guess set the value two the current 2 (for PLs) is a safer and more conservative approach until we evaluate what is the optimal value for this parameter. . Perhaps @davidbenjamin would like to have a different default for Mutec. This is last minute change and may break some of the integration test so bear with me if that is the case. However I think you can start reviewing the code at this point.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-516992042:824,integrat,integration,824,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-516992042,1,['integrat'],['integration']
Integrability,"@ldgauthier @lucidtronix I'm updating this with a proposed list of CNNScoreVariants issues I think need to be resolved before we can remove the `@Beta` tag (actually is currently marked `@Experimental`). Let me know what you think:. - https://github.com/broadinstitute/gatk/issues/4538 (Python factoring/PEP-8/code review); - factor python args handling (minimally factor out the inference args); - there is only one 2D test, which I think has no reads overlapping any of the variants; - we should add a test that specifies one or more intervals; - the tool currently adds standard VQSR header lines via addVQSRStandardHeaderLines, which is unnecssary; - integrate read downsampling; - determine/handle the failure mode when the user supplies a mix (of mismatched) 1D/2D arch and weights inputs. Other (not necessarily blockers):; - establish all defaults (weights/arch/etc) in Java code; - default arch is 1D - should this change to 2D ?; - see if we can remove the artificially small inference/batch sizes (1) used in the tests. I think we added these due to timeouts which should no longer be an issue.; - remove the `newExpectations` code paths in integration tests",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231:655,integrat,integrate,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231,2,['integrat'],"['integrate', 'integration']"
Integrability,"@ldgauthier @yfarjoun We have an update on this! We've identified the bug:. * When `AbstractFeatureReader.getFeatureReader()` tries to open a `.vcf.gz` that doesn't have an index, it returns a `TribbleIndexedFeatureReader` instead of a `TabixFeatureReader`, because `methods.isTabix()` returns false when an index is not present.; * `TribbleIndexedFeatureReader`, in turn, opens a Java vanilla `GZIPInputStream`, instead of the `BlockCompressedInputStream` that gets opened when you create a `TabixFeatureReader`.; * `GZIPInputStream`, in turn, has a *confirmed bug* filed against it in Oracle's bug tracker (see https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that it inappropriately relies on the `available()` method to detect end-of-file, which is never safe to do given the contract of `available()`; * As the final piece in the ghastly puzzle, implementations of `SeekableStream` in htsjdk do not implement `available()` at all, instead using the default implementation which always returns 0. As a result of this combination of bugs in Java's `GZIPInputStream` itself and bugs in htsjdk's `SeekableStream` classes, end-of-file can be detected prematurely when within 26 bytes of the end of a block, due to the following code in `GZIPInputStream.readTrailer()`:. ```; if (this.in.available() > 0 || n > 26) {; ....; }; return true; // EOF; ```. Where `n` is the number of bytes left to inflate in the current block. The solution is to replace all usages of the bugged `GZIPInputStream` with `BlockCompressedInputStream` in tribble in htsjdk (at least, for points in the code where the input is known to be block-gzipped rather than regular gzipped). For due diligence we should also implement `available()` correctly for all implementations of `SeekableStream` in htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461:795,contract,contract,795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461,1,['contract'],['contract']
Integrability,"@ldgauthier At the test locus used in `HaplotypeCallerIntegrationTest.testHaploidNoCall()`, <NON_REF> allele/haploid genotype is no longer the most likely genotype after the changes in this PR. So I removed the integration test and added a unit test that checks that when the <NON_REF> allele is present in the genotype, the no_call genotype (e.g. ""."" or ""./."") has the correct ploidy, which was the problem #6563 fixed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6696#issuecomment-679416696:211,integrat,integration,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6696#issuecomment-679416696,1,['integrat'],['integration']
Integrability,@ldgauthier Can you take a look at this? This fixed a pretty rare (but not rare enough that it wasn't causing mismatches in my other work) error in GATK where we would be mis-sizing assembly windows where indels that overlapped snps were involved. It made some moderate differences in PL scores in HC tests which suggests its actually happening somewhat more frequently than couple of dropped indels I observed would suggest. I see however that it affected one of the CombineGVCFs integration tests (specifically all the values seem to be off by very small margins). Is that a problem at all?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-671564473:481,integrat,integration,481,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-671564473,1,['integrat'],['integration']
Integrability,"@ldgauthier Certainly, if that's what's really in the VCFs. As mentioned in my earlier comment, the changes in 4.1.5.0 may just be revealing pre-existing problems in the data. It's unfortunate that the error message doesn't include the locus... @GATKSupportTeam @bhanugandham I think the next step here is to tell the user that the error message is an additional check added in recent versions of GATK, and suggests that a reference allele in one of their `--resource` VCFs mismatches a reference allele in the `-V` VCF. . Given that several of their VCFs are missing sequence dictionaries according to the warning messages at the beginning, it's likely that at least one VCF is using a different reference from the `-V` VCF.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-663065592:208,message,message,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-663065592,3,['message'],"['message', 'messages']"
Integrability,@ldgauthier I added an integration test for GVCF mode and it works fine: the alleles are as expected with the addition of `<NON REF>`. I'm now going to investigate how the MNPs interact with CombineGVCFs and GenotypeGVCFs.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-384473840:23,integrat,integration,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-384473840,1,['integrat'],['integration']
Integrability,@ldgauthier I wrote a detailed error message. Anything else?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-560982515:37,message,message,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-560982515,1,['message'],['message']
Integrability,"@ldgauthier I'm about to submit a bug fix PR. In the line you found the `.intersect(region)` should be `.intersect(region.getPaddedSpan())`. The intersection is to avoid a bug where the requested trimmed padded region is bigger than the original padded region, but `intersect(region)` causes it to lie within the original unpadded region, which is unnecessary and probably harmful to sensitivity (the trimming cigar didn't hurt sensitivity, but I wonder if this mistake may have offset a net benefit that it should have created). I replicated @jemunro's error in the branch, fixed it (of course), and wrote an equivalent regression test that fails before and passes after the PR. The rest is just the usual annoying updating of integration test files, which as of right now I'm in the middle of.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6495#issuecomment-599885755:728,integrat,integration,728,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6495#issuecomment-599885755,1,['integrat'],['integration']
Integrability,"@ldgauthier I've fixed the NPE by deleting an incorrect implementation of `getRawKeyNames()`. Actually, I deleted them all, and just put a correct implementation as a default method in the `ReducibleAnnotation` interface, as we discussed. I also removed a bunch of unnecessary qualifiers from the interface. If tests pass this time around, we should finally be able to release :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6079#issuecomment-539412047:211,interface,interface,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6079#issuecomment-539412047,2,['interface'],['interface']
Integrability,"@ldgauthier If you feel that you need some validation, but less strict/expensive than the default, then I'd suggest turning off the default validation, writing your own scaled-down dictionary validation routine, and calling it from `onTraversalStart()` in your tool. Then if it seems like the scaled-down validation might be generally useful, we could hook it up to the `SequenceDictionaryValidationArgumentCollection` as a third engine-level option.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6589#issuecomment-625438251:203,rout,routine,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6589#issuecomment-625438251,1,['rout'],['routine']
Integrability,"@ldgauthier In GATK4 we require that all PRs be squashed into a single commit at the end of review (ie., ""Squash and merge"" is the only option enabled for this repo). But I'll add that github will do the final squash for you -- all you have to do is click ""Squash and merge"", then edit the commit message in the text box that pops up to cleanly describe the final feature (you can enlarge the text box while editing).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316868380:297,message,message,297,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316868380,1,['message'],['message']
Integrability,"@ldgauthier It looks like when you added GVCF mode to Mutect2, you may have marked this arg as beta even though it's shared with the HaplotypeCaller. Perhaps it would be easiest for M2 and HC to just have separate `-ERC` arg declarations? Or you could remove the beta label from the argument itself, and have M2 emit a logger message saying that GVCF mode is beta when running with `-ERC GVCF`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5988#issuecomment-499609768:326,message,message,326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5988#issuecomment-499609768,1,['message'],['message']
Integrability,@ldgauthier Should we patch `GenotypeGVCFs` to detect reblocked input and throw a `UserException` with an explanatory message?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437#issuecomment-906617099:118,message,message,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437#issuecomment-906617099,1,['message'],['message']
Integrability,"@ldgauthier The new test files you added were indeed correctly checked in as git-lfs files! You can tell this because in the diff for the PR these files are marked with the message ""Git LFS file not shown"". (I'll add that any new files added under `src/test/resources/large` get automatically tracked by lfs provided that you've completed the lfs setup instructions in https://github.com/broadinstitute/gatk#lfs -- we generally put files that are more than about 1 MB in there)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316188293:173,message,message,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316188293,1,['message'],['message']
Integrability,"@ldgauthier This looks good, its a pretty simple change and there are unit tests and integration tests that enforce the new behavior. I would squash the two commits and give them an informative commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124:85,integrat,integration,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124,2,"['integrat', 'message']","['integration', 'message']"
Integrability,"@ldgauthier Unfortunately there are still two integration test failures left after fixing that NPE:. ```; Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.walkers.GnarlyGenotyperIntegrationTest > testUsingGenomicsDB[2]([Ljava.io.File;@2b20e8a, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GnarlyGenotyper/twoSampleAS.vcf, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GnarlyGenotyper/twoSampleASDB.vcf, [20:1-2147483647], [], /gatkCloneMountPoint/src/test/resources/large/human_g1k_v37.20.21.fasta) [31mFAILED[39m[0K. java.lang.IllegalStateException: Something went wrong: [0K. at org.broadinstitute.hellbender.tools.walkers.gnarlyGenotyper.GnarlyGenotyperEngine.finalizeGenotype(GnarlyGenotyperEngine.java:131). at org.broadinstitute.hellbender.tools.walkers.gnarlyGenotyper.GnarlyGenotyper.apply(GnarlyGenotyper.java:287). at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104). at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.Iterator.forEachRemaining(Iterator.java:116). at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801). at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482). at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472). at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151). at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174). at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234). at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418). at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102). at or",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6079#issuecomment-539518973:46,integrat,integration,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6079#issuecomment-539518973,1,['integrat'],['integration']
Integrability,"@ldgauthier this finishes what we started in #4858 and is necessary for the pileup-calls-on-bamouts MC3 validation. The cause is the same, in that Pair-HMM has a tiny bias in favor of shorter haplotypes and thus it prefers deletion haplotypes when reads end inside STRs. In #4858 we broke near-ties in favor of the reference; this PR fixes the case where two alt haplotypes share a SNV and one of them has a spurious deletion. One important sanity check was that when I set `cigarTerm` to zero in `AssemblyBasedCallerUtils.java` no tests broke. This means that the refactoring needed to set up the change didn't affect behavior. I looked at most of the sites where `PL`s and/or `DP`s changed in the integration test vcfs and in every case the difference was from a fake deletion that this PR fixed. I also went through the diff of the bamouts in IGV and found the same thing. Finally, the changes to test vcfs in `GenotypeGVCFsIntegrationTest` and `GenomicsDBImporterIntegrationTest` are a consequence of changes to the `HaplotypeCallerIntegrationTest` vcfs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5359:699,integrat,integration,699,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5359,1,['integrat'],['integration']
Integrability,"@lessdata In many cases we need to rely on the file extensions to check the file format, because actually opening the files and reading the first few bytes to determine the format gets expensive when the files are hosted in the cloud and there are many VCFs. I do agree that this error message could be improved, however -- it should mention the file extensions that are allowed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7691#issuecomment-1049130908:286,message,message,286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7691#issuecomment-1049130908,1,['message'],['message']
Integrability,"@louisb I did wind up making the docgen and wdlgen and tab completion integration tests non-docker only, since they're failing when run on the docker. The tasks themselves seem to be working fine - these tests are really just here to do a quick smoke test, and to make it easy to debug issues in case of a failure. I suspect the failures are related to the way we run the tests on the docker using the 3 separate jars. So for now I made them non-docker only.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1448991698:70,integrat,integration,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1448991698,1,['integrat'],['integration']
Integrability,"@lucidtronix @mbabadi @samuelklee I think the best solution would be to establish a single, common Python environment, with a single set of dependencies, that all GATK Python tools depend on. We would establish a single docker image that has all of these dependencies pip installed, and could also include a conda env for the GATK environment for users who don't want to use the docker image. If we could do that, it would eliminate the need load per-tool conda environments. From what I've seen so far based on existing branches, the two environments we need (gCNV and CNN-VQSR) don't look that far apart in terms of dependencies. gCNV is using Theano, and CNN Tensorflow, but the rest looks [pretty close](https://docs.google.com/a/broadinstitute.org/spreadsheets/d/1RV7--uBQ0ctlXzMH09cmr0VimpZYIU68DdxJzE60y-c/edit?usp=sharing). So a strawman proposal for the main components for a common environment would be:. Python 3.6; Numpy >= 1.13.1; Scipy 1.0.0; Theano .0.9.0; Tensorflow 1.4.0; Pymc3 3.1; Keras 2.1.1. Can you all chime on on whether you think we can converge in a single environment ? If so, it would greatly simplify things, and we can start with getting a docker image built for running travis tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-348188451:140,depend,dependencies,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-348188451,4,['depend'],"['depend', 'dependencies']"
Integrability,"@lucidtronix @mbabadi Update on this: There is a branch [here](https://github.com/broadinstitute/gatk/commits/cn_python_environment) that updates the docker image that we build on travis to include a full anaconda installation. That may be overkill in the long run but for now gives us a base environment for running integration tests on Travis. The environment managers I've looked at (conda and virtualenv) both appear to work by activating a shell environment. Ideally, we wouldn't need an intermediate shell between the Java code and the Python code, but thats still TBD. In parallel, I'm working on a streaming I/O solution for using input/output streams over standard I/O as the next incarnation of the PythonScriptExecutor for https://github.com/broadinstitute/gatk/issues/3698.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-340804405:317,integrat,integration,317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-340804405,1,['integrat'],['integration']
Integrability,"@lucidtronix Agreed -- provided that there's a fallback conda environment that users without AVX can use, and provided that the tool produces an easy-to-understand error message when AVX is not present, pointing the user to that fallback environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-428273650:170,message,message,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-428273650,1,['message'],['message']
Integrability,"@lucidtronix Based on the response we got from Intel, I tried upgrading to TF 1.15, but there are a cascade of downstream issues. The version of openssl we use conflicts (not sure what thats used for, but for now I removed the explicit dependency from the conda env); next was numpy, which I upgraded to 1.16; followed by what appear to be keras import issues. The branch with the 3 commits is [here](https://github.com/broadinstitute/gatk/tree/cn_update_tensorflow), and the most recent Travis results (with the keras issue) [here](https://travis-ci.com/broadinstitute/gatk/builds/144056822). Can you take a look ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6307#issuecomment-573878340:236,depend,dependency,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6307#issuecomment-573878340,1,['depend'],['dependency']
Integrability,"@lucidtronix Does the above outlined proposal for establishing a common environment work for you ? I think there are a bunch of other dependencies we need to include for one or the other of the tools, but I think this lists the common ones (plus Theano/Tensorflow).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-348528188:134,depend,dependencies,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-348528188,1,['depend'],['dependencies']
Integrability,"@lucidtronix Have you looked at the conda env defined in this branch ? The .yml file here is based in part on dependencies I took from your conda env (minus the actual VQSR-CNN package, since we want our travis tests to run on the code and env defined in the GATK source repo - see comment above), but I haven't actually tried running your code with it yet. I want to make sure we're converging on a unified conda env.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350307336:110,depend,dependencies,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350307336,1,['depend'],['dependencies']
Integrability,"@lucidtronix Hi Sam, wonder if you could take a look at this? Adding the ""AVX required"" message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-427873520:88,message,message,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-427873520,1,['message'],['message']
Integrability,@lucidtronix Probably something's up with my configuration...; `; $ gcc -v; Using built-in specs.; COLLECT_GCC=gcc; COLLECT_LTO_WRAPPER=/Users/markw/anaconda/envs/py27/bin/../libexec/gcc/x86_64-apple-darwin11.4.2/4.8.5/lto-wrapper; Target: x86_64-apple-darwin11.4.2; Configured with: ./configure --prefix=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --with-gxx-include-dir=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/gcc/include/c++ --bindir=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/bin --datarootdir=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/share --libdir=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/lib --with-gmp=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --with-mpfr=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_147764901285,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391065177:223,wrap,wrapper,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391065177,1,['wrap'],['wrapper']
Integrability,"@magicDGS . I am afraid this is not easy. I didn't write the binding (@tedsharpe did), but I would asseme the limitation comes from bwa mem itself, not the binding, as the binding is a thin wrapper that delegates the loading of the index files (or the image that combines all 5 index files in this case) to bwa. . The SV team here have a script (`scripts/sv/default_init.sh`) that when the Spark cluster is created and initialized, the image file is distributed to all walker nodes. Spark clusters other than Google's Dataproc would probably allow you to provide scripts as initialization actions as well. On the other hand, there seem to be a `--files` argument that you can append to your cmd line arguments which yarn will parse and distribute the provided local file to all nodes, though in this case it will be very inefficient considering the image file's size.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312362074:190,wrap,wrapper,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312362074,1,['wrap'],['wrapper']
Integrability,"@magicDGS A method like this should probably go into the base CommandLinePluginDescriptor class in Barclay first. . Having said that, I'm going to close this issue here, since I've recently added a new method in Barclay called [getDefaultInstances](https://github.com/broadinstitute/barclay/blob/976fafea23216cf0577b8e3fe635b115c7975a76/src/main/java/org/broadinstitute/barclay/argparser/CommandLinePluginDescriptor.java#L170) (not available until GATK upgrades, which I think will be soon). That, in combination with getAllInstances, might be sufficient for what you need. If not, please propose the new method in Barclay (or reopen this one here if I'm missing something). Either way, I think your original point about getAllInstances is valid, since the name doesn't reflect the contract, but for that I think we should just change the name of it in Barclay to something like ""getUserInstances"" to reflects what it actually does.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2362#issuecomment-275688356:782,contract,contract,782,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2362#issuecomment-275688356,1,['contract'],['contract']
Integrability,"@magicDGS After much thought I believe that the code we discussed belongs in your code, not in the GATK. Here's an outline of some static methods that should meet your needs:. ``` java; public class DGSUtils {; @FunctionalInterface; private interface LikelihoodFunction {; double apply(final Allele allele, final GATKRead read);; }. private static Allele createAllele(final PileupElement e, final byte refBase, final Allele refAllele) {; return e.isDeletion() ? Allele.SPAN_DEL : (e.getBase() == refBase ? refAllele : Allele.create(e.getBase()));; }. public static ReadLikelihoods<Allele> likelihoodsFromPileup(final ReadPileup pileup,; final Allele refAllele,; final SAMFileHeader header) {; final Map<String, List<GATKRead>> readsBySample = pileup.getReads().stream(); .collect(Collectors.groupingBy(read -> ReadUtils.getSampleName(read, header)));. final byte refBase = refAllele.getBases()[0];; final Set<Allele> alleleSet = new TreeSet<>();; pileup.forEach(e -> alleleSet.add(createAllele(e, refBase, refAllele)));. return new ReadLikelihoods<>(new IndexedSampleList(readsBySample.keySet()), new IndexedAlleleList<>(alleleSet), readsBySample);. }. public static void setLikelihoods(final ReadLikelihoods<Allele> likelihoods, final LikelihoodFunction likelihoodFunction) {; final int numAlleles = likelihoods.numberOfAlleles();; for (int sample = 0; sample < likelihoods.numberOfSamples(); sample++) {; final LikelihoodMatrix<Allele> matrix = likelihoods.sampleMatrix(sample);; final int numReads = matrix.numberOfReads();; for (int alleleIndex = 0; alleleIndex < numAlleles; alleleIndex++) {; final Allele allele = likelihoods.getAllele(alleleIndex);; for (int readIndex = 0; readIndex < numReads; readIndex++) {; final GATKRead read = matrix.getRead(readIndex);; matrix.set(alleleIndex, readIndex, likelihoodFunction.apply(allele, read));; }; }; }; }; }; ```. This lets you compute likelihoods with an arbitrary function of the read and the allele. In your toy example you would call it as:. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-253623925:241,interface,interface,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-253623925,1,['interface'],['interface']
Integrability,"@magicDGS Can you move the make*Transformer methods up to GATKTool (at some point we'll have a plugin at that level), and then also integrate these with AssemblyRegionWalker ? We'll want to do the Spark tools as well, but we leave that for a separate PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-289924338:132,integrat,integrate,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-289924338,1,['integrat'],['integrate']
Integrability,"@magicDGS I could certainly do that (split out an OptionalReadFilterArgumentCollection), though we'd then need to add a ""requiresReadFilters"" method to determine which to use. I guess it depends on how common that case would be. An simple alternative would be to just override makeReadFilter and reject any command line filter requests or do any custom filter handling.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1900#issuecomment-225997121:187,depend,depends,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1900#issuecomment-225997121,1,['depend'],['depends']
Integrability,"@magicDGS I don't expect we'll get to this for a while, at a minimum it will not be until after the beta milestone. The dependent changes referenced above are still under development.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-300189558:120,depend,dependent,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-300189558,1,['depend'],['dependent']
