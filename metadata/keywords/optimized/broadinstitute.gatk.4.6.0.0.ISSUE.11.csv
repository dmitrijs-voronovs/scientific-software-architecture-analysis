quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Integrability,Sweet! and LGTM!; You will need to redo this with every repo that depends on Hellbender.; @tomwhite let us know if this doesn't work for you.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/801#issuecomment-130347765:66,depend,depends,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/801#issuecomment-130347765,1,['depend'],['depends']
Integrability,Switch Spark dependency to 2.0.2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2294:13,depend,dependency,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2294,1,['depend'],['dependency']
Integrability,Switch to OneShotLogger for logging this message,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3828:41,message,message,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3828,1,['message'],['message']
Integrability,Sync up Hadoop-BAM and htsjdk dependencies,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2742:30,depend,dependencies,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2742,1,['depend'],['dependencies']
Integrability,"Sync uses the system call fsync() to synchronize contents and not sure how CIFS is erroring out. Please see my [previous comment](https://github.com/broadinstitute/gatk/issues/5342#issuecomment-433760934). Would it be possible to gather some more information using the gatk from [branch nalini_issue_5342](https://github.com/broadinstitute/gatk/tree/nalini_issue_5342)? This branch puts out additional information with errno, etc. One thing that can be done, is make an error return from the fsync() call non-fatal as it does not seem to be well supported for CIFS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5342#issuecomment-453695003:37,synchroniz,synchronize,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5342#issuecomment-453695003,1,['synchroniz'],['synchronize']
Integrability,Synchronize update of shared genotype likelihood tables.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5071:0,Synchroniz,Synchronize,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5071,1,['Synchroniz'],['Synchronize']
Integrability,"TGAG...TGTCGGTATG; 10:51:06.940 INFO PrintReads - Shutting down engine; [October 2, 2017 10:51:06 AM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 2.45 minutes.; Runtime.totalMemory()=5995233280; htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248574592, span 197316, expected MD5 cc8ace0545facc11349da783af07a076; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:601); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.hasNext(SAMRecordToReadIterator.java:24); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:779); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); 	at org.broadinstitute.hellbe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828:2073,wrap,wrapAndCopyInto,2073,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828,1,['wrap'],['wrapAndCopyInto']
Integrability,"TID 680, dataflow05.broadinstitute.org): java.lang.IllegalArgumentException: ; Invalid interval. Contig:20 start:62720124 end:62720123; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:34); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:46); at org.broadinstitute.hellbender.engine.spark.BroadcastJoinReadsWithVariants.lambda$join$3d1c3858$1(BroadcastJoinReadsWithVariants.java:27); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:30); at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.lambda$apply$26a6df3e$1(BaseRecalibratorSparkFn.java:28); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:156); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:156); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:706); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:706); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297); at org.apache.spark.rdd.RDD.iterator(RDD.scala:264); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297); at org.apache.spark.rdd.RDD.iterator(RDD.scala:264); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apac",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1560:1304,Wrap,Wrappers,1304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1560,1,['Wrap'],['Wrappers']
Integrability,"TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),37.44650732699998,Cpu time(s),37.414083634000015; [November 21, 2019 2:29:29 PM UTC] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 0.92 minutes.; Runtime.totalMemory()=1783103488; htsjdk.tribble.TribbleException: Invalid block size -1539959833; at htsjdk.variant.bcf2.BCF2Decoder.readNextBlock(BCF2Decoder.java:66); at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:134); at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:58); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:181); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:49); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275:1843,wrap,wrapAndCopyInto,1843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275,1,['wrap'],['wrapAndCopyInto']
Integrability,"TargetCodec is dependent on the old htsjdk indexing scheme whereby the indexer called readActualHeader on the codec first (for the side effect of initializing the codec header state), and then manually processed the feature file contents by:. - re-creating the input SOURCE/stream a second time; - NOT calling readActualHeader; - extracting and passing the features one at a time to the codec's decode method, using the stream position to find the feature file offsets. Although this scheme worked with TargetCodec, it had several other failure modes (see https://github.com/samtools/htsjdk/pull/906). With https://github.com/samtools/htsjdk/pull/906, the SOURCE/stream is only opened once for indexing. However, TargetCodec uses an underlying CSVReader that automatically buffers input, which confounds the indexer. This PR works around that issue for indexing. Note: this won't compile until there is an htsjdk snapshot available with https://github.com/samtools/htsjdk/pull/906.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3403:15,depend,dependent,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3403,1,['depend'],['dependent']
Integrability,Tensorflow dependency,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6369:11,depend,dependency,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6369,1,['depend'],['dependency']
Integrability,Test for presence of ack result message and simplify ProcessControllerAckResult API,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7816:32,message,message,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7816,1,['message'],['message']
Integrability,Test run with `load_data_scatter_width` set: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/f10f47ab-8b5b-428a-b418-c9dc9f9c3a58; Test run with `load_data_scatter_width` not set: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/5bf5fe73-10d6-4df2-a5df-3f793c25ebde; integration run: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/84f14232-dc62-4ce5-8031-7840f7f2aedc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8985:348,integrat,integration,348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8985,1,['integrat'],['integration']
Integrability,"Testing branch `ck_3487_port_LeftAlignAndTrimVariants`, which ports LeftAlignAndTrimVariants from GATK3 to GATK4. ### stdout; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 IN",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:333,wrap,wrapper,333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494,1,['wrap'],['wrapper']
Integrability,"Testing updated branch with improved messaging.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:265,wrap,wrapper,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326,1,['wrap'],['wrapper']
Integrability,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:129,depend,dependencies,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367,2,['depend'],['dependencies']
Integrability,"Thank you @SHuang-Broad. The error was gone after I copied bwaindeximage file to lustre file system, which can be accessed by all worker nodes.; The new problem is: the program started but didn't give any informative message/progress (see log below). It was stopped (Ctl-C) after 16 hours. The sequence data is regular human exome, which could be mapped in 1-2 hours in our traditional pipeline. ```; ../gatk/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; -I hdfs://ln16/user/myname/NA12878/wes/NA12878-NGv3-LAB1360-A.unaligned.bam ; -O hdfs://ln16/user/myname/gatk4test/BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://ln16/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /TEST/hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=720 ; --executor-cores 20 ; --executor-memory 50g ; --conf spark.driver.memory=50g; Using GATK jar /home/myname/gatk4/gatk/build/libs/gatk-package-4.alpha.2-1125-g27b5190-SNAPSHOT-spark.jar; Running:; /opt/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --master spark://ln16:7077 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOption; s=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.di$able=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --conf spark.cores.max=720 --executor-cores 20 --executor-memory 50g --conf spark.driver.memory=50g /home/myname/gatk4/gatk$build/libs/gatk",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:217,message,message,217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['message'],['message']
Integrability,Thank you @jamesemery! As a first pass at the integration tests we should make sure that the output files actually validate with Picard's ValidateSamFile tool. I can help with that if you have the files. Also we should look at some of the output manually. Can you point me to a location that has the new output files?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2021#issuecomment-233786535:46,integrat,integration,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2021#issuecomment-233786535,1,['integrat'],['integration']
Integrability,"Thank you @kshakir. What I see there is that the code sets the default NIO option, and as part of this is creates a google cloud `StorageOptions` object. Sadly for us, when this object is created it determines which Google credentials to use, and if nothing was specified by the user it will send some network messages to try to figure out whether it's running on a Google Compute Engine machine. When we wrote the default-setting code we didn't realize that setting the number of retries was going to cause a network message to be sent, with the associated potential retries and delays. We can't change the way Google Compute Engine works, or how the Google authentication works either. Ideally we'd want some way to only search for credentials when we know NIO is going to be used. The point of these defaults is that they're used for anything that uses NIO, including third-party library code. We can't fully replicate this behavior in a different way from the outside. So I think the ""correct"" fix would be to go deep inside the Google NIO library and change it so that instead of providing a default configuration (that the user would have to put together, causing the problem you've seen), we can provide a *callback* that sets the configuration when the Google Cloud NIO provider is loaded. This is harder for future developers to wrap their heads around, but at least it would prevent this delay if NIO is not used. I'd like to think about this some more before doing something quite this drastic, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504:310,message,messages,310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504,3,"['message', 'wrap']","['message', 'messages', 'wrap']"
Integrability,Thank you @lbergelson for the fix! For once a dependency conflict that turns out to be simple!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-841279259:46,depend,dependency,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-841279259,1,['depend'],['dependency']
Integrability,"Thank you @mehrzads for your contribution. It would appear that this optimization is aimed to incorporate the knowledge that we could never possibly visit a given vertex more than K times in the first K best paths. Since the graphs are prone to exponential expansion of paths this seems like an important safeguard against this exponential expansion of the graph. . Looking at the code and the algorithm behavior it is intending to copy I see that there is a degenerate case in the current code that can cause the results to be order dependent. My belief is that this code can fall over by virtue of the fact that we refuse to make new incoming edges to a given vertex if there are already too many incoming edges for that vertex. Unfortunately this heuristic doesn't strike me as being valid, because those incoming edges can have any weight, including very high weights because they are bad paths through the graph that we created at a previous step. . I think a more correct optimization would be to limit the number of edges we create LEAVING a given vertex. The logic for this is that while we may not necessarily see all of the incoming edges in the correct weight order we will necessarily see all of the leaving edges in the correct order because those paths are pulled off of the priority queue in the correct order. Thus we can safely ignore any additional paths we see leaving a given edge because by construction as they would necessarily have at least one path that is cheaper than all of the paths leaving the current node.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417:534,depend,dependent,534,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417,1,['depend'],['dependent']
Integrability,"Thank you @mwalker174 . The input bamfile is about 7 GB. If no `--bamPartitionSize` is specified, the job would stuck at the first step `collect at ReadsSparkSource.java:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:276,interface,interface,276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['interface'],['interface']
Integrability,"Thank you @vruano for your diligent review. I've implemented logger classes to encapsulate the metrics classes. Unfortunately the metrics classes must remain public in order to write output using `MetricsUtils.saveMetrics()`, but at least the tools aren't using them directly. There are two logging class groups - one for Filter and one Score. For Filter, there is an interface `PSFilterLogger` that is implemented by a file-logging class `PSFilterFileLogger` and a dummy class `PSFilterEmptyLogger` that does nothing. There are analogous classes for Score, but there is no Empty logger because it's not actually necessary. This adds a lot of new classes (maybe you can think of a better way) but usage has been greatly simplified. As we discussed in person, I don't think there is a faster way to count the reads in Spark. If you wanted to count the reads as they pass through, you would have to use some kind of atomic type that would be slow. Also it may be impossible to account for cases when tasks fail and restart. @lbergelson @droazen In this PR, I wanted to use htsjdk's MetricsFile and MetricBase classes for writing metrics to a file. I notice that these classes are mostly used for picard-related things. Is this the preferred way to do things? They do force you to expose public variables and also use an upper-case naming convention. On the other hand, they are somewhat convenient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160:368,interface,interface,368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160,1,['interface'],['interface']
Integrability,Thank you for all the work on GATK4 and for including a wrapper script to help in setting up Java options. I've included GATK4 in bioconda (https://anaconda.org/bioconda/gatk4) with the `gatk-launch` wrapper and wanted a way to be able to pass java options to the local run. This PR uses the `GATK_JVM_OPTS` environmental variable to pass Java options like memory specification to the gatk-launch script. Thanks for considering this change,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2778:56,wrap,wrapper,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2778,2,['wrap'],['wrapper']
Integrability,"Thank you for fast reply. @python from the same shell where you activated the conda env, and see if the command import gatktool succeeds. Yes, this works well. but when I run the command below and submit the job to HPC ;. conda activate gatk4 ; gatk CNNScoreVariants -V 21002.HaplotypeCaller.output.g.vcf.gz -R hg19.fa -O annotated.vcf. same error happened. another point is that when I run the command (gatk CNNScoreVariants -V 21002.HaplotypeCaller.output.g.vcf.gz -R hg19.fa -O annotated.vcf) without HPC by setting memory as qlogin -l s_vmem=16G -l mem_req=16G. it produces this:. Runtime.totalMemory()=2132803584; org.broadinstitute.hellbender.exceptions.GATKException: Exception waiting for ack from Python: org.broadinstitute.hellbender.exceptions.GATKException: Expected message of length 3 but only found 0 bytes; 	at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.waitForAck(StreamingProcessController.java:233); 	at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.waitForAck(StreamingPythonScriptExecutor.java:216); 	at org.broadinstitute.hellbender.utils.python.StreamingPythonScriptExecutor.waitForPreviousBatchCompletion(StreamingPythonScriptExecutor.java:293); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.sendBatchIfReady(CNNScoreVariants.java:416); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.firstPassApply(CNNScoreVariants.java:336); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:17); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemain",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147:779,message,message,779,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147,1,['message'],['message']
Integrability,"Thank you for the information information. That hardware seems pretty; standard. I wouldn't expect it to be causing this issue. On Wed, Jan 5, 2022, 7:08 PM greekkey ***@***.***> wrote:. > @lbergelson <https://github.com/lbergelson> OK. I will try the new; > version with my previous data as well as some new data later.; >; > My OS is Ubuntu 20.04.3 LTS 64-bit, GNOME version is 3.36.8. The major; > hardware info are Intel® Core™ i7-4770 CPU @ 3.40GHz × 8 , Intel® HD; > Graphics 4600 (HSW GT2), (memory) 31.3 GiB, (local HDD) 1.1 TB.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/7614#issuecomment-1006176609>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABD3RLBDEWS2JXL6P7G3YSDUUTMRJANCNFSM5KNXHR6A>; > .; > Triage notifications on the go with GitHub Mobile for iOS; > <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; > or Android; > <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.; >; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7614#issuecomment-1006183455:1182,Message,Message,1182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7614#issuecomment-1006183455,1,['Message'],['Message']
Integrability,"Thank you for your review, @vruano ! I addressed each of your comments. In the process, I discovered a bug in an integration test that needed fixing, which is added as another commit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3537#issuecomment-329907772:113,integrat,integration,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3537#issuecomment-329907772,1,['integrat'],['integration']
Integrability,Thank you very much！------------------&nbsp;原始邮件&nbsp;------------------; 发件人:&nbsp;&quot;Louis&amp;nbsp;Bergelson&quot;<notifications@github.com&gt;; 发送时间:&nbsp;2020年8月28日(星期五) 凌晨2:26; 收件人:&nbsp;&quot;broadinstitute/gatk&quot;<gatk@noreply.github.com&gt;;; 抄送:&nbsp;&quot;duanshumeng&quot;<2315440517@qq.com&gt;;&quot;Mention&quot;<mention@noreply.github.com&gt;;; 主题:&nbsp;Re: [broadinstitute/gatk] MESSAGE: Writing failed because there is no space left on the disk or hard drive. Please make some space or specify a different location for writing output files (#6772),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6772#issuecomment-683239624:401,MESSAGE,MESSAGE,401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6772#issuecomment-683239624,1,['MESSAGE'],['MESSAGE']
Integrability,"Thank you, sir. In fact , firstly I called SNP from both parents respectively, and then combined both parents vcf files to a integrate vcf file, I want to get maternal different homozygous SNP compare to reference genome and paternal different homozygous SNP compare to reference genome, and combined both parents SNPs to a integrate biSNP.vcf file ,and then filtered heterozygote sites. Finally I submited this integrate biSNP.vcf as a input file of argument ""sites"" of GATK-3.8 ASEReaderCounter, l got normal output file of ASE reads count. But if I used argument ""variants"" of GATK-4.0 to replace ""sites"" argument of GATK-3.8, other files were not changed, it reminded me that ""the SNP site of inupt file is not het"" , so I got null result file in the end,because l filtered integrate vcf file, all SNP sites of different parents are homozygote compare to reference genome. So l want to know what kind of vcf file can be used as input file of ""variants"" argument of GATK-4.0 ASEReadCounter ? both parents g.vcf files ? Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7747#issuecomment-1084770372:125,integrat,integrate,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7747#issuecomment-1084770372,4,['integrat'],['integrate']
Integrability,"Thanks @cmnbroad - I just propose a super-fine grained scheme, but it can be a different one. I would like that for easier development using GATK4 for downstream projects, but by now I am fine with all dependencies generating quite a big jar, but I can live with it until this happen...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3900#issuecomment-348965479:202,depend,dependencies,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900#issuecomment-348965479,1,['depend'],['dependencies']
Integrability,"Thanks @davidbenjamin. . For what it is worth, here are some of my thoughts. From my perspective, it might helpful to separate the discussion into read likelihood calculation and the genotype likelihood calculation. As I understand it, sequencing error is directly relevant to the pairHMM read likelihood calculation. I guess the location where PCR error is most relevant (read likelihood vs genotype likelihood) would depend on whether the read likelihood is computing a ""fragment likelihood"" (the likely DNA sequence of the fragment being sequenced) or a ""haplotype likelihood"" (the likely source haplotype for the fragment being sequenced). In any case, as I see it, this particular issue could be interpreted as a shortcoming in only the HaplotypeCaller genotype likelihood calculation, and it would essentially be an issue of double counting. So I'm not sure that a quick fix for this issue is necessarily off the table...Maybe something like one of the following could be used just before or during the genotype likelihood calculation:; - something like `filterOverlappingReads` from Mutect2 (https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java#L326); - separate consideration of overlapping reads when calculating genotype likelihoods, as used in UnifiedGenotyper (https://github.com/broadgsa/gatk-protected/blob/aa8764d6c3de146856b174a8674fa787a6311d7c/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/genotyper/DiploidSNPGenotypeLikelihoods.java#L183). As I see it, #4958, which seems to be more related to read likelihood calculation, is where a more involved solution, with more fundamental changes, might be warranted. From my perspective (not being especially familiar with the pairHMM model), an ideal solution would transition the pairHMM from read likelihood to a ""fragment likelihood"" or ""haplotype likelihood"" when information from read pairs is available,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5436#issuecomment-443558420:419,depend,depend,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5436#issuecomment-443558420,1,['depend'],['depend']
Integrability,"Thanks @droazen & @ldgauthier. I can certainly run a bunch more iterations of the same HC run on the same data. I'm not super hopeful it will turn anything up though. I can also try selecting a bunch of the different PairHMM implementations. I can't share too much, but this issue turned up in a very high throughput (1000s of samples a day) clinical pipeline. We're going back and looking for other instances where we see an excess of that `Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null` message, and re-running those samples to see if, on re-run, they generate different outputs. I realize the AVX-specific hardware issue is perhaps a little far-fetched, though given the volume of the pipeline and the fact that it runs in a cloud environment, I think it's entirely reasonable to suspect we'll run into hardware/instance issues occasionally. And there are AVX or at least SIMD specific registers, so if one of those were to see problems that could cause the PairHMM issues, without causing issues in other software that doesn't leverage the SIMD/AVX instructions. My main question really is this: is anyone familiar enough with the Intel PairHMM implementation and interface that they could weigh in on whether or not unexpected hardware errors could result in the return of empty likelihoods from the PairHMM instead of some kind of error, exception or segfault?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6889#issuecomment-709555915:532,message,message,532,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889#issuecomment-709555915,2,"['interface', 'message']","['interface', 'message']"
Integrability,"Thanks @droazen,; Additionally the dockstore integration App will need to be added this repo (as mentioned [here](https://docs.dockstore.org/en/develop/getting-started/dockstore-workflows.html#registration-with-github-apps)). . For example: ; ![Screen Shot 2020-10-14 at 11 11 04](https://user-images.githubusercontent.com/14318238/96010590-f6a15a80-0e0f-11eb-80e2-68568c18d8df.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6770#issuecomment-708478858:45,integrat,integration,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6770#issuecomment-708478858,1,['integrat'],['integration']
Integrability,"Thanks @droazen. Because you assigned it to me, I would like to know a couple of details on how this should be implemented in GATK4:. * GATK3 use to have a the `MisencodedBaseQualityReadTransformer` always on, with a switch for checking/fixing the qualities. If we follow this approach in GATK, the only change for this is to include the checking step every n reads and then #2160 will do the rest. Nevertheles, I think that it's quite dangerous to allow an user to disable it with the plugin (because the name suggest that it is only fixing the qualities), so I suggest to integrate in the read data source an iterator for checking every x reads if the qualities are misencoded, independently on the transformer.; * GATK3 throws an UserException for ""putatively misencoded"" qualities, using 60 as maximum base quality for throwing. I think that in the case of GATK4 could be more useful to use a warning if it is over 60 (I do not know what is the reasoning behind this value), and use `SAMUtils.MAX_PHRED_SCORE` for throwing. I'd be happy to implement this if there is a consensus about what to do here, so I'll wait for your ideas...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2082#issuecomment-288760814:574,integrat,integrate,574,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2082#issuecomment-288760814,1,['integrat'],['integrate']
Integrability,"Thanks @kdatta. The branch builds now, but there are a couple of problems that cause several tests to fail, including some existing tests that used to pass. You can see the results [here](https://travis-ci.org/broadinstitute/gatk/jobs/221534229). - The main issue is that GenomicsDB fails to load. This causes the importer tests to fail, as well as the existing GenomicsDB integration tests. (Note that the importer tests fail with a null pointer exception, but that problem is secondary and only happens when the db fails to load, which is the root problem.) We can fix the NPE in code review, for now the main issue is fix the core problem of why genomics db fails to load. - The changes in OptionalVariantInputArgumentCollection and RequiredVariantInputArgumentCollection are causing argument name collisions in other tools, which is why ExampleIntervalWalkerIntegrationTest tests are failing in this branch. The simplest fix in the short term is to just revert the changes you made to those two classes, and remove the new VariantInputArgumentCollection class. These aren't being used by the importer tool anyway. It should be pretty easy to reproduce load issue, it happens on my laptop and and travis, but let me know if you need help or have questions about any of this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294148791:373,integrat,integration,373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294148791,1,['integrat'],['integration']
Integrability,"Thanks @lbergelson! I agree that it might be good to break into more layers—could be worth talking to SV team and seeing what lessons they learned in putting together their hierarchy of images. Also, note that I pushed the install of miniconda into the base, but I did not push down the setup of the GATK conda environment itself (which takes the bulk of the time during the main-image build, as it requires lots of downloading). I think I commented elsewhere that a good strategy might be to set up the conda environment with the non-GATK python dependencies in the base, and then update the environment via a pip install of the GATK python packages in the main image. This would let us make python code changes without having to rebuild the base, but might require a bit of scripting to create a final yml for non-Docker users. I also agree that it would be nice to cut down the Travis time, might be worth taking a look at other strategies to do that—could save everyone a lot of time!. Will try to add the test you suggested sometime tomorrow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-621487662:547,depend,dependencies,547,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-621487662,1,['depend'],['dependencies']
Integrability,"Thanks @lbergelson. I try to not depend on this, but when we're developing tools that rely on a GATK feature not yet in a release (like i'm trying to do here), it's quite useful to have those snapshots.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8138#issuecomment-1370160247:33,depend,depend,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8138#issuecomment-1370160247,1,['depend'],['depend']
Integrability,"Thanks @mwalker174, back to you! Might need some more work depending on what you decide.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5699#issuecomment-471799446:59,depend,depending,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5699#issuecomment-471799446,1,['depend'],['depending']
Integrability,"Thanks @samuelklee , I will incorporate your conda update into this branch, now that we've dealt with the test failures!. I patched the VETS test code to include the h5diff (and diff) output in the exception messages when one of these commands fails, and switched to the existing `BaseTest` methods for running the process and capturing the output. You can see what the output looks like (when we remove the epsilon tolerance) here:. https://storage.googleapis.com/hellbender-test-logs/build_reports/8610/merge_7165443572.3/tests/testOnPackagedReleaseJar/classes/org.broadinstitute.hellbender.tools.walkers.vqsr.scalable.ScoreVariantAnnotationsIntegrationTest.html. https://storage.googleapis.com/hellbender-test-logs/build_reports/8610/merge_7165443572.3/tests/testOnPackagedReleaseJar/classes/org.broadinstitute.hellbender.tools.walkers.vqsr.scalable.TrainVariantAnnotationsModelIntegrationTest.html. As you suspected/hoped, all the differences were tiny. When you have a chance, could you please review these changes to the VETS tests and let me know if you spot any issues?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8610#issuecomment-1850563977:208,message,messages,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8610#issuecomment-1850563977,1,['message'],['messages']
Integrability,"Thanks @samuelklee! I don't think 5 is strictly necessary, since we should be able to use VariantFiltration with a hard filter of a VQSLOD threshold right? Or are you saying that ScoreVariantAnnotations is the tool that needs to convert between LL/sensitivity and VQSLOD cutoff? . I'm happy to work on the WDL, do most of the tools on this branch have integration tests? That's where I'll start grabbing commands.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069187834:352,integrat,integration,352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069187834,1,['integrat'],['integration']
Integrability,"Thanks a lot @davidbenjamin ; In the meantime I have compiled the master branch when I saw this issue was resolved and it worked fine. I tried also to create a pon with this fresh compiled version but I got some errors (don't remember exactly what right now). Looks like you are in the middle of changing the pipeline of pon creation by integrating GenomicsDB as an intermediate, right ? Do you think it will also be ready for this next release ? I would like to create the pon with the same GATK version. Problem is I can not fall back on an earlier version because I would definitely get the bug we are talking about in this thread :-). Perhaps we should also change our computing nodes at some point I guess :). Thanks again",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216:337,integrat,integrating,337,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216,1,['integrat'],['integrating']
Integrability,"Thanks a lot for looking into this @sooheelee - I understand the pain of making the small data for the tests, so I really appreciate your work there. I have almost prepare a PR for the new port of `RealignerTargetCreator` that will have TODOs for the test data prepared by you, and with some tests using files already in the repository (for the target-creator, I guess that the validation for getting the regions to realign would be enough, because thanks to that tests I realized of a small bug due to not including all the loci in the `LocusWalker`). On the other hand, I will still fight for the `--nWayOut` not blocking the inclusion of `IndelRealigner` in the first place. My reasons are the following:; ; 1. Looking a bit into the code of GATK3, there is a lot of complication to get the reader ID for each read. It will require to modify the `GATKRead` interface, the data source for reads, or find an *ad hoc* solution on `IndelRealignment` to set the procedence of the read. This requires going into the engine-level code, which in my experience is difficult to port from GATK3 and also slow on the reviewing/acceptance process.; 1. My idea for developing a new writer of general use as the n-way output (which can be used in other tools as well) is to factor out some code from `SplitReads` to have a custom `GATKReadWriter` for arbitrary splitting. i'm already using a similar solution on `ReadTools`, so backporting the code to GATK might be a solution. Nevertheless, this still requires that the `GATKRead` has somehow the identity store at the object level, which requires to address point 1.; 1. The use case of the tumor-normal pair can be resolved by an extra processing step (split by read group). I understand that it is quite convenient to add this argument, but I would suggest that until it can be develop.; 1. Last, bu quite important for me as a developer, I don't have time to spend looking at that engine-level features required to include that argument. I would definitely u",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231:860,interface,interface,860,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231,1,['interface'],['interface']
Integrability,"Thanks a lot for taking care of this. I met different error this time. I; git clone it from the master. version info: The Genome Analysis Toolkit; (GATK) v4.1.5.0-16-gf1aea57-SNAPSHOT. I ran four samples. All return the same problem when just started the; haplotypecaller. Here is the error message.; [March 17, 2020 1:54:08 PM EDT]; org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller; done. Elapsed time: 1.09 minutes.; Runtime.totalMemory()=4182245376; java.lang.IllegalStateException: Smith-Waterman alignment failure. Cigar =; 64M40D29M with reference length 133 but expecting reference length of 413; ref =; AGCATCCGACAGCCTGGAGCAGCACCCACACCCCCAGTTGAGCAACTGATGGTCTGGAGCAGCACCCACAACCACAGGTGAACATCAGAGAGTCTGGAGCAGCGCCCACAACCCCAGGCGAGCATCTGACAGCCTGGAGCAGTGCCCAAACACCCAGGTGAGCATCTGACAGCATGGAGCAGCACCCATAGCCCAAGGTGAGCATCTGACAACCTGGAGCAGCACCCACACCCCGAGGTGAGCATCTGACCTCCCGGAGCAGGACCCATACCTCCAGGCGAGCATCTGAACCCATGGAGCAGCACCCACGCCCCCAGGCGAGCATCTGACCGAACAGAGCAGCACCCACAACCCCATGCGAGCATCTGTCAGCCTGGAACAGCACCCACAACCCCAGGTGAGCATCTGACAGC; path; AGCATCCGACAGCCTGGAGCAGCACCCACACCCCCAGTTGAGCAACTGATGGTCTGGAGCAGCACCCACAACCCCAGGTGAGCATCTGACAGC. David Benjamin <notifications@github.com> 于2020年3月17日周二 下午12:49写道：. > @phpeters <https://github.com/phpeters> I expect that the fix in #6498; > <https://github.com/broadinstitute/gatk/pull/6498> corrected both leading; > and trailing deletions, but please let us know if it did not.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6490#issuecomment-600179222>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AEORBD6XHZDY2RBOTVNGQODRH6SY3ANCNFSM4LENWAMQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6490#issuecomment-600218205:291,message,message,291,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6490#issuecomment-600218205,1,['message'],['message']
Integrability,"Thanks also for this detailed report, @Stikus! The differences look small to me (mostly in the quals, which are the result of more numerically sensitive calculations), with the discrepant calls primarily being of low quality. Since the gCNV python code depends on native C/C++ code (via numpy, theano, etc.), these sorts of floating-point numerical differences might not be unexpected if there are changes in the underlying system packages or hardware. Unfortunately, we can only guarantee numerical reproducibility to this high degree within our Docker testing environment. Note also the upcoming #8561, which will also introduce changes on this level.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8619#issuecomment-1851935613:253,depend,depends,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8619#issuecomment-1851935613,1,['depend'],['depends']
Integrability,"Thanks for adding this! Incidentally, I noticed a few messages are still emitted by com.github.fommil.jni.JniLoader (which uses a different logger) in CreateReadCountPanelOfNormals when native libraries are loaded by MLlib, but probably more trouble than it's worth to clean those up. Couple of minor comments, looks fine to me but maybe engine team should chime in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5825#issuecomment-475703103:54,message,messages,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5825#issuecomment-475703103,1,['message'],['messages']
Integrability,"Thanks for adding this! Let me discuss further with @mwalker174 to understand the need and typical use cases (e.g., combining fixed-grid bins) to make sure we don't run into any gotchas downstream. I'll try to review by EOD, but in the meantime, you might want to address a few issues I see at first glance:. 1) Correct the name of the tool (PreprocessIntervals) in the commit message and description.; 2) Add descriptions of the new parameters to the tool Javadoc.; 3) Amend the corresponding WDL task and expose the new parameters in all relevant germline and somatic WDLs.; 4) We should be sure to update the relevant documentation for all germline and somatic WDLs, which emphasizes how PreprocessIntervals should be run differently for WES and WGS, if we plan on changing the default behavior of the tool in the future.; 5) Tests are failing due to a compilation warning about a redundant cast to int.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387:377,message,message,377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387,1,['message'],['message']
Integrability,"Thanks for all the help. Using the 4.2.0.0 docker resolved the problem!. On Tue, Mar 23, 2021 at 10:06 AM Chris Norman ***@***.***>; wrote:. > Oh, I missed that they had already tried reindexing. @ahaessly; > <https://github.com/ahaessly> can you find out what tool and what version; > was used to reindex this file ? We've had several reports of this error; > message in the last month or two, but reindexing has usually fixed it. I; > had been assuming that the corrupt index files were created by older; > versions of GATK/Picard tools, but it would super helpful to know if; > current versions of either samtools or GATK/Picard is creating these, and; > will help determine if we need to relax this check.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804930832>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AFO2VRJSHCFOODG56CXSO4TTFCN53ANCNFSM4ZNOBRZQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804963976:361,message,message,361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804963976,1,['message'],['message']
Integrability,"Thanks for bringing this to our attention, @Tintest. I think that we may be able to address this by setting `base_compiledir` via `os.environ[""THEANO_FLAGS""]` appropriately (see http://deeplearning.net/software/theano/library/config.html). @mbabadi @cmnbroad any thoughts? . In any case, thanks for trying out the GermlineCNVCaller pipeline. You may have to tune some parameters, depending on your data type. You may find the following discussions helpful:. https://gatkforums.broadinstitute.org/gatk/discussion/11711/germlinecnvcaller-interval-merging-rule-error. https://github.com/broadinstitute/gatk/issues/4719. Note that we're still in beta, but our preliminary evaluations have demonstrated improved performance over other callers in both WES and WGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-390303432:380,depend,depending,380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-390303432,1,['depend'],['depending']
Integrability,"Thanks for fixing the message! I couldn't track down the original `output.vcf` that caused the issue, and this is ancient enough that I can't even recall the context. However, because the site `1262288` only appears in our repo in the simulated gCNV test data, I suspect that this VCF was generated at some point during development of VCF output for PostprocessGermlineCNVCalls. Not sure in what way that VCF might have been invalid (I'm pretty sure the VCFs produced by that tool now are valid), but I can try to reproduce when I get a chance and will reopen if necessary.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6076#issuecomment-517813352:22,message,message,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6076#issuecomment-517813352,1,['message'],['message']
Integrability,"Thanks for helping with the updates, @MartonKN! Looks like you have some failing integration tests, though. Perhaps go through and fix those up before @sooheelee takes a look? Don't forget you can run integration tests locally for those tools you've updated. It might also be worth rebasing on the most recent version of master and re-pushing your branch to make sure no other argument updates slipped in that might conflict with yours.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3989#issuecomment-352525285:81,integrat,integration,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3989#issuecomment-352525285,2,['integrat'],['integration']
Integrability,"Thanks for indulging me on this. To me it seems like `UnfilledReadsLikelihoods` diverges too much from `ReadsLikelihoods` to extend it. In effect it's letting `ReadsLikelihoods` sometimes be a wrapper for something that is not a `ReadsLikelihoods`. I haven't worked this out but I would hope that it's possible to construct a `ReadsLikelihoods` from a pileup. I mean, the idea of pileup calling is that you use just a single base for the likelihoods and not the whole read (via Pair-HMM), so we should be able to fill the likelihoods from the base qualities.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4865#issuecomment-396369856:193,wrap,wrapper,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4865#issuecomment-396369856,1,['wrap'],['wrapper']
Integrability,"Thanks for looking into this @cmnbroad !. * Does this issue only affect tabix indices, or all indices? . * Does it only affect `IndexFeatureFile`, or other GATK4 tools as well? . * Will an htsjdk patch be required?. * You say that the offsets are correct when indexing on the fly -- does this mean that a tabix index produced by `ApplyVQSR` on an hg38 `.vcf.gz` on-the-fly will be correct? Can you comment on https://github.com/broadinstitute/gatk/issues/2821 to confirm?. If this is the case, can you craft an integration test proving that `ApplyVQSR` creates a correct tabix index for an hg38 `.vcf.gz`? We should also probably disable tabix index creation in `IndexFeatureFile` temporarily until we can patch htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2801#issuecomment-306768554:511,integrat,integration,511,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2801#issuecomment-306768554,1,['integrat'],['integration']
Integrability,"Thanks for looking into this @davidbenjamin. I followed the best practices using bwa mem, mark duplicates etc., to create these input bams for HaplotypeCaller. This is Novaseq 2 x 150 data, I ran Fastqc on the reads and everything looks really good, the only thing I can find that might explain the soft-clipping is that there's some Nextera adapter read through on a small percentage of the reads. I haven't been using -Y with bwa (I see it's used in GATK 4 wdls), so it seems like there should be less soft-clipping than normal. I'll admit these are definitely messy regions we're dealing with, but we really need to make the F5 calls for our clinical pipeline. I just tried --dont-use-soft-clipped-bases and I wasn't able to pick the SNP up in the 55-55003_F5_region.bam, but using forceActive/dontTrimActiveRegions does work on this call.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-402690747:342,adapter,adapter,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-402690747,1,['adapter'],['adapter']
Integrability,"Thanks for making this change! I might include more detail with the note (""Substantially improves results on FFPE samples""), for posterity---it's probably true, but we can't really say anything definitive with only N=1 and without the cross-validation procedure I mentioned on Slack. That is, the higher degree of denoising might just be an artifact of effectively removing more PCs with GC-bias correction (since I'm assuming the same number of PCs were explicitly removed in both cases), but it's possible that removing the optimal number of PCs without GC-bias correction could achieve a better result. Since our correction procedure is relatively naive, there may also be some dependence on bin size. However, I think it's probably not worth a detailed analysis, and that it's generally safe to enable correction by default.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5966#issuecomment-496933928:681,depend,dependence,681,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5966#issuecomment-496933928,1,['depend'],['dependence']
Integrability,"Thanks for taking a look @davidadamsphd. Regarding the singleton pattern, by the looks of things it was introduced for testing with the intention of avoiding the 10+ second overhead of creating the reference table, however `RefAPISourceUnitTest` still builds the table in `queryReferenceAPI` for each test. We could avoid that by using TestNG's `@BeforeClass` to create the `@RefAPISource` just once, as I mentioned above. Otherwise, the API is not called in tests, since a mock `ReferenceDataflowSource` is used. Let's work out a common references interface - @jean-philippe-martin and @akiezun, let me know what you prefer here. BTW the Travis test is failing as I pushed this to my own branch rather than one on hellbender. I'll push to a new one when this gets closer to being ready.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/804#issuecomment-130604350:549,interface,interface,549,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/804#issuecomment-130604350,1,['interface'],['interface']
Integrability,"Thanks for the explanation, I've generally not run into any memory issues with HaplotypeCaller so I think disabling it might be best in my case. I'll go ahead and close this issue now. Just as a side note (and I'm not sure if you would be interested in this), but the reason I've been digging so deeply into HaplotypeCaller behaviour is that we've been working on a rust based reimplementation of the HaplotypeCaller but geared towards metagenomic analysis. So the interface is more geared for handling many genomes all in parallel as well as adding in a bunch of metrics that microbiologists would find useful: https://github.com/rhysnewell/Lorikeet/tree/dev & https://github.com/philipc/gkl-rs. I think the work that you and the GATK team is astounding, and it has been really helpful to have all of the code so well documented and well written. Just thought I'd make you aware of the rust effort in case you had any thoughts on it. Cheers,; Rhys",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7873#issuecomment-1139184179:465,interface,interface,465,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7873#issuecomment-1139184179,1,['interface'],['interface']
Integrability,"Thanks for the files. We've identified the issue as a bug in htslib - pretty straightforward fix. The mixed ploidy is not a problem in this case. But the confluence of multiploidy, number of samples and number of alternate alleles causes some locations in the combined gvcf to have very large arrays of FORMAT data. That triggers an (unforeseen) overflow in htslib. . With Thanksgiving coming up, we won't be able to get the fix out in a released GenomicsDB this week. Can try for early next week, depending on when you're next doing a GATK release @droazen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-558813259:498,depend,depending,498,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-558813259,1,['depend'],['depending']
Integrability,"Thanks for the quick review, @ldgauthier!. I don't think my fix will address any non-determinism in the integration tests. I'm inclined to just do better with the new tools---there does seem to be enough duct tape in the integration tests regarding re/setting the RNG so that the exact-match tests consistently pass. As for learning how to run the WARP tests, I think that would indeed be pretty useful---for anyone that might have to update code for VQSR or the new tools in the future! Can we teach everyone to fish? Isn't this what CARROT is for?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1061830649:104,integrat,integration,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1061830649,2,['integrat'],['integration']
Integrability,"Thanks for the replies. Are these C/C++ tools something one could run today on a genomics db workspace, even if there isnt a formal java wrapper?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6895#issuecomment-711100739:137,wrap,wrapper,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6895#issuecomment-711100739,1,['wrap'],['wrapper']
Integrability,"Thanks for the response, @droazen! Technically, yes, that would be satisfactory & accurate... and if that's easiest, I'm fine with that. . From a user perspective though, it might be beneficial to report the first occurrence of this error, as that's most likely where I would go back to do future testing & troubleshooting. That being said, all of the overlapping intervals are already outputted to stderr, so all the information is retained regardless, and I could just look through the logs to find that first problematic interval. As an aside, I find it a bit weird that the overlapping interval message shows up as a _warning_ even when using the `-no-overlaps` option (I would assume it would be an error, not a warning). In my experience, most errors cause the program to quit immediately. So, perhaps instead, if this warning were an _error_ when using the `-no-overlaps` option, the program would stop after the first occurrence of this error... and then the error message would be accurate. Maybe that was the original intent of this code. But, again, if that requires much more testing & changes, when a quick rewording would also suffice, there's no need. If it's simply a rewording, I'm happy to make a pull request. Let me know what you think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329747570:599,message,message,599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329747570,2,['message'],['message']
Integrability,"Thanks for the review @akiezun. I've addressed all your points. I dropped the sequence dictionary code, so now we rely on a .dict file being present (and if it isn't you can generate one using Picard's CreateSequenceDictionary command). I think the only outstanding issue that is stopping this from being merged is integrating the build of jbwa. Currently you have to manually checkout and build jbwa yourself. The travis build does this automatically, but the local gradle build doesn't. Any thoughts about how to address this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-219770176:315,integrat,integrating,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-219770176,1,['integrat'],['integrating']
Integrability,"Thanks for the review @jamesemery. I've addressed your comments. A few outstanding issues:; * `ActivityProfileStateIterator` and `AssemblyRegionFromActivityProfileStateIterator` duplicate parts of `AssemblyRegionIterator`, so it would be nice to remove the code duplication. Not totally straightforward as the latter does read caching, but the first two don't (Spark shouldn't be caching reads).; * Downsampling needs more work. I would be OK doing that separately, since I've only ever seen it when running on a full genome, and the new strict code needs more work to work on a full genome (I've only got it running on an exome so far).; * There are some improvements we could make to `ReadlessAssemblyRegion` regarding Java interface design and generics, but I'm not sure what they are yet. I'm not sure if these are blockers, since the strict codepath is a new option (off by default), but would like to know what you and @jonn-smith think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5416#issuecomment-439843425:726,interface,interface,726,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5416#issuecomment-439843425,1,['interface'],['interface']
Integrability,"Thanks for the review and running those tests, @ldgauthier! Will restore the aforementioned GnarlyGenotyperIntegrationTests and update a few other exact matches in the rebase this afternoon. You also asked above if there was a theoretical reason to change the threshold. Since it seems the original was relatively arbitrary (at least from what I've been told, happy to be corrected), I think we can leave it. The new annotation is strictly larger, so we will then be slightly more conservative about keeping sites if we leave the threshold fixed. You can think of this as a slight change in the decision boundary in genotype-count space---perhaps I can add some plots to this thread this afternoon to demonstrate. In practice, what we care about is whether: 1) many sites flicker across the change in boundary after hard filtering, and/or 2) these sites result in discrepancies post-VQSR. I think the tests you ran suggest that we don't need to worry much about the second issue, and I can take a closer look later to check about the first (which will depend simply on the number of samples and the allele frequency spectrum). We can also take a basic look at how things might change with e.g. more samples using the aforementioned plots.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-914471272:1052,depend,depend,1052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-914471272,1,['depend'],['depend']
Integrability,"Thanks for the review, @droazen. My ideas about the ordering are the following: in #2084, I have the implementation of the fixing/checking of misencoded quals included in the read sources. So the only one that could be applied before filtering is gone if you accept that PR. Thus, I guess that the transformer could be applied after the filtering. Because transformers could be kind of demanding in computation, it will be interesting to pass directly to them filtered reads. In addition, could be included in the contract that only valid reads for the tool ensure that the read transformers don't blow up. Whatever the decision is, should I wait for addressing the comments?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-245958519:514,contract,contract,514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-245958519,1,['contract'],['contract']
Integrability,"Thanks for the review, @fleharty!. Thanks for highlighting the AVX business, which I didn't consider carefully. This was just copied from the other HC integration tests, and was in turn copied to the M2 tests---but I now realize that the style of the M2 tests is a little different in that an implementation isn't specified. But I think in both cases, we'll try to call an AVX implementation (since the M2 tests will default to `FASTEST_AVAILABLE`) and that Travis should be OK with it, at least?. @droazen can correct me if I'm wrong and let me know if he'd like further review on this branch. Otherwise I'll try to address comments and get this in before I head out on vacation next week.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-906679400:151,integrat,integration,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-906679400,1,['integrat'],['integration']
Integrability,"Thanks for the review, @lbergelson. Back to you with addressed comments and added tests. I don't know if it is good for the clarity of the framework to create an interface for `Pileup`s (for `ReadPileup` and `SAMPileupFeature`), but let me know if you would like that I include that in this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-225236672:162,interface,interface,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-225236672,1,['interface'],['interface']
Integrability,"Thanks for this pull request. It's failing at the moment because it's coming from an external pull request and travis doesn't decrypt secret keys for external pulls (for good security reasons.) It means I have to do a bit of work before this will successfully pass though. Looks good though :). The idea of removing `Feature` would correctly stop the warnings. `Feature` is actually used as a marker interface for identifying things that our input parsing system can read. So we can't just remove it and replace with `Locatable`. They're different conceptually even if they have basically the same methods. For now we can suppress those warnings, and we'll remove the methods once they are removed from htsjkd, or if that is difficult to pull of, we'll convert it to a default method once htsjdk switches to java 8.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/478#issuecomment-97956594:400,interface,interface,400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/478#issuecomment-97956594,1,['interface'],['interface']
Integrability,"Thanks for trying out the tool, @ssri28. The exception message states that “List of input read-count files cannot contain duplicates,” so that would be the first thing to check. (Indeed, it looks like you specify `--input sample.counts_ESI_17.hdf5` twice.) Since we are either building a model or calling ploidy from the count files, it doesn’t make sense to allow duplicates. The support forums at https://gatkforums.broadinstitute.org/ are a better place for getting help with running the tools and diagnosing exceptions. GitHub issues should be reserved for bug reports and feature requests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6217#issuecomment-543113598:55,message,message,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6217#issuecomment-543113598,1,['message'],['message']
Integrability,"Thanks for your feedback, @cmnbroad. In my case, I think that `IntegrationTestSpec` is a good way of avoid complicated code to test tool results, but it is true that it have some problems (one that I had was the usage for testing programs where the outputs are determined by a prefix in the command line, but with different suffixes). I think, from the API user point of view, that a class like `IntegrationTestSpec` to facilitate program output testing (including user exceptions) will be nice for developing purposes. Nevertheless, this is just a convenience that I asked for here, but I can try to solve the issues with the `BaseTest` instead. By the way, I would love to have this interface in GATK at least for now, because several of my tools rely on the `IntegrationTestSpecs` for development...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-243124889:63,Integrat,IntegrationTestSpec,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-243124889,4,"['Integrat', 'interface']","['IntegrationTestSpec', 'IntegrationTestSpecs', 'interface']"
Integrability,"Thanks for your reply. I try `--enable-journal` option and the following message is repeated many times. Received from stderr: [>>> ]. Sending: [vqsr_cnn.score_and_write_batch(args, model, tempFile, fifoFile, 2, 2, ''); ]. I trace the python process that is piped-forked by CNNScoreVariants. write(2, "">>> "", 4) = -1 EPIPE (Broken pipe); --- SIGPIPE {si_signo=SIGPIPE, si_code=SI_USER, si_pid=58415, si_uid=xxxx} ---; read(0, """", 1) = 0; write(2, ""\n"", 1) = -1 EPIPE (Broken pipe); --- SIGPIPE {si_signo=SIGPIPE, si_code=SI_USER, si_pid=58415, si_uid=xxxx} ---; rt_sigaction(SIGINT, {SIG_DFL, [], SA_RESTORER, 0x7f054d1fe5e0}, {0x5006d0, [], SA_RESTORER, 0x7f054d1fe5e0}, 8) = 0; close(3) = 0; write(4, ""952\n1\t121482273\tA\t[G]\t-14.449\n1\t""..., 2018) = 2018; close(4) = 0; :; close(21) = 0; exit_group(0) = ?; +++ exited with 0 +++; ; EPIPE is occured after CNNScoreVariants stops.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4696#issuecomment-384231912:73,message,message,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4696#issuecomment-384231912,1,['message'],['message']
Integrability,"Thanks for your response @droazen -- just tried it and it still does not work for me. I am able to access the bucket fine via gsutil -u {project} as expected. I wonder if this is some GCP issue because I am also unable to get Cromwell to pull down files from requester pays (via Terra, so this should be handled in theory), an issue that a colleague also has once I asked her to run this command on a different r/p bucket using her billing project and account. Also, for a different project and bucket the usual workflow I have to get Hail to read from r/p buckets seems to not work with this same error. Very confused. EDIT: https://support.terra.bio/hc/en-us/articles/4447388269851 seems to provide the most parsimonious explanation:; ```; It was determined that Google tweaked an error message causing Cromwell not to recognize buckets as requestor pays.; ```. Wonder if something similar is going on with GATK?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6179#issuecomment-1048028114:789,message,message,789,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6179#issuecomment-1048028114,1,['message'],['message']
Integrability,"Thanks for your work on this @samuelklee! Testing on both wes and wgs would be ideal. For wgs we can use the gatk-sv reference panel, which is our standard (I can help with this once a docker is ready). For wes, 1kgp would work although it's definitely showing its age. Are the integration test differences large?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1804698174:278,integrat,integration,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1804698174,1,['integrat'],['integration']
Integrability,"Thanks much for this. Unfortunately running as root isn't an option since external CWL runners (like bunny, Toil, cwltool and hopefully Cromwell soon) make the decisions about the username to use and will try to mirror the runner with the external user to match user permissions on the output files. Also people trust it more when you're not trying to run as root (hence, not wanting to mess with `/etc/passwd` in the Docker container for fix Spark as well). This was using the bcbio-vc Docker image (https://github.com/bcbio/bcbio_docker#docker-images) with gatk installed via bioconda, but I don't think is image specific unless you're specifically doing something in your images to work around the problem which is doesn't sound like. Is there any chance to tweak Spark to make it less picky/dependent on the user? I'm not enough of a Spark expert to know if this is work-aroundable in a reasonable way?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-378718128:795,depend,dependent,795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4626#issuecomment-378718128,1,['depend'],['dependent']
Integrability,"Thanks very much for your analysis. Job 4 does create a lot of garbage, but that appears to be inevitable whenever you are dealing with a PairRDD: You have to use a Tuple2 to represent key and value rather than using a more memory-conservative custom data object. You end up with a gazillion tiny objects that survive only during the shuffle. Too bad they didn't base PairRDD on an interface like Map.Entry. Also too bad that you cannot force a shuffle on a (plain old, non-Pair) RDD. Why not just treat it as a key-only structure and allow repartitioning? I mention this not merely to whine, but also in the faint hope that you've developed some helpful workarounds. I don't think we have enough memory to persist the reads, but we can revisit that later. Job 5 *is* doing a lot of computation. It's turning each read into kmers and testing each of those kmers to see if they exist in a large hash table. I don't think there's much opportunity for further optimization -- I knew this would be a bottleneck and tried my best to make the code efficient. The skew in task size is definitely a problem, and I'll be looking for opportunities to address that issue. Thanks again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292230002:382,interface,interface,382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292230002,1,['interface'],['interface']
Integrability,"Thanks! Just to be clear, the PR is incomplete. We need to determine the additional dependencies (which were previously installed along with R) required for AVX, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-413599300:84,depend,dependencies,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-413599300,1,['depend'],['dependencies']
Integrability,"Thanks, @cmnbroad!. - You're right about gatkbase-2.1.0, that image is coming from #5026, which needs some more work. We can delete it for the time being if you think it'll cause confusion.; - Correct, I think the import statement for `reshape` in BQSR.R was always incorrect/extraneous. `reshape2` is the correct dependency for `ggplot2` (which is itself imported), and `reshape` is not explicitly used in BQSR.R. So to recap: I removed the installation of this unnecessary package, but failed to remove an unnecessary import statement since it was in an untested code path, which was then caught when users tried to run the tool. Investigation of this issue then revealed that `ggplot2` was not installed correctly in the current base image, due to a completely unrelated dependency issue.; - Good call on clearing the Travis cache. Not actually sure how to do that, do I just delete the cache at https://travis-ci.org/broadinstitute/gatk/caches for this particular branch?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-408447924:314,depend,dependency,314,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-408447924,2,['depend'],['dependency']
Integrability,"Thanks, James! I'll check that out - I think we might be able to leverage; that. best,. Brian. On Fri, Mar 8, 2024 at 2:38 PM jamesemery ***@***.***> wrote:. > Hey @brianjohnhaas <https://github.com/brianjohnhaas>. I'm not quite sure; > i fully understand what we can change to help you here. However there is a; > feature you might not be aware of in the bamout that can help you figure; > out which reads go with what haplotype. In our bamout we assign a tag (that; > for whatever reason it looks like IGV hides by default) called the XA tag.; > If you look at an IGV bamout and color by that tag you can see what reads; > were grouped by what haplotypes. If a read has no XA tag that means it was; > non-informative about any one haplotype over a second possible contender; > and thus it was not strong evidence one way or another.; >; > Below is a screenshot of what it looks like to do this in a very simple; > case. Hopefully this answers your question? I would be happy to go deeper; > into this if you would like.; >; > Screenshot.2024-03-08.at.2.35.42.PM.png (view on web); > <https://github.com/broadinstitute/gatk/assets/16102845/7d11ff5f-418e-4826-89fc-07535648a71f>; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986302994>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABZRKX773HENZD2UVB356GDYXIHTTAVCNFSM6AAAAABD4OZKJ6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSOBWGMYDEOJZGQ>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986909258:1557,Message,Message,1557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986909258,1,['Message'],['Message']
Integrability,"Thanks, but I’m still not sure I understand. Haplotypecaller has the following parameters:. . Assembly-region-padding. Interval-padding. . The differences and relationships between these are not well documented on the gatk website. From what you describe below, it would seem to suggest that assembly-region-padding is doing what interval-padding is doing. But then why would there be multiple settings for the same thing?. . I just want to make sure that Assembly-region-padding is indeed adding intervals to the -L interval list itself, not just to the assembled regions. . From: droazen <notifications@github.com>; Reply-To: broadinstitute/gatk <reply@reply.github.com>; Date: Thursday, August 1, 2019 at 12:56 PM; To: broadinstitute/gatk <gatk@noreply.github.com>; Cc: gevro <g.evrony@gmail.com>, Mention <mention@noreply.github.com>; Subject: Re: [broadinstitute/gatk] Missing interval padding for HaplotypeCaller (#6071). . @gevro The HaplotypeCaller adds padding to the intervals on its own. This is controlled by the --assembly-region-padding argument, which defaults to 100 bases on either side. Note that this controls both padding around user-provided intervals, as well as padding around each individual assembly region that the HaplotypeCaller discovers. Typically a single user interval will get divided into many assembly regions, depending on where variant activity is located. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517387946:1346,depend,depending,1346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517387946,1,['depend'],['depending']
Integrability,"Thanks, that's a more useful error message I think. What version of java are you running? The current version of GATK requires java 8. It sounds like you're running a java that includes a module system which is java 9+. However, the situation is changing very soon, we are upgrading gatk to use java 17.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452483074:35,message,message,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452483074,1,['message'],['message']
Integrability,"Thanks. That’s what I thought too. But interestingly, looks like some of Agilent’s old BED files do not have such target BED files. Even though they are labeled as such, the boundaries of regions look only like probes. Specifically for the Sureselect clinical research exome and the Human all Exon v4 kits. . From: ldgauthier <notifications@github.com>; Reply-To: broadinstitute/gatk <reply@reply.github.com>; Date: Monday, August 5, 2019 at 10:08 AM; To: broadinstitute/gatk <gatk@noreply.github.com>; Cc: gevro <g.evrony@gmail.com>, Author <author@noreply.github.com>; Subject: Re: [broadinstitute/gatk] Which regions to use for exome calling_interval_list (#6080). . Calling intervals should be based on targets. The targets are the goal and the probes are the implementation. Depending on the bait design and the size of the exons, there can be regions of the targets that are not covered by baits, but still have coverage and still should be called. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6080#issuecomment-518250672:780,Depend,Depending,780,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6080#issuecomment-518250672,1,['Depend'],['Depending']
Integrability,That depends on how many of the existing ReferenceDependentFeatureCodecs we decide to keep.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/234#issuecomment-76261677:5,depend,depends,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/234#issuecomment-76261677,1,['depend'],['depends']
Integrability,"That is a separate matter altogether from both 1) unifying the allele-count collection tools, and 2) standardizing the format of tabular data. The most appropriate place for integration of Mutect2 SNV calls would be as input to the tumor-heterogeneity tool (along with the ModelSegments output) further downstream. This is because it is unlikely that including the SNVs as input to ModelSegments would significantly improve either segmentation or modeling there. If the allele-count collection tools are unified, I think that the only redundant work done across both pipelines would be the calling of hets from the pileups, which is extremely cheap. However, we should certainly also unify the code to do this (which I've spoken to @davidbenjamin about as well).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386734926:174,integrat,integration,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386734926,1,['integrat'],['integration']
Integrability,"That should work for both my cases. It could be nice for SelectVariants to; be able to specify whether genotypes should be called or not too. Other; tools might want the sites-only option. On Mon, Mar 4, 2019 at 12:40 PM droazen <notifications@github.com> wrote:. > *@droazen* commented on this pull request.; > ------------------------------; >; > In; > src/main/java/org/broadinstitute/hellbender/tools/genomicsdb/GenomicsDBUtils.java; > <https://github.com/broadinstitute/gatk/pull/4947#discussion_r262167602>:; >; > > @@ -40,7 +40,7 @@; > */; > public static GenomicsDBExportConfiguration.ExportConfiguration createExportConfiguration(final File reference, final String workspace,; > final String callsetJson, final String vidmapJson,; > - final String vcfHeader) {; > + final String vcfHeader, final boolean doGnarlyGenotyping) {; >; > @lbergelson <https://github.com/lbergelson> @ldgauthier; > <https://github.com/ldgauthier> If tools had a way to inject custom GDB; > config (eg., via an overridable method in GATKTool), and the engine used; > this config when creating the Feature Manager on startup, would that solve; > the problem here?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/4947#discussion_r262167602>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdOOjGpZBu39mqk7jekA7iOzWDTFrks5vTVqFgaJpZM4U4KK0>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-469412816:954,inject,inject,954,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-469412816,1,['inject'],['inject']
Integrability,That test (GATKReadAdaptersUnitTest.testGetAndSetBases) is not a bad test -- it is a unit test for the `getBases()` and `getBasesString()` methods in the `GATKRead` interface. Its test cases include reads with no bases (which is allowed).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/811#issuecomment-130760201:165,interface,interface,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/811#issuecomment-130760201,1,['interface'],['interface']
Integrability,That would be a clearer error message.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/489#issuecomment-99104999:30,message,message,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489#issuecomment-99104999,1,['message'],['message']
Integrability,"That's not unique to out of memory errors, I think it's the result of the process being hit with a SIGKILL so there are other reasons it could happen. A message that suggests that it might be a memory issue but doesn't hide the actual error would be helpful in pointing people in the right direction.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6362#issuecomment-572622465:153,message,message,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6362#issuecomment-572622465,1,['message'],['message']
Integrability,"That's why I am not using in ReadTools and other developmental toolkit the base class from GATK, due to the polluted command line with unused arguments. I think that for give flexibility, some of that arguments should be configurable by extending classes. For example, some tools that does not require reads at all should be able to turn off the read arguments. That will be very useful, although I am not sure how to do it in a proper way without adding more and more interfaces for argument collections. In context case of this PR, I think that adding it does not have any real effect on the GATK codebase, and a lot is gained by downstream projects. For example, if the wrapper script adds another argument that should be parsed in `Main` and documented, the GATK team just add it to its class. If a toolkit has a similar wrapper script, it can also add its own only-doc argument by simply overriding the method...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090:469,interface,interfaces,469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090,3,"['interface', 'wrap']","['interfaces', 'wrapper']"
Integrability,"Thats a good idea. I don't know what our release plan is. I think we might; do one more minor release on java 8 for someone internal and then give a; bit of time before a java 17 release to let things shake out a bit. There; are a bunch of things we punted until it was merged that we want to get; done related to the update. I will put out a snapshot tonight or tomorrow; for you to test against. I wouldn't anticipate many major problems; updating although there might be some wrangling module exports which is; awfully confusing. The bulk of our issues had to do with fixing the; documentation generation and dealing with spark both of which hopefully; will just work for you. On Thu, Mar 2, 2023, 3:56 PM bbimber ***@***.***> wrote:. > @lbergelson <https://github.com/lbergelson> or @cmnbroad; > <https://github.com/cmnbroad>: would you mind kicking off a build on; > this, so I can see how DISCVR-seq builds against it? Are you planning a; > GATK release any time soon?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1452531115>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABD3RLCRVXIM5Y3O2RC6IKTW2ECP3ANCNFSM6AAAAAAQV3ZLXM>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1452540395:1295,Message,Message,1295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1452540395,1,['Message'],['Message']
Integrability,The ADAM jar was pulling in dependencies that should not be in the sparkJar since they stop it working on a cluster.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/912:28,depend,dependencies,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/912,1,['depend'],['dependencies']
Integrability,"The AlleleFrequencyCalculatorUnitTest failure is due to the fact that Genomics DB is pulling in a newer version of testNG (we were using 6.9.6, but now were getting 6.10):. ```; :dependencyInsight; org.testng:testng:6.10 (conflict resolution); \--- com.intel:genomicsdb:0.5.0-proto-3.0.0-beta-1; \--- compile. org.testng:testng:6.9.6 -> 6.10; \--- compile; ```; and 6.10 seems to have a bug in how it handles arrays in lists, which is causing the failure. So we need to add a force resolution statement for testNG in build.gradle:. `force 'org.testng:testng:6.9.6'`. We need to make sure we don't confer this issue on gatk-protected, but thats a [separate issue](https://github.com/broadinstitute/gatk-protected/issues/982).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-296195599:179,depend,dependencyInsight,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-296195599,1,['depend'],['dependencyInsight']
Integrability,"The CNN tools currently use the FilterVariantTranches class to locate class-relative python resources, but FilterVariantTranches is the one CNN tool that doesn't need a Python dependency. If the individual (CNNVariantWriteTensors and CNNVariantTrain) tools still load python files as resources after https://github.com/broadinstitute/gatk/issues/4533 and https://github.com/broadinstitute/gatk/issues/4534 are done, the resources should be moved to live with the respective code for the respective tools.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4539:176,depend,dependency,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4539,1,['depend'],['dependency']
Integrability,"The Carrot run failed due to PAPI error code 9, by the way, not for any reason specific to this branch:. ```; ""executionStatus"": ""Failed"",; ""message"": ""Task BenchmarkComparison.EVALRuntimeTask:NA:4 failed. Job exit code 1. Check gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2aab3ed0-746b-451e-a7db-1c22fbb1bb29/call-CHMSampleHeadToHead/BenchmarkComparison/82289acc-83e7-49c8-acd0-9b2277166e10/call-EVALRuntimeTask/attempt-4/stderr for more information. PAPI error code 9. Please check the log file for more details: gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2aab3ed0-746b-451e-a7db-1c22fbb1bb29/call-CHMSampleHeadToHead/BenchmarkComparison/82289acc-83e7-49c8-acd0-9b2277166e10/call-EVALRuntimeTask/attempt-4/EVALRuntimeTask.log."",; ""message"": ""Workflow failed""; ""status"": ""Failed"",; ""message"": ""Task BenchmarkComparison.EVALRuntimeTask:NA:4 failed. Job exit code 1. Check gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2aab3ed0-746b-451e-a7db-1c22fbb1bb29/call-CHMSampleHeadToHead/BenchmarkComparison/82289acc-83e7-49c8-acd0-9b2277166e10/call-EVALRuntimeTask/attempt-4/stderr for more information. PAPI error code 9. Please check the log file for more details: gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2aab3ed0-746b-451e-a7db-1c22fbb1bb29/call-CHMSampleHeadToHead/BenchmarkComparison/82289acc-83e7-49c8-acd0-9b2277166e10/call-EVALRuntimeTask/attempt-4/EVALRuntimeTask.log."",; ""message"": ""Workflow failed""; ""message"": ""Workflow failed""; ```. Looks like the underlying cause is an R parsing issue:. ```; Error in parse(text = text) : <text>:1:1: unexpected '*'; 1: *; ^; Calls: ldply ... llply -> structure -> lapply -> FUN -> eval -> parse; ```. @jamesemery Have you seen that error before in the Carrot HC tests?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2153282072:141,message,message,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2153282072,5,['message'],['message']
Integrability,"The Carrot tests are failing due to issues with R dependencies unrelated to this PR. Since it might take a day to fix, we are debating whether we're comfortable merging this without seeing the full-scale Carrot HaplotypeCaller test results.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1850830178:50,depend,dependencies,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8609#issuecomment-1850830178,1,['depend'],['dependencies']
Integrability,"The CollectInsertSizeMetrics test cram file used to be zero-length, and was recently regenerated (most likely with Picard since it has BAM contents) but either way its STILL not a CRAM file. Also removed a stray junit dependency that crept in to CompareBaseQualities.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1803:218,depend,dependency,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1803,1,['depend'],['dependency']
Integrability,The Funcotator WDL needs to be integrated into the WDL for M2 and plugged into the automated testing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4088:31,integrat,integrated,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4088,1,['integrat'],['integrated']
Integrability,"The GATK framework depends on the WellformedReadFilter, and individual tools use additional filters for various tool-specific reasons. `--disable-tool-default-read-filters` is a pretty big hammer and should probably be labeled an `@Advanced` argument. I can't speak for Mutect specifically, but I wouldn't expect tools to run and/or produce meaningful results if all read filters are completely disabled.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4665#issuecomment-382367333:19,depend,depends,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4665#issuecomment-382367333,1,['depend'],['depends']
Integrability,The GATK's reference requirement makes it difficult to develop (and run integration tests) on laptops - I'd like to avoid it where feasible.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/100#issuecomment-69814592:72,integrat,integration,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/100#issuecomment-69814592,1,['integrat'],['integration']
Integrability,"The GCC OpenMP library, libgomp1, a required dependency of GCC, needs to be present in order to run the GKL accelerated PairHMM in tools like HaplotypeCaller. We now mention this requirement in the GATK README. Resolves #6012",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8196:45,depend,dependency,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8196,1,['depend'],['dependency']
Integrability,"The Intel-optimized version of TensorFlow 1.9 is now the default for Anaconda users. It now supports all processors with AVX - so everything since Sandy Bridge, which was released in 2011. With that in mind, I was thinking we could dispense with two different conda environments and fold everything into the ```gatk``` environment. @samuelklee , I'm the new guy on the Intel team you've been dealing with.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142:153,Bridg,Bridge,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142,1,['Bridg'],['Bridge']
Integrability,The PR at googleapis/google-cloud-java#5789 makes it possible to add a BigQuery dependency without having to move to the unshaded version. This should make our lives simpler.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516181784:80,depend,dependency,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516181784,1,['depend'],['dependency']
Integrability,The Python scripts called by the PythonScriptExecutor will require python dependencies which can be managed within a conda environment. Is there a way to load the appropriate conda environment from GATK so that users and unit tests can run the PythonScriptExecutor without worrying about wrangling python libraries. @samuelklee @mbabadi @cmnbroad Any ideas?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3692:74,depend,dependencies,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3692,1,['depend'],['dependencies']
Integrability,The README suggests that. >You can use test.single when you just want to run a specific test class:; >`./gradlew test -Dtest.single=SomeSpecificTestClass`. But when I run `./gradlew test -Dtest.single=HaplotypeCallerIntegrationTest` or `./gradlew test -Dtest.single=org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerIntegrationTest` gradle runs the entire integration test suite. Running `./gradlew test --tests *HaplotypeCallerIntegrationTest` does produce the desired result of running just `HaplotypeCallerIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6853:381,integrat,integration,381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6853,1,['integrat'],['integration']
Integrability,"The SVConcordance tool is currently too inefficient in terms of memory usage, requiring several 100's of GB of heap space on ~100K samples. This PR aims to reduce memory usage in two ways:. 1. Truth VCF records are stripped of all genotype fields except `GT` and `CN`, which are necessary and sufficient for concordance computations.; 2. A new option `--do-not-sort` is introduced to skip output record sorting. A major source of heap usage is the output buffer in the `ClosestSVFinder` class, which ensures records are emitted in coordinate-sorted order. This buffer quickly fills, however, when there is at least one record being actively clustered that spans a large interval because the buffer cannot be flushed until a variant beyond the maximal clusterable coordinate of that large variant is encountered. This option will allow users to substantially reduce max heap usage on larger call sets (a single SVRecord can consume ~100MB with 100K samples). Includes an integration test to cover the `--do-not-sort` functionality.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8623:970,integrat,integration,970,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8623,1,['integrat'],['integration']
Integrability,The SplitReads integration tests will fail once we upgrade htsjdk without this.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1241:15,integrat,integration,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1241,1,['integrat'],['integration']
Integrability,"The `-selectType` argument now is `--select-type`, and that's what is failing. It is true that the error message is not that useful. @cmnbroad - is this related with https://github.com/broadinstitute/barclay/issues/119, no?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4705#issuecomment-384228852:105,message,message,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4705#issuecomment-384228852,1,['message'],['message']
Integrability,"The `gatktool` Python code installs a system exception handler to catch unhandled Python exceptions, and sends a negative ack to the `StreamingProcessController` when it sees one. The controller then grabs the stdout/stderr contents; writes it to the log/journal file; and throws a java exception. However, there is a shutdown race condition where occasionally the GATK process will get the negative ack and terminate before the Python exception chain is finished processing, and the exception message never appears in the journal. We've seen this happen when the CNN Python inference code runs out of memory. It would be better to have the exception handler write the exception string directly to the ack FIFO, with a message length included, so the controller can deterministically retrieve the message for inclusion in the java exception without having to rely on std in/out.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5100:494,message,message,494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5100,3,['message'],['message']
Integrability,The acceptance criteria are to replicate the gatk3 functionality and tests. depends on #293 . there's code for some of it at googlegenomics/genomics-pipeline. @jean-philippe-martin can you describe the status of that code?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/424:76,depend,depends,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/424,1,['depend'],['depends']
Integrability,"The advantage of using SLF4J is that it is a general facade, so it makes simpler to change for one logging system to other if the bound is implemented. For the most common logging systems (log4j, jul, JLC, etc.), there are this implementation and even no-op logging. One of the nice things from slf4j is that it allows to use the logging format set by the software to every library dependency, controlling the verbosity of other libraries too. . After having a look to the gradle dependencies, it seems that ADAM and Spark use slf4j. This will allow better integration with the two libraries: now the `slf4-jdk` is completely removed, and I don't know if this will blow up at some point if some of the ADAM/Spark classes try to load them. In addition, it will make GATK4 more general. Regarding features, I'm not using more that what log4j is providing, but I'm quite familiar with logback and I have a bias to use it if possible, but the GATK framework as it is implemented now ""force"" to use log4j. But anyway, I'm happy also with using log4j and I was only suggesting this for make GATK4 more general (and to come back in my work to logback, but that is just personal taste). @lbergelson, feel free to close the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259211054:382,depend,dependency,382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259211054,3,"['depend', 'integrat']","['dependencies', 'dependency', 'integration']"
Integrability,"The biggest thing for a new data source would be the latest (or dare I say; the ability to choose the version) of GENCODE. On Wed, Apr 5, 2023, 10:06 AM Jonn Smith ***@***.***> wrote:. > @robby81 <https://github.com/robby81> This still has to be merged. I've; > been pulled off onto some other projects for a bit. Some changes to the; > internals of Funcotator are needed for this tool to be most useful, so I; > was waiting until those updates were made to merge this.; >; > I can compile a new release of the data sources, but I haven't heard from; > anyone in the community that it's a priority. Can you create a new issue; > for it? Some questions around a new release: If I were to create one, what; > would the new release include? Would there be any new data sources that; > were not included before? Are any included data sources no longer useful; > and should be removed?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1497550761>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AAJMDRJS4JRSEURXGDDFK5TW7V36RANCNFSM5COZRAWA>; > .; > You are receiving this because you are subscribed to this thread.Message; > ID: ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1497616444:1210,Message,Message,1210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1497616444,1,['Message'],['Message']
Integrability,"The broad artifactory moved to https://broadinstitute.jfrog.io/broadinstitute/. There is a redirect in place which as been working for downloads, but uploads are failing with `401 Unauthorized`. It seems like updating the url fixes the problem. As a second issue, our builds try to upload archives for every integration test build, which worked when we only had 1 integration test build, but now that we have multiples we are uploading duplicates which isn't good. We should fix that, probably by adding either a new environment variable to the travis build, or a final build stage to perform the upload.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3068:308,integrat,integration,308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3068,2,['integrat'],['integration']
Integrability,The build should give a clear error message explaining how to skip building the native code if it fails to build.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1554:36,message,message,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1554,1,['message'],['message']
Integrability,"The build.gradle code below builds the native shared library for AVX PairHMM using gcc and copies the .so file to the desired location. The jar task will archive the .so file in the GATK jar file. ``` gradle; apply plugin: 'cpp'; model {; components {; VectorLoglessPairHMM(NativeLibrarySpec) {; binaries.withType(SharedLibraryBinarySpec) { binary ->; cppCompiler.args ""-I"", ""${System.properties['java.home']}/../include""; cppCompiler.args ""-I"", ""${System.properties['java.home']}/../include/linux""; cppCompiler.args ""-mavx""; linker.args ""-static-libgcc"". task copySharedLib(type: Copy) {; from binary.tasks; into ""build/classes/main/org/broadinstitute/hellbender/utils/pairhmm""; }; jar.dependsOn copySharedLib; }; // skip static library build; binaries.withType(StaticLibraryBinarySpec) { binary ->; buildable = false; }; }; }; }; ```. The gradle gcc plugin expects to find the C++ source code in the default location shown below. We can use a different directory structure, if desired. ```; src/; |-- main; |-- test; `-- VectorLoglessPairHMM; |-- cpp; `-- headers; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1492:687,depend,dependsOn,687,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1492,1,['depend'],['dependsOn']
Integrability,"The builds have been broken as a result of the new mechanism for constructing smaller docker images. Namely no longer is the gatk clone and dockerfile sufficient to construct the docker image which has resulted in dockerhubs automated builds feature failing to construct the image successfully. Since there are a number of dependencies that our build has (notably things like java) and the vm dockers build runs is out of our control, a better approach would appear to be constructing the image with a cron job and pushing it to dockerhub manually.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4965#issuecomment-413284005:323,depend,dependencies,323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4965#issuecomment-413284005,1,['depend'],['dependencies']
Integrability,The changes in htsjdk are in [PR 327](https://github.com/samtools/htsjdk/pull/327). We'll most likely need some changes in gatk as well depending on the resolution to #900.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/903#issuecomment-148369495:136,depend,depending,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/903#issuecomment-148369495,1,['depend'],['depending']
Integrability,"The cloud tests are timing out after 10 minutes without emitting any output. It seems like `ApplyBQSRDataflowIntegrationTest.testPR_Cloud` is responsible. It looks like something is crashing in dataflow but the runner is never stopped so it keeps waiting indefinitely (or at least 10 minutes..) See the dataflow log [here](https://console.developers.google.com/project/broad-dsde-dev/dataflow/job/2015-07-24_12_44_26-17415749601435236766). . Executing locally also seems to hang forever, with messages like . ```; Error: (b65a2091061bf0f9): Workflow failed. Causes: (71540087aac21e37): Unable to create VMs. Causes: (71540087aac21994): Error:; Test: Test method testPR_Cloud[0](ApplyBQSR(args=''))(org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSRDataflowIntegrationTest) produced standard out/err: Message: Value for field 'resource.metadata.items[1].value' is too large; ```. Seems like this is possibly a dataflow bug. If the workflow fails in some way the client should be released.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/750:493,message,messages,493,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/750,2,"['Message', 'message']","['Message', 'messages']"
Integrability,"The code is dependent on the nd4j dtype system property being set to ""double"" by gradle. Otherwise the tests (and the tool itself) fail when run from intellij or from the command line. The nd4j unit tests have the same issue. Its easy enough to set the dtype programmatically, though I'm not sure where the best place to do that is.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3552:12,depend,dependent,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3552,1,['depend'],['dependent']
Integrability,"The code that composes the result output folder depends on ```git batch --contains HASH``` to pick up a line with a standard branch name (e.g. ``` joe_doe_bugfix```) . However this is not neceserely the case if the current checkout is not attach to a local branch... for example when one does ```git fetch; git checkout origin/master```. In that case a typical git-batch line that gets picked up is ```* (HEAD detached at origin/master)``` and in this case it will use ""origin/master)"" rather than ""joe_doe_bugfix"" to be part of the result output directory name. The problem is the ""/"" and "")"" which causes problems later at least when running copy_sv_results.sh as they are not escaped appropriately. Obvious ways to address this: ; 1. remove that component of the output name as is not needed to make it quite unique.; 2. change the sub-command to handle that situation. ; 3. or fail early (before spinning the cluster) if the GATK git checkout is detached.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3642:48,depend,depends,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3642,1,['depend'],['depends']
Integrability,"The code to automatically inject ""--VERBOSITY ERROR"" was included in [#171](https://github.com/broadinstitute/hellbender/pull/171/files), but without [#603](https://github.com/broadinstitute/hellbender/pull/603) or equivalent it doesn't affect log4j output. dding in #603 reduces the log output by about another 7000 lines. In addition, we could squeeze out another 5000 lines by automatically injecting ""--QUIET false"" the same way we inject --VERBOSITY.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/147#issuecomment-116737455:26,inject,inject,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/147#issuecomment-116737455,3,['inject'],"['inject', 'injecting']"
Integrability,"The command lines: . gatk --java-options ""-Xmx16G"" GenotypeGVCFs --reference {genome} --variant gendb://workdir/db_{idx} --output output.vcf.gz. gatk --java-options ""-Xmx16G"" CreateSomaticPanelOfNormals --reference {genome} --germline-resource {afsource} --variant gendb://workdir/pon_db_{idx} --output pon.vcf.gz. The output vcf files from the above two steps have chromosome 10 before 7. ; GenomicsDBImport, GenotypeGVCF, or CreateSomaticPanelOfNormals did not give any error messages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8416#issuecomment-1660490047:478,message,messages,478,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8416#issuecomment-1660490047,1,['message'],['messages']
Integrability,The command was 'java -jar gatk/gatk-package-4.1.2.0-local.jar'. It should output the help message.; The server has 256G memory. there should be a bug of linux kernel or java jvm or gatk of some version. Let's close it before I can reproduce it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6050#issuecomment-583827583:91,message,message,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6050#issuecomment-583827583,1,['message'],['message']
Integrability,The concise message is:. ```; cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle; > Configure project :; Executing: git lfs pull --include src/main/resources/large. > Task :condaStandardEnvironmentDefinition; Created standard Conda environment yml file: gatkcondaenv.yml. > Task :pythonPackageArchive; Created GATK Python package archive in /home/cb2/gatk/build/gatkPythonPackageArchive.zip. > Task :gatkDoc FAILED; Unable to find the 'javadoc' executable. Tried the java home: /usr/lib/jvm/java-11-openjdk-amd64 and the PATH. We will assume the executable can be ran in the current working folder. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Get more help at https://help.gradle.org; ```. And stacktrace flag output looks like:. ```; `cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle --stacktrace; > Task :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(Execu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:12,message,message,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716,1,['message'],['message']
Integrability,"The coordinates of output / input files depend on the file type. In this case it is a 1 based system because VCF is always 1 based. . From the [VCF Spec](https://samtools.github.io/hts-specs/VCFv4.2.pdf); > 2. POS - position: The reference position, with the 1st base having position 1. . Some other formats (ex: BED format) use a 0 based position. GATK reads and writes files in their matching coordinates. . Internally it converts them all to a uniform format for processing. The GATK internal format is 1 based and matches VCF.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9029#issuecomment-2452101380:40,depend,depend,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9029#issuecomment-2452101380,1,['depend'],['depend']
Integrability,"The current FindBreakpointEvidence code is classifying reads pairs that overlap such that the start position of the reverse read is before the start position of the forward read as ""OutiesPair"" discordant read pair evidence. However, these are likely due to sequencing of very short inserts that causes some of the adapter to be sequenced and potentially aligned. This change requires a read pair to not be overlapping to be counted as an 'OutiesPair'. On the CHM dataset this causes the number of intervals discovered to drop from 23152 to 21633, and the number of called variants to drop from 3467 to 3366. . @tedsharpe could you review?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2515:315,adapter,adapter,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2515,1,['adapter'],['adapter']
Integrability,"The current GATK framework is increasing in size and functionality a lot (engine, CNV, different tools, etc.). For example, the gCNV code from #3838, will include a full python framework to be use in conjunction with the GATK CNV code. In gatk3, different artifacts were generated to allow custom picking of the correct dependencies. With gradle, a composite build can be done to assemble together every GATK4 sub-modules, and still being able to publish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and re",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3900:320,depend,dependencies,320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900,2,['depend'],"['dependencies', 'dependency']"
Integrability,"The current docker build script runs `gradle installAll` in addition to running `localJar`. This causes the `gatk` script in our docker image to prefer running with the unpackaged set of jars, instead of the fully packaged jar. This, in turn, can cause us to run out of file handles in certain tools, since we need to open all of the jars for our dependencies individually at once. We should just run something like `gradle clean localJar sparkJar createPythonPackageArchive` in our `Dockerfile`, and avoid `installAll`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4409:347,depend,dependencies,347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4409,1,['depend'],['dependencies']
Integrability,"The current initialization action for dataproc workers puts the reference image in different places depending on whether or not an SSD is mounted. Preemptible dataproc workers don't have SSDs, so a mixed cluster will have references mounted on different paths depending on the worker. This change symlinks the SSD mount point onto the HDD so that paths can be consistent. . Also increases several cluster configuration parameters relating to retries, which I saw recommended if using preemptible workers.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4493:100,depend,depending,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4493,2,['depend'],['depending']
Integrability,"The current port of the `HaplotypeCaller` in `dr_runnable_haplotypecaller` has several ""fuzzy"" integration tests, in addition to traditional ""exact match"" integration tests, that test that we're above a certain % of concordance with a known good set (currently, GATK 3 output) using selected parts of the records (eg., alleles, genotypes, start/end positions). We should try to expand this strategy to include fuzzy testing for other parts of the output as well, such as annotations, with the ultimate goal of moving away from exact-match testing for the `HaplotypeCaller`. Will need to be done in consultation with methods people, particularly @ldgauthier",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1732:95,integrat,integration,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1732,2,['integrat'],['integration']
Integrability,"The current test report suggests that if we split off the tests in the `exome` package into a separate target, we would be close to a balanced 2-way split. Possibly the right way to do this is to have two new values for `TEST_TYPE` in `build.gradle`: `cnvIntegration` and `nonCNVIntegration`. Specifying just `integration` would run all the integration tests, as before. Specifying `cnvIntegration` would run everything in the `exome`, `copynumber`, and `coveragemodel` packages. Specifying `nonCNVIntegration` would run everything outside of those packages.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2818:310,integrat,integration,310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2818,2,['integrat'],['integration']
Integrability,"The current, early-stage ReadWalker interface has only an apply()/map operation. We need to determine whether the GATK engine should accumulate map output and/or provide full reduce functionality, or whether this should be done externally by a separate framework that runs the tools (a la Queue).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/114:36,interface,interface,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/114,1,['interface'],['interface']
Integrability,"The entire test suite aborts if HELLBENDER_TEST_INPUTS isn't set because an exception is thrown when loading the VariantWalkerGCSSupportIntegrationTest class. With this change, the tests will still fail, but the rest of the test suite will run. Depending on what the intent for these tests is, another possibility would be to add a dependsOn method with a hard dependency so the tests would be skipped in the case of no env variable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2404:245,Depend,Depending,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2404,3,"['Depend', 'depend']","['Depending', 'dependency', 'dependsOn']"
Integrability,"The error message about allele sorting is unhelpful -- it's from an integration test check for exact match of output vcf against an expected vcf and the ""sort order"" error really just means there are fewer alleles in the output than expected. Since this change is what we want, the solution is just to overwrite the expected VCF. I checked all the discordant files and found nothing wrong, so this is okay. I also looked at all the output after the change `!outputNonVariants` --> `true` that I suggested, and it is definitely more correct.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582252469:10,message,message,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582252469,2,"['integrat', 'message']","['integration', 'message']"
Integrability,"The error message indicates that the recalibration tables have different dimensions, but unfortunately it doesn't say which table it was. Looking at the source for `RecalibrationTables` it looks like it's probably `readGroupTable`, since it is the only 2D table I can see in `allTables`. So the question becomes, why is the number of read groups different for different tables created by `BaseRecalibratorSparkFn`? They all have the same header, so the number of read groups should be the same. One thing to try to see if it affects the result is to set a different partition size with `--bam-partition-size`. It defaults to the HDFS block size, which is 128MB, but you could try another value (e.g. `67108864`, which is 64MB) to see if you get the same error. Otherwise to make more progress I would need to debug locally. Are the files sharable @akkellogg?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-479397018:10,message,message,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-479397018,1,['message'],['message']
Integrability,"The executable archive you're imagining would be a platform-dependent thing. A use case we care about is GATK users being able to freely copy a particular GATK jar across different machines and architectures and have it work transparently, as we recently discussed with @vdauwera. I still think we should plan on having a packaged jar + launcher unless you can come up with a more specific proposal for your executable archive idea.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1693#issuecomment-215794348:60,depend,dependent,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1693#issuecomment-215794348,1,['depend'],['dependent']
Integrability,"The existing Spark interface for metrics collectors is described [here](https://github.com/broadinstitute/gatk/blob/fc66240a1a382ad803b7f83ead612f65957a644e/src/main/java/org/broadinstitute/hellbender/tools/spark/pipelines/metrics/MetricsCollectorSpark.java). [Here](https://github.com/broadinstitute/gatk/blob/414cedf60d2041636f772658a6d04f470affb0f4/src/main/java/org/broadinstitute/hellbender/tools/spark/pipelines/metrics/QualityYieldMetricsCollectorSpark.java) is one implementation of that interface, which in turn just delegates to the actual ""tool"" logic component that is reused for all variations of the tool (Spark, standalone, CollectMultiple, etc).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254217599:19,interface,interface,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254217599,2,['interface'],['interface']
Integrability,"The fact that `ReadCoordinateComparator` does not exactly match the ordering of htsjdk's `SAMRecordCoordinateComparator` has been the cause of a few bugs. It sorts all unmapped reads after mapped reads, whereas `SAMRecordCoordinateComparator` sorts unmapped reads that are assigned the positions of their mapped mates with their mapped mates. The issue is that the `GATKRead` interface does not allow unmapped reads to have a position. Ie., even if an unmapped `SAMRecord` is assigned the position of its mapped mate, calling `getContig()`/`getStart()` on the unmapped read via the `GATKRead` interface will return `null`/`0`. This was done mainly for consistency reasons and to simplify client code. Perhaps we could add `getAssignedContig()`, `getAssignedStart()`, etc. methods to GATKRead to expose the positions that unmapped reads with mapped mates get assigned for sorting purposes, and use these in `ReadCoordinateComparator`. This should allow us to match `SAMRecordCoordinateComparator` exactly, and then `ReadCoordinateComparator` could be used even when sorting for the purpose of writing a bam.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1911:376,interface,interface,376,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1911,2,['interface'],['interface']
Integrability,The fact that you can print stack traces on UserException is not very discoverable. We should probably include instructions to do so in the UserException message itself. We might want to write the stack trace to a file so that people don't have to rerun the program to get it as well. . It's also weird that it's set through an environment variable instead of as an argument. (Although it may be difficult to implement as an argument since it has to be set correctly even if argument parsing fails. @cmnbroad Any thoughts on that? ),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2443:154,message,message,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2443,1,['message'],['message']
Integrability,"The first commit has the raw GATK3 files, the second has the ported files. In order to minimize the diffs from GATK3 for the initial port, there are only very minimal style changes. Integration tests will follow in a separate PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2094:182,Integrat,Integration,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2094,1,['Integrat'],['Integration']
Integrability,"The first idea that comes to my mind is using to methods: `makeReadTransformerBefore` and `makeReadTransformerAfter`, and implementations could control the order of the transformers. Other idea is create two interfaces for transform reads: `ReadRepairTransformer` and `ReadProcessingTransformer`, and make the two methods return the specific interface to do not allow one or the other to be applied before/after.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-245994894:208,interface,interfaces,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-245994894,2,['interface'],"['interface', 'interfaces']"
Integrability,The first step of taking this code from the Hail team is just pasting it into our repo. Successful run:; https://job-manager.dsde-prod.broadinstitute.org/jobs/49d62f48-2dee-417c-aa65-411cbe47be17. GvsQuickstartHailIntegration--we remove the whl from the integration test---sure seems like we wont need one going forward!. Another ticket will be made for these next steps:; Likely this will need to end up in our docker image and the WDL that creates the Avro files can make a version of the input for this scripts instead; Next we will want to remove the Tranches calculations and instead of that value passed in as yet another parameter; Phasing and dropping GQ0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8282:254,integrat,integration,254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8282,1,['integrat'],['integration']
Integrability,"The follow error messages popped up after d25894b3bc80e450210cf8a9124c4171e65f3717. The program seems to function properly. ```; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.FileAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.FileAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""file"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by ; log4j:ERROR [sun.misc.Launcher$AppClassLoader@7506e922] whereas object of type ; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@28c4711c].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```. By backtracking, the problem goes away at commit d827adc81266c788482c9cb4f119f2e3c1e152b8. Since spark-submmit was broken after 8af8bcc920ee5f393562e3e632d9ccd4acd9a638, the bug could be anywhere between commit 8af8bcc920ee5f393",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2734:17,message,messages,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2734,1,['message'],['messages']
Integrability,"The following idiom occurs about 25 times in this repo, mainly in integration tests:; ```; StreamSupport.stream(new FeatureDataSource<VariantContext>(vcf).spliterator(), false). . .; ```; We should extract a method, perhaps `Utils.streamVcf(final File vcf)`, to replace this unwieldy construct.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5006:66,integrat,integration,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5006,1,['integrat'],['integration']
Integrability,The gVCF with intervals cases are pretty horrific. Is there anything different about intervals in the engine that might be responsible @lbergelson ? Would that tool-dependent look-ahead have an effect here?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1640#issuecomment-331494602:165,depend,dependent,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1640#issuecomment-331494602,1,['depend'],['dependent']
Integrability,"The gap-opening and gap-continuation parameters of Smith-Waterman realignment depend on PCA slippage and other stuff that depends on the sequencing platform and sample prep. In other words, they are not global parameters (_note: Smith-Waterman is often used to determine sequence similarity between individuals or species in which case its parameters are constants of the population. But a read differs from a candidate haplotype via sequencing error, not mutation_). @ronlevine suggested (and I am reporting because I like the idea) that we probably have sufficient data to learn these parameters for each sample.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1902:78,depend,depend,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1902,2,['depend'],"['depend', 'depends']"
Integrability,"The ggplot2 R dependency was not installed correctly in the gatkbase-2.0.0 Docker image. It appears that this resulted from a recent ggplot2 update that has broken dependencies (perhaps for the version of R that we use). This missing ggplot2 dependency was the root cause of #5022. I updated the install_R_packages.R script, which should now fail if any package fails to install, and pushed an updated gatkbase-2.0.1 image. The second commit addresses #5022. This should be considered a temporary fix until #5026 is in. Closes #5022.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5040:14,depend,dependency,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5040,3,['depend'],"['dependencies', 'dependency']"
Integrability,"The git hash refers to the commit of GATK you have checked out in your branch as opposed to the commit of GATK that has been built in Java (and will be run on the cluster). I will clarify the error message: it means that you need to rebuild GATK to match your changes to the repository. The malformed object name is a different story, and seems like a bug. I will try to figure that out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3593#issuecomment-330818394:198,message,message,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3593#issuecomment-330818394,1,['message'],['message']
Integrability,"The help message was wrong when an environment variable was missing. I've changed it so the same string is used to lookup the variable and report it missing so that can't ever be broken again. This does change it from loading the variables once at startup to loading them every time they are queried. I assumed that isn't an issue, but I can change it to cache them if someone can see a problem with that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/572:9,message,message,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/572,1,['message'],['message']
Integrability,The hstjdk downstream tests are failing and have been since we merged the repos. It looks like the failure are due to missing R dependencies on the worker nodes.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3234:128,depend,dependencies,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3234,1,['depend'],['dependencies']
Integrability,"The htsget.ga4gh.org appears to be down (tests get 404s, ping fails). This output is from my PR https://github.com/broadinstitute/gatk/pull/6799 that prints out the target URI:. ```; org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; at org.broadinstitute.hellbender.tools.HtsgetReader.doWork(HtsgetReader.java:266); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:146); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:187); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); at org.broadinstitute.hellbender.testutils.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:111); at org.broadinstitute.hellbender.tools.HtsgetReaderIntegrationTest.testSuccessfulParameters(HtsgetReaderIntegrationTest.java:85); ```; Jermey (GA4GH dev) says:. > I recently updated the server, but my understanding was that the gatk build was spinning up a local server from an older image; > 11:41; > so htsget.ga4gh.org is using a newer image, while the gatk tests should pull an older image, spin it up locally, and then request from http://localhost. But based on the output above, it looks like we actually target `https://htsget.ga4gh.org/read...`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6803:387,message,message,387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6803,1,['message'],['message']
Integrability,The htsjdk downstream tests were put together before gradle had composite builds and are very hacky. They should be refactored to use composite builds instead of installing a strangely named maven artifact. . We should also split them into unit/ integration tests to reduce wallclock time. This should be easy since we already to it in travis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3235:246,integrat,integration,246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3235,1,['integrat'],['integration']
Integrability,"The integration tests I had for the allele-specific annotations admittedly had very small VCFs, but they were very, very gross variants. :) At the very least, the rank sums need test data that have a 0/1 sample and a 0/2 sample.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-325462858:4,integrat,integration,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-325462858,1,['integrat'],['integration']
Integrability,"The intervals we are passing to GenomicsDBImport are sorted by chromosomal numbers for a subset of chromosomal regions: chr 7, 8, 9, 10. ; The next step is CreateSomaticPanelOfNormals or GenotypeGVCFs depending on the pipelines. But the output for both steps all shows the problem that chr 10 is ahead of chr 7 (chr 10, 7, 8, and 9). ; Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8416#issuecomment-1635962226:201,depend,depending,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8416#issuecomment-1635962226,1,['depend'],['depending']
Integrability,"The issue is that only the linked list version of hash sets/maps has a predictable iteration order. So, any algorithm that is order dependent may get different results between different Java versions. The only downside is the linked list will take up some additional storage.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1844#issuecomment-220625823:132,depend,dependent,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1844#issuecomment-220625823,1,['depend'],['dependent']
Integrability,The jenkins spark tests are failing with the following error:. This seems to have been introduced in https://github.com/broadinstitute/gatk/pull/3576. ```; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:339); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:194); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:162); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:118); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591:165,message,message,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591,1,['message'],['message']
Integrability,"The latest Picard release introduces a dependency on the Google Cloud NIO library that conflicts with GATK's dependency. We are going to have to blacklist the Picard NIO dependency for now. . Longer term, we might want to consider having both projects depend upon a build of htsjdk that comes with the NIO plugin.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4556:39,depend,dependency,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4556,4,['depend'],"['depend', 'dependency']"
Integrability,"The latest code in htsjdk, which includes https://github.com/samtools/htsjdk/pull/1454 (changes the Allele class into an interface, and uses SimpleAllele as the concrete implementation) causes the `VariantAnnotatorEngineUnitTest.testCombineAnnotations` test to fail because the order of the list returned by `ReducibleAnnotationData.getAlleles` is different with that change than it is without it (presumably due to the different hashCode/equals implementations). `AS_RMSMappingQuality.parseRawData` seems to assume that the order of the Alleles in the list returned by ; `ReducibleAnnotationData.getAlleles` exactly matches the order of the raw data in the String returned by `ReducibleAnnotationData.getRawData`, since it uses indexed access to the list, but I don't see anything that states or ensures/enforces this. Changing the Map maintained by `ReducibleAnnotationData` into a LinkedHashMap fixes the issue for this test, but that just changes the order to be input order - the real issue is that the contract around how the order of the list and the order of the raw data is maintained isn't clear. This will need to be addressed before we can upgrade to the next release of htsjdk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7586:121,interface,interface,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7586,2,"['contract', 'interface']","['contract', 'interface']"
Integrability,"The main issue was that the `StatusRuntimeException`s that the baseline error handling code was trying to catch in practice always seem to be wrapped in at least one layer of exception of a different type. There was no catch handing for these wrapper exception types so the `CreateVariantIngestFiles` tool would simply crash. The changes here also more generally try to follow the recommendations in the [BQ Write API documentation](https://cloud.google.com/bigquery/docs/write-api#error_handling), in particular `close`ing the `JsonStreamWriter` before retrying error codes not explicitly called out by the documentation. An exponential backoff was also added before retry attempts. Parallel logic was also added to load status writing which should reduce (but not eliminate) the possibility of inconsistent sample status writes that require manual intervention. There is still the possibility of an inopportunely timed preemption, which is why VS-262 exists.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7787:142,wrap,wrapped,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7787,2,['wrap'],"['wrapped', 'wrapper']"
Integrability,"The main issue was that the `StatusRuntimeException`s that the baseline error handling code was trying to catch in practice always seem to be wrapped in at least one layer of exception of a different type. There was no catch handing for these wrapper exception types so the `CreateVariantIngestFiles` tool would simply crash. ~The changes here also more generally try to follow the recommendations in the [BQ Write API documentation](https://cloud.google.com/bigquery/docs/write-api#error_handling), in particular `close`ing the `JsonStreamWriter` before retrying error codes not explicitly called out by the documentation.~. EDIT: actually closing the writer didn't work out too well as we use the writer in `PENDING` mode and closing it seems to lose all pending writes. 😬 So in this circumstance we just throw and let WDL-level `maxRetries` start the data loading over from the beginning. An exponential backoff was also added before retry attempts. Parallel logic was also added to load status writing which should reduce (but not eliminate) the possibility of inconsistent sample status writes that require manual intervention. There is still the possibility of an inopportunely timed preemption, which is why VS-262 exists. All of the WDL changes here are in support of a 2000-sample tieout, a large enough set that intermittent BigQuery errors are almost always observed. The tieout confirms that errors of the two major classes are seen (retryable and non-retryable) and that the number of rows per sample in the tieout dataset matches those in a reference dataset.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7841:142,wrap,wrapped,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7841,2,['wrap'],"['wrapped', 'wrapper']"
Integrability,"The main jar contains some test related classes. . This seems to be due to dependencies from gate-public to gatk-protected when the latter was around (no longer the case) and is maintained in case some gatk user code's depend on them as well. . IMO there should not be any such a test code in main jar and if it probes to be usefull for some, then we should provide a separate artifact (a test jar add-on).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3567:75,depend,dependencies,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3567,2,['depend'],"['depend', 'dependencies']"
Integrability,"The master branch failed on BaseRealibratorSpark when running WGS. Try to test this branch, but got hit by a strange error message. The jar file looks right to me. @tomwhite did you have some environment variables? . ````Using GATK jar /home/genomics/Projects/TomWhitePatches/gatk/build/libs/gatk-package-4.alpha.2-230-g19db939-SNAPSHOT-spark.jar; Running:; /home/genomics/Projects/spark/bin/spark-submit --master spark://n001:7077 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --executor-memory 25G --driver-memory 5G /home/genomics/Projects/TomWhitePatches/gatk/build/libs/gatk-package-4.alpha.2-230-g19db939-SNAPSHOT-spark.jar BaseRecalibratorSpark -I hdfs://n001:54310/GATK4TEST/LargeBroadData/WGS-G94982-NA12878.bam -knownSites hdfs://n001:54310/GATK4TEST/DBSNP/dbsnp_138.hg19.vcf.gz -R hdfs://n001:54310/GATK4TEST/OldData/human_g1k_v37.2bit -O hdfs://n001:54310/GATK4TEST/LargeOutput/WGS_BQSR --sparkMaster spark://n001:7077; Picked up JAVA_TOOL_OPTIONS: -XX:+UseG1GC -XX:ParallelGCThreads=4; Picked up JAVA_TOOL_OPTIONS: -XX:+UseG1GC -XX:ParallelGCThreads=4; java.lang.ClassNotFoundException: org.broadinstitute.hellbender.Main; at java.lang.ClassLoader.findClass(ClassLoader.java:530); at org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.scala:26); at java.lang.ClassLoader.loadClass(ClassLoader.ja",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-299259877:123,message,message,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2620#issuecomment-299259877,1,['message'],['message']
Integrability,"The n1-standard-1 instance we'll be using has a single hyper-thread available to it from either a; 2.6 GHz Intel Xeon E5 (Sandy Bridge), 2.5 GHz Intel Xeon E5 v2 (Ivy Bridge), 2.3 GHz Intel Xeon E5 v3 (Haswell), or 2.2 GHz Intel Xeon E5 v4 (Broadwell). [Source](https://cloud.google.com/compute/docs/machine-types)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2424#issuecomment-282143266:128,Bridg,Bridge,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2424#issuecomment-282143266,2,['Bridg'],['Bridge']
Integrability,The new annotation engine needs to consider dependencies between annotations.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/225:44,depend,dependencies,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/225,1,['depend'],['dependencies']
Integrability,The new index creation tool `IndexFeatureFile` needs integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/235:53,integrat,integration,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/235,1,['integrat'],['integration']
Integrability,"The new pipeline is in a complete state. Nearly all tools and scripts were rewritten, many from scratch. I've tried to minimize interaction with old `tools/exome` code (notably, `ReadCountCollection` and `SegmentUtils`). There are still some improvements that can be made (especially in segment union and the subsequent modeling), but we should be ready to go for a first validation. Some notes:. WDL:; - I've moved the old pipeline to `somatic_old` folders.; - There is now just a matched-pair workflow and a panel workflow. We can add a single BAM case workflow or expand the matched-pair workflow to handle this, depending on the discussion at https://github.com/broadinstitute/gatk/issues/3657.; - WES/WGS is toggled by providing an optional target-file input.; - For all workflows, we always collect integer read counts; for WGS, these are output as both HDF5 and TSV and the HDF5 is used for subsequent input.; - For the case workflow, we always collect allelic counts at all sites and output as TSV.; - [x] We should output all data files as HDF5 by default and as TSV optionally. EDIT: This is done for `CollectFragmentCounts`.; - [x] We will need to update the workflows when @MartonKN and @asmirnov239 get `PreprocessIntervals` and `CollectReadCounts` merged, respectively. These tools will remove the awkwardness required by `PadTargets` and `CalculateTargetCoverage`/`SparkGenomeReadCounts`. Denoising:; - All parameters are exposed in the PoN creation tool (#3356).; - Without a PoN, standardization and optional GC correction are performed (#3570).; - Other than the minor point about sample mean/median being used inconsistently noted above, the denoising process is essentially exactly the same mathematically as before (""superficial"" differences include the vastly improved memory and I/O optimizations, the ability to adjust number of principal components used, the removal of redundant SVDs, the enforcement of consistent GC-bias correction).; - [ ] That said, I'll carry over this ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:616,depend,depending,616,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['depend'],['depending']
Integrability,The new validation tests for `ReadsPipelineSpark` should be easily runnable in either a push-button fashion or on a set automatic schedule (nightly or weekly) via a jenkins server. Depends on https://github.com/broadinstitute/gatk/issues/1400,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1401:181,Depend,Depends,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1401,1,['Depend'],['Depends']
Integrability,The newest release of GenomicsDB treats spanning deletions (spanning; from earlier positions) as deletions in the min PL value computation.; This behavior now matches the behavior of CombineGVCFs. A more detailed description of the issue is provided in; https://github.com/broadinstitute/gatk/pull/4963. * Deleted a couple of files which are no longer necessary.; * Fixed the index of newMQcalc.combined.g.vcf; * Fixes #5045 (error out with a helpful error message); * Fixes #5300,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5397:457,message,message,457,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5397,1,['message'],['message']
Integrability,"The non-spark jar that this change actually creates is the one labelled; ""shadowJar"", ie. gatk-all-4.pre-alpha-175-*-SNAPSHOT-shadowJar.jar. This is a proper fatJar with all of the dependencies packaged up together. The installDist target produces a different jar file that doesn't shadow; all of the dependencies, and so I think it needs to be run with the 'gatk'; wrapper script that sets the classpath in build/scripts. It is a little confusing having all three jar targets, and maybe you guys; don't want to support that, but I was hoping to make a fat jar with all the; dependencies bundled, and the previous 'fatJar' target wasn't working; properly. My PR basically just replaced that old 'fatJar' target with; 'shadowJar'. On Fri, Dec 4, 2015 at 11:32 AM, Tom White notifications@github.com wrote:. > @cwhelan https://github.com/cwhelan I've having problems with the; > non-Spark JAR though:; > ; > $ gradle clean installDist; > $ java -jar build/libs/gatk-4.pre-alpha-*-SNAPSHOT.jar; > Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/logging/log4j/LogManager; > at org.broadinstitute.hellbender.cmdline.ClassFinder.<clinit>(ClassFinder.java:29); > at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:108); > at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); > at org.broadinstitute.hellbender.Main.main(Main.java:86); > Caused by: java.lang.ClassNotFoundException: org.apache.logging.log4j.LogManager; > at java.net.URLClassLoader$1.run(URLClassLoader.java:372); > at java.net.URLClassLoader$1.run(URLClassLoader.java:361); > at java.security.AccessController.doPrivileged(Native Method); > at java.net.URLClassLoader.findClass(URLClassLoader.java:360); > at java.lang.ClassLoader.loadClass(ClassLoader.java:424); > at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308); > at java.lang.ClassLoader.loadClass(ClassLoader.java:357); > ... 4 more; > ; > —; > Reply to this email directly or view it on GitHub; > https://githu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1213#issuecomment-162017907:181,depend,dependencies,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1213#issuecomment-162017907,4,"['depend', 'wrap']","['dependencies', 'wrapper']"
Integrability,"The number of backtrace messages emitted definitely went up with the addition of the Picard sources, but the number I see when I run the gatkTabComplete task locally is dramatically lower than the number emitted when the cron job runs it. The main difference I can see is the cron job is using openjdk, whereas I'm not; the number of times the message is emitted is definitely sensitive to the order in which the sources are processed and ClassDoc and FieldDoc objects are traversed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3710#issuecomment-337692643:24,message,messages,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3710#issuecomment-337692643,2,['message'],"['message', 'messages']"
Integrability,"The one check that fails, I have restarted twice with the same error message:; ```; The job exceeded the maximum time limit for jobs, and has been terminated.; ```. The limit appears to be around 49 minutes. I have seen this type of check failure for my other PRs. Why does this keep happening and is it possible to up the time limit?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2812#issuecomment-306047630:69,message,message,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2812#issuecomment-306047630,1,['message'],['message']
Integrability,"The other important thing about the sparkJar is that it doesn't contain Spark and Hadoop classes (and the classes of their transitive dependencies). This is because running spark-submit will provide these dependencies, and we want it to work on different versions of Spark. (Spark and Hadoop are fairly brittle and so a client with one version doesn't necessarily work against a cluster running another version.). It looks like this change maintains this property, but it will need testing on clusters to double check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1213#issuecomment-161707858:134,depend,dependencies,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1213#issuecomment-161707858,2,['depend'],['dependencies']
Integrability,"The package org.broadinstitute.hellbender.utils.commandline contains annotation classes called AdvancedOption and HiddenOption that are duplicates of Advanced and Hidden in org.broadinstitute.hellbender.commandline. All usages of these should be updated and this entire package should be removed. Also, it looks like Hidden is not integrated with the command line parser.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2130:331,integrat,integrated,331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2130,1,['integrat'],['integrated']
Integrability,"The packages for codecs is a key feature for downstream tools implementing new codecs for other formats or to include overrides of codecs already included. Nevertheless, the current implementation (at version 4.0.0.0) the only way of configuring this is at the package level using the `codec_packages` configuration. I request support for the following fine-grained configuration:. * Add/Remove concrete codec classes; * Exclude single classes from a concrete `codec_package` specified (this can be done by the previous requirement if it uses fully qualified codec names); * Exclude sub-packages from a concrete `codec_package` specified. Representing this in an YML format, I would like to have the ability to configure the codecs as following:. ```yml; - codecs:; - packages:; - htsjdk.variant; - htsjdk.tribble; - exclude_class: bed.BEDCodec; - org.broadinstitute.hellbender.utils.codecs; - exclude_package: gencode; - org.magicdgs.htsjdk.codecs; - classes:; - org.external.htsjdk_codecs.CustomBedCodec; ```. This would be even more useful if HTSJDK is moving to an interface-based library...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4180:1069,interface,interface-based,1069,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4180,1,['interface'],['interface-based']
Integrability,"The packages required by these tests are installed by scripts/docker/gatkbase/install_R_packages.R. Perhaps we should update the readme, which seems to indicate that the R dependencies are only used for plotting.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3740#issuecomment-338992163:172,depend,dependencies,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3740#issuecomment-338992163,1,['depend'],['dependencies']
Integrability,"The previos message was written a bit quick from my phone. The concrete PR is https://github.com/samtools/htsjdk-next-beta/pull/12. @lbergelson - would like to have a look to it, or do you prefer that I open another one with the interface on top of the CIGAR part? I prefer to go step by step, as it is clearer than adding too many classes to review at once...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5267#issuecomment-428735904:12,message,message,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5267#issuecomment-428735904,2,"['interface', 'message']","['interface', 'message']"
Integrability,"The problem currently with having everything in one repo is that we have no way of automatically testing on PPC. So an Intel engineer (for example) making a change to the x86 implementation would have to also find a way to manually test on PPC, which adds considerably to the testing/development burden. With separate repos, a change in the AVX repo wouldn't affect the PPC repo until the maintainer of the PPC repo updated it (after doing appropriate testing of their own), since the PPC repo would depend on a tagged version of the AVX repo. There could also still be some level of code sharing between the two implementations, since the PPC repo would pull in the AVX repo as a dependency. If someone could provide us with a means of automatically testing on PPC, with ability to see the test status on github, then I think we'd be more open to the idea of a single repo.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-215127556:500,depend,depend,500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-215127556,2,['depend'],"['depend', 'dependency']"
Integrability,"The problem is that the catch block in `CommandLineProgram` is calling both `commandLineParser.usage()` and `printDecoratedUserExceptionMessage()` -- it should only be calling `commandLineParser.usage()`, and letting the catch block in `Main.mainEntry()` call `printDecoratedUserExceptionMessage()`. Otherwise there are cases where a `CommandLineException` will be caught without printing any error message. This is a bug and should be fixed. The distinction between ""errors that are the user's fault"" and ""errors that are not the user's fault"" is very important for our support team -- it allows them to deal with bug reports and forum questions much more efficiently. Whatever solution we come up with here should maintain that distinction, and clearly label errors like ""bad argument value"" as being a user error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268712938:399,message,message,399,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268712938,1,['message'],['message']
Integrability,"The problem is that the package can't download any files during build due to security reasons. It has to use predefined, repeatable set of dependencies, and can't download random versions of gradle either. It has to use the ```devel/gradle``` port, and once this port has been upgraded to version 5.0 gatk became broken. ```devel/gradle4``` had to be created. Generally, indiscriminate downloads of files lead to security problems like the one that recently happened with a particular bitcoin-related node code, which was using a zillion node dependencies. One of them got infiltrated by a criminal who eventually stole bitcoins because he managed to inject his code into financial applications running on user's sites. To prevent such things from happening, all major packaging systems only use fingerprinted dependencies, and can't ""just download"" some alternative version of something during build, contrary to what devs might be expecting.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444205059:139,depend,dependencies,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444205059,4,"['depend', 'inject']","['dependencies', 'inject']"
Integrability,"The reason I was getting different behavior was because my local htsjdk was built from a fork, and it had stale tags. That doesn't matter for GATK, since the GATK build.gradle uses a resolution strategy of ""force"" for htsjdk, forcing it to use the version I specified (even though it looks old due to the old tags). But the gatk-protected build.gradle doesn't have an explicit resolution strategy declared, so gradle resolves conflicts via ""pick the newest one"". Since there are newer versions available in gatk-protected via other transitive dependencies, it was choosing those over my local one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292971228:543,depend,dependencies,543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292971228,1,['depend'],['dependencies']
Integrability,The remaining part of this ticket (removing the actual gradle dependency on dataflow) is for beta.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/954#issuecomment-157450255:62,depend,dependency,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/954#issuecomment-157450255,1,['depend'],['dependency']
Integrability,"The right way to approach this ticket is not to make a huge change that requires a massive amount of work across both our codebase and our dependencies, but instead to make a targeted fix that addresses the original bug. If we want to support zero-length intervals, that should be a separate ticket, as it's a non-trivial task to do correctly. I'll add: unless the semantics of using zero-length intervals are precisely defined in every case, we should probably not allow them. Eg., what should happen when you query using a zero-length interval? Should you always get back nothing, or should you get back abutting records? How does overlap work? Allowing intervals to be zero-length complicates everything immensely -- what is the tangible benefit of allowing them?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/373#issuecomment-97572681:139,depend,dependencies,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/373#issuecomment-97572681,1,['depend'],['dependencies']
Integrability,The sample name map file accepted by GenomicsDBImport can now optionally contain a third; column giving an explicit path to an index for the corresponding GVCF. It is allowed to; specify an explicit index in some lines of the sample name map and not others. Added comprehensive unit and integration tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7967:287,integrat,integration,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7967,1,['integrat'],['integration']
Integrability,"The snapshot builds get published to an artifact repository, but I don't think those are accessible from outside of Broad. The build from this morning with your branch is [here](https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot-local/org/broadinstitute/gatk/4.0.11.0-30-g9c4a27b-SNAPSHOT/) if you can access it. Otherwise, for local development, you can do the following:. - pull gatk master from today so it includes your commit; - run `git fetch --tags` (this is optional but it will give your local build a more reasonable version tag); - run `./gradlew install printVersion` to install the locally built gatk into your local machine's maven repository; - change your VariantQC gradle project to include the `maven` gradle plugin if its not already there; - add `mavenLocal()` to your projects' `repositories `closure; - change your gatk dependency to the version number printed out by 'printVersion'; - rebuild VariantQC. Having said all that, what code are you dependent on ? I expect the command line interface to VariantEval, and the VariantUtils and StratificationManager and friends classes all to undergo some refactoring and evolve a bit before the tool has the beta tag removed and the interfaces are stabilized. See https://github.com/broadinstitute/gatk/issues/5439 and https://github.com/broadinstitute/gatk/issues/5440.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440782148:852,depend,dependency,852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440782148,4,"['depend', 'interface']","['dependency', 'dependent', 'interface', 'interfaces']"
Integrability,"The spark dataproc tests seem to be failing, likely due to some dependencies changing on the backend outside of our control. I have disabled these tests temporarily while we sort out the issue. The failing tests are:. `DataprocIntegrationTest.markDuplicatesSparkOnDataproc`; `DataprocIntegrationTest.printReadSparkOnDataproc`. Once this is fixed, these tests should be re-enabled.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7172:64,depend,dependencies,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7172,1,['depend'],['dependencies']
Integrability,The standard integration/unit tests upload their test report -- the docker tests should as well.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2817:13,integrat,integration,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2817,1,['integrat'],['integration']
Integrability,"The tab completion integration test wasn't actually emitting any output because the classpath contained a list of class names (basenames only, without the "".class"" extension), so no work units were ever created. This PR:. - changes the classpath to use package names that contain CLPs instead of class names; - runs the javadoc in the current JVM (which makes debugging the test so much easier...); - adds an Assert to ensure the javadoc process succeeds. I made the latter change to the doc gen smoke test as well, to make debugging easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6647:19,integrat,integration,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6647,1,['integrat'],['integration']
Integrability,"The tests were failing for some reason, probably due to some dependency downloads failing, so I'm rerunning them. Will merge when that's done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5021#issuecomment-405984274:61,depend,dependency,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5021#issuecomment-405984274,1,['depend'],['dependency']
Integrability,"The tickets we're planning to do soon are all tagged with the ""beta"" milestone -- this one is low priority with only very minor benefits, and so didn't make the cut. Unfortunately it's a task we'd have to take on ourselves, since it affects our maven artifacts. We can consider it for a future milestone after beta. Is this something that's causing an actual problem for you, or is it just a matter of principle that you don't want test dependencies in the main jar?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1481#issuecomment-289785444:437,depend,dependencies,437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1481#issuecomment-289785444,1,['depend'],['dependencies']
Integrability,The tool is ported - see the `ak_contest_v2` branch (note that it will not compile if rebased because it depends on a reverted PR that introduced symbolic names for read inputs). . What remains to be done is tests. I'm not going to be able to work on this so I'll un-assign.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/246#issuecomment-235945563:105,depend,depends,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/246#issuecomment-235945563,1,['depend'],['depends']
Integrability,"The tutorial data would be an option, except that it covers reference territory not currently in the repo. It looks like that would add nearly 1 gig just for the reference data, which I think we'd really want to avoid. Ideally we'd have just one PR for each of the (two) tools. If you want to keep `ConstrainedMateFixingManager` and `NWaySAMFileWriter` as separate PRs, thats fine, but I don't think we'd take them until we know there is, or will very soon be, code that depends on them. Certainly using `@Experimental` for the tools could make sense, once we're certain that we have a way forward for test coverage. One other note, it's very helpful to include the original GATK3 file as the first commit, as you did in this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366271857:471,depend,depends,471,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366271857,1,['depend'],['depends']
Integrability,"The two main resources limiting how many gVCFs you can import at once will be memory and file handles. . I'm not sure if you mean incremental import or batch size when you mention the iterative approach. I assume the latter, but just want to clarify that there isn't any reason to break up the import using incremental import. The batch size parameter effectively does that, so you might as well import all gVCFs you have available (optionally using batch size if you're running out of memory). I'll throw out batch sizes of 50 or 100 as being reasonable, but the size of the intervals being imported will make a difference. It would be best to try to monitor how much memory is being used with those settings. There won't be a huge difference in import performance depending on the number of batches (ignoring memory issues) but if you have more than a 100 or so batches and you don't enable the `--consolidate` option you may see some query performance degradation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656376952:766,depend,depending,766,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656376952,1,['depend'],['depending']
Integrability,"The user mentioned and I agree:; Since the interval list isn't a required argument listed in the GenotypeGVCFs documentation, perhaps a note could be added to the --all-sites parameter to indicate that it should be used in conjunction with a specified -L parameter. Clarifying the error message will also be a big help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5865#issuecomment-480978282:287,message,message,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5865#issuecomment-480978282,1,['message'],['message']
Integrability,"The version of testNG that we're using has some [inconsistencies](https://github.com/cbeust/testng/pull/790) in how nested arrays/collections are handled, and they've resolved them in newer versions by implementing changes that are not backward compatible. The AlleleFrequencyCalculatorUnitTest tests fail with newer versions of testNG that have these changes, since they were wrapping an array in a single element List (not sure if that was intentional or not). The testNG issues seem to suggest using assertEqualsDeep for [some cases](https://github.com/cbeust/testng/issues/1342) but even the newest version doesn't seem to have an overload for Collections. For AlleleFrequencyCalculatorUnitTest though, the collection wrapping was unnecessary anyway, so the array comparisons can be made directly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2611:377,wrap,wrapping,377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2611,2,['wrap'],['wrapping']
Integrability,The vulnerabilities reduced a bit but most serious once continue to be there. Dependency upkeep is really needed to iron this out these.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1544539592:78,Depend,Dependency,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1544539592,1,['Depend'],['Dependency']
Integrability,"The warp pipeline tests caught some cases that we apparently didn't have in our integration tests, but now we do!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7670:80,integrat,integration,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7670,1,['integrat'],['integration']
Integrability,The work that @tomwhite has done in the HalpotypeCallerSpark has illuminated the fact that currently the downsampler is statefully dependent on the random generator underneath in terms of how it selects reads to be downsampled. This has become an issue since we would like to separate the process of assembly region construction and genotype calling across stages of the spark task. In order to do this successfully there needs to be some way to reproduce the same downsampled results for a given site based solely on the reads present at that site.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5437:131,depend,dependent,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5437,1,['depend'],['dependent']
Integrability,"The xbyak ""code is too big"" issue recently started happening on multiple branches (see https://github.com/broadinstitute/gatk/issues/6307), but is intermittent. I'll restart that one. The updated TF I gave you can't be checked in since its OSX specific, and needs additional work to be integrated (see https://github.com/broadinstitute/gatk/issues/6325) so it should be left out for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6330#issuecomment-567055679:286,integrat,integrated,286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6330#issuecomment-567055679,1,['integrat'],['integrated']
Integrability,"There appears to be a memory leak in gCNV coming from Theano 0.9.0, possibly fixed in https://github.com/Theano/Theano/pull/5832. A few possible fixes:. 1) Update Theano to the latest 1.0.4 version. I've tried this and it looks like the leak goes away. Need to confirm reproducibility of results between versions, see also #5730.; 2) Configure Theano 0.9.0 to use MKL, rather than OpenBLAS. It appears the leak is only an issue with the latter. This is a little more complicated, since I now realize that MKL is not actually fully utilized (if at all) in our conda environment. For example, we `pip install numpy`, rather than `conda install` a version from the `default` channel that is compiled against MKL. So we'd need to change a few dependencies in the environment which might have implications for VQSR-CNN. See also #4074. @lucidtronix any thoughts? @jamesemery and @cmnbroad might also be interested, as this could have pretty drastic implications for the size of the python dependencies---if we go with option 1, we might be able to get rid of MKL, etc. Not sure if the memory leak manifests the same across all architectures. Note that I believe this is a separate issue from #5714.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5764:739,depend,dependencies,739,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5764,2,['depend'],"['dependencies', 'dependencies---if']"
Integrability,"There are 4 separate commits:; - Upgrade to Barclay 2.0.0 and Picard 2.17.2.; - Changes for CommandLinePluginDescriptor updates (required for the Barclay upgrade); - Updates for Experimental tag (dependent on Barclay upgrade).; - Remove placeholder and obsolete program groups - Part 1 (dependent on Picard upgrade).There are still 3 obsolete program groups (ReadProgramGroup, VariantProgramGroup, and SparkProgramGroup) who's tools need to be redistributed to the new program groups. But thats can be a separate PR since it will be a lot of files.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4070:196,depend,dependent,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4070,2,['depend'],['dependent']
Integrability,"There are a few problems with IntegrationTestSpec that surface when adding CRAM tests to the Reads/BQSRSparkPipelines:; - generated output filenames contain no sam extension, so outputs always are treated as .bam; - it doesn't have explicit knowledge of the reference file, which is needed to do proper file comparisons through the SamAssertionUtils assertSamsEqual methods; - there is code that assumes that any expectedFile that doesn't end in "".bam"" should use text comparison. We could fix these, but I'm not sure what the incremental value-added of this class is when we can just use TestNG for expected exceptions, etc.; it might make more sense to just eliminate this style of test completely.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1562:30,Integrat,IntegrationTestSpec,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1562,1,['Integrat'],['IntegrationTestSpec']
Integrability,"There are currently a few known issues that reviewers should bear in mind (these will become tickets shortly):. -All codecs marked as implementing `ReferenceDependentFeatureCodec` are currently non-functional. I need to either refactor them to not require a GenomeLocParser or delete them entirely. -The `IndexFeatureFile` tool is not currently working on block-compressed files -- will fix this soon. -`IndexFeatureFile` needs integration tests (will work on this during code review). -`BQSR` needs integration tests for the case of multiple simultaneous known sites files (now that it supports them!). -All codecs should move to tribble, and must implement `canDecode()` correctly (this is a new requirement, since it's no longer possible to manually request a particular codec). Most `canDecode()` implementations can be file-extension-based; only things like VCF format detection need to examine file contents to determine file type. -`FeatureDataSource` supports querying by interval, as well as full traversals, but not full traversal by a set of intervals (yet). This latter feature will be needed for the `VariantWalker` traversal.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/224#issuecomment-75658867:428,integrat,integration,428,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/224#issuecomment-75658867,2,['integrat'],['integration']
Integrability,"There are no error messages.; The process was interrupted without any error messages.; I attached the screenshot.; I attached chr14 variant calling (completed) and chr14 variant calling; (interrupted).; In the system monitor, when I am using GATK 4.6.0.0., they are eating up; memory continuously.; When they are reaching up to 512Gb, the process was interrupted.; I tried to run this process on only 2-3 chromosomes, and I found that the; process was completed on chr 14, and the process was interrupted on the; rest of two chromosomes (interval -L).; So I rolled back to GATK 4.5.0.0, the process was normal. I can do; GenotypeGVCFs command entire chromosome simultaneously. My machine has 512Gb memory and 64 cores (5995wx AMD threadripper) dell; 7865 workstation.; Thanks; Jinu Han. On Fri, Jul 19, 2024 at 12:08 AM Gökalp Çelik ***@***.***>; wrote:. > Can you provide your logs that shows the error message?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2236819113>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AG7IXWWGPB73BXPN4Z5E4VTZM7LAFAVCNFSM6AAAAABLBRETECVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMZWHAYTSMJRGM>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2238806751:19,message,messages,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2238806751,4,"['Message', 'message']","['Message', 'message', 'messages']"
Integrability,"There are pretty significant incompatibilities between java 8 and 11 that make it hard to run the same code on both. It affects a number of our dependencies which use features which were removed/altered from java 8 -> 11. Unfortunately despite there being significant pain in switching to 11 there aren't particularly compelling new features after 8 so there isn't much incentive for developers to move forward. That said, you CAN now run gatk on java 11 if you build it using java 11, the jars built on 8 are incompatible with 11 and vice a versa. We consider running on 11 to be a beta feature and would love to hear feedback about either success or failure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6298#issuecomment-561371535:144,depend,dependencies,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6298#issuecomment-561371535,1,['depend'],['dependencies']
Integrability,"There are several cases where ValidateVariants does no actual validation, and issues no warning message. This includes the default case, where the minimal set of required args is provided (these are examples from the doc, which should be updated when this is fixed): . `gatk ValidateVariants -V some.vcf`; `gatk ValidateVariants -V some.vcf -R some.fasta`. Either of these silently results in no validation and no warning message, despite the entire VCF being decoded and traversed, because the default validation type is ""ALL"", which includes validation type ""IDS"". But IDS requires a dbsnp arg, and none was provided, so the code short-circuits out. The default case should probably do whatever validation it can, but at a minimum a warning should be logged. Ironically, if you provide an exclusion on the command line via `--validation-type-to-exclude IDS`, then validation is done. Another no-op case is `--validation-type-to-exclude ALL` (also recommended in the doc), which also should probably be rejected, or at least logged, since it silently does no validation and reports no errors. This tripped up [this user](https://github.com/samtools/htsjdk/issues/1117), and resulted in a downstream BCF issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5862:96,message,message,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862,2,['message'],['message']
Integrability,"There are several parts to this that all exist, but need to be committed in this order:. -Minor refactoring of CRAM container writing code in htsjdk to allow separation of the writing of CRAM containers from the writing of the CRAM file header, SAM file header, and EOF container for part-merging.; -Hadoop-BAM needs to go to Java8 and upgrade to newer htsjdk.; -Add CRAMOutputFormat, CRAMRecordWriter, etc. to Hadoop-BAM (these depend on the htsjdk code mentioned above).; -Modify ReadSparkSink to be CRAM aware.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1270#issuecomment-169339543:429,depend,depend,429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1270#issuecomment-169339543,1,['depend'],['depend']
Integrability,"There are tests for the CNV plotting tools, which use RScriptExecutor and uniquely require some of the R dependencies. There's also a test for the HMM code, which uses an HMM R package to generate expected results. I'd assume that tests for the other tools that use RScriptExecutor would also fail, but I don't know if they rely on any special dependencies or any particular version of R.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359102155:105,depend,dependencies,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359102155,2,['depend'],['dependencies']
Integrability,"There are two commits. The first one factores out code that can be shared between the R and Python executors, along with a few opportunistic changes in existing tests that have bad names. The second has a simple PythonScriptExecutor in the spirit of the RScriptExecutor, along with unit tests, and an example tool and integration test. First pass for https://github.com/broadinstitute/gatk/issues/3501.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3536:318,integrat,integration,318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3536,1,['integrat'],['integration']
Integrability,"There is GATK3 unit and integration test and could port them. BTW, I don't seen a VF unit test. I also looked at the GATK4 code an would expect the same problem would occur.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2301#issuecomment-265794458:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2301#issuecomment-265794458,1,['integrat'],['integration']
Integrability,"There is an existing NIO filesystem provider for Amazon S3 that has been used successfully with GATK4 by at least one user (with some minor tweaks to the engine). We should add the S3 plugin as a dependency, add basic tests for read support, and make whatever changes are needed to get it working.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3708:196,depend,dependency,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3708,1,['depend'],['dependency']
Integrability,"There is currently an issue with spark stderr output if running through the wrapper script, this is a workaround to that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4476:76,wrap,wrapper,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4476,1,['wrap'],['wrapper']
Integrability,"There is currently an issue with spark stderr output if running through the wrapper script, this should make it a little clearer what spark is doing after it finishes with the tools work.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4501:76,wrap,wrapper,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4501,1,['wrap'],['wrapper']
Integrability,"There is currently one failing integration test:. ```; completedicsdb.GenomicsDBImportIntegrationTest.testGenomicsDBImportFileInputsAgainstCombineGVCFWithMultipleIntervals FAILED; java.lang.AssertionError: actual is longer than expected with at least one additional element: [VC null @ chr20:17970000 Q. of type=SYMBOLIC alleles=[G*, <NON_REF>] attr={} GT=htsjdk.variant.bcf2.BCF2Codec$LazyData@134b79ab filters=; at org.testng.Assert.fail(Assert.java:93); at org.broadinstitute.hellbender.utils.test.BaseTest.assertCondition(BaseTest.java:395); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.lambda$checkGenomicsDBAgainstExpected$8(GenomicsDBImportIntegrationTest.java:326); at java.util.ArrayList.forEach(ArrayList.java:1249); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:319); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testGenomicsDBAgainstCombineGVCFs(GenomicsDBImportIntegrationTest.java:166); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testGenomicsDBImportFileInputsAgainstCombineGVCFWithMultipleIntervals(GenomicsDBImportIntegrationTest.java:107); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-386368519:31,integrat,integration,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-386368519,1,['integrat'],['integration']
Integrability,There is one test in ValidateSamFileIntegrationTest that is commented out since it depends on a change to htsjdk.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1084:83,depend,depends,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1084,1,['depend'],['depends']
Integrability,"There seems to be no obvious way to read thru the unmapped read pairs in a bam file in Spark. Looking at the code in ```ReadSparkSource#getParallelReads(String, String, List, long)``` it seems that ; perhaps it is possible by setting the appropriate property in Configuration returned by ```ctx.hadoopConfiguration()``` however there is no documentation as to what property that could be. . @droazen I assign it to you initially so that you route it to whoever might be most suited to address this issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2572:441,rout,route,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2572,1,['rout'],['route']
Integrability,"There were a couple of things I needed to do to get the new Spark code running on a cluster:. i. Go back to using Spark's version of Kryo. Using a different version of Kryo is not actually needed (2.21 used by Spark passes the tests), and actually caused errors on the cluster when run with `--conf spark.driver.userClassPathFirst=true` (which is needed to avoid other library conflicts, like with jopt-simple). ii. Exclude Spark from the JAR file to avoid library conflicts. It's normal to exclude Spark and Hadoop from JAR files since they are supplied by `spark-submit`. Since Gradle doesn't have a 'provided' dependency (see https://github.com/broadinstitute/hellbender/issues/836), I had to do a bit of a workaround with the `shadowJar` target, which is now `sparkJar`. . Here's the command I ran:. ``` bash; NAMENODE=...; SPARK_MASTER=yarn-client; HELLBENDER_HOME=...; spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ReadsPipelineSpark \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/spark-reads-pipeline \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --baseRecalibrationKnownVariants $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/882:613,depend,dependency,613,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/882,1,['depend'],['dependency']
Integrability,There were a few dead links in the GATK to http://gatkforums.broadinstitute.org/gatk/discussion/58/companion-utilities-reordersam which is still archived here: https://web.archive.org/web/20160720131152/http://gatkforums.broadinstitute.org/gatk/discussion/58/companion-utilities-reordersam. We should write a new short technical article here: https://gatk.broadinstitute.org/hc/en-us/sections/360007134392-Glossary preserving the knowledge about sort ordering and update the remaining two links in our error messages to be current with that.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8272:508,message,messages,508,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8272,1,['message'],['messages']
Integrability,"There were some good basic examples in the original ticket:. - get all the contiguously aligned reads (e.g, xxM); - get reads with soft clipping (e.g., xSxxM, could be reads with partial adapter sequence still left after trimming); - get reads with insertions (e.g., xxMxxIxxM, could be spliced reads, e.g., reads spanning exon-exon, or intron-intron junction); - get reads with deletions (g.g., xxMxxDxxM, could point at SV). Those would be the basic must-haves. Then the next step of nice-to-haves would be to be able to find specific patterns like ""D followed by I"" or specific numbers of operators like ""exactly five D in a row"" or ""five D in total, not necessarily in consecutive order"". Do you need me to be more specific than that?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/588#issuecomment-307890525:187,adapter,adapter,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/588#issuecomment-307890525,1,['adapter'],['adapter']
Integrability,"There's a big difference between picard-public and picard-private:; 1. Luckily Picard (the public part) is very stable and so new features/bugs are relatively rare. So I have no doubt we'll be able to backport fixes to Hellbender as needed. ; 2. Long term, yes, development of new features/tools that would previously go to Picard-public, will go to Hellbender. Again, that does not happen all that often because Picard-public is stable. . Picard-private is a very different beast and Hellbender is not touching that at all. The big unanswered question is, what happens to the picard/picard-private dependency. I suggest we can try the following cannibalistic approach to Picard-public: logically Picard-public has three parts (utilities, tools and the rest (command line parsing etc)).; a) parts of Picard-public that are generally useful utilities should be moved down to htsjdk.; b) tools from Picard-public will move to Hellbender and live there; c) what remains are things like commandline processing etc. That part can be moved over to picard private and live there (Hellbender will have its own cmd line processing, and it would not be desirable, at least initially, to make picard-private depend on hellbender).; At that point, all functionality from Picard-public will be somewhere else and so Picard-public will cease to exist as a separate entity and the public/private dependency will be obsolete. Adding @nh13 and @kcibul to the discussion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/125#issuecomment-73173623:599,depend,dependency,599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/125#issuecomment-73173623,3,['depend'],"['depend', 'dependency']"
Integrability,"These all sound like positive improvements. Provided they don't affect performance by dramatically increasing the number of discovered haplotypes, I'm on board. Hopefully this will go a long way towards removing the dependence of calling on the active region boundaries.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-447012273:216,depend,dependence,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-447012273,1,['depend'],['dependence']
Integrability,"These are a bunch of random, mostly just annoying things that I repeatedly encountered during the Java 17 port that we should look into. . **Log Spam Issues:** (these result in lots of error log spam that make the logs super hard to scan when there is a failure):. - The WDL test logs are riddled with “localization by hard link failed” and ""Docker not found"" failures, which makes it hard to scan them for real failures. Can we eliminate/fix these ?; - The logs have a few gradle task dependency warnings - we should hunt down the cause. ; - We routinely pull ~800 branches every time we run git clone for a CI job. Can we do shallow git clones?; - We're using deprecated gradle features that result in warnings in the logs, these should be updated.; - The test runner seems to serialize (via toString) every argument to every test method. Many of these have *huge* ""toString"" representations (i.e., `org.broadinstitute.hellbender.tools.spark.sv.integration.ExtractOriginalAlignmentRecordsByNameSparkIntegrationTest`) that fill the logs with reams of huge test values. We should codify/unify the test case wrapper class that we use in htsjdk for these cases. . **Other Issues:**. - We should review the shadowJar contents - it includes some surprising stuff (i.e., the publish-picard.sh script we use to publish picard).; - Do we still need the unpacktestjar task in `dockertest.gradle`, to work around testNG inability to find tests in a jar ?; - The test matrix job names all look the same in the github UI because only the first N characters are displayed, and they all have the same prefix. We should rename them so they start with unique prefixes.; - The library it.unimi.dsi:fastutil:7.0.61 appears to not be used [Fix] (reported in IntelliJ/Project Structure/Problems).; - It's non-intuitive that the *Dockerfile* builds the `run_unit_tests.sh` script. Is that necessary - can this not be built on demand ? Also, it should be named to run_tests.sh, since it doesn't run unit tests, but rather ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8087:486,depend,dependency,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8087,3,"['depend', 'integrat', 'rout']","['dependency', 'integration', 'routinely']"
Integrability,"These are changes we made in order to get the NeuralNetInference branch integration tests to pass, and some example program updates..",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4218:72,integrat,integration,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4218,1,['integrat'],['integration']
Integrability,"These are the changes needed to run on a whole genome in strict mode. We get out of memory errors without these changes. Reads downsampling was missing for the part where `AssemblyRegion`s are filled with reads - this PR adds it in. Downsampling is not deterministic yet, since that depends on #5437, but that's an orthogonal issue so it's OK to merge this change and add #5437 later.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5721:283,depend,depends,283,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5721,1,['depend'],['depends']
Integrability,"These codecs require a `GenomeLocParser` (and therefore a sequence dictionary), and so are currently broken in hellbender, which does not assume the presence of a sequence dictionary for Feature-containing files. We need to either refactor these codecs to not require a `GenomeLocParser` (and remove the `ReferenceDependentFeatureCodec` interface), or delete them if they are no longer needed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/234:337,interface,interface,337,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/234,1,['interface'],['interface']
Integrability,"These methods were showing up as time syncs on the profile for #5607 ; <img width=""982"" alt=""screen shot 2019-01-28 at 3 44 55 pm"" src=""https://user-images.githubusercontent.com/16102845/51868464-1e8b1a80-231c-11e9-8221-5424f31cbdde.png"">; <img width=""980"" alt=""screen shot 2019-01-28 at 3 44 41 pm"" src=""https://user-images.githubusercontent.com/16102845/51868479-2480fb80-231c-11e9-9e51-8f66d11e2244.png"">. I ran these a few times vs. its root branch, its probably a small improvement in runtime over this chr15 snippet of an exome on my local machine:; #5607:; ```; 2m57.516s, 2m56.677s, 3m2.531s, 3m4.116s; ```; This branch:; ```; 2m50.112s, 2m46.981s, 2m43.764s, 2m40.806s; ```. Depends On #5607",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5616:684,Depend,Depends,684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5616,1,['Depend'],['Depends']
Integrability,These should mirror existing `PrintReads` integration tests,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/675#issuecomment-122990499:42,integrat,integration,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/675#issuecomment-122990499,1,['integrat'],['integration']
Integrability,"They are retried. You're seeing this message because it failed more than `maxChannelReopens` times. The new version which you really want to use for any test at this point is described there:; https://github.com/broadinstitute/gatk/issues/2685#issuecomment-302798685. Among other things, this new version puts in a message about 'retry failed' when it runs out of retries to eliminate the very confusion that you ran into. GenomicsDBImport opens a large number of parallel connections and as a result is getting throttled fairly heavily (by the host GCE machine if nothing else). This results in timeouts and dropped connections. One way forward is to increase the retry delays, another is to find a way to do the same work with fewer parallel open connections.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-304123753:37,message,message,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-304123753,2,['message'],['message']
Integrability,They've been working as far as I know. Or at least I haven't gotten any; failure messages. That's why I closed the ticket.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2183#issuecomment-253016704:81,message,messages,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2183#issuecomment-253016704,1,['message'],['messages']
Integrability,"They've patched the warning message to be an info message instead, but I think it will still show a stacktrace since info is our standard level.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5220#issuecomment-426729414:28,message,message,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5220#issuecomment-426729414,2,['message'],['message']
Integrability,"This PR Modifies the GvsCreateVDS wdl to no longer store the values for 'yng_status' in the VDS. The field is still used to calculate filtering at the genotype level, but not stored after that. - Example run of GvsCreateVDS [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/e4e9905b-c967-4ced-9c02-41a3117eac84); - Passing integratino test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f6929247-1787-4ff7-b4f0-e367b0652ac8)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8861:365,integrat,integratino,365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8861,1,['integrat'],['integratino']
Integrability,"This PR addresses required changes in order to use latest version of GenomicsDB which exposes new functionality such as:; - [Multi interval import and query support](https://github.com/broadinstitute/gatk/issues/3269):; - We create multiple arrays (directories) in a single workspace - one per interval. So, if you wish to import intervals (""chr1"", [ 1, 100M ]) and (""chr2"", [ 1, 100M ]), you end up with 2 directories/arrays in the workspace with names chr1$1$100M and chr2$1$100M. The array names depend on the partition bounds.; - During the read phase, the user only supplies the workspace. The array names are obtained by scanning the entries in the workspace and reading the right arrays. For example, if you wish to read (""chr2"", [ 50, 50M] ), then only the second array is queried.; - In the previous version of the tool, the array name was a constant - _genomicsdb_array_. The new version will be backward compatible with respect to reads. Hence, if a directory named _genomicsdb_array_ is found in the workspace directory, it's passed as the array for the _GenomicsDBFeatureReader_ otherwise the array names are generated from the directory entry names.; - Parallel import based on chromosome intervals. The number of threads to use can be specified as an integer argument to the [executeImport call](https://github.com/francares/gatk/blob/fmc_GenomicsDB_parallel_import/src/main/java/org/broadinstitute/hellbender/tools/genomicsdb/GenomicsDBImport.java#L535). If no argument is specified, the number of threads is determined by Java's ForkJoinPool (typically equal to the \#cores in the system). ; - The max number of intervals to import in parallel can be controlled by the command line argument --max-num-intervals-to-import-in-parallel (default 1); - Note that increasing parallelism increases the number of FeatureReaders opened to feed data to the importer. So, if you are using _N_ threads and your batch size is _B_, you will have _N*B_ feature readers open.; - Protobuf based API fo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645:499,depend,depend,499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645,1,['depend'],['depend']
Integrability,"This PR adds a task to GvsAssignIds to verify that there are no duplicate sample names in the file provided. [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/af6651c5-37e1-48b6-8514-9c0d326dfc6f) is an example run of BulkIngest that replicates the original reported problem. No sample set provided, the sample id column is not sample_id and there's a duplicate in THAT column.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/25dc14df-c6e5-4710-b9b8-67b04906bc78) is an example run where the updated code runs and reports the problem early-ish without creating database tables that need to be cleaned up.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/b29d3eea-8330-4645-88fe-62bbf3b865bf) is a normal run that passes (same basic idea as the initial problem, except that I removed the duplicate row from the samples table. [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/82098882-8b57-4fe6-ad23-69963c3466f6) is a passing integration test.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8818:1086,integrat,integration,1086,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8818,1,['integrat'],['integration']
Integrability,This PR adds an integration test for Exomes.; It also adds an optional input to the test to allow you to use the default dockers (and NOT build the gatk override jar) if you so desire. Passing Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/e16edc16-92a7-4a52-834a-1b45e1a2f92c).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8433:16,integrat,integration,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8433,2,"['Integrat', 'integrat']","['Integration', 'integration']"
Integrability,"This PR adds segments VCF writing to `PostprocessGermlineCNVCalls`. Segmentation (Viterbi) and segment quality calculation are performed by `gcnvkernel`. This PR introduces the following additional features:; - Calls and model shards are not required to be provided in sorted order anymore; - The user can specify the ref copy-number state for autosomal contigs, as well as allosomal contigs; - For both intervals and segments VCF output: now we use either `<DUP>` or `<DEL>` alleles (in place of `CN_x` alleles), depending on whether the most likely copy-number call is below or above the ; contig baseline. The contig baseline state is whatever the user has specified for autosomal contigs, and the contig ploidy state on sex chromosomes (from the output of `DetermineGermlineContigPloidy`).; - Fail-fast validations and better test coverage; - Updated cohort and case WDL scripts and WDL tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4396:514,depend,depending,514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4396,1,['depend'],['depending']
Integrability,This PR adds sputnik CI https://sputnik.ci as a code reviewer on pull Reqs. I have configured it to use only FindBugs to limit messages to potentially useful ones. @droazen @lbergelson wdyt? we could give it a try and see if it helps us or annoys us.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1747:127,message,messages,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1747,1,['message'],['messages']
Integrability,"This PR adds the 'SCORE' field as an output in the VQSR-Lite derived VCFs; Score is the value from which the `CALIBRATION_SENSITIVITY` is derived. The latter is what we use for filtering based on sensitivity, but Sam and Laura also want the SCORE stored in the VCF. Passing Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/721bc470-a968-4fe4-9be3-a1ddddc9a792)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8423:274,Integrat,Integration,274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8423,1,['Integrat'],['Integration']
Integrability,"This PR allows the extract process to read ploidy information from an optional table and use it when writing out reference data. This code does NOT create that table. In the absence of such data, it will do nothing and behave like before (assuming a ploidy of 2 at all sites and expanding the reference data accordingly). Quickstart extract WITHOUT ploidy table specified:https://app.terra.bio/#workspaces/gvs-dev/GVS%20Tiny%20Quickstart%20hatcher/job_history/fcc47f3f-080c-41f3-9847-0dd1487ef39c. Quickstart extract WITH ploidy table specified: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Tiny%20Quickstart%20hatcher/job_history/2d608711-758f-47d2-ab54-ae825293e4a9. Successful integration run for verifying backwards compatibility: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/d30c9db9-bdeb-4ff7-a236-3d3078258d06. The ploidy table used was based on quickstart data, but had data for samples 5, 9, and 10 manually updated to haploid. This will produce a INCORRECT vcf, inasmuch as it will reflect a mismatch in ploidy between the variant and ref data. But it allows us to see that, when the table is specified, it does in fact use it for writing out the ref data. As expected, shards 0-21 are identical with the only changes being on shards 22 and 23, and with diffs of this form:. ```25106c25106; < chrX	2800975	.	C	CA	.	.	AC=2;AF=0.250;AN=8;AS_QUALapprox=0|108;CALIBRATION_SENSITIVITY=0.9621;QUALapprox=81;SCORE=-0.5449	GT:AD:GQ:RGQ	./.	./.	./.	./.	0/0:.:30	./.	0/0:.:30	0/1:8,3:27:27	./.	0/1:6,5:80:81; ---; > chrX	2800975	.	C	CA	.	.	AC=2;AF=0.286;AN=7;AS_QUALapprox=0|108;CALIBRATION_SENSITIVITY=0.9621;QUALapprox=81;SCORE=-0.5449	GT:AD:GQ:RGQ	./.	./.	./.	./.	0/0:.:30	./.	0:.:30	0/1:8,3:27:27	./.	0/1:6,5:80:81; 25122c25122; < chrX	2805509	.	C	T	.	.	AC=1;AF=0.100;AN=10;AS_QUALapprox=0|360;CALIBRATION_SENSITIVITY=0.8769;QUALapprox=360;SCORE=-0.4865	GT:AD:GQ:RGQ	0/0:.:30	./.	./.	./.	./.	0/0:.:20	0/0:.:30	0/1:14,13:99:360	0/0:.:30	./.; ---; > chrX	2805509	.	C	T	",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8857:683,integrat,integration,683,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8857,1,['integrat'],['integration']
Integrability,"This PR creates a tool for generating split read and paired end SV evidence files from an input WGS CRAM or BAM file for use in the GATK-SV pipeline. This tool emulates the behavior of `svtk collect-pesr`, which is the tool used in the current version of the pipeline. Briefly, it creates two tab-delimited, tabix-able output files. The first stores information about discordant read pairs -- the positions and orientations of a read and its mate, for each read pair marked ""not properly paired"" in the input file. Records are reported only for the upstream read in the pair. The second file contains the locations of all soft clips in the input file, including the coordinate and ""direction"" (right or left clipping) and the count of the number of reads clipped at that position and direction. The integration test expected results file was generated using `svtk collect-pesr` to help ensure that the results are identical. We hope to eventually replace this component of the SV pipeline with this GATK tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6356:799,integrat,integration,799,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6356,1,['integrat'],['integration']
Integrability,"This PR deals with the test failures that were occurring when we ran ALL chromosomes through the integration test, rather than just chr20 and X and Y (the default). It adds another truth set for all chromosomes.; Also two small changes.; - Skip the cost/table size check for the Hail integration, to allow it to get to the hail part if there are spurious test failures in cost.; - Change the name of the files used for table size and cost checking. Makes it easier to install new test data. Passing integration test on all chromosomes [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/d8837252-26fa-4d40-bdf1-e42ff8932fd1); Passing integration test on chr20/x/y [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f552e7a3-d245-492d-b5e1-a35ba323fae8).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8787:97,integrat,integration,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8787,4,['integrat'],['integration']
Integrability,This PR expands the GermlineCNVCaller integration test suite and addresses #6893 and #4375. The tests that were added are: . - Numerical accuracy test that checks for changes of gCNV model posterior values as compared to a previously computed model. This test is meant to detect Python library updates that affect gCNV results and unintentional consequences of minor gCNV model changes.; - A test that runs gCNV in the COHORT mode with a pre-trained model as a starting point.; - A test that runs gCNV with an annotated intervals file that contain GC content column. As @samuelklee suggested we should consider adding functionality to the GermlineCNVCallerIntegrationTest to regenerate test files when there is a discrepancy in gCNV model outputs and we are okay with that discrepancy. See example of it in the HaplotypeCallerSparkIntegrationTest class -- specifically note UPDATE_EXACT_MATCH_EXPECTED_OUTPUTS flag. @mwalker174 let me know what you think.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7889:38,integrat,integration,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7889,1,['integrat'],['integration']
Integrability,"This PR fixes a bug I found in testing. I was extracting all the samples for an Exome run and it was widely scattered. So there occurred a situation where there no VET entries in one of the shards and a NPE happened.; This PR fixes that and makes it tool generate an empty (well, has a header) VCF, which the GVS workflow can handle. Failing workflow showing the problem [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Data%2049k/job_history/9f821329-f2bd-487c-a9af-4a81d0716072). Passing workflow (after the fix) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Data%2049k/job_history/52ecbbaa-199d-413b-95fe-2a3285462b43); Passing Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/a2f67baa-9613-4c4e-be3b-85a1b25a3b3b)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8388:662,Integrat,Integration,662,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8388,1,['Integrat'],['Integration']
Integrability,"This PR fixes two bugs. First, the SplitIntervals task would enter WeightedSplitIntervals and hang. I added an extra boolean argument to extract so you can specify that no, you really don't want to use a weighted bed. Relatedly, the code branch for running the original GATK SplitIntervals code wasn't correct, as passing weight-bed-file to it as an argument caused a failure. It uses a slightly hacky method of defining a string in WDL to be empty or not depending on if we use weighted beds, interpolating that string into the bash, then checking to see if it's empty there to transmit that state. There is likely a cleaner way to do this, and in the next revision I will likely rewrite this part cleaner. Second, after SplitIntervals passed we hit an error during ExtractTask. The way it expanded intervals to handle large deletions could sometimes subtract past the start of a chromosome, so that logic needed to be patched in a few separate places to handle the interval for the mitochondrial dna that started much closer to the beginning (instead of having a 10k base pair buffer). This PR has those changes too. Successful run here: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Test/job_history/a006a959-9300-42cf-84a7-38c70a35ee21. Successful run after incorporating PR changes: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Test/job_history/e2ee3abd-288e-4f1d-b5be-f78cf5400ce9. Successful run after last PR refactoring that allowed me to revert almost all changes to GvsUtils.SplitIntervals: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Test/job_history/94fed63a-98ca-466e-8d4c-ac97f24adf37",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8113:456,depend,depending,456,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8113,1,['depend'],['depending']
Integrability,"This PR is a replacement for https://github.com/broadinstitute/gatk/pull/5055 (includes the cherry-picked commit with the tests from that PR), and a fix for https://github.com/broadinstitute/hdf5-java-bindings/issues/11. I implemented this in GATK rather than in hdf5-java-bindings because we need a version that does not depend on (throw) if the hdf5 library is not supported on the current platform.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5082:322,depend,depend,322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5082,1,['depend'],['depend']
Integrability,"This PR is dependent on https://github.com/broadinstitute/gatk/pull/4571, which in turn will require https://github.com/broadinstitute/gatk/pull/7021, plus one additional PR to change all of the tests to use the new variant compare methods.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-754923888:11,depend,dependent,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-754923888,1,['depend'],['dependent']
Integrability,"This PR is intended to introduce several new tools related to the CleanVcf workflow in GATK-SV, which the use of these tools being documented in https://github.com/broadinstitute/gatk-sv/pull/733. These tools are intended to introduce several enhancements over the existing implementation, including but not limited to:; - Introduce various unit and integration tests into the workflow.; - Create more robust and generalizable tools that can be used independent of _CleanVcf_.; - Improve runtime and execution speed by leveraging Java.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8996:350,integrat,integration,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8996,1,['integrat'],['integration']
Integrability,"This PR is the initial stage of implementing the calling of IMPRECISE variants in the SV pipeline. It introduces the concept of an evidence-target link, which joins an evidence interval to its distal target. This is an extension of the 'coherent' evidence concept previously used in determining evidence thresholds for assembly. The code in this PR contains the following changes:. - Evidence intervals and distal targets now are treated as stranded, and evidence-target link clustering depends on overlaps between both intervals and strands.; - Evidence target interval and distal target interval calculations have been modified to make sure that evidence supporting the same event clusters together (has overlapping intervals). This includes several changes such as extending the 'rest-of-fragment-size' calculation to try to capture almost all non-outlier fragment sizes in the library; increasing the split read location uncertainty a little; and being more precise about the boundaries of distal target intervals by taking advantage of information in the MD and MC tags if available.; - Evidence target links are gathered for every piece of evidence supporting a high-quality distal target. ; - Evidence target links are clustered together and store the amount of split-read and read-pair evidence that went into each cluster.; - All evidence target link clusters that are composed of at least 1 split read or at least 2 read pairs are collected in the driver and emitted in a BEDPE formatted file specified in the command line parameters.; - A `PairedStrandedIntervalTree` data structure is introduced to allow `SVIntervalTree`-style lookups for paired intervals. To finish this work, future PRs will 1) use the collected evidence target links to annotate our assembly called-variants with the number of split reads and read pairs observed in the original mappings and 2) create IMPRECISE VCF records for events that have enough evidence-target-link support, first for deletions and then possibl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3469:487,depend,depends,487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469,1,['depend'],['depends']
Integrability,"This PR makes two changes to Mutect2's filtering. 1. The first change updates `Math.min` to `Math.max` in `applyFiltersAndAccumulateOutputStats()`, which is probably the intended behavior. Unfortunately, this update breaks some of the integration tests at `org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModelIntegrationTest.testOnRealBam`. I'm not quite sure how the dev team would prefer to handle the failed tests, so I thought I'd raise the issue here. 2. In `StrictStrandBiasFilter`, the argument `minReadsOnEachStrand` is not used in the `areAllelesArtifacts()` function. The second update turns on the `minReadsOnEachStrand` argument rather than using the default of 0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6903:235,integrat,integration,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6903,1,['integrat'],['integration']
Integrability,This PR modifies the behavior of GvsExtractToPgen to no-call any filtered genotypes; It also allows one to run GvsExtractCallset so that VCFs generated by it also have no-called GTs.; I also took the liberty of renaming 'VQSR Classic' to 'VQSR' and 'VQSR Lite' to 'VETS' in much of the Java code. Passing Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/1e1ed014-47cf-4c95-96f4-5c1284fc4616); Run of tie out pgen to VCF with no-called GTs [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/9e78f44a-f531-450b-acd8-db66cc6454be).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8793:305,Integrat,Integration,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8793,1,['Integrat'],['Integration']
Integrability,"This PR reimplements the overlap detector used in WeighedSplitIntervals in a much faster form for our particular use case. It also involved preprocessing the weighted bed input file in a new way, so the previous weights files will no longer work. As such, there's a new weights file uploaded and referred to as part of this pr. I pulled down the documentation and rationale for the original process from the git issue to a markdown file that can live in our repo, and made python scripts out of the necessary bits of python logic there (as well as a new one to do the further preprocessing step that I added). The motivation for this was the inability of the previous WeightedSplitIntervals task to complete when run against an exome interval list. This new one does, and it does so quickly. The link referenced below is not a ""successful"" run in the Terra sense because it was 190k exomes and that was simply too much for Terra to handle, but it DOES show a successful WeightedSplitIntervals run before the real extract started and I believe that is sufficient to merge. Delaying while ticket VS-189 gets figured out will create an unnecessary delay. Successful integration run: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/294fd6a8-15ed-4722-a63e-bdf089c1c52a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8507:1163,integrat,integration,1163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8507,1,['integrat'],['integration']
Integrability,"This PR updates the Freemarker templates so that the resulting pages will work with the current state of the website code. Most of the changes have to do with functionality I put in to enable hosting multiple doc versions and easy switching between them via a dropdown menu. . I had already done some retrofitting on older tooldocs so the versioned tool docs go back to 3.5, and we can add beta versions of 4 without changing the ""latest supported version"". . The only remaining problem is that I couldn't figure out how to output php instead of html. To test the web integration, I just renamed all *.html to *.php with `for f in *.html; do mv -- ""$f"" ""${f%.html}.php""; done` but that doesn't take care of internal links, which are of course broken as a result. @cmnbroad please let me know if I missed something obvious on this front ^^. . That being said this PR is fully functional as far as I'm concerned.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3165:568,integrat,integration,568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3165,1,['integrat'],['integration']
Integrability,"This `DS` annotation has been kicking around in the header for a long time, but I've never seen it in the wild. It doesn't show up in any of our integration tests. We only have the ability to add this annotation if the GenotypingEngine gets a non-null `Map<String, AlignmentContext> stratifiedContexts`, but that doesn't seem to be the case in *_any_* of our tests. Maybe it's a holdover from UnifiedGenotyper?. @davidbenjamin have you seen cases where we `calculateGenotypes` with stratifiedContexts (or refContext or rawContext or likelihoods)? Given that there's zero test coverage, how would you feel about ripping it out and seeing if anyone complains?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5678:145,integrat,integration,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5678,1,['integrat'],['integration']
Integrability,"This addresses issues #5568 and #5342.; #5568 Buffer resize messages are now turned on only for Debug builds.; #5342: Added better general error reporting for system commands. For the file synching error in question, implemented a workaround. With environment variable - TILEDB_DISABLE_FILE_LOCKING - set to true or 1, there is no file locking and file synching error will only log warning messages and not return an error. Hopefully, this will mitigate the issues on NFS and CIFS.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5608:60,message,messages,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5608,2,['message'],['messages']
Integrability,This addresses the problem where serialized GMMs for VQSR assumed the annotation order would be the same between the commands that generated them and the commands that used them. VQSR no longer depends on the commandline order of the annotations.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3655:194,depend,depends,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3655,1,['depend'],['depends']
Integrability,This adds a new message to the StreamingProcessController ack FIFO protocol to allow additional message detail to be passed as part of a negative ack. Fixes https://github.com/broadinstitute/gatk/issues/5100.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5170:16,message,message,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5170,3,"['message', 'protocol']","['message', 'protocol']"
Integrability,"This adds a small test case for the WDL of the filtering pipeline. This still has indels and snps separated out. I can combine them if needed, but we'd like to use different annotations for each mode. This also doesn't actually apply the final filtering (with a threshold) since we still need to add a step to determine the correct threshold. The final VCFs from this workflow should have SCORE INFO annotations for each site. This takes in an array of VCFs (and outputs an array of VCFs) because this is an option for large callsets in the WARP joint genotyping WDL which is where this WDL will eventually be integrated. This test only ensures that the WDL runs and doesn't compare to expected results (the same as the other WDL tests in this repo).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7932:610,integrat,integrated,610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7932,1,['integrat'],['integrated']
Integrability,"This applies to projects that import the GATK jar as part of the build process, but are not part of the GATK itself. All unit and integration tests are (by default) broken, since the BaseTest class requires the mini fasta, even when it should not be required. This causes breakage, since a project built on the GATK should not be expected to have that file at the exact correct place in the filesystem. The tests do not even start.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3029:130,integrat,integration,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029,1,['integrat'],['integration']
Integrability,This branch does 2 things. ; 1. It makes ProgressMeter async #; 2. It makes ProgressMeter and interface so it could be made more flexible for non-locatables. This could be a first step to making it more flexible for https://github.com/broadinstitute/gatk/issues/6390 and https://github.com/broadinstitute/gatk/issues/5178,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6484:94,interface,interface,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6484,1,['interface'],['interface']
Integrability,"This branch is almost in a merge-able state -- comments have been addressed, we now have continuous tests showing 99%+ concordance with GATK 3.4, and we are about twice as fast in GVCF mode. The only remaining holdup is two integration tests that are failing due to slight precision issues/jitter in the QUAL field (possibly due to the native PairHMM). While I work on this final issue, I'll open a separate PR for the pieces of this branch outside of the `haplotypecaller` package itself.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1567#issuecomment-210654632:224,integrat,integration,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1567#issuecomment-210654632,1,['integrat'],['integration']
Integrability,"This branch takes the version of gatk-public that gatk-protected currently depends on (4.alpha.2-188-g7332d10) and applies @davidbenjamin 's fix to the `TandemRepeat` annotation to it. The only purpose of this PR is to cause a snapshot to be generated -- do not merge!. This is necessary to unblock @davidbenjamin 's work, because the `HaplotypeCaller` tests are failing if we update protected to the latest public head, and although we've fixed some of the issues there are some unexplained failures in the concordance tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2569:75,depend,depends,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2569,1,['depend'],['depends']
Integrability,"This bumped some transitive dependencies which required a minor update in unrelated classes. We shouldn't merge this until we get a 👍 from the SV team as well as running the jenkins spark tests. I think the SV team is already using 2.2.0 since they've gone to dataproc image 1.2. This will prevent the annoying adam log spam, closes #4186 ; closes #2555",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4314:28,depend,dependencies,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4314,1,['depend'],['dependencies']
Integrability,"This came up on PR #6351 after a rebase. The branch passes all tests locally (verified on my laptop and on @cmnbroad's) but fails `DocumentationGenerationIntegrationTest.documentationSmokeTest` in the docker integration CI job on Java 8 but not Java 11. The same test passed locally for me even after verifying Java 8 was enabled, refreshing the gradle project, rebasing again etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991:208,integrat,integration,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991,1,['integrat'],['integration']
Integrability,"This can be closed as Picard is pull-out as a dependency, no @droazen?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1636#issuecomment-336917081:46,depend,dependency,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1636#issuecomment-336917081,1,['depend'],['dependency']
Integrability,"This can improve some build configurations for GATK (ony noted the ones in 4.6, but not previos ones):. * `failFast` property for test tasks. This would be useful for PRs; * Declare reasons for dependency resolution rules and constraint dependencies. This could be useful for explaining why some dependencies are not the latest (e.g., protobuf).; * Allow options in the command line. This could be nice for the doc generation.; * Default jacoco is 0.8.0, which improves the coverage report by filtering out some empty constructors",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4659:194,depend,dependency,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4659,3,['depend'],"['dependencies', 'dependency']"
Integrability,"This can occur in cases where there was a mixup with the samples, meaning the user intended to run a properly matched normal/tumor pair, but there is a provenance error. This is how @asmoe4 and myself hit this issue. So this is not the same use case as #5821, where they know there's a deliberate mismatch. While we're not expecting the contamination check to provide something sensible in this case, may I suggest that the tool provides a user-friendly message to help debug, rather than a stack traceback. This could happen to other people if they have an accidental mismatch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483276300:454,message,message,454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483276300,1,['message'],['message']
Integrability,This causes integration tests to fail.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4839:12,integrat,integration,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4839,1,['integrat'],['integration']
Integrability,"This change enables SAMRecordToGATKReadAdapterSerializer, which has been in the codebase for a while now, just not explicitly enabled. We've been using it for manual testing and haven't seen any problems with it. All unit tests pass. The performance improvement is striking: running mark duplicates locally went from ~120s to ~36s (https://github.com/broadinstitute/gatk/issues/1047). In terms of the change this makes, it means that the header is not present on SAMRecord, but since operations on reads go through the GATKRead interface (which does not need the header), the change is safe. Note also that SAMRecordToGATKReadAdapterSerializer explicitly serializes the reference name (and the mate reference name) so that the round trip serialization/deserialization works.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1127:528,interface,interface,528,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1127,1,['interface'],['interface']
Integrability,This change is dependent on [this recent change](https://github.com/samtools/htsjdk/commit/4f550e1f1afabf21467957fa672ca2a4ad457897#diff-b678735810949d4263df7bd0fffdecb8L42) in htsjdk (and the build will fail without it). Once htsjdk2.0 is available we'll upgrade it in this branch/pr so the two changes can go in together.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1243:15,depend,dependent,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1243,1,['depend'],['dependent']
Integrability,"This change suppresses about 600k of output from the gatkTabComplete task, which should fix #3710 and allow the nightly cron job to complete. Note that this doesn't actually suppress the excessive ""backtrace"" messages we're seeing with the addition of Picard tools when running javadoc using openjdk (see the note in #3710), which we'll need to do separately in Barclay. To test this change, I added a temporary travis matrix entry that runs the target that is causing the cron job to fail (./gradlew bundle). That branch [fails](https://travis-ci.org/broadinstitute/gatk/builds/289636845) the same way as the cron job does without this change, and [succeeds](https://travis-ci.org/broadinstitute/gatk/builds/289569595) with it. But that doesn't guaranty that the cron job will succeed, since cron job does other things (like upload). Finally, note that the gatkDoc gradle task was also setting the verbose flag, but it didn't actually result in verbose output due to gradle/gradle#2354, so I removed that call in this PR as well.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3715:209,message,messages,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3715,1,['message'],['messages']
Integrability,This changes all doubles in CNV TSV output and most logging messages to be formatted as `%.6f`. Closes #4148. I will regenerate test files to appear consistent with the new formatting when I address #4007 in a later PR.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4149:60,message,messages,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4149,1,['message'],['messages']
Integrability,"This class was created to provided for a need to keep a sorted (by location) set of targets. However there is nothing in it that could not really be applied to any locatable in general. . As a matter of fact now I find myself in a situation in where I need the same functionality for a different subclass of Locatables, TargetCollection (and its implementations) have the functionality I need but using TargetCollection looks ugly due to its name and its methods names. The task is the to rename TargetCollection<T> to LocatableCollection<L> and accordingly replace 'target' in methods names for something else (either locatable or a generic name such 'elements'). . Also I recently noticed the existence of IntervalsSkipList which could be an additional implementation for TargetCollection (or rather the new LocatableCollection). So perhaps as part of this task we could unified the skip-list and the hash based solutions under a single common interface.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1538:946,interface,interface,946,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1538,1,['interface'],['interface']
Integrability,"This code wraps around BaseRecalibrator and presents a very basic interface (set up, add reads, teardown) that's going to be used at each Dataflow worker. Challenges here:; (1) I need to convert the intervals to Features because that's what the BaseRecalibrator class uses, and SimpleInterval is not a subclass of Feature. This may change in the future.; (2) BaseRecalibrator takes Features as inputs - the only simple Feature class I found I could reuse is ArtificialTestFeature. Please let me know if there is a better choice (solving (1) also solves this); (3) I didn't find code to test overlap between a SimpleInterval and a Feature. Rather than roll my own I chose to use the SimpleInterval overlap test and convert to Feature lazily instead of eagerly. This may cause an interval to be converted more than once. So please consider this the start of a discussion on ""here is something that works, but surely there's a better way?"" I'm not so much looking for every performance opportunity, but ideally I'd like to avoid using ArtificialTestFeature if a better candidate is available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/511:10,wrap,wraps,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511,2,"['interface', 'wrap']","['interface', 'wraps']"
Integrability,"This comes _extremely_ close to what I was looking for. But handling the parts that are expected to be common and those that are expected to be unique in the same way makes it very difficult for us to answer the core question that this is trying to answer: did these two samples have ""the same"" header in a meaningful way?. If you can add another column that is a flag to the vcf_header_lines table or something that allows you to mark whether or not an entry is sample-specific or common, that seems like it would be the fasted route between what is implemented here and easily answering the question we want to be able to ask. You'll likely need to keep the common and unique lines separate in processing to achieve that, though",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8321#issuecomment-1550079308:529,rout,route,529,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8321#issuecomment-1550079308,1,['rout'],['route']
Integrability,"This could either be implemented by making the default dataflow runner depend on a system property, and not specifying any runner in the tests, or by having tests authors explicitly specify a new `TestLocal` or `TestRemote` runner for their tests as appropriate.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/561:71,depend,depend,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/561,1,['depend'],['depend']
Integrability,This depends on https://github.com/HadoopGenomics/Hadoop-BAM/issues/71 (PR in https://github.com/HadoopGenomics/Hadoop-BAM/pull/81).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1651#issuecomment-205753754:5,depend,depends,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1651#issuecomment-205753754,1,['depend'],['depends']
Integrability,This depends on https://github.com/HadoopGenomics/Hadoop-BAM/pull/70.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1650#issuecomment-202794951:5,depend,depends,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1650#issuecomment-202794951,1,['depend'],['depends']
Integrability,"This doesn't fix the integration test, but a bug in GvsBulkIngest",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8736:21,integrat,integration,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8736,1,['integrat'],['integration']
Integrability,"This entails moving all dataflow code to hellbender-dataflow and mininimizing other dependencies. Ideally, up to the point of dropping from the buildscript.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/954:84,depend,dependencies,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/954,1,['depend'],['dependencies']
Integrability,"This error message is related to GATK's ability to load files on Google buckets (""gcs://bucket/file.bam""). This ability is enabled even when running locally (this aspect is intentional, because it's useful to be able to run a local GATK instance to process remote data without having to fire up a VM). As the bucket-reading code (""NIO"") initializes, it looks for credentials to use. Those can be set via an environment variable or via `gcloud auth`, as described in GATK's README. If neither of these are set, it checks whether it's currently running in a Google virtual machine (so it can figure out who owns the virtual machine that it's running on, and use those credentials). Apparently this code throws an exception if it runs out of ways to find credentials, and our code prints it out and moves on. The message is useful, for if we *were* running in a google VM and the credential-finding failed, we'd certainly like to know. Whether we need the full stack trace, now, that's a choice we have to make.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095:11,message,message,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095,2,['message'],['message']
Integrability,"This error message occurs when removing the network when running GATK in a docker container. GATK tools still run to completion, but the error message is disruptive. ; ```; $> docker run --rm --network none broadinstitute/gatk gatk -version. 2022-08-03 20:37:23,349 main ERROR Could not determine local host name java.net.UnknownHostException: de2c81c88ddc: de2c81c88ddc: Temporary failure in name resolution; at java.net.InetAddress.getLocalHost(InetAddress.java:1506); at org.apache.logging.log4j.core.util.NetUtils.getLocalHostname(NetUtils.java:54); at org.apache.logging.log4j.core.LoggerContext.lambda$setConfiguration$0(LoggerContext.java:620); at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660); at org.apache.logging.log4j.core.LoggerContext.setConfiguration(LoggerContext.java:620); at org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:699); at org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:716); at org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:270); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:155); at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:47); at org.apache.logging.log4j.LogManager.getContext(LogManager.java:196); at org.apache.logging.log4j.LogManager.getLogger(LogManager.java:599); at org.broadinstitute.hellbender.utils.Utils.<clinit>(Utils.java:72); at org.broadinstitute.hellbender.Main.<clinit>(Main.java:45); Caused by: java.net.UnknownHostException: de2c81c88ddc: Temporary failure in name resolution; at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method); at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:929); at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1324); at java.net.InetAddress.getLocalHost(InetAddress.java:1501); ...13 more. The Genome Analysis Toolkit (GATK) v4.2.6.1; HTSJDK Version: 2.24.1; Picard Ver",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7983:11,message,message,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7983,2,['message'],['message']
Integrability,"This error was reported by a user: . Dear GATK Team, . I am writing you to discuss a an error while using FilterMutectCalls program and it seems a potential bug. ; I wanted to change the default value of **--normal-p-value-threshold **. It looks like the tool doesn't accept this parameter at all. I tried using it with the default value of 0.001 as well. . The program works fine when this parameter is removed. Moreover, the error message also states that **BUG: couldn't set field value** . please see the attached command and the error message. . ** gatk FilterMutectCalls -V TAR-158_unfiltered.vcf.gz --normal-p-value-threshold 0.0001 -R ../data/hg_ref/genome.fa --contamination-table TAR-158_tumor_calculatecontamination.table -O TAR-158_artifact_0.01.vcf.gz**. Using GATK jar /mnt/gpfs1/lmod/apps/gatk/4.1.1.0/gatk-package-4.1.1.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /mnt/gpfs1/lmod/apps/gatk/4.1.1.0/gatk-package-4.1.1.0-local.jar FilterMutectCalls -V TAR-158_unfiltered.vcf.gz --normal-p-value-threshold 0.0001 -R ../data/hg_ref/genome.fa --contamination-table TAR-158_tumor_calculatecontamination.table -O TAR-158_artifact_0.01.vcf.gz; org.broadinstitute.barclay.argparser.CommandLineException$ShouldNeverReachHereException: **BUG: couldn't set field value. For normalPileupPValueThreshold in org.broadinstitute.hellbender.tools.walkers.mutect.filtering.M2FiltersArgumentCollection@69d45cca with value 1.0E-4 This shouldn't happen since we setAccessible(true)**; 	at org.broadinstitute.barclay.argparser.CommandLineArgumentParser$ArgumentDefinition.setFieldValue(CommandLineArgumentParser.java:1248); 	at org.broadinstitute.barclay.argparser.CommandLineArgumentParser.setArgument(CommandLineArgumentParser.java:710); 	at org.broadinstitute.barclay.argparser.CommandLineArgumentParser.parseArguments(CommandLineArgumentParser.java:427); 	at o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5978:433,message,message,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5978,2,['message'],['message']
Integrability,This fix is now in a numbered build 4.9-beta at maven central so we don't have an awkward snapshot dependency,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/170#issuecomment-73538926:99,depend,dependency,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/170#issuecomment-73538926,1,['depend'],['dependency']
Integrability,"This handles the case we saw in Shriner's beta files where variants on chrX (and presumably chrY) were represented with a call_GT of ""1."". NOTE: SOME of these changes fixed our code to work for any ploidy, but others only changed our pipeline to work for examples with a ploidy of 1. Specifically, the changes made to . `scripts/variantstore/wdl/extract/populate_alt_allele_table.py` and ; `src/main/resources/org/broadinstitute/hellbender/tools/gvs/filtering/feature_extract.sql`. have made it work for haploid and diploid values, but we'd need to generalize the code that explicitly lists the potential values for GT. Given that we're not seeing cases with a ploidy above 2 yet, doing that can be for a later ticket. Doc with steps I went through to test this:; https://docs.google.com/document/d/1F194j7OQh9ehs5pSdt5yHcsSWrm3WmqDlVVkDFkULuw/edit#heading=h.464spie271ew. Successful extract here:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Tiny%20Quickstart%20hatcher/job_history/a7cc6ffb-fd98-4142-a211-8235dea10b35. Successful integration run here:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/8d09d70e-a6f3-42a8-9c81-95065c653f4d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8334:1036,integrat,integration,1036,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8334,1,['integrat'],['integration']
Integrability,This has partially been handled by JP already :) with his `AuthHolder` class. The only missing piece is removing our dependance on `GCSOptions.Methods.createGCSAuth(options)` by instead calling the create auth stuff directly.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/963#issuecomment-149386222:117,depend,dependance,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/963#issuecomment-149386222,1,['depend'],['dependance']
Integrability,"This includes the fix for the position overflowing in CloudStorageReadChannel; (https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2283), as well; as the fix for the intermittent 503 errors we've already been depending on; (https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2281)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3373:220,depend,depending,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3373,1,['depend'],['depending']
Integrability,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/443:14,wrap,wrappers,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443,1,['wrap'],['wrappers']
Integrability,"This introduces a feature for `GenomicsDBImport` that allows merging multiple contigs into fewer genomicsdb partitions. This should give a huge boost for cases where users have a very large number of contigs (see [here ](https://gatk.broadinstitute.org/hc/en-us/community/posts/360060623952-GenomicsDBImport-very-slow-on-genome-with-many-contigs), for instance). Currently, GenomicsDB would create a separate folder/partition for each contig and this slows down import to a crawl with a large number of contigs. . To use this feature, users should set the flag `--merge-contigs-into-num-partitions` to the number of partitions. Using the feature requires that entire contigs be passed as input intervals -- we don't support merging together an interval list that contains partial contigs. . There's no magic threshold where this would start to be useful - we currently warn users when they specify more than 100 intervals, and I think the same threshold makes sense for when they should consider using this flag. Choosing the right value for `--merge-contigs-into-num-partitions` would be dependent on amount of parallelism users want to use (for example, do they want to want to import using `max-num-intervals-to-import-in-parallel`). If no parallelism is envisioned either on import or query, setting `--merge-contigs-into-num-partitions` to `1` should work as well -- though the user may find it more reassuring to break up the work into more partitions just so you can see some progress being made....",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6681:1089,depend,dependent,1089,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6681,1,['depend'],['dependent']
Integrability,"This is a checkpoint PR for https://github.com/broadinstitute/gatk/issues/1237 and https://github.com/broadinstitute/gatk/issues/1643. This is the first step in refactoring metrics collectors so they can be pipelined in Spark and reuse RDDs, but still share metrics computation code between walker and Spark versions. The next step will be to extend MultilevelCollector to be able to merge its own instances in order to support efficient map and reduce phases for multi level collectors. Suggested review order:. -MetricsCollectorSpark: interface to be implemented by all Spark collectors; -MetricsArgs:base class for all collector argument sets; -MetricsCollectorToolSpark: base class for all Spark metrics collector tools; -CollectQualityYieldMetrics: Spark version of QualityYieldMetrics using these new interfaces; -CollectInsertSizeMetricsSpark: existing Spark version of InsertSizeMetrics collector ported; to these interfaces; -CollectMultipleMetricsSpark: Spark version of CollectMultipleMetrics; currently only works; on QualityYieldMetrics and InsertSizeMetrics. The rest of the PR is refactoring existing to get QualityYieldMetrics and InsertSizeMetrics to conform to these interfaces (moving CollectInsertSizeMetrics out of the sv package and Program Groups, etc.). Note that the existing InsertSizeMetrics Spark collector doesn’t really share code with the walker; version (and their command line param sets are way out of sync) but this should be fixed separately from these changes as the interfaces evolve.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1827:537,interface,interface,537,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1827,5,['interface'],"['interface', 'interfaces']"
Integrability,"This is a fix for a ticket that was originally logged against a Spark tool that no longer exists (CompareBaseQualitiesSpark), so I added missing reference tests to PrintReads spark and walker versions. Note that Picard tools (such as CompareBaseQualities) still have the ugly error message originally reported since they open their input files manually.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1614#issuecomment-224052022:282,message,message,282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1614#issuecomment-224052022,1,['message'],['message']
Integrability,"This is a patch to fix the integration test that is broken in the EchoCallset.; There was refactoring done on GvsExtractAvroFilesForHail (in the EchoCallset branch) that has broken the inputs to the integration test on that branch. ; I'm not sure this is the perfect solution, but I'd like to get it merged into EchoCallset so we can unify EchoCallset and ah_var_store",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8737:27,integrat,integration,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8737,2,['integrat'],['integration']
Integrability,"This is a problem with your `R` environment -- you need to install the `gplots` package (amongst a few others, if you don't already have them). From https://gatk.broadinstitute.org/hc/en-us/articles/360035889531-What-are-the-requirements-for-running-GATK-; ```; R dependencies; Some of the GATK tools produce plots using R, so if you want to get the plots you'll need to have R and Rscript installed, as well as these R libraries: gsalib, ggplot2, reshape, gplots,; ```. Here's a quick article on installing packages in R if you're unfamiliar (https://www.r-bloggers.com/2010/11/installing-r-packages/). Note, you'll need a version of R that is compatible with these packages",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7006#issuecomment-770272506:264,depend,dependencies,264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006#issuecomment-770272506,1,['depend'],['dependencies']
Integrability,"This is a very minimal change of the testing framework to allow users of the framework to use `IntegrationTestSpec` with their own classes. It solves the problem of a custom `Main` class to run the command line test in programs using the framework (through overriding default behavior), and the loading of `GenomeLocParser` by the `BaseTest` if the test is simply extending `CommandLineProgramTest`. More details for this issue in #2033. Now API users could implements and modify default behavior of `CommandLineProgramTestInterface` and use this test classes in `IntegrationTestSpec`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122:95,Integrat,IntegrationTestSpec,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122,2,['Integrat'],['IntegrationTestSpec']
Integrability,"This is an experiment to see if it's possible to run BWA-MEM on Spark. (Please don't merge.) The basic idea is that it uses JNI to call BWA-MEM's align function to align a batch of read pairs in one go. I think it should complement the work that @SHuang-Broad has been doing in #1701. It would be great to get your (and @akiezun's) feedback on the direction here. A few comments; - Building the native libraries is not integrated, and it's not using the Apache 2 licensed code. I think this could use some of the changes in #1701.; - The ref is assumed to be on the local FS for the moment - it should really be loaded from HDFS. Also, the output is a single SAM file on the local FS, not a sharded BAM as for the rest of the GATK Spark tools.; - It is assumed that read pairs are interleaved and reads in a pair are placed in the same split (by setting `hadoopbam.bam.keep-paired-reads-together`). However, that property only works for queryname sorted BAMs, which isn't the case here, so we need to relax that requirement in Hadoop-BAM.; - I haven't tried this on large inputs, so I don't know how well it performs. To run, I used the following on a cluster. ```; ./gatk-launch BwaSpark \; --ref /home/tom/workspace/jbwa/test/ref.fa \; --input hdfs:///user/$USER/bwa/R.bam \; --output /tmp/bwa.sam \; -- \; --sparkRunner SPARK --sparkMaster yarn-client \; --driver-memory 3G \; --num-executors 1 \; --executor-cores 1 \; --executor-memory 3G \; --archives jbwa-native.tar#jbwa-native \; --conf 'spark.executor.extraLibraryPath=jbwa-native'; ```. The interesting bit is the use of Spark's `--archives` flag to copy a tarball of native libraries (which I built manually) to every executor, and unpacks it in the working directory. Then `spark.executor.extraLibraryPath` is set to add that path to the library path of the executor. This means that you don't have to rely on the native libraries being installed on every node in the cluster.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1750:419,integrat,integrated,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1750,1,['integrat'],['integrated']
Integrability,"This is based on @davidadamsphd's initial work to port mark duplicates to Spark. It's not finished yet, but I wanted to post this for discussion. In particular 7 of the 56 mark duplicates integration tests are failing with ""Cannot get mate information for an unpaired read"" - I'm not sure how to address that. I'd appreciate some help on this one. The code currently has four shuffles: one groupBy in transformFragments (in MarkDuplicatesSparkUtils), two groupBys in transformReads, and one combine (foldByKey) in generateMetrics. The combine is more efficient than the others since it can run on the map side, reducing the amount of data that goes through the shuffle. I think it may be possible to merge the processing of the fragments and the reads to eliminate a shuffle - so there are only two shuffles for the main transform. A fragment would be represented as a pair with an empty second slot, so it can be handed in the processing separately from the true pairs that have both slots filled.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/889:188,integrat,integration,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/889,1,['integrat'],['integration']
Integrability,This is important -- nothing is more infuriating than generic/cryptic error messages. Let's do it for alpha-1.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/575#issuecomment-169133377:76,message,messages,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/575#issuecomment-169133377,1,['message'],['messages']
Integrability,"This is not ready for merge -- I just want to see if tests pass with this configuration. There are still some unresolved vulnerabilities:. ```; [1/7] - pkg:maven/com.google.protobuf/protobuf-java@4.0.0-rc-2 - 3 vulnerabilities found!; [2/7] - pkg:maven/log4j/log4j@1.2.17 - 6 vulnerabilities found!; [3/7] - pkg:maven/org.codehaus.janino/janino@3.1.9 - 1 vulnerability found!; [4/7] - pkg:maven/net.minidev/json-smart@2.4.7 - 1 vulnerability found!; [5/7] - pkg:maven/org.codehaus.jettison/jettison@1.1 - 3 vulnerabilities found!; [6/7] - pkg:maven/org.eclipse.jetty/jetty-util@9.4.48.v20220622 - 1 vulnerability found!; [7/7] - pkg:maven/org.eclipse.jetty/jetty-http@9.4.48.v20220622 - 1 vulnerability found!; ```. Some of these we may be unable to resolve. Eg., the `protobuf-java` version in this branch appears to be the most recent one, but still has open vulnerabilities filed against it. The ancient log4j 1.x version is used by two of our dependencies (`hdf5-java-bindings` and `spark-mllib_2.12`), and is the most recent version. Note that this is completely unrelated to the infamous log4j 2.x vulnerability, which was patched in GATK a long time ago.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8352#issuecomment-1581408853:947,depend,dependencies,947,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8352#issuecomment-1581408853,1,['depend'],['dependencies']
Integrability,"This is now an update to htsjdk 2.4.1 rather than 2.4.0. I had to disable the `IntelDeflater` in htsjdk for now until `intel-gkl` is on maven central, since we can't release htsjdk to maven with a dependency that's not in central. . _facepalm_",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1867#issuecomment-222276209:197,depend,dependency,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1867#issuecomment-222276209,1,['depend'],['dependency']
Integrability,"This is rebased off of https://github.com/broadinstitute/gatk/pull/3716, since it depends on code there. Hence, only the second commit needs to be reviewed in this PR. The code and tests are quite similar to that for PlotSegmentedCopyRatio/PlotACNVResults. However, I've changed the R scripts to be more efficient (WGS plots no longer take several hours). Furthermore, PlotModeledSegments is more flexible than PlotACNVResults in that it plots CR, AF, or both on the fly depending on the available inputs. I've also added some more input validation, changed some terminology, and moved over to data.table for reading TSVs in R.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3729:82,depend,depends,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3729,2,['depend'],"['depending', 'depends']"
Integrability,"This is resolved -- we are going to take in the Picard tools as a dependency, and refactor both projects to depend on a shared arg parsing/documentation system (https://github.com/broadinstitute/barclay).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1210#issuecomment-265904560:66,depend,dependency,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1210#issuecomment-265904560,2,['depend'],"['depend', 'dependency']"
Integrability,"This is super interesting - the Java 11 integration tests that are failing in this last run are exactly the same tests that have been problematic on the Java 17 branch. I looked at the failing values that were being produced on that branch (which we've updated), and they're identical to the failing values seen here. Even on the Java 17 branch, there has been some inconsistency in the failures (they usually fail, but not always).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8102#issuecomment-1329162240:40,integrat,integration,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8102#issuecomment-1329162240,1,['integrat'],['integration']
Integrability,This is very important for integration tests. Not being able to use large files is significantly slowing porting of existing tools to hellbender. Maybe this will work https://git-lfs.github.com/ maybe something else.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/388:27,integrat,integration,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/388,1,['integrat'],['integration']
Integrability,"This issue has come up during my work on #6634 and has resulted in the decision to introduce a new argument to GATK `--use-original-alignments-for-genotyping-overlap` in order to better match DRAGEN for concordance. Reads in the GATK undergo a number of modifications before they are used for genotyping that I have listed down below. (Note: between each of these steps some reads get lost to various filtering code and this is not an exhaustive list). 1. Reads undergo modification in `AssemblyBasedCallerUtils.finalizeRegion()` where the reads have their soft-clipped bases reverted, low quality ends removed, mate overlapping base qualities modified, and overhangs outside of the active region removed. Then these reads are used for assembly to discover haplotypes. ; 2. Once we have discovered haplotypes the whole assembly region (reads, haplotypes and all) gets trimmed down to a smaller span that ~overlaps the variants discovered the haplotypes plus either 75+ or 20 bases of padding depending on what type of events are seen. ; 3. These clipped reads (with reads below 10 bases in length being removed) have their base qualities farther modified in `PairHMMLikelihoodCalculationEngine.createQualityModifiedRead()` in various ways. This modification does not stick however since the base qualities are all modified on a clean partial copy of the read.; 4. Following this the reads (the ones from step 2) are realigned to the reference according to their best haplotypes. Sometimes this means as few as 11 bases of ""read"" are being realigned at this stage. . It is these realigned reads that are used for genotyping, where the only reads that are actually used to contribute likelihoods for calls are reads that overlap the variant event within 2 bases of overlap on either side. In DRAGEN they do something different that we had to replicate to achieve concordance. Dragen still performs equivalent modifications for steps 1-3 as they apply to the reads but rather than performing step 4 and u",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6706:992,depend,depending,992,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6706,1,['depend'],['depending']
Integrability,This just needs to be wrapped in a `UserException`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1290#issuecomment-163299119:22,wrap,wrapped,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1290#issuecomment-163299119,1,['wrap'],['wrapped']
Integrability,This last set of changes is dependent on https://github.com/broadinstitute/barclay/pull/17. Once that's reviewed we'll need to snapshot or release and upgrade to Barclay.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-271290203:28,depend,dependent,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-271290203,1,['depend'],['dependent']
Integrability,"This likely has to do with your spark configuration. Check on the Spark job's progress through the web interface, which should be something like http://<driver_address>:4040 (see https://spark.apache.org/docs/latest/monitoring.html). . If your BAM is very small, you can also try increasing the number of partitions by reducing --bamPartitionSize.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932:103,interface,interface,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932,1,['interface'],['interface']
Integrability,This list of dependencies was generated by running `$ conda env export` on the nightly docker image `broadinstitute/gatk-nightly:2022-04-17-4.2.6.1-3-g0f6ca4f14-NIGHTLY-SNAPSHOT`. Resolves #7800,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7801:13,depend,dependencies,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7801,1,['depend'],['dependencies']
Integrability,"This looks good, and we should continue to dig into the integration tests. Back to @jamesemery",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2021#issuecomment-234068629:56,integrat,integration,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2021#issuecomment-234068629,1,['integrat'],['integration']
Integrability,This makes the Docker container more interoperable with other GATK containers that might not install to /gatk,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3866:37,interoperab,interoperable,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3866,1,['interoperab'],['interoperable']
Integrability,This method (validateSequenceDictionaries) in GATKTool needs to be modified so that the vcf file names associated with each sequence dictionary are passed into validateDictionaries() to make error messages more useful.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/660:197,message,messages,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/660,1,['message'],['messages']
Integrability,"This method is for unit/integration testing purposes only, and should not be called from tools.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4430:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4430,1,['integrat'],['integration']
Integrability,"This moves us to a snapshot of google-cloud-java based off of a branch in my fork here: https://github.com/droazen/google-cloud-java/tree/dr_retry_CloudStorageReadChannel_fetchSize. This patch wraps many more operations within retries, and in our tests resolves the intermittent 503/SSL errors completely when running at scale. This PR also migrates us from setting retry settings per-Path to setting it globally, using a new API from that google-cloud-java branch. This fixes an issue where the number of reopens was getting set to 0 deep in the google-cloud-java library. Resolves #2749; Resolves #2685; Resolves #3118; Resolves #3120; Resolves #3253",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3295:193,wrap,wraps,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3295,1,['wrap'],['wraps']
Integrability,"This occurs when there is an issue with the coding sequence for a given transcript in Gencode. It's a problem with the Gencode data itself. I would prefer to keep as an error so the user is more likely to see it. There is some work to be done here, though - the error message should also contain a description of an exception that was caught to produce this log statement.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4882#issuecomment-396389331:268,message,message,268,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4882#issuecomment-396389331,1,['message'],['message']
Integrability,"This one is no longer valid, since we've added `-L unmapped` support and the original error message has been removed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1309#issuecomment-227477439:92,message,message,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1309#issuecomment-227477439,1,['message'],['message']
Integrability,This or these tool would be use to use piece meal bam files that we can use for local (laptop/desktop) development and integration tests. The input would be SV called variant VCF with and two intervals lists. The first one would indicate for what variants in input we want to gather the evidence reads and the second the supported reference interval in the output (anything outside that interval will be changed to unmapped). The second interval list must include the first interval list since otherwise it would not make any sense.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2504:119,integrat,integration,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2504,1,['integrat'],['integration']
Integrability,"This problem happens with the IndexFactory [methods](https://github.com/samtools/htsjdk/blob/912c28bec415c430b43515652ccaf13222b07e7b/src/main/java/htsjdk/tribble/index/IndexFactory.java#L285) that take a file. When an index is created this way, the first feature that gets returned by the [FeatureIterator](https://github.com/samtools/htsjdk/blob/912c28bec415c430b43515652ccaf13222b07e7b/src/main/java/htsjdk/tribble/index/IndexFactory.java#L401) and handed to the [indexer](https://github.com/samtools/htsjdk/blob/912c28bec415c430b43515652ccaf13222b07e7b/src/main/java/htsjdk/tribble/index/IndexFactory.java#L352) always has it's file offset as 0, even if its actually offset by a header. Whether or not the bogus index that gets generated actually works is dependent on the size of the header. When the index is created on the fly (while writing the file), the offsets are correct. The BED file issue is a slightly different problem (its first feature actually IS at offset 0), but the first feature is never returned.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2801#issuecomment-306678058:760,depend,dependent,760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2801#issuecomment-306678058,1,['depend'],['dependent']
Integrability,"This pull request updates the environment to include `pytorch` to gatk conda environment. This required an update to numpy and consequently updates of PyMC3 and its dependencies, as well as parts of gCNV code.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8094:165,depend,dependencies,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8094,1,['depend'],['dependencies']
Integrability,"This really should be integrated with all the tests in GATKReadAdaptersUnitTest (currently its only integrated with the toString test), once it has equals, copy, deepCopy, getSAMString implementations, and can update its backing record,etc. Also, the sparkReadAdapter(final AlignmentRecord record) overload fails since the AlignmentRecordConverter always tries to dereference the (null) header that is passed in from that code path.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1189#issuecomment-159674555:22,integrat,integrated,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1189#issuecomment-159674555,2,['integrat'],['integrated']
Integrability,This release also errors out with a descriptive error message if the length of a field in the data lines does not match the length descriptor in the header - see https://github.com/broadinstitute/gatk/issues/5045.; Error out behavior as per [Laura's comment here](https://github.com/broadinstitute/gatk/issues/5113#issuecomment-413667356),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5397#issuecomment-437140783:54,message,message,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5397#issuecomment-437140783,1,['message'],['message']
Integrability,This removes some symlinks that were checked into git-lfs and puts them back into normal git. It stops lfs from outputting failure messages on checkout.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5229:131,message,messages,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5229,1,['message'],['messages']
Integrability,"This request removes all calls to getChr() in the code by replacing calls to getChr() with calls to getContig() and removing a redundant assertion that contains a call to getChr(). To complete the removal of getChr() from the code, we could:. Remove the getChr() method overrides in the TableFeature and ArtificialTestFeature classes and convert these classes from implementing the Feature interface to implementing the Locatable interface. Remove the definition of the Feature interface from htsjdk.tribble (since all Feature does is add getChr() to the Locatable interface), and replace all references to the Feature interface in the tools and libraries with references to the Locatable interface. These steps will also remove the deprecation warnings for getChr() (part of #377).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/478:390,interface,interface,390,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/478,6,['interface'],['interface']
Integrability,"This request was created from a contribution made by ABours on May 29, 2020 18:23 UTC. Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360067695771-GenotypeGvcfs-has-formatting-issues-in-both-v4-1-6-0-as-v4-1-7-0. --. Hi,. I'm using v4.1.6.0 of GenotypeGvcfs to make a vcf, out of whole genome data from 19 samples (following your recommendations). When I run ValidateVariants to check the output of GenotypeGvcfs I get a error message, which states that one or more of the ALT allele are actually not in the samples provided. A previous user already found a similar error in ValidateVariants (https://gatk.broadinstitute.org/hc/en-us/community/posts/360061452132-GATK4-RNAseq-short-variant-discovery-SNPs-Indels-), but then for Haplotypecaller, and you have opened a bugreport to add a feature to ValidateVariants: https://github.com/broadinstitute/gatk/issues/6553. However, it would be nice if you could actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: on",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:443,message,message,443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['message'],['message']
Integrability,"This request was created from a contribution made by Min-Hwan Sohn on March 05, 2020 01:00 UTC. Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360057956031-PathseqPipelineSpark-stop-with-error-message-regarding-com-esotericsoftware-kryo-KryoException-Buffer-underflow-. --. Hi GATK team. I recently used PathseqPipelineSpark embedded in GATK v4.1.4.1 (installed from anaconda) to identify potential microbial composition of human tissue Whole-Genome samples. . NovaSeq-sequenced paired-end reads (2X151bp) were aligned (onto hg19 reference), duplicate-removed, base quality score-recalibrated and BQSR-applied, which eventually used as an input to the PathseqPipelineSpark. . Since I failed to find hg19 host reference in the GATK resource bundle, first I created a BWA image file and a Kmer file originated from hg19 reference fasta with the command below. But for microbe-related files, I used ones that were contained in the bundle.  . **'''** ; ; **gatk --java-options ""-Xmx50G"" BwaMemIndexImageCreator -I ./ref.fasta** ; **gatk --java-options ""-Xmx50G"" PathSeqBuildKmers --reference ./ref.fasta -O ref.hss** ; ; **'''**.  . And then I ran PathSeq with the following command.  . **'''** ; ; **gatk --java-options ""-Xmx200G"" PathSeqPipelineSpark \** ; **--input sample.bam \** ; **--filter-bwa-image ref.fasta.img \** ; **--kmer-file ref.hss \** ; **--is-host-aligned true \** ; **--min-clipped-read-length 70 \** ; **--microbe-fasta pathseq\_microbe.fa \** ; **--microbe-bwa-image pathseq\_microbe.fa.img \** ; **--taxonomy-file pathseq\_taxonomy.db \** ; **--output sample.pathseq.bam \** ; **--scores-output sample.pathseq.txt** ; ; ; **'''**.  . and unfortunately it was shut down by this error message. **09:27:43.974 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/mnt/clinix1/Analysis/mongol/phenomata/Tools/Anaconda3/envs/gatk4/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so** ; **Mar 05, 2020 9:27",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:209,message,message-regarding-com-esotericsoftware-kryo-KryoException-Buffer-underflow,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['message'],['message-regarding-com-esotericsoftware-kryo-KryoException-Buffer-underflow']
Integrability,"This request was created from a contribution made by tc on February 09, 2022 17:49 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4418364848795-java-lang-IllegalArgumentException-Invalid-interval-in-FuncotateSegments](https://gatk.broadinstitute.org/hc/en-us/community/posts/4418364848795-java-lang-IllegalArgumentException-Invalid-interval-in-FuncotateSegments). \--. Hi,. I tried to annotated a called segment file after following the somatic CNV detection workflow of GATK:. gatk --java-options ""-Xmx10g -Djava.io.tmpdir=/lscratch/$SLURM\_JOBID"" FuncotateSegments \\ ; ; \--data-sources-path funcotator\_dataSources.v1.7.20200521s/ \\ ; ; \--ref-version hg19 \\ ; ; \--output-file-format SEG \\ ; ; \-R hs37d5.fa \\ ; ; \--segments sample.called.seg \\ ; ; \-O sample.seg.funcotated.tsv \\ ; ; \--transcript-list funcotator\_dataSources.v1.7.20200521s/transcriptList.exact\_uniprot\_matches.AKT1\_CRLF2\_FGFR1.txt. But I got the following error message:. 12:37:55.534 INFO  FuncotateSegments - The following datasources support funcotation on segments:  ; ; 12:37:55.535 INFO  FuncotateSegments -  Gencode 34 CANONICAL ; ; 12:37:55.542 INFO  FuncotatorEngine - VCF sequence dictionary detected as B37 in HG19 annotation mode.  Performing conversion. ; ; 12:37:55.542 WARN  FuncotatorEngine - WARNING: You are using B37 as a reference.  Funcotator will convert your variants to GRCh37, and this will be fine in the vast majority of cases.  There MAY be some errors (e.g. in the Y chromosome, but possibly in other places as well) due to changes between the two references. ; ; 12:37:55.679 INFO  ProgressMeter - Starting traversal ; ; 12:37:55.679 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Features Processed  Features/Minute ; ; 12:37:56.198 WARN  FuncotatorUtils - Reference allele is different than the reference coding sequence (strand: -, alt = G, ref G != T reference coding seq) @\[chr1:13839497\]!  Substituting given allele for sequence code (TTC-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7676:970,message,message,970,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7676,1,['message'],['message']
Integrability,"This requires an upgrade to Hadoop-BAM the next time its released in order to pick up [this commit](https://github.com/HadoopGenomics/Hadoop-BAM/commit/85222f0d56f5a4294ff8fdff84c87b74b99413fc), plus changes in GATK to pass the validation stringency through. I have the necessary changes to GATK, but can't commit them as is because they're intertwined with other changes necessary for https://github.com/broadinstitute/gatk/issues/1346, which are in turn dependent on [other changes](https://github.com/cmnbroad/Hadoop-BAM/commit/07fc5560c2fabfab8c2d8344489efc47996cc597) that are not yet merged into Hadoop-BAM. They could be separated but hopefully will not have to be,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1261#issuecomment-172041451:456,depend,dependent,456,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1261#issuecomment-172041451,1,['depend'],['dependent']
Integrability,This reverts commit 8a366c7ba570c61338f7109b86c3284b80d5cf47. We noticed a major performance regression in `BaseRecalibratorSpark` and `HaplotypeCallerSpark` after we upgraded our ADAM dependency (see https://github.com/broadinstitute/gatk/issues/4376). This PR reverts that upgrade for now until we understand the underlying cause.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4428:185,depend,dependency,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4428,1,['depend'],['dependency']
Integrability,"This seems like a compiler bug to me. It only produces a warning on some machines, and we're not sure which ones. It runs fine on travis which is running ubuntu 16.04 I think, and it runs fine on OSX. I'm not sure if producing the warning is the bug, or not producing the warning, but there's definitely a bug somewhere in one instance of the compiler. . You'll notice that the code it's referring to in the error message is NOT the code that's causing the issue, which is another manifestation of it's bugginess.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360212288:414,message,message,414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360212288,1,['message'],['message']
Integrability,"This seems like a lot of machinery (introducing two new types and a new method) just to hide the config file argument. What if we just mark it `@Hidden` (I know thats prohibited, but this is kind of a special case). The only reason it even exists is because we wanted it to appear in the command lines we display on output and embed in output files. If its `@Hidden` it will still be reflected there when it's used, but it wouldn't be displayed in tool help/usage. Its already always displayed in help as an arg for the gatk wrapper.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371570897:525,wrap,wrapper,525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371570897,1,['wrap'],['wrapper']
Integrability,"This seems to be a simple typo. The minimal data to calculate the segmentation cost should be `2 * windowSize`, rather than `windowSize`, as the error message indicates. In the current logic, the segmentation cost at a particular point is calculated as the difference between the sum of costs of two windows to the left and right of that point and the cost of a big window of size `2 * windowSize`. If the # of the data points is less than the `2 * windowSize`, the cost for the full window will be wrong in the circular buffer representation; it will get the wrong cost of a window of size `2 * windowSize - data_size`, instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6835:151,message,message,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6835,1,['message'],['message']
Integrability,"This seems to be caused by an incompatible minor update of a transitive dependency called typing_extensions that is installed as part of pymc3. . The maintainers say that their release shouldn't be picked up by package managers because it contains an instruction to only be used in 3.7+. Our version of conda is picking it up anyway though and apparently doesn't understand their package files. . It's possible upgrading the conda version in the base docker will fix this problem, but as far as I can tell we're using the most recent release of miniconda that supports python 3.6. . Ideally we can peg the version of typing_extensions to 4.1.1 somehow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7800#issuecomment-1104432972:72,depend,dependency,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7800#issuecomment-1104432972,1,['depend'],['dependency']
Integrability,"This set of optimizations brings the GATK4 HaplotypeCaller performance into line; with GATK3.x performance. Note that HaplotypeCallerSpark is not touched by this PR (that is for a future PR). Summary of changes:. * AssemblyRegionWalker: query all intervals on each contig simultaneously, rather than individually; * GATKRead: Cache adaptor boundary, soft start/end, and cigar length; * GATKRead: add getBasesNoCopy() / getBaseQualitiesNoCopy(); * ReadPileup: speed up stratified constructor; * LIBS.lazyLoadNextAlignmentContext(): don't keep pileup elements unnecessarily separated by sample during pileup creation; * Restore faster GATK3 version of ReferenceConfidenceModel.sumMismatchingQualities(); * RefVsAnyResult: nest within ReferenceConfidenceModel, and allow direct field access; * Remove redundant getBases() call in ReadThreadingGraph; * Fix BaseGraph Utils.validateArg() call; * ReadPileup: replace Collections.unmodifiableList(pileupElements).iterator() with direct return of an iterator that forbids removal; * Kill expensive bounds checking in GATKRead getBase()/getBaseQuality()/getCigarElement(); * Kill nonNull checks in PileupElement; * Kill expensive PileupElement and ReadPileup arg validation; * GATKRead adapter: clear cached values upon mutation",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4031:1227,adapter,adapter,1227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4031,1,['adapter'],['adapter']
Integrability,"This should be doable, if not in the integration test framework, then in the new testing framework @KevinCLydon is working on.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6013#issuecomment-581493620:37,integrat,integration,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6013#issuecomment-581493620,1,['integrat'],['integration']
Integrability,This should be done after #5688 does in. Some Mutect2 integration tests should be deleted once this is done.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5763:54,integrat,integration,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5763,1,['integrat'],['integration']
Integrability,This should be fixed in the next release as we are now on Picard 2.25.4 in master via #7255. If you need a docker build with an updated picard dependency I would suggest checking out our nightly builds gs://gatk-nightly-builds which should have an up-to-date version of master soon or simply waiting for the next release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7254#issuecomment-841405791:143,depend,dependency,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7254#issuecomment-841405791,1,['depend'],['dependency']
Integrability,This should be in the [gatk-bwamem-jni](https://github.com/broadinstitute/gatk-bwamem-jni) dependency. Maybe the artifact is not correctly packaged...but it is in the [gradle.build](https://github.com/broadinstitute/gatk/blob/master/build.gradle#L198)...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-311602501:91,depend,dependency,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-311602501,1,['depend'],['dependency']
Integrability,"This should fix the travis failure by forcing lfs to overwrite the existing commit hooks. The issue seems to be this:. We install lfs in the first part of the travis build, and then we run a docker build and mount the git folder into it. Docker then installs lfs again. The problem is occurring because git lfs 3.1.1 which released 2 days ago changed the format of the pre-push and other git hooks. Then it throws an error when it's installed again and there are hooks that look different than it expects already in place. Running install with `--force` fixes it. The lfs devs actually have a system for ignoring these differences, but they forgot to update their list of allowed differences ( or however they match it) in 3.1.1. They then released 3.1.2 today which fixes this. In most cases this would fix the issue, except the git-lfs installed INSIDE the docker image is on an ancient version and never updates since the ancient image ubuntu is pegged to an out of date one. While the one in travis outside of docker gets updated to the most recent one. So we have to manually force this. We should probably also update our ubuntu image to a newer one. Of note, we don't actually NEED lfs in the docker for the tests at all, since we've already downloaded the files outside of docker and are mounting them in. Here's a passing build where I remove it https://app.travis-ci.com/github/broadinstitute/gatk/builds/246595037. I'm afraid though that some other system depends on it so I don't want to change it. . Rebasing on this should fix the stuck branches. @droazen @jonn-smith @ldgauthier @jamesemery",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7682:1467,depend,depends,1467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7682,1,['depend'],['depends']
Integrability,This should use allele fraction to identify the neutral state. @MartonKN already has a python prototype. We need to wrap this in Java and evaluate.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4115:116,wrap,wrap,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4115,1,['wrap'],['wrap']
Integrability,"This sounds like a good idea, but it might be tricky because much of the file reading is likely done by native code that we're just wrapping. We could do something like automatically downloading and caching the file locally and handing the cached version to the native library. Would that suit your needs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3178#issuecomment-314147710:132,wrap,wrapping,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3178#issuecomment-314147710,1,['wrap'],['wrapping']
Integrability,This sounds like the EAMS filter that is implemented in Picard picard/illumina/parser/BclParser.java . The purpose of this filter is to convert the ends of reads for which the quality has deteriorated and convert them to 2. This used to be a filter that illumina ran on their data as they converted to fasta but since we wanted to convert BCL directly to bam we implemented this in our code-base. I'm not sure why it is in GATK (perhaps one could look in the commit message) as it doesn't seem to be needed given the current pipeline.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/263#issuecomment-94432699:466,message,message,466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/263#issuecomment-94432699,1,['message'],['message']
Integrability,"This ticket set out to do VS-962 (one FOFN to rule them all) only, but along the way I found I also needed to do VS-984 (use Bulk Ingest from integration test) as the interface to `GvsAssignIds` had changed. After making these changes I realized I had basically done VS-982 as well (use Bulk Ingest in Beta WDL) due to the beta WDL picking up the changes to the unified WDL both it and Quickstart call. - [Successful integration run](https://job-manager.dsde-prod.broadinstitute.org/jobs/ab07dffd-a2ea-4b69-9c4c-eec0019e5b3b); - [Pending beta run](https://job-manager.dsde-prod.broadinstitute.org/jobs/37f6be29-5aae-42c4-a86b-c6d00c3caec5)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404:142,integrat,integration,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404,3,"['integrat', 'interface']","['integration', 'interface']"
Integrability,"This ticket was intended as a spike but in the process of spiking I was able to create a peer Hail VDS integration test to the VCF integration test. This seems like a viable candidate for Q4 MVP so putting it out for review as is. This creates a separate integration test for AoU Delta-style Hail VDS outputs with a tieout to regular GVS VCFs. The existing `GvsQuickstartIntegration` WDL has become an ""uber"" integration WDL that by default runs both the VCF and Hail VDS integration tests, but these can be toggled on or off separately with optional boolean inputs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8086:103,integrat,integration,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8086,5,['integrat'],['integration']
Integrability,"This tool copies single large files or directories from GCS into HDFS using Spark. Spark parallelization allows each task to copy a chunk in the size of the blocks of the target HDFS system simultaneously. When copying a directory containing a 120GB WGS bam and its index, this takes approximately 1 minute on a 10 worker / 160 core cluster, as opposed to approximately 20 minutes using Hadoop distcp. This may eventually be superseded by the NIO GCS integration work if that ends up performing comparably. @lbergelson would you like to review? Or feel free to nominate someone else.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2540:451,integrat,integration,451,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2540,1,['integrat'],['integration']
Integrability,"This tool should be a ReadWalker, but because of the way it uses the reference it may require a bit of refactoring to port it to the ReadWalker interface.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/123:144,interface,interface,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/123,1,['interface'],['interface']
Integrability,"This user was getting a 'java.lang.IllegalArgumentException: Dictionary cannot have size zero' error message when they submitted a VCF as the -I input instead of a BAM. It would save other users a lot of troubleshooting if we added a check and a better error message. This request was created from a contribution made by Ruiqiao Bai on September 12, 2021 01:06 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4406653433499-Why-do-I-get-java-lang-IllegalArgumentException-Dictionary-cannot-have-size-zero-when-using-GetPileupSummaries-](https://gatk.broadinstitute.org/hc/en-us/community/posts/4406653433499-Why-do-I-get-java-lang-IllegalArgumentException-Dictionary-cannot-have-size-zero-when-using-GetPileupSummaries-). \--. Hi! I am using GATK4 following the tutorial \[(How to) Call somatic mutations using GATK4 Mutect2 – GATK (broadinstitute.org)\](/hc/en-us/articles/360035531132--How-to-Call-somatic-mutations-using-GATK4-Mutect2) for detecting somatic variants. I have received an error when using GetPileupSummaries. Specifically, the command line I used is: . gatk GetPileupSummaries -I /gatk/my\_data/wgs\_BAM/step1\_1/unfiltered\_LP6005115-DNA\_B07.vcf -L /gatk/my\_data/wgs\_processing\_facilitating\_data/hg38\_to\_hg19/lifted\_small\_exac\_common\_3.hg19.vcf.gz -V /gatk/my\_data/wgs\_processing\_facilitating\_data/hg38\_to\_hg19/lifted\_small\_exac\_common\_3.hg19.vcf.gz -O /gatk/my\_data/wgs\_BAM/step1\_3/getpileupsummaries\_LP6005115-DNA\_B07.table. The entire error log has been pasted below. May I know what might cause this problem? Thanks for your help!. Using GATK jar /gatk/gatk-package-4.2.0.0-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_s amtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_leve l=2 -jar /gatk/gatk-package-4.2.0.0-local.jar GetPileupSummaries -I /gatk/my\_dat a/wgs\_BAM/step1\_1/unfiltered\_LP6005115-DNA\_B07.vcf -L /gatk/my\_data/wgs\_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7479:101,message,message,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7479,2,['message'],['message']
Integrability,"This was a quick job, I think more than anything it highlighted that we are missing many features in spark as of right now. . Depends On #5416",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5451:126,Depend,Depends,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5451,1,['Depend'],['Depends']
Integrability,This was evil and insidious and we should probably file a spark bug to produce a better error message...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-296821517:94,message,message,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-296821517,1,['message'],['message']
Integrability,This will prevent any accidental collision with the version on which Picard depends.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4557:76,depend,depends,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4557,1,['depend'],['depends']
Integrability,Those warning messages are totally fine. Not all variant contexts contain those 2 annotations therefore they are not counted against those sites but other parameters are counted. The results also shows that your filtering is working and variants are marked as expected.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8964#issuecomment-2312156979:14,message,messages,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8964#issuecomment-2312156979,1,['message'],['messages']
Integrability,"ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.TaskSetManager: Task 284 in stage 25.0 failed 4 times; aborting job; 18/01/12 20:38:37 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@23007ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(50,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(52,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(34,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(60,WrappedArray()); 20:38:37.897 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [January 12, 2018 8:38:37 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 42.74 minutes.; Runtime.totalMemory()=16692805632; org.apache.spark.SparkException: Job aborted due to stage failure: Task 284 in stage 25.0 failed 4 times, most recent failure: Lost task 284.3 in stage 25.0 (TID 43224, cw-test-w-6.c.broad-dsde-methods.internal, executor 7): java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.ContigAlignmentsModifier.removeOverlap(ContigAlignmentsModifier.j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:5885,Wrap,WrappedArray,5885,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['Wrap'],['WrappedArray']
Integrability,"Three major changes here.; 1. Added in logic to create the ploidy table during ingest (with necessary supporting class) and use it during extract automatically as part of the default joint workflow. Also removed a column that we won't need when creating it automatically.; 2. Rearranged the PAR checking logic to consolidate it in its own class (PloidyUtils.java). Successful run against tiny sample set ""PLOIDY_TEST"" in echo callset project:. https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20WGS%20Echo%20Callset%20v2/job_history/a93aa2ef-9cef-451d-8cf8-b31f1c6a8407. You'll need your aou credentials to see the results. Successful integration run on XY:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/6a9a5fdf-ffaa-4dcb-af73-56a4b25e69a4. This run shows all of the OTHER integration tests running successfully except BGE, due to the test data needing an updates for BGE X and Y:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/21664810-7516-49f2-a60c-51b2e05faf06. The only difference between those two tests running was an update to the expected values for integration tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8994:650,integrat,integration,650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8994,3,['integrat'],['integration']
Integrability,Throttling integration test [VS-1076],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8545:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8545,1,['integrat'],['integration']
Integrability,"To add some commentary to why this is happening: It looks like multiple threads are hitting this line simultaneously and based on the overload of `ArrayList.add()` this error could be triggered by multiple calls to `ensureCapacityInternal()` inside the add method:; ```; final List<ReadsPathDataSource> readSources = new ArrayList<>(threads);; final ThreadLocal<ReadsPathDataSource> threadReadSource = ThreadLocal.withInitial(; () -> {; final ReadsPathDataSource result = new ReadsPathDataSource(readArguments.getReadPaths(), factory);; readSources.add(result);; return result;; });; ```; The fix should be simple you just have to make sure ti synchronize the initialization or swap out the readSources object to one that is itself thread safe. @vruano",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7403#issuecomment-899732721:644,synchroniz,synchronize,644,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7403#issuecomment-899732721,1,['synchroniz'],['synchronize']
Integrability,"To add, just in case it wasn't clear, note that this is almost certainly overkill for most somatic applications. However, if this is going to double as a more lightweight germline pipeline (as it is for the time being, as we are using some of the results to prototype SV integration), it might be worthwhile.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386269562:271,integrat,integration,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386269562,1,['integrat'],['integration']
Integrability,To be more exact here is an actual error message:. ```; Invalid command line: z is not a recognized option; ```. Ideally would be. ```; Invalid command line: 'zscores' is not a recognized option; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1751#issuecomment-212979192:41,message,message,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1751#issuecomment-212979192,1,['message'],['message']
Integrability,"To clarify this ticket: in `GATKTool.initializeReads()`, just check `readArguments.getReadFiles()` for files ending with a cram extension (should see if there's a canonical method in htsjdk for checking whether a file is cram) -- if you find any and we don't have a reference according to `hasReference()`, throw a `UserException` with a clear error message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/673#issuecomment-125265449:350,message,message,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/673#issuecomment-125265449,1,['message'],['message']
Integrability,"To clarify what needs to be done here:. -Add a new `--javaOptions` argument to `gatk-launch`. -When running with a packaged local jar, the value of `--javaOptions` should be injected into the command line built by `formatLocalJarCommand()`. -When running with the ""wrapper script"" (as a result of building with `./gradlew installDist` instead of `./gradlew localJar`), propagate the value of `--javaOptions` to the `JAVA_OPTS` environment variable the wrapper script expects. You can inspect the wrapper script itself by running `./gradlew installDist` and then examining `build/install/gatk/bin/gatk`. -When running on Spark, you'll need to add the `--javaOptions` to `spark.driver.extraJavaOptions` and `spark.executor.extraJavaOptions`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2694#issuecomment-305007868:174,inject,injected,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2694#issuecomment-305007868,4,"['inject', 'wrap']","['injected', 'wrapper']"
Integrability,"To clarify, the tests are being run. It appears to be a bug in how we have configured the jacocoTestReport job that gets executed inside the docker image which seems to result some missing xml files that codeCoverage uses to build its reports. Since we have our integration and cloud tests outside of the docker image the coverage didn't drop to zero. I am looking into reconfiguring the jacocoTestReport task to behave correctly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5001#issuecomment-404629551:262,integrat,integration,262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5001#issuecomment-404629551,1,['integrat'],['integration']
Integrability,"To confirm, it works on Chr01 but nothing else? And can you list the; files/folders in the Chr01 genomicsdb versus say Chr02?. On Thu, Jul 27, 2023 at 6:44 PM ShirelyI ***@***.***> wrote:. > Hi mlathara,; > it doesn't work at all chromosomes but chr01,; > the contig description from the fasta is as follows and I only analyse the; > Chr***; > [image: image]; > <https://user-images.githubusercontent.com/103233242/256700966-838657ef-5f16-4c47-af85-ee89aeef3ffb.png>; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8415#issuecomment-1654851989>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AHXPS2DRGZCEB36P3CS5YFLXSMKODANCNFSM6AAAAAA2IOM3Y4>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8415#issuecomment-1655054908:789,Message,Message,789,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8415#issuecomment-1655054908,1,['Message'],['Message']
Integrability,"To fix the failing tests, I had to add an `equalsIgnoreUUID()` method to the `GATKRead` interface. Tests should pass now -- please re-review at your leisure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/653#issuecomment-121304462:88,interface,interface,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/653#issuecomment-121304462,1,['interface'],['interface']
Integrability,"To summarize current state of discussions - we're going to have 3 repos, as originally planned (1 for the interfaces and 2 for Intel and IBM implementations, respectively). There will be a bit code duplication but many other aspects (some technical, some organizational) are massively simplified by such architecture. . @droazen @lbergelson @gspowley @paolonarvaez @frank-y-liu @t-ogasawara - please use this ticket to comment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-216545820:106,interface,interfaces,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-216545820,1,['interface'],['interfaces']
Integrability,"To support running CARROT tests from PR comments, it's necessary that the [carrot-publish-github-action ](https://github.com/broadinstitute/carrot-publish-github-action) be integrated following the instructions in the README for that repo, so that PR comments will be processed by the GitHub action. This also requires that secrets be set for the pubsub topic and SA key for sending the messages.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6916:173,integrat,integrated,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6916,2,"['integrat', 'message']","['integrated', 'messages']"
Integrability,Tool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); Caused by: java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerS,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:17204,wrap,wrapAndCopyInto,17204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['wrap'],['wrapAndCopyInto']
Integrability,Tools run. These error/warn messages are new.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-297048203:28,message,messages,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-297048203,1,['message'],['messages']
Integrability,Trailing SNP sites and depth intervals without read coverage were being omitted from the output.; Integration tests have been updated to test that this revision solves that problem.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8045:98,Integrat,Integration,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8045,1,['Integrat'],['Integration']
Integrability,"TrainVariantAnnotationsModel:. Trains a model for scoring variant calls based on site-level annotations. TODOs:. - [x] Integration tests. Exact-match tests for (non-exhaustive) configurations given by the Cartesian product of the following options:; * non-allele-specific vs. allele-specific; * SNP-only vs. SNP+INDEL (for both of these options, we use extracted annotations that contain both SNP and INDEL variants as input); * positive (training with *.annot.hdf5) vs. positive-unlabeled (training with *.annot.hdf5 and *.unlabeled.annot.hdf5); * Java Bayesian Gaussian Mixture Model (BGMM) backend vs. python sklearn IsolationForest backend; (BGMM tests to be added once PR for the backend goes in.); - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs.; - [x] Parameter/mode validation.; - [x] Refactor main code block for model training; it's a bit monolithic and procedural now.; - [x] Decide on behavior for ill-behaved annotations. E.g., all missing, zero variance. Future work:. - [ ] We could allow subsetting of annotations here, which might allow for easier treatment of ill-behaved annotations. However, I'd say enabling workflows where the set of annotations is fixed is the priority.; - [ ] We could do positive-unlabeled training more rigorously or iteratively. Right now, we essentially do a single iteration to determine negative data. This could perhaps be preceded by a round of refactoring to clean up model training and make it less procedural.; - [ ] Automatic threshold tuning could be built into the tool, see #7711. We'd probably have to introduce a ""validation"" label. Perhaps it makes sense to keep this sort of thing at the workflow level?; - [ ] In the positive-negative framework enforced by the Java code in this tool, a ""model"" is anything that assigns a score, we fit two models to different subsets of the data, and then take the difference of the two scores. While the python backend does give some freedom to specify a model, future developers may want",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369:119,Integrat,Integration,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369,1,['Integrat'],['Integration']
Integrability,Travis reported job failures from build [27940](https://travis-ci.com/broadinstitute/gatk/builds/135299602); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [27940.1](https://travis-ci.com/broadinstitute/gatk/jobs/253708933) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27940.1/tests/test/index.html) |; | cloud | openjdk11 | [27940.14](https://travis-ci.com/broadinstitute/gatk/jobs/253708946) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27940.14/tests/test/index.html) |; | integration | oraclejdk8 | [27940.11](https://travis-ci.com/broadinstitute/gatk/jobs/253708943) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27940.11/tests/test/index.html) |; | integration | openjdk11 | [27940.12](https://travis-ci.com/broadinstitute/gatk/jobs/253708944) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27940.12/tests/test/index.html) |; | integration | openjdk8 | [27940.2](https://travis-ci.com/broadinstitute/gatk/jobs/253708934) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27940.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550409459:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550409459,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [27949](https://travis-ci.com/broadinstitute/gatk/builds/135327240); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [27949.11](https://travis-ci.com/broadinstitute/gatk/jobs/253773862) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27949.11/tests/test/index.html) |; | integration | openjdk11 | [27949.12](https://travis-ci.com/broadinstitute/gatk/jobs/253773863) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27949.12/tests/test/index.html) |; | integration | openjdk8 | [27949.2](https://travis-ci.com/broadinstitute/gatk/jobs/253773853) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27949.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550484410:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550484410,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [27951](https://travis-ci.com/broadinstitute/gatk/builds/135328116); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [27951.11](https://travis-ci.com/broadinstitute/gatk/jobs/253775865) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27951.11/tests/test/index.html) |; | integration | openjdk11 | [27951.12](https://travis-ci.com/broadinstitute/gatk/jobs/253775866) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27951.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550488826:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550488826,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [27953](https://travis-ci.com/broadinstitute/gatk/builds/135328325); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [27953.12](https://travis-ci.com/broadinstitute/gatk/jobs/253776493) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27953.12/tests/test/index.html) |; | integration | oraclejdk8 | [27953.11](https://travis-ci.com/broadinstitute/gatk/jobs/253776492) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27953.11/tests/test/index.html) |; | integration | openjdk8 | [27953.2](https://travis-ci.com/broadinstitute/gatk/jobs/253776483) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27953.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550488386:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550488386,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [27955](https://travis-ci.com/broadinstitute/gatk/builds/135328649); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [27955.11](https://travis-ci.com/broadinstitute/gatk/jobs/253777172) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27955.11/tests/test/index.html) |; | integration | openjdk11 | [27955.12](https://travis-ci.com/broadinstitute/gatk/jobs/253777173) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27955.12/tests/test/index.html) |; | integration | openjdk8 | [27955.2](https://travis-ci.com/broadinstitute/gatk/jobs/253777162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27955.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550487300:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-550487300,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [27983](https://travis-ci.com/broadinstitute/gatk/builds/135478554); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [27983.11](https://travis-ci.com/broadinstitute/gatk/jobs/254104520) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27983.11/tests/test/index.html) |; | integration | openjdk11 | [27983.12](https://travis-ci.com/broadinstitute/gatk/jobs/254104521) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27983.12/tests/test/index.html) |; | integration | openjdk8 | [27983.2](https://travis-ci.com/broadinstitute/gatk/jobs/254104511) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27983.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-551166492:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6247#issuecomment-551166492,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28043](https://travis-ci.com/broadinstitute/gatk/builds/137035017); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28043.11](https://travis-ci.com/broadinstitute/gatk/jobs/257824467) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28043.11/tests/test/index.html) |; | integration | openjdk11 | [28043.12](https://travis-ci.com/broadinstitute/gatk/jobs/257824468) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28043.12/tests/test/index.html) |; | integration | openjdk8 | [28043.2](https://travis-ci.com/broadinstitute/gatk/jobs/257824445) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28043.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-555111252:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-555111252,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28083](https://travis-ci.com/broadinstitute/gatk/builds/137456935); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28083.11](https://travis-ci.com/broadinstitute/gatk/jobs/258764558) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28083.11/tests/test/index.html) |; | integration | openjdk11 | [28083.12](https://travis-ci.com/broadinstitute/gatk/jobs/258764559) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28083.12/tests/test/index.html) |; | integration | openjdk8 | [28083.2](https://travis-ci.com/broadinstitute/gatk/jobs/258764549) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28083.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-556381618:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-556381618,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28122](https://travis-ci.com/broadinstitute/gatk/builds/137698341); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [28122.4](https://travis-ci.com/broadinstitute/gatk/jobs/259308339) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.4/tests/test/index.html) |; | cloud | openjdk8 | [28122.1](https://travis-ci.com/broadinstitute/gatk/jobs/259308336) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.1/tests/test/index.html) |; | cloud | openjdk11 | [28122.14](https://travis-ci.com/broadinstitute/gatk/jobs/259308349) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.14/tests/test/index.html) |; | unit | openjdk11 | [28122.13](https://travis-ci.com/broadinstitute/gatk/jobs/259308348) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.13/tests/test/index.html) |; | integration | oraclejdk8 | [28122.11](https://travis-ci.com/broadinstitute/gatk/jobs/259308346) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.11/tests/test/index.html) |; | unit | openjdk8 | [28122.3](https://travis-ci.com/broadinstitute/gatk/jobs/259308338) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.3/tests/test/index.html) |; | integration | openjdk11 | [28122.12](https://travis-ci.com/broadinstitute/gatk/jobs/259308347) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.12/tests/test/index.html) |; | integration | openjdk8 | [28122.2](https://travis-ci.com/broadinstitute/gatk/jobs/259308337) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28122.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557361260:1052,integrat,integration,1052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557361260,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28130](https://travis-ci.com/broadinstitute/gatk/builds/137807694); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [28130.1](https://travis-ci.com/broadinstitute/gatk/jobs/259581190) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.1/tests/test/index.html) |; | cloud | openjdk11 | [28130.14](https://travis-ci.com/broadinstitute/gatk/jobs/259581203) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.14/tests/test/index.html) |; | variantcalling | openjdk8 | [28130.4](https://travis-ci.com/broadinstitute/gatk/jobs/259581193) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.4/tests/test/index.html) |; | integration | oraclejdk8 | [28130.11](https://travis-ci.com/broadinstitute/gatk/jobs/259581200) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.11/tests/test/index.html) |; | integration | openjdk11 | [28130.12](https://travis-ci.com/broadinstitute/gatk/jobs/259581201) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.12/tests/test/index.html) |; | integration | openjdk8 | [28130.2](https://travis-ci.com/broadinstitute/gatk/jobs/259581191) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28130.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557639788:845,integrat,integration,845,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557639788,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28139](https://travis-ci.com/broadinstitute/gatk/builds/137849676); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28139.13](https://travis-ci.com/broadinstitute/gatk/jobs/259674809) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.13/tests/test/index.html) |; | integration | oraclejdk8 | [28139.11](https://travis-ci.com/broadinstitute/gatk/jobs/259674807) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.11/tests/test/index.html) |; | integration | openjdk11 | [28139.12](https://travis-ci.com/broadinstitute/gatk/jobs/259674808) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.12/tests/test/index.html) |; | variantcalling | openjdk8 | [28139.4](https://travis-ci.com/broadinstitute/gatk/jobs/259674800) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.4/tests/test/index.html) |; | unit | openjdk8 | [28139.3](https://travis-ci.com/broadinstitute/gatk/jobs/259674799) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.3/tests/test/index.html) |; | integration | openjdk8 | [28139.2](https://travis-ci.com/broadinstitute/gatk/jobs/259674798) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28139.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557713113:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557713113,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28143](https://travis-ci.com/broadinstitute/gatk/builds/137902492); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28143.11](https://travis-ci.com/broadinstitute/gatk/jobs/259801266) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28143.11/tests/test/index.html) |; | unit | openjdk11 | [28143.13](https://travis-ci.com/broadinstitute/gatk/jobs/259801268) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28143.13/tests/test/index.html) |; | integration | openjdk11 | [28143.12](https://travis-ci.com/broadinstitute/gatk/jobs/259801267) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28143.12/tests/test/index.html) |; | unit | openjdk8 | [28143.3](https://travis-ci.com/broadinstitute/gatk/jobs/259801258) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28143.3/tests/test/index.html) |; | integration | openjdk8 | [28143.2](https://travis-ci.com/broadinstitute/gatk/jobs/259801257) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28143.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557830936:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557830936,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28145](https://travis-ci.com/broadinstitute/gatk/builds/137904160); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28145.13](https://travis-ci.com/broadinstitute/gatk/jobs/259805318) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28145.13/tests/test/index.html) |; | integration | oraclejdk8 | [28145.11](https://travis-ci.com/broadinstitute/gatk/jobs/259805316) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28145.11/tests/test/index.html) |; | integration | openjdk11 | [28145.12](https://travis-ci.com/broadinstitute/gatk/jobs/259805317) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28145.12/tests/test/index.html) |; | unit | openjdk8 | [28145.3](https://travis-ci.com/broadinstitute/gatk/jobs/259805308) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28145.3/tests/test/index.html) |; | integration | openjdk8 | [28145.2](https://travis-ci.com/broadinstitute/gatk/jobs/259805307) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28145.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557834045:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-557834045,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28162](https://travis-ci.com/broadinstitute/gatk/builds/138106843); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28162.13](https://travis-ci.com/broadinstitute/gatk/jobs/260296087) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28162.13/tests/test/index.html) |; | integration | oraclejdk8 | [28162.11](https://travis-ci.com/broadinstitute/gatk/jobs/260296085) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28162.11/tests/test/index.html) |; | integration | openjdk11 | [28162.12](https://travis-ci.com/broadinstitute/gatk/jobs/260296086) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28162.12/tests/test/index.html) |; | unit | openjdk8 | [28162.3](https://travis-ci.com/broadinstitute/gatk/jobs/260296076) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28162.3/tests/test/index.html) |; | integration | openjdk8 | [28162.2](https://travis-ci.com/broadinstitute/gatk/jobs/260296074) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28162.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-558291603:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-558291603,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28165](https://travis-ci.com/broadinstitute/gatk/builds/138115218); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28165.11](https://travis-ci.com/broadinstitute/gatk/jobs/260315679) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28165.11/tests/test/index.html) |; | integration | openjdk11 | [28165.12](https://travis-ci.com/broadinstitute/gatk/jobs/260315680) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28165.12/tests/test/index.html) |; | integration | openjdk8 | [28165.2](https://travis-ci.com/broadinstitute/gatk/jobs/260315669) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28165.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-558314958:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-558314958,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28167](https://travis-ci.com/broadinstitute/gatk/builds/138118033); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [28167.12](https://travis-ci.com/broadinstitute/gatk/jobs/260322542) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28167.12/tests/test/index.html) |; | integration | oraclejdk8 | [28167.11](https://travis-ci.com/broadinstitute/gatk/jobs/260322540) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28167.11/tests/test/index.html) |; | integration | openjdk8 | [28167.2](https://travis-ci.com/broadinstitute/gatk/jobs/260322530) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28167.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-558324081:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6262#issuecomment-558324081,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28277](https://travis-ci.com/broadinstitute/gatk/builds/139364724); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [28277.12](https://travis-ci.com/broadinstitute/gatk/jobs/263099166) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28277.12/tests/test/index.html) |; | integration | oraclejdk8 | [28277.11](https://travis-ci.com/broadinstitute/gatk/jobs/263099165) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28277.11/tests/test/index.html) |; | integration | openjdk8 | [28277.2](https://travis-ci.com/broadinstitute/gatk/jobs/263099156) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28277.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-561730330:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-561730330,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:424,integrat,integration,424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28535](https://travis-ci.com/broadinstitute/gatk/builds/143616436); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [28535.4](https://travis-ci.com/broadinstitute/gatk/jobs/273613592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28535.4/tests/test/index.html) |; | integration | openjdk11 | [28535.12](https://travis-ci.com/broadinstitute/gatk/jobs/273613600) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28535.12/tests/test/index.html) |; | integration | oraclejdk8 | [28535.11](https://travis-ci.com/broadinstitute/gatk/jobs/273613599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28535.11/tests/test/index.html) |; | integration | openjdk8 | [28535.2](https://travis-ci.com/broadinstitute/gatk/jobs/273613590) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28535.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572218616:432,integrat,integration,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572218616,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28547](https://travis-ci.com/broadinstitute/gatk/builds/143771509); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28547.11](https://travis-ci.com/broadinstitute/gatk/jobs/273966397) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28547.11/tests/test/index.html) |; | variantcalling | openjdk8 | [28547.4](https://travis-ci.com/broadinstitute/gatk/jobs/273966388) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28547.4/tests/test/index.html) |; | integration | openjdk11 | [28547.12](https://travis-ci.com/broadinstitute/gatk/jobs/273966398) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28547.12/tests/test/index.html) |; | integration | openjdk8 | [28547.2](https://travis-ci.com/broadinstitute/gatk/jobs/273966386) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28547.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572677906:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572677906,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28550](https://travis-ci.com/broadinstitute/gatk/builds/143787017); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [28550.4](https://travis-ci.com/broadinstitute/gatk/jobs/274003454) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28550.4/tests/test/index.html) |; | integration | oraclejdk8 | [28550.11](https://travis-ci.com/broadinstitute/gatk/jobs/274003461) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28550.11/tests/test/index.html) |; | integration | openjdk11 | [28550.12](https://travis-ci.com/broadinstitute/gatk/jobs/274003462) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28550.12/tests/test/index.html) |; | unit | openjdk8 | [28550.3](https://travis-ci.com/broadinstitute/gatk/jobs/274003453) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28550.3/tests/test/index.html) |; | integration | openjdk8 | [28550.2](https://travis-ci.com/broadinstitute/gatk/jobs/274003452) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28550.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572729169:432,integrat,integration,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572729169,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28552](https://travis-ci.com/broadinstitute/gatk/builds/143787227); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28552.11](https://travis-ci.com/broadinstitute/gatk/jobs/274004057) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28552.11/tests/test/index.html) |; | variantcalling | openjdk8 | [28552.4](https://travis-ci.com/broadinstitute/gatk/jobs/274004050) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28552.4/tests/test/index.html) |; | integration | openjdk11 | [28552.12](https://travis-ci.com/broadinstitute/gatk/jobs/274004058) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28552.12/tests/test/index.html) |; | integration | openjdk8 | [28552.2](https://travis-ci.com/broadinstitute/gatk/jobs/274004048) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28552.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572728974:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572728974,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28553](https://travis-ci.com/broadinstitute/gatk/builds/143787525); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [28553.4](https://travis-ci.com/broadinstitute/gatk/jobs/274004800) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28553.4/tests/test/index.html) |; | integration | oraclejdk8 | [28553.11](https://travis-ci.com/broadinstitute/gatk/jobs/274004808) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28553.11/tests/test/index.html) |; | integration | openjdk11 | [28553.12](https://travis-ci.com/broadinstitute/gatk/jobs/274004810) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28553.12/tests/test/index.html) |; | integration | openjdk8 | [28553.2](https://travis-ci.com/broadinstitute/gatk/jobs/274004798) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28553.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572730586:432,integrat,integration,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6361#issuecomment-572730586,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28716](https://travis-ci.com/broadinstitute/gatk/builds/145422010); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28716.11](https://travis-ci.com/broadinstitute/gatk/jobs/278054948) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28716.11/tests/test/index.html) |; | integration | openjdk11 | [28716.12](https://travis-ci.com/broadinstitute/gatk/jobs/278054949) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28716.12/tests/test/index.html) |; | integration | openjdk8 | [28716.2](https://travis-ci.com/broadinstitute/gatk/jobs/278054938) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28716.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6401#issuecomment-576845315:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6401#issuecomment-576845315,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28795](https://travis-ci.com/broadinstitute/gatk/builds/145954484); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [28795.4](https://travis-ci.com/broadinstitute/gatk/jobs/279782040) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28795.4/tests/test/index.html) |; | integration | oraclejdk8 | [28795.11](https://travis-ci.com/broadinstitute/gatk/jobs/279782047) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28795.11/tests/test/index.html) |; | unit | openjdk8 | [28795.3](https://travis-ci.com/broadinstitute/gatk/jobs/279782039) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28795.3/tests/test/index.html) |; | integration | openjdk8 | [28795.2](https://travis-ci.com/broadinstitute/gatk/jobs/279782038) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28795.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-578185465:432,integrat,integration,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-578185465,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [28808](https://travis-ci.com/broadinstitute/gatk/builds/146011126); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28808.11](https://travis-ci.com/broadinstitute/gatk/jobs/279909754) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28808.11/tests/test/index.html) |; | integration | openjdk11 | [28808.12](https://travis-ci.com/broadinstitute/gatk/jobs/279909755) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28808.12/tests/test/index.html) |; | integration | openjdk8 | [28808.2](https://travis-ci.com/broadinstitute/gatk/jobs/279909745) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28808.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6417#issuecomment-578310009:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6417#issuecomment-578310009,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28853](https://travis-ci.com/broadinstitute/gatk/builds/146340414); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [28853.2](https://travis-ci.com/broadinstitute/gatk/jobs/280854279) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28853.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-579107366:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-579107366,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [28922](https://travis-ci.com/broadinstitute/gatk/builds/146980249); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28922.11](https://travis-ci.com/broadinstitute/gatk/jobs/282436321) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28922.11/tests/test/index.html) |; | integration | openjdk11 | [28922.12](https://travis-ci.com/broadinstitute/gatk/jobs/282436322) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28922.12/tests/test/index.html) |; | integration | openjdk8 | [28922.2](https://travis-ci.com/broadinstitute/gatk/jobs/282436309) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28922.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-580903507:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-580903507,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28928](https://travis-ci.com/broadinstitute/gatk/builds/146990377); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28928.11](https://travis-ci.com/broadinstitute/gatk/jobs/282468192) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.11/tests/test/index.html) |; | variantcalling | openjdk8 | [28928.4](https://travis-ci.com/broadinstitute/gatk/jobs/282468185) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.4/tests/test/index.html) |; | unit | openjdk11 | [28928.13](https://travis-ci.com/broadinstitute/gatk/jobs/282468194) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.13/tests/test/index.html) |; | integration | openjdk11 | [28928.12](https://travis-ci.com/broadinstitute/gatk/jobs/282468193) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.12/tests/test/index.html) |; | unit | openjdk8 | [28928.3](https://travis-ci.com/broadinstitute/gatk/jobs/282468184) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.3/tests/test/index.html) |; | integration | openjdk8 | [28928.2](https://travis-ci.com/broadinstitute/gatk/jobs/282468183) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28928.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-580926214:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-580926214,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28947](https://travis-ci.com/broadinstitute/gatk/builds/147248704); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28947.11](https://travis-ci.com/broadinstitute/gatk/jobs/283088574) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28947.11/tests/test/index.html) |; | integration | openjdk11 | [28947.12](https://travis-ci.com/broadinstitute/gatk/jobs/283088576) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28947.12/tests/test/index.html) |; | integration | openjdk8 | [28947.2](https://travis-ci.com/broadinstitute/gatk/jobs/283088564) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28947.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6436#issuecomment-581541781:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6436#issuecomment-581541781,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [28980](https://travis-ci.com/broadinstitute/gatk/builds/147447359); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [28980.12](https://travis-ci.com/broadinstitute/gatk/jobs/283563549) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28980.12/tests/test/index.html) |; | integration | openjdk8 | [28980.2](https://travis-ci.com/broadinstitute/gatk/jobs/283563537) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28980.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6436#issuecomment-582121672:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6436#issuecomment-582121672,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [29013](https://travis-ci.com/broadinstitute/gatk/builds/147827421); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29013.11](https://travis-ci.com/broadinstitute/gatk/jobs/284497171) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29013.11/tests/test/index.html) |; | integration | openjdk11 | [29013.12](https://travis-ci.com/broadinstitute/gatk/jobs/284497172) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29013.12/tests/test/index.html) |; | integration | openjdk8 | [29013.2](https://travis-ci.com/broadinstitute/gatk/jobs/284497162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29013.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6411#issuecomment-583142673:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6411#issuecomment-583142673,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29015](https://travis-ci.com/broadinstitute/gatk/builds/147828086); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29015.11](https://travis-ci.com/broadinstitute/gatk/jobs/284498893) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29015.11/tests/test/index.html) |; | integration | openjdk11 | [29015.12](https://travis-ci.com/broadinstitute/gatk/jobs/284498894) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29015.12/tests/test/index.html) |; | integration | openjdk8 | [29015.2](https://travis-ci.com/broadinstitute/gatk/jobs/284498882) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29015.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6411#issuecomment-583143781:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6411#issuecomment-583143781,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29059](https://travis-ci.com/broadinstitute/gatk/builds/148070808); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [29059.1](https://travis-ci.com/broadinstitute/gatk/jobs/285180550) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29059.1/tests/test/index.html) |; | cloud | openjdk11 | [29059.14](https://travis-ci.com/broadinstitute/gatk/jobs/285180563) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29059.14/tests/test/index.html) |; | integration | oraclejdk8 | [29059.11](https://travis-ci.com/broadinstitute/gatk/jobs/285180560) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29059.11/tests/test/index.html) |; | integration | openjdk11 | [29059.12](https://travis-ci.com/broadinstitute/gatk/jobs/285180561) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29059.12/tests/test/index.html) |; | integration | openjdk8 | [29059.2](https://travis-ci.com/broadinstitute/gatk/jobs/285180551) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29059.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6446#issuecomment-583802851:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6446#issuecomment-583802851,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29063](https://travis-ci.com/broadinstitute/gatk/builds/148075396); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [29063.5](https://travis-ci.com/broadinstitute/gatk/jobs/285190126) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29063.5/tests/test/index.html) |; | unit | openjdk8 | [29063.3](https://travis-ci.com/broadinstitute/gatk/jobs/285190124) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29063.3/tests/test/index.html) |; | integration | openjdk8 | [29063.2](https://travis-ci.com/broadinstitute/gatk/jobs/285190123) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29063.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6448#issuecomment-583812428:628,integrat,integration,628,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6448#issuecomment-583812428,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [29125](https://travis-ci.com/broadinstitute/gatk/builds/148726118); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [29125.5](https://travis-ci.com/broadinstitute/gatk/jobs/286704576) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29125.5/tests/test/index.html) |; | variantcalling | openjdk8 | [29125.4](https://travis-ci.com/broadinstitute/gatk/jobs/286704575) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29125.4/tests/test/index.html) |; | unit | openjdk8 | [29125.3](https://travis-ci.com/broadinstitute/gatk/jobs/286704574) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29125.3/tests/test/index.html) |; | integration | openjdk8 | [29125.2](https://travis-ci.com/broadinstitute/gatk/jobs/286704573) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29125.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6445#issuecomment-585577409:842,integrat,integration,842,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6445#issuecomment-585577409,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [29157](https://travis-ci.com/broadinstitute/gatk/builds/148868090); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29157.12](https://travis-ci.com/broadinstitute/gatk/jobs/287031748) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29157.12/tests/test/index.html) |; | unit | openjdk11 | [29157.14](https://travis-ci.com/broadinstitute/gatk/jobs/287031750) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29157.14/tests/test/index.html) |; | integration | openjdk11 | [29157.13](https://travis-ci.com/broadinstitute/gatk/jobs/287031749) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29157.13/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6454#issuecomment-586001111:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6454#issuecomment-586001111,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [29224](https://travis-ci.com/broadinstitute/gatk/builds/149883140); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29224.12](https://travis-ci.com/broadinstitute/gatk/jobs/289430111) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29224.12/tests/test/index.html) |; | unit | openjdk11 | [29224.14](https://travis-ci.com/broadinstitute/gatk/jobs/289430113) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29224.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29224.4](https://travis-ci.com/broadinstitute/gatk/jobs/289430103) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29224.4/tests/test/index.html) |; | integration | openjdk11 | [29224.13](https://travis-ci.com/broadinstitute/gatk/jobs/289430112) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29224.13/tests/test/index.html) |; | integration | openjdk8 | [29224.2](https://travis-ci.com/broadinstitute/gatk/jobs/289430101) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29224.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-589296062:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-589296062,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29238](https://travis-ci.com/broadinstitute/gatk/builds/150105026); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [29238.14](https://travis-ci.com/broadinstitute/gatk/jobs/289940648) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29238.14/tests/test/index.html) |; | integration | oraclejdk8 | [29238.12](https://travis-ci.com/broadinstitute/gatk/jobs/289940646) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29238.12/tests/test/index.html) |; | unit | openjdk8 | [29238.3](https://travis-ci.com/broadinstitute/gatk/jobs/289940637) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29238.3/tests/test/index.html) |; | integration | openjdk11 | [29238.13](https://travis-ci.com/broadinstitute/gatk/jobs/289940647) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29238.13/tests/test/index.html) |; | integration | openjdk8 | [29238.2](https://travis-ci.com/broadinstitute/gatk/jobs/289940636) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29238.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6465#issuecomment-589866076:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6465#issuecomment-589866076,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29412](https://travis-ci.com/broadinstitute/gatk/builds/151996956); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29412.12](https://travis-ci.com/broadinstitute/gatk/jobs/295002547) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29412.12/tests/test/index.html) |; | integration | openjdk11 | [29412.13](https://travis-ci.com/broadinstitute/gatk/jobs/295002548) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29412.13/tests/test/index.html) |; | integration | openjdk8 | [29412.2](https://travis-ci.com/broadinstitute/gatk/jobs/295002537) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29412.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595341676:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595341676,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29414](https://travis-ci.com/broadinstitute/gatk/builds/151997149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29414.12](https://travis-ci.com/broadinstitute/gatk/jobs/295003009) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29414.12/tests/test/index.html) |; | integration | openjdk11 | [29414.13](https://travis-ci.com/broadinstitute/gatk/jobs/295003010) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29414.13/tests/test/index.html) |; | integration | openjdk8 | [29414.2](https://travis-ci.com/broadinstitute/gatk/jobs/295002999) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29414.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595342221:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595342221,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29416](https://travis-ci.com/broadinstitute/gatk/builds/152000044); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29416.12](https://travis-ci.com/broadinstitute/gatk/jobs/295015583) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29416.12/tests/test/index.html) |; | integration | openjdk11 | [29416.13](https://travis-ci.com/broadinstitute/gatk/jobs/295015584) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29416.13/tests/test/index.html) |; | integration | openjdk8 | [29416.2](https://travis-ci.com/broadinstitute/gatk/jobs/295015573) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29416.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595346842:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6477#issuecomment-595346842,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29475](https://travis-ci.com/broadinstitute/gatk/builds/152932209); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [29475.14](https://travis-ci.com/broadinstitute/gatk/jobs/297213806) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29475.14/tests/test/index.html) |; | unit | openjdk8 | [29475.3](https://travis-ci.com/broadinstitute/gatk/jobs/297213795) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29475.3/tests/test/index.html) |; | integration | openjdk8 | [29475.2](https://travis-ci.com/broadinstitute/gatk/jobs/297213794) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29475.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6498#issuecomment-598028671:629,integrat,integration,629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6498#issuecomment-598028671,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [29539](https://travis-ci.com/broadinstitute/gatk/builds/153610218); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29539.6](https://travis-ci.com/broadinstitute/gatk/jobs/298810423) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29539.6/tests/test/index.html) |; | python | openjdk8 | [29539.5](https://travis-ci.com/broadinstitute/gatk/jobs/298810422) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29539.5/tests/test/index.html) |; | variantcalling | openjdk8 | [29539.4](https://travis-ci.com/broadinstitute/gatk/jobs/298810421) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29539.4/tests/test/index.html) |; | unit | openjdk8 | [29539.3](https://travis-ci.com/broadinstitute/gatk/jobs/298810420) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29539.3/tests/test/index.html) |; | integration | openjdk8 | [29539.2](https://travis-ci.com/broadinstitute/gatk/jobs/298810419) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29539.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6507#issuecomment-599901701:1043,integrat,integration,1043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6507#issuecomment-599901701,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [29604](https://travis-ci.com/broadinstitute/gatk/builds/154146351); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [29604.14](https://travis-ci.com/broadinstitute/gatk/jobs/300039008) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.14/tests/test/index.html) |; | integration | oraclejdk8 | [29604.12](https://travis-ci.com/broadinstitute/gatk/jobs/300039006) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.12/tests/test/index.html) |; | integration | openjdk11 | [29604.13](https://travis-ci.com/broadinstitute/gatk/jobs/300039007) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.13/tests/test/index.html) |; | integration | openjdk8 | [29604.2](https://travis-ci.com/broadinstitute/gatk/jobs/300038996) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29682](https://travis-ci.com/broadinstitute/gatk/builds/154630422); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29682.12](https://travis-ci.com/broadinstitute/gatk/jobs/301258495) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29682.12/tests/test/index.html) |; | integration | openjdk11 | [29682.13](https://travis-ci.com/broadinstitute/gatk/jobs/301258496) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29682.13/tests/test/index.html) |; | integration | openjdk8 | [29682.2](https://travis-ci.com/broadinstitute/gatk/jobs/301258485) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29682.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602719177:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602719177,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29684](https://travis-ci.com/broadinstitute/gatk/builds/154637286); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29684.12](https://travis-ci.com/broadinstitute/gatk/jobs/301273903) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29684.12/tests/test/index.html) |; | integration | openjdk11 | [29684.13](https://travis-ci.com/broadinstitute/gatk/jobs/301273904) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29684.13/tests/test/index.html) |; | integration | openjdk8 | [29684.2](https://travis-ci.com/broadinstitute/gatk/jobs/301273893) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29684.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602739941:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602739941,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29685](https://travis-ci.com/broadinstitute/gatk/builds/154640951); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29685.12](https://travis-ci.com/broadinstitute/gatk/jobs/301286235) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29685.12/tests/test/index.html) |; | integration | openjdk11 | [29685.13](https://travis-ci.com/broadinstitute/gatk/jobs/301286236) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29685.13/tests/test/index.html) |; | integration | openjdk8 | [29685.2](https://travis-ci.com/broadinstitute/gatk/jobs/301286225) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29685.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602742528:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602742528,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29688](https://travis-ci.com/broadinstitute/gatk/builds/154646560); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29688.12](https://travis-ci.com/broadinstitute/gatk/jobs/301299237) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29688.12/tests/test/index.html) |; | integration | openjdk11 | [29688.13](https://travis-ci.com/broadinstitute/gatk/jobs/301299238) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29688.13/tests/test/index.html) |; | integration | openjdk8 | [29688.2](https://travis-ci.com/broadinstitute/gatk/jobs/301299227) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29688.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602759165:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-602759165,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29804](https://travis-ci.com/broadinstitute/gatk/builds/156857783); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29804.6](https://travis-ci.com/broadinstitute/gatk/jobs/309185373) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.6/tests/test/index.html) |; | integration | oraclejdk8 | [29804.12](https://travis-ci.com/broadinstitute/gatk/jobs/309185379) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.12/tests/test/index.html) |; | python | openjdk8 | [29804.5](https://travis-ci.com/broadinstitute/gatk/jobs/309185372) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.5/tests/test/index.html) |; | cloud | openjdk8 | [29804.1](https://travis-ci.com/broadinstitute/gatk/jobs/309185366) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.1/tests/test/index.html) |; | integration | openjdk11 | [29804.13](https://travis-ci.com/broadinstitute/gatk/jobs/309185380) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.13/tests/test/index.html) |; | cloud | openjdk11 | [29804.15](https://travis-ci.com/broadinstitute/gatk/jobs/309185382) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.15/tests/test/index.html) |; | integration | openjdk8 | [29804.2](https://travis-ci.com/broadinstitute/gatk/jobs/309185367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29804.4](https://travis-ci.com/broadinstitute/gatk/jobs/309185371) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29804.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-606204666:419,integrat,integration,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-606204666,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29830](https://travis-ci.com/broadinstitute/gatk/builds/157356833); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29830.12](https://travis-ci.com/broadinstitute/gatk/jobs/310893235) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29830.12/tests/test/index.html) |; | integration | openjdk11 | [29830.13](https://travis-ci.com/broadinstitute/gatk/jobs/310893236) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29830.13/tests/test/index.html) |; | cloud | openjdk8 | [29830.1](https://travis-ci.com/broadinstitute/gatk/jobs/310893224) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29830.1/tests/test/index.html) |; | cloud | openjdk11 | [29830.15](https://travis-ci.com/broadinstitute/gatk/jobs/310893238) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29830.15/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-606967314:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-606967314,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [29832](https://travis-ci.com/broadinstitute/gatk/builds/157562667); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29832.12](https://travis-ci.com/broadinstitute/gatk/jobs/311543311) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29832.12/tests/test/index.html) |; | integration | openjdk11 | [29832.13](https://travis-ci.com/broadinstitute/gatk/jobs/311543312) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29832.13/tests/test/index.html) |; | cloud | openjdk11 | [29832.15](https://travis-ci.com/broadinstitute/gatk/jobs/311543314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29832.15/tests/test/index.html) |; | cloud | openjdk8 | [29832.1](https://travis-ci.com/broadinstitute/gatk/jobs/311543300) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29832.1/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607339427:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607339427,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [29837](https://travis-ci.com/broadinstitute/gatk/builds/157591374); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29837.12](https://travis-ci.com/broadinstitute/gatk/jobs/311628431) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29837.12/tests/test/index.html) |; | integration | openjdk11 | [29837.13](https://travis-ci.com/broadinstitute/gatk/jobs/311628432) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29837.13/tests/test/index.html) |; | integration | openjdk8 | [29837.2](https://travis-ci.com/broadinstitute/gatk/jobs/311628421) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29837.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607423696:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607423696,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29839](https://travis-ci.com/broadinstitute/gatk/builds/157593279); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29839.12](https://travis-ci.com/broadinstitute/gatk/jobs/311633272) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29839.12/tests/test/index.html) |; | integration | openjdk11 | [29839.13](https://travis-ci.com/broadinstitute/gatk/jobs/311633273) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29839.13/tests/test/index.html) |; | integration | openjdk8 | [29839.2](https://travis-ci.com/broadinstitute/gatk/jobs/311633261) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29839.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607427515:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607427515,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29842](https://travis-ci.com/broadinstitute/gatk/builds/157628713); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [29842.12](https://travis-ci.com/broadinstitute/gatk/jobs/311717563) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29842.12/tests/test/index.html) |; | integration | openjdk11 | [29842.13](https://travis-ci.com/broadinstitute/gatk/jobs/311717564) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29842.13/tests/test/index.html) |; | integration | openjdk8 | [29842.2](https://travis-ci.com/broadinstitute/gatk/jobs/311717553) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29842.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607510446:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-607510446,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29895](https://travis-ci.com/broadinstitute/gatk/builds/158261477); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29895.6](https://travis-ci.com/broadinstitute/gatk/jobs/313692987) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.6/tests/test/index.html) |; | python | openjdk8 | [29895.5](https://travis-ci.com/broadinstitute/gatk/jobs/313692986) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.5/tests/test/index.html) |; | integration | oraclejdk8 | [29895.12](https://travis-ci.com/broadinstitute/gatk/jobs/313692993) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.12/tests/test/index.html) |; | cloud | openjdk8 | [29895.1](https://travis-ci.com/broadinstitute/gatk/jobs/313692982) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.1/tests/test/index.html) |; | integration | openjdk11 | [29895.13](https://travis-ci.com/broadinstitute/gatk/jobs/313692994) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.13/tests/test/index.html) |; | cloud | openjdk11 | [29895.15](https://travis-ci.com/broadinstitute/gatk/jobs/313692996) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.15/tests/test/index.html) |; | integration | openjdk8 | [29895.2](https://travis-ci.com/broadinstitute/gatk/jobs/313692983) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29895.4](https://travis-ci.com/broadinstitute/gatk/jobs/313692985) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29895.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608562413:625,integrat,integration,625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608562413,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29897](https://travis-ci.com/broadinstitute/gatk/builds/158264975); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [29897.5](https://travis-ci.com/broadinstitute/gatk/jobs/313702266) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.5/tests/test/index.html) |; | integration | oraclejdk8 | [29897.12](https://travis-ci.com/broadinstitute/gatk/jobs/313702273) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.12/tests/test/index.html) |; | cloud | openjdk8 | [29897.1](https://travis-ci.com/broadinstitute/gatk/jobs/313702262) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.1/tests/test/index.html) |; | integration | openjdk11 | [29897.13](https://travis-ci.com/broadinstitute/gatk/jobs/313702274) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.13/tests/test/index.html) |; | integration | openjdk8 | [29897.2](https://travis-ci.com/broadinstitute/gatk/jobs/313702263) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.2/tests/test/index.html) |; | cloud | openjdk11 | [29897.15](https://travis-ci.com/broadinstitute/gatk/jobs/313702276) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.15/tests/test/index.html) |; | variantcalling | openjdk8 | [29897.4](https://travis-ci.com/broadinstitute/gatk/jobs/313702265) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29897.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608574955:424,integrat,integration,424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608574955,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29900](https://travis-ci.com/broadinstitute/gatk/builds/158267113); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29900.6](https://travis-ci.com/broadinstitute/gatk/jobs/313708020) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.6/tests/test/index.html) |; | integration | oraclejdk8 | [29900.12](https://travis-ci.com/broadinstitute/gatk/jobs/313708026) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.12/tests/test/index.html) |; | integration | openjdk11 | [29900.13](https://travis-ci.com/broadinstitute/gatk/jobs/313708027) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.13/tests/test/index.html) |; | cloud | openjdk8 | [29900.1](https://travis-ci.com/broadinstitute/gatk/jobs/313708015) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.1/tests/test/index.html) |; | integration | openjdk8 | [29900.2](https://travis-ci.com/broadinstitute/gatk/jobs/313708016) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.2/tests/test/index.html) |; | cloud | openjdk11 | [29900.15](https://travis-ci.com/broadinstitute/gatk/jobs/313708029) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.15/tests/test/index.html) |; | variantcalling | openjdk8 | [29900.4](https://travis-ci.com/broadinstitute/gatk/jobs/313708018) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29900.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608580670:419,integrat,integration,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-608580670,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [29984](https://travis-ci.com/broadinstitute/gatk/builds/159673754); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29984.6](https://travis-ci.com/broadinstitute/gatk/jobs/317851324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.6/tests/test/index.html) |; | python | openjdk8 | [29984.5](https://travis-ci.com/broadinstitute/gatk/jobs/317851323) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.5/tests/test/index.html) |; | integration | oraclejdk8 | [29984.12](https://travis-ci.com/broadinstitute/gatk/jobs/317851330) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.12/tests/test/index.html) |; | integration | openjdk11 | [29984.13](https://travis-ci.com/broadinstitute/gatk/jobs/317851331) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.13/tests/test/index.html) |; | cloud | openjdk8 | [29984.1](https://travis-ci.com/broadinstitute/gatk/jobs/317851319) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.1/tests/test/index.html) |; | cloud | openjdk11 | [29984.15](https://travis-ci.com/broadinstitute/gatk/jobs/317851333) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.15/tests/test/index.html) |; | unit | openjdk11 | [29984.14](https://travis-ci.com/broadinstitute/gatk/jobs/317851332) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.14/tests/test/index.html) |; | integration | openjdk8 | [29984.2](https://travis-ci.com/broadinstitute/gatk/jobs/317851320) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29984.4](https://travis-ci.com/broadinstitute/gatk/jobs/317851322) | [logs](https://sto,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611695380:625,integrat,integration,625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611695380,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [29988](https://travis-ci.com/broadinstitute/gatk/builds/159678058); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29988.6](https://travis-ci.com/broadinstitute/gatk/jobs/317861684) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.6/tests/test/index.html) |; | integration | oraclejdk8 | [29988.12](https://travis-ci.com/broadinstitute/gatk/jobs/317861697) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.12/tests/test/index.html) |; | python | openjdk8 | [29988.5](https://travis-ci.com/broadinstitute/gatk/jobs/317861683) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.5/tests/test/index.html) |; | integration | openjdk11 | [29988.13](https://travis-ci.com/broadinstitute/gatk/jobs/317861698) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.13/tests/test/index.html) |; | cloud | openjdk11 | [29988.15](https://travis-ci.com/broadinstitute/gatk/jobs/317861700) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.15/tests/test/index.html) |; | cloud | openjdk8 | [29988.1](https://travis-ci.com/broadinstitute/gatk/jobs/317861676) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.1/tests/test/index.html) |; | unit | openjdk11 | [29988.14](https://travis-ci.com/broadinstitute/gatk/jobs/317861699) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.14/tests/test/index.html) |; | integration | openjdk8 | [29988.2](https://travis-ci.com/broadinstitute/gatk/jobs/317861680) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29988.4](https://travis-ci.com/broadinstitute/gatk/jobs/317861682) | [logs](https://sto,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611710351:419,integrat,integration,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611710351,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [29990](https://travis-ci.com/broadinstitute/gatk/builds/159681491); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29990.6](https://travis-ci.com/broadinstitute/gatk/jobs/317870153) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.6/tests/test/index.html) |; | integration | oraclejdk8 | [29990.12](https://travis-ci.com/broadinstitute/gatk/jobs/317870159) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.12/tests/test/index.html) |; | python | openjdk8 | [29990.5](https://travis-ci.com/broadinstitute/gatk/jobs/317870152) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.5/tests/test/index.html) |; | cloud | openjdk8 | [29990.1](https://travis-ci.com/broadinstitute/gatk/jobs/317870147) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.1/tests/test/index.html) |; | cloud | openjdk11 | [29990.15](https://travis-ci.com/broadinstitute/gatk/jobs/317870162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.15/tests/test/index.html) |; | integration | openjdk11 | [29990.13](https://travis-ci.com/broadinstitute/gatk/jobs/317870160) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.13/tests/test/index.html) |; | integration | openjdk8 | [29990.2](https://travis-ci.com/broadinstitute/gatk/jobs/317870149) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.2/tests/test/index.html) |; | unit | openjdk11 | [29990.14](https://travis-ci.com/broadinstitute/gatk/jobs/317870161) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29990.4](https://travis-ci.com/broadinstitute/gatk/jobs/317870151) | [logs](https://sto,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629:419,integrat,integration,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [29992](https://travis-ci.com/broadinstitute/gatk/builds/159687710); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | R | openjdk8 | [29992.6](https://travis-ci.com/broadinstitute/gatk/jobs/317887706) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.6/tests/test/index.html) |; | python | openjdk8 | [29992.5](https://travis-ci.com/broadinstitute/gatk/jobs/317887705) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.5/tests/test/index.html) |; | integration | oraclejdk8 | [29992.12](https://travis-ci.com/broadinstitute/gatk/jobs/317887712) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.12/tests/test/index.html) |; | integration | openjdk11 | [29992.13](https://travis-ci.com/broadinstitute/gatk/jobs/317887713) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.13/tests/test/index.html) |; | cloud | openjdk8 | [29992.1](https://travis-ci.com/broadinstitute/gatk/jobs/317887701) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.1/tests/test/index.html) |; | cloud | openjdk11 | [29992.15](https://travis-ci.com/broadinstitute/gatk/jobs/317887715) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.15/tests/test/index.html) |; | integration | openjdk8 | [29992.2](https://travis-ci.com/broadinstitute/gatk/jobs/317887702) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.2/tests/test/index.html) |; | unit | openjdk11 | [29992.14](https://travis-ci.com/broadinstitute/gatk/jobs/317887714) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29992.4](https://travis-ci.com/broadinstitute/gatk/jobs/317887704) | [logs](https://sto,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611733065:625,integrat,integration,625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611733065,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30007](https://travis-ci.com/broadinstitute/gatk/builds/159946837); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk8 | [30007.3](https://travis-ci.com/broadinstitute/gatk/jobs/318548433) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30007.3/tests/test/index.html) |; | integration | openjdk8 | [30007.2](https://travis-ci.com/broadinstitute/gatk/jobs/318548432) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30007.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6544#issuecomment-612573044:422,integrat,integration,422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6544#issuecomment-612573044,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [30166](https://travis-ci.com/broadinstitute/gatk/builds/161861232); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30166.13](https://travis-ci.com/broadinstitute/gatk/jobs/323065577) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30166.13/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-619117426:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-619117426,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [30170](https://travis-ci.com/broadinstitute/gatk/builds/161888712); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [30170.12](https://travis-ci.com/broadinstitute/gatk/jobs/323130022) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30170.12/tests/test/index.html) |; | integration | openjdk11 | [30170.13](https://travis-ci.com/broadinstitute/gatk/jobs/323130023) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30170.13/tests/test/index.html) |; | integration | openjdk8 | [30170.2](https://travis-ci.com/broadinstitute/gatk/jobs/323130012) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30170.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-619192806:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-619192806,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [30184](https://travis-ci.com/broadinstitute/gatk/builds/162226990); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [30184.12](https://travis-ci.com/broadinstitute/gatk/jobs/323827982) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30184.12/tests/test/index.html) |; | integration | openjdk11 | [30184.13](https://travis-ci.com/broadinstitute/gatk/jobs/323827983) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30184.13/tests/test/index.html) |; | integration | openjdk8 | [30184.2](https://travis-ci.com/broadinstitute/gatk/jobs/323827972) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30184.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-620008431:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6570#issuecomment-620008431,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [30367](https://travis-ci.com/broadinstitute/gatk/builds/166938202); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [30367.1](https://travis-ci.com/broadinstitute/gatk/jobs/337021781) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.1/tests/test/index.html) |; | conda | openjdk8 | [30367.5](https://travis-ci.com/broadinstitute/gatk/jobs/337021785) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.5/tests/test/index.html) |; | cloud | openjdk11 | [30367.13](https://travis-ci.com/broadinstitute/gatk/jobs/337021793) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.13/tests/test/index.html) |; | unit | openjdk11 | [30367.12](https://travis-ci.com/broadinstitute/gatk/jobs/337021792) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.12/tests/test/index.html) |; | integration | openjdk11 | [30367.11](https://travis-ci.com/broadinstitute/gatk/jobs/337021791) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.11/tests/test/index.html) |; | variantcalling | openjdk8 | [30367.4](https://travis-ci.com/broadinstitute/gatk/jobs/337021784) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.4/tests/test/index.html) |; | unit | openjdk8 | [30367.3](https://travis-ci.com/broadinstitute/gatk/jobs/337021783) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.3/tests/test/index.html) |; | integration | openjdk8 | [30367.2](https://travis-ci.com/broadinstitute/gatk/jobs/337021782) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30367.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-630883022:1043,integrat,integration,1043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-630883022,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30416](https://travis-ci.com/broadinstitute/gatk/builds/168461453); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30416.11](https://travis-ci.com/broadinstitute/gatk/jobs/340668381) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30416.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6571#issuecomment-634926766:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6571#issuecomment-634926766,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [30432](https://travis-ci.com/broadinstitute/gatk/builds/168636249); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30432.11](https://travis-ci.com/broadinstitute/gatk/jobs/341109053) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30432.11/tests/test/index.html) |; | integration | openjdk8 | [30432.2](https://travis-ci.com/broadinstitute/gatk/jobs/341109044) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30432.2/tests/test/index.html) |; | integration | openjdk11 | [30432.11](https://travis-ci.com/broadinstitute/gatk/jobs/341109053) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30432.11/tests/test/index.html) |; | integration | openjdk8 | [30432.2](https://travis-ci.com/broadinstitute/gatk/jobs/341109044) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30432.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6536#issuecomment-635559332:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6536#issuecomment-635559332,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [30435](https://travis-ci.com/broadinstitute/gatk/builds/168646579); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30435.11](https://travis-ci.com/broadinstitute/gatk/jobs/341136130) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30435.11/tests/test/index.html) |; | integration | openjdk8 | [30435.2](https://travis-ci.com/broadinstitute/gatk/jobs/341136121) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30435.2/tests/test/index.html) |; | integration | openjdk11 | [30435.11](https://travis-ci.com/broadinstitute/gatk/jobs/341136130) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30435.11/tests/test/index.html) |; | integration | openjdk8 | [30435.2](https://travis-ci.com/broadinstitute/gatk/jobs/341136121) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30435.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-635608349:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-635608349,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [30438](https://travis-ci.com/broadinstitute/gatk/builds/168656638); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30438.11](https://travis-ci.com/broadinstitute/gatk/jobs/341162861) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30438.11/tests/test/index.html) |; | integration | openjdk8 | [30438.2](https://travis-ci.com/broadinstitute/gatk/jobs/341162852) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30438.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-635642092:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-635642092,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30440](https://travis-ci.com/broadinstitute/gatk/builds/168676133); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30440.11](https://travis-ci.com/broadinstitute/gatk/jobs/341217438) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30440.11/tests/test/index.html) |; | integration | openjdk8 | [30440.2](https://travis-ci.com/broadinstitute/gatk/jobs/341217429) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30440.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6571#issuecomment-635722922:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6571#issuecomment-635722922,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30450](https://travis-ci.com/broadinstitute/gatk/builds/168819223); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30450.11](https://travis-ci.com/broadinstitute/gatk/jobs/341603988) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30450.11/tests/test/index.html) |; | integration | openjdk8 | [30450.2](https://travis-ci.com/broadinstitute/gatk/jobs/341603979) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30450.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-636225750:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-636225750,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30452](https://travis-ci.com/broadinstitute/gatk/builds/168836017); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30452.11](https://travis-ci.com/broadinstitute/gatk/jobs/341649474) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30452.11/tests/test/index.html) |; | integration | openjdk8 | [30452.2](https://travis-ci.com/broadinstitute/gatk/jobs/341649465) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30452.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-636272145:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-636272145,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30457](https://travis-ci.com/broadinstitute/gatk/builds/169030325); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30457.11](https://travis-ci.com/broadinstitute/gatk/jobs/342158813) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30457.11/tests/test/index.html) |; | integration | openjdk8 | [30457.2](https://travis-ci.com/broadinstitute/gatk/jobs/342158804) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30457.2/tests/test/index.html) |; | integration | openjdk11 | [30457.11](https://travis-ci.com/broadinstitute/gatk/jobs/342158813) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30457.11/tests/test/index.html) |; | integration | openjdk8 | [30457.2](https://travis-ci.com/broadinstitute/gatk/jobs/342158804) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30457.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6628#issuecomment-636901985:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6628#issuecomment-636901985,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [30459](https://travis-ci.com/broadinstitute/gatk/builds/169034436); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30459.11](https://travis-ci.com/broadinstitute/gatk/jobs/342168332) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30459.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-636917795:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-636917795,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [30475](https://travis-ci.com/broadinstitute/gatk/builds/169229345); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30475.11](https://travis-ci.com/broadinstitute/gatk/jobs/342675165) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30475.11/tests/test/index.html) |; | integration | openjdk8 | [30475.2](https://travis-ci.com/broadinstitute/gatk/jobs/342675156) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30475.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-637680721:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-637680721,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30477](https://travis-ci.com/broadinstitute/gatk/builds/169277901); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30477.11](https://travis-ci.com/broadinstitute/gatk/jobs/342782902) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30477.11/tests/test/index.html) |; | integration | openjdk8 | [30477.2](https://travis-ci.com/broadinstitute/gatk/jobs/342782893) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30477.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-637717214:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6561#issuecomment-637717214,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30481](https://travis-ci.com/broadinstitute/gatk/builds/169292148); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30481.11](https://travis-ci.com/broadinstitute/gatk/jobs/342819741) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30481.11/tests/test/index.html) |; | integration | openjdk8 | [30481.2](https://travis-ci.com/broadinstitute/gatk/jobs/342819732) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30481.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6632#issuecomment-637767968:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6632#issuecomment-637767968,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30487](https://travis-ci.com/broadinstitute/gatk/builds/169311637); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30487.11](https://travis-ci.com/broadinstitute/gatk/jobs/342871642) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30487.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-637836728:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-637836728,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [30489](https://travis-ci.com/broadinstitute/gatk/builds/169313463); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30489.11](https://travis-ci.com/broadinstitute/gatk/jobs/342876908) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30489.11/tests/test/index.html) |; | integration | openjdk8 | [30489.2](https://travis-ci.com/broadinstitute/gatk/jobs/342876899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30489.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6559#issuecomment-637843246:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6559#issuecomment-637843246,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30494](https://travis-ci.com/broadinstitute/gatk/builds/169351481); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30494.11](https://travis-ci.com/broadinstitute/gatk/jobs/342986478) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30494.11/tests/test/index.html) |; | integration | openjdk8 | [30494.2](https://travis-ci.com/broadinstitute/gatk/jobs/342986469) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30494.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6636#issuecomment-637936325:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6636#issuecomment-637936325,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30509](https://travis-ci.com/broadinstitute/gatk/builds/169658943); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30509.11](https://travis-ci.com/broadinstitute/gatk/jobs/343744765) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30509.11/tests/test/index.html) |; | integration | openjdk8 | [30509.2](https://travis-ci.com/broadinstitute/gatk/jobs/343744756) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30509.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-639041011:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-639041011,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30624](https://travis-ci.com/broadinstitute/gatk/builds/171270341); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30624.11](https://travis-ci.com/broadinstitute/gatk/jobs/348890773) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30624.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-643784213:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-643784213,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [30643](https://travis-ci.com/broadinstitute/gatk/builds/171606871); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | conda | openjdk8 | [30643.5](https://travis-ci.com/broadinstitute/gatk/jobs/349726487) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30643.5/tests/test/index.html) |; | unit | openjdk11 | [30643.12](https://travis-ci.com/broadinstitute/gatk/jobs/349726494) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30643.12/tests/test/index.html) |; | integration | openjdk11 | [30643.11](https://travis-ci.com/broadinstitute/gatk/jobs/349726493) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30643.11/tests/test/index.html) |; | unit | openjdk8 | [30643.3](https://travis-ci.com/broadinstitute/gatk/jobs/349726485) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30643.3/tests/test/index.html) |; | integration | openjdk8 | [30643.2](https://travis-ci.com/broadinstitute/gatk/jobs/349726484) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30643.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-644793169:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-644793169,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30644](https://travis-ci.com/broadinstitute/gatk/builds/171613538); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30644.11](https://travis-ci.com/broadinstitute/gatk/jobs/349743817) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30644.11/tests/test/index.html) |; | integration | openjdk8 | [30644.2](https://travis-ci.com/broadinstitute/gatk/jobs/349743808) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30644.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-644819369:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-644819369,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30666](https://travis-ci.com/broadinstitute/gatk/builds/171680645); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [30666.12](https://travis-ci.com/broadinstitute/gatk/jobs/349984895) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30666.12/tests/test/index.html) |; | conda | openjdk8 | [30666.5](https://travis-ci.com/broadinstitute/gatk/jobs/349984888) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30666.5/tests/test/index.html) |; | integration | openjdk11 | [30666.11](https://travis-ci.com/broadinstitute/gatk/jobs/349984894) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30666.11/tests/test/index.html) |; | unit | openjdk8 | [30666.3](https://travis-ci.com/broadinstitute/gatk/jobs/349984886) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30666.3/tests/test/index.html) |; | integration | openjdk8 | [30666.2](https://travis-ci.com/broadinstitute/gatk/jobs/349984885) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30666.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-644966563:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-644966563,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30678](https://travis-ci.com/broadinstitute/gatk/builds/171691595); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [30678.12](https://travis-ci.com/broadinstitute/gatk/jobs/350014518) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30678.12/tests/test/index.html) |; | conda | openjdk8 | [30678.5](https://travis-ci.com/broadinstitute/gatk/jobs/350014511) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30678.5/tests/test/index.html) |; | integration | openjdk11 | [30678.11](https://travis-ci.com/broadinstitute/gatk/jobs/350014517) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30678.11/tests/test/index.html) |; | unit | openjdk8 | [30678.3](https://travis-ci.com/broadinstitute/gatk/jobs/350014509) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30678.3/tests/test/index.html) |; | integration | openjdk8 | [30678.2](https://travis-ci.com/broadinstitute/gatk/jobs/350014508) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30678.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-645006687:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-645006687,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30698](https://travis-ci.com/broadinstitute/gatk/builds/171852295); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30698.11](https://travis-ci.com/broadinstitute/gatk/jobs/350395411) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30698.11/tests/test/index.html) |; | variantcalling | openjdk8 | [30698.4](https://travis-ci.com/broadinstitute/gatk/jobs/350395404) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30698.4/tests/test/index.html) |; | integration | openjdk8 | [30698.2](https://travis-ci.com/broadinstitute/gatk/jobs/350395402) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30698.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-645419790:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-645419790,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30705](https://travis-ci.com/broadinstitute/gatk/builds/171899359); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [30705.12](https://travis-ci.com/broadinstitute/gatk/jobs/350530956) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30705.12/tests/test/index.html) |; | conda | openjdk8 | [30705.5](https://travis-ci.com/broadinstitute/gatk/jobs/350530949) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30705.5/tests/test/index.html) |; | integration | openjdk11 | [30705.11](https://travis-ci.com/broadinstitute/gatk/jobs/350530955) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30705.11/tests/test/index.html) |; | unit | openjdk8 | [30705.3](https://travis-ci.com/broadinstitute/gatk/jobs/350530947) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30705.3/tests/test/index.html) |; | integration | openjdk8 | [30705.2](https://travis-ci.com/broadinstitute/gatk/jobs/350530946) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30705.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-645543363:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-645543363,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30712](https://travis-ci.com/broadinstitute/gatk/builds/171935407); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30712.11](https://travis-ci.com/broadinstitute/gatk/jobs/350622577) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30712.11/tests/test/index.html) |; | cloud | openjdk8 | [30712.1](https://travis-ci.com/broadinstitute/gatk/jobs/350622567) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30712.1/tests/test/index.html) |; | cloud | openjdk11 | [30712.13](https://travis-ci.com/broadinstitute/gatk/jobs/350622579) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30712.13/tests/test/index.html) |; | unit | openjdk11 | [30712.12](https://travis-ci.com/broadinstitute/gatk/jobs/350622578) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30712.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6612#issuecomment-645656060:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6612#issuecomment-645656060,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [30869](https://travis-ci.com/broadinstitute/gatk/builds/174096694); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [30869.13](https://travis-ci.com/broadinstitute/gatk/jobs/357066667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30869.13/tests/test/index.html) |; | integration | openjdk11 | [30869.12](https://travis-ci.com/broadinstitute/gatk/jobs/357066666) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30869.12/tests/test/index.html) |; | variantcalling | openjdk8 | [30869.4](https://travis-ci.com/broadinstitute/gatk/jobs/357066658) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30869.4/tests/test/index.html) |; | unit | openjdk8 | [30869.3](https://travis-ci.com/broadinstitute/gatk/jobs/357066657) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30869.3/tests/test/index.html) |; | integration | openjdk8 | [30869.2](https://travis-ci.com/broadinstitute/gatk/jobs/357066656) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30869.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6113#issuecomment-653150268:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6113#issuecomment-653150268,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30892](https://travis-ci.com/broadinstitute/gatk/builds/174640358); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30892.12](https://travis-ci.com/broadinstitute/gatk/jobs/358397668) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30892.12/tests/test/index.html) |; | integration | openjdk8 | [30892.2](https://travis-ci.com/broadinstitute/gatk/jobs/358397658) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30892.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6684#issuecomment-654947147:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6684#issuecomment-654947147,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30955](https://travis-ci.com/broadinstitute/gatk/builds/175590051); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30955.12](https://travis-ci.com/broadinstitute/gatk/jobs/360964271) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30955.12/tests/test/index.html) |; | integration | openjdk8 | [30955.2](https://travis-ci.com/broadinstitute/gatk/jobs/360964260) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30955.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658304029:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658304029,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30957](https://travis-ci.com/broadinstitute/gatk/builds/175592807); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30957.12](https://travis-ci.com/broadinstitute/gatk/jobs/360970944) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30957.12/tests/test/index.html) |; | integration | openjdk8 | [30957.2](https://travis-ci.com/broadinstitute/gatk/jobs/360970934) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30957.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658313849:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658313849,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30961](https://travis-ci.com/broadinstitute/gatk/builds/175596623); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30961.12](https://travis-ci.com/broadinstitute/gatk/jobs/360981529) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30961.12/tests/test/index.html) |; | integration | openjdk8 | [30961.2](https://travis-ci.com/broadinstitute/gatk/jobs/360981519) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30961.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658331353:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658331353,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30964](https://travis-ci.com/broadinstitute/gatk/builds/175616122); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30964.12](https://travis-ci.com/broadinstitute/gatk/jobs/361032988) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30964.12/tests/test/index.html) |; | integration | openjdk8 | [30964.2](https://travis-ci.com/broadinstitute/gatk/jobs/361032978) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30964.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658402464:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-658402464,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30972](https://travis-ci.com/broadinstitute/gatk/builds/175949953); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [30972.1](https://travis-ci.com/broadinstitute/gatk/jobs/361875017) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30972.1/tests/test/index.html) |; | integration | openjdk11 | [30972.12](https://travis-ci.com/broadinstitute/gatk/jobs/361875028) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30972.12/tests/test/index.html) |; | integration | openjdk8 | [30972.2](https://travis-ci.com/broadinstitute/gatk/jobs/361875018) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30972.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-659640018:423,integrat,integration,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-659640018,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30974](https://travis-ci.com/broadinstitute/gatk/builds/175951574); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [30974.1](https://travis-ci.com/broadinstitute/gatk/jobs/361879074) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.1/tests/test/index.html) |; | unit | openjdk11 | [30974.13](https://travis-ci.com/broadinstitute/gatk/jobs/361879086) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.13/tests/test/index.html) |; | conda | openjdk8 | [30974.5](https://travis-ci.com/broadinstitute/gatk/jobs/361879078) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.5/tests/test/index.html) |; | integration | openjdk11 | [30974.12](https://travis-ci.com/broadinstitute/gatk/jobs/361879085) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.12/tests/test/index.html) |; | unit | openjdk8 | [30974.3](https://travis-ci.com/broadinstitute/gatk/jobs/361879076) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.3/tests/test/index.html) |; | integration | openjdk8 | [30974.2](https://travis-ci.com/broadinstitute/gatk/jobs/361879075) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30974.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-659647328:835,integrat,integration,835,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-659647328,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30976](https://travis-ci.com/broadinstitute/gatk/builds/175952777); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30976.12](https://travis-ci.com/broadinstitute/gatk/jobs/361882175) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30976.12/tests/test/index.html) |; | integration | openjdk8 | [30976.2](https://travis-ci.com/broadinstitute/gatk/jobs/361882165) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30976.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-659661207:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-659661207,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30984](https://travis-ci.com/broadinstitute/gatk/builds/176331364); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30984.12](https://travis-ci.com/broadinstitute/gatk/jobs/362887049) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30984.12/tests/test/index.html) |; | integration | openjdk8 | [30984.2](https://travis-ci.com/broadinstitute/gatk/jobs/362887038) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30984.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6602#issuecomment-661096333:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6602#issuecomment-661096333,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [30988](https://travis-ci.com/broadinstitute/gatk/builds/176344004); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [30988.12](https://travis-ci.com/broadinstitute/gatk/jobs/362915950) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30988.12/tests/test/index.html) |; | integration | openjdk8 | [30988.2](https://travis-ci.com/broadinstitute/gatk/jobs/362915940) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_30988.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6602#issuecomment-661139174:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6602#issuecomment-661139174,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31014](https://travis-ci.com/broadinstitute/gatk/builds/176929508); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31014.12](https://travis-ci.com/broadinstitute/gatk/jobs/364378637) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31014.12/tests/test/index.html) |; | integration | openjdk8 | [31014.2](https://travis-ci.com/broadinstitute/gatk/jobs/364378627) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31014.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6723#issuecomment-663219099:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6723#issuecomment-663219099,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31019](https://travis-ci.com/broadinstitute/gatk/builds/177075400); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [31019.13](https://travis-ci.com/broadinstitute/gatk/jobs/364732566) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31019.13/tests/test/index.html) |; | integration | openjdk11 | [31019.12](https://travis-ci.com/broadinstitute/gatk/jobs/364732565) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31019.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-663706251:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-663706251,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31021](https://travis-ci.com/broadinstitute/gatk/builds/177076345); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [31021.13](https://travis-ci.com/broadinstitute/gatk/jobs/364735420) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31021.13/tests/test/index.html) |; | conda | openjdk8 | [31021.5](https://travis-ci.com/broadinstitute/gatk/jobs/364735412) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31021.5/tests/test/index.html) |; | integration | openjdk11 | [31021.12](https://travis-ci.com/broadinstitute/gatk/jobs/364735419) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31021.12/tests/test/index.html) |; | unit | openjdk8 | [31021.3](https://travis-ci.com/broadinstitute/gatk/jobs/364735410) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31021.3/tests/test/index.html) |; | integration | openjdk8 | [31021.2](https://travis-ci.com/broadinstitute/gatk/jobs/364735409) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31021.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-663710294:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-663710294,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31043](https://travis-ci.com/broadinstitute/gatk/builds/177838328); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [31043.13](https://travis-ci.com/broadinstitute/gatk/jobs/366761867) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31043.13/tests/test/index.html) |; | conda | openjdk8 | [31043.5](https://travis-ci.com/broadinstitute/gatk/jobs/366761859) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31043.5/tests/test/index.html) |; | integration | openjdk11 | [31043.12](https://travis-ci.com/broadinstitute/gatk/jobs/366761866) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31043.12/tests/test/index.html) |; | unit | openjdk8 | [31043.3](https://travis-ci.com/broadinstitute/gatk/jobs/366761857) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31043.3/tests/test/index.html) |; | integration | openjdk8 | [31043.2](https://travis-ci.com/broadinstitute/gatk/jobs/366761856) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31043.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-666525725:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-666525725,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31078](https://travis-ci.com/broadinstitute/gatk/builds/178593210); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31078.12](https://travis-ci.com/broadinstitute/gatk/jobs/368742472) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31078.12/tests/test/index.html) |; | variantcalling | openjdk8 | [31078.4](https://travis-ci.com/broadinstitute/gatk/jobs/368742464) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31078.4/tests/test/index.html) |; | integration | openjdk8 | [31078.2](https://travis-ci.com/broadinstitute/gatk/jobs/368742462) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31078.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-669368534:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-669368534,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31080](https://travis-ci.com/broadinstitute/gatk/builds/178599096); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31080.12](https://travis-ci.com/broadinstitute/gatk/jobs/368765328) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31080.12/tests/test/index.html) |; | integration | openjdk8 | [31080.2](https://travis-ci.com/broadinstitute/gatk/jobs/368765318) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31080.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-669402367:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-669402367,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31110](https://travis-ci.com/broadinstitute/gatk/builds/179177202); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31110.12](https://travis-ci.com/broadinstitute/gatk/jobs/370468323) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31110.12/tests/test/index.html) |; | integration | openjdk8 | [31110.2](https://travis-ci.com/broadinstitute/gatk/jobs/370468313) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31110.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-671583467:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-671583467,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31195](https://travis-ci.com/broadinstitute/gatk/builds/181151716); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [31195.14](https://travis-ci.com/broadinstitute/gatk/jobs/377065385) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31195.14/tests/test/index.html) |; | integration | openjdk8 | [31195.2](https://travis-ci.com/broadinstitute/gatk/jobs/377065373) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31195.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-679370909:426,integrat,integration,426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-679370909,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31212](https://travis-ci.com/broadinstitute/gatk/builds/181345735); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31212.2](https://travis-ci.com/broadinstitute/gatk/jobs/377600452) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31212.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680182147:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680182147,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31215](https://travis-ci.com/broadinstitute/gatk/builds/181356386); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31215.2](https://travis-ci.com/broadinstitute/gatk/jobs/377629183) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31215.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680225942:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680225942,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31219](https://travis-ci.com/broadinstitute/gatk/builds/181373545); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31219.2](https://travis-ci.com/broadinstitute/gatk/jobs/377677482) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31219.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680264087:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680264087,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31232](https://travis-ci.com/broadinstitute/gatk/builds/181489744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31232.12](https://travis-ci.com/broadinstitute/gatk/jobs/377973557) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31232.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680949614:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-680949614,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31239](https://travis-ci.com/broadinstitute/gatk/builds/181521398); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31239.12](https://travis-ci.com/broadinstitute/gatk/jobs/378060367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31239.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-681066658:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-681066658,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31247](https://travis-ci.com/broadinstitute/gatk/builds/181644287); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31247.2](https://travis-ci.com/broadinstitute/gatk/jobs/378372688) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31247.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-681992455:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-681992455,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31250](https://travis-ci.com/broadinstitute/gatk/builds/181656346); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31250.2](https://travis-ci.com/broadinstitute/gatk/jobs/378403341) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31250.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-682037890:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-682037890,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31337](https://travis-ci.com/broadinstitute/gatk/builds/183389891); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31337.12](https://travis-ci.com/broadinstitute/gatk/jobs/382388334) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31337.12/tests/test/index.html) |; | integration | openjdk8 | [31337.2](https://travis-ci.com/broadinstitute/gatk/jobs/382388324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31337.2/tests/test/index.html) |; | integration | openjdk8 | [31337.2](https://travis-ci.com/broadinstitute/gatk/jobs/382388324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31337.2/tests/test/index.html) |; | integration | openjdk11 | [31337.12](https://travis-ci.com/broadinstitute/gatk/jobs/382388334) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31337.12/tests/test/index.html) |; | integration | openjdk8 | [31337.2](https://travis-ci.com/broadinstitute/gatk/jobs/382388324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31337.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6799#issuecomment-688972966:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6799#issuecomment-688972966,5,['integrat'],['integration']
Integrability,Travis reported job failures from build [31339](https://travis-ci.com/broadinstitute/gatk/builds/183391027); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31339.12](https://travis-ci.com/broadinstitute/gatk/jobs/382390918) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31339.12/tests/test/index.html) |; | integration | openjdk8 | [31339.2](https://travis-ci.com/broadinstitute/gatk/jobs/382390908) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31339.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-688977676:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-688977676,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31347](https://travis-ci.com/broadinstitute/gatk/builds/183553091); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31347.12](https://travis-ci.com/broadinstitute/gatk/jobs/382751875) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31347.12/tests/test/index.html) |; | integration | openjdk8 | [31347.2](https://travis-ci.com/broadinstitute/gatk/jobs/382751865) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31347.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6802#issuecomment-689573574:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6802#issuecomment-689573574,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31349](https://travis-ci.com/broadinstitute/gatk/builds/183570461); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [31349.1](https://travis-ci.com/broadinstitute/gatk/jobs/382794132) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31349.1/tests/test/index.html) |; | integration | openjdk11 | [31349.12](https://travis-ci.com/broadinstitute/gatk/jobs/382794143) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31349.12/tests/test/index.html) |; | integration | openjdk8 | [31349.2](https://travis-ci.com/broadinstitute/gatk/jobs/382794133) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31349.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-689627653:423,integrat,integration,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-689627653,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31351](https://travis-ci.com/broadinstitute/gatk/builds/183609447); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31351.12](https://travis-ci.com/broadinstitute/gatk/jobs/382897378) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31351.12/tests/test/index.html) |; | integration | openjdk8 | [31351.2](https://travis-ci.com/broadinstitute/gatk/jobs/382897368) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31351.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-689773463:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-689773463,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31353](https://travis-ci.com/broadinstitute/gatk/builds/183610371); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31353.12](https://travis-ci.com/broadinstitute/gatk/jobs/382899552) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31353.12/tests/test/index.html) |; | integration | openjdk8 | [31353.2](https://travis-ci.com/broadinstitute/gatk/jobs/382899542) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31353.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-689779833:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660#issuecomment-689779833,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31358](https://travis-ci.com/broadinstitute/gatk/builds/183616396); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31358.12](https://travis-ci.com/broadinstitute/gatk/jobs/382914758) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31358.12/tests/test/index.html) |; | integration | openjdk8 | [31358.2](https://travis-ci.com/broadinstitute/gatk/jobs/382914748) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31358.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-689804506:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6800#issuecomment-689804506,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31362](https://travis-ci.com/broadinstitute/gatk/builds/183621979); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31362.12](https://travis-ci.com/broadinstitute/gatk/jobs/382955645) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31362.12/tests/test/index.html) |; | integration | openjdk8 | [31362.2](https://travis-ci.com/broadinstitute/gatk/jobs/382955635) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31362.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6718#issuecomment-689817531:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6718#issuecomment-689817531,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31384](https://travis-ci.com/broadinstitute/gatk/builds/183805923); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31384.12](https://travis-ci.com/broadinstitute/gatk/jobs/383393943) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_31384.12/tests/test/index.html) |; | integration | openjdk8 | [31384.2](https://travis-ci.com/broadinstitute/gatk/jobs/383393933) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_31384.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6806#issuecomment-690768109:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6806#issuecomment-690768109,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31394](https://travis-ci.com/broadinstitute/gatk/builds/183915996); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [31394.14](https://travis-ci.com/broadinstitute/gatk/jobs/383673641) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31394.14/tests/test/index.html) |; | integration | openjdk11 | [31394.12](https://travis-ci.com/broadinstitute/gatk/jobs/383673639) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31394.12/tests/test/index.html) |; | integration | openjdk8 | [31394.2](https://travis-ci.com/broadinstitute/gatk/jobs/383673629) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31394.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6809#issuecomment-691150417:426,integrat,integration,426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6809#issuecomment-691150417,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31727](https://travis-ci.com/broadinstitute/gatk/builds/189051039); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [31727.2](https://travis-ci.com/broadinstitute/gatk/jobs/397423689) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31727.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-706233780:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6624#issuecomment-706233780,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31792](https://travis-ci.com/broadinstitute/gatk/builds/189715425); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31792.13](https://travis-ci.com/broadinstitute/gatk/jobs/398842818) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_31792.13/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6881#issuecomment-707791058:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6881#issuecomment-707791058,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [31957](https://travis-ci.com/broadinstitute/gatk/builds/195786303); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31957.12](https://travis-ci.com/broadinstitute/gatk/jobs/419334595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31957.12/tests/test/index.html) |; | integration | openjdk8 | [31957.2](https://travis-ci.com/broadinstitute/gatk/jobs/419334585) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31957.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-718862955:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-718862955,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [31965](https://travis-ci.com/broadinstitute/gatk/builds/195873537); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [31965.12](https://travis-ci.com/broadinstitute/gatk/jobs/419598303) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31965.12/tests/test/index.html) |; | integration | openjdk8 | [31965.2](https://travis-ci.com/broadinstitute/gatk/jobs/419598293) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_31965.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-718895504:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-718895504,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32049](https://travis-ci.com/broadinstitute/gatk/builds/198559577); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32049.12](https://travis-ci.com/broadinstitute/gatk/jobs/429147025) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32049.12/tests/test/index.html) |; | integration | openjdk8 | [32049.2](https://travis-ci.com/broadinstitute/gatk/jobs/429147015) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32049.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-722658012:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-722658012,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32149](https://travis-ci.com/broadinstitute/gatk/builds/202173930); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [32149.1](https://travis-ci.com/broadinstitute/gatk/jobs/441791105) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32149.1/tests/test/index.html) |; | integration | openjdk11 | [32149.12](https://travis-ci.com/broadinstitute/gatk/jobs/441791121) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32149.12/tests/test/index.html) |; | conda | openjdk8 | [32149.5](https://travis-ci.com/broadinstitute/gatk/jobs/441791111) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32149.5/tests/test/index.html) |; | unit | openjdk8 | [32149.3](https://travis-ci.com/broadinstitute/gatk/jobs/441791108) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32149.3/tests/test/index.html) |; | integration | openjdk8 | [32149.2](https://travis-ci.com/broadinstitute/gatk/jobs/441791106) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32149.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-729060312:423,integrat,integration,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-729060312,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32180](https://travis-ci.com/broadinstitute/gatk/builds/202787538); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32180.12](https://travis-ci.com/broadinstitute/gatk/jobs/443607068) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32180.12/tests/test/index.html) |; | integration | openjdk8 | [32180.2](https://travis-ci.com/broadinstitute/gatk/jobs/443607058) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32180.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-730467975:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-730467975,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32196](https://travis-ci.com/broadinstitute/gatk/builds/202875234); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32196.12](https://travis-ci.com/broadinstitute/gatk/jobs/443900497) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32196.12/tests/test/index.html) |; | integration | openjdk8 | [32196.2](https://travis-ci.com/broadinstitute/gatk/jobs/443900487) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32196.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-730608277:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6928#issuecomment-730608277,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32198](https://travis-ci.com/broadinstitute/gatk/builds/202876316); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32198.12](https://travis-ci.com/broadinstitute/gatk/jobs/443903163) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32198.12/tests/test/index.html) |; | integration | openjdk8 | [32198.2](https://travis-ci.com/broadinstitute/gatk/jobs/443903153) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32198.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-730613743:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-730613743,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32308](https://travis-ci.com/broadinstitute/gatk/builds/206017880); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32308.12](https://travis-ci.com/broadinstitute/gatk/jobs/452716639) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32308.12/tests/test/index.html) |; | integration | openjdk8 | [32308.2](https://travis-ci.com/broadinstitute/gatk/jobs/452716628) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32308.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-737442197:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6430#issuecomment-737442197,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32329](https://travis-ci.com/broadinstitute/gatk/builds/206640419); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [32329.1](https://travis-ci.com/broadinstitute/gatk/jobs/454533901) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.1/tests/test/index.html) |; | cloud | openjdk11 | [32329.14](https://travis-ci.com/broadinstitute/gatk/jobs/454533914) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.14/tests/test/index.html) |; | integration | openjdk11 | [32329.12](https://travis-ci.com/broadinstitute/gatk/jobs/454533912) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.12/tests/test/index.html) |; | integration | openjdk8 | [32329.2](https://travis-ci.com/broadinstitute/gatk/jobs/454533902) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.2/tests/test/index.html) |; | cloud | openjdk8 | [32329.1](https://travis-ci.com/broadinstitute/gatk/jobs/454533901) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.1/tests/test/index.html) |; | cloud | openjdk11 | [32329.14](https://travis-ci.com/broadinstitute/gatk/jobs/454533914) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.14/tests/test/index.html) |; | integration | openjdk11 | [32329.12](https://travis-ci.com/broadinstitute/gatk/jobs/454533912) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.12/tests/test/index.html) |; | integration | openjdk8 | [32329.2](https://travis-ci.com/broadinstitute/gatk/jobs/454533902) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32329.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6989#issuecomment-738879938:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6989#issuecomment-738879938,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [32366](https://travis-ci.com/broadinstitute/gatk/builds/208141255); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [32366.13](https://travis-ci.com/broadinstitute/gatk/jobs/458419765) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32366.13/tests/test/index.html) |; | integration | openjdk11 | [32366.12](https://travis-ci.com/broadinstitute/gatk/jobs/458419764) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32366.12/tests/test/index.html) |; | conda | openjdk8 | [32366.5](https://travis-ci.com/broadinstitute/gatk/jobs/458419757) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32366.5/tests/test/index.html) |; | unit | openjdk8 | [32366.3](https://travis-ci.com/broadinstitute/gatk/jobs/458419755) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32366.3/tests/test/index.html) |; | integration | openjdk8 | [32366.2](https://travis-ci.com/broadinstitute/gatk/jobs/458419754) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32366.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-743353051:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6554#issuecomment-743353051,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32512](https://travis-ci.com/broadinstitute/gatk/builds/212721931); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk8 | [32512.3](https://travis-ci.com/broadinstitute/gatk/jobs/470580370) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.3/tests/test/index.html) |; | integration | openjdk8 | [32512.2](https://travis-ci.com/broadinstitute/gatk/jobs/470580369) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.2/tests/test/index.html) |; | cloud | openjdk11 | [32512.14](https://travis-ci.com/broadinstitute/gatk/jobs/470580381) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.14/tests/test/index.html) |; | cloud | openjdk8 | [32512.1](https://travis-ci.com/broadinstitute/gatk/jobs/470580368) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.1/tests/test/index.html) |; | unit | openjdk11 | [32512.13](https://travis-ci.com/broadinstitute/gatk/jobs/470580380) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.13/tests/test/index.html) |; | integration | openjdk11 | [32512.12](https://travis-ci.com/broadinstitute/gatk/jobs/470580379) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.12/tests/test/index.html) |; | unit | openjdk8 | [32512.3](https://travis-ci.com/broadinstitute/gatk/jobs/470580370) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.3/tests/test/index.html) |; | integration | openjdk8 | [32512.2](https://travis-ci.com/broadinstitute/gatk/jobs/470580369) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32512.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-758148911:422,integrat,integration,422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-758148911,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [32589](https://travis-ci.com/broadinstitute/gatk/builds/213965618); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32589.12](https://travis-ci.com/broadinstitute/gatk/jobs/473858986) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32589.12/tests/test/index.html) |; | integration | openjdk8 | [32589.2](https://travis-ci.com/broadinstitute/gatk/jobs/473858976) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32589.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7046#issuecomment-764774849:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7046#issuecomment-764774849,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32607](https://travis-ci.com/broadinstitute/gatk/builds/214188217); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [32607.1](https://travis-ci.com/broadinstitute/gatk/jobs/474485135) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.1/tests/test/index.html) |; | cloud | openjdk11 | [32607.14](https://travis-ci.com/broadinstitute/gatk/jobs/474485148) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.14/tests/test/index.html) |; | integration | openjdk11 | [32607.12](https://travis-ci.com/broadinstitute/gatk/jobs/474485146) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.12/tests/test/index.html) |; | integration | openjdk8 | [32607.2](https://travis-ci.com/broadinstitute/gatk/jobs/474485136) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.2/tests/test/index.html) |; | cloud | openjdk11 | [32607.14](https://travis-ci.com/broadinstitute/gatk/jobs/474485148) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.14/tests/test/index.html) |; | cloud | openjdk8 | [32607.1](https://travis-ci.com/broadinstitute/gatk/jobs/474485135) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.1/tests/test/index.html) |; | integration | openjdk11 | [32607.12](https://travis-ci.com/broadinstitute/gatk/jobs/474485146) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.12/tests/test/index.html) |; | integration | openjdk8 | [32607.2](https://travis-ci.com/broadinstitute/gatk/jobs/474485136) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32607.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-765667586:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-765667586,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [32618](https://travis-ci.com/broadinstitute/gatk/builds/214398386); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [32618.1](https://travis-ci.com/broadinstitute/gatk/jobs/475091885) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32618.1/tests/test/index.html) |; | cloud | openjdk11 | [32618.14](https://travis-ci.com/broadinstitute/gatk/jobs/475091898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32618.14/tests/test/index.html) |; | integration | openjdk11 | [32618.12](https://travis-ci.com/broadinstitute/gatk/jobs/475091896) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32618.12/tests/test/index.html) |; | integration | openjdk8 | [32618.2](https://travis-ci.com/broadinstitute/gatk/jobs/475091886) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32618.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6989#issuecomment-766922899:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6989#issuecomment-766922899,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32622](https://travis-ci.com/broadinstitute/gatk/builds/214430101); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [32622.1](https://travis-ci.com/broadinstitute/gatk/jobs/475160500) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32622.1/tests/test/index.html) |; | cloud | openjdk11 | [32622.14](https://travis-ci.com/broadinstitute/gatk/jobs/475160513) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32622.14/tests/test/index.html) |; | integration | openjdk11 | [32622.12](https://travis-ci.com/broadinstitute/gatk/jobs/475160511) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32622.12/tests/test/index.html) |; | integration | openjdk8 | [32622.2](https://travis-ci.com/broadinstitute/gatk/jobs/475160501) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32622.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-767055706:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-767055706,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32624](https://travis-ci.com/broadinstitute/gatk/builds/214440857); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32624.12](https://travis-ci.com/broadinstitute/gatk/jobs/475184731) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32624.12/tests/test/index.html) |; | integration | openjdk8 | [32624.2](https://travis-ci.com/broadinstitute/gatk/jobs/475184721) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32624.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-767117162:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026#issuecomment-767117162,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32658](https://travis-ci.com/broadinstitute/gatk/builds/214909015); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32658.12](https://travis-ci.com/broadinstitute/gatk/jobs/477355523) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32658.12/tests/test/index.html) |; | integration | openjdk8 | [32658.2](https://travis-ci.com/broadinstitute/gatk/jobs/477355513) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32658.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7058#issuecomment-768431643:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7058#issuecomment-768431643,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32698](https://travis-ci.com/broadinstitute/gatk/builds/215638691); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32698.12](https://travis-ci.com/broadinstitute/gatk/jobs/479312671) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32698.12/tests/test/index.html) |; | integration | openjdk8 | [32698.2](https://travis-ci.com/broadinstitute/gatk/jobs/479312661) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32698.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7063#issuecomment-771066064:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7063#issuecomment-771066064,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32700](https://travis-ci.com/broadinstitute/gatk/builds/215640700); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [32700.2](https://travis-ci.com/broadinstitute/gatk/jobs/479317038) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32700.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7063#issuecomment-771096981:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7063#issuecomment-771096981,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [32714](https://travis-ci.com/broadinstitute/gatk/builds/215832180); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32714.12](https://travis-ci.com/broadinstitute/gatk/jobs/479776403) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32714.12/tests/test/index.html) |; | integration | openjdk8 | [32714.2](https://travis-ci.com/broadinstitute/gatk/jobs/479776393) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32714.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7066#issuecomment-772003143:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7066#issuecomment-772003143,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [32755](https://travis-ci.com/broadinstitute/gatk/builds/216440553); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [32755.13](https://travis-ci.com/broadinstitute/gatk/jobs/481338469) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32755.13/tests/test/index.html) |; | integration | openjdk11 | [32755.12](https://travis-ci.com/broadinstitute/gatk/jobs/481338468) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32755.12/tests/test/index.html) |; | unit | openjdk8 | [32755.3](https://travis-ci.com/broadinstitute/gatk/jobs/481338459) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32755.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6763#issuecomment-775371146:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6763#issuecomment-775371146,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [32758](https://travis-ci.com/broadinstitute/gatk/builds/216451581); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [32758.12](https://travis-ci.com/broadinstitute/gatk/jobs/481368144) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32758.12/tests/test/index.html) |; | integration | openjdk8 | [32758.2](https://travis-ci.com/broadinstitute/gatk/jobs/481368134) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_32758.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6763#issuecomment-775457190:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6763#issuecomment-775457190,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33028](https://travis-ci.com/broadinstitute/gatk/builds/218904203); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [33028.13](https://travis-ci.com/broadinstitute/gatk/jobs/487894628) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33028.13/tests/test/index.html) |; | integration | openjdk11 | [33028.12](https://travis-ci.com/broadinstitute/gatk/jobs/487894627) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33028.12/tests/test/index.html) |; | integration | openjdk8 | [33028.2](https://travis-ci.com/broadinstitute/gatk/jobs/487894617) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33028.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-790085277:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-790085277,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33241](https://travis-ci.com/broadinstitute/gatk/builds/220390768); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33241.12](https://travis-ci.com/broadinstitute/gatk/jobs/491751868) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33241.12/tests/test/index.html) |; | integration | openjdk8 | [33241.2](https://travis-ci.com/broadinstitute/gatk/jobs/491751858) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33241.2/tests/test/index.html) |; | integration | openjdk11 | [33241.12](https://travis-ci.com/broadinstitute/gatk/jobs/491751868) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33241.12/tests/test/index.html) |; | integration | openjdk8 | [33241.2](https://travis-ci.com/broadinstitute/gatk/jobs/491751858) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33241.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-801174546:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-801174546,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [33277](https://travis-ci.com/broadinstitute/gatk/builds/220814326); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [33277.1](https://travis-ci.com/broadinstitute/gatk/jobs/492787754) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.1/tests/test/index.html) |; | cloud | openjdk11 | [33277.14](https://travis-ci.com/broadinstitute/gatk/jobs/492787767) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.14/tests/test/index.html) |; | unit | openjdk11 | [33277.13](https://travis-ci.com/broadinstitute/gatk/jobs/492787766) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.13/tests/test/index.html) |; | integration | openjdk11 | [33277.12](https://travis-ci.com/broadinstitute/gatk/jobs/492787765) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.12/tests/test/index.html) |; | unit | openjdk8 | [33277.3](https://travis-ci.com/broadinstitute/gatk/jobs/492787756) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.3/tests/test/index.html) |; | integration | openjdk8 | [33277.2](https://travis-ci.com/broadinstitute/gatk/jobs/492787755) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33277.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-804124554:838,integrat,integration,838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-804124554,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33368](https://travis-ci.com/broadinstitute/gatk/builds/221347661); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [33368.1](https://travis-ci.com/broadinstitute/gatk/jobs/494112466) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33368.1/tests/test/index.html) |; | cloud | openjdk11 | [33368.14](https://travis-ci.com/broadinstitute/gatk/jobs/494112479) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33368.14/tests/test/index.html) |; | integration | openjdk11 | [33368.12](https://travis-ci.com/broadinstitute/gatk/jobs/494112477) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33368.12/tests/test/index.html) |; | integration | openjdk8 | [33368.2](https://travis-ci.com/broadinstitute/gatk/jobs/494112467) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33368.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7166#issuecomment-808550699:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7166#issuecomment-808550699,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33381](https://travis-ci.com/broadinstitute/gatk/builds/221504222); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [33381.14](https://travis-ci.com/broadinstitute/gatk/jobs/494506581) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.14/tests/test/index.html) |; | cloud | openjdk8 | [33381.1](https://travis-ci.com/broadinstitute/gatk/jobs/494506568) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.1/tests/test/index.html) |; | unit | openjdk11 | [33381.13](https://travis-ci.com/broadinstitute/gatk/jobs/494506580) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.13/tests/test/index.html) |; | integration | openjdk11 | [33381.12](https://travis-ci.com/broadinstitute/gatk/jobs/494506579) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.12/tests/test/index.html) |; | unit | openjdk8 | [33381.3](https://travis-ci.com/broadinstitute/gatk/jobs/494506570) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.3/tests/test/index.html) |; | integration | openjdk8 | [33381.2](https://travis-ci.com/broadinstitute/gatk/jobs/494506569) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33381.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7166#issuecomment-809438028:838,integrat,integration,838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7166#issuecomment-809438028,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33441](https://travis-ci.com/broadinstitute/gatk/builds/221813707); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33441.12](https://travis-ci.com/broadinstitute/gatk/jobs/495278045) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33441.12/tests/test/index.html) |; | integration | openjdk8 | [33441.2](https://travis-ci.com/broadinstitute/gatk/jobs/495278035) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33441.2/tests/test/index.html) |; | integration | openjdk11 | [33441.12](https://travis-ci.com/broadinstitute/gatk/jobs/495278045) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33441.12/tests/test/index.html) |; | integration | openjdk8 | [33441.2](https://travis-ci.com/broadinstitute/gatk/jobs/495278035) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33441.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-811282668:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-811282668,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [33523](https://travis-ci.com/broadinstitute/gatk/builds/222089183); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33523.12](https://travis-ci.com/broadinstitute/gatk/jobs/495929374) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33523.12/tests/test/index.html) |; | integration | openjdk8 | [33523.2](https://travis-ci.com/broadinstitute/gatk/jobs/495929364) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33523.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813018382:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813018382,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33528](https://travis-ci.com/broadinstitute/gatk/builds/222109060); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33528.12](https://travis-ci.com/broadinstitute/gatk/jobs/495994529) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33528.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813154031:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813154031,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [33531](https://travis-ci.com/broadinstitute/gatk/builds/222109820); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33531.12](https://travis-ci.com/broadinstitute/gatk/jobs/495997078) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33531.12/tests/test/index.html) |; | integration | openjdk8 | [33531.2](https://travis-ci.com/broadinstitute/gatk/jobs/495997068) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33531.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813161773:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7154#issuecomment-813161773,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33698](https://travis-ci.com/broadinstitute/gatk/builds/222963404); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [33698.12](https://travis-ci.com/broadinstitute/gatk/jobs/498206052) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33698.12/tests/test/index.html) |; | integration | openjdk8 | [33698.2](https://travis-ci.com/broadinstitute/gatk/jobs/498206042) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33698.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-818922214:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7148#issuecomment-818922214,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33752](https://travis-ci.com/broadinstitute/gatk/builds/223087196); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [33752.14](https://travis-ci.com/broadinstitute/gatk/jobs/498538900) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.14/tests/test/index.html) |; | cloud | openjdk8 | [33752.1](https://travis-ci.com/broadinstitute/gatk/jobs/498538887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.1/tests/test/index.html) |; | unit | openjdk11 | [33752.13](https://travis-ci.com/broadinstitute/gatk/jobs/498538899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.13/tests/test/index.html) |; | integration | openjdk11 | [33752.12](https://travis-ci.com/broadinstitute/gatk/jobs/498538898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.12/tests/test/index.html) |; | variantcalling | openjdk8 | [33752.4](https://travis-ci.com/broadinstitute/gatk/jobs/498538890) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.4/tests/test/index.html) |; | unit | openjdk8 | [33752.3](https://travis-ci.com/broadinstitute/gatk/jobs/498538889) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.3/tests/test/index.html) |; | conda | openjdk8 | [33752.5](https://travis-ci.com/broadinstitute/gatk/jobs/498538891) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.5/tests/test/index.html) |; | integration | openjdk8 | [33752.2](https://travis-ci.com/broadinstitute/gatk/jobs/498538888) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.2/tests/test/index.html) |; | cloud | openjdk11 | [33752.14](https://travis-ci.com/broadinstitute/gatk/jobs/498538900) | [logs](https://storage.g,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234:838,integrat,integration,838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [33764](https://travis-ci.com/broadinstitute/gatk/builds/223104949); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [33764.13](https://travis-ci.com/broadinstitute/gatk/jobs/498596230) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_33764.13/tests/test/index.html) |; | integration | openjdk11 | [33764.12](https://travis-ci.com/broadinstitute/gatk/jobs/498596229) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_33764.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7192#issuecomment-819880055:431,integrat,integration,431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7192#issuecomment-819880055,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [33778](https://travis-ci.com/broadinstitute/gatk/builds/223218042); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [33778.1](https://travis-ci.com/broadinstitute/gatk/jobs/498881502) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.1/tests/test/index.html) |; | cloud | openjdk11 | [33778.14](https://travis-ci.com/broadinstitute/gatk/jobs/498881515) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.14/tests/test/index.html) |; | unit | openjdk11 | [33778.13](https://travis-ci.com/broadinstitute/gatk/jobs/498881514) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.13/tests/test/index.html) |; | integration | openjdk11 | [33778.12](https://travis-ci.com/broadinstitute/gatk/jobs/498881513) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.12/tests/test/index.html) |; | variantcalling | openjdk8 | [33778.4](https://travis-ci.com/broadinstitute/gatk/jobs/498881505) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.4/tests/test/index.html) |; | unit | openjdk8 | [33778.3](https://travis-ci.com/broadinstitute/gatk/jobs/498881504) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33778.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-820624091:838,integrat,integration,838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-820624091,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [33826](https://travis-ci.com/broadinstitute/gatk/builds/223338129); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [33826.13](https://travis-ci.com/broadinstitute/gatk/jobs/499176631) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33826.13/tests/test/index.html) |; | integration | openjdk11 | [33826.12](https://travis-ci.com/broadinstitute/gatk/jobs/499176630) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33826.12/tests/test/index.html) |; | unit | openjdk8 | [33826.3](https://travis-ci.com/broadinstitute/gatk/jobs/499176621) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33826.3/tests/test/index.html) |; | variantcalling | openjdk8 | [33826.4](https://travis-ci.com/broadinstitute/gatk/jobs/499176622) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33826.4/tests/test/index.html) |; | integration | openjdk8 | [33826.2](https://travis-ci.com/broadinstitute/gatk/jobs/499176620) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33826.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-821531530:425,integrat,integration,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-821531530,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [33926](https://travis-ci.com/broadinstitute/gatk/builds/224016577); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [33926.14](https://travis-ci.com/broadinstitute/gatk/jobs/500776650) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33926.14/tests/test/index.html) |; | cloud | openjdk8 | [33926.1](https://travis-ci.com/broadinstitute/gatk/jobs/500776637) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33926.1/tests/test/index.html) |; | integration | openjdk11 | [33926.12](https://travis-ci.com/broadinstitute/gatk/jobs/500776648) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33926.12/tests/test/index.html) |; | variantcalling | openjdk8 | [33926.4](https://travis-ci.com/broadinstitute/gatk/jobs/500776640) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33926.4/tests/test/index.html) |; | integration | openjdk8 | [33926.2](https://travis-ci.com/broadinstitute/gatk/jobs/500776638) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33926.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6514#issuecomment-825820423:631,integrat,integration,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6514#issuecomment-825820423,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34034](https://travis-ci.com/broadinstitute/gatk/builds/224639210); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [34034.1](https://travis-ci.com/broadinstitute/gatk/jobs/502313480) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.1/tests/test/index.html) |; | cloud | openjdk11 | [34034.14](https://travis-ci.com/broadinstitute/gatk/jobs/502313493) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.14/tests/test/index.html) |; | unit | openjdk11 | [34034.13](https://travis-ci.com/broadinstitute/gatk/jobs/502313492) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.13/tests/test/index.html) |; | integration | openjdk11 | [34034.12](https://travis-ci.com/broadinstitute/gatk/jobs/502313491) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.12/tests/test/index.html) |; | variantcalling | openjdk8 | [34034.4](https://travis-ci.com/broadinstitute/gatk/jobs/502313483) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.4/tests/test/index.html) |; | conda | openjdk8 | [34034.5](https://travis-ci.com/broadinstitute/gatk/jobs/502313484) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.5/tests/test/index.html) |; | unit | openjdk8 | [34034.3](https://travis-ci.com/broadinstitute/gatk/jobs/502313482) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.3/tests/test/index.html) |; | integration | openjdk8 | [34034.2](https://travis-ci.com/broadinstitute/gatk/jobs/502313481) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34034.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-830228734:838,integrat,integration,838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-830228734,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34176](https://travis-ci.com/broadinstitute/gatk/builds/225873785); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34176.12](https://travis-ci.com/broadinstitute/gatk/jobs/505251208) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34176.12/tests/test/index.html) |; | integration | openjdk8 | [34176.2](https://travis-ci.com/broadinstitute/gatk/jobs/505251198) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34176.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-840825700:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-840825700,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34203](https://travis-ci.com/broadinstitute/gatk/builds/226224930); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34203.12](https://travis-ci.com/broadinstitute/gatk/jobs/506165950) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34203.12/tests/test/index.html) |; | integration | openjdk8 | [34203.2](https://travis-ci.com/broadinstitute/gatk/jobs/506165940) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34203.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-843369362:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-843369362,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34279](https://travis-ci.com/broadinstitute/gatk/builds/226733391); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34279.12](https://travis-ci.com/broadinstitute/gatk/jobs/507507826) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34279.12/tests/test/index.html) |; | integration | openjdk8 | [34279.2](https://travis-ci.com/broadinstitute/gatk/jobs/507507816) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34279.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-847313079:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-847313079,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34296](https://travis-ci.com/broadinstitute/gatk/builds/226870023); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34296.12](https://travis-ci.com/broadinstitute/gatk/jobs/507857713) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34296.12/tests/test/index.html) |; | integration | openjdk8 | [34296.2](https://travis-ci.com/broadinstitute/gatk/jobs/507857703) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34296.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-848129767:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-848129767,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34321](https://travis-ci.com/broadinstitute/gatk/builds/227013958); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34321.12](https://travis-ci.com/broadinstitute/gatk/jobs/508266496) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_34321.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-849067439:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-849067439,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [34441](https://travis-ci.com/broadinstitute/gatk/builds/228463818); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34441.12](https://travis-ci.com/broadinstitute/gatk/jobs/512421669) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34441.12/tests/test/index.html) |; | unit | openjdk8 | [34441.3](https://travis-ci.com/broadinstitute/gatk/jobs/512421660) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34441.3/tests/test/index.html) |; | variantcalling | openjdk8 | [34441.4](https://travis-ci.com/broadinstitute/gatk/jobs/512421661) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34441.4/tests/test/index.html) |; | integration | openjdk8 | [34441.2](https://travis-ci.com/broadinstitute/gatk/jobs/512421659) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34441.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-857761857:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-857761857,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34475](https://travis-ci.com/broadinstitute/gatk/builds/228578939); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34475.12](https://travis-ci.com/broadinstitute/gatk/jobs/512727645) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34475.12/tests/test/index.html) |; | integration | openjdk8 | [34475.2](https://travis-ci.com/broadinstitute/gatk/jobs/512727635) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34475.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7303#issuecomment-858525709:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7303#issuecomment-858525709,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34532](https://travis-ci.com/broadinstitute/gatk/builds/228754848); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34532.12](https://travis-ci.com/broadinstitute/gatk/jobs/513165911) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34532.12/tests/test/index.html) |; | unit | openjdk8 | [34532.3](https://travis-ci.com/broadinstitute/gatk/jobs/513165902) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34532.3/tests/test/index.html) |; | variantcalling | openjdk8 | [34532.4](https://travis-ci.com/broadinstitute/gatk/jobs/513165903) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34532.4/tests/test/index.html) |; | integration | openjdk8 | [34532.2](https://travis-ci.com/broadinstitute/gatk/jobs/513165901) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34532.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-859898603:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-859898603,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34651](https://travis-ci.com/broadinstitute/gatk/builds/230215055); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34651.12](https://travis-ci.com/broadinstitute/gatk/jobs/517109941) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34651.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7295#issuecomment-865183878:218,integrat,integration,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7295#issuecomment-865183878,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [34916](https://app.travis-ci.com/broadinstitute/gatk/builds/232376083); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34916.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/523434656) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_34916.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7305#issuecomment-877695650:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7305#issuecomment-877695650,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [34953](https://app.travis-ci.com/broadinstitute/gatk/builds/232776802); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34953.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524527790) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34953.12/tests/test/index.html) |; | integration | openjdk8 | [34953.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/524527780) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34953.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-880180901:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-880180901,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34955](https://app.travis-ci.com/broadinstitute/gatk/builds/232778439); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34955.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524531918) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34955.12/tests/test/index.html) |; | integration | openjdk8 | [34955.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/524531908) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34955.2/tests/test/index.html) |; | integration | openjdk11 | [34955.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524531918) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34955.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-880195656:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-880195656,3,['integrat'],['integration']
Integrability,Travis reported job failures from build [34968](https://app.travis-ci.com/broadinstitute/gatk/builds/232871891); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34968.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524746057) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_34968.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7342#issuecomment-880918843:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7342#issuecomment-880918843,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [34975](https://app.travis-ci.com/broadinstitute/gatk/builds/232883183); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34975.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524775421) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34975.12/tests/test/index.html) |; | integration | openjdk8 | [34975.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/524775411) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34975.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-880991859:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-880991859,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34989](https://app.travis-ci.com/broadinstitute/gatk/builds/232957715); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34989.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524971906) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34989.12/tests/test/index.html) |; | integration | openjdk8 | [34989.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/524971896) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34989.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881554091:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881554091,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34993](https://app.travis-ci.com/broadinstitute/gatk/builds/232963432); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34993.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/524986404) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34993.12/tests/test/index.html) |; | integration | openjdk8 | [34993.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/524986393) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34993.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881599208:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881599208,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34997](https://app.travis-ci.com/broadinstitute/gatk/builds/232970936); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34997.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/525003829) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34997.12/tests/test/index.html) |; | integration | openjdk8 | [34997.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/525003819) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34997.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881652786:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881652786,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [34999](https://app.travis-ci.com/broadinstitute/gatk/builds/232971052); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [34999.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/525004179) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34999.12/tests/test/index.html) |; | integration | openjdk8 | [34999.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/525004169) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_34999.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881652638:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7349#issuecomment-881652638,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35038](https://app.travis-ci.com/broadinstitute/gatk/builds/233229631); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [35038.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731805) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.1/tests/test/index.html) |; | cloud | openjdk11 | [35038.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731818) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.14/tests/test/index.html) |; | unit | openjdk11 | [35038.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731817) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.13/tests/test/index.html) |; | integration | openjdk11 | [35038.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731816) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.12/tests/test/index.html) |; | unit | openjdk8 | [35038.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731807) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.3/tests/test/index.html) |; | variantcalling | openjdk8 | [35038.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731808) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.4/tests/test/index.html) |; | conda | openjdk8 | [35038.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731809) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.5/tests/test/index.html) |; | integration | openjdk8 | [35038.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/525731806) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35038.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-883544427:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-883544427,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35066](https://app.travis-ci.com/broadinstitute/gatk/builds/233352611); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [35066.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037648) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.1/tests/test/index.html) |; | cloud | openjdk11 | [35066.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037661) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.14/tests/test/index.html) |; | unit | openjdk11 | [35066.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037660) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.13/tests/test/index.html) |; | integration | openjdk11 | [35066.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037659) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.12/tests/test/index.html) |; | unit | openjdk8 | [35066.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037650) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.3/tests/test/index.html) |; | variantcalling | openjdk8 | [35066.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037651) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.4/tests/test/index.html) |; | conda | openjdk8 | [35066.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037652) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.5/tests/test/index.html) |; | integration | openjdk8 | [35066.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526037649) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35066.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884405742:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884405742,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35068](https://app.travis-ci.com/broadinstitute/gatk/builds/233354016); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [35068.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041270) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.14/tests/test/index.html) |; | cloud | openjdk8 | [35068.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041257) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.1/tests/test/index.html) |; | unit | openjdk11 | [35068.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041269) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.13/tests/test/index.html) |; | integration | openjdk11 | [35068.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041268) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.12/tests/test/index.html) |; | unit | openjdk8 | [35068.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041259) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.3/tests/test/index.html) |; | conda | openjdk8 | [35068.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041261) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.5/tests/test/index.html) |; | variantcalling | openjdk8 | [35068.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041260) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.4/tests/test/index.html) |; | integration | openjdk8 | [35068.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526041258) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35068.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884419815:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884419815,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35073](https://app.travis-ci.com/broadinstitute/gatk/builds/233356361); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [35073.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047078) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.1/tests/test/index.html) |; | cloud | openjdk11 | [35073.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047091) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.14/tests/test/index.html) |; | unit | openjdk11 | [35073.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047090) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.13/tests/test/index.html) |; | integration | openjdk11 | [35073.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047089) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.12/tests/test/index.html) |; | unit | openjdk8 | [35073.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.3/tests/test/index.html) |; | conda | openjdk8 | [35073.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047082) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.5/tests/test/index.html) |; | variantcalling | openjdk8 | [35073.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.4/tests/test/index.html) |; | integration | openjdk8 | [35073.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526047079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35073.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884440415:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884440415,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35075](https://app.travis-ci.com/broadinstitute/gatk/builds/233357441); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35075.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050087) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35075.13/tests/test/index.html) |; | integration | openjdk11 | [35075.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050086) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35075.12/tests/test/index.html) |; | unit | openjdk8 | [35075.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050077) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35075.3/tests/test/index.html) |; | integration | openjdk8 | [35075.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050076) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35075.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884464290:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884464290,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35077](https://app.travis-ci.com/broadinstitute/gatk/builds/233357592); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35077.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050451) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35077.13/tests/test/index.html) |; | integration | openjdk11 | [35077.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050450) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35077.12/tests/test/index.html) |; | unit | openjdk8 | [35077.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050441) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35077.3/tests/test/index.html) |; | integration | openjdk8 | [35077.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526050440) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35077.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884466100:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-884466100,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35104](https://app.travis-ci.com/broadinstitute/gatk/builds/233468304); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35104.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526328126) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35104.13/tests/test/index.html) |; | integration | openjdk11 | [35104.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526328125) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35104.12/tests/test/index.html) |; | unit | openjdk8 | [35104.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526328116) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35104.3/tests/test/index.html) |; | integration | openjdk8 | [35104.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526328115) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35104.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-885267425:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-885267425,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35151](https://app.travis-ci.com/broadinstitute/gatk/builds/233705984); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35151.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526977289) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35151.13/tests/test/index.html) |; | integration | openjdk11 | [35151.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526977288) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35151.12/tests/test/index.html) |; | unit | openjdk8 | [35151.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526977279) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35151.3/tests/test/index.html) |; | integration | openjdk8 | [35151.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526977278) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35151.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7370#issuecomment-886981872:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7370#issuecomment-886981872,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35153](https://app.travis-ci.com/broadinstitute/gatk/builds/233712151); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35153.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526992860) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35153.13/tests/test/index.html) |; | integration | openjdk11 | [35153.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526992859) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35153.12/tests/test/index.html) |; | unit | openjdk8 | [35153.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526992850) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35153.3/tests/test/index.html) |; | integration | openjdk8 | [35153.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526992849) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35153.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887032589:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887032589,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35156](https://app.travis-ci.com/broadinstitute/gatk/builds/233712370); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35156.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/526993410) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35156.13/tests/test/index.html) |; | integration | openjdk11 | [35156.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/526993409) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35156.12/tests/test/index.html) |; | unit | openjdk8 | [35156.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/526993400) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35156.3/tests/test/index.html) |; | integration | openjdk8 | [35156.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/526993399) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35156.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887035947:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887035947,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35159](https://app.travis-ci.com/broadinstitute/gatk/builds/233733841); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35159.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/527041438) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35159.13/tests/test/index.html) |; | integration | openjdk11 | [35159.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/527041437) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35159.12/tests/test/index.html) |; | unit | openjdk8 | [35159.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/527041428) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35159.3/tests/test/index.html) |; | integration | openjdk8 | [35159.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/527041427) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35159.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887209071:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7343#issuecomment-887209071,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35162](https://app.travis-ci.com/broadinstitute/gatk/builds/233781027); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35162.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/527164191) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35162.13/tests/test/index.html) |; | integration | openjdk11 | [35162.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/527164190) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35162.12/tests/test/index.html) |; | unit | openjdk8 | [35162.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/527164181) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35162.3/tests/test/index.html) |; | integration | openjdk8 | [35162.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/527164180) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35162.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7370#issuecomment-887581627:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7370#issuecomment-887581627,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35191](https://app.travis-ci.com/broadinstitute/gatk/builds/233897916); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35191.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/527474110) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35191.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7378#issuecomment-888459910:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7378#issuecomment-888459910,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35222](https://app.travis-ci.com/broadinstitute/gatk/builds/234104192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35222.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/528002701) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35222.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7355#issuecomment-889960163:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7355#issuecomment-889960163,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35263](https://app.travis-ci.com/broadinstitute/gatk/builds/234381437); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35263.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/528794786) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35263.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7389#issuecomment-891948742:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7389#issuecomment-891948742,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35281](https://app.travis-ci.com/broadinstitute/gatk/builds/234493943); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35281.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/529086898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35281.13/tests/test/index.html) |; | integration | openjdk11 | [35281.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/529086897) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35281.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35281.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/529086889) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35281.4/tests/test/index.html) |; | unit | openjdk8 | [35281.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/529086888) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35281.3/tests/test/index.html) |; | integration | openjdk8 | [35281.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/529086887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35281.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-892730894:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-892730894,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35283](https://app.travis-ci.com/broadinstitute/gatk/builds/234495207); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35283.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/529090922) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35283.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35283.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/529090914) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35283.4/tests/test/index.html) |; | integration | openjdk8 | [35283.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/529090912) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35283.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892751062:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892751062,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35285](https://app.travis-ci.com/broadinstitute/gatk/builds/234495551); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35285.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/529091673) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35285.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35285.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/529091665) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35285.4/tests/test/index.html) |; | integration | openjdk8 | [35285.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/529091663) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35285.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892753629:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892753629,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35299](https://app.travis-ci.com/broadinstitute/gatk/builds/234500111); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35299.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/529102784) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35299.13/tests/test/index.html) |; | integration | openjdk11 | [35299.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/529102783) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35299.12/tests/test/index.html) |; | unit | openjdk8 | [35299.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/529102774) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35299.3/tests/test/index.html) |; | variantcalling | openjdk8 | [35299.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/529102775) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35299.4/tests/test/index.html) |; | integration | openjdk8 | [35299.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/529102773) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35299.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-892780628:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7122#issuecomment-892780628,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35352](https://app.travis-ci.com/broadinstitute/gatk/builds/234805799); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35352.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/529942933) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35352.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7381#issuecomment-894924291:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7381#issuecomment-894924291,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35359](https://app.travis-ci.com/broadinstitute/gatk/builds/234864331); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35359.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/530084737) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35359.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7396#issuecomment-895367993:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7396#issuecomment-895367993,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35408](https://app.travis-ci.com/broadinstitute/gatk/builds/235081908); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | openjdk8 | [35408.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/530725600) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35408.4/tests/test/index.html) |; | integration | openjdk8 | [35408.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/530725598) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896970810:440,integrat,integration,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896970810,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35460](https://app.travis-ci.com/broadinstitute/gatk/builds/235309831); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35460.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/531318301) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35460.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-898668477:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-898668477,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35462](https://app.travis-ci.com/broadinstitute/gatk/builds/235310455); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35462.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/531320214) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35462.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-898675262:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-898675262,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35466](https://app.travis-ci.com/broadinstitute/gatk/builds/235310716); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35466.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/531321172) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35466.12/tests/test/index.html) |; | integration | openjdk8 | [35466.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/531321162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35466.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7223#issuecomment-898680924:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7223#issuecomment-898680924,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35514](https://app.travis-ci.com/broadinstitute/gatk/builds/235493198); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35514.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/531838051) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35514.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-899777125:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7412#issuecomment-899777125,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35542](https://app.travis-ci.com/broadinstitute/gatk/builds/235595824); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35542.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/532100892) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35542.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35542.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/532100884) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35542.4/tests/test/index.html) |; | integration | openjdk8 | [35542.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/532100882) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35542.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900593417:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900593417,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35544](https://app.travis-ci.com/broadinstitute/gatk/builds/235596805); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35544.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103274) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35544.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35544.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103266) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35544.4/tests/test/index.html) |; | integration | openjdk8 | [35544.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103264) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35544.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900601946:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900601946,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35546](https://app.travis-ci.com/broadinstitute/gatk/builds/235596899); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35546.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103522) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35546.12/tests/test/index.html) |; | variantcalling | openjdk8 | [35546.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103514) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35546.4/tests/test/index.html) |; | integration | openjdk8 | [35546.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/532103512) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35546.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900603007:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-900603007,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35614](https://app.travis-ci.com/broadinstitute/gatk/builds/235796214); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35614.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/532702729) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35614.13/tests/test/index.html) |; | integration | openjdk11 | [35614.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/532702728) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35614.12/tests/test/index.html) |; | unit | openjdk8 | [35614.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/532702719) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35614.3/tests/test/index.html) |; | integration | openjdk8 | [35614.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/532702718) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35614.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-902180244:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-902180244,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35652](https://app.travis-ci.com/broadinstitute/gatk/builds/236008516); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35652.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/533261173) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35652.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7435#issuecomment-903940281:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7435#issuecomment-903940281,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35656](https://app.travis-ci.com/broadinstitute/gatk/builds/236041444); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35656.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/533345256) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35656.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7434#issuecomment-904228563:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7434#issuecomment-904228563,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35662](https://app.travis-ci.com/broadinstitute/gatk/builds/236042965); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35662.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/533348915) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35662.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7434#issuecomment-904245474:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7434#issuecomment-904245474,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35724](https://app.travis-ci.com/broadinstitute/gatk/builds/236321310); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35724.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/534059154) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35724.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7440#issuecomment-906727232:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7440#issuecomment-906727232,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35827](https://app.travis-ci.com/broadinstitute/gatk/builds/236734529); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35827.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/535106160) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35827.13/tests/test/index.html) |; | integration | openjdk11 | [35827.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/535106159) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35827.12/tests/test/index.html) |; | unit | openjdk8 | [35827.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/535106150) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35827.3/tests/test/index.html) |; | integration | openjdk8 | [35827.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/535106149) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35827.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7223#issuecomment-910535218:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7223#issuecomment-910535218,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35833](https://app.travis-ci.com/broadinstitute/gatk/builds/236752487); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [35833.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/535149111) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35833.13/tests/test/index.html) |; | integration | openjdk11 | [35833.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/535149110) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35833.12/tests/test/index.html) |; | unit | openjdk8 | [35833.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/535149101) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35833.3/tests/test/index.html) |; | integration | openjdk8 | [35833.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/535149100) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_35833.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-910840432:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-910840432,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [35880](https://app.travis-ci.com/broadinstitute/gatk/builds/237199054); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35880.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/536209432) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35880.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7426#issuecomment-915310800:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7426#issuecomment-915310800,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35897](https://app.travis-ci.com/broadinstitute/gatk/builds/237244422); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35897.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/536323693) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35897.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7457#issuecomment-915694430:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7457#issuecomment-915694430,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35935](https://app.travis-ci.com/broadinstitute/gatk/builds/237322016); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35935.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/536512235) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35935.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7463#issuecomment-916403114:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7463#issuecomment-916403114,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [35951](https://app.travis-ci.com/broadinstitute/gatk/builds/237326442); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [35951.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/536522087) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_35951.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7463#issuecomment-916440221:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7463#issuecomment-916440221,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36058](https://app.travis-ci.com/broadinstitute/gatk/builds/237840259); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36058.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/537863419) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36058.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7452#issuecomment-921082427:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7452#issuecomment-921082427,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36081](https://app.travis-ci.com/broadinstitute/gatk/builds/237929248); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36081.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/538089676) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36081.12/tests/test/index.html) |; | integration | openjdk8 | [36081.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/538089666) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36081.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-921944948:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-921944948,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36105](https://app.travis-ci.com/broadinstitute/gatk/builds/238044050); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36105.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/538399326) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36105.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7475#issuecomment-922931171:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7475#issuecomment-922931171,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36112](https://app.travis-ci.com/broadinstitute/gatk/builds/238062338); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36112.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/538446562) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36112.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7452#issuecomment-923093725:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7452#issuecomment-923093725,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36116](https://app.travis-ci.com/broadinstitute/gatk/builds/238079815); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36116.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/538495506) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36116.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7477#issuecomment-923269951:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7477#issuecomment-923269951,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36174](https://app.travis-ci.com/broadinstitute/gatk/builds/238460134); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36174.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/539549145) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36174.12/tests/test/index.html) |; | integration | openjdk8 | [36174.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/539549135) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36174.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-926929814:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-926929814,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36176](https://app.travis-ci.com/broadinstitute/gatk/builds/238460981); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36176.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/539551561) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36176.12/tests/test/index.html) |; | integration | openjdk8 | [36176.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/539551551) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36176.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-926933533:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7471#issuecomment-926933533,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36275](https://app.travis-ci.com/broadinstitute/gatk/builds/239090322); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36275.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/541228649) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36275.12/tests/test/index.html) |; | integration | openjdk8 | [36275.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/541228639) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36275.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7491#issuecomment-933868301:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7491#issuecomment-933868301,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36352](https://app.travis-ci.com/broadinstitute/gatk/builds/239379640); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36352.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/542050919) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36352.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7495#issuecomment-938192993:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7495#issuecomment-938192993,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36425](https://app.travis-ci.com/broadinstitute/gatk/builds/239885552); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36425.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/543355253) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36425.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7450#issuecomment-944020627:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7450#issuecomment-944020627,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36457](https://app.travis-ci.com/broadinstitute/gatk/builds/240144608); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36457.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/544058431) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/rsa_parallelize_execute_sql_36457.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7509#issuecomment-946831152:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7509#issuecomment-946831152,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36459](https://app.travis-ci.com/broadinstitute/gatk/builds/240145151); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36459.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/544060034) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36459.12/tests/test/index.html) |; | integration | openjdk8 | [36459.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/544060024) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36459.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946834797:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946834797,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36461](https://app.travis-ci.com/broadinstitute/gatk/builds/240145685); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36461.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/544061450) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36461.12/tests/test/index.html) |; | integration | openjdk8 | [36461.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/544061440) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36461.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946842201:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946842201,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36463](https://app.travis-ci.com/broadinstitute/gatk/builds/240151564); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36463.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/544076662) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36463.12/tests/test/index.html) |; | integration | openjdk8 | [36463.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/544076652) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36463.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946896833:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-946896833,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36659](https://app.travis-ci.com/broadinstitute/gatk/builds/240872073); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [36659.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/545893308) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36659.1/tests/test/index.html) |; | cloud | openjdk11 | [36659.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/545893321) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36659.14/tests/test/index.html) |; | integration | openjdk11 | [36659.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/545893319) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36659.12/tests/test/index.html) |; | integration | openjdk8 | [36659.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/545893309) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36659.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-955060271:655,integrat,integration,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-955060271,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36699](https://app.travis-ci.com/broadinstitute/gatk/builds/241035376); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [36699.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/546298343) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36699.1/tests/test/index.html) |; | cloud | openjdk11 | [36699.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/546298356) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36699.14/tests/test/index.html) |; | integration | openjdk11 | [36699.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546298354) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36699.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-957815959:655,integrat,integration,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-957815959,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [36704](https://app.travis-ci.com/broadinstitute/gatk/builds/241045493); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [36704.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/546319630) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36704.1/tests/test/index.html) |; | cloud | openjdk11 | [36704.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/546319643) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36704.14/tests/test/index.html) |; | integration | openjdk11 | [36704.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546319641) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36704.12/tests/test/index.html) |; | integration | openjdk8 | [36704.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546319631) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36704.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-957942604:655,integrat,integration,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-957942604,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36712](https://app.travis-ci.com/broadinstitute/gatk/builds/241134777); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [36712.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/546539784) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36712.1/tests/test/index.html) |; | cloud | openjdk11 | [36712.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/546539797) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36712.14/tests/test/index.html) |; | integration | openjdk11 | [36712.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546539795) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36712.12/tests/test/index.html) |; | integration | openjdk8 | [36712.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546539785) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36712.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-959840632:655,integrat,integration,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-959840632,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36716](https://app.travis-ci.com/broadinstitute/gatk/builds/241142844); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [36716.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/546560178) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36716.1/tests/test/index.html) |; | cloud | openjdk11 | [36716.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/546560192) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36716.14/tests/test/index.html) |; | integration | openjdk11 | [36716.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546560189) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36716.12/tests/test/index.html) |; | integration | openjdk8 | [36716.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546560179) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36716.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-960096611:655,integrat,integration,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-960096611,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36725](https://app.travis-ci.com/broadinstitute/gatk/builds/241190517); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36725.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546679928) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36725.12/tests/test/index.html) |; | integration | openjdk8 | [36725.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546679918) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36725.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961166918:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961166918,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36729](https://app.travis-ci.com/broadinstitute/gatk/builds/241192115); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36729.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546683875) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36729.12/tests/test/index.html) |; | integration | openjdk8 | [36729.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546683865) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36729.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961184778:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961184778,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36733](https://app.travis-ci.com/broadinstitute/gatk/builds/241200444); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36733.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546705723) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36733.12/tests/test/index.html) |; | integration | openjdk8 | [36733.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546705713) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36733.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961272306:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961272306,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36735](https://app.travis-ci.com/broadinstitute/gatk/builds/241201544); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36735.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546708298) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36735.12/tests/test/index.html) |; | integration | openjdk8 | [36735.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546708288) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36735.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961283261:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961283261,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36737](https://app.travis-ci.com/broadinstitute/gatk/builds/241202305); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36737.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546710279) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36737.12/tests/test/index.html) |; | integration | openjdk8 | [36737.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546710269) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36737.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961293526:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961293526,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36739](https://app.travis-ci.com/broadinstitute/gatk/builds/241202374); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36739.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546710447) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36739.12/tests/test/index.html) |; | integration | openjdk8 | [36739.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546710437) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36739.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961291100:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961291100,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36747](https://app.travis-ci.com/broadinstitute/gatk/builds/241218893); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36747.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/546762423) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36747.12/tests/test/index.html) |; | integration | openjdk8 | [36747.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/546762413) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_36747.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961477821:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7530#issuecomment-961477821,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36844](https://app.travis-ci.com/broadinstitute/gatk/builds/241531802); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36844.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/547544565) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36844.12/tests/test/index.html) |; | conda | openjdk8 | [36844.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/547544558) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36844.5/tests/test/index.html) |; | integration | openjdk8 | [36844.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/547544555) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_36844.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7559#issuecomment-965446296:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7559#issuecomment-965446296,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36923](https://app.travis-ci.com/broadinstitute/gatk/builds/241945043); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36923.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/548529658) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36923.12/tests/test/index.html) |; | integration | openjdk8 | [36923.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/548529648) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36923.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971704225:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971704225,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36925](https://app.travis-ci.com/broadinstitute/gatk/builds/241945819); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36925.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/548531508) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36925.12/tests/test/index.html) |; | integration | openjdk8 | [36925.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/548531498) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36925.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971715805:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971715805,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36927](https://app.travis-ci.com/broadinstitute/gatk/builds/241946394); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36927.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/548532718) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36927.12/tests/test/index.html) |; | integration | openjdk8 | [36927.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/548532708) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36927.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971720500:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7568#issuecomment-971720500,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [36937](https://app.travis-ci.com/broadinstitute/gatk/builds/242038149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [36937.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/548759909) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36937.12/tests/test/index.html) |; | integration | openjdk8 | [36937.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/548759899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_spike_writeapi_36937.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7571#issuecomment-973153376:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7571#issuecomment-973153376,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38060](https://app.travis-ci.com/broadinstitute/gatk/builds/247666991); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [38060.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/562747871) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38060.13/tests/test/index.html) |; | integration | openjdk11 | [38060.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/562747870) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38060.12/tests/test/index.html) |; | unit | openjdk8 | [38060.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/562747861) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38060.3/tests/test/index.html) |; | integration | openjdk8 | [38060.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/562747860) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38060.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1063589941:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1063589941,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38083](https://app.travis-ci.com/broadinstitute/gatk/builds/247786992); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38083.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563060315) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38083.12/tests/test/index.html) |; | integration | openjdk8 | [38083.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563060305) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38083.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1065595863:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1065595863,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38087](https://app.travis-ci.com/broadinstitute/gatk/builds/247802968); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38087.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563097964) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38087.12/tests/test/index.html) |; | integration | openjdk8 | [38087.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563097954) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38087.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1065926332:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1065926332,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38091](https://app.travis-ci.com/broadinstitute/gatk/builds/247852896); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [38091.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/563219289) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38091.13/tests/test/index.html) |; | integration | openjdk11 | [38091.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563219288) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38091.12/tests/test/index.html) |; | unit | openjdk8 | [38091.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/563219279) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38091.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1066920877:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1066920877,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38096](https://app.travis-ci.com/broadinstitute/gatk/builds/247860433); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38096.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563238843) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38096.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7720#issuecomment-1067068324:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7720#issuecomment-1067068324,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38098](https://app.travis-ci.com/broadinstitute/gatk/builds/247860511); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38098.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563239018) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38098.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7720#issuecomment-1067069713:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7720#issuecomment-1067069713,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38100](https://app.travis-ci.com/broadinstitute/gatk/builds/247864839); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084,4,['integrat'],['integration']
Integrability,Travis reported job failures from build [38110](https://app.travis-ci.com/broadinstitute/gatk/builds/247893700); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [38110.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325496) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.14/tests/test/index.html) |; | cloud | openjdk8 | [38110.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325483) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.1/tests/test/index.html) |; | unit | openjdk11 | [38110.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325495) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.13/tests/test/index.html) |; | integration | openjdk11 | [38110.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325494) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.12/tests/test/index.html) |; | unit | openjdk8 | [38110.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325485) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.3/tests/test/index.html) |; | variantcalling | openjdk8 | [38110.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325486) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.4/tests/test/index.html) |; | integration | openjdk8 | [38110.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563325484) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38110.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1067659375:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1067659375,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38112](https://app.travis-ci.com/broadinstitute/gatk/builds/247913834); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38112.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563379132) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38112.12/tests/test/index.html) |; | integration | openjdk8 | [38112.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563379122) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38112.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1068024511:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1068024511,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38115](https://app.travis-ci.com/broadinstitute/gatk/builds/247937100); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [38115.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444106) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.1/tests/test/index.html) |; | cloud | openjdk11 | [38115.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444119) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.14/tests/test/index.html) |; | unit | openjdk11 | [38115.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444118) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.13/tests/test/index.html) |; | integration | openjdk11 | [38115.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444117) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.12/tests/test/index.html) |; | unit | openjdk8 | [38115.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444108) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.3/tests/test/index.html) |; | variantcalling | openjdk8 | [38115.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444109) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.4/tests/test/index.html) |; | integration | openjdk8 | [38115.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563444107) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38115.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1068358237:854,integrat,integration,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1068358237,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38129](https://app.travis-ci.com/broadinstitute/gatk/builds/248000561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38129.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563600186) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38129.12/tests/test/index.html) |; | integration | openjdk8 | [38129.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563600176) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38129.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069521375:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069521375,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38164](https://app.travis-ci.com/broadinstitute/gatk/builds/248125832); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [38164.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/563917586) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38164.1/tests/test/index.html) |; | cloud | openjdk11 | [38164.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/563917599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38164.14/tests/test/index.html) |; | conda | openjdk8 | [38164.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/563917590) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38164.5/tests/test/index.html) |; | integration | openjdk8 | [38164.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563917587) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38164.2/tests/test/index.html) |; | variantcalling | openjdk8 | [38164.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/563917589) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38164.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072776529:852,integrat,integration,852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072776529,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38166](https://app.travis-ci.com/broadinstitute/gatk/builds/248127071); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38166.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563920785) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38166.12/tests/test/index.html) |; | integration | openjdk8 | [38166.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563920775) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38166.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1072830769:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1072830769,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38168](https://app.travis-ci.com/broadinstitute/gatk/builds/248128606); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk11 | [38168.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/563924706) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38168.14/tests/test/index.html) |; | cloud | openjdk8 | [38168.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/563924693) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38168.1/tests/test/index.html) |; | integration | openjdk8 | [38168.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563924694) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38168.2/tests/test/index.html) |; | conda | openjdk8 | [38168.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/563924697) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38168.5/tests/test/index.html) |; | variantcalling | openjdk8 | [38168.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/563924696) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38168.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072841847:643,integrat,integration,643,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072841847,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38170](https://app.travis-ci.com/broadinstitute/gatk/builds/248128971); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [38170.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/563925511) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38170.1/tests/test/index.html) |; | cloud | openjdk11 | [38170.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/563925524) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38170.14/tests/test/index.html) |; | conda | openjdk8 | [38170.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/563925515) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38170.5/tests/test/index.html) |; | integration | openjdk8 | [38170.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563925512) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38170.2/tests/test/index.html) |; | variantcalling | openjdk8 | [38170.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/563925514) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38170.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072847450:852,integrat,integration,852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1072847450,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38174](https://app.travis-ci.com/broadinstitute/gatk/builds/248186522); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38174.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564065551) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38174.12/tests/test/index.html) |; | integration | openjdk8 | [38174.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564065541) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38174.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074044045:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074044045,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38177](https://app.travis-ci.com/broadinstitute/gatk/builds/248191891); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38177.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564080035) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38177.12/tests/test/index.html) |; | integration | openjdk8 | [38177.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564080025) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38177.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074141420:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074141420,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38179](https://app.travis-ci.com/broadinstitute/gatk/builds/248192670); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38179.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564082094) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38179.12/tests/test/index.html) |; | integration | openjdk8 | [38179.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564082084) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38179.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074156376:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074156376,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38183](https://app.travis-ci.com/broadinstitute/gatk/builds/248198988); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38183.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564098711) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38183.12/tests/test/index.html) |; | integration | openjdk8 | [38183.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564098701) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38183.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074271488:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074271488,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38185](https://app.travis-ci.com/broadinstitute/gatk/builds/248205358); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38185.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564114801) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38185.12/tests/test/index.html) |; | integration | openjdk8 | [38185.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564114791) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38185.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074353651:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074353651,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38187](https://app.travis-ci.com/broadinstitute/gatk/builds/248207168); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38187.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564119758) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38187.12/tests/test/index.html) |; | integration | openjdk8 | [38187.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564119748) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38187.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074389896:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074389896,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38191](https://app.travis-ci.com/broadinstitute/gatk/builds/248213511); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38191.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564136597) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38191.12/tests/test/index.html) |; | integration | openjdk8 | [38191.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564136587) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38191.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074495163:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1074495163,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38203](https://app.travis-ci.com/broadinstitute/gatk/builds/248266948); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38203.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564269407) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38203.12/tests/test/index.html) |; | integration | openjdk8 | [38203.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564269397) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38203.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7734#issuecomment-1075494924:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7734#issuecomment-1075494924,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38216](https://app.travis-ci.com/broadinstitute/gatk/builds/248313687); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [38216.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/564383062) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38216.13/tests/test/index.html) |; | integration | openjdk11 | [38216.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564383061) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38216.12/tests/test/index.html) |; | unit | openjdk8 | [38216.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/564383052) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38216.3/tests/test/index.html) |; | integration | openjdk8 | [38216.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564383051) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38216.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1076366765:439,integrat,integration,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7718#issuecomment-1076366765,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38225](https://app.travis-ci.com/broadinstitute/gatk/builds/248338488); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38225.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564447801) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38225.12/tests/test/index.html) |; | integration | openjdk8 | [38225.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564447791) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38225.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7734#issuecomment-1076776102:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7734#issuecomment-1076776102,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38233](https://app.travis-ci.com/broadinstitute/gatk/builds/248387440); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38233.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564566861) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38233.12/tests/test/index.html) |; | integration | openjdk8 | [38233.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564566851) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38233.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7733#issuecomment-1077790207:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7733#issuecomment-1077790207,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38284](https://app.travis-ci.com/broadinstitute/gatk/builds/248554579); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [38284.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/564972333) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38284.13/tests/test/index.html) |; | integration | openjdk11 | [38284.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564972332) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38284.12/tests/test/index.html) |; | cloud | openjdk8 | [38284.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/564972321) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38284.1/tests/test/index.html) |; | cloud | openjdk11 | [38284.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/564972334) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38284.14/tests/test/index.html) |; | unit | openjdk8 | [38284.3](https://app.travis-ci.com/broadinstitute/gatk/jobs/564972323) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38284.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1081073154:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1081073154,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38286](https://app.travis-ci.com/broadinstitute/gatk/builds/248555577); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38286.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/564975067) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38286.12/tests/test/index.html) |; | integration | openjdk8 | [38286.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/564975057) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38286.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7739#issuecomment-1081135051:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7739#issuecomment-1081135051,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38293](https://app.travis-ci.com/broadinstitute/gatk/builds/248569068); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38293.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/565009924) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38293.12/tests/test/index.html) |; | integration | openjdk8 | [38293.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/565009914) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38293.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7664#issuecomment-1081368863:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7664#issuecomment-1081368863,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38297](https://app.travis-ci.com/broadinstitute/gatk/builds/248597167); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [38297.13](https://app.travis-ci.com/broadinstitute/gatk/jobs/565077614) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38297.13/tests/test/index.html) |; | integration | openjdk11 | [38297.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/565077613) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38297.12/tests/test/index.html) |; | cloud | openjdk8 | [38297.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/565077602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38297.1/tests/test/index.html) |; | cloud | openjdk11 | [38297.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/565077615) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38297.14/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1081845776:433,integrat,integration,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1081845776,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38312](https://app.travis-ci.com/broadinstitute/gatk/builds/248621240); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38312.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/565138626) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38312.12/tests/test/index.html) |; | integration | openjdk8 | [38312.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/565138616) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38312.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1082317832:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7738#issuecomment-1082317832,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38347](https://app.travis-ci.com/broadinstitute/gatk/builds/248689004); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38347.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/565306999) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38347.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7746#issuecomment-1083594910:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7746#issuecomment-1083594910,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38393](https://app.travis-ci.com/broadinstitute/gatk/builds/248813440); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | openjdk8 | [38393.1](https://app.travis-ci.com/broadinstitute/gatk/jobs/565618194) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38393.1/tests/test/index.html) |; | cloud | openjdk11 | [38393.14](https://app.travis-ci.com/broadinstitute/gatk/jobs/565618207) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38393.14/tests/test/index.html) |; | conda | openjdk8 | [38393.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/565618198) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38393.5/tests/test/index.html) |; | integration | openjdk8 | [38393.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/565618195) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38393.2/tests/test/index.html) |; | variantcalling | openjdk8 | [38393.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/565618197) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38393.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1086251277:852,integrat,integration,852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1086251277,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38445](https://app.travis-ci.com/broadinstitute/gatk/builds/248902356); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38445.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/565826830) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38445.12/tests/test/index.html) |; | integration | openjdk8 | [38445.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/565826820) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7750#issuecomment-1087979534:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7750#issuecomment-1087979534,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38522](https://app.travis-ci.com/broadinstitute/gatk/builds/249024354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38522.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566140964) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38522.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7739#issuecomment-1090476624:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7739#issuecomment-1090476624,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38567](https://app.travis-ci.com/broadinstitute/gatk/builds/249037237); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk8 | [38567.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/566174075) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38567.2/tests/test/index.html) |; | conda | openjdk8 | [38567.5](https://app.travis-ci.com/broadinstitute/gatk/jobs/566174078) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38567.5/tests/test/index.html) |; | variantcalling | openjdk8 | [38567.4](https://app.travis-ci.com/broadinstitute/gatk/jobs/566174077) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38567.4/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1090792544:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730#issuecomment-1090792544,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38623](https://app.travis-ci.com/broadinstitute/gatk/builds/249089579); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38623.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566299427) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38623.12/tests/test/index.html) |; | integration | openjdk8 | [38623.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/566299417) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38623.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7752#issuecomment-1091967282:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7752#issuecomment-1091967282,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38735](https://app.travis-ci.com/broadinstitute/gatk/builds/249251446); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38735.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566697912) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38735.12/tests/test/index.html) |; | integration | openjdk11 | [38735.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566697912) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38735.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7713#issuecomment-1095535534:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7713#issuecomment-1095535534,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38745](https://app.travis-ci.com/broadinstitute/gatk/builds/249258011); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38745.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566714710) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38745.12/tests/test/index.html) |; | integration | openjdk8 | [38745.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/566714700) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38745.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7773#issuecomment-1095668751:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7773#issuecomment-1095668751,2,['integrat'],['integration']
Integrability,Travis reported job failures from build [38757](https://app.travis-ci.com/broadinstitute/gatk/builds/249261923); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38757.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566724825) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38757.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7772#issuecomment-1095767061:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7772#issuecomment-1095767061,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38788](https://app.travis-ci.com/broadinstitute/gatk/builds/249322535); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38788.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/566886037) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38788.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7776#issuecomment-1097243112:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7776#issuecomment-1097243112,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38872](https://app.travis-ci.com/broadinstitute/gatk/builds/249441958); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38872.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/567177790) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38872.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7784#issuecomment-1099583851:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7784#issuecomment-1099583851,1,['integrat'],['integration']
Integrability,Travis reported job failures from build [38983](https://app.travis-ci.com/broadinstitute/gatk/builds/249657082); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38983.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/567712058) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_38983.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7801#issuecomment-1104482113:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7801#issuecomment-1104482113,1,['integrat'],['integration']
Integrability,"Trying to generate the documentation with gatk-protected to explore how a dependent-project could include ReadFilters and other utilities, running in my local computer it throws the following error:. ```; javadoc: error - In doclet class org.broadinstitute.hellbender.utils.help.GATKHelpDoclet, method start has thrown an exception java.lang.reflect.InvocationTargetException; java.lang.RuntimeException: Could not find the field corresponding to java.lang.Throwable.backtrace, presumably because the field is inaccessible; at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.getFieldDoc(DefaultDocWorkUnitHandler.java:604); at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.getFieldDoc(DefaultDocWorkUnitHandler.java:622); at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.getFieldDoc(DefaultDocWorkUnitHandler.java:622); at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.getFieldDoc(DefaultDocWorkUnitHandler.java:622); at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.getFieldDoc(DefaultDocWorkUnitHandler.java:591); at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.getFieldDocForCommandLineArgument(DefaultDocWorkUnitHandler.java:403); at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.processNamedArgument(DefaultDocWorkUnitHandler.java:357); at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.lambda$addCommandLineArgumentBindings$5(DefaultDocWorkUnitHandler.java:287); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580); at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.addCommandLineArgumentBindings(DefaultDocWorkUnitHandler.java:287); at org.broadinstitute.barclay.help.DefaultDocWorkUnitHandler.processWorkUnit(DefaultDocWorkUnitHandler.java:202); at org.broadinstitute.barclay.help.DocWorkUnit.processDoc(DocWorkUnit.java:144); at org.broadinstitute.barclay.help.HelpDoclet.lambd",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2739:74,depend,dependent-project,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2739,1,['depend'],['dependent-project']
Integrability,Turn off caching for workspace-data dependent task [VS-1075],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8544:36,depend,dependent,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8544,1,['depend'],['dependent']
Integrability,"Two .vcf.idx files used by the haplotype caller integration test had; file name lengths > 144. This is incompatible with ecryptfs, which is; commonly used for encrypted home directories on linux. Renaming the; .vcf and .vcf.idx files and updating references to them fixed the; problem. Fixes #4718.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4736:48,integrat,integration,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4736,1,['integrat'],['integration']
Integrability,"Two annotations, allele depth and total depth, consider whether reads are informative relative to the alleles in the output `VariantContext`, which is in general a subset of the alleles contains in the `ReadLikelihoods`. In PR #2185 I overlooked this and forgot to subset the likelihoods' alleles to those of the vc, which was the previous behavior (see the diff from that PR for the two annotations in this PR). This PR duplicates the old behavior. This fixes failures in the HaplotypeCaller integration tests introduced by the previous PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2239:493,integrat,integration,493,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2239,1,['integrat'],['integration']
Integrability,"Two comments for the reviewer. 1) The ArgumentCollection ""dependsOnArgument"" attritbutes were added so the command line parser can recognize and complain when the user specifies the argument for a read filter, but not the filter itself, i.e., specifying a maxReadLength value without enabling the corresponding readLength filter. 2) In this PR, the pipeline tools honor the user's command line filters, including disabled filters, for the whole pipeline - are there cases where that isn't the right thing to do ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1900#issuecomment-225681550:58,depend,dependsOnArgument,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1900#issuecomment-225681550,1,['depend'],['dependsOnArgument']
Integrability,Two commits here:. - The first is to fix a no longer accurate message in `UserException.BadTmpDir`; - The second is a few improvements to IOUtils. ; 1. Rename and simplify `tmpDir` -> `createTempDir` and make it automatically scheduled for deletion; 2. Add documentation to the confusing `absolute` method so that I stop wondering what it's for,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4711:62,message,message,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4711,1,['message'],['message']
Integrability,"Two high level questions/concerns about the implementation… . 1. I think when things are parallelized, we then lose the retries. In order to do that, we might need to get a little more python async-y than I was originally thinking. The retries are pretty important to recover from transient errors in BQ. 2. I think perhaps the ordering/dependecies are lost between queries? It looks like we fire them all off and then wait for them all to complete. But really we need to wait for the vet_new queries to finish before launching the pet queries since they depend on data from the vet_new. If vet_new hasn't started this would fail… but if vet_new has created the table we'll just get the wrong results",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7505#issuecomment-944301753:337,depend,dependecies,337,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7505#issuecomment-944301753,2,['depend'],"['depend', 'dependecies']"
Integrability,"USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:01:51.713 INFO SortSam - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 18:01:51.713 INFO SortSam - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:01:51.713 INFO SortSam - Defaults.USE_CRAM_REF_DOWNLOAD : false; 18:01:51.713 INFO SortSam - Deflater IntelDeflater; 18:01:51.713 INFO SortSam - Initializing engine; 18:01:51.713 INFO SortSam - Done initializing engine; 18:02:01.512 INFO SortSam - Shutting down engine; [December 7, 2016 6:02:01 PM AST] org.broadinstitute.hellbender.tools.picard.sam.SortSam done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=1911029760; Exception in thread ""main"" java.lang.NoClassDefFoundError: org/xerial/snappy/LoadSnappy; 	at htsjdk.samtools.util.SnappyLoader.<init>(SnappyLoader.java:86); 	at htsjdk.samtools.util.SnappyLoader.<init>(SnappyLoader.java:52); 	at htsjdk.samtools.util.TempStreamFactory.getSnappyLoader(TempStreamFactory.java:42); 	at htsjdk.samtools.util.TempStreamFactory.wrapTempOutputStream(TempStreamFactory.java:74); 	at htsjdk.samtools.util.SortingCollection.spillToDisk(SortingCollection.java:223); 	at htsjdk.samtools.util.SortingCollection.add(SortingCollection.java:166); 	at htsjdk.samtools.SAMFileWriterImpl.addAlignment(SAMFileWriterImpl.java:192); 	at org.broadinstitute.hellbender.tools.picard.sam.SortSam.doWork(SortSam.java:52); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:62); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); Caused by: java.lang.ClassNotFoundException: org.xerial.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2299#issuecomment-265469924:2090,wrap,wrapTempOutputStream,2090,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2299#issuecomment-265469924,1,['wrap'],['wrapTempOutputStream']
Integrability,"Ugh, there's some wierd bug with one of our dependencies not understanding java version id's with 4 parts. The install java action must have just moved from installing 11.0.16 too 11.0.16.1 behind our back. It sounds like we have to update Jetty or something manually. ```; java.lang.ExceptionInInitializerError; at org.eclipse.jetty.webapp.WebInfConfiguration.findAndFilterContainerPaths(WebInfConfiguration.java:185); at org.eclipse.jetty.webapp.WebInfConfiguration.preConfigure(WebInfConfiguration.java:155); at org.eclipse.jetty.webapp.WebAppContext.preConfigure(WebAppContext.java:485); at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:521); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:131); at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:113); at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:61); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:131); at org.eclipse.jetty.server.Server.start(Server.java:[42](https://github.com/broadinstitute/gatk/actions/runs/3499912997/jobs/5862011952#step:10:43)7); at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:105); at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:61); at org.eclipse.jetty.server.Server.doStart(Server.java:394); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1155); at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:181); at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:885); at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(Nam",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8098#issuecomment-1320505279:44,depend,dependencies,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8098#issuecomment-1320505279,1,['depend'],['dependencies']
Integrability,Unfortunate that the commit message is incorrect (2.5.0 vs 2.15.0). Might it be worth fixing up the commit history?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7600#issuecomment-993113043:28,message,message,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7600#issuecomment-993113043,1,['message'],['message']
Integrability,"Unfortunately I don't think it's practical to try to enforce that ""only the arg parser can throw `CommandLineException`"" -- there's too much downstream code and too many tools that do so already, so it would be a bit painful to treat it as a bug. Instead I think what we should do is:. * Make sure that barclay uses a separate exception class for internal errors that are not the user's fault. This internal exception class should not be usable outside of barclay (perhaps we can make it package-private?).; * Catch `CommandLineException` in GATK and present it as a user error (output should say ""A USER ERROR HAS OCCURRED"").; * Move the `printDecoratedUserExceptionMessage()` call for caught `CommandLineExceptions` from `CommandLineProgram.parseArgs()` to `Main.mainEntry()`, to ensure that a message always gets printed for `CommandLineException`. As @cmnbroad said, this will have to wait until after the holiday break (most of us are going to be away until early January).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268828854:796,message,message,796,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268828854,1,['message'],['message']
Integrability,Unfortunately we can't merge this until we get the corresponding Barclay changes released in Barclay and integrated into GATK.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4523#issuecomment-454157311:105,integrat,integrated,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4523#issuecomment-454157311,1,['integrat'],['integrated']
Integrability,Unfortunately we'll still have the dependency unless we also cut out our ability to read from the google reference store. (which we might not care about anymore...) It would be good to at least rename BucketUtils. Maybe FilesSystemUtils or something like that.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1887#issuecomment-224374350:35,depend,dependency,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1887#issuecomment-224374350,1,['depend'],['dependency']
Integrability,"Unit and integration tests are now all passing on openjdk11. The build does not however work on Java 8, since the javadoc compilation has been commented out. This will need to be made conditional on the Java version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-529514256:9,integrat,integration,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-529514256,1,['integrat'],['integration']
Integrability,"Unit tests for tool X should not rely on the behavior of instanceMain or doWork in tool Y. . In particular, unit tests that involve comparing/validating outputs should not reference CLPs like CompareSAMs or ValidateSamFile directly. Instead, these CLPs should just be thin wrappers around other classes that have the actual logic. This is already the case for ValidateSamFile, which is just a wrapper for SamFileValidator in HTSJDK. CompareSAMs should be refactored to match this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/145:273,wrap,wrappers,273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/145,2,['wrap'],"['wrapper', 'wrappers']"
Integrability,Unit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.net.UnknownHostException: www.googleapis.com; 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:668); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at sh,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094:7007,protocol,protocol,7007,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094,1,['protocol'],['protocol']
Integrability,Update GATK dependencies to patch security vulnerabilities,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8352:12,depend,dependencies,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8352,1,['depend'],['dependencies']
Integrability,Update Protocol Buffer dependency to 3.0.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2437:7,Protocol,Protocol,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2437,2,"['Protocol', 'depend']","['Protocol', 'dependency']"
Integrability,Update Quickstart & Integration to use re-blocked v2 gVCFs [VS-491],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7924:20,Integrat,Integration,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7924,1,['Integrat'],['Integration']
Integrability,Update Quickstart Integration for X/Y scaling changes [VS-464],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7881:18,Integrat,Integration,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7881,1,['Integrat'],['Integration']
Integrability,Update bwamem-jni dependency to 1.0.3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3723:18,depend,dependency,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3723,1,['depend'],['dependency']
Integrability,Update data.table R dependency.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3712:20,depend,dependency,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3712,1,['depend'],['dependency']
Integrability,"Update dependencies to address security vulnerabilities, and add a security scanner to build.gradle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8607:7,depend,dependencies,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8607,1,['depend'],['dependencies']
Integrability,Update error message based on https://github.com/broadinstitute/gatk/issues/4669.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4678:13,message,message,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4678,1,['message'],['message']
Integrability,Update git-lfs prerequisite message.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4678:28,message,message,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4678,1,['message'],['message']
Integrability,Update google-cloud-java dependency to a snapshot containing newly added NIO API methods,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2441:25,depend,dependency,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2441,1,['depend'],['dependency']
Integrability,Update google-cloud-nio dependency to 0.20.4-alpha-20170727.190814-1:shaded,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3373:24,depend,dependency,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3373,1,['depend'],['dependency']
Integrability,Update hail version to 120 in Integration test VS 1025,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8502:30,Integrat,Integration,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8502,1,['Integrat'],['Integration']
Integrability,Update ojAlgo and improve commons-math / ojAlgo integration,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3970:48,integrat,integration,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3970,1,['integrat'],['integration']
Integrability,Update our HTSJDK dependency to 4.0.2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8584:18,depend,dependency,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8584,1,['depend'],['dependency']
Integrability,Update several dependencies to fix vulnerabilities,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8898:15,depend,dependencies,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8898,1,['depend'],['dependencies']
Integrability,Update the BQSR integration tests to test without BAQ and indel qualities,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2563:16,integrat,integration,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2563,1,['integrat'],['integration']
Integrability,Update to htsjdk 2.24.1. This fixes a gross issue where we accidentally included Junit as a runtime dependency.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7149:100,depend,dependency,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7149,1,['depend'],['dependency']
Integrability,"Update: I wrote an integration test in my branch that runs M2 with ; `--kmer-size 1 --dont-increase-kmer-sizes-for-cycles`. It still calls the given alleles, whereas in master it does not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571:19,integrat,integration,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571,1,['integrat'],['integration']
Integrability,"Updated PostprocessGermlineCNVCalls (segments VCF writing, WDL scripts, unit tests, integration tests)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4396:84,integrat,integration,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4396,1,['integrat'],['integration']
Integrability,Updated README to state that only 64-bit Linux distributions are supported. Made this edit under the Python dependencies section. Fix issue #6786,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6788:108,depend,dependencies,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6788,1,['depend'],['dependencies']
Integrability,Updated install_R_packages.R to fix broken ggplot2 dependency in gatkbase Docker image.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5040:51,depend,dependency,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5040,1,['depend'],['dependency']
Integrability,"Updated the title of this ticket to clarify that the task is now just to improve the error message, not fix an actual bug.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1417#issuecomment-195063857:91,message,message,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1417#issuecomment-195063857,1,['message'],['message']
Integrability,"Updated with [this](https://github.com/SHuang-Broad/JNIFermiLite). @cwhelan would you mind taking a brief look and see what improvements can be made to the interface?; @lbergelson I also added you as a contributor so later if we decide to make use of fermi-lite in the SV pipeline, you'll be in control. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2072#issuecomment-237125901:156,interface,interface,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2072#issuecomment-237125901,1,['interface'],['interface']
Integrability,"Updates (EchoCallset Version):. Changes to scatter width of VCFs generated has changed the amount of data generated in tests, so need to update truth; Adding a new field to extracted VCF Header EXCESS_ALLLELES and that will break the tests.; And why not validate our VCFs for jollies.; Updates 'truth' path for data to match these changes. Integration tests failed due to different number of output VCFs now. So I cherry-picked Miguel's commit on ah_var_store that changed the scatter.; Integration tests *still* [failing](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/8f7b0cc9-4a31-404b-99b3-89e182707e8b) due to the change in VCF Header:. > 6,7d5; < ##FILTER=<ID=high_CALIBRATION_SENSITIVITY_INDEL,Description=""Site failed INDEL model calibration sensitivity cutoff (0.99)"">; < ##FILTER=<ID=high_CALIBRATION_SENSITIVITY_SNP,Description=""Site failed SNP model calibration sensitivity cutoff (0.997)"">; 9c7; < ##FORMAT=<ID=FT,Number=1,Type=String,Description=""Genotype Filter Field"">; ---; > ##FORMAT=<ID=FT,Number=1,Type=String,Description=""Sample Genotype Filter Field"">; 3388a3387,3388; > ##high_CALIBRATION_SENSITIVITY_INDEL=Sample Genotype FT filter value indicating that the genotyped allele failed INDEL model calibration sensitivity cutoff (0.99); > ##high_CALIBRATION_SENSITIVITY_SNP=Sample Genotype FT filter value indicating that the genotyped allele failed SNP model calibration sensitivity cutoff (0.997)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8848:340,Integrat,Integration,340,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8848,2,['Integrat'],['Integration']
Integrability,"Updates SVAnnotate's functional consequence annotation of complex SVs.; * Introduce PREDICTED_PARTIAL_DISPERSED_DUP annotation to describe dispersed duplications of coding sequence that are not expected to behave the same way as tandem duplications; * Ignore INV intervals in dDUP events; * Modify INV intervals in dupINV and similar events to more accurately capture the overall impact of the complex SV; * Ignore complex DUP segments for promoter, noncoding, and nearest TSS annotations because these DUPs are never in tandem; * Merge relevant intervals before annotating nearest TSS for complex events containing DELs; * Update documentation. Testing; * Add unit test for CPX SV segment determination; * Add CPX SV unit test cases; * Update unit/integration test expected outputs; * All unit & integration tests for SVAnnotate ran successfully",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8516:749,integrat,integration,749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8516,2,['integrat'],['integration']
Integrability,Updates files for integration tests that were failing because of a conflict between #3876 and #3611. (Feel free to merge if it passes review so others can continue working immediately),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3910:18,integrat,integration,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3910,1,['integrat'],['integration']
Integrability,Updates gatk-bwamem-jni dependency to 1.0.3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3727:24,depend,dependency,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3727,1,['depend'],['dependency']
Integrability,"Updates the code to pull the PS field out of gVCFs and stores it in the VET_* table(s).; Note schema change on the VET table; Successful BulkIngest [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Exome%20Beta%20Test%20ggrant/job_history/5d1f17a9-eeb2-4db3-a681-32d36d9e567e) (run on Exomes as they have PGT, PID, and PS in their gVCFs).; Successful Integration Test Run [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/9ab365ff-743b-4d97-9c2a-6a09cf8728f4) - But note that the Exome Integration test failed for slight (and expected) difference in table sizes. I have updated the truth in `gs://gvs-internal-quickstart/integration/2023-07-25-quicker/exome_weighted/table_sizes_expected.csv`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8531:356,Integrat,Integration,356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8531,3,"['Integrat', 'integrat']","['Integration', 'integration']"
Integrability,"Updates:; - Changes to scatter width of VCFs generated has changed the amount of data generated in tests, so need to update truth; - Adding a new field to extracted VCF Header `EXCESS_ALLLELES` and that will break the tests.; - And why not validate our VCFs for jollies.; - Updates 'truth' path for data to match these changes. Integration Tests:; Passing test against Chr20/X/Y [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/985fbc06-36ed-4006-9703-0b86577f704c); Passing test against All Chromosomes [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/9d473c81-4742-4188-bc70-1e9371bfcc11)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8846:328,Integrat,Integration,328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8846,1,['Integrat'],['Integration']
Integrability,"Updating the AUTHORS file to include authors who contributed to gatk-protected who's work has been integrated into GATK by the merger. I need to find out the preferred emails for the newly listed authors. Anders Peterson; Ayman Abdel Ghany <aymana.ghany@devfactory.com>; Kenji Kaneda ; Nils Homer. @apete @AymanDF @kkaneda @nh13 Would you like to be included here and if so, what email address would you like listed? Have I spelled your name correctly?. Resolves #3048",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3330:99,integrat,integrated,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3330,1,['integrat'],['integrated']
Integrability,Upgrade Barclay and integrate ExperimentalFeature annotation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2744:20,integrat,integrate,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2744,1,['integrat'],['integrate']
Integrability,Upgrade spark dependency to 1.5,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1406:14,depend,dependency,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1406,1,['depend'],['dependency']
Integrability,"Upgrade testNG to 6.11, use force dependency resolution for testNG",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2617:34,depend,dependency,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2617,1,['depend'],['dependency']
Integrability,"Upgrade to gkl-0.5.6, and added log4j-1.2-api bridge to dependencies,…",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3416:46,bridg,bridge,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416,2,"['bridg', 'depend']","['bridge', 'dependencies']"
Integrability,"Use Cromwell's [noAddress](https://support.terra.bio/hc/en-us/community/posts/360060020871-noAddress-true-results-in-stalling-jobs) feature to avoid the unnecessary use of external IPs on Cromwell worker VMs on wide scatters that cause us Google quota problems. For most of the GVS code this only involves adding `noAddress: true` to the existing runtime attributes. In the PGEN code this was slightly more work to change away from `docker: ""ubuntu:22.04""` which is implicitly pulled from Docker Hub. Since `noAddress: true` means the VM can only interact with Google services, we have to switch to a GCR-hosted image as Docker Hub has become unreachable. - [Mostly successful integration test](https://job-manager.dsde-prod.broadinstitute.org/jobs/32b9e2b5-3c56-4bf8-ab5e-66fa72c7cadb), delta some existing issues with cost discrepancies documented in VS-1324.; - [Successful PGEN extract](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/1f19bea2-a9b9-4ec5-b741-e9f64bbfa35a)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8764:677,integrat,integration,677,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8764,1,['integrat'],['integration']
Integrability,Use gvs-internal project in integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7901:28,integrat,integration,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7901,1,['integrat'],['integration']
Integrability,Use these issues to cover next integration steps. #1903 #1946,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1935#issuecomment-228740961:31,integrat,integration,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1935#issuecomment-228740961,1,['integrat'],['integration']
Integrability,"Used to be used. Used to be tested through an integration test that is no longer, I guess. Merge away. @lbergelson",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4078#issuecomment-355870074:46,integrat,integration,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4078#issuecomment-355870074,1,['integrat'],['integration']
Integrability,"User Report:; ------------; Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360055990891-CollectGcBiasMetrics-Array-Index-Out-Of-Bounds-Exception](https://gatk.broadinstitute.org/hc/en-us/community/posts/360055990891-CollectGcBiasMetrics-Array-Index-Out-Of-Bounds-Exception); ------------. Hello,. When running CollectGcBiasMetrics on a moderately sized sam file (~500Mb), picard gives ArrayIndexOutOfBoundsException and ""Exception counting mismatches for read ..."". The SCAN\_WINDOW\_SIZE=1000. When it's set to default value 100, the error message is slightly different but ArrayIndexOutOfBoundsException persists. I have also experimented with different window sizes, all values >1000 give same error at the same read on chrX (details below). The reference fasta file is taken from UCSC: [https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz](https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz). Any feedback leading to resolving the issue is greatly appreciated. a) Picard version:. 2.21.6-SNAPSHOT. b) Command script:. java -jar picard.jar CollectGcBiasMetrics \\ ; ; I=sorted.sam \\ ; ; O=gc\_bias\_metrics.txt \\ ; ; CHART=gc\_bias\_metrics.pdf \\ ; ; S=summary\_metrics.txt \\ ; ; R=hg19.fa \\ ; ; SCAN\_WINDOW\_SIZE=1000. c) Error log:. MINIMUM\_GENOME\_FRACTION=1.0E-5 IS\_BISULFITE\_SEQUENCED=false METRIC\_ACCUMULATION\_LEVEL=\[ALL\_READS\] ALSO\_IGNORE\_DUPLICATES=false ASSUME\_SORTED=true STOP\_AFTER=0 VERBOSITY=INFO QUIET=false VALIDATION\_STRINGENCY=STRICT COMPRESSION\_LEVEL=5 MAX\_RECORDS\_IN\_RAM=500000 CREATE\_INDEX=false CREATE\_MD5\_FILE=false GA4GH\_CLIENT\_SECRETS=client\_secrets.json USE\_JDK\_DEFLATER=false USE\_JDK\_INFLATER=false ; ; \[Tue Jan 07 16:48:19 PST 2020\] Executing as [akoch@hpc5-0-3.local](mailto:akoch@hpc5-0-3.local) on Linux 2.6.32-431.11.2.el6.x86\_64 amd64; OpenJDK 64-Bit Server VM 1.8.0\_181-b13; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.21.6-SNAPSHOT ; ; INFO",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6372:558,message,message,558,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6372,1,['message'],['message']
Integrability,"User is @wleeidt and they outline their case in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/40530#Comment_40530>. **I can generate plots** with their data and so presumably they are missing some component for the tool to generate plots. Whatever these dependencies, the tool should not emit a `SUCCESS` for the run when plots are absent. User instead gets a `plotting_dump.rda` file. Data is at `/humgen/gsa-scr1/pub/incoming/bugReport_by_wleeidt.updated.zip`.; User's system is; ```; Mac OS X; 10.11.4 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_101-b13; ; ```; GATK Version:; ```; 4.beta.1; ```; Command; ```; gatk-launch PlotSegmentedCopyRatio -TN S4_tumor.pn.tsv -PTN S4_tumor.ptn.tsv -S S4_tumor.seg -O sandbox -SD hg19.dict -pre S4_gatk4_cnv_segment -LOG; ```. Tool could use better error messaging. I will hand this to @LeeTL1220 for appropriate assignment.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3301:271,depend,dependencies,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3301,1,['depend'],['dependencies']
Integrability,"User is running Mutect2 on GATK 4.1.3.0 and gets a NullPointerException error. Their bam did run using different variant callers. However, they got these [results twice](https://gatkforums.broadinstitute.org/gatk/discussion/comment/60577#Comment_60577) on two different bams. Here is the latest error below. . If possible, can the error message improve? The user was able to continue after creating a new index and dictionary for their reference:. ./gatk --java-options ""-Dsamjdk.sra_libraries_download=true"" Mutect2 -R hg19.fa -I test3.bam -O unfiltered.vcf; Using GATK jar /c/linux/gatk/gatk-package-4.1.3.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.sra_libraries_download=true -jar /c/linux/gatk/gatk-package-4.1.3.0-local.jar Mutect2 -R hg19.fa -I test3.bam -O unfiltered.vcf; 10:33:35.145 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/c/linux/gatk/gatk-package-4.1.3.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 28, 2019 10:33:37 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:33:37.506 INFO Mutect2 - ------------------------------------------------------------; 10:33:37.507 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.3.0; 10:33:37.507 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:33:37.508 INFO Mutect2 - Executing as ascott3@LAPTOP-L1C565MP on Linux v4.4.0-17763-Microsoft amd64; 10:33:37.508 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v11.0.4+11-post-Ubuntu-1ubuntu218.04.3; 10:33:37.508 INFO Mutect2 - Start Date/Time: August 28, 2019 at 10:33:35 AM GMT; 10:33:37.509 INFO Mutect2 - ------------------------------------------------------------; 10:33:37.509 INFO Mutect2 - -------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6142:337,message,message,337,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6142,1,['message'],['message']
Integrability,"User replies the missing element was the Rscript packages and once this was installed they were able to plot. So the error message needs to point to the repo's Rscript and the dependent R packages it installs. As of this writing, here is what the error message should say:. > Install R package dependencies using `Rscript install_R_packages.R` with the script from https://github.com/broadinstitute/gatk/blob/master/scripts/docker/gatkbase/install_R_packages.R. The script lists the packages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504:123,message,message,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504,4,"['depend', 'message']","['dependencies', 'dependent', 'message']"
Integrability,UserException.BadTmpDir has an out of date error message,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4709:49,message,message,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4709,1,['message'],['message']
Integrability,Users tend to feed GVCF files to these 3 tools primarily that ends up giving error messages of missing annotations or else. I added these warning messages.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9008:83,message,messages,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9008,2,['message'],['messages']
Integrability,Using 4.0.4.0 and got the following rather unhelpful error from a ImportGenomicsDB. I suspect it might be a variant in one of my VCFs being imported causing an issue but the error message doesn't even hint at which file it was working on. ```; ~/gatk-4.0.4.0/gatk GenomicsDBImport -R hs37d5.fa --sample-name-map gvcfs.samplemap --genomicsdb-workspace-path outputsb.workspace -L 6:29691241-33054015 --batch-size 50 --consolidate true; Using GATK jar /home/cloud-user/gatk-4.0.4.0/gatk-package-4.0.4.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/cloud-user/gatk-4.0.4.0/gatk-package-4.0.4.0-local.jar GenomicsDBImport -R hs37d5.fa --sample-name-map gvcfs.samplemap --genomicsdb-workspace-path outputsb.workspace -L 6:29691241-33054015 --batch-size 50 --consolidate true; 17:01:47.406 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/cloud-user/gatk-4.0.4.0/gatk-package-4.0.4.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 17:01:47.522 INFO GenomicsDBImport - ------------------------------------------------------------; 17:01:47.522 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.0.4.0; 17:01:47.522 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:01:47.522 INFO GenomicsDBImport - Executing as cloud-user@lustre-assembly-1 on Linux v3.10.0-862.3.3.el7.x86_64 amd64; 17:01:47.522 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_171-b10; 17:01:47.523 INFO GenomicsDBImport - Start Date/Time: 17 July 2018 17:01:47 BST; 17:01:47.523 INFO GenomicsDBImport - ------------------------------------------------------------; 17:01:47.523 INFO GenomicsDBImport - ------------------------------------------------------------; 17:01:47.523 INFO GenomicsDBImport - HTSJDK Version: 2.14.3; 17:01:47.523 INFO GenomicsDBImport - Picard,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5064:180,message,message,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5064,1,['message'],['message']
Integrability,Using GATK as a dependency blows up after gkl is included,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1985:16,depend,dependency,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1985,1,['depend'],['dependency']
Integrability,"Using VCFTools to validate:; ```; vcf-validator SAMPLE7T-vs-SAMPLE7N-filtered.vcf; ```. I get a massive amount of messages:; ```; .....snip.......; column SAMPLE7N at 19:49136721 .. Could not validate the float [NaN],FORMAT tag [MPOS] expected different number of values (expected 1, found 2),FORMAT tag [MFRL] expected different number of values (expected 1, found 2),FORMAT tag [MMQ] expected different number of values (expected 1, found 2),FORMAT tag [MCL] expected different number of values (expected 1, found 2),FORMAT tag [MBQ] expected different number of values (expected 1, found 2); .....snip.......; column SAMPLE7T at 19:45901415 .. FORMAT tag [MBQ] expected different number of values (expected 1, found 2),FORMAT tag [MMQ] expected different number of values (expected 1, found 2),FORMAT tag [MCL] expected different number of values (expected 1, found 2),FORMAT tag [MFRL] expected different number of values (expected 1, found 2),FORMAT tag [MPOS] expected different number of values (expected 1, found 2); .....snip.......; ```. Sure enough, the header does not match the values for those fields (in the header number=""A""), so the validation errors are correct. Not sure what is the deal with FOXOG, but that may not be a big deal.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3296:114,message,messages,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3296,1,['message'],['messages']
Integrability,"Using https://jitpack.io/#broadinstitute/gatk for building SNAPSHOTS (independent on your jfrog repository, which has a expired date for snapshots - https://github.com/broadinstitute/gatk/issues/4565) is not working any longer due to the requirement of git-lfs (e.g., https://jitpack.io/com/github/broadinstitute/gatk/4.0.4.0/build.log). It will be nice to add a `jitpack.yml` file (see https://jitpack.io/docs/BUILDING/#custom-commands) to install dependencies - this will be useful for downstream project depending on SNAPSHOTS.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4819:449,depend,dependencies,449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4819,2,['depend'],"['dependencies', 'depending']"
Integrability,"Using the `--gcs-project-for-requester-pays` argument to access a requester-pays bucket, I tried `broad-dsde-methods`, `""broad-dsde-methods""`, and `222581509023`, but no dice. The log shows that the engine is reading the argument, but it doesn't seem to be passed to the cloud utils correctly.; ```; 14:23:16.753 INFO PrintReads - GCS max retries/reopens: 20; 14:23:16.753 INFO PrintReads - Requester pays: enabled. Billed to: broad-dsde-methods; 14:23:16.753 INFO PrintReads - Initializing engine; 14:23:18.501 INFO PrintReads - Shutting down engine; [September 23, 2019 2:23:18 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=375914496; code: 400; message: Bucket is requester pays bucket but no user project provided.; reason: required; location: null; retryable: false; com.google.cloud.storage.StorageException: Bucket is requester pays bucket but no user project provided.; ```. `gsutil -u 222581509023 stat gs://fc-secure-2011b97c-a9c9-4a13-8911-f3833be31253/CCDG_WashU_CVD_EOCAD_METSIM_WGS_all/2893803451.cram` works and `gsutil stat gs://fc-secure-2011b97c-a9c9-4a13-8911-f3833be31253/CCDG_WashU_CVD_EOCAD_METSIM_WGS_all/2893803451.cram` produces; ```; BadRequestException: 400 Bucket is requester pays bucket but no user project provided.; ```. I tried the above variations on `export GOOGLE_CLOUD_PROJECT=` in the shell, but that didn't change things. It's possible I missed some combination of the above, but at the very least our docs need clarification.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6179:714,message,message,714,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6179,1,['message'],['message']
Integrability,"Using the latest `master` version of GATK4 as dependency in gradle (using [jitpack](https://jitpack.io/)) to build a shadow jar generetes the following error when a custom walker run using `java -jar shadowJar.jar CustomTool`, but also with public tools. Only if `--use_jdk_deflater true` is provided, it works. . The log is the following (there is no other log):. ```; 14:57:19.102 INFO IntelGKLUtils - Trying to load Intel GKL library from:; jar:file:/Users/daniel/workspaces/gatk4test/build/libs/shadowJar-0.0.1-SNAPSHOT-all.jar!/com/intel/gkl/native/libIntelGKL.dylib; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x0000000128c014d0, pid=31197, tid=5891; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libIntelGKL8818190486223479934.dylib+0xe4d0] _ZN7ContextIfEC2Ev+0x30; #; # Core dump written. Default location: /cores/core or core.31197; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/gatk4test/hs_err_pid31197.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; Abort trap: 6 (core dumped); ```. To fix it, I tried by excluding `com.intel.gkl` from GATK and add it as a dependency to my program, but it blows up anyway. In addition, I tried a sample program to load the PairHMM fastest implementation by `PairHMM.Implementation.FASTEST_AVAILABLE.makeNewHMM()`, and it also blows up. If I remove completely the dependency in my shadow jar, the command line blows up because the gkl `IntelDeflaterFactory` is not found. I guess that the error in the library is GKL-related, but in the case of the GATK framework I would like to have a way of using the",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1985:46,depend,dependency,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1985,1,['depend'],['dependency']
Integrability,"Using the latest version of ADAM (which has a Scala 2.12 version) fixes the 2bit failures. I also added a fix for the `java.nio.ByteBuffer.clear()` problem. All unit tests are passing, and the only integration test failures are the `Could not serialize lambda` problems. It should be possible to fix these by making the relevant classes implement `Serializable` (like in https://github.com/samtools/htsjdk/pull/1408).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527483090:198,integrat,integration,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527483090,1,['integrat'],['integration']
Integrability,"Usually when we see silent failures like what's happening in singularity, it's due to an out of memory error that results in the JVM process being rudely killed before it can output an error message. It's possible that's what's happening there. If you're running in a container with a limited memory pool, you have to be sure to set the java memory explicitly with -Xmx, but also be sure to leave some memory left over for the system and for native code invoked by java. For example, if you have a container with 8G of memory available I would set -Xmx7g to leave a bit of overhead available. . I think trying with a newer release of java 17 is a good idea.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8988#issuecomment-2386655253:191,message,message,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8988#issuecomment-2386655253,1,['message'],['message']
Integrability,VCFs.java:266); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.regenotypeVC(GenotypeGVCFs.java:222); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:201); at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:151); at org.broadinstitute.hellbender.engine.VariantWalkerBase$$Lambda$96/1188871851.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:149); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:984); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5009:5081,wrap,wrapAndCopyInto,5081,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5009,1,['wrap'],['wrapAndCopyInto']
Integrability,VS 1102 add vds creation wdl to integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8554:32,integrat,integration,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8554,1,['integrat'],['integration']
Integrability,VS 1171 Add an optional Hail whl to the integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8624:40,integrat,integration,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8624,1,['integrat'],['integration']
Integrability,"VS-1092 - Fix for GvsCreateFilterSet OOD; Integration test ran [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/f2dc8eca-1fc2-4ab3-ac38-ab430fb1d60a).; One failure - in the Exome test on AssertCostIsTrackedAndExpected. Doesn't seem related to this code change, so am going to allow it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8573:42,Integrat,Integration,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8573,1,['Integrat'],['Integration']
Integrability,VS-1291 fix integration test in ah var store,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8736:12,integrat,integration,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8736,1,['integrat'],['integration']
Integrability,VS-1324 Investigate integration test failures,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8787:20,integrat,integration,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8787,1,['integrat'],['integration']
Integrability,VS-1433.; This PR adds the tool vcf-validator to our variants docker and uses it in our integration test.; It validates that the VCFs have no errors in the `AD` field (which were previously reported by AoU friends).; It also modifies the Beta integration test to only run on WGS samples (previously ran on all samples). Passing Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/0c9fb830-7831-4bee-a82c-d0146b250e59).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8903:88,integrat,integration,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8903,3,"['Integrat', 'integrat']","['Integration', 'integration']"
Integrability,VS-1476. Removing All usage of VQSR from VDS creation. Only will accept VETS annotated data now. Passing Integration Test (small chrs) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/fa745d55-38d6-4899-a75d-474081eac013); Passing Integration Test (all chrs) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/bb04d1a6-7cf6-45cb-b17f-5e934ab42631),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9015:105,Integrat,Integration,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9015,2,['Integrat'],['Integration']
Integrability,VS-857.; Change default behavior of GvsBulkIngestGenomes.wdl BACK to not dropping GQ0 ref blocks.; Updated AoU documentation to say we need to do it there (as an input). Passing Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/c4f921d8-52e7-4a44-9e0b-9f876eac71f3),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8550:178,Integrat,Integration,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8550,1,['Integrat'],['Integration']
Integrability,VS-914 Add support for vqsr lite to integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8324:36,integrat,integration,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8324,1,['integrat'],['integration']
Integrability,VS-931 Exome integration test on bulk ingest staging,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8448:13,integrat,integration,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8448,1,['integrat'],['integration']
Integrability,VS-931 exome integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8433:13,integrat,integration,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8433,1,['integrat'],['integration']
Integrability,"Valentin & I discussed this in person just now, with the following results:. -The various *Context objects should probably be refactored to return empty lists upon lack of input, as Valentin suggested, instead of being `Optional`. -There may be a need to allow tools to request additional context around the current locus/interval, but tools should probably not be performing arbitrary queries as a general rule, since it would be difficult or impossible to optimize a traversal in which the access pattern is random. If a tool needs to group disparate data items together (eg., mates on different contigs), there should be an initial grouping step to prepare the required data for the main analysis, instead of random queries within the main analysis. -apply()/map() should take its inputs as parameters instead of directly accessing member variables into which input data has been injected.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76805735:883,inject,injected,883,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76805735,1,['inject'],['injected']
Integrability,"Valentin reported that hellbender currently takes ~2 minutes to load BAM index data for a WEx BAM + WEx interval list. We should see if there is some obvious inefficiency here that we can optimize out. At the very least, we need log messages to signal the start and end of index loading/processing. On the plus side, Valentin reports that the actual WEx traversal takes only 12 minutes with his new walker, which seems pretty reasonable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/250:233,message,messages,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/250,1,['message'],['messages']
Integrability,ValidateVariants exception message improvement,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6076:27,message,message,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6076,1,['message'],['message']
Integrability,"ValidateVariants give an `IllegalArgumentException` if a reference isn't provided. . It should be a `UserException`. I don't know but I think there may be modes that don't require the reference, so it may need to give a smart error message. ```; gatk-launch ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.119 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/louisb/Workspace/gatk/build/install/gatk/lib/gkl-0.4.1.jar!/com/intel/gkl/native/libgkl_compression.dylib; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf --doNotValidateFilteredRecords false --warnOnErrors false --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Def",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:232,message,message,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,2,"['message', 'wrap']","['message', 'wrapper']"
Integrability,Variant interface should include an equalsIgnoreUUID() method like GATKRead,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/664:8,interface,interface,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/664,1,['interface'],['interface']
Integrability,"VariantAnnotator, extract a common interface between readsLikelihoods and UnfilledReadsLikelihoods.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4462:35,interface,interface,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4462,1,['interface'],['interface']
Integrability,VariantFiltration is hardwired to output vcf - it should be changed to created writers depending on the extension,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/671:87,depend,depending,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/671,1,['depend'],['depending']
Integrability,"VariantQC is a tool we made that is somewhat analogous to FastQC. Given an input VCF, it runs VariantEval to generate various summary tables of data, and then makes an HTML report (borrowing a lot from the tool MultiQC) summarizing that VCF. . I wrote this originally by forking GATK3 and wrote a new walker that internally called and run VariantEval. That was never the final plan. I dont know what this will need to look like in GATK4 yet. I'm fine with the expectation that GATK4 VariantEval will evolve and we'd need to update our code wrapping it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440806347:540,wrap,wrapping,540,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440806347,1,['wrap'],['wrapping']
Integrability,VariantRecalibrator Reference alleles not same position error message,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6963:62,message,message,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963,1,['message'],['message']
Integrability,VariantRecalibrator and ApplyVQSR integration tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2164:34,integrat,integration,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2164,1,['integrat'],['integration']
Integrability,VariantRecalibrator and ApplyVQSR port part 1 (no integration tests).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2094:50,integrat,integration,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2094,1,['integrat'],['integration']
Integrability,"Variants interface, two implementations, and a test",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/519:9,interface,interface,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/519,1,['interface'],['interface']
Integrability,"Variants with the `-no-overlaps` option, a USER ERROR is outputted after the entire tool finishes running, as shown below:. ```; ***********************************************************************. A USER ERROR has occurred: This GVCF contained overlapping reference blocks. The first overlapping interval is [genomic coordinates here]. ***********************************************************************; ```. This error should be generally helpful, but it appears that the interval that is reported in the error message is the _last_ overlapping interval, not the _first_. I'm not super familiar with java, but I'm guessing that `firstOverlap` might be continuously replaced by `refInterval` if there are multiple overlaps, which is inconsistent with expected behavior. . Potentially relevant lines of code: ; - `-no-overlaps` argument description ([lines 192-201](; https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L192-L201)); - `firstOverlap = refInterval` ([line 275](https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L275)). #### Steps to reproduce. Running ValidateVariants with the `-no-overlaps` flag on a .g.vcf with overlapping intervals will cause this error. More specifically, we're running this within WARP's Exome Germline Single Sample v.3.1.7 WDL release. Our command is as follows:. ```; gatk --java-options ""-Xms6000m -Xmx6500m"" \; ValidateVariants \; -V /path/to/our/.g.vcf.gz \; -R /path/to/our/.fa \; -L /path/to/our/.interval_list \; -gvcf \; --validation-type-to-exclude ALLELES \; --dbsnp /path/to/our/.vcf.gz \; --no-overlaps; ```. #### Expected behavior. The error message should report the _first_ overlapping interval. #### Actual behavior; The error message is reporting the _last_ overlapping interval.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103:2225,message,message,2225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103,2,['message'],['message']
Integrability,"Very funny! Closing, since this is clearly meant as a joke. Let's discuss after alpha ways to actually slim down our dependencies.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1120#issuecomment-157435278:117,depend,dependencies,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1120#issuecomment-157435278,1,['depend'],['dependencies']
Integrability,Vs 299 spike speed up integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8706:22,integrat,integration,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8706,1,['integrat'],['integration']
Integrability,"Want a `Copyable` interface, plus a `DoFn` wrapper that copies each element and wraps in a new `ProcessContext`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/702#issuecomment-126427683:18,interface,interface,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/702#issuecomment-126427683,3,"['interface', 'wrap']","['interface', 'wrapper', 'wraps']"
Integrability,Want to keep this open until we're all satisfied with the way expected output is being checked in the integration test suite -- reopening.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/190#issuecomment-124125237:102,integrat,integration,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/190#issuecomment-124125237,1,['integrat'],['integration']
Integrability,"We don't want users to have to prepend ""file://"" to their input/output files. Let's create a class that wraps URI, and prepends ""file://"" by default when there's no explicit prefix. It should have a constructor that takes a single String to integrate with our argument parsing system.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/477:104,wrap,wraps,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/477,2,"['integrat', 'wrap']","['integrate', 'wraps']"
Integrability,"We found an issue with the way GKL was freeing an internal data structure. The issue was exposed by the `IntelInflaterIntegrationTest`, which uses the Inflater API in a different way than HTSJDK and GATK. We've fixed that issue and the GATK integration tests pass. We're releasing GKL 0.4.1 now and will update this PR when 0.4.1 is available in Maven Central.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282325096:241,integrat,integration,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282325096,1,['integrat'],['integration']
Integrability,"We had another edge-case bug in our clipping code: when calling ReadClipper.revertSoftClippedBases(); on a read at the start of a contig (position == 1), we could end up with an empty read if the cigar; was something like ""41S59H"", since the reverted soft-clipped bases would just get hard-clipped away.; The method did not correctly handle this case, and blew up with an exception. Added a unit test for ReadClipper that fails before the fix and passes after it, as well as an; integration test for HaplotypeCaller that also fails before the fix and passes after it. Resolves #3845",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4203:479,integrat,integration,479,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4203,1,['integrat'],['integration']
Integrability,"We have WGS for more than 800 samples of cod. We are trying to genotype them with GATK, but we cannot get GenomicsDBImport to complete. It seems to run fine but we get the following message at the end of our slurm output file: ""slurmstepd: error: Exceeded step memory limit at some point."" We're running it one chromosome at a time.; We're running it with:; #SBATCH --mem-per-cpu=100G; #SBATCH --partition=hugemem; #SBATCH --cpus-per-task=2. --java-options ""-Xmx190g -Xms190g"" ; --batch-size 50 --consolidate; ; Could you help us optimize it so it actually runs and completes?; Thanks a lot",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6321:182,message,message,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6321,1,['message'],['message']
Integrability,"We have [a researcher reporting that even when running locally, they are getting messages related to the GCS](https://gatkforums.broadinstitute.org/gatk/discussion/13015/failed-to-detect-whether-we-are-running-on-google-compute-engine#latest), which they find puzzling. > WARNING: Failed to detect whether we are running on Google Compute Engine. plus what looks like an error stacktrace in the middle of the stdout. Is this intentional?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424004818:81,message,messages,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424004818,1,['message'],['messages']
Integrability,"We have a lot of code in Hellbender that's at its core a simple function, but it needs many lines of Dataflow boilerplate to wrap it into a transform. It would be a great timesaver to create a helper function that goes from function to PTransform. We might for example use it like this:. `PTransform<A,B> myTransform = Map.<A,B>of( a -> new B(a.start+1, a.end));`. references:; lambda syntax: https://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html; serializable lambdas: http://stackoverflow.com/questions/22807912/how-to-serialize-a-lambda",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/658:125,wrap,wrap,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/658,1,['wrap'],['wrap']
Integrability,We have a number of R package dependencies and it's not clear if we actually need all of them or if some of them are there for historical reasons. We should review them and identify which we actually need.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3047:30,depend,dependencies,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3047,1,['depend'],['dependencies']
Integrability,"We have another researcher asking about this feature at <https://gatkforums.broadinstitute.org/gatk/discussion/14299/gatk4-variantannotator-de-novo-ped-workshop-1809#latest>. If annotating de novos will not be a feature, then please can we remove the option and/or update the error message to be more informative? Would appreciate it. Thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4987#issuecomment-439235429:282,message,message,282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4987#issuecomment-439235429,1,['message'],['message']
Integrability,"We have to keep on top of the times. These are changes we pushed for, so; we can access genomic positions through the same interface on features,; intervals, and samrecords.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/330#issuecomment-85740663:123,interface,interface,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/330#issuecomment-85740663,1,['interface'],['interface']
Integrability,"We just package both Mac and Linux versions of the library in a jar on the artifactory. Problem solved, no pain for users. Your solution could potentially cause user pain if the native build fails due to missing dependencies (don't say it won't happen -- you said that about OpenMP and it happened yesterday!). It also doesn't address the packaging issue at all.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-220146128:212,depend,dependencies,212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-220146128,1,['depend'],['dependencies']
Integrability,We need a file reader that is based on the `java.nio.path` interface that can read lines from a `Path` object. This should wrap `files.lines` and return an `Iterator<String>`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3756:59,interface,interface,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3756,2,"['interface', 'wrap']","['interface', 'wrap']"
Integrability,"We need a interface for variants that can be backed by the Google variant as well as VariantContext (from htsjdk). At first, we only need interval and isSNP/isIndel, so that's the interface right now. This shouldn't impact clients much as the interface interface grows because it will initially only be filled by Hellbender code.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/519:10,interface,interface,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/519,4,['interface'],['interface']
Integrability,"We need a way to install GATK Python modules onto the docker image, from repo source, in a way that doesn't assume a repo clone is present on the docker image (there currently is one, but we want to remove it to recover space), and that also doesn't make the conda environment dependent on a repo clone. This PR adds a build task that creates a zip archive of the GATK Python source; propagates that to the docker image, and then pip installs the contents of the archive into the conda environment on the docker. Since we don't have an actual python module in the repo at the moment, there is a second, temporary, commit that contains a dummy python module used only to trigger and test that the installation works.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3964:277,depend,dependent,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3964,1,['depend'],['dependent']
Integrability,We need to wait for google cloud dependency updates in order for the fix to be incorporated into gatk.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-442117552:33,depend,dependency,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-442117552,1,['depend'],['dependency']
Integrability,"We needed UUIDs for Dataflow, but they are just a hinderance in Spark.; In this PR, I removed every reference to UUID that was related to the original Dataflow code. I also fixed some unit tests that were implicitly depending on the UUIDs to have test reads not equal. The fix was to give the test reads different names.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1068:216,depend,depending,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1068,1,['depend'],['depending']
Integrability,"We recently created the ""variantcalling"" task in the travis CI test suite to reduce the runtime of our integration tests. Once we refactored the docker image we found that the the integration tests are still taking an uncomfortable amount of time to run (upwards of 57 minutes). Short of resolving the issue more permanently (#4989) we can temporarily fix the solution by just splitting off more of the integration tests to other jobs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4990:103,integrat,integration,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4990,3,['integrat'],['integration']
Integrability,"We recently determined that the FTZ setting gets cleared during integration tests for unknown reasons. We temporarily fixed this by explicitly turning FTZ on in every call to `jniComputeLikelihoods()` (https://github.com/broadinstitute/gatk/pull/1764), but this might be inefficient, and even if it isn't it would be good to understand what's going on. Without the fix in https://github.com/broadinstitute/gatk/pull/1764, if you run `HaplotypeCallerIntegrationTest`, the ""consistent with past results"" tests will either succeed or fail depending on whether they run first or not, and the failure is definitely due to FTZ somehow getting unset between tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1771:64,integrat,integration,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1771,2,"['depend', 'integrat']","['depending', 'integration']"
Integrability,"We recently introduced some new log4j error messages on spark. ```; og4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4769b07b] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@5ef60048].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@4769b07b] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@5ef60048].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; ```. These are likely the result of an additional transitive log4j dependency from GenomicsDB introduced in #2389. . We should can probably stop them with additional exclusions in our spark build.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2622:44,message,messages,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2622,2,"['depend', 'message']","['dependency', 'messages']"
Integrability,"We ship an Intel conda environment that uses the Intel optimized tensorflow implementation for those with AVX-enabled hardware, but the environment requires AVX, so there are no tests since we can't assume we have AVX hardware on Travis. We need to provision some kind of continuous test that ensures that the CNN tools continue to work in this environment as we upgrade our dependencies for things like tensorflow, keras, etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5255:375,depend,dependencies,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5255,1,['depend'],['dependencies']
Integrability,"We should also make sure that hellbender handles the case of ""wrong reference for CRAM"" gracefully and does not do anything stupid -- what we want is a `UserException` to be thrown with a descriptive error message. We should add an integration test to verify that we handle this properly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/677#issuecomment-122996429:206,message,message,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/677#issuecomment-122996429,2,"['integrat', 'message']","['integration', 'message']"
Integrability,"We should be able to use this single implementation to satisfy both https://github.com/broadinstitute/gatk/issues/4347 and https://github.com/broadinstitute/gatk/issues/4351. Questions: @vdauwera What other tools that were dropped from GATK3 should be added to the list now? GATK3 also has a deprecated annotations list, which is included here, but is empty. Are there any annotations that should be listed ? I can't really implement/test that part unless I populate it with something. Also, trying to run a missing tool is currently handled as an error, and surfaces in the context of a usage message. Perhaps that hides it too much:. <img width=""918"" alt=""screen shot 2018-03-07 at 11 25 40 am"" src=""https://user-images.githubusercontent.com/10062863/37104403-a15635ae-21fa-11e8-985a-94ff0e203cf8.png"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4505:594,message,message,594,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4505,1,['message'],['message']
Integrability,We should fix the dependency issue and then re-enable them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7170:18,depend,dependency,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7170,1,['depend'],['dependency']
Integrability,We should make sure for beta that we use a version of Hadoop-BAM that depends on the same version of htsjdk as GATK uses.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2742:70,depend,depends,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2742,1,['depend'],['depends']
Integrability,We should patch to give a better error message as well...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6260#issuecomment-553004443:39,message,message,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6260#issuecomment-553004443,1,['message'],['message']
Integrability,"We should probably consider using a resolution policy of ""failOnVersionConflict"" in both gatk and gatk-protected. This will force us to manually resolve any dependent module version conflicts as they arise, rather than depending on Gradle (which will choose the newest one by default) to do the resolution for us.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2592:157,depend,dependent,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2592,2,['depend'],"['dependent', 'depending']"
Integrability,We should update our small dependencies if they need it. - [x] gatk-native-bindings -> release it as version 1.0.0; - [x] gatk-fermilite-jni -> release the current version as 1.1.0; - [x] gatk-bwamem-jni -> release a version 1.0.4 which includes a new method; - [ ] update gatk with new libraries,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4030:27,depend,dependencies,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4030,1,['depend'],['dependencies']
Integrability,"We shouldn't call toAbsolutePath on our Paths since it resolves paths that are not already absolute to a (implementation dependent) default location, which will often return an incorrect result for non-default file systems. This is the cosmetic part of the fix for https://github.com/broadinstitute/gatk/issues/6348. The actual fix requires an htsjdk that has https://github.com/samtools/htsjdk/pull/1449.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6367:121,depend,dependent,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6367,1,['depend'],['dependent']
Integrability,"We somehow missed some new deprecation warnings that gradle gives when we updated to 7.3.2. . When running `bundle`; ex:; ```; Task :sparkJar; Execution optimizations have been disabled for task ':sparkJar' to ensure correctness due to the following reasons:; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/classes/java/main'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/resources/main'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/tmp/sparkJar/MANIFEST.MF'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; ```. ```; Deprecated Gradle features were used in this build, making it incompatible with Gradle 8.0. You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins. See https://docs.g",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7625:503,depend,dependency,503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7625,3,['depend'],"['dependency', 'depending']"
Integrability,"We use Gauss-Legendre integration in the strand bias model. The number of subdivisions increases with the read count and for very deep coverage this can cause a stack overflow because, unfortunately, Apache Commons has a very questionable recursive implementation. The short-term fix is to cap the number of subdivisions. The long-term fix is to write some sort of simple adaptive 1D and 2D quadrature method. This ticket is for the short-term fix.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3317:22,integrat,integration,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3317,1,['integrat'],['integration']
Integrability,We use the Concordance tool in the GATK workshop hard filtering tutorial and it has a big scary red beta message in the log. I don't see any open issues reported against it. If there are no further features planned we can take the beta tag off.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6392:105,message,message,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6392,1,['message'],['message']
Integrability,"We want tasks such as parsing VCF files to be done in Java, rather than in Python, so that we can leverage all the work we do in htsjdk even in tools that call into a `PythonScriptExecutor`. This implies that we need an easy/efficient means of streaming data in and out of the child Python process. Perhaps a ""popen()""-like approach would be good here (or a named FIFO, or protocol buffers...lots of options).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3698:373,protocol,protocol,373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3698,1,['protocol'],['protocol']
Integrability,"We want to add an overload of `SamReaderFactory.open()` in htsjdk that accepts a `java.nio.file.Path`, and uses `Files.newInputStream(path)` or similar to get an `InputStream` from it and return a SAM/BAM/CRAM reader. This should enable us to transparently load reads from any input source for which there is a Java NIO file system provider available. Such a provider is already implemented for HDFS (https://github.com/damiencarol/jsr203-hadoop). There may be one for GCS as well (and if there isn't, it might be simple to implement one). Note that this feature needs to handle the companion index as well, if present. Also note that we should not add any new dependencies to htsjdk as part of this change. This change should be modeled on the equivalent change @tomwhite recently made for the reference classes in htsjdk (https://github.com/samtools/htsjdk/pull/308). The unit tests in htsjdk for this feature can be very simple -- just take existing `File` arguments to test cases and call `toPath()` on them, and make sure the existing test cases pass. . On the GATK side, we'd want tests to make sure that we can use the new `SamReaderFactory.open()` overload to open BAM/SAM/CRAM files locally, on HDFS, and on GCS. If it turns out that there isn't already a Java NIO provider for GCS and it's non-trivial to implement, that could become a separate ticket.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1426:661,depend,dependencies,661,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1426,1,['depend'],['dependencies']
Integrability,"We want to continue to go through `AddContextDataToReadSpark` at the top level, if possible, because we want that to be our standard interface for joining reads with all kinds of overlapping data. We can certainly add a mode in which it assumes that the reference is broadcast and just joins reads with variants.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/909#issuecomment-141992169:133,interface,interface,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/909#issuecomment-141992169,1,['interface'],['interface']
Integrability,We were seeing failures on spark clusters that manifested as being; unable to find the Main class while running spark submit. The caused was the accidental introduction of a jar signature file; and key from the transitive gnu.getopt dependency. This was causing; signature validation failures since our uber jar did not match the; expected hashes. Fixed by excluding .SF and .RSA files from our jars.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2618:233,depend,dependency,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2618,1,['depend'],['dependency']
Integrability,"We'd also need a good integration test that reads in a VCF containing genotypes using `SelectVariants` with `--sites-only`, writes it out, reads it back in using `VariantContextTestUtils.readEntireVCFIntoMemory()`, and asserts that the genotypes are gone. The test should probably live someplace like `GATKToolIntegrationTest` or `FeatureSupportIntegrationTest` -- don't put it in `SelectVariantsIntegrationTest`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4763#issuecomment-388453987:22,integrat,integration,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4763#issuecomment-388453987,1,['integrat'],['integration']
Integrability,"We'd prefer something tightly integrated with our main test suite in travis, and reserve jenkins for long-running/nightly tests. Having to deal with two CI environments for pull requests is too cumbersome.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-287474520:30,integrat,integrated,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-287474520,1,['integrat'],['integrated']
Integrability,"We'd really like to be able to move forward to newer java versions. Unfortunately we have a pretty long list of dependencies which don't support any version newer than 8 yet. In particular, our dependency on Spark is problematic. Spark is stuck on java 8 because of issues with scala on java 9+ as well as issues with their dependencies. As I understand it, Java 9+ made changes to various methods which were widely used by libraries that do low level memory management. It also deprecated some forms of cross package reflection. Spark makes heavy use of both of those things so I think there having trouble updating. . So... we'd like to update, I have no idea when will be able to. Probably not for at least a year.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5737#issuecomment-468476353:112,depend,dependencies,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5737#issuecomment-468476353,3,['depend'],"['dependencies', 'dependency']"
Integrability,"We're leaning towards the wrapper option at this point, so as not to penalize non-dataflow code for dataflow's shortcomings.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/702#issuecomment-125703530:26,wrap,wrapper,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/702#issuecomment-125703530,1,['wrap'],['wrapper']
Integrability,"We're seeing a lot of failures of the form:. ```; com.google.cloud.storage.StorageException: 806222273987-uilktks3j6i7962rp0v7nusveer58497@developer.gserviceaccount.com does not have serviceusage.services.use access to project 685190392835.; Caused by:; shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; {; ""code"" : 403,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""806222273987-uilktks3j6i7962rp0v7nusveer58497@developer.gserviceaccount.com does not have serviceusage.services.use access to project 685190392835."",; ""reason"" : ""forbidden""; } ],; ""message"" : ""806222273987-uilktks3j6i7962rp0v7nusveer58497@developer.gserviceaccount.com does not have serviceusage.services.use access to project 685190392835.""; }; ```. It looks like it now requires some new permission for the service accounts but our existing service account doesn't have that permission.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-511986926:410,message,message,410,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-511986926,2,['message'],['message']
Integrability,"We're seeing messages like the following when running `GenomicsDBImport`:. ```; Column 948660 has too many alleles in the combined VCF record : 61 : current limit : 50. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location.; Column 948710 has too many alleles in the combined VCF record : 83 : current limit : 50. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location.; ```. Is this limit of 50 configurable, if we wanted to raise it, and if not, could it be made configurable?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2687:13,message,messages,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2687,1,['message'],['messages']
Integrability,"We've been implementing new features but the coverage in the `sv.utils` package has been non-pretty. Some of the classes like `ExternalCommandlineProgramModule.java` and `GATKSVVCFConstants.java` are OK (`ExternalCommandlineProgramModule` exists for historical reason, when we had SGA as the assembler; `GATKSVVCFConstants` is mostly holding String literals), but other classes are doing actual work and have low coverage. We should test them, not via integration tests only, but also unit tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5139:452,integrat,integration,452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5139,1,['integrat'],['integration']
Integrability,We've definitely seen similar problems before with accented characters. Might be system dependent since I can't reproduce the issue... What OS are you building on?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4434#issuecomment-367406877:88,depend,dependent,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4434#issuecomment-367406877,1,['depend'],['dependent']
Integrability,"We've patched GatherVCFs to allow it to read from NIO, but since it's a picard tool it's going to be reverted when we switch to depending on the real picard. We need to either port the changes to picard or make a gatk-tool version",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2745:128,depend,depending,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2745,1,['depend'],['depending']
Integrability,"Well, I guess that part of the contract for GATKTool is that GATK tools should report progress as they go. I agree that the ProgressMeter should be made more flexible and allow reporting of progress in terms of things other than genomic location.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577262636:31,contract,contract,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577262636,1,['contract'],['contract']
Integrability,"Well, there's that, but there's also the unnecessary dependency on (what I imagine is) a large jar of Google code, and the cognitive dissonance of using something in the gcs package called _Bucket_Utils to do HDFS work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1887#issuecomment-224366777:53,depend,dependency,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1887#issuecomment-224366777,1,['depend'],['dependency']
Integrability,What I'm saying is that the tarball that github auto-publishes is missing important files that are managed by git-lfs. So you need to fetch those somehow. They're not gradle dependencies and gradle doesn't know how to localize them without using git-lfs which relies on the git directory. If you have a mechanism for localizing those (and for setting the version manually) then it would be possible get rid of the git repo requirement. If you don't then there's no point in overriding the check.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6395#issuecomment-584455736:174,depend,dependencies,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6395#issuecomment-584455736,1,['depend'],['dependencies']
Integrability,What is driving the transcript error messages? Do we need to worry about these?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4882:37,message,messages,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4882,1,['message'],['messages']
Integrability,"What is the current I/O throughput, the amount of data being pushed and the desired response-time? Usually keeping read-only data locally is usually faster, but it depends on how frequently it is used. Otherwise there would be dedicated sharded indexed servers, which would perform part of the repetitive data-processing to increase the response-time back to any workers and returned results.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/490#issuecomment-102111648:164,depend,depends,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/490#issuecomment-102111648,1,['depend'],['depends']
Integrability,What is the progress on this @cmnbroad? Is this waiting for the new Barclay plugin interface?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-282995363:83,interface,interface,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-282995363,1,['interface'],['interface']
Integrability,"What is the timeline for removing pysam, PyVCF, etc. dependencies (#4465)? I think we agreed to abide by certain rules when we started python development, but I don't know who is responsible for enforcing them...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-387139875:53,depend,dependencies,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-387139875,1,['depend'],['dependencies']
Integrability,What test was depending on toString? We should maybe update that test...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/811#issuecomment-130750068:14,depend,depending,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/811#issuecomment-130750068,1,['depend'],['depending']
Integrability,"What we saw recently wasn't the reference itself, but rather our AF-only gnomAD resource lifted-over to the hg38 reference. The error only came up for sites that reached genotyping, which depends on the specific tumor sample as well as the lack of evidence in the normal. That's why it only appeared in some tumor-normal combinations. That being said, it might be something else. If you are able to share the unfiltered vcf file and the vcf.stats file it would be the most direct way to debug.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478310143:188,depend,depends,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478310143,1,['depend'],['depends']
Integrability,What's the protocol for getting this PR merged - @meganshand are you the right reviewer?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6872#issuecomment-710701299:11,protocol,protocol,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6872#issuecomment-710701299,1,['protocol'],['protocol']
Integrability,"When I tried to run the latest build of the spark gatk I got the following error message on both dataproc and the onprem cluster.; `File Not Found: [/Users/emeryj/IdeaProjects/gatk/build/libIntelDeflater.so]`. Making the following changes to gatk-launch seems to fix it. ```; @@ -23,14 +23,13 @@ BUILD_LOCATION = script +""/build/install/"" + projectName + ""/bin/""; GATK_RUN_SCRIPT = BUILD_LOCATION + projectName; BIN_PATH = script + ""/build/libs"". -EXTRA_JAVA_OPTIONS=""-Dsamjdk.intel_deflater_so_path=libIntelDeflater.so -Dsamjdk.compression_level=1 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true ""; +EXTRA_JAVA_OPTIONS=""-DGATK_STACKTRACE_ON_USER_EXCEPTION=true "". DEFAULT_SPARK_ARGS = [""--conf"", ""spark.kryoserializer.buffer.max=512m"",; ""--conf"", ""spark.driver.maxResultSize=0"",; ""--conf"", ""spark.driver.userClassPathFirst=true"",; ""--conf"", ""spark.io.compression.codec=lzf"",; ""--conf"", ""spark.yarn.executor.memoryOverhead=600"",; -""--conf"", ""spark.yarn.dist.files="" + script + ""/build/libIntelDeflater.so"",; ""--conf"", ""spark.driver.extraJavaOptions="" + EXTRA_JAVA_OPTIONS,; ""--conf"", ""spark.executor.extraJavaOptions="" + EXTRA_JAVA_OPTIONS]; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1930:81,message,message,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1930,1,['message'],['message']
Integrability,"When I was trying to use user exceptions in a consistent way independently of the constructor (mostly related with files), I found very weird behaviour with the messages. Here I try to fix some of the things that I was struggling with:. * Support for path in constructors for `CouldNotReadInputFile`, `CouldNotCreateOutputFile`, `MalformedFile` and `MalformedBAM`, in addition to some missing constructors to have the same structure for all of them (with `File` and/or `String`).; * ~~Updated javadoc in `CommandLineException`, including extending classes to make clear that in the GATK framework is not printed out if it is thrown out of parameter validation.~~ __Edited__: this is not longer required, because `CommandLineException` is decoupled from `UserException` through barclay.; * Added a TODO into the `MalformedBAM` constructor that includes a `GATKRead` that is not used.; * __Edited__: added final to constructors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282:161,message,messages,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282,1,['message'],['messages']
Integrability,"When doing this, make `canDecode()` abstract in the codec interface so that all codecs are forced to implement it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/230#issuecomment-90153118:58,interface,interface,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/230#issuecomment-90153118,1,['interface'],['interface']
Integrability,"When parsing interval arguments in GATK using the latest htsjdk, files that end in "".interval_list"" are claimed by the new IntervalListCodec introduced in https://github.com/samtools/htsjdk/pull/1327. This PR renames the one test file in GATK that has a Picard interval list file extension but isn't really a Picard interval list; without this change, CountReads and CountReadsSpark integration tests will fail when we upgrade to the next htsjdk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5879:383,integrat,integration,383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5879,1,['integrat'],['integration']
Integrability,"When running GATK with specific interval(s), the default behavior is to include any variant spanning those interval(s). When running scatter/gather jobs, this behavior is generally not what one wants, since this would result in variants spanning the job intervals getting included twice. In a handful of GATK tools, there is support for something like --ignore-variants-starting-outside-interval, which is probably designed to solve this problem. GenotypeGVCFs supports this. However, the implementation/support is generally tool-level and I dont believe all tools support this. For example, SelectVariants does not appear to. If one wants to run a scatter/gather task that doesnt start with a GATK tool that supports --ignore-variants-starting-outside-interval, you're out of luck. My questions are:. 1) Am I completely missing some existing capability?. 2) There is already some low-level support in the engine for control over intervals. Would you be receptive to a PR that pushes support for ""--ignore-variants-starting-outside-intervals"" lower into GATK? Perhaps into VariantWalkerBase? One possibility would be to create a StartsWithinIntervalsVariantFilter, and override makeVariantFilter() to inject it. I dont think this would be particularly invasive, and could be pretty useful across many tools. As part of this, MultiVariantWalkerGroupedOnStart's argument would get merged with this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8063:1201,inject,inject,1201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8063,1,['inject'],['inject']
Integrability,"When running jobs on our Spark cluster I start seeing error messages in the logs midway through the job, of the form:. ```; 16/02/16 11:45:10 ERROR TransportRequestHandler: Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=1974353486066, chunkIndex=0}, buffer=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=715964266 cap=715964266]}} to /69.173.65.228:49341; closing connection; ```. java.nio.channels.ClosedChannelException. These are often followed by stacktraces like this:. ```; java.io.IOException: Broken pipe; at sun.nio.ch.FileDispatcherImpl.write0(Native Method); at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47); at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93); at sun.nio.ch.IOUtil.write(IOUtil.java:65); at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:466); at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:105); at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:91); at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:254); at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237); at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:281); at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:761); at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:311); at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:729); at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1127); at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:663); at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:644); at io.netty.channel.ChannelOutboundHandlerAdapter.flush(ChannelOutboundHandlerAdapter.java:115); at io.netty.channel.AbstractChannelHandler",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1491:60,message,messages,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1491,6,"['Message', 'message', 'protocol']","['MessageWithHeader', 'messages', 'protocol']"
Integrability,"When running the following command. gatk4 BaseRecalibratorSpark -I xx_markduplicatespark.bam -knownSites dbsnp_138.b37.vcf -knownSites Mills_and_1000G_gold_standard.indels.b37.vcf -O xx_baserecalibratespark.table -R humann_g1k_v37.2bit --TMP_DIR tmp. I got error message,. Using GATK wrapper script /curr/tianj/software/gatk/build/install/gatk/bin/gatk; Running:; /curr/tianj/software/gatk/build/install/gatk/bin/gatk BaseRecalibratorSpark -I A15_markduplicatespark.bam -knownSites ref/Mills_and_1000G_gold_standard.indels.b37.vcf -O A15_baserecalibratespark.table -R /curr/tianj/data/humann_g1k_v37.2bit; 17:19:00.338 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/curr/tianj/software/gatk/build/instabgkl_compression.so; [May 17, 2017 5:19:00 PM UTC] org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark --knownSites /genome/ref/db_1000G_gold_standard.indels.b37.vcf --output A15_baserecalibratespark.table --reference /curr/tianj/data/humann_g1k_v37.2bp --joinStrategy BROADCAST --mismatches_context_size 2 --indels_context_size 3 --maximum_cycle_value 500 --mismatches_defdeletions_default_quality 45 --low_quality_tail 2 --quantizing_levels 16 --bqsrBAQGapOpenPenalty 40.0 --preserve_qscores_lles false --useOriginalQualities false --defaultBaseQualities -1 --readShardSize 10000 --readShardPadding 1000 --readValid-interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --sharl[*] --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inf; [May 17, 2017 5:19:00 PM UTC] Executing as tianj@ip-172-31-78-66 on Linux 4.4.41-36.55.amzn1.x86_64 amd64; Java HotSpot(TM:4.alpha.2-261-gb8d32ee-SNAPSHOT; 17:19:00.371 INFO BaseRecalibratorSpark - Defaults.BUFFER_SIZE : 131072; 17:19:00.371 INFO BaseRecalibratorSpark - Defaults.COMPRESSION_LEVEL : 1; 17:19:00.371 INFO BaseRecalibratorSpark - Defaults.CREATE_INDEX : false; 17:19:00.371 INFO BaseR",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2732:263,message,message,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2732,2,"['message', 'wrap']","['message', 'wrapper']"
Integrability,"When set, the # argument leads to a message saying it is not recognized (idem with shorter notation -new-qual). * is this parameter obsolete with this version of GATK4 (4.1.6.0) and should it be removed from best practice?; * is it the current default behaviour and is not needed anymore?; * did I do something wrong?. many questions ! sorry :-). ```; java ${javaopts} -jar $GATK/gatk.jar \; 	GenotypeGVCFs \; 	--reference ${reference_fa} \; 	--variant gendb://${outfolder}/merged_gvcf.db \; 	--annotation-group StandardAnnotation \; #	--use-new-qual-calculator true \; 	--output ${outfolder}/gatk_variants.vcf.gz \; 	--tmp-dir ${basedir}/tmpfiles/; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6547:36,message,message,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6547,1,['message'],['message']
Integrability,"When splitting up samples over regions to pass to HaplotypeCallerSpark, we ran into an edge case where it will die on regions not containing any reads, with a empty collection error. It would be great if we could catch this cleanly and generate a VCF without any calls. Here is a small self contained test case which demonstrates the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_hcspark_noreads.tar.gz. and the full error message:; ```; java.lang.UnsupportedOperationException: empty collection; at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$apply$35.apply(RDD.scala:1004); at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$apply$35.apply(RDD.scala:1004); at scala.Option.getOrElse(Option.scala:121); at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1004); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.reduce(RDD.scala:984); at org.apache.spark.api.java.JavaRDDLike$class.reduce(JavaRDDLike.scala:384); at org.apache.spark.api.java.AbstractJavaRDDLike.reduce(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.callVariantsWithHaplotypeCaller(HaplotypeCallerSpark.java:229); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.callVariantsWithHaplotypeCallerAndWriteOutput(HaplotypeCallerSpark.java:182); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.runTool(HaplotypeCallerSpark.java:143); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:387); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4234:440,message,message,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4234,1,['message'],['message']
Integrability,"When the MultiVariantWalker is integrated with VQSR, we need to make sure to update the code that populates the output header to match the way GATK3 did it with multiple inputs (mostly affects ApplyVQSR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2114#issuecomment-246357129:31,integrat,integrated,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2114#issuecomment-246357129,1,['integrat'],['integrated']
Integrability,When the changes from this https://github.com/broadinstitute/picard/pull/1442 go in and we update our picard dependency we should port the test and scaling factor from that branch.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6316:109,depend,dependency,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6316,1,['depend'],['dependency']
Integrability,"When the gvcf was merged by ""bcftools concat"", the following error will be happen. more info: ; https://gatkforums.broadinstitute.org/gatk/discussion/10817/gatk-runtime-error-on-genotypegvcfs-java-lang-double-cannot-be-cast-to-java-lang-integer. **java.lang.ClassCastException: java.lang.Double cannot be cast to java.lang.Integer**; 	at java.lang.Integer.compareTo(Integer.java:52); 	at java.util.Comparators$NaturalOrderComparator.compare(Comparators.java:52); 	at java.util.Comparators$NaturalOrderComparator.compare(Comparators.java:47); 	at java.util.TimSort.countRunAndMakeAscending(TimSort.java:351); 	at java.util.TimSort.sort(TimSort.java:216); 	at java.util.Arrays.sort(Arrays.java:1507); 	at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:302); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:513); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.utils.Utils.getMedianValue(Utils.java:1137); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:277); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:101); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.endPreviousStates(CombineGVCFs.java:340); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.createIntermediateVariants(CombineGVCFs.java:189); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.apply(CombineGVCFs.java:134); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:73); 	at org.broadinstitute.hellben",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4633:888,wrap,wrapAndCopyInto,888,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4633,1,['wrap'],['wrapAndCopyInto']
Integrability,"When the user includes an unknown argument in a tool command line the error message only indicates the first letter of the unknown argument as supposed to the full name. . At the very least the message should read ""unknown argument STARTING with 'x'"". However I would say that is far better if the whole argument name is output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1751:76,message,message,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1751,2,['message'],['message']
Integrability,When this is integrated we should make sure that we require a reference for output CRAMs.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1069#issuecomment-157509556:13,integrat,integrated,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1069#issuecomment-157509556,1,['integrat'],['integrated']
Integrability,"When we make enhancements to the walker engine (eg., modify the `GATKTool` base class to support CRAM, or to validate the sequence dictionaries of the inputs), it would be good if Spark tools could also reap the benefits of these changes automatically. We may need to unify (or better integrate) the `GATKTool` and `SparkCommandLineProgram` base classes somehow to make this possible, as well as classes like `ReadsDataSource` (for walkers) and `ReadsSparkSource` (for Spark tools).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/680:285,integrat,integrate,285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/680,1,['integrat'],['integrate']
Integrability,"When you merge, be sure to update the commit comment and message to reflect the fact that it's been replaced instead of deprecated and that the default behavior is the opposite of what it used to be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318688481:57,message,message,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318688481,1,['message'],['message']
Integrability,"When you run a tool, a message with the bundled versions should show in the log.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4733#issuecomment-386247582:23,message,message,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4733#issuecomment-386247582,1,['message'],['message']
Integrability,"While a minor issue, moving to `slf4j-api` as the logging API and `slf4j-log4jxx` as the implementation would help with interoperability. For example, I'm working on a proposal for a separate library for conversions between formats, and currently the API passes in a slf4j `Logger` and an enum similar to `ValidationStringency`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-261286474:120,interoperab,interoperability,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-261286474,1,['interoperab'],['interoperability']
Integrability,"While most jobs have been failing with an error like the above, chr8 gave the following. Does this also suggest a memory issue, based on Z_MEM_ERROR: https://zlib.net/manual.html?. 07 Nov 2020 08:34:25,100 DEBUG: 08:34:24.941 INFO GenomicsDBImport - Done importing batch 3/4; 07 Nov 2020 08:34:29,847 DEBUG: 08:34:29.847 INFO GenomicsDBImport - Importing batch 4 with 33 samples; 08 Nov 2020 10:46:27,095 DEBUG: [TileDB::utils] Error: (gzip_handle_error) Cannot decompress with GZIP: inflateInit error: Z_MEM_ERROR; 08 Nov 2020 10:46:27,280 DEBUG: [TileDB::Codec] Error: Could not compress with .; 08 Nov 2020 10:46:27,285 DEBUG: [TileDB::ReadState] Error: Cannot decompress tile.; 08 Nov 2020 10:47:00,459 DEBUG: 10:47:00.458 erro NativeGenomicsDB - pid=16931 tid=17036 VariantStorageManagerException exception : Error while consolidating TileDB array 8$1$145679320; 08 Nov 2020 10:47:00,473 DEBUG: TileDB error message : ; 08 Nov 2020 10:47:00,487 DEBUG: terminate called after throwing an instance of 'std::exception'; 08 Nov 2020 10:47:00,492 DEBUG: what(): std::exception; 08 Nov 2020 10:47:37,511 WARN : process exited with non-zero value: 134",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-724231609:913,message,message,913,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-724231609,1,['message'],['message']
Integrability,"While producing combined VariantContext objects in GenomicsDB, combine operations must be specified for the INFO fields through the vid object. Some of the commonly used fields (*RankSum, DP) are handled by the GenomicsDB code. If an INFO field does not have a combine operation (in the vid or in the GenomicsDB source code), then the combine operation ignores the field (producing the message above). Note that the data is still imported into GenomicsDB - the combine operation (query) ignores these fields. A new query with the fixed vid will return the field. GATK CombineGVCFs ignores MLEAC, MLEAF and DS fields. HaplotypeScore and InbreedingCoeff have no data in the gVCFs (any gVCF we have seen). Other fields like ExcessHet are combined using median operation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293635317:386,message,message,386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293635317,1,['message'],['message']
Integrability,"While trying to run a tool with a CRAM input located on a hdfs attached to a dataproc cluster, we are hit by an error message described below:. ```; ***********************************************************************. A USER ERROR has occurred: Failed to read bam header from hdfs://svdev-caller-m:8020/data/smallCram.cram; Caused by:Pathname /tmp/da63aa3c-e3bc-4893-9f40-42921719a343/hdfs:/svdev-caller-m:8020/reference/Homo_sapiens_assembly38.fasta from /tmp/da63aa3c-e3bc-4893-9f40-42921719a343/hdfs:/svdev-caller-m:8020/reference/Homo_sapiens_assembly38.fasta is not a valid DFS filename. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: A USER ERROR has occurred: Failed to read bam header from hdfs://svdev-caller-m:8020/data/smallCram.cram; Caused by:Pathname /tmp/da63aa3c-e3bc-4893-9f40-42921719a343/hdfs:/svdev-caller-m:8020/reference/Homo_sapiens_assembly38.fasta from /tmp/da63aa3c-e3bc-4893-9f40-42921719a343/hdfs:/svdev-caller-m:8020/reference/Homo_sapiens_assembly38.fasta is not a valid DFS filename.; 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:206); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:381); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:361); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:351); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2382:118,message,message,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2382,1,['message'],['message']
Integrability,"While we normally don't recommend ignoring that wrapper, this seems like a good reason to do so. . The wrapper is pretty simple, most of what it's doing is some munging of the input to allow it to be more standardized in several different gatk use cases. The only thing I can think of that you would want to be sure to copy is that it sets a number of properties. . We set these spark `--conf` properties with the wrapper. I don't actually know how important some of them are anymore. If it works without them then you're probably good.; ```; ""spark.kryoserializer.buffer.max"" : ""512m"",; ""spark.driver.maxResultSize"" : ""0"",; ""spark.driver.userClassPathFirst"" : ""false"",; ""spark.io.compression.codec"" : ""lzf"",; ""spark.executor.memoryOverhead"" : ""600"",; ""spark.driver.extraJavaOptions"" : EXTRA_JAVA_OPTIONS_SPARK,; ""spark.executor.extraJavaOptions"" : EXTRA_JAVA_OPTIONS_SPARK; ```. These are htsjdk properties we want to set for spark. ; ```; EXTRA_JAVA_OPTIONS_SPARK= ""-DGATK_STACKTRACE_ON_USER_EXCEPTION=true "" \; ""-Dsamjdk.use_async_io_read_samtools=false "" \; ""-Dsamjdk.use_async_io_write_samtools=false "" \; ""-Dsamjdk.use_async_io_write_tribble=false "" \; ""-Dsamjdk.compression_level=2 ""; ```. If you can get this value into your spark environment variables it prevents and anying warning output. `SUPPRESS_GCLOUD_CREDS_WARNING=true`. Let us know how it works for you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6198#issuecomment-539073054:48,wrap,wrapper,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6198#issuecomment-539073054,3,['wrap'],['wrapper']
Integrability,While working on #9012 I tried to update the gencode v28 datasource snippets in the Funcotator integration tests to V43. In doing so I found that it broke the MAF vs. VCF output render tests with errors of the following nature: . ```; java.lang.AssertionError: Failed Matching VCF and MAF fields:; 	VCF (Gencode_43_variantClassification): 	RNA[0]	RNA[1]	RNA[2]	RNA[3]	RNA[4]	RNA[5]	RNA[6]	RNA[7]	RNA[8]	RNA[9]	RNA[10]; 	MAF (Variant_Classification): 	LINCRNA[0]	LINCRNA[1]	LINCRNA[2]	LINCRNA[3]	LINCRNA[4]	LINCRNA[5]	LINCRNA[6]	LINCRNA[7]	LINCRNA[8]	LINCRNA[9]	LINCRNA[10]; ----; 	VCF (Gencode_43_otherTranscripts): 	[0]	[1]	[2]	[3]	[4]	[5]	[6]	[7]	[8]	[9]	[10]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK/PIK3CA-DT_ENST00000435560.1_RNA[11]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK/PIK3CA-DT_ENST00000435560.1_RNA[12]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK/PIK3CA-DT_ENST00000435560.1_RNA[13]	PIK3CA_ENST00000643187.1_INTRON/PIK3CA-DT_ENST00000435560.1_FIVE_PRIME_FLANK[14]	[48]	[49]	[50]	[51]	[52]	[53]	[54]	[55]	[56]	[57]	[58]	[59]	[60]	[61]	[62]	[63]	[64]	[65]	[66]	[67]	[68]	[69]	[70]	[71]	[72]	[73]	[74]	[75]	[76]	[77]	[78]	[79]	[80]	[81]	[82]	[83]	[84]	[85]	[86]	[87]	[88]	[89]	[90]	[91]	[92]	[93]	[94]	[95]	[96]	[97]	[98]	[99]	[100]	[101]	[102]	[103]; 	MAF (Other_Transcripts): 	[0]	[1]	[2]	[3]	[4]	[5]	[6]	[7]	[8]	[9]	[10]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK|PIK3CA-DT_ENST00000435560.1_LINCRNA[11]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK|PIK3CA-DT_ENST00000435560.1_LINCRNA[12]	PIK3CA_ENST00000643187.1_FIVE_PRIME_FLANK|PIK3CA-DT_ENST00000435560.1_LINCRNA[13]	PIK3CA_ENST00000643187.1_INTRON|PIK3CA-DT_ENST00000435560.1_FIVE_PRIME_FLANK[14]	[48]	[49]	[50]	[51]	[52]	[53]	[54]	[55]	[56]	[57]	[58]	[59]	[60]	[61]	[62]	[63]	[64]	[65]	[66]	[67]	[68]	[69]	[70]	[71]	[72]	[73]	[74]	[75]	[76]	[77]	[78]	[79]	[80]	[81]	[82]	[83]	[84]	[85]	[86]	[87]	[88]	[89]	[90]	[91]	[92]	[93]	[94]	[95]	[96]	[97]	[98]	[99]	[100]	[101]	[102]	[103]; ----; ```. Its unclear what is the most correct output ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9013:95,integrat,integration,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9013,1,['integrat'],['integration']
Integrability,"Why did you switch from bash? Using Python adds another runtime dependency, which will likely increase the number of support tickets. Ideally the script would be fairly dumb and pass through its arguments, so there shouldn't be a lot of complexity for bash to handle. I think that the settings in `SparkContextFactory#CMDLINE_ATTRIBUTES` should be removed since they can't be overridden as it stands. If they are specified in the launcher script only (as they are with this PR) then they can be overridden by adding a `--conf` argument to the Spark args - this works since the last conf value wins. I would leave `spark.serializer` and `spark.kryo.registrator` in `SparkContextFactory#CMDLINE_ATTRIBUTES` since they are required for correctness, but remove all the others. For example, it's certainly conceivable that `spark.driver.userClassPathFirst`, which we've talked about before as always being required, may have to be overridden for certain versions of Spark.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1211#issuecomment-161959953:64,depend,dependency,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1211#issuecomment-161959953,1,['depend'],['dependency']
Integrability,Will do (for all points). As an FYI: here is the main doc page for this feature (it's not what I used though); https://cloud.google.com/dataproc/cluster-web-interfaces,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/975#issuecomment-148465549:157,interface,interfaces,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/975#issuecomment-148465549,1,['interface'],['interfaces']
Integrability,Will do. Most of the work is done. I need to add unit and integration tests to make sure any hidden diploid assumptions are uncovered.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1382#issuecomment-201858023:58,integrat,integration,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1382#issuecomment-201858023,1,['integrat'],['integration']
Integrability,"Will write integration test for breakpoint finder next time. It's too much in flux at the moment to make this a wise investment of time, IMO.; And you're certainly correct that the unit testing is, at best, barely adequate. I'm pleading for the mercy of the court. This code will be almost completely rewritten very soon. I just want to get us (the SV team) caught up with the mainstream before plunging ahead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1435#issuecomment-182123420:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1435#issuecomment-182123420,1,['integrat'],['integration']
Integrability,"With GATKv4.0.0.0, when I try to run GenomicsDBimport, it crashes and gives this error message:. > 19:29:01.249 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/gatk/4.0.0.0/gatk-package-4.0.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 19:29:01.391 INFO GenomicsDBImport - ------------------------------------------------------------; 19:29:01.391 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.0.0.0; 19:29:01.391 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:29:01.391 INFO GenomicsDBImport - Executing as gowens@cdr619.int.cedar.computecanada.ca on Linux v3.10.0-693.5.2.el7.x86_64 amd64; 19:29:01.391 INFO GenomicsDBImport - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 19:29:01.392 INFO GenomicsDBImport - Start Date/Time: January 10, 2018 7:29:01 PST PM; 19:29:01.392 INFO GenomicsDBImport - ------------------------------------------------------------; 19:29:01.392 INFO GenomicsDBImport - ------------------------------------------------------------; 19:29:01.392 INFO GenomicsDBImport - HTSJDK Version: 2.13.2; 19:29:01.392 INFO GenomicsDBImport - Picard Version: 2.17.2; 19:29:01.392 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 19:29:01.392 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:29:01.392 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:29:01.392 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:29:01.393 INFO GenomicsDBImport - Deflater: IntelDeflater; 19:29:01.393 INFO GenomicsDBImport - Inflater: IntelInflater; 19:29:01.393 INFO GenomicsDBImport - GCS max retries/reopens: 20; 19:29:01.393 INFO GenomicsDBImport - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 19:29:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4124:87,message,message,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124,1,['message'],['message']
Integrability,"With the GATK gCNV having great performance results on the first round of evaluations it is ready to be used to call on ExAC. The following things need to be done first:. - Set up gCNV workflow to run on SGE (since exome samples are stored on prem). - Decide on target filtering strategy. . - Decide on the number of samples to use to learn the model (PoN). - Get some truth data to do QC, for example CNV calls from Genome STRiP on matched genome samples in gnomAD. - Design an interval list for samples in ExAC that do not mention one in their metadata. One possible solution could be to use cluster assignment of a sample to choose the interval list pertaining to that cluster. - (Optional) Consider importing list of common CNV regions into gCNV. To make job of gCNV inference easier we could use the list of common CNV regions that was obtained from Genome STRiP calls. To start @ldgauthier suggested using samples sequenced using latest Illumina capture protocol (Standard_Exome_Sequencing_v4) to get the ball rolling",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4738:960,protocol,protocol,960,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4738,1,['protocol'],['protocol']
Integrability,"With the exception of the HMM package, all of our R dependencies are available through the conda R or bioconda channels; the HMM package is available only through a user's custom channel. However, the HMM package is only used to generate truth for testing the Java HMM code by @vruano (which is currently unused, but we thought was worth keeping around). I'm sure we could easily rewrite the tests to load the truth from a file. I think we should get rid of the install_R_packages.R script altogether and just roll all of these dependencies into the conda environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920:52,depend,dependencies,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920,2,['depend'],['dependencies']
Integrability,With this new version I'm able to make it fail again; I opened a million channels to read the same file (across 1k threads) and got the error below. Yes I know a million parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:772,protocol,protocol,772,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156,3,['protocol'],['protocol']
Integrability,With updated command:. > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb-0.8.1-proto-3.0.0-beta-1+uuid-static-jar-with-dependencies.jar libtiledbgenomicsdb.so; > + jar xf genomicsdb-0.8.1-proto-3.0.0-beta-1+uuid-static-jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: warning: you do not have execution permission for `./libtiledbgenomicsdb.so'; > linux-vdso.so.1 (0x00007ffca79df000); > libpthread.so.0 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libpthread.so.0 (0x00007f146cb0c000); > libz.so.1 => not found; > libuuid.so.1 => not found; > librt.so.1 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/librt.so.1 (0x00007f146c902000); > libm.so.6 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libm.so.6 (0x00007f146c5fd000); > libc.so.6 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libc.so.6 (0x00007f146c25f000); > /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib64/ld-linux-x86-64.so.2 (0x000055ddfd95d000); > + md5sum libtiledbgenomicsdb.so; > 83007be5ce8b0c832b539b21b6c0d68d libtiledbgenomicsdb.so,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357064392:323,depend,dependencies,323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357064392,2,['depend'],['dependencies']
Integrability,With which frequency will you make point-releases? I'm afraid that incompatibilities will make me stick to an unreleased GATK4 dependency!. I am preparing a PR at this moment to try to get it in!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356297676:127,depend,dependency,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356297676,1,['depend'],['dependency']
Integrability,"Without the curl command, gcloud build failed with this error message: The command '/bin/sh -c apt-get --assume-yes install git-lfs' returned a non-zero code: 100",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6842#issuecomment-696904831:62,message,message,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6842#issuecomment-696904831,1,['message'],['message']
Integrability,Work is split into two commits:. - Removed undocumented mid-p correction to p-values in exact test of Hardy-Weinberg equilibrium and updated corresponding unit tests.; - Updated expected ExcessHet values in integration test resources and added an update toggle to GnarlyGenotyperIntegrationTest. Various scout cleanups as well. We now report the same value as ExcHet in bcftools. Note that previous values of 3.0103 (corresponding to mid-p values of 0.5) will now be 0.0000. See discussion below and in linked issue for additional details. Closes #7392.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394:207,integrat,integration,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394,1,['integrat'],['integration']
Integrability,"Work with project maintainers and stakeholders to create a roadmap document for the next generation of the HTSJDK file-parsing library, and obtain buy-in from all stakeholders. From our point of view, should address major pain points for GATK:. * NIO support everywhere; * Interfaces for all data types; * Easily extensible/pluggable, easy to add parsers for new versions of our formats (such as the still-unsupported VCF 4.3 and BCF 2.2); * Fix dumb design decisions that are killing GATK performance (such as always slurping tabix indices into memory)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4340:273,Interface,Interfaces,273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340,1,['Interface'],['Interfaces']
Integrability,Would be very helpful for projects like htsjdk that can't have a direct dependency on `google-cloud-java`!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2486:72,depend,dependency,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2486,1,['depend'],['dependency']
Integrability,"Would it be helpful to discuss this in person? Filter behavior is an important design decision and I'm not sure I have a good handle on the current state + context. On Mon, Feb 23, 2015 at 9:22 PM, Louis Bergelson notifications@github.com wrote: Some always throw, some always filter, some depend on the arguments you; pass to the filter constructor.; On Feb 23, 2015 9:19 PM, ""Geraldine Van der Auwera"" <; notifications@github.com> wrote:. > Ah -- maybe I'm mistaken. Or can it be a difference in how they're; > applied/invoked?; > ; > Maybe there's some inconsistency in behavior. Would be nice to iron this; > all out.; > ; > On Mon, Feb 23, 2015 at 5:17 PM, Louis Bergelson <notifications@github.com; > ; > > wrote:; > > ; > > I'm pretty sure they all do... or at least all can depending on how you; > > configure your MalformedReadFilter.; > > ; > > example:; > > ; > > private static boolean checkHasReadGroup(final SAMRecord read) {; > > if ( read.getReadGroup() == null ) {; > > // there are 2 possibilities: either the RG tag is missing or it is not; > > defined in the header; > > final String rgID =; > > (String)read.getAttribute(SAMTagUtil.getSingleton().RG);; > > if ( rgID == null ); > > throw new UserException.ReadMissingReadGroup(read);; > > throw new UserException.ReadHasUndefinedReadGroup(read, rgID);; > > }; > > return true;; > > }; > > ; > > —; > > Reply to this email directly or view it on GitHub; > > <; > > https://github.com/broadinstitute/hellbender/issues/193#issuecomment-75649333; > > ; > > .; > ; > ## ; > ; > Geraldine A. Van der Auwera, Ph.D.; > Bioinformatics Scientist II; > GATK Support & Outreach; > Broad Institute; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/hellbender/issues/193#issuecomment-75686467; > . —Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/193#issuecomment-76679907:290,depend,depend,290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/193#issuecomment-76679907,2,['depend'],"['depend', 'depending']"
Integrability,Would it be possible to update the `gatktool` bioconda repo to ensure that all python dependencies are well installed to run CNNScoreVariants ? It would be really helpful and easier to manage a GATK conda environment.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1735565877:86,depend,dependencies,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1735565877,1,['depend'],['dependencies']
Integrability,"Wow, thanks for the detailed comments so far, @davidbenjamin! But perhaps let's quickly chat before you go any further?. There are a lot of things you commented on---temporary integration tests using local files, lots of code/arguments/etc. intentionally copied verbatim over from VQSR/tranches, and entire tools (the ""monolithic"" GMMVariantTrain and ScikitLearnVariantTrain)---that are rather in flux or will be scrapped/cleaned up shortly. That said, the comments on the code inherited from VQSR will certainly be useful in this process!. But it might save you some time if we could chat so I can give you a rough orientation and perhaps point out where the vestigial VQSR code remains. I think focusing discussion on the high level design of the tools that are likely to stay would also be most useful at this stage. Feel free to throw something on my calendar!. In the end, I think we will probably just retain the BGMM backend + the versions of the tools in the ""scalable"" package. I left the ""monolithic"" GMMVariantTrain and ScikitLearnVariantTrain tools in this branch so I could do one round of tieout. That tieout came out OK, so I think we'll abandon the monolithic tools, along with all the associated code outside of the scalable package. If it helps, I can go ahead and remove that stuff from this draft PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1029393942:176,integrat,integration,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1029393942,1,['integrat'],['integration']
Integrability,Wrap Reads within object containing commonly-needed API methods for reads; Convert between Reads and SAMRecords (for legacy code),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/283:0,Wrap,Wrap,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/283,1,['Wrap'],['Wrap']
Integrability,Wrap file-not-found SAMExceptions and other user errors from htsjdk in UserExceptions,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/86:0,Wrap,Wrap,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/86,1,['Wrap'],['Wrap']
Integrability,Wrapper around VC object to access SVContext specific annotations.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3476:0,Wrap,Wrapper,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3476,1,['Wrap'],['Wrapper']
Integrability,Wrapper for Read,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/283:0,Wrap,Wrapper,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/283,1,['Wrap'],['Wrapper']
Integrability,"Wrapping a prefetcher into another would be an error, check; for it and report it. The commit also includes a test. Also shut down the executor when the channel is closed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2643:0,Wrap,Wrapping,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2643,1,['Wrap'],['Wrapping']
Integrability,Write a stub end-to-end integration test for the ReadsPreprocessingPipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/761:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/761,1,['integrat'],['integration']
Integrability,Write a tribble codec for parsing Picard interval_list format (+ integration tests in GATK),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5788:65,integrat,integration,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5788,1,['integrat'],['integration']
Integrability,Write basic integration tests for CRAM support using PrintReads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/675:12,integrat,integration,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/675,1,['integrat'],['integration']
Integrability,Write common interfaces for the different kinds of transforms we identify in the dataflow read pre-processing pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/463:13,interface,interfaces,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/463,1,['interface'],['interfaces']
Integrability,Write integration test for GermlineCNVCaller for single sample calling,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3002:6,integrat,integration,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3002,1,['integrat'],['integration']
Integrability,Yeah - the integration tests cover this case. I had some trouble adding unit tests for this because of #5356 .,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5357#issuecomment-432873687:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5357#issuecomment-432873687,1,['integrat'],['integration']
Integrability,"Yeah, I don't like these new interface methods -- they make `GATKRead` significantly worse. We should cache `isUnmapped`, etc. in the adapter to accomplish the same thing, as @lbergelson suggests. Not that hard, and we can just unconditionally invalidate the cached values (using `Boolean` fields set to null) whenever the read is mutated in any way in order to simplify the logic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235102282:29,interface,interface,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235102282,2,"['adapter', 'interface']","['adapter', 'interface']"
Integrability,"Yeah, being able to print multiple lines of errors at once is nice for the users. Most tools don't do that though. The ones that do can wrap the multiple errors into a single exception with a multiline message. Will changing the method signature and moving the call up into the try block fix the problem your having?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2226#issuecomment-255848690:136,wrap,wrap,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2226#issuecomment-255848690,2,"['message', 'wrap']","['message', 'wrap']"
Integrability,"Yeah, it's definitely confusing, we should look into changing it for the future. We definitely do recommend using our launcher script though, which handles it for you. . It was tricky to enable both spark-submit and standalone running spark through the jar without having a way to inject the spark master as a command line argument, but there's probably a better way of handling it then the way we do. . I'm keeping this issue open, but since it's a pretty easy workaround I don't know when we'll be able to fix it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2718#issuecomment-302179455:281,inject,inject,281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2718#issuecomment-302179455,1,['inject'],['inject']
Integrability,"Yep, I created https://github.com/broadinstitute/gatk/issues/2715 this morning to ask Intel to add a helpful error message in this case. Glad to hear that you can work around the issue for now by using `-V`!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2713#issuecomment-301540412:115,message,message,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2713#issuecomment-301540412,1,['message'],['message']
Integrability,"Yep, antares58 is me. Elizabeth Lee. Sent with [Proton Mail](https://proton.me/) secure email. ------- Original Message -------; On Tuesday, November 22nd, 2022 at 7:14 AM, Anthony Dias-Ciarla ***@***.***> wrote:. > Hi ***@***.***(https://github.com/antares58) ,; >; > We created this ticket for one of our users on the GATK forum, [Elizabeth Lee](https://gatk.broadinstitute.org/hc/en-us/community/posts/9761457082907-JointGenotyping-ImportGvcfs-terminates-without-an-active-exception).; >; > In the interest of clarity, are you responding on her behalf? Are you the cluster admin? If you are not related to the original user, we will need to create a separate ticket.; >; > Thank you in advance for any clarity that you can provide!; >; > Best,; > Anthony; >; > —; > Reply to this email directly, [view it on GitHub](https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1323834544), or [unsubscribe](https://github.com/notifications/unsubscribe-auth/AWNKFIEGLOGOYBSTJEDLUF3WJTPNBANCNFSM6AAAAAARQLF3GE).; > You are receiving this because you were mentioned.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1336529947:112,Message,Message,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1336529947,2,['Message'],['Message']
Integrability,"Yep, sorry. Just learned that as you were closing it. On Tue, Aug 14, 2018 at 11:51 AM, Louis Bergelson <notifications@github.com>; wrote:. > It's useful to put something like fixes #5104 in the commit message. That; > way it automatically closes the issue and shows a link from the PR to the; > Issue.; >; > —; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412920923>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AoMkWAqeYbmnX12i6s9k_5bEWy149CPFks5uQvITgaJpZM4UyozK>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412923593:202,message,message,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412923593,1,['message'],['message']
Integrability,"Yep, that will definitely cause a crash - variable length fields need a length value stored while fixed length fields don't. I can add checks for this scenario in GenomicsDB. Please let me know if the following make sense:; Header says that the field F is a fixed length field with length = N. In the data section, if; * length(F) < N - pad with missing values, no error message, continue; * length(F) > N - error, throw exception and print descriptive error message",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407501684:371,message,message,371,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407501684,2,['message'],['message']
Integrability,"Yep, the new jar fetches and prints the TileDB error message",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4753#issuecomment-387935793:53,message,message,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4753#issuecomment-387935793,1,['message'],['message']
Integrability,"Yes - trying to run the integration test so that I can update the outputs, but keep getting transient docker pull errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8655#issuecomment-1898811668:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8655#issuecomment-1898811668,1,['integrat'],['integration']
Integrability,"Yes PathSeq has generally been used with longer reads in the past and also with BWA. I suspect with the shorter reads, novel splice sites are getting missed by PathSeq. You could turn down the match threshold to 16 (half the read length) to help this further, or even hard-filter any aligned read, but you do risk losing some microbial reads at this length. . You're also right that in your case, using the mate information would be useful, but this would not be appropriate, for example, when there are host-pathogen chimeras, such as virus integration events.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6687#issuecomment-652638341:542,integrat,integration,542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6687#issuecomment-652638341,1,['integrat'],['integration']
Integrability,Yes please! I'd also find this incredibly useful. @lbergelson any thoughts on how hard it would be to generate a separate build artifact for the local reassembly code that didn't have too many dependencies?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3286#issuecomment-340717669:193,depend,dependencies,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3286#issuecomment-340717669,1,['depend'],['dependencies']
Integrability,"Yes! I am so relieved to have all of this python dependency wrangling done. Perhaps not the sexiest work, but still very important -- thank you @asmirnov239 !",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8094#issuecomment-1322447041:49,depend,dependency,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8094#issuecomment-1322447041,1,['depend'],['dependency']
Integrability,"Yes, Hadoop-BAM uses the NIO API to do file merging, whereas in GATK we were using the Hadoop APIs (and therefore the GCS<->HDFS adapter) to do it. It looks like there are a couple of things needed in GCS-NIO to use the NIO API for this.; 1. https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1450 so that we don't have to special-case `gs` URIs to remove everything except the scheme and host when looking up the filesystem (see https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L40); 2. https://github.com/GoogleCloudPlatform/google-cloud-java/issues/813 to support path matching (https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L90). There may be more, as I stopped there. The best way forward is probably to go back to the old code in GATK while the deficiencies in GCS-NIO are fixed and then released. The stacktrace I got for 1 was:. ```; java.lang.IllegalArgumentException: GCS FileSystem URIs mustn't have: port, userinfo, path, query, or fragment: gs://gatk-demo-tom/TEST/markdups.parts/_SUCCESS; 	at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:192); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:83); 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:336); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:54); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); ```. And for 2:. ```; java.lang.UnsupportedOperationException; 	at com.google.cloud.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265132050:129,adapter,adapter,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265132050,1,['adapter'],['adapter']
Integrability,"Yes, I messed up the commit message and wrote that it ""resolves issue 5433"" instead of ""resolves issue #5433"". Without the hash I guess github assumes it's stupid meatbag language and ignores it. The bug should be fixed so I'm closing the issue manually. Sorry to leave this hanging the last month, and thanks for pointing it out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5433#issuecomment-449899779:28,message,message,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5433#issuecomment-449899779,1,['message'],['message']
Integrability,"Yes, I ran option 3, 5 times (using the older version not latest master). Of those 5, 3 failed. One of the failures was: `java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: All reopens failed`. The other two were both the non-negative error message:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr6:1+ --use_jdk_deflater --use_jdk_inflater; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.4ZS1WV; [July 24, 2017 5:48:10 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr6:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:302,message,message,302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472,1,['message'],['message']
Integrability,"Yes, I think it is what we want. It would be consistent with the GNU standards. https://www.gnu.org/prep/standards/html_node/Command_002dLine-Interfaces.html; ""It is usually a good idea for file names given as ordinary arguments to be input files only; any output files would be specified using options (preferably ‘-o’ or ‘--output’). Even if you allow an output file name as an ordinary argument for compatibility, try to provide an option as another way to specify it. This will lead to more consistency among GNU utilities, and fewer idiosyncrasies for users to remember."". By ""ordinary arguments"" they mean what you name ""standard arguments"".",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/141#issuecomment-72783597:142,Interface,Interfaces,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/141#issuecomment-72783597,1,['Interface'],['Interfaces']
Integrability,"Yes, OpenMP is needed to compile **and** run this code. The `libVectorLoglessPairHMM` shared library depends on an OpenMP shared library. ```; > ldd ./build/classes/main/lib/libVectorLoglessPairHMM.so; linux-vdso.so.1 => (0x00007ffc9b2b3000); libstdc++.so.6 => /opt/gcc-4.8.2/lib64/libstdc++.so.6 (0x00007fe67bacf000); libm.so.6 => /lib64/libm.so.6 (0x00007fe67b831000); --> libgomp.so.1 => /opt/gcc-4.8.2/lib64/libgomp.so.1 (0x00007fe67b623000); libpthread.so.0 => /lib64/libpthread.so.0 (0x00007fe67b405000); libc.so.6 => /lib64/libc.so.6 (0x00007fe67b071000); /lib64/ld-linux-x86-64.so.2 (0x000000378cc00000); libgcc_s.so.1 => /opt/gcc-4.8.2/lib64/libgcc_s.so.1 (0x00007fe67ae5b000); librt.so.1 => /lib64/librt.so.1 (0x00007fe67ac52000); ```. I'll look into statically linking OpenMP as an option. Another option would be a clean room source code implementation of the thread pool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1813#issuecomment-218783667:101,depend,depends,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1813#issuecomment-218783667,1,['depend'],['depends']
Integrability,"Yes, definitely pin h5py in this case. Not 100% sure what form the alert should take or what manual interventions should be required when it’s triggered, but perhaps we can discuss at the next dependency meeting.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6955#issuecomment-725021274:193,depend,dependency,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6955#issuecomment-725021274,1,['depend'],['dependency']
Integrability,"Yes, if you have Version Control integration enabled, you can select the branch, and then any commit, or group of commits, in order to see the diffs. So once its read, I'll be able to look at just the diffs between the initial GATK3 commit and your commit(s) right from within IntelliJ.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-416341795:33,integrat,integration,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-416341795,1,['integrat'],['integration']
Integrability,"Yes, let me know if they should go in this repo or the wrapper repo.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-318243071:55,wrap,wrapper,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-318243071,1,['wrap'],['wrapper']
Integrability,"Yes, of course :) It can be a challenge to get good error messages out of Spark, but perhaps we could have some kind of up-front check in GATK4 for a Spark version mismatch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290761293:58,message,messages,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290761293,1,['message'],['messages']
Integrability,"Yes, thank you for jogging my memory @bbimber. @davidbenjamin adding something to that extend in the BadArgumentException message would be helpful.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-558740872:122,message,message,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-558740872,1,['message'],['message']
Integrability,"Yes, that seems to be working as intended. You'll see that in your first log, the following lines indicate that convergence has been reached after 2 iterations:. ````; 09:40:44.924 INFO MultidimensionalModeller - Smoothing iteration: 2; 09:40:44.924 INFO MultidimensionalModeller - Number of segments before smoothing iteration: 398; 09:40:44.924 INFO MultidimensionalModeller - Number of segments after smoothing iteration: 398; ````. Therefore, when you set N >= 3, the behavior is the same as when N = 2. In your second log, only one iteration goes by before we refit again. This refit yields posteriors that are sufficiently different from the approximation used when no refitting is performed so that additional smoothing needs to be performed before convergence. You'll see that in the second case, we end up with fewer segments. Whether or not this smoother result (which takes longer to arrive at, since refitting is expensive) is desired will depend on the goals of the analysis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4683#issuecomment-382807646:952,depend,depend,952,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4683#issuecomment-382807646,1,['depend'],['depend']
Integrability,"Yes, that's the error message. You should see [this part of the GenomicsDB](https://github.com/Intel-HLS/GenomicsDB/blob/stack_ovf_fix/src/main/cpp/src/genomicsdb/variant_storage_manager.cc#L540) code that retries the function when an error is detected. So, you don't need to be concerned by those error messages. They are annoying though and I will disable them from being printed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407440149:22,message,message,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407440149,2,['message'],"['message', 'messages']"
Integrability,"Yes, the same error message was reported in https://github.com/broadinstitute/gatk/issues/5094. It was supposedly fixed by a patch to the Pipelines API. GCS-NIO has support for a list of retriable codes in the `CloudStorageConfiguration`, see there:. https://github.com/googleapis/google-cloud-java/blob/master/google-cloud-clients/google-cloud-contrib/google-cloud-nio/src/main/java/com/google/cloud/storage/contrib/nio/CloudStorageConfiguration.java. I think GATK calls this somewhere. It certainly should.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548517465:20,message,message,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548517465,1,['message'],['message']
Integrability,"Yes, they did seem go away when I ran with a block size of 10m vs 1g. It would be nice to get a memory-related error message here rather than just having the executors be killed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1491#issuecomment-188327272:117,message,message,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1491#issuecomment-188327272,1,['message'],['message']
Integrability,"Yes, this is the tool I used. I think I documented this in a commit message where I added the 2bit file into the repo.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1277#issuecomment-164057004:68,message,message,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1277#issuecomment-164057004,1,['message'],['message']
Integrability,"Yes, this issue is not yet fully resolved. We intend to make additional progress in reducing vulnerabilities in our dependencies in the next GATK release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1546114646:116,depend,dependencies,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1546114646,1,['depend'],['dependencies']
Integrability,"Yes, this looks very similar to what I'm seeing. The VariantSparkSinkUnitTests run fine on their own. When the whole test suite is run though, an OOM error is thrown when VariantSparkSinkUnitTests run:. java.lang.OutOfMemoryError: GC overhead limit exceeded; at org.gradle.internal.remote.internal.hub.MethodInvocationSerializer$MethodInvocationReader.read(MethodInvocationSerializer.java:120); at org.gradle.internal.remote.internal.hub.MethodInvocationSerializer$MethodInvocationReader.read(MethodInvocationSerializer.java:99); at org.gradle.internal.serialize.kryo.TypeSafeSerializer$1.read(TypeSafeSerializer.java:34); at org.gradle.internal.remote.internal.hub.InterHubMessageSerializer$MessageReader.read(InterHubMessageSerializer.java:66); at org.gradle.internal.remote.internal.hub.InterHubMessageSerializer$MessageReader.read(InterHubMessageSerializer.java:52); at org.gradle.internal.remote.internal.inet.SocketConnection.receive(SocketConnection.java:78); at org.gradle.internal.remote.internal.hub.MessageHub$ConnectionReceive.run(MessageHub.java:250); at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 13:37 DEBUG: [kryo] Read object reference 986: reference=GRCh37.3; Test: Test method testWritingToFileURL[0](/Users/cnorman/projects/gatk/src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf, .vcf)(org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSinkUnitTest) produced standard out/err: 13:37 DEBUG: [kryo] Read object reference 203: contig=<ID=20,length=63025520,assembly=b37>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-287857575:692,Message,MessageReader,692,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-287857575,4,['Message'],"['MessageHub', 'MessageReader']"
Integrability,"Yes, we can pretty easily detect this exit code and generate an error message suggesting it might be an OOM issue. I'll make a PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6362#issuecomment-572769179:70,message,message,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6362#issuecomment-572769179,1,['message'],['message']
Integrability,"Yes, you're reading it exactly right: on local files the code's currently ignoring the asked intervals. So neither is the complete solution that we need. We could take my code and put together a ""BAM reader for all intervals"" that'd work locally or on the cloud, and then either call ReadsSource or that one depending on whether we want to specify intervals?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/556#issuecomment-111215514:308,depend,depending,308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/556#issuecomment-111215514,1,['depend'],['depending']
Integrability,Yes. We desperately need to improve error messages for hadoop bam.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1417#issuecomment-175781499:42,message,messages,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1417#issuecomment-175781499,1,['message'],['messages']
Integrability,"You mean you saw an **informative** error message rather than an **uninformative** one, I assume? :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3745#issuecomment-364168059:42,message,message,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3745#issuecomment-364168059,1,['message'],['message']
Integrability,"You're totally right about the assembly failures. As we talked about in person yesterday, I worry about biasing the; likelihoods when genotyping positions near homVar variants. For the; record, the conclusion of that conversation was to inject the GGA allele; into the five best assembled haplotypes, though I'm open to something less; heuristic than ""best five"" if anyone has a good idea. (I don't want to; double the number of haplotypes by adding the GGA allele into all of them). On Thu, Apr 4, 2019 at 2:19 PM David Benjamin <notifications@github.com>; wrote:. > Update: I wrote an integration test in my branch that runs M2 with; > --kmer-size 1 --dont-increase-kmer-sizes-for-cycles. It still calls the; > given alleles, whereas in master it does not.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdF1sCpAlqKNa6S_qlL_ypNX_A0eGks5vdkI7gaJpZM4cbxVV>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626:237,inject,inject,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626,2,"['inject', 'integrat']","['inject', 'integration']"
Integrability,You're using an old version of ojAlgo. I upgraded it for you. There has been improvements to the SVD implementations. (Significant improvements to some users.). Also added a dependency to ojalgo-commons-math3 which gives you wrapper classes to convert back and forth between ojAlgo and Commons Math matrix classes. You no longer need to copy the resulting matrices.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3970:174,depend,dependency,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3970,2,"['depend', 'wrap']","['dependency', 'wrapper']"
Integrability,"Your solution doesn't address your third listed drawback to the current; approach, though I'm not sure there's any way to do that that wouldn't; require a pretty dramatic change. It's not obvious to me why we wanted the given alleles in the graph; originally. Maybe the use case was variants from UG that we didn't; necessarily believe were aligned properly?. I don't have any objections, but I'd feel better if we had a better guess; at what the original method was trying to do. On Wed, Apr 3, 2019 at 9:56 PM David Benjamin <notifications@github.com>; wrote:. > In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them; > into the ref haplotype, then threading these constructed haplotypes into; > the assembly graph with a large edge weight. There are several drawbacks to; > this approach:; >; > - The strange edge weights interfere with the AdaptiveChainPruner.; > - The large edge weights may not be large enough to avoid pruning when; > depth is extremely high.; > - The alleles may be lost if assembly fails.; > - If the alleles actually exist but are in phase with another variant; > we end up putting an enormous amount of weight on a false haplotype.; >; > We can get around these issue with the following method:; >; > - assemble haplotypes without regard to the force-called alleles.; > - if an allele is present in these haplotypes, do nothing further.; > - otherwise, add a haplotype in which the allele is injected into the; > reference haplotype.; >; > @LeeTL1220 <https://github.com/LeeTL1220> I prototyped this and it seems; > to resolve the missed forced alleles that Ziao found.; >; > @ldgauthier <https://github.com/ldgauthier> Can you think of any; > objections to making this change in HaplotypeCaller?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMcaTJg47gn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767:622,inject,injecting,622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767,1,['inject'],['injecting']
Integrability,"Yup, as you might recall from some discussions with @bhanugandham and @mwalker174, getting automated pipeline-level CNV evaluations up and running was highest on my list before I handed over the role and went on paternity leave. I think these tests would be more useful than unit/integration tests for correctness, but they would almost certainly have to run on CARROT. That said, the current level of unit/integration test coverage is a bit different from that for the somatic tools, because 1) it's difficult to run gCNV in any useful way on Travis infrastructure, and 2) we hadn't decided on a framework/convention for python unit tests at the time the production code went in (although I think @ldgauthier has added some python unit tests by now). So we currently only have plumbing WDL/integration tests on very small data for gCNV---and these only test that the tools run, not for correctness. For somatic CNV, we have unit tests for correctness on small simulated data (e.g., for things like segmentation and modeling classes), but integration tests don't cover correctness (and it would be pretty redundant to use the same simulated data for integration, so I'd rather put effort towards pipeline-level tests on real data). It might be good for you and @mwalker174 to review the current level of testing coverage and understand where things need to be shored up---happy to discuss more.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7261#issuecomment-859563124:280,integrat,integration,280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7261#issuecomment-859563124,5,['integrat'],['integration']
Integrability,[10 sample run](https://app.terra.bio/#workspaces/gvs-dev/GVS_190k_Exomes/job_history/10d083c7-2c20-4339-aa2b-70945056de44); [5k sample run](https://app.terra.bio/#workspaces/gvs-dev/GVS_190k_Exomes/job_history/60325b52-7040-492b-82e1-23a58850fb59); [20k sample run](https://app.terra.bio/#workspaces/gvs-dev/GVS_190k_Exomes/job_history/7fee1590-d00c-4038-a575-fd06a9edba1a); [50k sample run](https://app.terra.bio/#workspaces/gvs-dev/GVS_190k_Exomes/job_history/2efb51a2-105a-4f62-a1fe-26b7350706ed); [100k sample run](https://app.terra.bio/#workspaces/gvs-dev/GVS_190k_Exomes/job_history/dba1e793-51e4-47cc-9016-c478628e7252); [integration run](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/19c865ab-69bc-45a3-a897-ff4e5f3d2a53),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8615:630,integrat,integration,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8615,1,['integrat'],['integration']
Integrability,"[Apache Thrift](https://github.com/apache/thrift) looks like a plausible alternative to py4j. It might be possible to automate the generation of thrift wrappers. But, at the heart of any of these systems is essentially an RPC mechanism, not a binary interface, and ill suited to high-frequency function calls.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4938#issuecomment-1304217213:152,wrap,wrappers,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4938#issuecomment-1304217213,2,"['interface', 'wrap']","['interface', 'wrappers']"
Integrability,"[Broadcast data presentation.pdf](https://github.com/broadinstitute/gatk/files/369684/Broadcast.data.presentation.pdf). Here is a link to the presentation I gave on the broadcasting profiling data that I collected. The big takeaways are:; - Broadcasting is relatively time efficient and appears to scale linearly with filesize; - Reference broadcasting takes longer and is much more variable compared to the variants which get broadcast immediately before; - There doesn't seem to be any memory shared between executors for broadcast variables, making it very memory inefficient when there are many executors ; - The brodcast block size is best kept small, (in the order of 4-10MB) as it can explode the broadcast time to be very slow; - Having files in HDFS is significantly faster than using the GCS adapter for large file sizes",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1675#issuecomment-233396177:802,adapter,adapter,802,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1675#issuecomment-233396177,1,['adapter'],['adapter']
Integrability,"[For fun, our latest question related to Java 1.5 for Picard was in December!](http://sourceforge.net/p/samtools/mailman/message/33099984/)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9#issuecomment-66529683:121,message,message,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9#issuecomment-66529683,1,['message'],['message']
Integrability,[Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/5eb30da2-4afe-4f8e-ad72-e96ac647c588) is a passing Integration test (note - updated truth).; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/7ab3d8de-4325-4ca1-b507-1546f9b89986) is a run of GvsJointCalling using this code.; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/494b9661-b5d2-4d4e-8da7-8df84d52e162) is a run of GvsExtractCalset extracting from tables created by this code (with phasing fields in the prepare tables) ; [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/dddfefce-f4c7-49bf-aabb-d9b92720b809) is a run of GvsExtractCallset extracing from (OLD) tables created before this code (without phasing fields in the prepare tables).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8655:130,Integrat,Integration,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8655,1,['Integrat'],['Integration']
Integrability,[Integration run](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/dfeb564d-5b4d-4b6b-9ffd-88e618acf5e0) in progress,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8454:1,Integrat,Integration,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8454,1,['Integrat'],['Integration']
Integrability,"[log](https://freebsd.org/~yuri/gatk-4.6.0.0-tests-5.log). Examples of test failures from the above log:; ```; Running Test: Test method testRequirePythonEnvironment(org.broadinstitute.hellbender.utils.python.StreamingPythonExecutorIntegrationTest). Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.python.StreamingPythonExecutorIntegrationTest > testRequirePythonEnvironment FAILED; java.lang.NullPointerException: Cannot invoke ""Object.getClass()"" because the return value of ""java.lang.RuntimeException.getCause()"" is null; at org.broadinstitute.hellbender.utils.python.StreamingPythonExecutorIntegrationTest.testRequirePythonEnvironment(StreamingPythonExecutorIntegrationTest.java:34); ```. Error messages in another test case:; ```; src/main/java/org/broadinstitute/hellbender/tools/walkers/groundtruth/GroundTruthScorer.java:68: error: unmappable character (0xE2) for encoding US-ASCII; * <li>Score : A flow-based alignment score. Since the alignment is per-flow, in the case that there???s a cycle skip, the read and reference flow signals will not be aligned, and therefore the score will be inaccurate.</li>; ^; src/main/java/org/broadinstitute/hellbender/tools/walkers/groundtruth/GroundTruthScorer.java:68: error: unmappable character (0x80) for encoding US-ASCII; * <li>Score : A flow-based alignment score. Since the alignment is per-flow, in the case that there???s a cycle skip, the read and reference flow signals will not be aligned, and therefore the score will be inaccurate.</li>; ^; src/main/java/org/broadinstitute/hellbender/tools/walkers/groundtruth/GroundTruthScorer.java:68: error: unmappable character (0x99) for encoding US-ASCII; * <li>Score : A flow-based alignment score. Since the alignment is per-flow, in the case that there???s a cycle skip, the read and reference flow signals will not be aligned, and therefore the score will be inaccurate.</li>; ^; ```. This test is skipped without any apparent reason:; ```; Running Test: Test method loadIndex(o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8940:717,message,messages,717,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8940,1,['message'],['messages']
Integrability,] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=194510848; java.lang.IllegalArgumentException: Illegal base [] seen in the allele; 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:231); 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:374); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:181); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:664); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); 	at org.broadi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:5174,wrap,wrapAndCopyInto,5174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['wrap'],['wrapAndCopyInto']
Integrability,"_Is there any way to get it to use fewer partitions in a case like this where there are lots of intervals ?_; No - see the PR message https://github.com/broadinstitute/gatk/pull/4645#issue-180678162. The multi-interval support in GenomicsDBImport tool is purely for convenience. For scalability with a large number of intervals and samples, you should use multiple processes, each writing to a small (1?) number of intervals. **_Somewhat more concerning is that when with 8000 intervals, I see a different failure mode. First I see lots (thousands) of these messages:_**; The first set of messages are spurious debug messages - no error in reality. I'll provide a jar without these messages. The second set of messages are a result of too many file handles open per process - your system is limiting the number of file handles opened by a single process. Again, this goes back to the previous statement.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407228434:126,message,message,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407228434,6,['message'],"['message', 'messages']"
Integrability,"__ _ _(_)_ __ __ _ \ \ \ \; ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \; \\/ ___)| |_)| | | | | || (_| | ) ) ) ); ' |____| .__|_| |_|_| |_\__, | / / / /; =========|_|==============|___/=/_/_/_/; :: Spring Boot :: (v2.3.0.RELEASE). 2020-05-29 15:14:30.695 INFO 12904 --- [ main] com.luz.push.PushApplication : Starting PushApplication on DESKTOP-05L3FQL with PID 12904 (C:\project\push\target\classes started by Sweet in C:\project\push); 2020-05-29 15:14:30.712 INFO 12904 --- [ main] com.luz.push.PushApplication : No active profile set, falling back to default profiles: default; 2020-05-29 15:14:32.088 WARN 12904 --- [ main] o.m.s.mapper.ClassPathMapperScanner : No MyBatis mapper was found in '[com.luz.push]' package. Please check your configuration.; 2020-05-29 15:14:32.662 INFO 12904 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8282 (http); 2020-05-29 15:14:32.675 INFO 12904 --- [ main] o.a.coyote.http11.Http11NioProtocol : Initializing ProtocolHandler [""http-nio-8282""]; 2020-05-29 15:14:32.676 INFO 12904 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat]; 2020-05-29 15:14:32.677 INFO 12904 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.35]; 2020-05-29 15:14:32.802 INFO 12904 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext; 2020-05-29 15:14:32.802 INFO 12904 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 1944 ms; 2020-05-29 15:14:32.899 INFO 12904 --- [ main] com.luz.push.utils.GcmUtils : start init gcm server; 2020-05-29 15:14:33.029 WARN 12904 --- [ main] c.g.a.oauth2.ComputeEngineCredentials : Failed to detect whether we are running on Google Compute Engine. java.net.SocketException: Network is unreachable: connect; 	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method); 	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackP",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:11941,Protocol,ProtocolHandler,11941,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['Protocol'],['ProtocolHandler']
Integrability,"_data_structure.h:94:16: error: 'isinf' was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive]; if (isinf(small) == -1 || isinf(big) == -1); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:1:; /usr/local/Cellar/gcc/5.3.0/include/c++/5.3.0/cmath:853:5: note: 'template<class _Tp> typename __gnu_cxx::__enable_if<std::__is_arithmetic<_Tp>::__value, int>::__type std::isinf(_Tp)' declared here, later in the translation unit; isinf(_Tp __f); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:2:0:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:38: error: 'isinf' was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive]; if (isinf(small) == -1 || isinf(big) == -1); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:1:; /usr/local/Cellar/gcc/5.3.0/include/c++/5.3.0/cmath:853:5: note: 'template<class _Tp> typename __gnu_cxx::__enable_if<std::__is_arithmetic<_Tp>::__value, int>::__type std::isinf(_Tp)' declared here, later in the translation unit; isinf(_Tp __f); ^. In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/utils.h:4:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc:1:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h: In instantiation of 'static NUMBER ContextBase<NUMBER>::approximateLog10SumLog10(NUMBER, NUMBER) [with NUMBER = float]':; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:75:53: required ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343:8643,depend,dependent,8643,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343,1,['depend'],['dependent']
Integrability,"_data_structure.h:94:16: error: 'isinf' was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive]; if (isinf(small) == -1 || isinf(big) == -1); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:1:; /usr/local/Cellar/gcc/5.3.0/include/c++/5.3.0/cmath:853:5: note: 'template<class _Tp> typename __gnu_cxx::__enable_if<std::__is_arithmetic<_Tp>::__value, int>::__type std::isinf(_Tp)' declared here, later in the translation unit; isinf(_Tp __f); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:2:0:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:38: error: 'isinf' was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive]; if (isinf(small) == -1 || isinf(big) == -1); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:1:; /usr/local/Cellar/gcc/5.3.0/include/c++/5.3.0/cmath:853:5: note: 'template<class _Tp> typename __gnu_cxx::__enable_if<std::__is_arithmetic<_Tp>::__value, int>::__type std::isinf(_Tp)' declared here, later in the translation unit; isinf(_Tp __f); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:2:0:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h: In instantiation of 'static NUMBER ContextBase<NUMBER>::approximateLog10SumLog10(NUMBER, NUMBER) [with NUMBER = float]':; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:57:5: required from 'NUMBER compute_full_prob(testcase*, NUMBER*) [with NUMBER = float]'; /Users/louisb/Workspace/gatk/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343:6499,depend,dependent,6499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343,1,['depend'],['dependent']
Integrability,"`./gatk-launch BuildBamIndex -I src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram`. blows up with a bogus exception. ```; htsjdk.samtools.SAMException: Input file must be bam file, not sam file.; at org.broadinstitute.hellbender.tools.picard.sam.BuildBamIndex.doWork(BuildBamIndex.java:101); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:61); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); ```. desired outcome: message that using files that are not in BAM format is not supported. No exception!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1783:782,message,message,782,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1783,1,['message'],['message']
Integrability,`./gatk-launch CountVariants --variant some.vcf -L 21`. i get. `A USER ERROR has occurred: We currently require a sequence dictionary (from a reference or source of reads) to process intervals. This restriction may be removed in the future.`. the message should tell me what to do. References to the future are less useful than help in what argument to pass,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1305:247,message,message,247,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1305,1,['message'],['message']
Integrability,"`GATKReadFilterPluginDescriptor.getAllInstances()` returns only the filters provided by the user, but I expect it to return the default ones. I know that they are added to the merged filter in `getMergedReadFilter`, but this does not allow to retrieve it as a list. In addition, there is no way to access the default filters provided. I suggest to move the code to merge into the same list the default and the user-provided filters to `getAllInstances()` and use that list in the `getMergedReadFilter`. ## EDITED:; The contract of `getAllInstances()` says that it should not include the default ones, so I propose a new specific method for retrieval.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2362:519,contract,contract,519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2362,1,['contract'],['contract']
Integrability,"`IntegrationTestSpec` currently ignores leading/trailing whitespace by default when doing its comparison against expected outputs. This is problematic given that whitespace can include things like field delimiters, leading to bugs like the one fixed in https://github.com/broadinstitute/gatk/pull/7559. We should change the default to *not* ignore leading/trailing whitespace. Tests that have a legitimate reason for ignoring it can then explicitly opt-in by calling `setTrimWhiteSpace()`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7560:1,Integrat,IntegrationTestSpec,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7560,1,['Integrat'],['IntegrationTestSpec']
Integrability,"`SortReadFileSpark` gives a log message like this:; ```; 17:31:00.062 INFO SortReadFileSpark - Using %s reducers2744; ```; It's trivial, but I think the [logger](https://github.com/broadinstitute/gatk/blob/c18e7800ed85c55f81387cf02fdcbf6cb3aaaf5e/src/main/java/org/broadinstitute/hellbender/tools/spark/pipelines/SortReadFileSpark.java#L41) needs a small fix.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3095:32,message,message,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3095,1,['message'],['message']
Integrability,"`TableReader` and `TableWriter` only work on `java.io.File`, and need to be updated to accept `java.nio.Path` so we can Path-enable the tools that have code paths that depend on this package, like FilterByOrientationBias.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5747:168,depend,depend,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5747,1,['depend'],['depend']
Integrability,"`Tribble` codecs can only read data from `Locatable` data sources (those with contig + start + end position). Recently we have found a need for reading in files that do not have locatable data (e.g. tabular data that has a `Gene Name` and a set of attributes, but no start/stop location). Tribble should be updated to have a baseline `Interface` that is generic (and not necessarily `Locatable`). Our current interface / infrastructure can inherit from that for data sources that are `Locatable`. Then a new `Codec` can be created for data sources that are not Locatable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3760:335,Interface,Interface,335,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3760,2,"['Interface', 'interface']","['Interface', 'interface']"
Integrability,"`UserException.BadTmpDir` has the error message: ; `""Failure working with the tmp directory %s. Override with -Djava.io.tmpdir=X on the command line to a bigger/better file system.""`. This should be changed refer to either the `--java-options` command or `--TMP_DIR`. Also, it doesn't attach the casual exception.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4709:40,message,message,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4709,1,['message'],['message']
Integrability,"`VariantEvalUtils` was ported directly from GATK3, and depends on `VariantEval` to discover various input argument values for stratifiers, etc. An argument collection class should be factored out of VariantEval, with `@Argument`values for these values, and methods for retrieving them (each method in `VariantEvalUtils` that calls back to the walker should be moved into the arg collection class). The dependency should be inverted so that `VariantEvalUtils` and `VariantEval` both depend on the argument collection class. Currently the various classes in the varianteval project make assumptions about things like VariantEval command line argument names.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5441:55,depend,depends,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5441,3,['depend'],"['depend', 'dependency', 'depends']"
Integrability,"```; % python3 workflow_compute_costs.py \; --workspace_namespace 'not' \ ; --workspace_name 'there' ; Traceback (most recent call last):; File ""workflow_compute_costs.py"", line 135, in <module>; costs = compute_costs(args.workspace_namespace, args.workspace_name, args.exclude); File ""workflow_compute_costs.py"", line 32, in compute_costs; submissions = list_submissions(workspace_namespace, workspace_name); File ""workflow_compute_costs.py"", line 14, in fapi_list_submissions; return fapi_error_check(fapi.list_submissions(workspace_namespace, workspace_name)); File ""workflow_compute_costs.py"", line 8, in fapi_error_check; raise Exception(j['message']); Exception: workspace not/there does not exist or you do not have permission to use it; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7942:646,message,message,646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7942,1,['message'],['message']
Integrability,"```; ./gatk --version; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk --version; The Genome Analysis Toolkit (GATK) v4.0.12.0-1-g10aa8c7-SNAPSHOT; ```. This is different than the output of the tool --version...; ```; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk PrintReads --version; Version:4.0.12.0-1-g10aa8c7-SNAPSHOT; Tool returned:; 0; ```. I can change this to be that version, or we can change barclay to do it differently and provide more info. It might be useful to print the library versions with both commands as well.. that's printed during the normal run...; ```; 14:19:57.172 INFO PrintReads - HTSJDK Version: 2.18.1; 14:19:57.173 INFO PrintReads - Picard Version: 2.18.16; ```. @cmnbroad What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272:34,wrap,wrapper,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272,2,['wrap'],['wrapper']
Integrability,```; ./gatk-launch CountVariants -V fred -L 20; ```. blows up with a message . ```; A USER ERROR has occurred: We currently require a sequence dictionary (from a reference or source of reads) to process intervals. This restriction may be removed in the future.; ```. which makes no sense because `fred` does not even exist,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1896:69,message,message,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1896,1,['message'],['message']
Integrability,```; gradle clean installSpark; ./gatk-launch FlagStatSpark -I src/test/resources/org/broadinstitute/hellbender/tools/count_bases.bam ; Missing GATK wrapper script: /Users/droazen/src/hellbender/build/install/gatk/bin/gatk; To generate the wrapper run:. /Users/droazen/src/hellbender/gradlew installDist; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1314:149,wrap,wrapper,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1314,2,['wrap'],['wrapper']
Integrability,```; org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariantsIntegrationTest.testAlleleTrimming FAILED; java.lang.RuntimeException: org.broadinstitute.hellbender.exceptions.UserException$NoSuitableCodecs: A USER ERROR has occurred: Cannot read src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/forHardLeftAlignVariantsTest.vcf because no suitable codecs found; at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:153); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:126); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:108); at org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariantsIntegrationTest.testAlleleTrimming(SelectVariantsIntegrationTest.java:398); Caused by:; org.broadinstitute.hellbender.exceptions.UserException$NoSuitableCodecs: A USER ERROR has occurred: Cannot read src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/forHardLeftAlignVariantsTest.vcf because no suitable codecs found; at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:360); at org.broadinstitute.hellbender.engine.VariantWalker.initializeDrivingVariants(VariantWalker.java:62); at org.broadinstitute.hellbender.engine.VariantWalker.initializeFeatures(VariantWalker.java:55); at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:313); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:100); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:152); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:171); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:74); at or,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1685#issuecomment-205913501:461,Integrat,IntegrationTestSpec,461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1685#issuecomment-205913501,6,['Integrat'],['IntegrationTestSpec']
Integrability,"`ah_var_store` edition: Allows hard-filtering based on a maximum number of alt alleles [VS-1334], as well as fixing GATK Docker image building to use image IDs rather than git hashes [VS-1357]. Integration test _mostly_ successful [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/5d021859-5971-4fd7-8451-086c224fdb00). `GvsQuickstartIntegration` failed with:. ```; The bytes observed (89733530) for 'ExtractFilterTask.GvsCreateFilterSet.BigQuery Query Scanned' differ from those expected (85119360); FAIL!!! The relative difference between these is 0.0514208, which is greater than the allowed tolerance (0.05); ```. Successful tieout run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/04b840f9-9779-48d6-8faa-4425d67ddadb). [VS-1334]: https://broadworkbench.atlassian.net/browse/VS-1334?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ; [VS-1357]: https://broadworkbench.atlassian.net/browse/VS-1357?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8806:194,Integrat,Integration,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8806,1,['Integrat'],['Integration']
Integrability,"`fastutil` is a huge library with 10,000+ classes -- we can't keep adding dependencies like this and then use them in only one or two classes - our jar size is becoming ridiculous. We should replace usages of `fastutil` with either guava or primitive arrays.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1117#issuecomment-156503535:74,depend,dependencies,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1117#issuecomment-156503535,1,['depend'],['dependencies']
Integrability,`mvn clean` did not help although I do see its output logged properly. Let's ignore the `external-example` build issue as it is not present in 3.8-1 (as I managed to build it now). I care therefore only about the `rm: missing operand` message.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4686#issuecomment-383194874:235,message,message,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4686#issuecomment-383194874,1,['message'],['message']
Integrability,`serializeToVcfString` should not be be in the interface for Funcotation (see `Funcotation.java`). That should be the job of the VCFOutputRenderer to sanitize any strings. A Funcotation should not care whether it is being rendered to a VCF or MAF. It's poor separation of concerns.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4797:47,interface,interface,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4797,1,['interface'],['interface']
Integrability,"a:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 5.0 failed 1 times, most recent failure: Lost task 1.0 in stage 5.0 (TID 12",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:6969,Message,MessageHubBackedObjectConnection,6969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,"a:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. F",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:5278,Message,MessageHubBackedObjectConnection,5278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,aLine.java:483); 	at org.broadinstitute.hellbender.utils.tsv.DataLine.get(DataLine.java:452); 	at org.broadinstitute.hellbender.utils.tsv.DataLine.get(DataLine.java:581); 	at org.broadinstitute.hellbender.tools.walkers.contamination.PileupSummary$PileupSummaryTableReader.createRecord(PileupSummary.java:193); 	at org.broadinstitute.hellbender.tools.walkers.contamination.PileupSummary$PileupSummaryTableReader.createRecord(PileupSummary.java:188); 	at org.broadinstitute.hellbender.utils.tsv.TableReader.fetchNextRecord(TableReader.java:364); 	at org.broadinstitute.hellbender.utils.tsv.TableReader.access$200(TableReader.java:99); 	at org.broadinstitute.hellbender.utils.tsv.TableReader$1.hasNext(TableReader.java:472); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.utils.tsv.TableReader.toList(TableReader.java:532); 	at org.broadinstitute.hellbender.tools.walkers.contamination.PileupSummary.readFromFile(PileupSummary.java:139); 	at org.broadinstitute.hellbender.tools.walkers.contamination.CalculateContamination.doWork(CalculateContamination.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstit,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7707:4378,wrap,wrapAndCopyInto,4378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7707,1,['wrap'],['wrapAndCopyInto']
Integrability,a](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvUm9idXN0QnJlbnRTb2x2ZXJVbml0VGVzdC5qYXZh) | | |; | [...ute/hellbender/utils/solver/RobustBrentSolver.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvUm9idXN0QnJlbnRTb2x2ZXIuamF2YQ==) | | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvVW5pdmFyaWF0ZVNvbHZlclNwZWNpZmljYXRpb25zLmphdmE=) | | |; | [...der/utils/solver/SynchronizedUnivariateSolver.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvU3luY2hyb25pemVkVW5pdmFyaWF0ZVNvbHZlci5qYXZh) | | |; | [...r/utils/solver/UnivariateSolverJobDescription.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvVW5pdmFyaWF0ZVNvbHZlckpvYkRlc2NyaXB0aW9uLmphdmE=) | | |; | ... and [22 more](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7918#issuecomment-1168977988:4543,Synchroniz,SynchronizedUnivariateSolver,4543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7918#issuecomment-1168977988,1,['Synchroniz'],['SynchronizedUnivariateSolver']
Integrability,"abadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 01:42:05 2017 -0500. hybrid ADVI abstract argument collection w/ flexible default values; hybrid ADVI argument collection for contig ploidy model; hybrid ADVI argument collection for germline denoising and calling model. commit 56e21bf955d3dc0c52aceb384f28cf6173959de0; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 23:18:39 2017 -0500. rewritten python-side coverage metadata table reader using pandas to fix the issues with comment line; change criterion for cohort/case based on whether a contig-ploidy model is provided or not; simulated test files for ploidy determination tool; proper integration test for ploidy determination tool and all edge cases; updated docs for ploidy determination tool. commit 7fa104b2e9170770cfc5b338835e41215d7fd39c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 18:43:17 2017 -0500. kabab case for gCNV-related tools; removed short args (this also partially affected PlotDenoisedCopyRatios and PlotModeledSegments and their integration tests). commit f02cb024331a986213cfd9fae2da706bbc5ddbd9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 18:02:40 2017 -0500. synced with mb_gcnv_python_kernel. commit 2963bbf8c90418d9b88545c93771ae51cf542db9; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 11:38:05 2017 -0500. Fixing typo in travis.yml. commit 6cf589999c716ec66404eb0a2ae4310dd130a772; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 11:13:58 2017 -0500. editable, full path. commit d998f2d5c2b33dd41e291be9bfeaea72fe479b8a; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:56:24 2017 -0500. revert Dockerfile, change yml. commit 930d7486b7d2cf918fcb16dd03394bb9c9f0611b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:34:46 2017 -0500. more Dockerfile. commit 94112131526b514ef254bcc2c50a239dbae35aa1; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 10:25:13 2017",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:8122,integrat,integration,8122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,1,['integrat'],['integration']
Integrability,"acktrace:; ```; Feb 07, 2018 12:41:59 PM com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; java.net.SocketTimeoutException: connect timed out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:158); 	at com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:489); 	at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:206); 	at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:70); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369:6108,protocol,protocol,6108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369,1,['protocol'],['protocol']
Integrability,actory.java:2866) ; ;     at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:239) ; ;     at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211) ; ;     at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182) ; ;     at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForSegment$2(FuncotatorEngine.java:218) ; ;     at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; ;     at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; ;     at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382) ; ;     at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ;     at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ;     at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ;     at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ;     at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ;     at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForSegment(FuncotatorEngine.java:221) ; ;     at org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments.apply(FuncotateSegments.java:191) ; ;     at org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments.apply(FuncotateSegments.java:59) ; ;     at org.broadinstitute.hellbender.engine.FeatureWalker.lambda$traverse$0(FeatureWalker.java:99) ; ;     at java.util.Iterator.forEachRemaining(Iterator.java:116) ; ;     at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ;     at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) ; ;     at org.broadin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7676:4397,wrap,wrapAndCopyInto,4397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7676,1,['wrap'],['wrapAndCopyInto']
Integrability,ad.java:745); Caused by: java.net.UnknownHostException: www.googleapis.com; 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:668); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:6133); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094:7319,protocol,protocol,7319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094,1,['protocol'],['protocol']
Integrability,add CreateVariantIngestFiles integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7071:29,integrat,integration,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7071,1,['integrat'],['integration']
Integrability,add a clear error message if native code fails to build,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1554:18,message,message,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1554,1,['message'],['message']
Integrability,add echocallset as an option for integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8757:33,integrat,integration,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8757,1,['integrat'],['integration']
Integrability,add error message for when tree-score-threshold is set in ReblockGVCF…,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8218:10,message,message,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8218,1,['message'],['message']
Integrability,add scoring strategy for mark dups in Spark. Thus fixes 1 integration…,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1156:58,integrat,integration,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1156,1,['integrat'],['integration']
Integrability,add tests for FastaAlternateReferenceMaker because it has none. depends on #105 and #36,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/410:64,depend,depends,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/410,1,['depend'],['depends']
Integrability,add warning message to install_R_scripts,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4289:12,message,message,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4289,1,['message'],['message']
Integrability,adding git hash dependent version number,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/196:16,depend,dependent,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/196,1,['depend'],['dependent']
Integrability,adding issue comment to test hipchat integration after rename,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/945#issuecomment-146399336:37,integrat,integration,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/945#issuecomment-146399336,1,['integrat'],['integration']
Integrability,adding required dataflow dependencies,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/272:25,depend,dependencies,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/272,1,['depend'],['dependencies']
Integrability,ader.<init>(SnappyLoader.java:52); 	at htsjdk.samtools.util.TempStreamFactory.getSnappyLoader(TempStreamFactory.java:42); 	at htsjdk.samtools.util.TempStreamFactory.wrapTempOutputStream(TempStreamFactory.java:74); 	at htsjdk.samtools.util.SortingCollection.spillToDisk(SortingCollection.java:223); 	at htsjdk.samtools.util.SortingCollection.add(SortingCollection.java:166); 	at com.github.discvrseq.walkers.BackportLiftedVcf.apply(BackportLiftedVcf.java:156); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at com.github,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333579182:1519,wrap,wrapAndCopyInto,1519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333579182,1,['wrap'],['wrapAndCopyInto']
Integrability,adle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); [TileDB::FileSystem] Error: hdfs: Error getting hdfs connection; [TileDB::StorageManagerConfig] Error: Error getting hdfs connection: Connection refused.; Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest > testWriteToAndQueryF,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6522:6729,Message,MessageHubBackedObjectConnection,6729,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6522,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,advanced isn't integrated either,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2130#issuecomment-248046609:15,integrat,integrated,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2130#issuecomment-248046609,1,['integrat'],['integrated']
Integrability,"after a clean build, build/libIntelDeflater.so is a directory (!) and not a file and running gatk does not use the IntelDeflater (plus prints out a (bogus) message) - `Java HotSpot(TM) 64-Bit Server VM warning: You have loaded library /local/akiezun/gatk4_bqsr_deleteIndels_v2/gatk/build/libIntelDeflater.so which might have disabled stack guard. The VM will try to fix the stack guard now.; It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'`. @lbergelson please fix (ideally prevent from happening in the future or at least enter a ticket to future proof it)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1739:156,message,message,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1739,1,['message'],['message']
Integrability,"age 1.0 (TID 528, localhost): TaskKilled (killed intentionally); 00:11:24.786 INFO HaplotypeCallerSpark - Shutting down engine; [May 26, 2017 12:11:24 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 10.58 minutes.; Runtime.totalMemory()=16622026752; org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 1.0 failed 1 times, most recent failure: Lost task 15.0 in stage 1.0 (TID 519; , localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:10313,wrap,wrapAndCopyInto,10313,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['wrap'],['wrapAndCopyInto']
Integrability,"ailure: Task 181 in stage 5.0 failed 4 times, most recent failure: Lost task 181.3 in stage 5.0 (TID 1139, scc-q02.scc.bu.edu, executor 24): java.lang.IllegalArgumentException: provided start is negative: -1; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:40342,Wrap,Wrappers,40342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,2,['Wrap'],['Wrappers']
Integrability,"aling with large ploidies (typically for pooled experiments) run into limitations where the combination of the ploidy and numbers of alleles in the high teens and above produces too many possible genotypes for GenotypeGVCFs to handle under its current architecture. . For example, in the case reported here, the ploidy is 19 and the number of alternate alleles is 21, so GenotypeGVCFs cannot handle the large number of possible genotypes that result from all the possible combinations. A reasonable way to deal with this would be to cull the possible combinations dynamically at runtime to eliminate the most unlikely combinations up front. ; #### Test data. Has been provided by the user ; #### [Original forum post](http://gatkforums.broadinstitute.org/discussion/4954/combination-of-ploidy-and-number-of-alleles-error-when-running-genotypegvcfs/p1). ---. @vruano commented on [Tue Mar 10 2015](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-77993425). The error message explain the reason well ... a possibility to actually address this issue is to dynamically reduce the number of alt alleles loosing the less likely ones base on a maximum number of possible genotypes. So the user does not indicate the maximum number of alternative but the maximum number of genotypes. Which alt. alleles make it could be decided by taking a look in the corresponding hom. alt genotype likelihood dropping those alternatives with the worst hom. PLs. ---. @vdauwera commented on [Tue Mar 10 2015](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-78122186). @vruano What you propose sounds great. How much work would it take to implement this? . ---. @vruano commented on [Mon Mar 23 2015](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-85066881). Looking into that particular use case... the problem seem to be in position:. 45SrDNA_Jacobsen 9283. That seems to be very polymorphic or noisy even within individual samples, to the point that m",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2955:1248,message,message,1248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2955,1,['message'],['message']
Integrability,allerUtils.java:246); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:493); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1326(HaplotypeCallerSpark.java:223); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:213); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866); at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670); at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.ap,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149:2788,Wrap,Wrappers,2788,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149,1,['Wrap'],['Wrappers']
Integrability,ance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at org.seqdoop.hadoop_bam.BAMRecordReader.nextKeyValue(BAMRecordReader.java:225); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:182); 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:7433,wrap,wrapAndCopyInto,7433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['wrap'],['wrapAndCopyInto']
Integrability,and . ```; org.broadinstitute.hellbender.engine.filters.ReadFilter.lambda$and$cbfb947b$1(ReadFilter.java:31); org.broadinstitute.hellbender.engine.filters.ReadFilter$$Lambda$33/1797796358.test(Unknown Source); org.broadinstitute.hellbender.engine.filters.ReadFilter.lambda$and$cbfb947b$1(ReadFilter.java:31); org.broadinstitute.hellbender.engine.filters.ReadFilter$$Lambda$33/1797796358.test(Unknown Source); org.broadinstitute.hellbender.engine.filters.ReadFilter.lambda$and$cbfb947b$1(ReadFilter.java:31); org.broadinstitute.hellbender.engine.filters.ReadFilter$$Lambda$33/1797796358.test(Unknown Source); org.broadinstitute.hellbender.engine.filters.ReadFilter.lambda$and$cbfb947b$1(ReadFilter.java:31); org.broadinstitute.hellbender.engine.filters.ReadFilter$$Lambda$33/1797796358.test(Unknown Source); org.broadinstitute.hellbender.engine.filters.WellformedReadFilter.test(WellformedReadFilter.java:31); org.broadinstitute.hellbender.engine.spark.GATKSparkTool.lambda$getReads$e4b35a40$1(GATKSparkTool.java:196); org.broadinstitute.hellbender.engine.spark.GATKSparkTool$$Lambda$39/818029262.call(Unknown Source); org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:390); scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388); scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327); scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388); scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388); scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327); scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327); scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327); scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:29); org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.lambda$apply$26a6df3e$1(BaseRecalibratorSparkFn.java:27); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1657#issuecomment-203742647:4276,Wrap,Wrappers,4276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1657#issuecomment-203742647,2,['Wrap'],['Wrappers']
Integrability,and depends on https://github.com/broadinstitute/hellbender/issues/388,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/52#issuecomment-94113420:4,depend,depends,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/52#issuecomment-94113420,1,['depend'],['depends']
Integrability,"and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run. ...skipped for brevity... VcfFormatConverter (Picard) Converts VCF to BCF or BCF to VCF.; VcfToIntervalList (Picard) Converts a VCF or BCF file to a Picard Interval List. --------------------------------------------------------------------------------------. Exception in thread ""main"" org.broadinstitute.hellbender.exceptions.UserException: 'FixVcfHead' is not a valid command.; Did you mean this?; FixVcfHeader; 	at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:341); 	at org.broadinstitute.hellbender.Main.setupConfigAndExtractProgram(Main.java:172); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:192); 	at org.broadinstitute.hellbender.Main.main(Main.java:275); ```. I expect something without the stack trace and the scary ""Exception"" message. For example:. ```; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Base Calling: Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run. ...skipped for brevity... VcfFormatConverter (Picard) Converts VCF to BCF or BCF to VCF.; VcfToIntervalList (Picard) Converts a VCF or BCF file to a Picard Interval List. --------------------------------------------------------------------------------------. Did you mean this?; FixVcfHeader; ```. The same happens with unknown commands. The code that should be changed for that is the following, where the `setupConfigAndExtractProgram` call should be also inside th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4256:1352,message,message,1352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4256,1,['message'],['message']
Integrability,"and likely to require some iteration so I'd be ok with starting with just the minimal ""porting"" changes to keep things simple, and then doing a code hygiene pass at the end. The ""porting"" changes should include things like updated javadoc, GATK4-style command line arguments, updating of outdated GATK3 terminology such as ""ROD"", Utils.nonNull assertions, etc. The finals and curly braces can wait for a separate pass (we will want to do those in this PR though). If you're not sure what to include or not just ask. I like the idea of keeping the GATK3 tests working as we go along. We should make a clear distinction between the old and new tests though. Ideally the GATK3 tests would be in a separate commit that we can just delete at the end, but that can get unwieldy if the files in the commit need to change as we go along. Alternatively you could isolate them into a separate directory. They should either be disabled or made dependent on a test method (see the `@Test` annotation properties `enabled` and `dependsOn`) that is easily toggled so they can be run locally, but don't run on the CI server. Otherwise the CI server build will always fail. In general, its really helpful to have the first commit in the PR contain the completely unmodified GATK3 source files. It makes it much easier for the reviewer to see what changed for the port. I noticed that you have 2 new plugins included in this. I'm not sure if that was suggested by someone on the GATK team (I'm wondering if we want to go down that path...) but I can tell you that the existing plugins required an enormous amount of test development and review iteration. If we do decide to make them plugins, I think it would be a good idea to do so in a separate PR. Also, if we choose to make an AbstractPlugin base class, we may want that to live in the Barclay repo. As @magicdgs points out, master already has your previous commits, so you should start by rebasing on that. Ideally, the branch would have the following commits bef",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352:1155,depend,dependent,1155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352,2,['depend'],"['dependent', 'dependsOn']"
Integrability,and sometimes I get:. ```; java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:170); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:3; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271423848:1031,protocol,protocol,1031,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271423848,3,['protocol'],['protocol']
Integrability,anonfun$13.apply(PairRDDFunctions.scala:1190); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). **This is the stack I get when the test completes but fails (note that the expected line count appears to not match the line count of the expected output file in the repo): **. java.lang.AssertionError: line counts expected [2629] but found [507]; 	at org.testng.Assert.fail(Assert.java:94); 	at org.testng.Assert.failNotEquals(Assert.java:496); 	at org.testng.Assert.assertEquals(Assert.java:125); 	at org.testng.Assert.assertEquals(Assert.java:372); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:211); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:190); 	at org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.testExampleAssemblyRegionWalker(ExampleAssemblyRegionWalkerSparkIntegrationTest.java:29); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:3501,Integrat,IntegrationTestSpec,3501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['Integrat'],['IntegrationTestSpec']
Integrability,"anslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at org.apache.hadoop.ipc.Client.call(Client.java:1475); 	at org.apache.hadoop.ipc.Client.call(Client.java:1412); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229); 	at com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:255); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191); 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102); 	at com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source); 	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1226); 	... 28 more; 18/10/06 09:45:36 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 16, (reason: Shutdown hook called before final status was reported.); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:10242,protocol,protocolPB,10242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocolPB']
Integrability,ansportRequestHandler.java:110); at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:85); at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:101); at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51); at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:244); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846); at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131); at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511); at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468); at io.netty.channel.nio.NioEventLoop.processSelectedKey,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1491:3987,Message,MessageToMessageDecoder,3987,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1491,1,['Message'],['MessageToMessageDecoder']
Integrability,"ants(VariantLocusWalker.java:76); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:67); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:709); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.onStartup(VariantLocusWalker.java:63); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.io.IOException: GenomicsDB JNI Error: VariantQueryProcessorException : Could not open array 1$1$188260577 at workspace: /data1/EquCab/GenomicsDB/ECA3_GenomicsDB_260/1; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed; 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:200); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:85); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:407); 	... 12 more. I'm assuming it is something in the array 1$1$188260577 files, and possibly the _book_keep.tbs.gz file, although I'm not sure how to go about trouble shooting the issue. I also recreated the dat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012:5224,message,message,5224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012,1,['message'],['message']
Integrability,antutils/SelectVariants/forHardLeftAlignVariantsTest.vcf because no suitable codecs found; at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:153); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:126); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:108); at org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariantsIntegrationTest.testAlleleTrimming(SelectVariantsIntegrationTest.java:398); Caused by:; org.broadinstitute.hellbender.exceptions.UserException$NoSuitableCodecs: A USER ERROR has occurred: Cannot read src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/forHardLeftAlignVariantsTest.vcf because no suitable codecs found; at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:360); at org.broadinstitute.hellbender.engine.VariantWalker.initializeDrivingVariants(VariantWalker.java:62); at org.broadinstitute.hellbender.engine.VariantWalker.initializeFeatures(VariantWalker.java:55); at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:313); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:100); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:152); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:171); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:74); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:65); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:69); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:148); ... 3 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1685#issuecomment-205913501:2248,Integrat,IntegrationTestSpec,2248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1685#issuecomment-205913501,2,['Integrat'],['IntegrationTestSpec']
Integrability,"apache.spark.SparkException: Job aborted due to stage failure: Task 27 in stage 15.0 failed 4 times, most recent failure: Lost task 27.3 in stage 15.0 (TID 29483, scc-q15.scc.bu.edu, executor 13): org.broadinstitute.hellbender.exc eptions.GATKException: Erred when inferring breakpoint location and event type from chimeric alignment:; asm010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.sc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:5685,Wrap,WrappingSpliterator,5685,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['Wrap'],['WrappingSpliterator']
Integrability,are running on Google Compute Engine.; java.net.ConnectException: Host is down (connect failed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:112); 	at shaded.cloud_nio,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:1249,protocol,protocol,1249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235,2,['protocol'],['protocol']
Integrability,"ariant.bcf2.BCF2Codec.decodeInfo(BCF2Codec.java:410); 17 Jun 2020 15:49:59,420 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decodeSitesExtendedInfo(BCF2Codec.java:298); 17 Jun 2020 15:49:59,422 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:132); 17 Jun 2020 15:49:59,423 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:58); 17 Jun 2020 15:49:59,425 DEBUG: at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:183); 17 Jun 2020 15:49:59,426 DEBUG: at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:49); 17 Jun 2020 15:49:59,428 DEBUG: at java.util.Iterator.forEachRemaining(Iterator.java:116); 17 Jun 2020 15:49:59,429 DEBUG: at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 17 Jun 2020 15:49:59,431 DEBUG: at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 17 Jun 2020 15:49:59,432 DEBUG: at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 17 Jun 2020 15:49:59,433 DEBUG: at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 17 Jun 2020 15:49:59,435 DEBUG: at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 17 Jun 2020 15:49:59,436 DEBUG: at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 17 Jun 2020 15:49:59,437 DEBUG: at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:423); 17 Jun 2020 15:49:59,438 DEBUG: at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); 17 Jun 2020 15:49:59,439 DEBUG: at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 17 Jun 2020 15:49:59,440 DEBUG: at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 17 Jun 2020 15:49:59,441 DEBUG: at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 17",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6667:2273,wrap,wrapAndCopyInto,2273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6667,1,['wrap'],['wrapAndCopyInto']
Integrability,ariantcontext.VariantContext.getAttributeAsIntList(VariantContext.java:827) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.DuplicatedAltReadFilter.areAllelesArtifacts(DuplicatedAltReadFilter.java:26) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.HardAlleleFilter.calculateErrorProbabilityForAlleles(HardAlleleFilter.java:16) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2AlleleFilter.errorProbabilities(Mutect2AlleleFilter.java:86) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$0(ErrorProbabilities.java:27) ; ; at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321) ; ; at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:25) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:138) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:154) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; ; at java.util,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:7950,wrap,wrapAndCopyInto,7950,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['wrap'],['wrapAndCopyInto']
Integrability,ariants$2(HaplotypeCallerSpark.java:253); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark$$Lambda$312.00000000EC650830.apply(Unknown Source); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:278); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1823); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:305); at java.util.stream.StreamSpliterators$WrappingSpliterator$$Lambda$314.00000000EC651070.getAsBoolean(Unknown Source); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:217); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:180); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:311); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:692); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948); at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:888); at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:948); at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:694); at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334); at org.apache.spark.rdd.RDD.iterator(RDD.scala:285); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.ap,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4265:2265,Wrap,Wrappers,2265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4265,1,['Wrap'],['Wrappers']
Integrability,art your build.; > Cannot create service of type DependencyLockingHandler using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyLockingHandler() as there is a problem with parameter #2 of type ConfigurationContainerInternal.; > Cannot create service of type ConfigurationContainerInternal using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createConfigurationContainer() as there is a problem with parameter #13 of type DefaultConfigurationFactory.; > Cannot create service of type DefaultConfigurationFactory using DefaultConfigurationFactory constructor as there is a problem with parameter #2 of type ConfigurationResolver.; > Cannot create service of type ConfigurationResolver using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyResolver() as there is a problem with parameter #1 of type ArtifactDependencyResolver.; > Cannot create service of type ArtifactDependencyResolver using method DependencyManagementBuildScopeServices.createArtifactDependencyResolver() as there is a problem with parameter #4 of type List<ResolverProviderFactory>.; > Could not create service of type VersionControlRepositoryConnectionFactory using VersionControlBuildSessionServices.createVersionControlSystemFactory().; > Failed to create parent directory '/home/jdjdj0202/gatk/.gradle' when creating directory '/home/jdjdj0202/gatk/.gradle/vcs-1'. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. BUILD FAILED in 754ms. FAILURE: Build failed with an exception. * What went wrong:; Could not update /home/jdjdj0202/gatk/.gradle/7.5.1/fileChanges/last-build.bin; > /home/jdjdj0202/gatk/.gradle/7.5.1/fileChanges/last-build.bin (No such file or directory). * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --i,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8346:1781,Depend,DependencyManagementBuildScopeServices,1781,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8346,1,['Depend'],['DependencyManagementBuildScopeServices']
Integrability,"as per an in-person disucssion, the integration tests will for now only work at the Broad system. Once we move to https://help.github.com/articles/versioning-large-files/ (or similar) these will be enabled again",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/52#issuecomment-92577600:36,integrat,integration,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/52#issuecomment-92577600,1,['integrat'],['integration']
Integrability,ase.initializeIterator(CRAMFileReader.java:500); 	at htsjdk.samtools.CRAMFileReader$CRAMIntervalIterator.<init>(CRAMFileReader.java:558); 	at htsjdk.samtools.CRAMFileReader$CRAMIntervalIterator.<init>(CRAMFileReader.java:553); 	at htsjdk.samtools.CRAMFileReader.query(CRAMFileReader.java:425); 	at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.query(SamReader.java:533); 	at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.queryOverlapping(SamReader.java:405); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextIterator(SamReaderQueryingIterator.java:130); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.<init>(SamReaderQueryingIterator.java:69); 	at org.broadinstitute.hellbender.engine.ReadsPathDataSource.prepareIteratorsForTraversal(ReadsPathDataSource.java:412); 	at org.broadinstitute.hellbender.engine.ReadsPathDataSource.prepareIteratorsForTraversal(ReadsPathDataSource.java:389); 	at org.broadinstitute.hellbender.engine.ReadsPathDataSource.query(ReadsPathDataSource.java:352); 	at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.readStream(CalibrateDragstrModel.java:835); 	at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.lambda$null$10(CalibrateDragstrModel.java:478); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:747); 	at java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:721); 	at java.util.stream.AbstractTask.compute(AbstractTask.java:327); 	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731); 	... 4 more; Using GATK jar /gatk/gatk-package-4.1.9.0-15-g8f07c46-SNAPSHOT-local.jar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7060:5864,wrap,wrapAndCopyInto,5864,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7060,1,['wrap'],['wrapAndCopyInto']
Integrability,"assMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more**. 00:59 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:55:54 INFO TaskSetManager: Starting task 1.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 1, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:55:54 INFO TaskSetManager: Lost task 0.0 in stage 2.0 (TID 3) on xx.xx.xx.25, executor 2: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 01:00 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:54 INFO TaskSetManager: Starting task 0.1 in stage 2.0 (TID 6, xx.xx.xx.16, executor 3, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:55:55 INFO TaskSetManager: Lost task 0.1 in stage 2.0 (TID 6) on xx.xx.xx.16, executor 3: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:26955,Wrap,WrappedArray,26955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Wrap'],['WrappedArray']
Integrability,assigning to @vdauwera to make a recommendation on the message,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/418#issuecomment-94617530:55,message,message,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/418#issuecomment-94617530,1,['message'],['message']
Integrability,ateGenotypes(GenotypeGVCFsEngine.java:244); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.regenotypeVC(GenotypeGVCFsEngine.java:152); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:135); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:283); at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:135); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); (base) [adagilis@longleaf-login4 logs]$; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:490); at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadins,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639:8675,wrap,wrapAndCopyInto,8675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639,1,['wrap'],['wrapAndCopyInto']
Integrability,"ated a new SpanningDeletionRecord as a subclass of ReferenceRecord but allows us to store GT and GQ; 2. in handlePotentialSpanningDeletion when processing a deletion, we create a new SpanningDeletionRecord with the correct GT and GQ based on the deletion; 3. When processing reference data at a variant site, return ReferenceRecords/SpanningDeletionRecord instead of just a string ""state"" since we need more than just state now; 4. Because of the above, we are now returning an object for the inferred state instead of just a string. Since the inferred state is so, so common a singleton InferredReferenceRecord was created; 5. Processing of spanning deletions beyond. **Ugly**; 1. The construction of the singleton is ugly because it _requires_ a location even though we don't for this case. We could go to an tagging interface (like Cloneable) these all implement, but that seems ugly also. *Refactoring Changes*; One of the challenges with this PR was testing as the work is really done in the lower-level methods and it would be nice to have this as a unit test rather than an integration/end-to-end test. This motivated the following changes:. 1. don't write to VCF directly, instead have take a Consumer<VariantContext> to emit VariantContexts. This let's us provide a different consumer in unit tests to collect our result.; 2. we previously had a chain of calls createVariantsFromSortedRanges -> processSampleRecordsForLocation -> finalizeCurrentVariant that returned void and as a side effect wrote to VCF. These deeper methods now return a VariantContext and the writing (via consumer) is done higher up in the call stack; 3. made some private methods package-private so we could call them from tests. **Thinking Out Loud**. We have three different sets of datastructures for the same data, some of this is history, some is performance/memory, but could use some rethinking; 1. GenericRecord (pulling from BQ); 2. ReferenceRecord/SpanningDeletionRecord (in memory data structure for referenc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7857:1118,integrat,integration,1118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7857,1,['integrat'],['integration']
Integrability,"ation more efficient. . ---. @vruano commented on [Thu May 05 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-217267297). Those haplotype scores have not been throughly analyzed but we are already using them to discard haplotypes beyond the maximum allowed per graph kmer size so I don't see the harm in using the for further reduction. . Certainly is a step forward from just throwing an exception back to the user. However, we should output a Warning every time we need to do such a reduction just to keep track. ---. @sooheelee commented on [Fri May 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-217443170). Is it possible for the user to mask this 45SrDNA locus for separate analysis? Assuming of course that this locus is of further interest to their aims. For example, either for more exact mapping then variant calling or separate variant calling. I say this because a quick glance at the literature suggests this is potentially a highly variable region that may be present in multiple copies depending on species. It's a ribosomal DNA locus, that is, a site from which rRNA is transcribed. In mammals (humans & mice) it looks like it is a tandemly repeated locus residing on several chromosomes:. <img width=""424"" alt=""screenshot 2016-05-06 09 37 12"" src=""https://cloud.githubusercontent.com/assets/11543866/15074654/264e199a-136e-11e6-852e-431d8690f2aa.png"">. Some random references:; - [Concerted copy number variation balances ribosomal; DNA dosage in human and mouse genomes](http://www.pnas.org/content/112/8/2485.full.pdf); - [Haplotype Detection from Next-Generation Sequencing in High-Ploidy-Level Species: 45S rDNA Gene Copies in the Hexaploid Spartina maritima.](http://www.ncbi.nlm.nih.gov/pubmed/26530424); - [Non-Random Distribution of 5S rDNA Sites and Its Association with 45S rDNA in Plant Chromosomes.](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0035139). ---. @vruano commented on [Fri May ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2955:7348,depend,depending,7348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2955,1,['depend'],['depending']
Integrability,ationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:192); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkCont,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:7633,Wrap,Wrappers,7633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,3,['Wrap'],['Wrappers']
Integrability,ationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:192); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:3571,Wrap,Wrappers,3571,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Wrap'],['Wrappers']
Integrability,"ations are described as early as [VCF v4.1 specs](https://samtools.github.io/hts-specs/) and expanded upon in v4.3 specs. I think @jonn-smith you refer to MAF-format functional annotations. Yes? Here we are discussing much less complex variant call level annotations like genotype that would have a few associated numerical values, e.g. 10th, 50th, and 90th confidence interval allele fractions AND copy ratio value for each CN segment. . One last thing of interest towards visualization. I've been reminded recently of some open-source software that is a standard in visualizing somatic data for the biologist in the Cancer Genetics field--[CBioPortal](http://www.cbioportal.org/index.do?cancer_study_id=blca_mskcc_solit_2014&Z_SCORE_THRESHOLD=2.0&RPPA_SCORE_THRESHOLD=2.0&data_priority=0&case_set_id=blca_mskcc_solit_2014_cnaseq&gene_list=RB1%2520RBL1%2520RBL2%2520CCNA1%2520CCNB1%2520CDK1%2520CCNE1%2520CDK2%2520CDC25A%2520CCND1%2520CDK4%2520CDK6%2520CCND2%2520CDKN2A%2520CDKN2B%2520MYC%2520CDKN1A%2520CDKN1B%2520E2F1%2520E2F2%2520E2F3%2520E2F4%2520E2F5%2520E2F6%2520E2F7%2520E2F8%2520SRC%2520JAK1%2520JAK2%2520STAT1%2520STAT2%2520STAT3%2520STAT5A%2520STAT5B&geneset_list=+&tab_index=tab_visualize&Action=Submit&genetic_profile_ids_PROFILE_MUTATION_EXTENDED=blca_mskcc_solit_2014_mutations&genetic_profile_ids_PROFILE_COPY_NUMBER_ALTERATION=blca_mskcc_solit_2014_cna) (I plugged in some data--try clicking on the different tabs). They are Dockerized and their repo is at https://github.com/cBioPortal/cbioportal. They do a good job bridging the gap between genomics data and what the biologist is interested in. Their CNA visualization currently takes GISTIC-type data. For segmented CNs, they use a JavaScript version of IGV. It's worth checking out and perhaps enabling GATK users to visualize their somatic data with CBioPortal. . I'd like for us to save all our time for the interesting questions and leverage the hard work of others towards questions such as standarization and visualization.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386386120:2653,bridg,bridging,2653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386386120,1,['bridg'],['bridging']
Integrability,aturesFromFeatureContext(DataSourceFuncotationFactory.java:304); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:219); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:197); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7090:12282,wrap,wrapAndCopyInto,12282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7090,1,['wrap'],['wrapAndCopyInto']
Integrability,auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Connection refused (Connection refused); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsPr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:1500,protocol,protocol,1500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843,1,['protocol'],['protocol']
Integrability,"ava HotSpot(TM) 64-Bit Server VM v1.8.0_181-b13; 14:35:47.080 INFO SelectVariants - Start Date/Time: September 24, 2018 2:35:45 PM EET; 14:35:47.080 INFO SelectVariants - ------------------------------------------------------------; 14:35:47.081 INFO SelectVariants - ------------------------------------------------------------; 14:35:47.082 INFO SelectVariants - HTSJDK Version: 2.16.1; 14:35:47.082 INFO SelectVariants - Picard Version: 2.18.13; 14:35:47.082 INFO SelectVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:35:47.082 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:35:47.082 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:35:47.082 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:35:47.082 INFO SelectVariants - Deflater: IntelDeflater; 14:35:47.082 INFO SelectVariants - Inflater: IntelInflater; ```. From @jean-philippe-martin . > This error message is related to GATK's ability to load files on Google buckets (""gcs://bucket/file.bam""). This ability is enabled even when running locally (this aspect is intentional, because it's useful to be able to run a local GATK instance to process remote data without having to fire up a VM).; > ; > As the bucket-reading code (""NIO"") initializes, it looks for credentials to use. Those can be set via an environment variable or via gcloud auth, as described in GATK's README. If neither of these are set, it checks whether it's currently running in a Google virtual machine (so it can figure out who owns the virtual machine that it's running on, and use those credentials). Apparently this code throws an exception if it runs out of ways to find credentials, and our code prints it out and moves on.; > ; > The message is useful, for if we were running in a google VM and the credential-finding failed, we'd certainly like to know. Whether we need the full stack trace, now, that's a choice we have to make.; > . We should tone down the e",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5220:5440,message,message,5440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5220,1,['message'],['message']
Integrability,"avadoc.doclet](https://docs.oracle.com/en/java/javase/11/docs/api/jdk.javadoc/jdk/javadoc/doclet/package-summary.html). The javadoc tools in `org.broadinstitute.hellbender.utils.help` may need to be re-written (and it's not clear if it's possible to support Java 8 and Java 11 simultaneously).; * Travis build. Getting this to build and test on Java 11 in addition to the current builds may be fairly involved as the matrix is already quite complicated. (The current PR just changes Java 8 to Java 11 for testing purposes - we'd need a way of getting both to run.). The vast majority of tests are passing on Java 11, the following are failing:; * Missing `TwoBitRecord` (from ADAM); * `ReferenceMultiSparkSourceUnitTest`; * `ImpreciseVariantDetectorUnitTest`; * `SVVCFWriterUnitTest`; * `DiscoverVariantsFromContigAlignmentsSAMSparkIntegrationTest`; * `StructuralVariationDiscoveryPipelineSparkIntegrationTest`; * `SvDiscoverFromLocalAssemblyContigAlignmentsSparkIntegrationTest`; * `java.lang.NoSuchMethodError: java.nio.ByteBuffer.clear()Ljava/nio/ByteBuffer;`; * `SeekableByteChannelPrefetcherTest`; * `GatherVcfsCloudIntegrationTest`; * `Could not serialize lambda`; * `ExampleAssemblyRegionWalkerSparkIntegrationTest`; * `PileupSparkIntegrationTest`; * Native HMM library code caused the tests to crash on my Mac:; ```; Running Test: Test method testLikelihoodsFromHaplotypes[0](org.broadinstitute.hellbender.utils.pairhmm.VectorLoglessPairHMM@6282d367, true)(org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest); dyld: lazy symbol binding failed: can't resolve symbol __ZN13shacc_pairhmm9calculateERNS_5BatchE in /private/var/folders/cj/wyp4zgw17vj4m9qdmddvmcc80000gn/T/libgkl_pairhmm13775554937319419112.dylib because dependent dylib #1 could not be loaded; dyld: can't resolve symbol __ZN13shacc_pairhmm9calculateERNS_5BatchE in /private/var/folders/cj/wyp4zgw17vj4m9qdmddvmcc80000gn/T/libgkl_pairhmm13775554937319419112.dylib because dependent dylib #1 could not be loaded; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527179359:2504,depend,dependent,2504,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527179359,2,['depend'],['dependent']
Integrability,"b UI at http://xx.xx.xx.xx:4040; 18/04/24 17:42:02 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/24 17:42:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/24 17:42:02 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/gatk-package-4.0.3.0-spark.jar, byteCount=138618122, body=FileSegmentManagedBuffer{file=/scratch/home/int/eva/username/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-spark.jar, offset=0, length=138618122}} to /xx.xx.xx.25:57139; closing connection; java.io.IOException: Connection reset by peer; at sun.nio.ch.FileChannelImpl.transferTo0(Native Method); at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428); at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493); at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608); at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139); at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121); at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287); at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237); at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314); at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802); at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319); at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637); at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566); at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442); at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorat",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:37226,protocol,protocol,37226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['protocol'],['protocol']
Integrability,"back to @lbergelson ; i exposed the hidden exceptions a bit more. Annoyingly I had to catch IOExceptions and SAMExceptions (an alternative would have been to let SAMExceptions go all the way up to the caller but that seemed suboptimal). Ideally, htsjdk should not have wrapped IOException in a SAMException but rather expose IOExceptions for what they are and leave their handling to the app layer (ie us)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/448#issuecomment-96774011:269,wrap,wrapped,269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/448#issuecomment-96774011,1,['wrap'],['wrapped']
Integrability,back to @lbergelson for second review. log10 cache is now static (and synchronized at expansion only) as in gatk3 - it looks faster (no map lookup that would be needed in the thread local solution),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1957#issuecomment-230860880:70,synchroniz,synchronized,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1957#issuecomment-230860880,1,['synchroniz'],['synchronized']
Integrability,bender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:2501,Wrap,Wrappers,2501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,3,['Wrap'],['Wrappers']
Integrability,bender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:5130); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:491); 	... 12 more; Caused by: java.io.EOFException: SSL peer shut down incorrectly; 	at sun.security.ssl.InputRe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685:6825,protocol,protocol,6825,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685,1,['protocol'],['protocol']
Integrability,better Gnarly error message,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8270:20,message,message,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8270,1,['message'],['message']
Integrability,better error message,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3812:13,message,message,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3812,1,['message'],['message']
Integrability,better error message for JEXL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1498:13,message,message,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1498,1,['message'],['message']
Integrability,"bgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded; >; > 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported; >; > 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; >; > 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded; >; > 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; >; > Since the calculation takes quite long, I checked the WARN messages of the; > output above. Especially the last one about the AVX instruction set where; > it says that a *MUCH* slower implementation will be used. From the few; > WARN messages it seems like the root cause is the failure to load libgkl; > and that again seems to be related to my platform. Does anyone know more; > about this issue or how to work around it?; >; > Best regards,; > Robert; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6794>, or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AAKOLMAQSKLJ5N7SHDOJQ7DSEESQFANCNFSM4QZASPYQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600:6483,message,messages,6483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600,2,['message'],['messages']
Integrability,"blish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and remove if required, without any major version bump.; * `testing`: this will contain the testing framework. It is related with #1481 and #3567. ; * `documentation`: this might be useful for code dependent on `com.sun.javadoc` to do not interact with other classes if code for documenting a downstream project is not necessary.; * Other modules might be useful for concrete components: e.g, ., the gCNV python computational kernel implemented in #3838.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3900:2193,depend,dependent,2193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900,1,['depend'],['dependent']
Integrability,bmRlci91dGlscy9SL1JTY3JpcHRFeGVjdXRvci5qYXZh) | `80.282% <0%> (-8.451%)` | `17% <0%> (-3%)` | |; | [...g/broadinstitute/hellbender/utils/io/Resource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9SZXNvdXJjZS5qYXZh) | `55.556% <0%> (-7.407%)` | `6% <0%> (-1%)` | |; | [...llbender/tools/walkers/bqsr/AnalyzeCovariates.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQW5hbHl6ZUNvdmFyaWF0ZXMuamF2YQ==) | `67.593% <0%> (-4.63%)` | `29% <0%> (-1%)` | |; | [...ute/hellbender/utils/recalibration/RecalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL1JlY2FsVXRpbHMuamF2YQ==) | `89.407% <0%> (-3.814%)` | `52% <0%> (-1%)` | |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `90.909% <0%> (-3.209%)` | `2% <0%> (+1%)` | |; | [...te/hellbender/tools/spark/sv/utils/SVInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkludGVydmFsLmphdmE=) | `85.507% <0%> (-1.993%)` | `64% <0%> (+28%)` | |; | [...walkers/bqsr/AnalyzeCovariatesIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4997/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQW5hbHl6ZUNvdmFyaWF0ZXNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `92.063% <0%> (-1.783%)` | `22% <0%> (-2%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/b,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-404596846:2425,integrat,integration,2425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-404596846,1,['integrat'],['integration']
Integrability,"broadinstitute.hellbender.engine.datasources.ReferenceMultiSource, org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource@78eac8f2); - element of array (index: 1); - array (class [Ljava.lang.Object;, size 2); - field (class: java.lang.invoke.SerializedLambda, name: capturedArgs, type: class [Ljava.lang.Object;); - object (class java.lang.invoke.SerializedLambda, SerializedLambda[capturingClass=class org.broadinstitute.hellbender.engine.spark.ShuffleJoinReadsWithRefBases, functionalInterfaceMethod=org/apache/spark/api/java/function/PairFlatMapFunction.call:(Ljava/lang/Object;)Ljava/lang/Iterable;, implementation=invokeStatic org/broadinstitute/hellbender/engine/spark/ShuffleJoinReadsWithRefBases.lambda$addBases$cff38836$1:(Lorg/broadinstitute/hellbender/utils/SerializableFunction;Lorg/broadinstitute/hellbender/engine/datasources/ReferenceMultiSource;Lscala/Tuple2;)Ljava/lang/Iterable;, instantiatedMethodType=(Lscala/Tuple2;)Ljava/lang/Iterable;, numCaptured=2]); - writeReplace data (class: java.lang.invoke.SerializedLambda); - object (class org.broadinstitute.hellbender.engine.spark.ShuffleJoinReadsWithRefBases$$Lambda$74/1217660878, org.broadinstitute.hellbender.engine.spark.ShuffleJoinReadsWithRefBases$$Lambda$74/1217660878@663d7f24); - field (class: org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1, name: f$5, type: interface org.apache.spark.api.java.function.PairFlatMapFunction); - object (class org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1, <function1>); at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:40); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:47); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101); at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:301); ... 30 more; 16/10/17 16:03:47 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2216:5282,interface,interface,5282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2216,1,['interface'],['interface']
Integrability,broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.net.UnknownHostException: www.googleapis.com; 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:668); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClien,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094:6937,protocol,protocol,6937,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094,1,['protocol'],['protocol']
Integrability,browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:1853,Message,MessageLoop,1853,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491,1,['Message'],['MessageLoop']
Integrability,bstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<ini,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1468,protocol,protocol,1468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,"build will break because genomicsdb-0.6.0 hasn't been released yet and dependence on protobuf-java-format needs to be fixed!. @droazen, remember now that I added the dependence on protobuf-java-format to use protobuf.JsonFormat.printToString() method which converts a protobuf structure to JSON string. I want to use import configuration protocol buffers in this code which means this dependence will be back to bite us! Need to fix this cause I don't want to break the Spark build again",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2634:71,depend,dependence,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2634,4,"['depend', 'protocol']","['dependence', 'protocol']"
Integrability,build.gradle finds the tool provider with the following line:. ```; final javadocJDKFiles = files(((URLClassLoader) ToolProvider.getSystemToolClassLoader()).getURLs()); ```; ToolPrivider.getSystemToolClassLoader() returns null on jre and certain other java installations. This causes a confusing null pointer exceptions. We should have a better error message when this happens.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4532:351,message,message,351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4532,1,['message'],['message']
Integrability,buildRequest(HttpRequestFactory.java:93); at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:333); ... 17 more; Caused by: java.net.UnknownHostException: metadata; at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); at sun.net.www.http.HttpClient.New(HttpClient.java:308); at sun.net.www.http.HttpClient.New(HttpClient.java:326); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:104); ... 27 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412904420:6756,protocol,protocol,6756,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412904420,4,['protocol'],['protocol']
Integrability,"build_docker.sh creates unzippedJar and testsJar, but it does not remove them and it fails as a result in subsequent runs. . I ran ./build_socker.sh -e <GIT LOG HASH> and I got the error message ; mv: rename ./build/bundle-files-collected to ./unzippedJar/bundle-files-collected: Directory not empty. Only after removing unzippedJar and testJar could I build the image again successfully.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5369:187,message,message,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5369,1,['message'],['message']
Integrability,"but the size of the data structures depends on the data - eg, on the number of read groups, on size of context covariates etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-178320413:36,depend,depends,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-178320413,1,['depend'],['depends']
Integrability,"bwt, i just checked - removing this direct dependency does make the jar file smaller, but only by 71301771-70815509 = 486262 bytes (0.68% smaller)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1120#issuecomment-162999580:43,depend,dependency,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1120#issuecomment-162999580,1,['depend'],['dependency']
Integrability,"by delegating work to ; `FindBreakpointEvidenceSpark` and `DiscoverVariantsFromContigAlignmentsSpark`, ; so we have a single tool running the whole pipeline. This PR also does:; * refactoring of `FindBreakpointEvidenceSpark` and `DiscoverVariantsFromContigAlignmentsSpark` to accommodate the new tool; * added three integration test (dummy in the sense that it only makes sure they run, and no correctness check on the output) for the three tools. Known differences:. * For NA12878 test sample: The `FindBreakpointEvidenceSpark`->`DiscoverVariantsFromContigAlignmentsSpark` generated VCF and `StructuralVariationDiscoveryPipelineSpark` generated VCF differ by how supplementary alignment's soft clipping is treated. The `FindBreakpointEvidenceSpark`->`DiscoverVariantsFromContigAlignmentsSpark` path has an optimization turned on that soft clipped bases for supplementary alignments are hard clipped away (no contig sequence is lost as it is always saved in the primary alignment), so the CIGARs are a little different. As a consequence, the SAM file generated by the two routes also differ in this CIGAR and sequence part.; * For CHM test sample: The differences are more delicate and even master version yields slightly different results from run to run. So I summarized them in the attached zip. @tedsharpe and @cwhelan please take a look, as `FindBreakpointEvidenceSpark` is modified (no change of logic, but how code is called).; [chm.zip](https://github.com/broadinstitute/gatk/files/919925/chm.zip)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2595:316,integrat,integration,316,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2595,2,"['integrat', 'rout']","['integration', 'routes']"
Integrability,"c 5 12:51:17 2017 -0500. Updates to handle SAM header changes from sl_wgs_acnv_headers and updates to mb_gcnv_python_kernel. commit d02d04df684a2820308a1d1c2bfda4b7d1c5f05e; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Mon Nov 13 12:52:33 2017 -0500. Added CLIs and WDL for python gCNV pipeline. commit 66ed74b68375d43514ef84658e7a6c771ed9053c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Nov 15 01:50:03 2017 -0500. Polished code, ready for review; ; gCNV computational kernel (initial release); ; renaming gammas_s to psi_s to uniformity (sample-specific unexplained variance); ; renamed determine_ploidy_and_depth.py to cohort_determine_ploidy_and_depth.py; finite-temperature forward-backward algorithm; in the ploidy model, replaced alpha_j (NB over-dispersion) with psi_j (unexplained variance) for uniformity. Also, added the possibility of sample-specific unexplained variance in the germline contig ploidy model; ; updated I/O routines and CLIs according to team discussion; ; updated I/O routines and CLIs according to team discussion; ; changed the output layout of the ploidy determination tool; refactored parts of io.py; upped the version to 0.3 as it is not backwards compatible anymore; ; case ploidy determination tool from a given ploidy model; major code cleanup and refactoring of I/O module; refactoring of common CLI script snippets; ; removed all ""targets""; some code cleanup; ; pad flat class bitmask w/ a given padding value in the hybrid q_c_expectation_mode; option to disable annealing and keep the temperature fixed; ; bugfix in finite-temperature forward-backward; further refactoring of model I/O; ; the option to take a previously trained model as starting point in cohort CLI; the option to take previous calls as a starting point in cohort CLI; ; option to save and load adamax moments; ; import/export adamax bias correction tensor; ; refactoring related to fancy opt I/O; added average ploidy column to read depth; updated docs of hybrid ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:10911,rout,routines,10911,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['rout'],['routines']
Integrability,"c. to `pytensor`/`pt`/etc. However, there were some more nontrivial changes, including to 1) model priors (since some of the distributions previously used were removed or are now supported differently), 2) the implementation of posterior sampling, 3) some shape/dimshuffle operations, and other things along these lines. Using a single test shard of 20 1kGP WES samples x 1000 intervals, I have verified determinism/reproducibility for DetermineGermlineContigPloidy COHORT/CASE modes, GermlineCNVCaller COHORT/CASE modes, and PostprocessGermlineCNVCalls. Numerical results are also relatively close to those from 4.4.0.0 for all identifiable call and model quantities (albeit far outside any reasonable exact-match thresholds, most likely due to differences in RNG, sampling, and the aforementioned priors). Some remaining TODOs:. - [x] Rebuild and push the base Docker. EDIT: Mostly covered by #8610, but this also includes an addition of `libblas-dev`.; - [x] Update expected results for integration tests, perhaps add any that might be missing. EDIT: These were generated on WSL Ubuntu 20.04.2, we'll see if things pass on 22.04. Note that changing the ARD priors does change the *names* of the expected files, since the transform is appended to the corresponding variable name. DetermineGermlineContigPloidy and PostprocessGermlineCNVCalls are missing exact-match tests and should probably have some, but I'll leave that to someone else.; - [x] Update other python integration tests.; - [x] Clean up some of the changes to the priors.; - [x] Clean up some TODO comments that I left to track code changes that might result in changed numerics. I'll try to go through and convert these to PR comments in an initial review pass.; - [x] Test over multiple shards on WGS and WES. Probably some scientific tests on ~100 samples in both cohort and case mode would do the trick. We should also double check runtime/memory performance (I noted ~1.5x speedups, but didn't measure carefully; I also want to m",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285:1955,integrat,integration,1955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285,1,['integrat'],['integration']
Integrability,"c.Start.parseAndExecute(Start.java:366); at com.sun.tools.javadoc.Start.begin(Start.java:219); at com.sun.tools.javadoc.Start.begin(Start.java:205); at com.sun.tools.javadoc.Main.execute(Main.java:64); at com.sun.tools.javadoc.Main.main(Main.java:54); 1 error; :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/Users/shlee/Documents/branches/hellbender-protected/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 3.807 secs; WMCF9-CB5:hellbender-protected shlee$ ; ```. ---. @cmnbroad commented on [Wed May 17 2017](https://github.com/broadinstitute/gatk-protected/issues/1048#issuecomment-302219179). The doc processing code tries to walk up the class hierarchy of all dependent types, and there are classes in the cachemanager package that have inner classes that derive from RuntimeException, which it can't resolve. Apparently we've never run it on such code before. Anyway, the fix needs to be in Barclay. ---. @sooheelee commented on [Fri May 19 2017](https://github.com/broadinstitute/gatk-protected/issues/1048#issuecomment-302784016). Any word on this @cmnbroad? I'm running into pre-existing documentation whose formatting I need to check appears correctly. I think I will create a testing doc in gatk public to see how formatting appears. However, this has me going back and forth between two repos so adds to my mental overhead. ---. @cmnbroad commented on [Mon May 22 2017](https://github.com/broadinstitute/gatk-protected/issues/1048#issuecomment-303094262). @sooheelee I have a fix, but reproducing this in a test is challenging. Will try to get something as soon as possible. ---. @sooheelee commented on [Mon May 22 2017](https://github.com/broadinstitute/gatk-protected/issues/1048#issuecomme",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2988:4493,depend,dependent,4493,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2988,1,['depend'],['dependent']
Integrability,"c79f3d00e1f1a7b492b0a8f	AS:38	UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta	SP:Homo sapiens; @SQ	SN:HLA-A*01:09	LN:3105	M5:68176666a98582ea361a9181d69679af	AS:38	UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta	SP:Homo sapiens; @SQ	SN:HLA-A*01:11N	LN:3374	M5:b9ad3338cc73e2a99888a36e04c29f75	AS:38	UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta	SP:Homo sapiens; @SQ	SN:HLA-A*01:14	LN:3095	M5:0385be87eb49df4c59d7487495e3b1b4	AS:38	UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta	SP:Homo sapiens; @SQ	SN:HLA-A*01:16N	LN:2985	M5:10150ad21301a29f92e1521530fdd3f5	AS:38	UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta	SP:Homo sapiens; @SQ	SN:HLA-A*01:20	LN:3105	M5:05dc0384da2f751afe549a9bfdbc3037	AS:38	UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta	SP:Homo sapiens; ```. If the contig name is the issue, then this is a bug of sorts that, depending on your project, may or may not be an issue. If you expect all of your samples (PoN normals and tumor samples) to have coverage for specific alternate contigs and need to include such contigs in your analysis, then we can request a fix for this parsing error. I think this case would be unusual. If alternate contigs are not needed for your research, or you expect sporadic coverage for the contigs across samples, then you can move ahead by limiting your analysis to the [primary assembly](https://gatkforums.broadinstitute.org/gatk/discussion/7857/reference-genome-components). For a typical somatic CNV analysis, because of the way the PoN is pruned, when working with GRCh38 alignments, you want to be sure to limit your counting to the primary assembly. You want to use the `-L` argument with an intervals file that only lists the primary assembly and excludes alternate and decoy contigs. This is really important. Any apparent arm/contig level event with variable coverage acr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3357:2959,depend,depending,2959,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357,1,['depend'],['depending']
Integrability,calibrator.java:542); at java.util.ArrayList.forEach(ArrayList.java:1251); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.consumeQueuedVariants(VariantRecalibrator.java:542); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.apply(VariantRecalibrator.java:521); at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6963:8427,wrap,wrapAndCopyInto,8427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963,1,['wrap'],['wrapAndCopyInto']
Integrability,calibrator.java:542); at java.util.ArrayList.forEach(ArrayList.java:1251); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.consumeQueuedVariants(VariantRecalibrator.java:542); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.apply(VariantRecalibrator.java:521); at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-726406532:7079,wrap,wrapAndCopyInto,7079,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-726406532,1,['wrap'],['wrapAndCopyInto']
Integrability,can i haz integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8757:10,integrat,integration,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8757,1,['integrat'],['integration']
Integrability,ccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:635); Caused by: java.io.FileNotFoundException: File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInst,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:6025,protocol,protocol,6025,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocol']
Integrability,"ce output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes quite long, I checked the WARN messages of the output above. Especially the last one about the AVX instruction set where it says that a **MUCH** slower implementation will be used. From the few WARN messages it seems like the root cause is the failure to load libgkl and that again seems to be related to my platform. From another thread/topic I concluded that the instruction set problem might be gone if libgkl could be loaded. Does anyone know more about this issue or how to work around it?. Best regards,; Robert",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794:5514,message,messages,5514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794,2,['message'],['messages']
Integrability,"ce/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:16: note: 'isinf' declared here, later in the translation unit; if (isinf(small) == -1 || isinf(big) == -1); ^. In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:2:0:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h: In instantiation of 'static NUMBER ContextBase<NUMBER>::approximateLog10SumLog10(NUMBER, NUMBER) [with NUMBER = double]':; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:57:5: required from 'NUMBER compute_full_prob(testcase*, NUMBER*) [with NUMBER = double]'; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:115:72: required from here; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:16: error: 'isinf' was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive]; if (isinf(small) == -1 || isinf(big) == -1); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:1:; /usr/local/Cellar/gcc/5.3.0/include/c++/5.3.0/cmath:853:5: note: 'template<class _Tp> typename __gnu_cxx::__enable_if<std::__is_arithmetic<_Tp>::__value, int>::__type std::isinf(_Tp)' declared here, later in the translation unit; isinf(_Tp __f); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:2:0:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:38: error: 'isinf' was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive]; if (isinf(small) == -1 || isinf(big) == -1); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /U",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343:5666,depend,dependent,5666,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343,1,['depend'],['dependent']
Integrability,"ceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; GET https://storage.googleapis.com/storage/v1/b/fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/o?maxResults=1&prefix=5c2db926-3b1c-479c-9ed3-a99ce518de91/omics_mutect2/60955825-7723-4bc9-8202-bdd9975bb5c0/call-mutect2/Mutect2/7d737efc-c8be-4a6d-8803-4f786129521a/call-SplitIntervals/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list.idx/&projection=full&userProject; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""User project specified in the request is invalid."",; ""reason"" : ""invalid""; } ],; ""message"" : ""User project specified in the request is invalid.""; }; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:428); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1111); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:514); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:455); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.ex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716:4548,message,message,4548,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716,1,['message'],['message']
Integrability,"cf.filtered.vcf.gz \ ; --ref-version hg38 \ ; --allele-frequency-data-source gnomad --lenient true; ; ; ; ; . However, the command fails with the error message below:. ; ; ; ; [October 14, 2021 at 12:20:24 PM CEST] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 16.57 minutes. ; Runtime.totalMemory()=1134559232 ; java.lang.IllegalStateException: Duplicate key Gencode\_34\_annotationTranscript (attempted merging values ENST00000450305.2 and ENST00000456328.2) ; at java.base/java.util.stream.Collectors.duplicateKeyException(Collectors.java:133) ; at java.base/java.util.stream.Collectors.lambda$uniqKeysMapAccumulator$1(Collectors.java:180) ; at java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; at java.base/java.util.HashMap$KeySpliterator.forEachRemaining(HashMap.java:1603) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.AlleleFrequencyUtils.lambda$buildMaxMafRule$1(AlleleFrequencyUtils.java:30) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.lambda$checkFilter$0(FuncotationFilter.java:48) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(Redu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:2591,wrap,wrapAndCopyInto,2591,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['wrap'],['wrapAndCopyInto']
Integrability,cf2.BCF2Codec.decode(BCF2Codec.java:134); at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:58); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:181); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:49); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.loadNextFeature(FeatureIntervalIterator.java:98); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.loadNextNovelFeature(FeatureIntervalIterator.java:74); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.next(FeatureIntervalIterator.java:62); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.next(FeatureIntervalIterator.java:24); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:490); at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadins,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-574113941:2330,wrap,wrapAndCopyInto,2330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-574113941,1,['wrap'],['wrapAndCopyInto']
Integrability,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/296:205,depend,depends,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296,4,"['depend', 'integrat']","['depend', 'dependency', 'depends', 'integration']"
Integrability,changing the default behavior of `RScriptExecutor` from logging a warning on a failure to crashing on failure. the exception message will include output from the failed Rscript; closes #223,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/237:125,message,message,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/237,1,['message'],['message']
Integrability,che.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); 18/10/17 19:23:59 ERROR Executor: Exception in task 518.0 in stage 0.0 (TID 518); java.io.FileNotFoundException: /home/data/WGS/F002/F002.sort.bam (Too many open files); 	at java.io.FileInputStream.open0(Native Method); 	at java.io.FileInputStream.open(FileInputStream.java:195); 	at java.io.FileInputStream.<init>(FileInputStream.java:138); 	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.<init>(RawLocalFileSystem.java:106); 	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:202); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:349); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.seqdoop.hadoop_bam.util.WrapSeekable.openPath(WrapSeekable.java:60); 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:147); 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:222); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:187); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:186); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:141); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:70); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apac,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:5470,Wrap,WrapSeekable,5470,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,1,['Wrap'],['WrapSeekable']
Integrability,che.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:113); at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340); at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340); at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340); at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340); at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362); at io.netty,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:44448,Message,MessageToMessageDecoder,44448,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['Message'],['MessageToMessageDecoder']
Integrability,"ciMap.apply(TraverseLociNano.java:267); 	at org.broadinstitute.gatk.engine.traversals.TraverseLociNano$TraverseLociMap.apply(TraverseLociNano.java:255); 	at org.broadinstitute.gatk.utils.nanoScheduler.NanoScheduler.executeSingleThreaded(NanoScheduler.java:274); 	at org.broadinstitute.gatk.utils.nanoScheduler.NanoScheduler.execute(NanoScheduler.java:245); 	at org.broadinstitute.gatk.engine.traversals.TraverseLociNano.traverse(TraverseLociNano.java:144); 	at org.broadinstitute.gatk.engine.traversals.TraverseLociNano.traverse(TraverseLociNano.java:92); 	at org.broadinstitute.gatk.engine.traversals.TraverseLociNano.traverse(TraverseLociNano.java:48); 	at org.broadinstitute.gatk.engine.executive.ShardTraverser.call(ShardTraverser.java:98); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.7-0-gcfedb67):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: the number of genotypes is too large for ploidy 20 and allele 16: approx. 3247943160; ##### ERROR ------------------------------------------------------------------------------------------; ```. ---; - Original discussion with user; http://gatkforums.broadinstitute.org/gatk/discussion/comment/36309#Comment_36309; - related dsde-docs issue; https://github.com/broadinstitute/dsde-docs/issues/1744",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2946:12170,message,message,12170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2946,2,"['MESSAGE', 'message']","['MESSAGE', 'message']"
Integrability,"cker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(App",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1041,wrap,wrapper,1041,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,clearing the milestone - our alpha does not depend on this pull req.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/936#issuecomment-151705716:44,depend,depend,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/936#issuecomment-151705716,1,['depend'],['depend']
Integrability,"closes #230 . deleted useless codecs, left only TableCodec (per @ldgauthier's request), removed GenomeLoc (and reference dependency), simplified parsing code and added tests for the codec (and corresponding `TableFeature`). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/362:121,depend,dependency,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/362,1,['depend'],['dependency']
Integrability,"closes #230. deleted useless codecs, left only TableCodec (per @ldgauthier's request), removed GenomeLoc (and reference dependency), simplified parsing code and added tests for the codec (and corresponding TableFeature). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/363:120,depend,dependency,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/363,1,['depend'],['dependency']
Integrability,codeFuncotationFactory.java:1083); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653:3175,wrap,wrapAndCopyInto,3175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653,1,['wrap'],['wrapAndCopyInto']
Integrability,"come up with the right name ""ROD vs variant vs something else""; depends on issue #93",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/104#issuecomment-69785593:64,depend,depends,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/104#issuecomment-69785593,1,['depend'],['depends']
Integrability,"conf spark.io.compression.codec=lzf \; --conf spark.yarn.executor.memoryOverhead=600 \; --executor-memory ${execMem}g \; --num-executors $execs \; --executor-cores $cores \; bin/cleanHellbender/gatk/build/libs/gatk-all-*-spark.jar \; ReadsPipelineSpark \; --sparkMaster yarn-client \; -I hdfs:///user/akiezun/CEUTrio.HiSeq.WEx.b37.NA12892.bam \; -R hdfs:///user/droazen/bqsr/human_g1k_v37.2bit \; --programName ${name} \; -O $bamout \; --knownSites hdfs:////user/akiezun/dbsnp_138.b37.excluding_sites_after_129.vcf \; --emit_original_quals \; --duplicates_scoring_strategy SUM_OF_BASE_QUALITIES; ```. exec=24; cores=5; execMem=25. fails with . ```; java.lang.IllegalArgumentException: SimpleInterval is 1 based, so start must be >= 1, start: 0; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:58); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.baq.BAQ.getReferenceWindowForRead(BAQ.java:525); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine$BQSRReferenceWindowFunction.apply(BaseRecalibrationEngine.java:46); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine$BQSRReferenceWindowFunction.apply(BaseRecalibrationEngine.java:41); at org.broadinstitute.hellbender.engine.spark.BroadcastJoinReadsWithRefBases.lambda$addBases$c54addeb$1(BroadcastJoinReadsWithRefBases.java:52); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:30); at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.lambda$apply$26a6df3e$1(BaseRecalibratorSparkFn.java:30). ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1234:2080,Wrap,Wrappers,2080,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1234,2,['Wrap'],['Wrappers']
Integrability,"consider combining this code (along with `AllelicCount`/`PileupSummary`) at some point.; - [x] Added option to use matched normal.; - [ ] Rather than port over the old modeling code, I would rather expand the allele-fraction model to allow for the modeling of hom sites. I wrote up such a model in some notes I sent around a few months back. This model allows for an allelic PoN that uses all sites to learn reference bias, not just hets. Depending on how our python development proceeds, I may try to implement this model using the old `GibbsSampler` code instead.; - [x] In the meantime, we can try to speed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed the mode and highest density credible interval (because of the below item).; - [x] Some residual bias remains in the estimate of the minor-allele fraction posterior mode. This is simply because we are performing kernel density estimation of a bounded quantity. One possibility would be to logit transform to an unbounded support, perform the estimation, then transform back. EDIT: Just removed kernel density estimation for now, partly due to #3599 as well.; - Hmm, actually still a tiny bit of residual bias. This is apparent e.g. in WGS normals. I think focusing on a new allele-fraction model rather than t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:5988,Integrat,Integration,5988,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['Integrat'],['Integration']
Integrability,contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:232); 	... 22 more; Caused by: java.net.SocketTimeoutException: connect timed out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:162); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:79); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:996); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:541); 	at shaded.cloud_nio.com.google.api.client.goog,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:7339,protocol,protocol,7339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['protocol'],['protocol']
Integrability,"cotationFactory.createDefaultFuncotationsOnVariant(GencodeFuncotationFactory.java:499); 22 Jun 2023 14:54:27,163 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:217); 22 Jun 2023 14:54:27,164 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 22 Jun 2023 14:54:27,166 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:152); 22 Jun 2023 14:54:27,167 DEBUG: 		at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197); 22 Jun 2023 14:54:27,168 DEBUG: 		at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179); 22 Jun 2023 14:54:27,170 DEBUG: 		at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625); 22 Jun 2023 14:54:27,171 DEBUG: 		at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509); 22 Jun 2023 14:54:27,172 DEBUG: 		at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499); 22 Jun 2023 14:54:27,174 DEBUG: 		at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:921); 22 Jun 2023 14:54:27,175 DEBUG: 		at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 22 Jun 2023 14:54:27,177 DEBUG: 		at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:682); 22 Jun 2023 14:54:27,178 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); 22 Jun 2023 14:54:27,180 DEBUG: 		at com.github.discvrseq.walkers.ExtendedFuncotator.enqueueAndHandleVariant(ExtendedFuncotator.java:209); 22 Jun 2023 14:54:27,181 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1603412226:2793,wrap,wrapAndCopyInto,2793,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1603412226,1,['wrap'],['wrapAndCopyInto']
Integrability,cotationFactory.createFuncotationsOnSegment(GencodeFuncotationFactory.java:2866); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:239); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForSegment$2(FuncotatorEngine.java:223); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForSegment(FuncotatorEngine.java:226); at org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments.apply(FuncotateSegments.java:191); at org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments.apply(FuncotateSegments.java:59); at org.broadinstitute.hellbender.engine.FeatureWalker.lambda$traverse$0(FeatureWalker.java:99); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:647); at org.broadinstitute.hellbender.engine.FeatureWalker.traverse(FeatureWalker.java:97); at o,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314:3062,wrap,wrapAndCopyInto,3062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314,2,['wrap'],['wrapAndCopyInto']
Integrability,cotationFactory.java:1044) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:978) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:805) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:789) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:474) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:475) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:530) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFac,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651:4096,wrap,wrapAndCopyInto,4096,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651,1,['wrap'],['wrapAndCopyInto']
Integrability,count reads in spark + integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/920:23,integrat,integration,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/920,1,['integrat'],['integration']
Integrability,cram : message should say what argument to use for reference,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1288:7,message,message,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1288,1,['message'],['message']
Integrability,create .bigqueryrc to suppress warning messages; change disk size to 150,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7319:39,message,messages,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7319,1,['message'],['messages']
Integrability,ctPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1553,protocol,protocol,1553,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/221:791,depend,depend,791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221,1,['depend'],['depend']
Integrability,cvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `96.296% <0.000%> (-3.704%)` | :arrow_down: |; | [...rg/broadinstitute/hellbender/utils/SVInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/7951/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TVkludGVydmFsLmphdmE=) | `90.000% <0.000%> (-2.857%)` | :arrow_down: |; | [...ute/hellbender/tools/spark/utils/IntHistogram.java](https://codecov.io/gh/broadinstitute/gatk/pull/7951/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay91dGlscy9JbnRIaXN0b2dyYW0uamF2YQ==) | `86.335% <0.000%> (-2.484%)` | :arrow_down: |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/7951/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `93.333% <0.000%> (-0.784%)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/7951/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `66.818% <0.000%> (-0.455%)` | :arrow_down: |; | [...tructuralVariationDiscoveryArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/7951/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=com,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7951#issuecomment-1189612695:3418,integrat,integration,3418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7951#issuecomment-1189612695,1,['integrat'],['integration']
Integrability,"d=33414234, featureStartFilePosition=1403632876, featureEndFilePosition=-1})``. This is has something to do with your input file. If I am wrong and this is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (general-use/engine) dependency of ``FilterByOrientationBias`` will try to instantiate a class that does not exist. The ``sed`` was supposed to be temporary until picard was wrapped properly in GATK. But until then, it does mean that all GATK-based downstream dependencies of ``CollectSequencingArtifactMetrics`` will fail without the sed. Again, the fix is not in ``FilterByOrientationBias``. > Also, FilterByOrientationBias does not output bgzipped VCFs. So this is not in line with how GATK tools should work. . ``FilterByOrientationBias`` just farms it out to a VCF Writer. That dependency (VCF Writer) should handle that. Can you confirm, @lbergelson ? Is there an additional step to make this work that I did not know about?. > Again, FilterByOrientationBias is not production worthy and I think at this point it should get an experimental or BETA label. Only because of the ``sed`` nonsense, as near as I can tell. Definitely, BETA -- not experimental. All I'm saying is that I don't believe any code change needs to go into ``FilterByO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:2017,depend,dependency,2017,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143,1,['depend'],['dependency']
Integrability,"dException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 02:34 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:41:53 INFO TaskSetManager: Starting task 0.3 in stage 2.0 (TID 8, xx.xx.xx.xx, executor 3, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:41:53 INFO TaskSetManager: Lost task 1.1 in stage 2.0 (TID 6) on xx.xx.xx.24, executor 1: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 02:34 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:41:53 INFO TaskSetManager: Starting task 1.2 in stage 2.0 (TID 9, xx.xx.xx.25, executor 6, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:41:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.xx:45142 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:42:02 INFO TaskSetManager: Lost task 0.3 in stage 2.0 (TID 8) on xx.xx.xx.xx, executor 3: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 2]; 18/04/24 17:42:02 ERROR TaskSetManager: Task 0 in stage 2.0 failed 4 times; aborting job; 18/04/24 17:42:02 INFO TaskSchedulerImpl: Cancelling stage 2; 18/04/24 17:42:02 INFO TaskSchedulerImpl: Stage 2 was cancelled; 18/04/24 17:42:02 INFO DAGScheduler: ShuffleMapStage 2 (mapToPair at PSFilter.java:125) failed in 117.782 s due to Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most rec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:32931,Wrap,WrappedArray,32931,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Wrap'],['WrappedArray']
Integrability,de(AsciiFeatureCodec.java:70); at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:37); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:181); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:49); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.loadNextFeature(FeatureIntervalIterator.java:98); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.loadNextNovelFeature(FeatureIntervalIterator.java:74); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.next(FeatureIntervalIterator.java:62); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.next(FeatureIntervalIterator.java:24); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ; at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:490) ; at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broad,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-574329688:3747,wrap,wrapAndCopyInto,3747,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-574329688,1,['wrap'],['wrapAndCopyInto']
Integrability,deFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:152); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:924); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.stream.Refe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680:3647,wrap,wrapAndCopyInto,3647,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680,1,['wrap'],['wrapAndCopyInto']
Integrability,dependency conflict with gcloud-java-nio,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2044:0,depend,dependency,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2044,1,['depend'],['dependency']
Integrability,"dependency-name=commons-io:commons-io&package-manager=gradle&previous-version=2.7&new-version=2.14.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/broadinstitute/gatk/network/alerts). </details>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9003:1352,depend,dependabot,1352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9003,11,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,depends on #279,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/275#issuecomment-94340406:0,depend,depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/275#issuecomment-94340406,1,['depend'],['depends']
Integrability,depends on #294. the requirement is to replicate the current functionality of the walker and make all tests pass,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/423:0,depend,depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/423,1,['depend'],['depends']
Integrability,"depends on #418 (the review should be of all arguments printed by the tool, not just the tool's description)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/967#issuecomment-148113655:0,depend,depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/967#issuecomment-148113655,1,['depend'],['depends']
Integrability,depends on #731,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/732#issuecomment-128404431:0,depend,depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/732#issuecomment-128404431,1,['depend'],['depends']
Integrability,depends on https://github.com/broadinstitute/hellbender/issues/403. Tests must be in place before this ticket is attempted,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/402#issuecomment-94329734:0,depend,depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/402#issuecomment-94329734,1,['depend'],['depends']
Integrability,depends on https://github.com/broadinstitute/hellbender/issues/404 Tests must be in place before this ticket is implemented,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/399#issuecomment-94330835:0,depend,depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/399#issuecomment-94330835,1,['depend'],['depends']
Integrability,depends on https://github.com/broadinstitute/hellbender/issues/405 Tests must be in place first,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/397#issuecomment-94330937:0,depend,depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/397#issuecomment-94330937,1,['depend'],['depends']
Integrability,depends on https://github.com/broadinstitute/hellbender/issues/406 Tests must be in place first,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/395#issuecomment-94331037:0,depend,depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/395#issuecomment-94331037,1,['depend'],['depends']
Integrability,depends on https://github.com/broadinstitute/hellbender/issues/407,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/394#issuecomment-94331138:0,depend,depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/394#issuecomment-94331138,1,['depend'],['depends']
Integrability,depends on https://github.com/broadinstitute/hellbender/issues/408,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/393#issuecomment-94331235:0,depend,depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/393#issuecomment-94331235,1,['depend'],['depends']
Integrability,depends on https://github.com/broadinstitute/hellbender/issues/409,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/392#issuecomment-94331321:0,depend,depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/392#issuecomment-94331321,1,['depend'],['depends']
Integrability,depends on if it's limited to picard ports or no,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1728#issuecomment-212148858:0,depend,depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1728#issuecomment-212148858,1,['depend'],['depends']
Integrability,depends on window traversal,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/18#issuecomment-76043115:0,depend,depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/18#issuecomment-76043115,1,['depend'],['depends']
Integrability,der$PrimitiveSamReaderToSamReaderAdapter.query(SamReader.java:550); at htsjdk.samtools.SamReader$PrimitiveSamReaderToSamReaderAdapter.queryOverlapping(SamReader.java:417); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextIterator(SamReaderQueryingIterator.java:130); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.<init>(SamReaderQueryingIterator.java:69); at org.broadinstitute.hellbender.engine.ReadsPathDataSource.prepareIteratorsForTraversal(ReadsPathDataSource.java:412); at org.broadinstitute.hellbender.engine.ReadsPathDataSource.prepareIteratorsForTraversal(ReadsPathDataSource.java:389); at org.broadinstitute.hellbender.engine.ReadsPathDataSource.query(ReadsPathDataSource.java:352); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.readStream(CalibrateDragstrModel.java:915); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.lambda$null$11(CalibrateDragstrModel.java:556); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at org.broadinstitute.hellbender.tools.dragstr.InterleavingListSpliterator.forEachRemaining(InterleavingListSpliterator.java:87); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:952); at java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:926); at java.base/java.util.stream.AbstractTask.compute(AbstractTask.java:327); at java.base/java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:746); ... 5 more; ```. However it does work when running the tool single threaded with the exact same options. . #### Steps to reproduce; I've sadly been unable to create a reproducible example. I've only encountered this with non-public data which I can't share here. I'd be happy to run tests for you though.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8139:11282,wrap,wrapAndCopyInto,11282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8139,1,['wrap'],['wrapAndCopyInto']
Integrability,diff engine port and added hookup for our integration tests; +added PrintVariants as an example variant walker,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/619:42,integrat,integration,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/619,1,['integrat'],['integration']
Integrability,"disabled; 11:57:50.898 INFO GenomicsDBImport - Initializing engine; 11:57:52.588 INFO FeatureManager - Using codec BEDCodec to read file file:///mnt/isilon/experiment/resources/final_mm10_exon.bed; 11:57:53.791 INFO IntervalArgumentCollection - Processing 199895151 bp from intervals; 11:57:53.825 WARN GenomicsDBImport - A large number of intervals were specified. Using more than 100 intervals in a single import is not recommended and can cause performance to suffer. It is recommended that intervals be aggregated together.; 11:57:53.837 INFO GenomicsDBImport - Done initializing engine; 11:57:54.037 INFO GenomicsDBImport - Vid Map JSON file will be written to /mnt/isilon/experiment/18075-01/aligned/variant_calling/genomics_db/vidmap.json; 11:57:54.037 INFO GenomicsDBImport - Callset Map JSON file will be written to /mnt/isilon/experiment/18075-01/aligned/variant_calling/genomics_db/callset.json; 11:57:54.037 INFO GenomicsDBImport - Complete VCF Header will be written to /mnt/isilon/experiment/18075-01/aligned/variant_calling/genomics_db/vcfheader.vcf; 11:57:54.037 INFO GenomicsDBImport - Importing to array - /mnt/isilon/experiment/18075-01/aligned/variant_calling/genomics_db/genomicsdb_array; 11:57:54.038 INFO ProgressMeter - Starting traversal; 11:57:54.038 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 12:05:27.926 INFO GenomicsDBImport - Starting batch input file preload; 12:05:29.246 INFO GenomicsDBImport - Finished batch preload; 12:05:29.246 INFO GenomicsDBImport - Importing batch 1 with 4 samples; terminate called after throwing an instance of 'VariantStorageManagerException'; what(): VariantStorageManagerException exception : Error while syncing array chr10$3119692$3120841 to disk; TileDB error message :; ```. The filesystem is being mounted at boot time in /etc/fstab as follows:; ```; //server/share /mnt/isilon cifs uid=user,credentials=/home/user/.smbcredentials,domain=THE_DOMAIN,iocharset=utf8,sec=ntlm,vers=3.0 0 0; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5342#issuecomment-453590820:4502,message,message,4502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5342#issuecomment-453590820,1,['message'],['message']
Integrability,dle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImp,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482:1278,wrap,wrapper,1278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482,1,['wrap'],['wrapper']
Integrability,"do you know how?. On Wed, May 18, 2016 at 3:50 PM, droazen notifications@github.com wrote:. > @akiezun https://github.com/akiezun I don't think we should add yet; > another Frankenstein monster step to our build process like this. I; > recommend instead that we package the library in Broad artifactory (after; > obtaining the author's permission), and depend on it from there.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gatk/pull/1750#issuecomment-220138064",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-220142640:353,depend,depend,353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-220142640,1,['depend'],['depend']
Integrability,docker.network: workbench; traefik.port: 50075. volumes:; datanode:; namenode:. networks:; workbench:; external: true; ```; the datanodes and namenode and spark master and workers are all working.; My hardware resources are:; 16 core and 1Tb memory ssd and 56Gb ram for 3 machines. I have this problem when I launch the version(GATK) v4.0.4.0 but not with this version v4.0.2.0-4-gb59d863-SNAPSHOT:. >java.lang.IllegalStateException: Duplicate key -1; 	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); 	at java.util.HashMap.merge(HashMap.java:1253); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$mark$2142e97f$1(MarkDuplicatesSpark.java:82); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.ap,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:4131,wrap,wrapAndCopyInto,4131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['wrap'],['wrapAndCopyInto']
Integrability,"does two small things:; 1. bump the image version so that we don't get the annoying ""org.bdgenomics.adam.serialization.ADAMKryoRegistrator: Did not find Spark internal class. This is expected for Spark 1."" message; 2. name of cluster created with manage_sv_pipeline.sh now post-fixed with ""master"" or ""feature"" depending on if running master or a feature branch. @TedBrookings can you please review?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4137:206,message,message,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4137,2,"['depend', 'message']","['depending', 'message']"
Integrability,"ds but `VariantAnnotator` only has the reads. Several annotations had fallback code to annotate a likelihoods object that had no likelihoods. @vruano This is the class that you disliked so much in your recent code review of #5783 . A few issues with this state of things:. * Torturing the definition of `AlleleLikelihoods`, which forced the class to have methods like `hasLikelihoods()`.; * `VariantAnnotator` only applied the few annotations that had custom pileup-based fallback code.; * Lots more annotation code for the fallback mode. So the first step was the option that @lbergelson and @jamesemery liked most: create a regular likelihoods object in `VariantAnnotator` by hard-assigning of each read to the allele it best matches. This is exactly what all the custom fallback modes were doing in effect, but now it's implemented in one place instead of six or so. This lets us delete `UnfilledLikelihoods` and also lets `VariantAnnotator` apply any annotation. @ldgauthier Since the most non-trivial aspect is the new integration test I'm inclined to assign you the review, but a case could be made for someone on the engine team. This completely broke the `VariantAnnotator` tests, which were based on exact matches. This had been an issue before and has always been a bit of a nuisance, but now overhauling the tests became completely unavoidable. So, I rewrote all the tests and wrote a rigorous test based on concordance with annotations from `Mutect2`. If I were reviewing I would start with the new code in `VariantAnnotator` that constructs the likelihoods object from the reads and verify that it is just a more polished version of the fallback code that several annotations used to have. Then I would look at the new `VariantAnnotator` integration tests. Some of the tolerances are fairly liberal but it's worth noting that much of the old exact match ""truth"" annotations were completely bogus. This is better than what we had before by a long shot but it's still use at your own risk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6172:1269,integrat,integration,1269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6172,2,['integrat'],['integration']
Integrability,"due to recursive implementation of Legendre abscissas in Apache Commons. @vdauwera @takutosato this is very simple; it just caps the number of subdivisions of the integral to avoid the recursive stack overflow. I tested it on absurdly high coverage (100,000) and reproduced the error with the old code. Whichever one of you gets to this first should review. While this isn't the most beautiful thing in the world, it will work reasonably while new integration code is pending.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3335:448,integrat,integration,448,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3335,1,['integrat'],['integration']
Integrability,"dules, and still being able to publish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and remove if required, without any major version bump.; * `testing`: this will contain the testing framework. It is related with #1481 and #3567. ; * `documentation`: this might be useful for code dependent on `com.sun.javadoc` to do not interact with other classes if code for documenting a downstream project is not necessary.; * Other modules might be useful for concrete components: e.g, ., the gCNV python computati",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3900:1445,depend,depending,1445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900,1,['depend'],['depending']
Integrability,"e GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be passed to the CLP on construction (in `Main`) and defaults to whatever base class is chosen. This will allow custom toolkits to override in their `Main` the formatter and thus make consistent the output of every tool. Another option is to use directly something like the Spring framework, but I think that it is quite complicated for API users without knowledge of Spring (like me).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:2301,interface,interface,2301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646,1,['interface'],['interface']
Integrability,"e I have users `--disableReadFilter MateOnSameContigOrNoMappedMateReadFilter`. This latter hack is particularly germane to somatic analyses where there can be many fusion events. The `MateOnSameContigOrNoMappedMateReadFilter` filter asks HaplotypeCaller or Mutect2 to ignore reads whose mate maps to a different contig. This filter is not at the engine level but rather deep within the assembler and was made disable-able in the summer. I do not know the reasoning behind ignoring read pairs that map across chromosomes. My assumption is that (at least previously) these types of mappings tended to be artifactual and so we wanted to discount them to improve specificity. I think it prudent we assess whether this still holds true for more recent sequencing data and processing pipelines.; - For example, I also know that BWA prefers mappings that place mates within a standard insert distance, e.g. on the same contig. ; - Also, for chimeric reads produced by weird sequencer bridging reactions, we have dual barcodes that would then discount such reads in the `0x200` QCFAIL pool. **Here, I am asking for a simple feature at the engine level**; What I would like is an option for tools that employ the `MateOnSameContigOrNoMappedMateReadFilter` to count mates on what should be molecularly contiguous (but represented as different contigs in the reference) as on the same contig for ALT-aware alignments. The dictionary section of the header will indicate ALT-aware alignment with an AH tag and an asterisk if processed through MergeBamAlignment. Corresponding ALT to primary assembly pairings are given by the `.alt` file used in alt-aware alignment and post-processing and the parameter would ask for this. What this feature enables is for us to continue discounting read pairs that map across chromosomes while correctly counting read pairs split across primary assembly and ALT contigs. . - Alternatively, or additionally, it might be good to have a stand-alone tool that can change the mate pai",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3764:2610,bridg,bridging,2610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3764,1,['bridg'],['bridging']
Integrability,"e VM ubuntu. ; I downloaded gatk-4.4.0.0. Step by step, I tried to build GATK4. (https://github.com/broadinstitute/gatk/blob/master/README.md#building). I made a gitclone using ; wget https://github.com/broadinstitute/gatk. and entered gatk folder. ; there was a gradlew.; and I entered ; ./gradlew bundle ; or; ./gradlew. but it failed to build GATK4 with following errors. . ====================================; OpenJDK 64-Bit Server VM warning: Insufficient space for shared memory file:; 30934; Try using the -Djava.io.tmpdir= option to select an alternate temp location. FAILURE: Build failed with an exception. * What went wrong:; Gradle could not start your build.; > Cannot create service of type DependencyLockingHandler using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyLockingHandler() as there is a problem with parameter #2 of type ConfigurationContainerInternal.; > Cannot create service of type ConfigurationContainerInternal using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createConfigurationContainer() as there is a problem with parameter #13 of type DefaultConfigurationFactory.; > Cannot create service of type DefaultConfigurationFactory using DefaultConfigurationFactory constructor as there is a problem with parameter #2 of type ConfigurationResolver.; > Cannot create service of type ConfigurationResolver using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyResolver() as there is a problem with parameter #1 of type ArtifactDependencyResolver.; > Cannot create service of type ArtifactDependencyResolver using method DependencyManagementBuildScopeServices.createArtifactDependencyResolver() as there is a problem with parameter #4 of type List<ResolverProviderFactory>.; > Could not create service of type VersionControlRepositoryConnectionFactory using VersionControlBuildSessionServices.createVersionControlSystemFactory().; > Failed to cre",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8346:1146,Depend,DependencyResolutionScopeServices,1146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8346,1,['Depend'],['DependencyResolutionScopeServices']
Integrability,e are running on Google Compute Engine.; java.net.NoRouteToHostException: No route to host (Host unreachable); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.goo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417:1443,protocol,protocol,1443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417,3,['protocol'],['protocol']
Integrability,"e canonical name for this metric actually is, but it doesn't appear to be ""LL score""---perhaps someone else knows or has better Google-fu and can figure it out) before moving on to their methods for estimating F1. Doing a literature search for other discussions of optimizing F1 or other metrics in the context of positive-unlabeled learning might be worthwhile, but I think most methods will probably involve some sort of estimation of the base rate in unlabeled data. I think we may have to add some mechanism for holding out a validation set during training if we want to automatically tune thresholds in a rigorous fashion. Shouldn't be too bad---we can just have the training tool randomly mask out a set of the truth and pass the mask to the scoring tool (or maybe just determine the threshold in the training tool, if we are running in positive/negative mode and have access to unlabeled data)---but does add a couple of parameters to the tool interfaces. This also adds additional dependence on the quality of the truth resources. I think an implicit assumption in any use of the truth---even just thresholding/calibrating by sensitivity---is that it is a random sample; however, I'm not sure how true this is in actual use. For example, in malaria, it looks like we may have to resort to using a callset that has been very conservatively filtered as truth, which will bias us towards high scores and the peaks of the positive distribution. Perhaps we can also experiment with just treating training/truth on an equal footing (I think the distinction between the two is somewhat blurry in the original VQSR design, anyway). Perhaps @davidbenjamin has some thoughts? I see some related stuff going on in ThresholdCalculator, but I have to admit that I can't tell whether that's used in a similar PU context. Also note that depending on the model used, we might not have well calibrated posteriors---the IsolationForest simply outputs scores in a unit interval, and we simply report the differe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241:1716,depend,dependence,1716,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241,1,['depend'],['dependence']
Integrability,"e it would be nice to have the option for IGV compatibility, but I don't think the MAF format is supported by the engine nor do I know if there are plans to implement support. Perhaps @LeeTL1220 or @davidbenjamin can comment. ---. @sooheelee commented on [Wed Jan 25 2017](https://github.com/broadinstitute/gatk-protected/issues/495#issuecomment-275250701). To clarify, the CNV callset should have IGV compatibility where it displays as a heatmap (like GISTIC outputs in IGV). To this folks can overlay whatever mutation data they have, whether that be in MAF or VCF format. . ---. @samuelklee commented on [Wed Jan 25 2017](https://github.com/broadinstitute/gatk-protected/issues/495#issuecomment-275254706). Ah, gotcha. In that case it should already be relatively easy for users to create IGV-compatible output according to http://software.broadinstitute.org/software/igv/SegmentedData. Depending on which tool output they are trying to plot (CNV or ACNV), they may have to manually create files with the column order expected by IGV by removing or reordering columns, but I don't think this is unreasonable. (I think this is preferable to outputting additional 4-column segment files specifically for use with IGV, right?). ---. @samuelklee commented on [Wed Jan 25 2017](https://github.com/broadinstitute/gatk-protected/issues/495#issuecomment-275259864). Started a branch. Will have to cook up some new test data but should hopefully be relatively quick. Note that we will lose the dotted centromere indicators unless we require their locations as an additional input. ---. @sooheelee commented on [Wed Jan 25 2017](https://github.com/broadinstitute/gatk-protected/issues/495#issuecomment-275262070). I think IGV's default heatmap coloring is centered around 0 or 1, whichever CNV data isn't. As for the centromere locations, I'm not sure but perhaps [this format](http://software.broadinstitute.org/software/igv/Cytoband) can help define those for people who want to define them. I'd have to d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2853:4518,Depend,Depending,4518,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2853,1,['Depend'],['Depending']
Integrability,"e spec"". Third, although I don't know in detail about the different execution ; environments you are trying to support, there is a general strategy that ; I haven't seen discussed in these threads.; Perhaps it's impractical, but I'll mention it anyway. It seems like ; another approach would be to create (internal to the implementation) a ; ""header tag"" that could be efficiently serialized; and passed as part of the SAMRecord when you need to distribute it. The ; header tag could be used by the receiver to reattach the SAMRecord to ; its header (either proactively or on demand), but transparently to ; application code that is running against the SAMRecord API.; This would allow SAM headers to be transmitted out-of-band in a way that ; depends on the execution environment. Depending on the environment, ; this might be done by proactive broadcast, or you could think of the ; header tag as a promise to retrieve the header if/when it is needed. ; The size and complexity of the header tag might also depend on the ; execution environment. If the execution environment only supports a ; small finite number of headers, the header tag could be a small integer, ; or in a different execution environment it could be; a unique hash of the header or something like that. Memory footprint in ; the receiver is minimized because many SAMRecords can all share the same ; header object.; This requires more work to support in each execution environment, but it ; seems like it could be efficient and allows application code written to ; operate on SAMRecords to be portable; across different execution environments without having to contend with ; the possible presence of headerless SAMRecords. -Bob. On 9/17/15 4:28 PM, droazen wrote:. > @davidadamsphd https://github.com/davidadamsphd, @lbergelson ; > https://github.com/lbergelson, and myself met for an hour or two ; > just now to discuss this issue, and after reviewing all the options I ; > think we were convinced by the following argument:; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518:2038,depend,depend,2038,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518,1,['depend'],['depend']
Integrability,"e to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/12/21 13:13:16 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 18/12/21 13:13:19 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; [Stage 0:> (0 + 2) / 155]18/12/21 13:13:57 WARN scheduler.TaskSetManager: Lost task 10.0 in stage 0.0 (TID 1, scc-q15.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 2485550, span 40026, expected MD5 106b97c463c8a19ce0f92bbd488ac81d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:5015,Wrap,Wrappers,5015,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['Wrap'],['Wrappers']
Integrability,"e typically used to indicate adapter sequence. See reply to jhess in <https://gatkforums.broadinstitute.org/gatk/discussion/comment/35120#Comment_35120>:. > That's correct, Q2 bases are considered to be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3540:1145,adapter,adapter,1145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540,1,['adapter'],['adapter']
Integrability,e.StorageImpl.get(StorageImpl.java:240); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:232); 	... 22 more; Caused by: java.net.SocketTimeoutException: connect timed out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:162); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:79); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:996); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleCl,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:7269,protocol,protocol,7269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['protocol'],['protocol']
Integrability,"e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be passed to the CLP on construction (in `Main`) and defaults to whatever base class is chosen. This will allow custom toolkits to override in their `Main` the formatter and thus make consistent the output of every tool. Another option is to use ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:1642,depend,dependency,1642,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646,1,['depend'],['dependency']
Integrability,e.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://st,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084:1333,integrat,integration,1333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084,1,['integrat'],['integration']
Integrability,e.hellbender.tools.walkers.genotyper.AlleleSubsettingUtils.subsetAlleles(AlleleSubsettingUtils.java:133); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.AlleleSubsettingUtils.subsetAlleles(AlleleSubsettingUtils.java:48); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:191); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:263); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:979); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$assemblyFunction$0(HaplotypeCallerSpark.java:179); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197); 	at java.base/java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1856); 	at java.base/java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:292); 	at java.base/java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.base/java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.base/java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:298); 	at java.base/java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$ConcatenatedIterator.getTopMetaIterator(Iterators.java:1379); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$ConcatenatedIterator.hasNext(Iterators.java:1395); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.fillCache(PushToPullIterator.java:71); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.advanceToNextElement(PushToPullIterator.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8961:1640,Wrap,WrappingSpliterator,1640,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8961,1,['Wrap'],['WrappingSpliterator']
Integrability,"e.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2102919168; **java.lang.NullPointerException**; at java.util.ComparableTimSort.countRunAndMakeAscending(ComparableTimSort.java:325); at java.util.ComparableTimSort.sort(ComparableTimSort.java:202); at java.util.Arrays.sort(Arrays.java:1312); at java.util.Arrays.sort(Arrays.java:1506); at java.util.ArrayList.sort(ArrayList.java:1462); at java.util.Collections.sort(Collections.java:143); at org.broadinstitute.hellbender.utils.IntervalUtils.sortAndMergeIntervals(IntervalUtils.java:467); at org.broadinstitute.hellbender.utils.IntervalUtils.getIntervalsWithFlanks(IntervalUtils.java:965); at org.broadinstitute.hellbender.utils.IntervalUtils.getIntervalsWithFlanks(IntervalUtils.java:980); at org.broadinstitute.hellbender.engine.MultiIntervalLocalReadShard.(MultiIntervalLocalReadShard.java:59); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.makeReadShards(AssemblyRegionWalker.java:104); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:84); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203). #### Expected behavior; Exception should be catched by GATK to provide a meaningful message. #### Actual behavior; NullPointerException is thrown by java. ### Tool(s) or class(es) involved; I think this method https://github.com/broadinstitute/gatk/blob/95852a1e70300b932bad153c845003a097abbbe1/src/main/java/org/broadinstitute/hellbender/utils/GenomeLocParser.java#L517 could return null, and is not correctly handled by caller method.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7496:4757,message,message,4757,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7496,1,['message'],['message']
Integrability,e.hellbender.utils.IndexRange.shift(IndexRange.java:73). at org.broadinstitute.hellbender.utils.IndexRange.shiftLeft(IndexRange.java:77). at org.broadinstitute.hellbender.utils.read.AlignmentUtils.leftAlignIndels(AlignmentUtils.java:735). at org.broadinstitute.hellbender.tools.LeftAlignIndels.apply(LeftAlignIndels.java:78). at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96). at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.Iterator.forEachRemaining(Iterator.java:116). at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801). at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481). at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471). at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151). at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174). at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234). at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418). at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94). at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210). at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163). at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206). at org.broadinstitute.hellbender.Main.m,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6765:7222,wrap,wrapAndCopyInto,7222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6765,1,['wrap'],['wrapAndCopyInto']
Integrability,e.java:491); at org.broadinstitute.hellbender.engine.FeatureManager.getFeatures(FeatureManager.java:253); at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:162); at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:114); at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:253); at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:169); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:80); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:78); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:517); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:152); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:171); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); Caused by: java.io.IOException: Stream Closed; at java.i,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638#issuecomment-202435140:2293,wrap,wrapAndCopyInto,2293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638#issuecomment-202435140,1,['wrap'],['wrapAndCopyInto']
Integrability,"e>8a60b65</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.23.4...v3.25.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major versio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:2946,depend,dependabot,2946,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,1,['depend'],['dependabot']
Integrability,eGenotypes(GenotypingEngine.java:255); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:210); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.calculateGenotypes(GenotypeGVCFs.java:266); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.regenotypeVC(GenotypeGVCFs.java:222); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:201); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:109); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:107); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:980); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4975:2976,wrap,wrapAndCopyInto,2976,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4975,1,['wrap'],['wrapAndCopyInto']
Integrability,eGenotypes(ReferenceConfidenceVariantContextMerger.java:543); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:130); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:310); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:136); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:423); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:134); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6357:6288,wrap,wrapAndCopyInto,6288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6357,1,['wrap'],['wrapAndCopyInto']
Integrability,eGenotypes(ReferenceConfidenceVariantContextMerger.java:543); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:130); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:310); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:136); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:423); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:134); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-571886057:6242,wrap,wrapAndCopyInto,6242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-571886057,1,['wrap'],['wrapAndCopyInto']
Integrability,"ePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred deletion calls, which currently output as `DEL` with `INSSEQ` annotation, to one of these; - [x] `INS`/`DEL`, when deleted/inserted bases are < 50 bp and annotate accordingly; when type is determined as`INS`, the `POS` will be 1 base before the micro-deleted range and `END` will be end of the micro-deleted range, where the `REF` allele will be the corresponding reference bases.; - [x] two records `INS` and `DEL` when both are >= 50, share the same `POS`, and link by `EVENT`; - [ ] we are making a choice that treats duplication expansion as insertion. If decide to treat `DUP` as a separate 1st class type, we need to ; - [ ] shift the left breakpoint to the ri",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:2183,integrat,integration,2183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021,1,['integrat'],['integration']
Integrability,"eProgramTest.java:76); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:80); at org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCountsIntegrationTest.testSparkGenomeReadCounts(SparkGenomeReadCountsIntegrationTest.java:28). Caused by:; java.io.NotSerializableException: org.broadinstitute.hellbender.engine.TaggedInputFileArgument; Serialization stack:; - object not serializable (class: org.broadinstitute.hellbender.engine.TaggedInputFileArgument, value: /home/travis/build/broadinstitute/gatk-protected/src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr3_1K_11K.tiny.bam); - writeObject data (class: java.util.ArrayList); - object (class java.util.ArrayList, [/home/travis/build/broadinstitute/gatk-protected/src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr3_1K_11K.tiny.bam]); - field (class: org.broadinstitute.hellbender.cmdline.argumentcollections.OptionalReadInputArgumentCollection, name: readInputs, type: interface java.util.List); - object (class org.broadinstitute.hellbender.cmdline.argumentcollections.OptionalReadInputArgumentCollection, org.broadinstitute.hellbender.cmdline.argumentcollections.OptionalReadInputArgumentCollection@21d212c8); - field (class: org.broadinstitute.hellbender.engine.spark.GATKSparkTool, name: readArguments, type: class org.broadinstitute.hellbender.cmdline.argumentcollections.ReadInputArgumentCollection); - object (class org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts, org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts@5aef1838); - element of array (index: 0); - array (class [Ljava.lang.Object;, size 2); - field (class: java.lang.invoke.SerializedLambda, name: capturedArgs, type: class [Ljava.lang.Object;); - object (class java.lang.invoke.SerializedLambda, SerializedLambda[capturingClass=class org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts, functionalInterfaceMethod=org/apache/spark/ap",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2003:3133,interface,interface,3133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2003,1,['interface'],['interface']
Integrability,eReads(AssemblyBasedCallerUtils.java:246); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:493); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1326(HaplotypeCallerSpark.java:223); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:213); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866); at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670); at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149:2754,Wrap,Wrappers,2754,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149,1,['Wrap'],['Wrappers']
Integrability,ead.State: RUNNABLE; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	- locked <0x0000000584a63348> (a java.net.SocksSocketImpl); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1190,protocol,protocol,1190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,"eader$PrimitiveSamReaderToSamReaderAdapter.queryOverlapping(SamReader.java:417); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextIterator(SamReaderQueryingIterator.java:130); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.<init>(SamReaderQueryingIterator.java:69); at org.broadinstitute.hellbender.engine.ReadsPathDataSource.prepareIteratorsForTraversal(ReadsPathDataSource.java:412); at org.broadinstitute.hellbender.engine.ReadsPathDataSource.iterator(ReadsPathDataSource.java:336); at java.lang.Iterable.spliterator(Iterable.java:101); at org.broadinstitute.hellbender.utils.Utils.stream(Utils.java:1176); at org.broadinstitute.hellbender.engine.GATKTool.getTransformedReadStream(GATKTool.java:384); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:97); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. #### Steps to reproduce; `gatk --java-options ""-DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" CollectReadCounts -R [...].fasta -L [...].interval_list -I Sample.bam --interval-merging-rule OVERLAPPING_ONLY -O Sample.counts.hdf5` where `Sample.bam` is a symlink to a BAM-file from an NFS-mounted location. #### Possible workaround; You can create symlink for the parent directory of the target BAM-file instead. #### Expected behavior; I would expect a better error message that would help to indicate the cause behind ""Size exceeds Integer.MAX_VALUE"" exception.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7579:3185,message,message,3185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7579,1,['message'],['message']
Integrability,eam.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:5130); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180:7469,protocol,protocol,7469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180,1,['protocol'],['protocol']
Integrability,"ect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:18154,Wrap,Wrappers,18154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['Wrap'],['Wrappers']
Integrability,"ed Minutes Variants Processed Variants/Minute; 12:01:49.492 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chrM:63 the annotation MLEAC=[2, 0] was not a numerical value and was ignored; 12:01:49.505 INFO CombineGVCFs - Shutting down engine; [August 24, 2020 12:01:49 PM HKT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=6277824512; java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.makeRawAnnotationString(StrandBiasUtils.java:46); at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_StrandBiasTest.combineRawData(AS_StrandBiasTest.java:115); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:210); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); at org.broadinstitute.hellbender.tools.wal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766:6029,wrap,wrapAndCopyInto,6029,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766,1,['wrap'],['wrapAndCopyInto']
Integrability,"ed that if; you set this flag and don't set the appropriate environment or make; sure you have the right version you *will* get wrong results. ----. Here is the pip list from my environment:. cached-property 1.5.2+computecanada ; cycler 0.11.0+computecanada ; enum34 1.1.10+computecanada ; gatkpythonpackages 0.1 ; gcnvkernel 0.8 ; h5py 3.1.0+computecanada ; intel-openmp 2021.1.1+computecanada; joblib 0.14.1+computecanada ; kiwisolver 1.3.1+computecanada ; matplotlib 3.3.4+computecanada ; mkl 2021.1.1+computecanada; numpy 1.17.3+computecanada ; pandas 1.0.3+computecanada ; patsy 0.5.3+computecanada ; Pillow 8.1.2+computecanada ; pip 20.0.2 ; pymc3 3.1 ; pyparsing 3.1.0 ; python-dateutil 2.8.2+computecanada ; pytz 2023.3+computecanada ; scipy 1.1.0+computecanada ; setuptools 46.1.3 ; six 1.16.0+computecanada ; tbb 2021.1.1+computecanada; Theano 1.0.4 ; tqdm 4.19.5+computecanada ; wheel 0.34.2 ; ----. I used python 3.6.10 as suggested in gatkcondaenv.yml.template and respecting these dependencies found here setup_gcnvkernel.py:. ""theano == 1.0.4"",; ""pymc3 == 3.1"",; ""numpy >= 1.13.1"",; ""scipy >= 0.19.1"",; ""tqdm >= 4.15.0"" . ----. mkl is installed in my environment.; When I do : python -c ""import numpy ; numpy.show_config()"". I get this message:. blas_mkl_info:; libraries = ['mkl_rt', 'pthread']; library_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib/intel64']; define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]; include_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/include', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib']; blas_opt_info:; libraries = ['mkl_rt', 'pthread']; library_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib/intel64']; define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]; include_dirs = ['/cv",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8387:5974,depend,dependencies,5974,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8387,1,['depend'],['dependencies']
Integrability,ed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:112); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:113);,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:1341,protocol,protocol,1341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235,2,['protocol'],['protocol']
Integrability,ed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:2467,protocol,protocol,2467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['protocol'],['protocol']
Integrability,efConfidenceGenotypes(ReferenceConfidenceVariantContextMerger.java:543); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:130); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:310); at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:136); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:423); at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:134); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadins,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6357#issuecomment-581619640:9382,wrap,wrapAndCopyInto,9382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6357#issuecomment-581619640,1,['wrap'],['wrapAndCopyInto']
Integrability,eflectionDispatch.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); at com.sun.proxy.$Proxy2.stop(Unknown Source); at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360); at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: htsjdk.tribble.TribbleException: Exception encountered in worker thread.; at htsjdk.tribble.readers.AsynchronousLineReader.checkAndThrowIfWorkerException(AsynchronousLineReader.java:61); at htsjdk.tribble.readers.AsynchronousLineReader.readLine(AsynchronousLineReader.java:43); at htsjdk.tribble.readers.LineIteratorImpl.advance(LineIteratorImpl.java:24); at htsjdk.tribble.readers.LineIteratorImpl.advance(LineIteratorImpl.java:11); at htsjdk.samtools.util.AbstractIterator.hasNext(AbstractIterator.java:44); at htsjdk.tribble.AsciiFeatureCod,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:4112,Message,MessageHub,4112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,1,['Message'],['MessageHub']
Integrability,egalStateException: Encountered genotype with ploidy 0 but 1 alleles.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.correctGenotypePloidy(JointGermlineCNVSegmentation.java:701); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.prepareGenotype(JointGermlineCNVSegmentation.java:682); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.lambda$createDepthOnlyFromGCNVWithOriginalGenotypes$4(JointGermlineCNVSegmentation.java:666); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.ArrayList$Itr.forEachRemaining(ArrayList.java:1033); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.createDepthOnlyFromGCNVWithOriginalGenotypes(JointGermlineCNVSegmentation.java:667); at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.apply(JointGermlineCNVSegmentation.java:280); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:133); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.afterTraverse(MultiVariantWalkerGroupedOnStart.java:193); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:166); at org.broadinstitute.hellbender.engine.GATKTo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8164:1503,wrap,wrapAndCopyInto,1503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8164,1,['wrap'],['wrapAndCopyInto']
Integrability,"egarding the OutOfBoundsException. Please find below the user report:. I am running the Mutect2 pipeline on canine tumor samples in Terra, using WDL version 2.5 and GATK version 4.1.2.0. I was able to run the pipeline successfully without entering a germline resource file or VCF of common variants for contamination, however, when I did add these files in, I got the following error:. ```; java.lang.IndexOutOfBoundsException: Index: 5, Size: 5; 	at java.util.ArrayList.rangeCheck(ArrayList.java:657); 	at java.util.ArrayList.get(ArrayList.java:433); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.lambda$getGermlineAltAlleleFrequencies$31(SomaticGenotypingEngine.java:350); 	at java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:244); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 	at java.util.stream.DoublePipeline.toArray(DoublePipeline.java:506); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getGermlineAltAlleleFrequencies(SomaticGenotypingEngine.java:352); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getNegativeLogPopulationAFAnnotation(SomaticGenotypingEngine.java:335); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:141); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:250); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:324); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); 	at org.broad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098:1022,wrap,wrapAndCopyInto,1022,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098,1,['wrap'],['wrapAndCopyInto']
Integrability,"egv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.23.4...v3.25.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:3065,Depend,Dependabot,3065,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,1,['Depend'],['Dependabot']
Integrability,el.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.ja,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685:6626,protocol,protocol,6626,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685,1,['protocol'],['protocol']
Integrability,"elpful to have some very clear guidelines about how number of samples and the number of intervals within each scatter affect both runtime and memory usage. Here's what I've been able to infer from the WDL pipelines, tool docs and experimentation (though I suspect some of it is wrong):. 1. Memory usage is approximately proportional to number of samples, number of intervals, number of bias covariates and max copy number. What the docs don't say is what the default is for the number of bias covariates _and_ how to take these numbers and project an approximate memory usage. 2. It would appear that GermlineCNVCaller will, by default, attempt to use all CPU cores available on the machine. From the WDL I see that setting environment variables `MKL_NUM_THREADS` and `OMP_NUM_THREADS` seems to control the parallelism? It would be nice if `GermlineCNVCaller` took a `--threads` and then set these before spawning the python process. 3. Runtime? This would be really nice to have some guidelines around as I get wildly varying results depending on how I'm running. My experimentation is with a) 20 45X WGS samples, b) bin size = 500bp, c) running on a 96-core general purpose machine at AWS with 384GB of memory. My first attempt a) scattered the genome into 48 shards of approximately 115k bins each, representing ~50mb of genome and b) ran 24 jobs concurrently but failed to set the environment variables to control parallelism. In that attempt the first wave of jobs were still running after 24 hours and getting close to finishing up the initial de-noising epoch, with 3/24 having failed due to memory allocation failures. My second attempt, now running, scattered the genome into 150 shards, and is running 12 jobs at a time with 8 cores each and the environment variables set. On the second attempt it looks like the jobs will finish the first denoising epoch in < 1 hour each. That's far faster than the 6x reduction in runtime you might expect if a) runtime is linear in the number of bins an",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6166:1400,depend,depending,1400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6166,1,['depend'],['depending']
Integrability,emory()=1809317888; java.lang.ArrayIndexOutOfBoundsException: 2; 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyContaminationFilter(Mutect2FilteringEngine.java:64); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:518); 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:130); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverseVariants(TwoPassVariantWalker.java:74); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverse(TwoPassVariantWalker.java:27); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.ru,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6102:4014,wrap,wrapAndCopyInto,4014,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6102,1,['wrap'],['wrapAndCopyInto']
Integrability,"endencies to the conda environment in a branch and rebased on that. A few issues that I've run into or that came up in discussion with @jamesemery and @cmnbroad:. -I moved all tests that depend on R into the `python` test group (which should perhaps be renamed to `conda`). Note that some of these also fall into the `spark` test group---not sure if there is any special Spark setup done for that group, but we should make sure that they don't fail if they're not run with the conda environment. -@cmnbroad mentioned that some Picard tools that depend on R may break outside of the conda environment if the user does not have the R dependencies. -When we install R in the base image, we pull in a lot of basic dependencies (e.g., build-essential, various libraries and compilers, etc.) So when the R install is removed, it looks like many tests begin failing or hanging, perhaps because they are falling back on Java implementations (e.g., AVX PairHMM tests). We need to determine the dependencies for these tests and install them separately. Here is the list of packages that get pulled in by the R install: ```autoconf automake autotools-dev binutils bsdmainutils build-essential; bzip2-doc cdbs cpp cpp-5 debhelper dh-strip-nondeterminism dh-translations; dpkg-dev fakeroot g++ g++-5 gcc gcc-5 gettext gettext-base gfortran; gfortran-5 groff-base ifupdown intltool intltool-debian iproute2; isc-dhcp-client isc-dhcp-common libalgorithm-diff-perl; libalgorithm-diff-xs-perl libalgorithm-merge-perl libarchive-zip-perl; libasan2 libasprintf-dev libasprintf0v5 libatm1 libatomic1; libauthen-sasl-perl libblas-common libblas-dev libblas3 libbz2-dev; libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libcroco3 libcurl3; libdns-export162 libdpkg-perl libencode-locale-perl libfakeroot; libfile-basedir-perl libfile-desktopentry-perl libfile-fcntllock-perl; libfile-listing-perl libfile-mimeinfo-perl libfile-stripnondeterminism-perl; libfont-afm-perl libfontenc1 libgcc-5-dev libgdbm3 libgettextpo-dev; libget",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954:1078,depend,dependencies,1078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954,1,['depend'],['dependencies']
Integrability,ender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:131); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:106); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); 	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:163); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6790:4679,wrap,wrapAndCopyInto,4679,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790,1,['wrap'],['wrapAndCopyInto']
Integrability,ender.tools.walkers.CombineGVCFs.apply(CombineGVCFs.java:162); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:131); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:106); at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:163); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Mai,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7708:5453,wrap,wrapAndCopyInto,5453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7708,1,['wrap'],['wrapAndCopyInto']
Integrability,ender.tools.walkers.CombineGVCFs.apply(CombineGVCFs.java:162); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:131); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:106); at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:163); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Mai,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766:8228,wrap,wrapAndCopyInto,8228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766,1,['wrap'],['wrapAndCopyInto']
Integrability,ent&utm_campaign=pr+comments&utm_term=broadinstitute) | Coverage Δ | |; |---|---|---|; | [...tructuralVariationDiscoveryArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/7950/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5QXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `94.595% <ø> (-0.142%)` | :arrow_down: |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7950/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `96.296% <ø> (-3.704%)` | :arrow_down: |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/7950/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `93.333% <ø> (-0.784%)` | :arrow_down: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/7950/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `69.710% <100.000%> (+0.225%)` | :arrow_up: |; | [...er/tools/spark/sv/evidence/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/7950/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7950#issuecomment-1188387745:2253,integrat,integration,2253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7950#issuecomment-1188387745,1,['integrat'],['integration']
Integrability,ent.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 15 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:8606,protocol,protocol,8606,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['protocol'],['protocol']
Integrability,ent.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 47 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 50 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727:6900,protocol,protocol,6900,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727,1,['protocol'],['protocol']
Integrability,ent.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:209); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 68 more; ```. Also,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:10388,protocol,protocol,10388,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['protocol'],['protocol']
Integrability,equirement: existing integration tests (CollectInsertSizeMetricsTest) need to produce identical results,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/491#issuecomment-99299519:21,integrat,integration,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/491#issuecomment-99299519,1,['integrat'],['integration']
Integrability,"er and of varying scope:. -Change SliceSampler to be able to handle multimodal univariate distributions. Should just be a matter of implementing the pseudocode in Neal 2003 http://projecteuclid.org/download/pdf_1/euclid.aos/1056562461. -Add Metropolis-Hastings univariate sampler as alternative to SliceSampler. -Add Metropolis-Hastings/nested/etc. multivariate samplers as alternatives to GibbsSampler. This should only be tackled if a model/dataset necessitates it. -Implement hierarchical/multilevel models in an OOP way. Currently, the samplers operate on lists of global parameters and lists of lists of ""local"" parameters (i.e., segment-level or site-level parameters), which is a bit clunky. -Add convergence diagnostics (e.g., autocorrelation time). -Add ability to make trace plots and corner plots. -Implement more flexible discarding of burn-in. Currently, samples from all iterations are aggregated in memory. Depending on the maximum number of iterations we want to allow, it might be better to write samples to disk, only store samples in memory after burn-in, etc. so we don't run into memory issues. -Parallelization (again, only if a model/dataset necessitates it). ---. @LeeTL1220 commented on [Tue Nov 03 2015](https://github.com/broadinstitute/gatk-protected/issues/126#issuecomment-153466956). @samuelklee Do we need this for the beta release?. ---. @samuelklee commented on [Tue Nov 03 2015](https://github.com/broadinstitute/gatk-protected/issues/126#issuecomment-153471237). I'd say no to pretty much all of the points, except for whatever @davidbenjamin ends up needing to implement for the allele-fraction model (David, last time I looked at your branch there was some MH sampling going on?). Some of them will probably be relatively easy to address before beta (e.g., the first point about fixing up the SliceSampler), but I think they are low priority. The only thing that we'll definitely have to decide on for beta release is how to store/plot the MCMC chains (i.e., the",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2824:1088,Depend,Depending,1088,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2824,1,['Depend'],['Depending']
Integrability,"er.cmdline.argumentcollections.ReadInputArgumentCollection); - object (class org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts, org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts@5aef1838); - element of array (index: 0); - array (class [Ljava.lang.Object;, size 2); - field (class: java.lang.invoke.SerializedLambda, name: capturedArgs, type: class [Ljava.lang.Object;); - object (class java.lang.invoke.SerializedLambda, SerializedLambda[capturingClass=class org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts, functionalInterfaceMethod=org/apache/spark/api/java/function/Function.call:(Ljava/lang/Object;)Ljava/lang/Object;, implementation=invokeSpecial org/broadinstitute/hellbender/tools/genome/SparkGenomeReadCounts.lambda$collectReads$24c02dc7$2:(Lhtsjdk/samtools/SAMSequenceDictionary;Lorg/broadinstitute/hellbender/utils/read/GATKRead;)Lorg/broadinstitute/hellbender/utils/SimpleInterval;, instantiatedMethodType=(Lorg/broadinstitute/hellbender/utils/read/GATKRead;)Lorg/broadinstitute/hellbender/utils/SimpleInterval;, numCaptured=2]); - writeReplace data (class: java.lang.invoke.SerializedLambda); - object (class org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts$$Lambda$1140/887035829, org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts$$Lambda$1140/887035829@1a912c1e); - field (class: org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1, name: fun$1, type: interface org.apache.spark.api.java.function.Function); - object (class org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1, <function1>); at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:40); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:47); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101); at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:301); ... 23 more; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2003:4967,interface,interface,4967,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2003,1,['interface'],['interface']
Integrability,er.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:565); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1(HaplotypeCallerSpark.java:271); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); [2018-04-15T03:55Z] ip-10-0-0-57: 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1038); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1029); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:969); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1029); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661:3885,Wrap,WrappingSpliterator,3885,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661,1,['Wrap'],['WrappingSpliterator']
Integrability,"er: Missing parents: List(ShuffleMapStage 6); 18/04/24 17:40:04 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[19] at mapToPair at PSFilter.java:125), which has no missing parents; 18/04/24 17:40:04 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.2 KB, free 366.0 MB); 00:45 DEBUG: [kryo] Write: byte[]; 18/04/24 17:40:04 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KB, free 366.0 MB); 18/04/24 17:40:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.xx:42081 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:40:04 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 18/04/24 17:40:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[19] at mapToPair at PSFilter.java:125) (first 15 tasks are for partitions Vector(0, 1)); 18/04/24 17:40:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks; 00:45 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:40:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3, xx.xx.xx.25, executor 2, partition 0, PROCESS_LOCAL, 6010 bytes); 00:45 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:40:04 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 4, xx.xx.xx.23, executor 5, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:40:21 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (xx.xx.xx.24:44437) with ID 1; 18/04/24 17:40:21 INFO BlockManagerMasterEndpoint: Registering block manager xx.xx.xx.24:44322 with 366.3 MB RAM, BlockManagerId(1, xx.xx.xx.24, 44322, None); 18/04/24 17:40:27 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (xx.xx.xx.24:44439) with ID 4; 18/04/24 17:40:27 INFO BlockManagerMasterEndp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:22658,Wrap,WrappedArray,22658,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Wrap'],['WrappedArray']
Integrability,"er: Missing parents: List(ShuffleMapStage 6); 18/04/24 17:55:54 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[19] at mapToPair at PSFilter.java:125), which has no missing parents; 18/04/24 17:55:54 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.2 KB, free 366.0 MB); 00:59 DEBUG: [kryo] Write: byte[]; 18/04/24 17:55:54 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KB, free 366.0 MB); 18/04/24 17:55:54 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.16:49734 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:55:54 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 18/04/24 17:55:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[19] at mapToPair at PSFilter.java:125) (first 15 tasks are for partitions Vector(0, 1)); 18/04/24 17:55:54 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks; 00:59 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:54 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3, xx.xx.xx.25, executor 2, partition 0, PROCESS_LOCAL, 6010 bytes); 00:59 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:55:54 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 4, xx.xx.xx.16, executor 3, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:55:54 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.16:39037 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:55:54 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.25:41354 (size: 6.4 KB, free: 366.3 MB); **18/04/24 17:55:54 WARN TaskSetManager: Lost task 1.0 in stage 2.0 (TID 4, xx.xx.xx.16, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or direct",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:24062,Wrap,WrappedArray,24062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Wrap'],['WrappedArray']
Integrability,"erDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 5.0 failed 1 times, most recent failure: Lost task 1.0 in stage 5.0 (TID 12, localhost, executor driver): java.util.ConcurrentModificationException; 	at java.util.ArrayList.sort(ArrayList.java:1464); 	at org.broadinstitut",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:7115,Message,MessageHubBackedObjectConnection,7115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,"erDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:5424,Message,MessageHubBackedObjectConnection,5424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,"ergelson please comment on the following proposal. The proposal is that we would spin off native PairHMM as a separate project/repo on github and host AVX code there and have alternative implementations extend that project/repo (by creating repos that depend on the AVX one). . In other words, now we have 1 repo, broadinstitute/gatk. After the proposed change we'll have 3 repos (all BSD licensed):; 1) broadinstitute/gatk; 2) broadinstitute/nativePairHMM-AVX; 2) broadinstitute/nativePairHMM-PPC. We will duplicate the native code (AVX and PPC will be separate copies of C++ files etc) to simplify the testing burden. The parties interested in working on a specific architecture will contribute code directly to the respective architecture-specific repo and gatk will take occasional updates of those repos. The gatk repo will depend on the other two. The PPC repo will depend on the AVX repo (and any other native repos will depend on the AVX one). The avx and ppc repos will have their own build systems and unit tests against the new interface. The AVX repo will expose something like the following Java API (to be worked out in detail). ```; //Used to copy references to byteArrays to JNI from reads; public final class JNIReadDataHolderClass {; public byte[] readBases = null;; public byte[] readQuals = null;; public byte[] insertionGOP = null;; public byte[] deletionGOP = null;; public byte[] overallGCP = null;; }. //Used to copy references to byteArrays to JNI from haplotypes; public final class JNIHaplotypeDataHolderClass {; public byte[] haplotypeBases = null;; }. public interface NativePairHMMKernel extends AutoCloseable { . /**; * Function to initialize the fields of JNIReadDataHolderClass and JNIHaplotypeDataHolderClass from JVM.; * C++ code gets FieldIDs for these classes once and re-uses these IDs for the remainder of the program. Field IDs do not; * change per JVM session; *; * @param readDataHolderClass class type of JNIReadDataHolderClass; * @param haplotypeDataHolder",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864:1101,interface,interface,1101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864,1,['interface'],['interface']
Integrability,"error messages about ""tranches"" when I'm running VariantRecalibrator",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7225:6,message,messages,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7225,1,['message'],['messages']
Integrability,ers(FilterFuncotations.java:191) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.secondPassApply(FilterFuncotations.java:174) ; at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:19) ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77) ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ; at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133) ; at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497) ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75) ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40) ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085) ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:6931,wrap,wrapAndCopyInto,6931,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['wrap'],['wrapAndCopyInto']
Integrability,erver.java:2489). ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Failed to read bam header from /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; Caused by:File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:237); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:488); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:468,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:3108,protocol,protocol,3108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocol']
Integrability,eryAndPrefetch(FeatureDataSource.java:302); at org.broadinstitute.hellbender.engine.FeatureManager.getFeatures(FeatureManager.java:264); at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:162); at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:114); at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:253); at org.broadinstitute.hellbender.tools.examples.ExampleReadWalkerWithVariants.apply(ExampleReadWalkerWithVariants.java:71); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:80); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:78); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:508); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:108); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:166); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:185); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1983:2459,wrap,wrapAndCopyInto,2459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1983,1,['wrap'],['wrapAndCopyInto']
Integrability,"es Variants Processed Variants/Minute; 17:53:24.189 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location scaffold1159:34 the annotation MLEAC=[2, 0] was not a numerical value and was ignored; 17:53:31.218 INFO CombineGVCFs - Shutting down engine; [January 11, 2020 5:53:31 PM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.15 minutes.; Runtime.totalMemory()=2739404800; java.lang.IllegalStateException: The elements of the input Iterators are not sorted according to the comparator htsjdk.variant.variantcontext.VariantContextComparator; 	at htsjdk.samtools.util.MergingIterator.next(MergingIterator.java:107); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:122); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6368:5466,wrap,wrapAndCopyInto,5466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6368,1,['wrap'],['wrapAndCopyInto']
Integrability,es(FeatureContext.java:163); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:115); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:253); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:180); 	at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:6567,wrap,wrapAndCopyInto,6567,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['wrap'],['wrapAndCopyInto']
Integrability,es(FeatureContext.java:163); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:115); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:253); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:180); 	at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:5924,wrap,wrapAndCopyInto,5924,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963,2,['wrap'],['wrapAndCopyInto']
Integrability,es(FeatureContext.java:172); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:124); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:262); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:185); 	at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellb,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5968:10327,wrap,wrapAndCopyInto,10327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5968,1,['wrap'],['wrapAndCopyInto']
Integrability,"ess, I guess that what @droazen is suggesting is quite important and I appreciate the interest for making better the downstream toolkits integration. Here, a real use case: I've just started to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of mana",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:1265,wrap,wrappers,1265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646,1,['wrap'],['wrappers']
Integrability,esting.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2797:4069,Message,MessageHub,4069,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2797,2,['Message'],['MessageHub']
Integrability,ethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:175); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:157); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:404); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:46); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:55); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6086#issuecomment-519578293:3706,Message,MessageHubBackedObjectConnection,3706,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6086#issuecomment-519578293,6,['Message'],"['MessageHub', 'MessageHubBackedObjectConnection']"
Integrability,ethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6307:6027,Message,MessageHubBackedObjectConnection,6027,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6307,6,['Message'],"['MessageHub', 'MessageHubBackedObjectConnection']"
Integrability,"event was detected. I am showing the IGV screenshot for one of such calls (chr12:25398285). ![](https://gatk.broadinstitute.org/hc/user_images/46GjRo3tH-Y456j6ApIsqw.png). I am using the latest version GATK 4.2.0.0 and the following is the full Mutect2 command from the log file. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /gatk/gatk-package-4.2.0.0-local.jar Mutect2 -R ../resources/hg19.fa -L ../resources/coding\_regions.bed -I bam\_files/sample1.bam --pon ../resources/pon.vcf.gz --germline-resource ../resources/af-only-gnomad.raw.sites.hg19.vcf.gz --bam-output sample1.mutect2\_out.bam --recover-all-dangling-branches true -min-pruning 1 --min-dangling-branch-length 2 --debug --max-reads-per-alignment-start 0 --genotype-pon-sites True --f1r2-tar-gz vcf\_files/f1r2.sample1.tar.gz -O vcf\_files/unfiltered.sample1.vcf  . In the debug mode, the following log messages are generated for this region. 08:01:26.086 INFO  Mutect2Engine - Assembling chr12:**2539**8242-**2539**8320 with 14298 reads:    (with overlap region = chr12:**2539**8142-**2539**8420). I have another call with similar VAF that is detected in the vcf output(chr12:25380275). **chr12** 25380275   .    T    G    .    .     AS\_SB\_TABLE=3911,5343|26,21;DP=9485;ECNT=1;MBQ=36,36;MFRL=0,0;MMQ=42,42;MPOS=18;POPAF=7.30;TLOD=53.53     GT:AD:AF:DP:F1R2:F2R1:SB   0/1:9254,47:4.970e-03:9301:5321,21:3867,26:3911,5343,26,21. The input and the output BAMs show this call with the variant. ![](https://gatk.broadinstitute.org/hc/user_images/FVlI3WhNIzYK7NB7PakCmw.png). In the logs, it shows the detection of an active region here:. 08:01:23.642 INFO  Mutect2Engine - Assembling chr12:**2538**0238-**2538**0327 with 19912 reads:    (with overlap region = chr12:**2538**0138-**2538**0427). 08:01:24.119 INFO  EventMap - >> Events = EventMap{chr12:**2538**0275-**2538**0275 \[T\*, G\],}. 08:01:24.154 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7232:1881,message,messages,1881,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7232,1,['message'],['messages']
Integrability,executeUnparsed(AbstractGoogleClientRequest.java:419); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:347); ... 17 more; Caused by:; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:170); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); at shaded.cloud-nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); at shaded.cloud-nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); at shaded.cloud-nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:317); ... 27 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:4167,protocol,protocol,4167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,5,['protocol'],['protocol']
Integrability,"executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:49 INFO TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:49 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 1, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:25208,Wrap,Wrappers,25208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,ext.getValues(FeatureContext.java:138); at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.areClusteredSNPs(VariantFiltration.java:369); at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.filter(VariantFiltration.java:300); at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.apply(VariantFiltration.java:265); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$30(VariantWalker.java:96); at org.broadinstitute.hellbender.engine.VariantWalker$$Lambda$415/83249460.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:94); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:517); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:151); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:170); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:74); at org.broadinstitute.hellbender.CommandLi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:6969,wrap,wrapAndCopyInto,6969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,1,['wrap'],['wrapAndCopyInto']
Integrability,extracted SourceShard interface from #1708,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2023:22,interface,interface,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2023,1,['interface'],['interface']
Integrability,"fasta_dict} ;; FASTA_NAME=`basename ${ref_fasta} `; . ```. Then, instead of --reference ${ref_fasta} in calling gatk-protected, I put --reference $FASTA_NAME and the ""null"" exception went away and the program run successfully. ---. @eddiebroad commented on [Thu Dec 01 2016](https://github.com/broadinstitute/gatk-protected/issues/806#issuecomment-264264203). per @droazen : @achevali @LeeTL1220 . ---. @LeeTL1220 commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gatk-protected/issues/806#issuecomment-265342816). @eddiebroad Before this gets assigned, what version of gatk-protected are you using?; Assuming that this is a version we built (despite the name ""eddie.jar""): @achevali , can you figure out how you are reporting the error. @droazen are you sure this is not in the engine?. ---. @eddiebroad commented on [Wed Dec 07 2016](https://github.com/broadinstitute/gatk-protected/issues/806#issuecomment-265464665). @LeeTL1220 . The original JAVA JAR where I first observed the ""null"" message I presume was based off commit 3a2bb0d. At the time the project was initiated I think it was the latest commit. The original JAR where the ""null"" message was observed was gatk-protected-all-3a2bb0d-SNAPSHOT-spark_standalone.jar . Because of the ""3a2bb0d"" in the JAR file name is why I presume that it's based off commit 3a2bb0d. . From the gatk-protected repo code (and also ""gatk"" repo) I added some debug/print statements and saved to a differently named JAR ""eddie.jar"" to help me distinguish my hacking from the original JAR. . The JAVA file where I added the most helpful statements was in CommandLineProgram.java which is actually in ""gatk"" repo (not ""gatk-protected"" repo). If I look at a LOG, I can see ""EAS"" my initials and see c40e75b which appears to be a more recent commit compared to 3a2bb0d. ```; EAS in main!!!!; EAS to call instanceMain second....; EAS to call instanceMain first....; 17:28:40.295 INFO SparkGenomeReadCounts - EAS ABOUT TO CALL instanceMainPostParseArgs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2922:3718,message,message,3718,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2922,1,['message'],['message']
Integrability,"fined intervals. We have a final job that merges the resulting VCFs into one end file. That's great for VCF-creating tools, but does not work for VariantEval, since a) it aggregates data across the genome and therefore summaries per interval dont make sense, and b) it does produce an easily aggregatable product. In #6973 I authored some changes to VariantEval, which include switching it to use MultiVariantWalkerGroupedOnStart, and also creating a separate VariantEvalEngine, which contains the guts of VariantEval. I would like to do one more change, but @cmnbroad suggested I run this proposal by others here first. The core idea is to make it possible to run VariantEval over a defined set of interval(s), and then make it save that state to disk. A separate step would read those files, combine, and then do the actual aggregation step. My use case is to enable this in VariantEvalEngine and then use that capability in our non-GATK VariantQC tool. I'd be happy to enable that in the VariantEval walker or not, depending on your thoughts. Here is what happens now: VariantEval/VariantEvalEngine iterates the input VCF(s) and tracks values in StratificationManager. Once traversal is complete, onTraveralSuccess() will call finalizeReport(), which essentially takes the pre-aggregated information from StratificationManager and finalizes to make the output. Therefore if one could scatter jobs per interval, store the data from StratificationManager, and then restore/aggregate it, we could execute VariantEval/VariantQC scatter/gathered. Here is the proposal:; ; - This assumes my PR to separate VariantEvalEngine has been merged.; - In StratificationManager, create a SerializedStratificationState class. This class is responsible for gathering the relevant state of StratificationManager and would get serialized to disk using Jackson.; - StratificationManager would have a saveToDisk(), and a new constructor that accepts the Path to a serialized SerializedStratificationState object. The i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7030:1366,depend,depending,1366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7030,1,['depend'],['depending']
Integrability,fix R dependency link,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3772:6,depend,dependency,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3772,1,['depend'],['dependency']
Integrability,fix message in GATKAnnotationPluginDescription,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5444:4,message,message,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5444,1,['message'],['message']
Integrability,fix typo in AFCalculator error message,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2153:31,message,message,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2153,1,['message'],['message']
Integrability,fixed #358 ; for @droazen ; I don't see why #358 depends on @121 btw.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1502:49,depend,depends,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1502,1,['depend'],['depends']
Integrability,"fixed it by forcing the installation of numpy in the pip section, in order to bypass biopython dependencies resolution that grabs the last numpy available. patch is trivial. ```; gatkcondaenv.yml 2019-10-08 15:34:52.000000000 +0000; +++ gatkcondaenv2.yml 2020-01-21 16:17:06.777123115 +0000; @@ -21,6 +21,7 @@; - xz=5.2.3=0; - zlib=1.2.11=0; - pip:; + - numpy==1.13.3; - biopython==1.70; - bleach==1.5.0; - cycler==0.10.0; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6396#issuecomment-576770330:95,depend,dependencies,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6396#issuecomment-576770330,1,['depend'],['dependencies']
Integrability,fixes #1117; note though that removing fastutil as a direct dependency does not remove it as a indirect one and so the code still compiles and runs. Removing the indirect dependency would be a much more heroic task,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1120:60,depend,dependency,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1120,2,['depend'],['dependency']
Integrability,fixes #754. updating spark along side the dataflow jump; also updating other dependencies as well. changing GatkTestPipeline to downgrade a naming error to a warning; replacing calls to setName; replacing calls to setCoder with calls to withCoder when possible. hooking up the validation stringency for local files; fixes #745. disabling failing test and opening #774 to reenable it,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/775:77,depend,dependencies,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/775,1,['depend'],['dependencies']
Integrability,"fixes the issue where CommandLineExceptions produced no error message. added a public getUsage() method to CommandLineProgram; added a catch for these in instanceMain(), where the CommandLineProgram is in scope for printing the usage message; added a protected accessor getCommandLineParser to CommandLineProgram which guards against having an uninitialized CommandLineParser; moved the ""A USER ERROR HAS OCCURRED"" text out of the actual user exception and into the pretty printing",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2340:62,message,message,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2340,2,['message'],['message']
Integrability,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:9355,message,messages,9355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['message'],['messages']
Integrability,"font{; line-height: 1.6;; }; ul,ol{; padding-left: 20px;; list-style-position: inside;; }. ; the following graph is one site info of final filtered gvcf file. I noticed in the red  GQ is 45(relatively high), but I find AD and DP is zero(0,0;0).; ; ; ; ; ; besides, I also have another problem, why I find the site-261733 diappeared. I don't find it in the ref position.why? ,can you help me .; your bestdengziguang; ; ; ; ; ***@***.***; ; ; . ; ---- Replied Message ----; ; ; ; ; ; From ; ; ; ***@***.***>; ; ; ; ; ; Date ; ; ; 11/15/2022 04:39; ; ; ; ; To ; ; ; ; ; ***@***.***>; ; ; ; ; ; ; Cc ; ; ; ; ***@***.***>; ,; ; ; ***@***.***>; ; ; ; ; ; ; Subject ; ; ; Re: [broadinstitute/gatk] In the gvcf file, Does anyone know what this info means? (Issue #8081); ; ; ; ; ; Is there any phasing info for sites that look like that, i.e. PID and PGT tags? HaplotypeCaller will assign a lot of confidence to variants that are phased with variants that have good support. It's also possible that reads used to assemble the haplotype graph aren't high enough quality to count towards the AD, and I believe the DP here is sum(AD). (In contrast, the INFO DP for the site is based on all of the reads seen.) Here the GQ is still shockingly high. I really hate how our genotyping model behaves for haploids, but that's not the entire problem.; Do you have the reads that go with this GVCF? I could give you a more satisfactory explanation if I saw the data, even just an IGV screenshot of the area. —Reply to this email directly, view it on GitHub, or unsubscribe.You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8081#issuecomment-1314706114:458,Message,Message,458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8081#issuecomment-1314706114,2,['Message'],['Message']
Integrability,"for writing BAM files. This reduces memory usage since the reads; don't need to all be stored in memory. Also add some missing calls to addDataflowRunnerArgs in the integration; tests to ensure the correct dataflow runner is being picked up. This is related to https://github.com/broadinstitute/hellbender/issues/771, for the Spark/Hadoop side.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/845:165,integrat,integration,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/845,1,['integrat'],['integration']
Integrability,forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.util.concurrent.ExecutionException: org.broadinstitute.hellbender.exceptions.GATKException: Expected message of length 3 but only found 0 bytes; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.waitForAck(StreamingProcessController.java:228); 	... 26 more; Caused by: org.broadinstitute.hellbender.exceptions.GATKException: Expected message of length 3 but only found 0 bytes; 	at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.getBytesFromStream(StreamingProcessController.java:261); 	at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.lambda$waitForAck$0(StreamingProcessController.java:208); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). but if I change memory as below: it works. ; q,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147:3543,message,message,3543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147,1,['message'],['message']
Integrability,"form(name='psi_t', lower=psi_min, upper=psi_max, shape=T); depth_s = Uniform(name='depth_s', lower=depth_min, upper=depth_max, shape=N); ; z_su = Normal(name='z_us', mu=0., sd=1., shape=(N, D)); W_tu = Normal(name='W_tu', mu=0., sd=1. / sqrt(alpha_u), shape=(T, D)); mu_st = Deterministic(name='mu_st', var=z_su.dot(W_tu.T) + m_t); b_st = Normal(name='b_st', mu=mu_st, sd=sqrt(psi_t), shape=(N, T)); n_ts = Poisson(name='n_ts', mu=depth_s * exp(b_st).T, observed=n_ts_data); ; fit_pm = pm.variational.advi(model=model, n=num_iterations, learning_rate=learning_rate, random_seed=random_seed, eval_elbo=eval_elbo_iterations); ```. @eitanbanks @droazen @lbergelson @LeeTL1220 @ldgauthier @yfarjoun This is just one example of how using recently developed ML frameworks could make our lives orders of magnitude easier. The sooner we can develop a strategy to leverage these in Java land, the better!. I'd expect that roughly the same amount of code would be needed to specify this model using Stan. Interfaces for Stan exist for many other languages, so it might be relatively easy to come up with some Java bindings. However, one downside is that Stan is not built on top of a computational graph (e.g., theano/tensorflow), so we don't get GPU/distributed computing for free. I don't think this is a deal breaker, but it's something we should consider. ---. @samuelklee commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1038#issuecomment-302429919). It should be said that I consider this a major blocker for the CNV team. I don't think it makes sense to rebuild the somatic pipeline to include the new coverage model until we move to this ADVI framework or something like it. I do think @mbabadi should continue adding features (such as common CNV calling) to his non-ADVI germline implementation, so that we can be in a position to start calling on gnomAD or other large cohorts, but that we should eventually move the germline tool over to this framework as well.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2984:3523,Interface,Interfaces,3523,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2984,1,['Interface'],['Interfaces']
Integrability,"fter which the usual modelling and smoothing steps are performed. For the 75% tumor + 25% normal mixture, this yields 122 segments (up from 83):; ![N-25-T-75-SJS modeled](https://user-images.githubusercontent.com/11076296/76558618-015bd180-6474-11ea-996a-48d39770149b.png). For the 25% tumor + 75% normal mixture, this yields 105 segments (up from 50):; ![N-75-T-25-SJS modeled](https://user-images.githubusercontent.com/11076296/76560726-34a05f80-6478-11ea-9027-a54726c46b9e.png). One could imagine that smoothing could be disabled (so that all samples retain the common segmentation after modeling) or made more aggressive (so that private events don't get inadvertently introduced into other samples due to noise, perhaps), depending on the use case. It looks like the joint segmentation allows some additional events to be resolved, although I haven't done any rigorous evaluations. We could probably cook up some evaluations using simulated toy data or in silico mixtures, but there's really no reason why this shouldn't work decently well, especially if the kernel-segmentation method works well on a single sample for your data. It would also be interesting to understand at which point changing segmentation parameters on a single sample can no longer yield the same performance as joint segmentation on a fixed number of samples; however, this is probably a function of various S/N ratios, and it might not be easy to characterize this behavior outside of toy data. The segmentation parameter space is big enough to make this unwieldy even for toy data, too. Perhaps we can get some feedback from test users---not only on performance, but also on the structure of the new workflow. It might also be worth gauging whether a new WDL is warranted. Otherwise, we just need to add some unit tests for correctness of the multisample-segmentation backend class, integration tests for plumbing of the new tool, and perhaps address some of the issues mentioned above. Then I'd say this is good to go.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598386823:2996,integrat,integration,2996,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598386823,1,['integrat'],['integration']
Integrability,future proofing our R dependency references,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3352:22,depend,dependency,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3352,1,['depend'],['dependency']
Integrability,g on Google Compute Engine.; java.net.ConnectException: Connection refused (Connection refused); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); 	at shaded.cloud_ni,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:2375,protocol,protocol,2375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['protocol'],['protocol']
Integrability,g.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:137); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:113); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:496); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:387); at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:892); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hel,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385137363:5847,wrap,wrapAndCopyInto,5847,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385137363,1,['wrap'],['wrapAndCopyInto']
Integrability,g.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1025); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(Da,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680:2057,wrap,wrapAndCopyInto,2057,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680,1,['wrap'],['wrapAndCopyInto']
Integrability,g.gradle.launcher.bootstrap.EntryPoint.run(EntryPoint.java:45); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54); at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35); at org.gradle.launcher.GradleMain.main(GradleMain.java:23); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:129); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: org.gradle.api.UncheckedIOException: java.io.IOException: Disk quota exceeded; at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:58); at org.gradle.cache.internal.btree.CachingBlockStore.close(CachingBlockStore.java:40); at org.gradle.cache.internal.btree.FreeListBlockStore.close(FreeListBlockStore.java:60); at org.gradle.cache.internal.btree.StateCheckBlockStore.close(StateCheckBlockStore.java:41); at org.gradle.cache.internal.btree.BTreePersistentIndexedCache.close(BTreePersistentIndexedCache.java:195); ... 60 more; Caused by: java.io.IOException: Disk quota exceeded; at java.io.RandomAccessFile.close0(Native Method); at java.io.RandomAccessFile.close(RandomAccessFile.java:645); at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:56); ... 64 more; Could not stop Service PluginResolutionServiceClient at Bui,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:14102,Wrap,WrapperExecutor,14102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,1,['Wrap'],['WrapperExecutor']
Integrability,g.gradle.launcher.bootstrap.EntryPoint.run(EntryPoint.java:45); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54); at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35); at org.gradle.launcher.GradleMain.main(GradleMain.java:23); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:129); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: org.gradle.api.UncheckedIOException: java.io.IOException: Disk quota exceeded; at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:58); at org.gradle.cache.internal.btree.CachingBlockStore.close(CachingBlockStore.java:40); at org.gradle.cache.internal.btree.FreeListBlockStore.close(FreeListBlockStore.java:60); at org.gradle.cache.internal.btree.StateCheckBlockStore.close(StateCheckBlockStore.java:41); at org.gradle.cache.internal.btree.BTreePersistentIndexedCache.close(BTreePersistentIndexedCache.java:195); ... 60 more; Caused by: java.io.IOException: Disk quota exceeded; at java.io.RandomAccessFile.close0(Native Method); at java.io.RandomAccessFile.close(RandomAccessFile.java:645); at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:56); ... 64 more; Could not stop org.gradle.cache.internal.DefaultMultiProces,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:7277,Wrap,WrapperExecutor,7277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,1,['Wrap'],['WrapperExecutor']
Integrability,g.gradle.launcher.bootstrap.EntryPoint.run(EntryPoint.java:45); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54); at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35); at org.gradle.launcher.GradleMain.main(GradleMain.java:23); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:129); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: org.gradle.api.UncheckedIOException: java.io.IOException: Disk quota exceeded; at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:58); at org.gradle.cache.internal.btree.CachingBlockStore.close(CachingBlockStore.java:40); kStore.java:60); at org.gradle.cache.internal.btree.StateCheckBlockStore.close(StateCheckBlockStore.java:41); at org.gradle.cache.internal.btree.BTreePersistentIndexedCache.close(BTreePersistentIndexedCache.java:195); ... 64 more; Caused by: java.io.IOException: Disk quota exceeded; at java.io.RandomAccessFile.close0(Native Method); at java.io.RandomAccessFile.close(RandomAccessFile.java:645); at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:56); ... 68 more. FAILURE: Build failed with an exception.; - What went wrong:; org.gradle.api.UncheckedIOException: java.io.IOException: Disk quota ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:21485,Wrap,WrapperExecutor,21485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,1,['Wrap'],['WrapperExecutor']
Integrability,"g/hc/en-us/community/posts/4408348163227-FilterFuncotations-Duplicate-key-error). \--. Hello,. I'm using the `FilterFuncotations` to process the output from the `Functotator` as per this WARP \[pipeline\]( [warp/AnnotationFiltration.wdl at cec97750e3819fd88ba382534aaede8e05ec52df · broadinstitute/warp (github.com)](https://github.com/broadinstitute/warp/blob/cec97750e3819fd88ba382534aaede8e05ec52df/pipelines/broad/annotation_filtration/AnnotationFiltration.wdl)). . ; ; ; ; /home/azzaea/software/gatk/gatk-4.2.2.0/gatk --java-options ""-Xmx3072m"" \ ; FilterFuncotations \ ; --variant /scratch/FPTVM/src/warp/pipelines/broad/annotation\_filtration/cromwell-executions/AnnotationFiltration/4e3bd06b-3018-4c94-ac98-feb78b924d1f/call-FilterFuncotations/shard-0/inputs/1333115969/104566-001-001.filtered.vcf.funcotated.vcf.gz \ ; --output 104566-001-001.filtered.vcf.filtered.vcf.gz \ ; --ref-version hg38 \ ; --allele-frequency-data-source gnomad --lenient true; ; ; ; ; . However, the command fails with the error message below:. ; ; ; ; [October 14, 2021 at 12:20:24 PM CEST] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 16.57 minutes. ; Runtime.totalMemory()=1134559232 ; java.lang.IllegalStateException: Duplicate key Gencode\_34\_annotationTranscript (attempted merging values ENST00000450305.2 and ENST00000456328.2) ; at java.base/java.util.stream.Collectors.duplicateKeyException(Collectors.java:133) ; at java.base/java.util.stream.Collectors.lambda$uniqKeysMapAccumulator$1(Collectors.java:180) ; at java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; at java.base/java.util.HashMap$KeySpliterator.forEachRemaining(HashMap.java:1603) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.u",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:1759,message,message,1759,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['message'],['message']
Integrability,"gatk-4.4.0.0 out there and still, `gatk HaplotypeCaller --sample-name 7-Wu-FF ...` bails on me with:. `A USER ERROR has occurred: Argument --sample_name has a bad value: Specified name does not exist in input bam files`. Indeed, there is not `@RG` line at all, how how about adding an extra error/warning message somewhere more above in the code path?. ```; $ samtools view -H 7-Wu-FF.sorted.bam; @HD VN:1.6 SO:coordinate; @SQ SN:7-Wu-FF LN:443; @PG ID:bwa PN:bwa VN:0.7.17-r1188 CL:bwa mem -t 32 -o exact_matches/7-Wu-FF.sam 7-Wu-FF.fasta 7-Wu-FF_R1.fastq.gz 7-Wu-FF_R2.fastq.gz; @PG ID:samtools PN:samtools PP:bwa VN:1.17 CL:samtools sort 7-Wu-FF.sorted.bam 7-Wu-FF.sam; @PG ID:samtools.1 PN:samtools PP:samtools VN:1.17 CL:samtools view -H 7-Wu-FF.sorted.bam; $; ```. Like others I agree that if there are no samples found by GATK then *all* data should be used. I also think that `@SQ SN:` is enough for a sanity check. No need for `@RG SN:` tag. Finally, fix the `--sample_name` with `--sample-name` in the error message output, the old syntax with an underscore is not accepted anymore.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6501#issuecomment-1832051700:305,message,message,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6501#issuecomment-1832051700,2,['message'],['message']
Integrability,"gatk3. . ```; java.lang.IndexOutOfBoundsException: Index: 0, Size: 0; 	at java.util.ArrayList.rangeCheck(ArrayList.java:653); 	at java.util.ArrayList.get(ArrayList.java:429); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:270); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:204); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.regenotypeVC(GenotypeGVCFs.java:174); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:157); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:664); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2530:1301,wrap,wrapAndCopyInto,1301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2530,1,['wrap'],['wrapAndCopyInto']
Integrability,gcc should be listed in the README as required dependency for running GATK,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6012:47,depend,dependency,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6012,1,['depend'],['dependency']
Integrability,"ge 15.0 (TID 29448) in 2653 ms on scc-q03.scc.bu.edu (executor 6) (50/70); 18/02/23 23:06:23 WARN scheduler.TaskSetManager: Lost task 27.0 in stage 15.0 (TID 29438, scc-q13.scc.bu.edu, executor 7): org.broadinstitute.hellbender.exceptions.GATKException: Erred when inferring breakpoint location and event type from chimeric alignment:; asm010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.sc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:2006,Wrap,WrappingSpliterator,2006,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['Wrap'],['WrappingSpliterator']
Integrability,"ge tested against the workflow (#8062); - VS-637 Address a couple of issues in SampleLoadStatus handling in GVSImportGenomes. (#8052); - Revert Alpinizing of apt dependent task [VS-688] (#8065); - Fix missing vat schema JSONs [VS-699] (#8072); - Fix integration expectations for fixed AD [VS-689] (#8066); - VS-698 Remove unnecessary columns from Call set statistics (#8073); - Fix Dockerfile nits that break 20.10.21 (#8078); - Nirvana 3.18.1 Docker images support [VS-661] (#8082); - Add option to not prepare __REF_DATA or __SAMPLES tables to Prepare [VS-697] (#8079); - ""build-base"" Docker image for faster variantstore image builds [VS-712] (#8085); - GVS / Hail VDS integration test [VS-639] (#8086); - Remove AI/AN from VDS docs [VS-726] (#8096); - Add flag for cost_observability table writing to support sub-cohort use case [VS-521] (#8093); - Document STS delivery process for VDS [VS-727] (#8101); - delete obsolete callset_QC directory and its contents [VS-318] (#8108); - doc link typo and add check for control samples in AVRO export (#8110); - Add defaults for scatter_count in GvsExtractCohortFromSampleNames [VS-496] (#8109); - Escape table names properly in ValidateVat WDL (#8116); - Vs 741 fix indefinite freeze in split intervals task when using exome data (#8113); - VAT Readme updates (#8090); - WDL and python scripts to use the VDS in the VAT (#8077); - VS-757 - Use JASIX to make sub-jsons of annotated output of Nirvana (#8133); - add note about permissions for P&S workflow to work (#8135); - VS-759 (and VS-760) (#8137); - VS-765. Scatter the RemoveDuplicates task. (#8144); - update delivery docs based on latest VDS delivery run [VS-770] (#8150); - Add monitoring to index vcf (#8151); - Make some noise when VDS validation succeeds (#8155); - Handle empty genes annotation file. (#8153); - Add escapes for otherwise problematic dataset / table names. (#8162); - New WDL to create VAT tsvs from previously generated BigQuery table. (#8165); - Treat withdrawn samples in ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:30397,integrat,integration,30397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['integrat'],['integration']
Integrability,"genomicsdb_array; 17:00:54.470 INFO ProgressMeter - Starting traversal; 17:00:54.470 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 17:00:54.488 INFO GenomicsDBImport - Importing batch 1 with 1 samples; terminate called after throwing an instance of 'FileBasedVidMapperException'; what(): FileBasedVidMapperException : type_index_iter != VidMapper::m_typename_string_to_type_index.end() && ""Unhandled field type""; [login1:01909] *** Process received signal ***; [login1:01909] Signal: Aborted (6); [login1:01909] Signal code: (-6); [login1:01909] [ 0] /lib64/libpthread.so.0[0x30bfa0f7e0]; [login1:01909] [ 1] /lib64/libc.so.6(gsignal+0x35)[0x30bf6325e5]; [login1:01909] [ 2] /lib64/libc.so.6(abort+0x175)[0x30bf633dc5]; [login1:01909] [ 3] /apps/GCC/6.3.0/lib64/libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0x15d)[0x7f507f7018ed]; [login1:01909] [ 4] /apps/GCC/6.3.0/lib64/libstdc++.so.6(+0x8e8a6)[0x7f507f6ff8a6]; [login1:01909] [ 5] /apps/GCC/6.3.0/lib64/libstdc++.so.6(+0x8e8f1)[0x7f507f6ff8f1]; [login1:01909] [ 6] /apps/GCC/6.3.0/lib64/libstdc++.so.6(+0x8eb08)[0x7f507f6ffb08]; [login1:01909] [ 7] /apps/GENOMICSDB/0.9.2/lib/libtiledbgenomicsdb.so(+0x151df1)[0x7f507fb56df1]; [login1:01909] [ 8] /apps/GENOMICSDB/0.9.2/lib/libtiledbgenomicsdb.so(+0x1434d9)[0x7f507fb484d9]; [login1:01909] [ 9] /apps/GENOMICSDB/0.9.2/lib/libtiledbgenomicsdb.so(+0x1489f9)[0x7f507fb4d9f9]; [login1:01909] [10] /apps/GENOMICSDB/0.9.2/lib/libtiledbgenomicsdb.so(+0x12c78e)[0x7f507fb3178e]; [login1:01909] [11] /apps/GENOMICSDB/0.9.2/lib/libtiledbgenomicsdb.so(+0x12d7b4)[0x7f507fb327b4]; [login1:01909] [12] /apps/GENOMICSDB/0.9.2/lib/libtiledbgenomicsdb.so(+0x11f80d)[0x7f507fb2480d]; [login1:01909] [13] /apps/GENOMICSDB/0.9.2/lib/libtiledbgenomicsdb.so(Java_com_intel_genomicsdb_GenomicsDBImporter_jniSetupGenomicsDBLoader+0x98)[0x7f507fb99c78]; [login1:01909] [14] [0x7f50f1015814]; [login1:01909] *** End of error message ***. Thanks in advance!. Cristina.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4514:5160,message,message,5160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514,1,['message'],['message']
Integrability,"ger:54 - Lost task 1.1 in stage 0.0 (TID 3) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2, partition 9, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 0, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:28110,Wrap,Wrappers,28110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"ger:54 - Lost task 1.1 in stage 0.0 (TID 4) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 6, scc-q01.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:52 WARN TaskSetManager:66 - Lost task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 2, start 131325815, span 181534, expected MD5 c240a972d49aa89fb57dae94d1d90d36; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:29135,Wrap,Wrappers,29135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,"gic, I prefer not to do it this way, because we can add more logics in the future, and capturing/resolving these BND's that are not suitable for _THIS PARTICULAR_ logic. I guess in general my personal preference is to put less algorithm-related information in VCF for analysts (less reading for them), and produce add on files for tool developers. What's your thoughts?. > Does this even have to be a spark tool? It looks like you are just reading the variants into a parallel spark context, filtering, and then collecting them to actually process them. Why not just make this a non-spark tool and process it all in memory on one node?. Answer: Agree. It doesn't have to be, at least in theory, and it probably is going to be faster as we don't need to incur the Spark overhead for such a typically small job. But (I'm saying too many buts....) up to this point all SV tools are under the package `hellbender.tools.spark.sv`, so I'm following suit here. Note the two classes's main interface methods mentions nothing about RDDs (that's on purpose). ; On the other hand, this is an engineering question I believe, and it depends on whether we want to put as much of discovery code as possible into `StructuralVariationDiscoveryPipelineSpark` (the last commit actually hooks the two classes into it, so a single invocation of the tool produces more variants), or we go wdl in pipelining the whole process. -------. All in all, I think the comments and critics are generally about the ""filtering""/""classifying"" part, and the most serious concern about it is false negatives. Am I understanding correctly? If so, given that the filtering step is only picking the BND's that are suitable to the linking logic, I can imagine the false negative problem be solved in the future by other logics (e.g. more relaxed requirement on pair matching, or not even requiring matching INV55/INV33 pairs, etc.) In fact, that's what I'm planning on.; Another part of the problem is how much I can accomplish in this single",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4789#issuecomment-406483929:6140,interface,interface,6140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4789#issuecomment-406483929,1,['interface'],['interface']
Integrability,"git clone https://github.com/lindenb/jbwa. and make, error message is:. ksw.c:29:23: fatal error: emmintrin.h: No such file or directory; # include <emmintrin.h>. ^; compilation terminated.; make[1]: **\* [ksw.o] Error 1; make[1]: Leaving directory `/home/dlspark/gatk/lib/jbwa/bwa-8e2da1e407972170d1a660286f07a3a3a71ee6fb'; make: **\* [bwa-8e2da1e407972170d1a660286f07a3a3a71ee6fb/libbwa.a] Error 2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1870:59,message,message,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1870,1,['message'],['message']
Integrability,"gments` optionally takes denoised copy ratio and/or allelic counts, `PlotModeledSegments` outputs only the corresponding plots appropriately.; - I added a dependency on the R package `data.table` to slightly speed up the reading of input files.; - Setting `pch="".""` also sped up the generation of scatter plots.; - Plotting now takes a couple of minutes, most of which is I/O (#3554).; - AAF (rather than MAF) is now plotted for allele fraction (#2957). Other:; - I've introduced a `LocatableCollection` class to unify how allelic counts, copy ratios, and segments are stored and read/written from/to TSV (#2836). Intervals are always output in lexicographical order for now, to be consistent with the old coverage collection (#2951). Once @asmirnov239's `CollectReadCounts` is in, we can change everything over to ordering determined by the sequence dictionary.; - Column headers and log2 copy ratio output have been standardized throughout (#2886).; - [x] I've also introduced a `NamedSampleFile` abstract class to tag files that have `#SAMPLE_NAME=...` as the first comment line. For `CollectAllelicCounts`, this simply uses code borrowed from `GetSampleName`. We should unify the reading and storing of sample names at some point (#2910).; - [x] We will need to replace `SimpleReadCountCollection` (which currently serves as the interface between the old coverage collection files and the new code) with one of these subclasses when `CollectReadCounts` is in. We can also change `NamedSampleFile` depending on what he's implemented.; - [x] We should eventually write proper SAM headers with useful tags to all TSV and HDF5 files generated by our tools that represent annotated intervals that can be associated with a single sample. Documentation:; - [x] I need to update class javadoc and example invocations throughout. The initial PR will already be quite massive, so I'll leave this until later. Perhaps @sooheelee might want to be involved?; - [ ] I will update the white paper at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:10316,interface,interface,10316,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,2,"['depend', 'interface']","['depending', 'interface']"
Integrability,gnomADaccuracyTest.SynDip.vcf.gz; 	at htsjdk.variant.vcf.AbstractVCFCodec.decodeLine(AbstractVCFCodec.java:281); 	at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:262); 	at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:64); 	at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:70); 	at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:37); 	at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.readNextRecord(TribbleIndexedFeatureReader.java:372); 	at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:353); 	at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:314); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359849134:1519,wrap,wrapAndCopyInto,1519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359849134,1,['wrap'],['wrapAndCopyInto']
Integrability,googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://stor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084:1557,integrat,integration,1557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084,1,['integrat'],['integration']
Integrability,"gradle builds the dependency cache archive while online, and then builds a package using this archive while offline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6395#issuecomment-584455056:18,depend,dependency,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6395#issuecomment-584455056,1,['depend'],['dependency']
Integrability,"gradle gives when we updated to 7.3.2. . When running `bundle`; ex:; ```; Task :sparkJar; Execution optimizations have been disabled for task ':sparkJar' to ensure correctness due to the following reasons:; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/classes/java/main'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/resources/main'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/tmp/sparkJar/MANIFEST.MF'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; ```. ```; Deprecated Gradle features were used in this build, making it incompatible with Gradle 8.0. You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins. See https://docs.gradle.org/7.3.2/userguide/command_line_interface.html",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7625:1056,depend,depending,1056,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7625,1,['depend'],['depending']
Integrability,gradle.build task shadowJar should depend on localJar and not vice versa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2724:35,depend,depend,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2724,1,['depend'],['depend']
Integrability,"gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(Buffere",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1109,wrap,wrapper,1109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,"gumentParser.java:384); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.parseArgs(CommandLineProgram.java:217); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:191); > 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); > 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); > 	at org.broadinstitute.hellbender.Main.main(Main.java:239); > 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); > 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); > 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); > 	at java.lang.reflect.Method.invoke(Method.java:498); > 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:733); > 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:177); > 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:202); > 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:116); > 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala). Actually, I just re-checked and i'm not sure my solution `--conf 'spark.submit.deployMode=cluster'` works well. I'm currently testing it. My current command is:; > /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --sparkRunner SPARK --sparkMaster yarn --conf 'spark.submit.deployMode=cluster' --javaOptions -Dmapr.library.flatclass. I need the `-Dmapr.library.flatclass` because our spark is using a mapr filesystem and I was getting error about JNI library linkage.; However, the paths of files are given with `hdfs://spark01:7222` because I get a protocol error when I set `maprfs://` instead. Don't bother with it right now, I'm going to open another issue about it :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350038452:2490,protocol,protocol,2490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350038452,1,['protocol'],['protocol']
Integrability,"h a stack trace:; ```; code: 401; message: Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.; reason: required; location: Authorization; retryable: false; com.google.cloud.storage.StorageException: Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:220); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:415); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:198); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:195); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89); at com.google.cloud.RetryHelper.run(RetryHelper.java:74); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:195); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:673); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:429); at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); ```. ```; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 401 Unauthorized; {; ""code"" : 401,; ""errors"" : [ {; ""domain"" : ""global"",; ""location"" : ""Authorization"",; ""locationType"" : ""header"",; ""message"" : ""Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram."",; ""reason"" : ""required""; } ],; ""message"" : ""Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.""; }; ```. ### Desired; Something like ""Unable to read gs://joel-cram/SAM24339124.cram due to permissions. Have you enabled Google Cloud Application Default Credentials by running 'gcloud auth application-default login'? See [this forum post] for details.""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5468:2038,message,message,2038,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5468,2,['message'],['message']
Integrability,h.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Host is down (connect failed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCrede,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:1154,protocol,protocol,1154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235,1,['protocol'],['protocol']
Integrability,"h/supportingMultiA.vcf; > ; > which outputs:; > INFO field at 1:768589 .. INFO tag [AC=1] expected different number of; > values (expected 2, found 1),INFO tag [AF=0.00047] expected different; > number of values (expected 2, found 1); > Notes; > ; > Currently, all the validation modes call out to HTSJDK. Do we want to put; > the new functionality there as well?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1053. ---. @ldgauthier commented on [Fri Jul 17 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122308040). Today I learned that the way we currently build GATK, you can't point to a local htsjdk jar anymore, so this task will be two-fold:; 1) Make a PR to htsjdk with a new function in the VariantContext class for validateInfoFieldCounts(VCFInfoHeaderLine headerLine) or similar; add a test to VariantContextUnitTest.java; 2) After change 1) is merged, update ValidateVariants accordingly to use the new function and add a test to its integration tests. ---. @vdauwera commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222213763). @ldgauthier is this still a thing? (in the sense of not having been addressed in htsjdk). ---. @ldgauthier commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222214083). Still a thing. No work has been done here AFAIK. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-260465013). This seems like fairly low-hanging fruit -- @ronlevine . ---. @ronlevine commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613152). @ldgauthier Shouldn't a locus without genotypes bypass `AC` validation, given it's defined as: `Allele count in genotypes, for each ALT allele, in the same order as listed`?. ---. @ldgauthier commented on [Wed No",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:4596,integrat,integration,4596,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['integrat'],['integration']
Integrability,hangFixingManager.java:445) ; ; at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.splitNCigarRead(SplitNCigarReads.java:212) ; ; at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.lambda$traverseReads$1(SplitNCigarReads.java:181) ; ; at org.broadinstitute.hellbender.engine.MultiplePassReadWalker.lambda$forEachRead$0(MultiplePassReadWalker.java:60) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; ; at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418) ; ; at org.broadinstitute.hellbender.engine.MultiplePassReadWalker.forEachRead(MultiplePassReadWalker.java:58) ; ; at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.traverseReads(SplitNCigarReads.java:180) ; ; at org.broadinstitute.hellbender.engine.MultiplePassReadWalker.traverse(MultiplePassReadWalker.java:74) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ; at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6776:32498,wrap,wrapAndCopyInto,32498,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776,1,['wrap'],['wrapAndCopyInto']
Integrability,"hat I'm thinking about, is two pass:; one pass for splitting them up into the 3 classes,; then another pass on each of those 3 RDD's to turn them into VariantContext's.; Any better idea?. Reply by @cwhelan ; > That would be better, and yeah you don't have to do it in this PR.; In theory you could make the keys for the groupByKey() (ie NovelAdjacencyAndAltHaplotype, CpxVariantCanonicalRepresentation, right?) all inherit from the same superclass and do a single group by, couldn't you? Then you could do everything in a single pass. Reply by @SHuang-Broad; > Yes, that is what I'm planning but I'm not sure yet about how to approach that (I actually tried it, before putting in the above comment, and quickly ran into the problem of mixing Java serialization and Kryo serialization, so a larger re-structuring might be needed, and not just a inheritance structure). ------------; ### On the problem of having a confusing TODO for ; `boolean SimpleChimera.isCandidateInvertedDuplication()`. The todo message. > TODO: 5/5/18 Note that the use of the following predicate is currently obsoleted by; {@link AssemblyContigWithFineTunedAlignments#hasIncompletePictureFromTwoAlignments()}; because the contigs with this alignment signature is classified as ""incomplete"",; hence will NOT sent here for constructing SimpleChimera's.; But we may want to keep the code (and related code in BreakpointComplications) for future use. Comment by @cwhelan ; > I'm a bit confused by this comment: this method is still being called in several places, so how is it obsolete?. Reply by @SHUANG-Broad (also copied to update the ""TODO"" message; > this predicate is currently used in two places (excluding appearance in comments): `BreakpointComplications.IntraChrStrandSwitchBreakpointComplications`, where it is use to test if the input simple chimera indicates an inverse tandem duplication and trigger the logic for inferring duplicated region; and `BreakpointsInference.IntraChrStrandSwitchBreakpointInference`, where",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030:2134,message,message,2134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030,1,['message'],['message']
Integrability,"hat it can output and genotype spanning deletion alleles represented by the `*` allele. . Currently, the output of `HaplotypeCaller` will not include spanning deletion alleles when run in single sample VCF mode or in genotype given alleles mode, even when that genotype would be more appropriate. In the joint calling workflow `GenotypeGVCFs` adds genotypes for spanning deletions, although the input likelihoods will not be broken out to specifically account for spanning deletion alleles. Some implementation notes:. - I also fixed some behavior specific to GGA mode that I encountered while testing this bug. In particular, when GGA mode was run with multiple variants with the same start position or with spanning events, `HaplotypeCaller` used to emit the warning `""Multiple valid VCF records detected in the alleles input file at site "" + loc + "", only considering the first record""` for each such site. This was a bit of a misleading message, since the other variants were in fact taken into account UNLESS HC decided to emit an empty variant context, for example due to zero coverage.; - I rewrote the `createAlleleMapper` method in `AssemblyBasedCallerGenotypingEngine`. The old version had a very brittle mapping scheme that depended heavily on the ordering of alleles in the variant context created by `AssemblyBasedCallerUtils.makeMergedVariantContext` and `getEventsAtThisLoc`. This proved to be difficult to ensure when spanning deletions were added in, and there was an ominous TODO in the old method saying that the logic was not good enough, so I ended up re-writing it from scratch. The new version is longer but I hope it is easier to read and less fragile, but let me know if I've missed anything. Test currently fail on this branch and therefore it should not be merged. To make them pass we need a fix to https://github.com/broadinstitute/gatk/issues/4716 which is currently being worked on in https://github.com/broadinstitute/gatk/pull/4645. However, since that PR is taking a ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4963:980,message,message,980,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4963,1,['message'],['message']
Integrability,"he code is in `CommandLineProgram`:. ```java; /**; *; * @return true if command line is valid; */; protected boolean parseArgs(final String[] argv) {. commandLineParser = new CommandLineArgumentParser(this, getPluginDescriptors());; try{; final boolean ret = commandLineParser.parseArguments(System.err, argv);; commandLine = commandLineParser.getCommandLine();; if (!ret) {; return false;; }; final String[] customErrorMessages = customCommandLineValidation();; if (customErrorMessages != null) {; for (final String msg : customErrorMessages) {; System.err.println(msg);; }; commandLineParser.usage(System.err, false);; return false;; }; return true;; } catch (final CommandLineException e){; //The CommandLineException is treated specially - we display help and no blow up; commandLineParser.usage(System.err, true);; printDecoratedUserExceptionMessage(System.err, e);; //rethrow e - this will be caught upstream and the right exit code will be used.; //we don't exit here though - only Main.main is allowed to call System.exit.; throw e;; }; }; ```. I think that GATK should discourage the usage of `CommandLineException` outside the Barclay engine or `customCommandLineValidation()`, and no wrapping the exception to `UserException` because it is related with the parsing. For instance, `MissingArgument` could be considere also an user exception, and almost all `CommandLineException` except the internal ones. I had the same problem when `CommandLineException` was part of `UserException` and I changed to use that one only to parts of the code related with arg parsing. That's why I included in the try-catch block the `customCommandLineValidation()` in #2226. I think that it makes more sense like this, because command line exceptions (e.g., bad or missing args) are printed with the usage of the tool, indicating why the argument is wrong and refering to the help; on the other hand, an user exception is more related with malformed files or other requirements not related with arg parsing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268660546:1373,wrap,wrapping,1373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268660546,1,['wrap'],['wrapping']
Integrability,"hellbender.tools.PrintReads - Shutting down engine; [August 17, 2015 5:44:45 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=257425408; java.lang.IllegalArgumentException: end must be >= start. start:2801961 end:2801960; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$25(ReadWalker.java:64); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$43/308889081.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:63); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:386); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:99); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:152); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.main(Main.java:86); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/828#issuecomment-131972247:2238,wrap,wrapAndCopyInto,2238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/828#issuecomment-131972247,1,['wrap'],['wrapAndCopyInto']
Integrability,hellbender.tools.walkers.filters.VariantFiltration.matchesFilter(VariantFiltration.java:379); at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.filter(VariantFiltration.java:338); at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.apply(VariantFiltration.java:298); at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:153); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:151); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5582:2251,wrap,wrapAndCopyInto,2251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582,1,['wrap'],['wrapAndCopyInto']
Integrability,hether we are running on Google Compute Engine.; java.net.ConnectException: No route to host (connect failed); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.goo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5220:1927,protocol,protocol,1927,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5220,1,['protocol'],['protocol']
Integrability,hod); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cl,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180:7300,protocol,protocol,7300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180,1,['protocol'],['protocol']
Integrability,hodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:635); Caused by: java.io.FileNotFoundException: File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.j,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:5868,protocol,protocolPB,5868,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocolPB']
Integrability,hooking up tools so they take path wrappers for Features,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2393:35,wrap,wrappers,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2393,1,['wrap'],['wrappers']
Integrability,"hread.run(Thread.java:745). 18/12/21 13:14:09 ERROR scheduler.TaskSetManager: Task 16 in stage 0.0 failed 4 times; aborting job; 13:14:09.675 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 1:14:09 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.97 minutes.; Runtime.totalMemory()=937426944; org.apache.spark.SparkException: Job aborted due to stage failure: Task 16 in stage 0.0 failed 4 times, most recent failure: Lost task 16.3 in stage 0.0 (TID 11, scc-q16.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.r",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:13307,Wrap,Wrappers,13307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['Wrap'],['Wrappers']
Integrability,"hromosome chr1 position 5160262 (TileDB column 5160261) has too many alleles in the combined VCF record : 209 : current limit : 50. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. ; ; 04:30:07.108 WARN MinimalGenotypingEngine - Attempting to genotype more than 50 alleles. Site will be skipped at location chr1:5160262 ; ; Chromosome chr1 position 5160266 (TileDB column 5160265) has too many alleles in the combined VCF record : 1601 : current limit : 50. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. ; ; 04:33:01.269 WARN MinimalGenotypingEngine - Attempting to genotype more than 50 alleles. Site will be skipped at location chr1:5160266 ; ; Chromosome chr1 position 5160272 (TileDB column 5160271) has too many alleles in the combined VCF record : 183 : current limit : 50. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. ; ; Chromosome chr1 position 5160273 (TileDB column 5160272) has too many alleles in the combined VCF record : 25795 : current limit : 50. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. ; ; java: /home/vagrant/GenomicsDB/dependencies/htslib/vcf.c:4225: bcf\_update\_format: Assertion \`nps && nps\*line->n\_sample==n' failed. ; ; parallel: This job failed: ; ; /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk --java-options ""-Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M"" GenotypeGVCFs --genomicsdb-use-vcf-codec -R /odinn/data/extdata/1000genomes/2019-06-21\_GRCh38/GRCh38\_full\_analysis\_set\_plus\_decoy\_hla.fa -V gendb:///tmp/tmp.ceRdvv/GDB --tmp-dir=/tmp/tmp.ceRdvv --interval-padding 1000 --only-output-calls-starting-in-intervals -L chr1:5161113-5163890 -O /tmp/tmp.ceRdvv/splitdir/reg\_5.padded.vcf.gz<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/6566'>Zendesk ticket #6566</a>)<br>gz#6566</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6742:18942,depend,dependencies,18942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742,1,['depend'],['dependencies']
Integrability,"htsjdk doesn't accept 2bit reference files, so we can't use them as CRAM references. One possible fix is to change the htsjdk CRAM reference class to be an interface, and then provide a 2bit implementation from GATK. For Spark, Hadoop-BAM would need to know how to instantiate these as well.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1443:156,interface,interface,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1443,1,['interface'],['interface']
Integrability,"htsjdk has been patched (https://github.com/samtools/htsjdk/pull/286) -- before this ticket can be closed, however, we need to wait for the next htsjdk release, rev the htsjdk dependency in hellbender, and ensure that hellbender can now handle the ""wrong/missing reference for CRAM"" case gracefully with a sensible error message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/677#issuecomment-125260020:176,depend,dependency,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/677#issuecomment-125260020,2,"['depend', 'message']","['dependency', 'message']"
Integrability,"htsjdk is included in the GenomcisDB fat jar, maybe that's why getting pulled in from there. GenomicsDB class paths should be okay as long as htsjdk is in the path. @droazen , is it okay to make this change in the latest GenomicsDB import PR? The version dependency has changed anyway.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292582744:255,depend,dependency,255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292582744,1,['depend'],['dependency']
Integrability,"https://github.com/broadinstitute/gatk/blob/b4cba377e0aff179dbff615783506913e7fe3aa4/src/main/java/org/broadinstitute/hellbender/tools/funcotator/dataSources/xsv/LocatableXsvFuncotationFactory.java#L245-L247. Double-Checked Locking is widely cited and used as an efficient method for implementing lazy initialization in a multithreaded environment.; Unfortunately, it will not work reliably in a platform independent way when implemented in Java, without additional synchronization. Modify the variable ‘supportedFieldNames’ with volatile to tackle the problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7376:466,synchroniz,synchronization,466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7376,1,['synchroniz'],['synchronization']
Integrability,"https://github.com/broadinstitute/gatk/issues/1270. Depends on https://github.com/broadinstitute/gatk/pull/1469, which should be reviewed first and then I can remove the first commit from this branch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1488:52,Depend,Depends,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1488,1,['Depend'],['Depends']
Integrability,"hub.com/protocolbuffers/protobuf/commit/b5a7cf7cf4b7e39f6b02205e45afe2104a7faf81""><code>b5a7cf7</code></a> Remove RecursiveGroup test case which doesn't exist in 25.x pre-Editions</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/f000b7e18fd6921ca02ea4b87608e8cadcb7b64f""><code>f000b7e</code></a> Fix merge conflict by adding optional label to proto2 unittest_lite.proto</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/4728531c162f2f9e8c2ca1add713cfee2db6be3b""><code>4728531</code></a> Add recursion check when parsing unknown fields in Java.</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/850fcce9176e2c9070614dab53537760498c926b""><code>850fcce</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b7044987de77f1dc368fee558636d0b56d7e75e1""><code>b704498</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/e67347986eaf7d777a6ee34367fa99f4912423ab""><code>e673479</code></a> Fix cord handling in DynamicMessage and oneofs. (<a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/18375"">#18375</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/8a60b6527a976cfd0028153da3ad8e4ed280e0de""><code>8a60b65</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.23.4...v3.25.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:1575,protocol,protocolbuffers,1575,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,1,['protocol'],['protocolbuffers']
Integrability,"i.e. uses updated kebab syntax. --- . ## CalcMetadataSpark . 1. Revise one-line summary to something like:; Collects read metrics relevant to structural variant discovery. - Notice the lack of a period at the end above.; - Not statistics but metrics?. 2. Overview and Notes could use finessing but let's leave this for next year. One thing to do now is move this statement up top:; This tool is used in development and should not be of interest to most researchers. 3. I think this tool fits under the DiagnosticsAndQCProgramGroup.java.; 4. The tool takes a SAM/BAM/CRAM and calculates fragment length statistics...; 5. ""This is the first step in the workflow""--> makes it sound like this tool is necessary in the SV workflow but you say otherwise in the debugging sentence. I find this confusing. 6. I'm noticing that the example command does not have spark options despite the tool being a Spark tool. For such cases, it would be helpful to state, e.g. ""This tool can run in both Spark and non-Spark modes, depending on if --sparkMaster is set."" Then include a second example command that shows how to utilize Spark. There is an example from ChrisW in <https://github.com/broadinstitute/gatk/issues/3853>:. ```; 	-- \; --sparkRunner GCS \; --cluster my-dataproc-spark-cluster; ```. ---; ## DiscoverVariantsFromContigAlignmentsSAMSpark. 1. ""Parse"" is vague. How about: ; Parses aligned contig assemblies of genomic breakpoints and calls structural variants. And `6. ` from above. ---; ## ExtractOriginalAlignmentRecordsByNameSpark. 1. Subsets reads by names; 2. I think you mean FilterSamReads (Picard) and not PrintReads. AFAIK, PrintReads cannot subset based on a list of read names. Rather FilterSamReads can do so as long as the reads are queryname-sorted. So then it would be good to distinguish this tool from FilterSamReads by saying (assuming true) ""Unlike FilterSamReads, this tool can take any sort-order, e.g. unsorted, to subset target reads.""; 3. ReadDataProgramGroup.java. And `6. ` fr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451:1342,depend,depending,1342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451,1,['depend'],['depending']
Integrability,"i><a href=""https://github.com/protocolbuffers/protobuf/commit/e67347986eaf7d777a6ee34367fa99f4912423ab""><code>e673479</code></a> Fix cord handling in DynamicMessage and oneofs. (<a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/18375"">#18375</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/8a60b6527a976cfd0028153da3ad8e4ed280e0de""><code>8a60b65</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.23.4...v3.25.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested mer",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:2551,depend,dependency-name,2551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,1,['depend'],['dependency-name']
Integrability,iantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142) ; ; at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:130) ; ; at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:281) ; ; at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:135) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; ; at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ; ; at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:490) ; ; at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211) ; ; at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160) ; ; at org.broadinstitute.hellbender.Main.mainEntr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7465:8918,wrap,wrapAndCopyInto,8918,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7465,1,['wrap'],['wrapAndCopyInto']
Integrability,iantContextUtils.isAlleleInList(GATKVariantContextUtils.java:164) ; ; at org.broadinstitute.hellbender.tools.walkers.vqsr.FilterVariantTranches.firstPassApply(FilterVariantTranches.java:187) ; ; at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:17) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; ; at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ; ; at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211) ;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6701:8087,wrap,wrapAndCopyInto,8087,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701,1,['wrap'],['wrapAndCopyInto']
Integrability,"ies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge::keras after 2.2.5; # undesirably set the environment variable KERAS_BACKEND = theano by default; - defaults::intel-openmp=2019.4; - conda-forge::scikit-learn=0.22.2; - conda-forge::matplotlib=3.2.1; - conda-forge::pandas=1.0.3. # core R dependencies; these should only be used for plotting and do not take precedence over core python dependencies!; -",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:2316,depend,dependencies,2316,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,1,['depend'],['dependencies']
Integrability,if there is a mismatch between VCF header name and sample map name... an helpful error message would be nice. Checking 1000s of VCFs to find an error would be a pain,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2713#issuecomment-301532660:87,message,message,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2713#issuecomment-301532660,1,['message'],['message']
Integrability,"ignore, testing GitZen integration<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/4401'>Zendesk ticket #4401</a>)<br>gz#4401</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6380:23,integrat,integration,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6380,1,['integrat'],['integration']
Integrability,il.Optional.ifPresent(Optional.java:159); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.applyFiltersAndAccumulateOutputStats(Mutect2FilteringEngine.java:174); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:142); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbend,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6058:1810,wrap,wrapAndCopyInto,1810,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6058,1,['wrap'],['wrapAndCopyInto']
Integrability,ileup - Defaults.CUSTOM_READER_FACTORY : ; 15:04:36.349 INFO Pileup - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 15:04:36.349 INFO Pileup - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 15:04:36.349 INFO Pileup - Defaults.REFERENCE_FASTA : null; 15:04:36.349 INFO Pileup - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 15:04:36.349 INFO Pileup - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:04:36.349 INFO Pileup - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 15:04:36.350 INFO Pileup - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:04:36.350 INFO Pileup - Defaults.USE_CRAM_REF_DOWNLOAD : false; 15:04:36.350 INFO Pileup - Deflater IntelDeflater; 15:04:36.350 INFO Pileup - Initializing engine; WARNING: BAM index file /home/lichtens/broad_oncotator_configs/hcc_purity/SM-74NEG.bai is older than BAM /home/lichtens/broad_oncotator_configs/hcc_purity/SM-74NEG.bam; 15:04:38.560 INFO IntervalArgumentCollection - Processing 999914 bp from intervals; 15:04:38.630 INFO Pileup - Done initializing engine; 15:04:38.635 INFO ProgressMeter - Starting traversal; 15:04:38.636 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; JProfiler> Protocol version 49; JProfiler> Using JVMTI; JProfiler> JVMTI version 1.1 detected.; JProfiler> 64-bit library; JProfiler> Listening on port: 31757.; JProfiler> Attach mode initialized; JProfiler> Instrumenting native methods.; JProfiler> Can retransform classes.; JProfiler> Can retransform any class.; JProfiler> Retransforming 8 base class files.; JProfiler> Base classes instrumented.; JProfiler> Native library initialized; JProfiler> Using dynamic instrumentation; JProfiler> Time measurement: elapsed time; JProfiler> CPU profiling enabled; JProfiler> Initializing configuration.; JProfiler> Retransforming 3697 class files.; JProfiler> Configuration updated. ```. ![oncobuntu_mk3](https://cloud.githubusercontent.com/assets/2152339/22307273/583f61a8-e310-11e6-87ef-e87eaba7cf93.png),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2356:3363,Protocol,Protocol,3363,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2356,1,['Protocol'],['Protocol']
Integrability,"ility to tweak sample-every-Nth-variant parameter for SNP model creation (#8019); - add initial notebook copy pasta (#8008); - add sample_table_timestamp to GetNumSamplesLoaded (#8022); - Batched Avro export [VS-630] (#8020); - Updating references to old GATK for VS-620 (#8023); - VS-517 Use standard version of GetBQTableLastModifiedDatetime in GvsValidateVat (#8024); - Fix bug in GvsWithdrawSamples.wdl (#8026); - Ah 617 exposing the drop_state parameter to the GvsJointVariantCalling wdl used for beta (and internal customer) (#8032); - Expose maximum-training-variants VQSR parameter [VS-634] (#8029); - Callset statistics [VS-560] (#8018); - Check for withdrawn before exporting to AVRO files [VS-646] (#8039); - Small updates to GVS Integration WDL [VS-618] (#8042); - Rework Hail script generation [VS-616] (#8034); - Alpine based Variant Store Docker image [VS-648] (#8044); - update warp version (#7906); - Fail Avro extract and callset stats on bad filter name [VS-655] (#8046); - Vs 629 failure to retrieve job information during ingest (#8047); - Restore accidentally removed bcftools [VS-661] (#8051); - Allowing our pipeline to function with a sample size of one (#8055); - Vs 665 re create vcf for cd 68 po 52339 with ad padding fixed (#8057); - VS-665 and VS-620 updating code to use latest docker images containing Rori's AD calculation changes in extract (#8061); - updating the beta workflow to use the latest jar, representing the version of GATK George tested against the workflow (#8062); - VS-637 Address a couple of issues in SampleLoadStatus handling in GVSImportGenomes. (#8052); - Revert Alpinizing of apt dependent task [VS-688] (#8065); - Fix missing vat schema JSONs [VS-699] (#8072); - Fix integration expectations for fixed AD [VS-689] (#8066); - VS-698 Remove unnecessary columns from Call set statistics (#8073); - Fix Dockerfile nits that break 20.10.21 (#8078); - Nirvana 3.18.1 Docker images support [VS-661] (#8082); - Add option to not prepare __REF_DATA or __",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:28993,Integrat,Integration,28993,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['Integrat'],['Integration']
Integrability,ils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:5130); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685:6705,protocol,protocol,6705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685,1,['protocol'],['protocol']
Integrability,iltering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:68); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePip,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1654,wrap,wrapAndCopyInto,1654,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887,1,['wrap'],['wrapAndCopyInto']
Integrability,"implementation is different from the one in `ReadWindowWalker`: first, the overlap between windows is only in one direction; second, `SlidingWindowWalker` is more like a reference/interval walker, from the beginning of the reference (or interval) till the end, it walks in overlapping windows. One example is the following (window-size 10, window-step 5, the - represent the window):. ```; Reference: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; Windows1: _ _ _ _ _ _ _ _ _ _; Windows2: _ _ _ _ _ _ _ _ _ _; Windows3: _ _ _ _ _ _ _ _ _ _; Windows4: _ _ _ _ _ _ _ _ _ _; Windows5: _ _ _ _ _ _ _ _ _ _; ```. Of course, after having a look to `ReadWindowWalker` I think that several things could be improved in my implementation for a general `SlidingWindowWalker`:; - Apply function similar to the `ReadWindowWalker`, with `ReadWindow` being empty if reads are not provided.; - Three window options: `windowSize` (the actual size of the window), `windowStep` (how much advance for the following window) and `windowPadding` (how much extend the window in both directions). Using this abstraction, `ReadWindowWalker` could be implemented setting `windowSize=windowStep`, and the problem that I need to solve could be implemented setting `windowPadding=0`. The simplest way to acomplish this is to use the current implementation of `ReadWindowWalker` to develop a `SlidingWindowWalker` adding three abstract methods for the three parameters (`getWindowSize()`, `getWindowStep()` and `getWindowPadding()`, and implement `ReadWindowWalker` as a extension of this interface setting `getWindowStep()` to return `getWindowSize()` and `requiresReads()` to true. I can do this once the PR #1567 is accepted and generate the two interfaces (to be sure that the integration with the HC engine is working as expected with the changes), or just implement the `SlidingWindowWalker` and you can include it in the HC PR, or update afterwards to avoid redundancy in the code. What do you think, @droazen?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-198438775:2154,interface,interface,2154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-198438775,3,"['integrat', 'interface']","['integration', 'interface', 'interfaces']"
Integrability,improve error message during build when ToolProvider is unavailable,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4532:14,message,message,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4532,1,['message'],['message']
Integrability,improve message or missing seq dict on variants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1305:8,message,message,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1305,1,['message'],['message']
Integrability,improve usage message for missing argument,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/418:14,message,message,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/418,1,['message'],['message']
Integrability,improved an error message for missing sequence dictionary. Closes #1305.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2653:18,message,message,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2653,1,['message'],['message']
Integrability,improving error message in GATKSparkTool.writeReads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2336:16,message,message,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2336,1,['message'],['message']
Integrability,"improving gatk, one error message at a time",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3812:26,message,message,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3812,1,['message'],['message']
Integrability,"in CountVariants -V means 'variant'. in IndexFeatureFile it seems to mean 'verbosity', see message below:. ```; ./gatk-launch IndexFeatureFile -V /xchip/cga_home/akiezun/data/dbsnp_135.b37.excluding_sites_after_129.vcf; ```. ``````; A USER ERROR has occurred: Invalid command line: Argument VERBOSITY has a bad value: /xchip/cga_home/akiezun/data/dbsnp_135.b37.excluding_sites_after_129.vcf. '/xchip/cga_home/akiezun/data/dbsnp_135.b37.excluding_sites_after_129.vcf' is not a valid value for LogLevel. Possible values: {ERROR, WARNING, INFO, DEBUG}```. ``````",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1306:91,message,message,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1306,1,['message'],['message']
Integrability,"in case you don't feel like bothering looking at that branch, add . ```; compile 'com.google.gcloud:gcloud-java:0.1.6-20160404.190825-1'; ```. to your build.gradle dependencies and it should hopefully work. Still waiting on travis to find out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1662#issuecomment-205458275:164,depend,dependencies,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1662#issuecomment-205458275,1,['depend'],['dependencies']
Integrability,in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://stor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084:1112,integrat,integration,1112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084,1,['integrat'],['integration']
Integrability,"in"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$Ht",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1375,wrap,wrapper,1375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,in.doAction(Main.java:33); at org.gradle.launcher.bootstrap.EntryPoint.run(EntryPoint.java:45); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54); at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35); at org.gradle.launcher.GradleMain.main(GradleMain.java:23); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:129); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: org.gradle.api.UncheckedIOException: java.io.IOException: Disk quota exceeded; at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:58); at org.gradle.cache.internal.btree.CachingBlockStore.close(CachingBlockStore.java:40); at org.gradle.cache.internal.btree.FreeListBlockStore.close(FreeListBlockStore.java:60); at org.gradle.cache.internal.btree.StateCheckBlockStore.close(StateCheckBlockStore.java:41); at org.gradle.cache.internal.btree.BTreePersistentIndexedCache.close(BTreePersistentIndexedCache.java:195); ... 60 more; Caused by: java.io.IOException: Disk quota exceeded; at java.io.RandomAccessFile.close0(Native Method); at java.io.RandomAccessFile.close(RandomAccessFile.java:645); at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:56); ... 64 more; Could not stop Service Plug,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:14070,wrap,wrapper,14070,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,1,['wrap'],['wrapper']
Integrability,in.doAction(Main.java:33); at org.gradle.launcher.bootstrap.EntryPoint.run(EntryPoint.java:45); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54); at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35); at org.gradle.launcher.GradleMain.main(GradleMain.java:23); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:129); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: org.gradle.api.UncheckedIOException: java.io.IOException: Disk quota exceeded; at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:58); at org.gradle.cache.internal.btree.CachingBlockStore.close(CachingBlockStore.java:40); at org.gradle.cache.internal.btree.FreeListBlockStore.close(FreeListBlockStore.java:60); at org.gradle.cache.internal.btree.StateCheckBlockStore.close(StateCheckBlockStore.java:41); at org.gradle.cache.internal.btree.BTreePersistentIndexedCache.close(BTreePersistentIndexedCache.java:195); ... 60 more; Caused by: java.io.IOException: Disk quota exceeded; at java.io.RandomAccessFile.close0(Native Method); at java.io.RandomAccessFile.close(RandomAccessFile.java:645); at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:56); ... 64 more; Could not stop org.gradle.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:7245,wrap,wrapper,7245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,1,['wrap'],['wrapper']
Integrability,in.doAction(Main.java:33); at org.gradle.launcher.bootstrap.EntryPoint.run(EntryPoint.java:45); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54); at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35); at org.gradle.launcher.GradleMain.main(GradleMain.java:23); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:129); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: org.gradle.api.UncheckedIOException: java.io.IOException: Disk quota exceeded; at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:58); at org.gradle.cache.internal.btree.CachingBlockStore.close(CachingBlockStore.java:40); kStore.java:60); at org.gradle.cache.internal.btree.StateCheckBlockStore.close(StateCheckBlockStore.java:41); at org.gradle.cache.internal.btree.BTreePersistentIndexedCache.close(BTreePersistentIndexedCache.java:195); ... 64 more; Caused by: java.io.IOException: Disk quota exceeded; at java.io.RandomAccessFile.close0(Native Method); at java.io.RandomAccessFile.close(RandomAccessFile.java:645); at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:56); ... 68 more. FAILURE: Build failed with an exception.; - What went wrong:; org.gradle.api.UncheckedIOException: ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:21453,wrap,wrapper,21453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,1,['wrap'],['wrapper']
Integrability,"inaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run. ...skipped for brevity... VcfFormatConverter (Picard) Converts VCF to BCF or BCF to VCF.; VcfToIntervalList (Picard) Converts a VCF or BCF file to a Picard Interval List. --------------------------------------------------------------------------------------. Exception in thread ""main"" org.broadinstitute.hellbender.exceptions.UserException: 'FixVcfHead' is not a valid command.; Did you mean this?; FixVcfHeader; 	at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:341); 	at org.broadinstitute.hellbender.Main.setupConfigAndExtractProgram(Main.java:172); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:192); 	at org.broadinstitute.hellbender.Main.main(Main.java:275); ```. I expect something without the stack trace and the scary ""Exception"" message. For example:. ```; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Base Calling: Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run. ...skipped for brevity... VcfFormatConverter (Picard) Converts VCF to BCF or BCF to VCF.; VcfToIntervalList (Picard) Converts a VCF or BCF file to a Picard Interval List. --------------------------------------------------------------------------------------. Did you mean this?; FixVcfHeader; ```. The same happens with unknown commands. The code that should be changed for that is the following, where the `setupConfigAndExtractProgram` call should be also inside the try block:. https://github.com/broadinstitute/gatk/blob/8ac2f102b303f343c4787ad4e3359335641c5121/src/main/java/org/broadinstitute/hellbender/Main.java#L190-L212",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4256:1646,adapter,adapters,1646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4256,1,['adapter'],['adapters']
Integrability,"inatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:37271,Wrap,Wrappers,37271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"inatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:37023,Wrap,Wrappers,37023,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,ine.java:162); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:596); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1(HaplotypeCallerSpark.java:282); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1038); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:969); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:760); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230:2033,Wrap,Wrappers,2033,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230,1,['Wrap'],['Wrappers']
Integrability,ine.java:210); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.calculateGenotypes(GenotypeGVCFs.java:266); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.regenotypeVC(GenotypeGVCFs.java:222); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:201); at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:149); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:984); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hel,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401904928:3328,wrap,wrapAndCopyInto,3328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401904928,2,['wrap'],['wrapAndCopyInto']
Integrability,"info NativeGenomicsDB - pid=19608 tid=19609 No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records; 21:02:11.780 info NativeGenomicsDB - pid=19608 tid=19609 No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; 21:02:17.065 INFO GenotypeGVCFs - Done initializing engine; 21:02:17.110 INFO ProgressMeter - Starting traversal; 21:02:17.111 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 21:02:45.390 INFO ProgressMeter - Chr1:369351 0.5 1000 2121.8; 21:03:16.132 INFO ProgressMeter - Chr1:505230 1.0 2000 2033.2; 21:03:29.421 INFO ProgressMeter - Chr1:575285 1.2 3000 2489.3; ... (continued for more than 1000 lines); 21:49:51.317 INFO ProgressMeter - Chr1:3713346 47.6 242000 5087.2; 21:50:06.596 INFO ProgressMeter - Chr1:3718941 47.8 244000 5102.0; [TileDB::ReadState] Error: Cannot read tile from file; Memory map error.; terminate called after throwing an instance of 'VariantStorageManagerException'; what(): VariantStorageManagerException exception : VariantArrayCellIterator increment failed; TileDB error message : [TileDB::ReadState] Error: Cannot read tile from file; Memory map error; Using GATK jar /home/wtc/software/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx800G -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /home/wtc/software/gatk-4.2.0.0/gatk-package-4.2.0.0-local.jar GenotypeGVCFs -R /mnt/d/Share/SYJ/liulan/ref/genome.fa -V gendb:///mnt/d/Share/SYJ/liulan/DBI -O /mnt/d/Share/SYJ/liulan/sortbam/combDBI.vcf.gz --tmp-dir /mnt/d/Share/SYJ/liulan/NOHUP/tmp; ```. I have tried to change -Xmx to 20G and 100G, etc. But all processes stop running at Variants Processed 244000.; Could you tell me what the problem is?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8302:4590,message,message,4590,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8302,1,['message'],['message']
Integrability,"ing GenomicDBImport and import gvcf file for update genomicdb(Command). but since my server was shut down, during GenomicDBImport process, process is broke down. After I tried to GenomicDBImport same command for overwrite genomicdb and encounter to error message(error message).; ; In this case, should genomicdb be recreated from scratch? How to update the gvcf file I want to update? what should I do?. ### Command. java -jar $GATK GenomicsDBImport \; -L chr${1} \; -V $File_PATH/4762/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4763/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4764/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4765/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; -V $File_PATH/4767/bwa-gatk4/VARIANT/ForEachChr/chr22.g.vcf \; --genomicsdb-update-workspace-path $DB_PATH/test_database \; --genomicsdb-shared-posixfs-optimizations true \; --max-num-intervals-to-import-in-parallel 5 \; --reader-threads 10 \; --tmp-dir $Script_PATH/tmp. ### Error message. 10:49:12.018 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/mnt/mone/OMICS/Tools/Programs/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jun 18, 2021 10:49:12 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:49:12.231 INFO GenomicsDBImport - ------------------------------------------------------------; 10:49:12.232 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.8.1; 10:49:12.232 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:49:12.232 INFO GenomicsDBImport - Executing as chowoo1023@bdcm04 on Linux v3.10.0-514.2.2.el7.x86_64 amd64; 10:49:12.232 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_191-b12; 10:49:12.232 INFO GenomicsDBImport - Start Date/Time: June 18, 2021 10:49:11 AM KST; 10:49:12.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7324:1140,message,message,1140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7324,1,['message'],['message']
Integrability,ing argument: input; 	at org.broadinstitute.hellbender.cmdline.GATKPlugin.GATKAnnotationPluginDescriptor.getAllowedValuesForDescriptorHelp(GATKAnnotationPluginDescriptor.java:246); 	at org.broadinstitute.barclay.argparser.CommandLineArgumentParser.usageForPluginDescriptorArgumentIfApplicable(CommandLineArgumentParser.java:870); 	at org.broadinstitute.barclay.argparser.CommandLineArgumentParser.makeArgumentDescription(CommandLineArgumentParser.java:847); 	at org.broadinstitute.barclay.argparser.CommandLineArgumentParser.printArgumentUsage(CommandLineArgumentParser.java:791); 	at org.broadinstitute.barclay.argparser.CommandLineArgumentParser.lambda$printArgumentUsageBlock$2(CommandLineArgumentParser.java:276); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.SortedOps$SizedRefSortingSink.end(SortedOps.java:352); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.barclay.argparser.CommandLineArgumentParser.printArgumentUsageBlock(CommandLineArgumentParser.java:276); 	at org.broadinstitute.barclay.argparser.CommandLineArgumentParser.usage(CommandLineArgumentParser.java:308); 	at org.broadinstitute.barclay.argparser.CommandLineArgumentParser.parseArguments(CommandLineArgumentParser.java:417); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.parseArgs(CommandLineProgram.java:221); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.bro,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4875:1846,wrap,wrapAndCopyInto,1846,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4875,1,['wrap'],['wrapAndCopyInto']
Integrability,"ing the following unhelpful stack trace when running a local job. . ```; Gokalps-Mac-mini:1000GVCFs sky$ gatk SelectVariants -V 1000G_CEU_chr16.vcf.gz -O 1000G_CEU_AFfilt_chr16.vcf.gz -select ""AF > 0.0""; Using GATK jar /Users/sky/scripts/gatk-package-4.0.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /Users/sky/scripts/gatk-package-4.0.9.0-local.jar SelectVariants -V 1000G_CEU_chr16.vcf.gz -O 1000G_CEU_AFfilt_chr16.vcf.gz -select AF > 0.0; 14:35:45.842 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/sky/scripts/gatk-package-4.0.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 24, 2018 2:35:47 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: No route to host (connect failed); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.pr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5220:1010,rout,route,1010,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5220,1,['rout'],['route']
Integrability,"ing wheel for gatkpythonpackages (setup.py): finished with status 'done'; Created wheel for gatkpythonpackages: filename=gatkpythonpackages-0.1-py3-none-any.whl size=117686 sha256=8095375e139fa0729c7a41c8f5e8a43281fc1b6859b6d3951d3bfba7296ee349; Stored in directory: /tmp/pip-ephem-wheel-cache-ecx6e_m0/wheels/06/f7/e1/87cb7da6f705baa602256a58c9514b47dc313aade8809a01da; Successfully built gatkpythonpackages; Installing collected packages: gatkpythonpackages; Successfully installed gatkpythonpackages-0.1. done; #; # To activate this environment, use; #; # $ conda activate gatk; #; # To deactivate an active environment, use; #; # $ conda deactivate. ```. #### Actual behavior; ```sh; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda --version; conda 23.10.0; root@d12ac7710afc:/soft/gatk-4.4.0.0# ""$CONDA"" env create -n gatk -f ""$SOFT/gatk-${GATK_VERSION}/gatkcondaenv.yml""; ...; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Installing pip dependencies: | Ran pip subprocess with arguments:; ['/opt/miniconda/envs/gatk/bin/python', '-m', 'pip', 'install', '-U', '-r', '/soft/gatk-4.4.0.0/condaenv.i9brvcrk.requirements.txt', '--exists-action=b']; Pip subprocess output:. Pip subprocess error:; /opt/miniconda/envs/gatk/bin/python: No module named pip. failed. CondaEnvException: Pip failed. ```; ---; It can be fixed with setting classic colver:; ```; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda --version; conda 23.10.0; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda config --set solver classic; root@d12ac7710afc:/soft/gatk-4.4.0.0# ""$CONDA"" env create -n gatk -f ""$SOFT/gatk-${GATK_VERSION}/gatkcondaenv.yml""; ...; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Installing pip dependencies: \ Ran pip subprocess with arguments:; ['/opt/miniconda/envs/gatk/bin/python', '-m', 'pip', 'install', '-U', '-r', '/soft/gatk-4.4.0.0/condaenv.rtsyg5rl.requirements.txt', '--exists-action=b']; Pip subprocess output:; Processing",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8618:2054,depend,dependencies,2054,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8618,1,['depend'],['dependencies']
Integrability,integration run: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/534011af-6909-49b4-b451-a0604eafb447,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7901#issuecomment-1155658697:0,integrat,integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7901#issuecomment-1155658697,1,['integrat'],['integration']
Integrability,integration test for BQSR Plotting,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/420:0,integrat,integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/420,1,['integrat'],['integration']
Integrability,integration test for CollectQualityYieldMetrics,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/842:0,integrat,integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/842,1,['integrat'],['integration']
Integrability,integration tests for SplitNCigarReads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1378:0,integrat,integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1378,1,['integrat'],['integration']
Integrability,integration tests to check min-bq argument is hooked up to HC and M2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4192:0,integrat,integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4192,1,['integrat'],['integration']
Integrability,integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |; | integration | openjdk11 | [38100.12](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251324) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.12/tests/test/index.html) |; | integration | openjdk8 | [38100.2](https://app.travis-ci.com/broadinstitute/gatk/jobs/563251314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/ah_var_store_38100.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084:1781,integrat,integration,1781,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7715#issuecomment-1067136084,4,['integrat'],['integration']
Integrability,internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6745:4995,Message,MessageHubBackedObjectConnection,4995,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745,6,['Message'],"['MessageHub', 'MessageHubBackedObjectConnection']"
Integrability,internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:80); at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:59); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); at com.sun.proxy.$Proxy2.stop(Unknown Source); at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:116); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360); at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1258#issuecomment-162574174:4745,Message,MessageHub,4745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1258#issuecomment-162574174,2,['Message'],['MessageHub']
Integrability,internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:83); at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); at com.sun.proxy.$Proxy2.stop(Unknown Source); at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360); at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1768:5486,Message,MessageHub,5486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1768,2,['Message'],['MessageHub']
Integrability,ionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.util.ConcurrentModificationException; 	at java.util.Vector$Itr.checkForComodification(Vector.java:1184); 	at java.util.Vector$Itr.next(Vector.java:1137); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:92); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:40); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); 	... 120 more; ```. @jamesemery @t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5680:10951,Message,MessageHub,10951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680,1,['Message'],['MessageHub']
Integrability,ionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.Te,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:1869,Message,MessageHub,1869,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858,1,['Message'],['MessageHub']
Integrability,"ions here, which might allow for easier treatment of ill-behaved annotations. However, I'd say enabling workflows where the set of annotations is fixed is the priority.; - [ ] We could do positive-unlabeled training more rigorously or iteratively. Right now, we essentially do a single iteration to determine negative data. This could perhaps be preceded by a round of refactoring to clean up model training and make it less procedural.; - [ ] Automatic threshold tuning could be built into the tool, see #7711. We'd probably have to introduce a ""validation"" label. Perhaps it makes sense to keep this sort of thing at the workflow level?; - [ ] In the positive-negative framework enforced by the Java code in this tool, a ""model"" is anything that assigns a score, we fit two models to different subsets of the data, and then take the difference of the two scores. While the python backend does give some freedom to specify a model, future developers may want to go beyond the framework itself. For example, more traditional classification frameworks, etc. could be explored. As an intermediate step, one could perhaps use the positive/negative scores from the current framework in a more sophisticated way (e.g., using them as features), rather than just taking their difference. This sort of future work could be developed completely independently of the codebase associated with the current training tool (or done externally in python), but should still be able to make use of the extract and score tools, since the contracts should be relatively general. EDIT: I think I will go ahead and ablate the positive-negative option, as this adds a lot of overly complicated code for little benefit. So Java code in this tool will only be responsible for selecting variant types---and we may even want to move that functionality into backends in the future. To start, BGMM and IsolationForest backends will be positive-only, and custom Python backends will have the unlabeled annotations passed directly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369:2561,contract,contracts,2561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369,1,['contract'],['contracts']
Integrability,ipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.DoublePipeline.toArray(DoublePipeline.java:506); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.calculateLog10GP(GenotypeCopyNumberTriStateSegments.java:198); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.lambda$composeVariantContext$0(GenotypeCopyNumberTriStateSegments.java:125); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.composeVariantContext(GenotypeCopyNumberTriStateSegments.java:141); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.makeCalls(GenotypeCopyNumberTriStateSegments.java:104); at org.broadinstitute.hellbender.tools.exome.germlinehmm.CopyNumberTriStateSegmentCaller.doWork(CopyNumberTriStateSegmentCaller.java:121); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:108); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:166); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLine,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2898:1907,wrap,wrapAndCopyInto,1907,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2898,1,['wrap'],['wrapAndCopyInto']
Integrability,irHMMLikelihoodCalculationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:192); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:7599,Wrap,Wrappers,7599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,3,['Wrap'],['Wrappers']
Integrability,irHMMLikelihoodCalculationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:192); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:3537,Wrap,Wrappers,3537,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Wrap'],['Wrappers']
Integrability,irHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:192); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:3381,Wrap,WrappingSpliterator,3381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,4,['Wrap'],['WrappingSpliterator']
Integrability,"ire count file for all samples a determining factor? If we can drastically reduce this cost, then we can dedicate more to increasing resolution, etc. Here is a minimal set of fixes that could enable the querying of intervals for GermlineCNVCaller (and also for DetermineGermlineContigPloidy without too much extra work, since we also subset intervals there) *only in the gCNV WGS pipeline*, without disrupting other interfaces:. 1) Write a Tribble SimpleCountCodec for the `counts.tsv` extension. I've already done this in a branch.; 2) Change GermlineCNVCaller and DetermineGermlineContigPloidy tools to accept paths.; 3) If an index is present for each count path, create a FeatureDataSource, merge the requested -L/-XL intervals, and query to perform the subset. We will also need to stream the SAM header metadata. It should not require much code to extract all this to a temporary IndexedSimpleCountCollection class. (Caveat: for now, this will work with the current gCNV convention of providing bins via -L/-XL. Technically, it will also work with the more conventional use of -L/-XL to denote contiguous regions, but we may have to perform checks that bins are not duplicated in adjacent shards if they overlap both, since querying a FeatureDataSource will return any bins that overlap the interval---rather than only those that are completely contained within it.); 4) Index read-count TSVs in the gCNV WGS pipeline after collection and modify the DetermineGermlineContigPloidy and GermlineCNVCaller tasks to take read-count paths and indices, if necessary. These changes could be confined in the gCNV WGS WDL for now. I think that should do the trick. If this is high priority, I can implement now. In the future, we might be able to promote all Locatable CNV Records to Features and write code to automatically pass the columns/encoders/decoders (currently held in the Collection corresponding to each Record) to a single Tribble codec. This codec should not depend upon the file extension.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082:2121,depend,depend,2121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082,1,['depend'],['depend']
Integrability,"is is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (general-use/engine) dependency of ``FilterByOrientationBias`` will try to instantiate a class that does not exist. The ``sed`` was supposed to be temporary until picard was wrapped properly in GATK. But until then, it does mean that all GATK-based downstream dependencies of ``CollectSequencingArtifactMetrics`` will fail without the sed. Again, the fix is not in ``FilterByOrientationBias``. > Also, FilterByOrientationBias does not output bgzipped VCFs. So this is not in line with how GATK tools should work. . ``FilterByOrientationBias`` just farms it out to a VCF Writer. That dependency (VCF Writer) should handle that. Can you confirm, @lbergelson ? Is there an additional step to make this work that I did not know about?. > Again, FilterByOrientationBias is not production worthy and I think at this point it should get an experimental or BETA label. Only because of the ``sed`` nonsense, as near as I can tell. Definitely, BETA -- not experimental. All I'm saying is that I don't believe any code change needs to go into ``FilterByOrientationBias`` (with the possible exception of the bgzip VCF). These issues are all in its dependencies, which are part of the engine/picard-ports.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:2256,depend,dependencies,2256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143,3,['depend'],"['dependencies', 'dependency']"
Integrability,"is that not expected to get different sorting depending on `sort_by_all_columns`?; BTW, running without sort_by_all_columns seems silly - let's fix it to `true` and remove the option: see https://github.com/broadinstitute/gatk/issues/1418",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1416#issuecomment-169455720:46,depend,depending,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1416#issuecomment-169455720,1,['depend'],['depending']
Integrability,"is there a haplotype-based prior that uses the alignment of the haplotype; to the reference? A prior that depends on the alignment might be better; than a flat pro-reference prior. On Thu, May 31, 2018 at 9:34 AM, ldgauthier <notifications@github.com>; wrote:. > I found the data from yet another example of this behavior (see poorly; > aligned reads in the bamout -- somehow the big fat deletion is preferred; > over the reference):; > [image: dlbcl-c_d_pair13 nkap x_119059262 frame_shift_del; > ctctcttcttggttaaaggatgcaaggg_-]; > <https://user-images.githubusercontent.com/6578548/40785072-7fdff344-64b5-11e8-8539-78267b9a2950.png>; >; > tumor exome: /seq/picard_aggregation/C1637/c_D_pair13_Dx/v3/c_D_pair13_; > Dx.bam; > normal exome: /seq/picard_aggregation/C1637/RICOVER_134_N/v2/RICOVER_134_; > N.bam; > M2 tumor bam: /xchip/cga_home/stewart/Cancer/DLBCL/M2/test/c_D_; > pair13_Dx.bam; > M2 normal bam: /xchip/cga_home/stewart/Cancer/DLBCL/M2/test/RICOVER_; > 134_N.bam; > M2 combined bam: /xchip/cga_home/stewart/Cancer/DLBCL/M2/test/DLBCL-c_; > D_pair13.M2_validation_bam.bam; > I can't guarantee the data is still around and I don't have the exact; > intervals, but if it doesn't reproduce in the latest GATK4 M2 then we can; > forget about it. If it does reproduce then it would put my mind at ease if; > the prior fixes this case too (and you could let Chip know that it got; > fixed 2.5 years later :-P); >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4829#issuecomment-393531485>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0qP335PYrMmALyjp96ZdOw_hv03Mks5t3_FQgaJpZM4UUW5o>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4829#issuecomment-393559160:106,depend,depends,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4829#issuecomment-393559160,1,['depend'],['depends']
Integrability,"isTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:2923,message,message,2923,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,1,['message'],['message']
Integrability,itute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:118); at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:189); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:100); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:98); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.m,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8523:2460,wrap,wrapAndCopyInto,2460,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8523,1,['wrap'],['wrapAndCopyInto']
Integrability,itute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:527); 	at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:180); 	at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4005:3239,wrap,wrapAndCopyInto,3239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4005,1,['wrap'],['wrapAndCopyInto']
Integrability,"java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /opt/conda/envs/789546e2/share/gatk4-4.0.1.1-0/gatk-package-4.0.1.1-local.jar GenotypeGVCFs -ploidy 1 -R references/359488/genome_fasta.fasta --annotate-with-num-discovered-alleles true --annotations-to-exclude InbreedingCoeff -V gendb://typing/gatk_gvcfs/full_genome/359488/bwa/genomics_db -O typing/gatk_gvcfs/full_genome/359488/bwa/all_samples.vcf; ```; In between the last ProgressMeter and the Shutting down of the engine, I see the java process still running with top. Do you know what could be causing the problem ? Could it be related to -ERC BP_RESOLUTION ? I used to use -ERC GVCF before but I would rather keep the information of the coverage for post filtering, and I am not sure how to use --GVCFGQBands to match my criteria for coverage filtering. Thanks a lot for your help !. Edit: sorry with the latest version of gatk I get a new message error :; ```; 08:22:54.446 INFO ProgressMeter - NC_016854.1:20000 0.2 20000 87450.8; 08:23:04.942 INFO ProgressMeter - NC_016854.1:58000 0.4 58000 143694.8; 08:25:25.155 INFO ProgressMeter - NC_016854.1:82000 2.7 82000 29921.4; 08:25:35.161 INFO ProgressMeter - NC_016854.1:100000 2.9 100000 34396.6; 08:28:02.395 INFO ProgressMeter - NC_016854.1:102000 5.4 102000 19025.7; 08:28:13.248 INFO ProgressMeter - NC_016854.1:140000 5.5 140000 25261.3; 08:28:24.027 INFO ProgressMeter - NC_016854.1:175000 5.7 175000 30585.2; 08:46:13.574 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),29.232685148998623,Cpu time(s),29.09919726900138; [February 28, 2018 8:46:13 AM UTC] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 23.59 minutes.; Runtime.totalMemory()=5588910080; Exception in thread ""main"" java.lang.OutOfMemoryError: GC overhead limit exceeded; 	at org.broadinstitute.hellbender.tool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4467:2130,message,message,2130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4467,1,['message'],['message']
Integrability,"java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1098); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:166); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:209); at org.broadinstitute.hellbender.Main.main(Main.java:306); ```; #### Steps to reproduce; When the command is run with original (haplotypecaller output, left aligned and trimmed, with a number of variants), the program crashes and prematurely terminate the output. . The problem can be isolated to one variant with the bam file. . ```; gatk VariantAnnotator -I ../test.bam -V test.vcf -O test_2.vcf --reference ~/refs/hg19/ucsc.hg19.fasta --enable-all-annotations true -jdk-deflater true -jdk-inflater true; ```. test.vcf is a haplotypecaller + leftalignandtrimvariant vcf file with one single variant: ; ```; chr8 145743102 . C A 37.32 . AC=2;AF=1.00;AN=2;DP=2;ExcessHet=0.0000;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;QD=18.66;SOR=0.693 GT:AD:DP:GQ:PL 1/1:0,2:2:6:49,6,0; ```. test.bam is a hg19-aligned, duplicate-marked bam file (372kb, containing only reads associated with the site, can be sent privately if necessary) . troubleshooting steps done: ; - the program does not crash if the bam file is not provided; - the program does not crash if --enable-all-annotations true is not given. #### Expected behavior; error/warning message or no annotation generated for a variant. #### Actual behavior; crashed with outputs truncated (where original, large number of variant in a file was analyzed)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8800:8514,message,message,8514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8800,1,['message'],['message']
Integrability,java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:162); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:79); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:996); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:541); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:474); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientReq,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:7560,protocol,protocol,7560,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['protocol'],['protocol']
Integrability,java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:77); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:361); 	at org.broadinstitute.hellbender.cmdline.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1727,protocol,protocol,1727,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,"java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.r",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:18120,Wrap,Wrappers,18120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['Wrap'],['Wrappers']
Integrability,java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19TdHJhbmRCaWFzVGVzdC5qYXZh) | `86.179% <0%> (+0.813%)` | `44% <0%> (+1%)` | :arrow_up: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `69.583% <0%> (+0.833%)` | `60% <0%> (+1%)` | :arrow_up: |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `0.862% <0%> (+0.862%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `93.194% <0%> (+1.047%)` | `61% <0%> (+2%)` | :arrow_up: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `73.118% <0%> (+1.075%)` | `25% <0%> (ø)` | :arrow_down: |; | [...e/hellbender/tools/spark/sv/utils/SVFileUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkZpbGVVdGlscy5qYXZh) | `29.67% <0%> (+1.099%)` | `7% <0%> (ø)` | :arrow_down: |; | ... and [506 more](https://codecov.io/gh/broadinstitute/gatk/pull/4621/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4621#issuecomment-378027085:3674,Integrat,IntegrationTestSpec,3674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4621#issuecomment-378027085,1,['Integrat'],['IntegrationTestSpec']
Integrability,"just curious, is deTin model already part of the GATK4 MuTect2 algorithm, or it has not been integrated yet?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3088#issuecomment-1887867443:93,integrat,integrated,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3088#issuecomment-1887867443,1,['integrat'],['integrated']
Integrability,"k.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:07 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 3, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:07 WARN TaskSetManager:66 - Lost task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:25919,Wrap,Wrappers,25919,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,k.java:271); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); [2018-04-15T03:55Z] ip-10-0-0-57: 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1038); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1029); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:969); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1029); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:760); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apach,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661:4111,Wrap,Wrappers,4111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661,1,['Wrap'],['Wrappers']
Integrability,k.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). **This is the stack I get when the test completes but fails (note that the expected line count appears to not match the line count of the expected output file in the repo): **. java.lang.AssertionError: line counts expected [2629] but found [507]; 	at org.testng.Assert.fail(Assert.java:94); 	at org.testng.Assert.failNotEquals(Assert.java:496); 	at org.testng.Assert.assertEquals(Assert.java:125); 	at org.testng.Assert.assertEquals(Assert.java:372); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:211); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:190); 	at org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.testExampleAssemblyRegionWalker(ExampleAssemblyRegionWalkerSparkIntegrationTest.java:29); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:3577,Integrat,IntegrationTestSpec,3577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['Integrat'],['IntegrationTestSpec']
Integrability,"ke a Microsoft bug than a GATK one though. It seems crazy that each layer pull has to be a separate web request and there's no batch api for it? Multi layer docker builds are pretty standard from what I understand. . It sounds like your suggestions are talking about 2 slightly different issues to me. 1. Too many layers:. We typically have squashed the GATK docker images, but we recently switched to building our release images with google cloud build. Since squash is *STILL* an experimental feature in docker we've had trouble getting it to work there. Since the size reduction was pretty minimal from squashing we figured it would be ok to not prioritize it. It's definitely possible for us to consolidate various layers in the build. Or manually squash the images. We can take a look for our next release. Wide workflows on azure are something we need to support. 2. Docker size reduction:; I've spend a lot of time looking at this in the past. Our docker image is huge, but it's mostly due to the massive size of our python and R dependencies. I've done a bunch of work reducing temporary files in independent layers and using multiple stages to reduce the size. There's not much low hanging fruit left there. Similarly, moving to alpine is tricky an has limited benefit. GATK packages a number of C libraries which do not work out of the box on alpine due to the different C runtime. (At least that was the case the last time I investigated it a few years ago. ) I suspect there's a way to port things so they work on it, but it's not something we can do now. It also wouldn't be much of a help, the base image is completely dwarfed by piles of python and R dependencies which are very difficult to safely trim. Anyway, that's the state of things. We've considered a java only image for a while which would be much smaller than the current one. (although still fat by most docker standards...). We've never released one publicly because it seemed like it might cause confusion, but it's a rea",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427:1123,depend,dependencies,1123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427,1,['depend'],['dependencies']
Integrability,ket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:77); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1677,protocol,protocol,1677,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,"l or two that use `PythonScriptExecutor` to call into a Python machine-learning library, and do an assessment of maintainability, etc. `PythonScriptExecutor` will come with an attached set of conditions for its use, intended to address the most serious issues raised by the engine and support teams with having Python code in the GATK. We should document these conditions in the docs for `PythonScriptExecutor` when it's implemented:. 1. All tools that use `PythonScriptExecutor` must have a Java-based front-end, with standard GATK (barclay-based) arguments. We put a lot of development effort into our arg parser and into striving for user-interface consistency across tools, and cannot afford to duplicate this effort in Python. Geraldine (CC'd) and the rest of the support team can back me up on this one!. 2. An honest effort should be made to minimize the amount of code written in Python -- as much of each tool's work as possible should be done in Java. In particular, reading/writing final inputs and outputs should happen in Java. This is important for a number of reasons, including the engine team's goal of ensuring universal GCS support, consistent Google authentication handling, etc. Again, we really don't want to have to duplicate that work in Python, or for the tools that call into Python to be inconsistent with the rest of the toolkit. 3. All dependencies (Python and native) of Python libraries used will be clearly documented, and included in the default GATK docker image. I don't think I need to explain why this one is important :) . 4. Before we go any further down this path, we prototype one or two tools using `PythonScriptExecutor`, and do a fair assessment of maintainability and other concerns of the engine/support teams, such as whether it will even be possible to package all dependencies without conflicts. 5. Engine team will continue to search for Java-based solutions while this evaluation is ongoing, but this proposal at least unblocks the CNV team for now.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3501:1547,depend,dependencies,1547,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501,2,['depend'],['dependencies']
Integrability,"l(StorageImpl.java:191); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	... 15 more; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; {; ""code"" : 403,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi."",; ""reason"" : ""forbidden""; } ],; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi.""; }; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4592:4048,message,message,4048,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4592,1,['message'],['message']
Integrability,"la:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:13:58 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0, scc-q16.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 9999, span 21707, expected MD5 059b07ed1e0589040ada9b236b88b509; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:6595,Wrap,Wrappers,6595,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['Wrap'],['Wrappers']
Integrability,lateGenotypes(GenotypingEngine.java:210); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:162); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:596); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1(HaplotypeCallerSpark.java:282); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1038); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:969); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:760); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230:1841,Wrap,WrappingSpliterator,1841,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230,1,['Wrap'],['WrappingSpliterator']
Integrability,"lbender.Main.main(Main.java:275); Caused by: java.net.SocketTimeoutException: connect timed out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:158); 	at com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:489); 	at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:206); 	... 31 more; ```; Followed by repetitions of the following stacktrace:; ```; Feb 07, 2018 12:41:59 PM com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; java.net.SocketTimeoutException: connect timed out; 	at jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369:4306,protocol,protocol,4306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369,1,['protocol'],['protocol']
Integrability,lbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:320); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:300); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:256); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:230); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:214); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapP,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:2678,wrap,wrapAndCopyInto,2678,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,2,['wrap'],['wrapAndCopyInto']
Integrability,lbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:324); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:304); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:256); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:230); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:214); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapP,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5979#issuecomment-498620174:2087,wrap,wrapAndCopyInto,2087,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5979#issuecomment-498620174,1,['wrap'],['wrapAndCopyInto']
Integrability,lbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); > at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); > at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.Iterator.forEachRemaining(Iterator.java:116); > at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); > at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); > at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); > at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); > at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); > at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); > at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); > at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); > at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); > at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); > at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); > at org.b,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708:21379,wrap,wrapAndCopyInto,21379,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708,1,['wrap'],['wrapAndCopyInto']
Integrability,lbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:173); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); > at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); > at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.Iterator.forEachRemaining(Iterator.java:116); > at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); > at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); > at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); > at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); > at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); > at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); > at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); > at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); > at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); > at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); > at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); > at org.b,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975:18767,wrap,wrapAndCopyInto,18767,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975,1,['wrap'],['wrapAndCopyInto']
Integrability,lbender.tools.walkers.filters.VariantFiltration.matchesFilter(VariantFiltration.java:453); 	at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.filter(VariantFiltration.java:407); 	at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.apply(VariantFiltration.java:354); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6789#issuecomment-686118887:2520,wrap,wrapAndCopyInto,2520,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6789#issuecomment-686118887,1,['wrap'],['wrapAndCopyInto']
Integrability,"ld happen now if some of the inputs lack PLs... (an Exception?) ; - For example QUAL could be approximated as the max of the input Quals, and QD as the average? ; - Or simple lift them blank?. So it would a bit of work I would say... 3 of the old PTs worth. ---. @vdauwera commented on [Thu May 14 2015](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-102235192). Recording test case while sanitizing: . The files are located here: . ```; gsa1:/humgen/gsa-scr1/schandra/GenotypeGVCFs_LargePloidyAndLargeAlleles; ```. The command I ran:. ```; java -jar /humgen/gsa-hpprojects/GATK/private_unstable_builds/GenomeAnalysisTK_latest_unstable.jar \; -T GenotypeGVCFs \; -R /humgen/gsa-scr1/schandra/GenotypeGVCFs_LargePloidyAndLargeAlleles/45S_Jacobsen_rearranged.fa \; -V /humgen/gsa-scr1/schandra/GenotypeGVCFs_LargePloidyAndLargeAlleles/Input_ploidy.list \; -o Sheila.GenotypeGVCFs.vcf; ```. Which produces:. ```; ##### ERROR MESSAGE: the combination of ploidy (19) and number of alleles (21) results in a very large number of genotypes (> 2147483647). You need to limit ploidy or the number of alternative alleles to analyze this locus; ```. ---. @chandrans commented on [Wed Jan 20 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-173357206). @davidbenjamin Hi David. Have you had a chance to look at this?. ---. @davidbenjamin commented on [Sat Jan 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-174245406). @chandrans My other bug turned into a very long undertaking, but seems to be nearing completion. It might even be done already, pending Laura's confirmation that the output vcfs are what we want. Then I will move on to this one. ---. @chandrans commented on [Tue Jan 26 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-175192516). Ah wonderful. Thanks David. ---. @davidbenjamin commented on [Tue Apr 12 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2955:3946,MESSAGE,MESSAGE,3946,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2955,1,['MESSAGE'],['MESSAGE']
Integrability,le-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAcce,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482:1212,Wrap,WrapperExecutor,1212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482,1,['Wrap'],['WrapperExecutor']
Integrability,"leMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.TaskSetManager: Task 284 in stage 25.0 failed 4 times; aborting job; 18/01/12 20:38:37 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@23007ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(50,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(52,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(34,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(60,WrappedArray()); 20:38:37.897 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [January 12, 2018 8:38:37 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 42.74 minutes.; Runtime.totalMemory()=16692805632; org.apache.spark.SparkException: Job aborted due to stage failure: Task 284 in stage 25.0 failed 4 times, most recent failure: Lost task 284.3 in stage 25.0 (TID 43224, cw-test-w-6.c.broad-dsde-methods.internal, executor 7): java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:5533,Wrap,WrappedArray,5533,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['Wrap'],['WrappedArray']
Integrability,"let's measure. 2 reruns of HC should tell us all we need to know. On Thu, Jul 7, 2016 at 12:06 PM, Louis Bergelson notifications@github.com; wrote:. > So there may be some unfortunate performance implications with some of; > these changes. Utils.nonNull(value, message) and it's compatriots will; > always compute the message even if the error condition is not met. Using; > any message which isn't a constant will generate garbage in the form of; > strings. In most cases this isn't a problem, but it is not ideal if it's; > placed in a tight loop.; > ; > We could offset the problem by adding a family of Utils functions that; > take a lambda String producer instead of a string itself, this would allow; > the message to be computed only when the error condition is triggered; > avoiding garbage creation.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gatk/pull/1979#issuecomment-231126857,; > or mute the thread; > https://github.com/notifications/unsubscribe/AB5rL-76TnggBn8C75KiUGdpb_0ZgIjdks5qTSQigaJpZM4JGaiQ; > .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1979#issuecomment-231127666:261,message,message,261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1979#issuecomment-231127666,4,['message'],['message']
Integrability,"lfs pull (#7806); - Document AoU SOP (up to the VAT) [VS-63] (#7807); - Incident VS 365 clinvar classification fix (#7769); - VS-390. Add precision and sensitivity wdl (#7813); - Quickstart based integration test [VS-357] (#7812); - 365 vat python testing additions (#7756); - VS 396 clinvar grabs too many values (#7823); - Added a test to validate WDLs in the scripts directory. (#7826) (#7829); - VAT Performance / Reliability Improvements (#7828); - VAT naming conventions [VS-410] (#7827); - Rc remove ad from vat (#7832); - bugfix, we were trying to grep a binary file (#7837); - Cleanup scripts/variantstore [VS-414] (#7834); - Merge VAT TSV files into single bgzipped file [VS-304] (#7848); - Handle fully and partially loaded samples [VS-262] [VS-258] (#7843); - Ingest Error Handling Fixes [VS-261] (#7841); - First cut at a python notebook to validate inputs. (#7845); - Compute filter scatter [VS-392] (#7852); - remove withdrawn req (#7844); - Improve import error message [VS-437] (#7855); - Fix Input Validation python notebook (#7853); - Add VAT Validation check that aa_change and exon_number are consistently set. (#7850); - Ingest 10K [VS-344] (#7860); - X/Y chromosome reweighting for better extract shard runtime balance [VS-389] (#7868); - VET Ingest Validation / Allow Ingest of non-VQSR'ed data (#7870); - Fix AoU workflow bugs (#7874); - Curate input arrays to skip already ingested sample data [VS-246] (#7862); - KM upload GVS product sheet (#7883); - Default extract scatter width [VS-415] (#7878); - Volatile tasks review [VS-447] (#7880); - Update Quickstart Integration for X/Y scaling changes [VS-464] (#7881); - clean up dockstore; - Rc vs 63 vat sop documentation (#7879); - Fix up FQ and race condition issues with volatile tasks work [VS-478] (#7888); - Use gvs-internal project in integration test (#7901); - Add cost observability BQ table [VS-441] (#7891); - Add preliminary labels to queries [VS-381] (#7902); - Workflow compute costs [VS-472] (#7905); - Fix bu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:24579,message,message,24579,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['message'],['message']
Integrability,libration.BaseRecalibrationEngine.calculateSkipArray(BaseRecalibrationEngine.java:322); 	at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:137); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:185); 	at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:91); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:89); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:7253,wrap,wrapAndCopyInto,7253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,1,['wrap'],['wrapAndCopyInto']
Integrability,lkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:131); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:106); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker$$Lambda$110/1374115041.accept(Unknown Source); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:163); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6913:9631,wrap,wrapAndCopyInto,9631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6913,1,['wrap'],['wrapAndCopyInto']
Integrability,lkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:131); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:106); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker$$Lambda$110/1374115041.accept(Unknown Source); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:163); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hel,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-716640444:9394,wrap,wrapAndCopyInto,9394,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-716640444,1,['wrap'],['wrapAndCopyInto']
Integrability,"ll(ExternalSorter.scala:191); 	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.TaskSetManager: Task 284 in stage 25.0 failed 4 times; aborting job; 18/01/12 20:38:37 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@23007ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(50,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(52,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(34,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(60,WrappedArray()); 20:38:37.897 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [January 12, 2018 8:38:37 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 42.74 minutes.; Runtime.totalMemory()=16692805632; org.apache.spark.SparkException: Job aborted due to stage failure: Task 284 in stage 25.0 failed 4 times, most recent failure: Lost task 284.3 in st",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:5357,Wrap,WrappedArray,5357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['Wrap'],['WrappedArray']
Integrability,llbender.tools.walkers.variantutils.SelectVariants.initalizeAlleleAnyploidIndicesCache(SelectVariants.java:674); at org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants.apply(SelectVariants.java:580); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:106); at org.broadinstitute.hellbender.engine.VariantWalker$$Lambda$73/388489274.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:104); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5929:2894,wrap,wrapAndCopyInto,2894,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5929,1,['wrap'],['wrapAndCopyInto']
Integrability,"llegalArgumentException: evidence provided is not in sample'. Full stack trace below. This is found for Sample NA17-308, Shard 49.; https://cromwell.gotc-dev.broadinstitute.org/api/workflows/1/83938362-b9b5-49f3-a65d-715065d6eabd/metadata; Execution bucket is:; broad-gotc-dev-cromwell-execution (results will stay there for 30 days before being automatically cleaned up). ----. ## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - 4.1.7.0. ### Description ; Stack trace:; java.lang.IllegalArgumentException: evidence provided is not in sample; 	at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.lambda$removeEvidence$9(AlleleLikelihoods.java:1124); 	at java.util.stream.ReferencePipeline$4$1.accept(ReferencePipeline.java:210); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:546); 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 	at java.util.stream.IntPipeline.toArray(IntPipeline.java:504); 	at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.removeEvidence(AlleleLikelihoods.java:1128); 	at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.contaminationDownsampling(AlleleLikelihoods.java:315); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:173); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:608); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:210); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6586:1154,wrap,wrapAndCopyInto,1154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6586,1,['wrap'],['wrapAndCopyInto']
Integrability,llion parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogle,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:1160,protocol,protocol,1160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156,1,['protocol'],['protocol']
Integrability,logger message in SortReadFileSpark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3095:7,message,message,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3095,1,['message'],['message']
Integrability,looks fine. the biggest issue is that now we have completely separate integration tests for dataflow and non-dataflow tools. This is non sustainable i think. can you come up with a way to reuse and keep things in synch? back to @lbergelson,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/443#issuecomment-96791578:70,integrat,integration,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443#issuecomment-96791578,1,['integrat'],['integration']
Integrability,ls.java:283); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.AlleleSubsettingUtils.subsetAlleles(AlleleSubsettingUtils.java:92); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:296); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:210); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:162); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:596); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1(HaplotypeCallerSpark.java:282); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1038); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:969); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1029); 	a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230:1499,Wrap,WrappingSpliterator,1499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230,1,['Wrap'],['WrappingSpliterator']
Integrability,ls.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:130); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:281); at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:135); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:423); at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1058); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadins,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437:9428,wrap,wrapAndCopyInto,9428,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437,1,['wrap'],['wrapAndCopyInto']
Integrability,"ltTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 00:11:09.632 WARN TaskSetManager:66 - Lost task 15.0 in stage 1.0 (TID 519, localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:5872,wrap,wrapAndCopyInto,5872,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['wrap'],['wrapAndCopyInto']
Integrability,"lterMutectCalls - Shutting down engine; [December 12, 2020 2:51:02 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2385510400; java.lang.IllegalStateException: Duplicate key 7.395307178412063E-4; at java.util.stream.Collectors.lambda$throwingMerger$138(Collectors.java:133); at java.util.stream.Collectors$$Lambda$67/403388441.apply(Unknown Source); at java.util.HashMap.merge(HashMap.java:1245); at java.util.stream.Collectors.lambda$toMap$196(Collectors.java:1320); at java.util.stream.Collectors$$Lambda$69/854719230.accept(Unknown Source); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.<init>(ContaminationFilter.java:26); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.buildFiltersList(Mutect2FilteringEngine.java:290); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.<init>(Mutect2FilteringEngine.java:60); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.onTraversalStart(FilterMutectCalls.java:138); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProg",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6996:4199,wrap,wrapAndCopyInto,4199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996,1,['wrap'],['wrapAndCopyInto']
Integrability,ltering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-29T18:18:04.002441351Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-29T18:18:04.002446409Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-29T18:18:04.002493533Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-29T18:18:04.002503311Z 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 2019-10-29T18:18:04.002508016Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002512520Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002574562Z 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 2019-10-29T18:18:04.002625341Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 2019-10-29T18:18:04.002635077Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002683298Z 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 2019-10-29T18:18:04.002692496Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); 2019-10-29T18:18:04.002697751Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002731707Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 2019-10-29T18:18:04.002740306Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6237:3559,wrap,wrapAndCopyInto,3559,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6237,1,['wrap'],['wrapAndCopyInto']
Integrability,ltering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-29T18:18:04.002441351Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-29T18:18:04.002446409Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-29T18:18:04.002493533Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-29T18:18:04.002503311Z 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 2019-10-29T18:18:04.002508016Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002512520Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002574562Z 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 2019-10-29T18:18:04.002625341Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 2019-10-29T18:18:04.002635077Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002683298Z 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 2019-10-29T18:18:04.002692496Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); 2019-10-29T18:18:04.002697751Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002731707Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 2019-10-29T18:18:04.002740306Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:3559,wrap,wrapAndCopyInto,3559,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300,1,['wrap'],['wrapAndCopyInto']
Integrability,ltering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-30T13:35:51.795253632Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.795448274Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-30T13:35:51.795607447Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-30T13:35:51.795775473Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-30T13:35:51.795944490Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-30T13:35:51.796108757Z 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 2019-10-30T13:35:51.796277399Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.796441683Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.796940319Z 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 2019-10-30T13:35:51.797119562Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 2019-10-30T13:35:51.797275911Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.797439525Z 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 2019-10-30T13:35:51.797567816Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); 2019-10-30T13:35:51.797740910Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.797896360Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 2019-10-30T13:35:51.798060735Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:3560,wrap,wrapAndCopyInto,3560,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227,1,['wrap'],['wrapAndCopyInto']
Integrability,"m/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.23.4...v3.25.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:2975,depend,dependabot-automerge-start,2975,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,mFeatureContext(DataSourceFuncotationFactory.java:314); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:229); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:207); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); > at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); > at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); > at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); > at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); > at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); > at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); > at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); > at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); > at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708:20090,wrap,wrapAndCopyInto,20090,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708,1,['wrap'],['wrapAndCopyInto']
Integrability,"mVariants - Reference allele is too long (236) at position chr1:214679654; skipping that record. Set --reference_window_stop >= 236 ; ...; INFO 21:38:54,227 LeftAlignAndTrimVariants - Reference allele is too long (212) at position chr2_KI270894v1_alt:202602; skipping that record. Set --reference_window_stop >= 212 ; INFO 21:38:54,233 LeftAlignAndTrimVariants - Reference allele is too long (220) at position chr2_KI270894v1_alt:204859; skipping that record. Set --reference_window_stop >= 220 ; INFO 21:38:54,237 LeftAlignAndTrimVariants - Reference allele is too long (262) at position chr2_KI270894v1_alt:207863; skipping that record. Set --reference_window_stop >= 262 ; 0 variants were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from abov",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487:7305,message,messages,7305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487,1,['message'],['messages']
Integrability,make kmer counts depend on coverage,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3819:17,depend,depend,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3819,1,['depend'],['depend']
Integrability,making constants BQSR_TABLE_LONG_NAME and BQSR_TABLE_SHORT_NAME in StandardArgumentDefinitions; fixing outdated references to -BQSR -> -bqsr in documentation and error messages; fixes #1631,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1633:168,message,messages,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1633,1,['message'],['messages']
Integrability,making the version number depend on the git hash using a gradle git plugin from https://github.com/ajoberstar/gradle-git. It seems like the top gradle-git integration library. There are lots of pre-baked things in it to help with releases and such that we can grow into.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/196:26,depend,depend,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/196,2,"['depend', 'integrat']","['depend', 'integration']"
Integrability,manage_sv_pipeline checks version from gatk-spark.jar and compares it; to the current git hash (to ensure the correct version is run). Newer; gatk versions had a slightly different file name format and caused; errors parsing the hash. This updates the hash check and produces; more comprehensible error messages when it fails. Resolves: #3593,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3595:303,message,messages,303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3595,1,['message'],['messages']
Integrability,"mark duplicates in dataflow - based on the code by garrickevans . The main work is done in; `private static final class MarkDuplicatesDataflowTransform extends PTransform<PCollection<Read>, PCollection<Read>>` - the sigrature conforms to the main read processing pipeline. Limitations:; - no optical duplicates; - only integration tests (would be good to have unit tests that check dup detection logic on very specific reads - ideally those from picard's tests). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/541:319,integrat,integration,319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/541,1,['integrat'],['integration']
Integrability,"maybe we could use a different character than `:` to separate logical names. Maybe `+` (?) Or hardwire a bunch of protocols like `hdfs`, `file`, `gs`, etc?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2000#issuecomment-232473734:114,protocol,protocols,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2000#issuecomment-232473734,1,['protocol'],['protocols']
Integrability,"menode:8020/$dir_prepro$output -- \; --spark-runner SPARK --spark-master spark://$SPARK_MASTER_HOST:7077 \; --driver-memory 20g --executor-cores 4 --executor-memory 8g; ```. Furthermore I have this problem with this version v4.0.4.0-23-g6e1cc8c-SNAPSHOT. > mark duplicate records objects corresponding to read with name, this could be the result of readnames spanning more than one partition; 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$null$0(MarkDuplicatesSpark.java:109); 	at java.util.HashMap.merge(HashMap.java:1253); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$mark$62928560$1(MarkDuplicatesSpark.java:109); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:7527,wrap,wrapAndCopyInto,7527,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['wrap'],['wrapAndCopyInto']
Integrability,mention --help in error message,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1341:24,message,message,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1341,1,['message'],['message']
Integrability,merged two ploidy models together and got rid of interface,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6082:49,interface,interface,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6082,1,['interface'],['interface']
Integrability,"mmm... that said, I think this must fail using the right error message, don't you think? @droazen.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290743500:63,message,message,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290743500,1,['message'],['message']
Integrability,"more recent versions of gatk have a different message now, which is also confusing:. ```; ./gatk-launch PrintReadsSpark -I hdfs://local/print_reads.sorted.bam -O output.bam -- --sparkRunner SPARK --sparkMaster yarn-client; ```. ```; java.lang.IllegalArgumentException: java.net.UnknownHostException: local; at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:374); at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:310); at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:176); at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:707); at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:650); at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:148); at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2643); at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:93); at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2680); at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2662); at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:379); at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:183); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:337); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:317); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:308); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(Co",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1257#issuecomment-175789890:46,message,message,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1257#issuecomment-175789890,1,['message'],['message']
Integrability,"most people get protected. I'd rather push the pain down to public (unless; it doubles the pain and both repos need this). Oh btw, perhaps we should spin off the HDF5 to a separate project that we; would just inject in gatk; wdyt?. On Thu, Jun 9, 2016 at 10:37 AM, Louis Bergelson notifications@github.com; wrote:. > do we want this in protected? It means people have to go through arcane; > installation procedures...; > ; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gatk/pull/1901#issuecomment-224914735,; > or mute the thread; > https://github.com/notifications/unsubscribe/AB5rLyoyUN__Bfdub4Sejc920Eh84aQUks5qKCUMgaJpZM4IxmGO; > .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1901#issuecomment-224925037:209,inject,inject,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1901#issuecomment-224925037,1,['inject'],['inject']
Integrability,moved dependency fixes from protected to here,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1863:6,depend,dependency,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1863,1,['depend'],['dependency']
Integrability,"mputeLogLikelihoods() : 0.28976746200000003; 14:14:09.378 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 1.41 sec; 14:14:09.384 INFO Mutect2 - Shutting down engine; [May 13, 2022 2:14:09 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.49 minutes.; Runtime.totalMemory()=850644992; java.lang.ArrayIndexOutOfBoundsException: -1; at java.util.ArrayList.elementData(ArrayList.java:422); at java.util.ArrayList.get(ArrayList.java:435); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.lambda$getGermlineAltAlleleFrequencies$27(SomaticGenotypingEngine.java:376); at java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:244); at java.util.stream.SliceOps$1$1.accept(SliceOps.java:204); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:546); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.DoublePipeline.toArray(DoublePipeline.java:530); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getGermlineAltAlleleFrequencies(SomaticGenotypingEngine.java:377); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getNegativeLogPopulationAFAnnotation(SomaticGenotypingEngine.java:354); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:161); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:283); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:300); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:200); at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7849:5434,wrap,wrapAndCopyInto,5434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7849,1,['wrap'],['wrapAndCopyInto']
Integrability,n Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); [TileDB::FileSystem] Error: hdfs: Error getting hdfs connection; [TileDB::StorageManagerConfig] Error: Error getting hdfs connection: Connection refused.; Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest > testWriteToAndQueryFromGCS FAILED; java.io.IOException: GenomicsDB JNI Error: VCFAdapterException : Could not copy contents of VCF header filename gs://hellbender-test-,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6522:6898,Message,MessageHub,6898,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6522,1,['Message'],['MessageHub']
Integrability,"n Tools; #; # Only update this environment if there is a *VERY* good reason to do so!; # If the build is broken but could be fixed by doing something else, then do that thing instead.; # Ensuring the correct environment for canonical (or otherwise reasonable) usage of our standard Docker takes precedence over edge cases.; # If you break the environment, you are responsible for fixing it and also owe the last developer who left this in a reasonable state a beverage of their choice.; # (This may be yourself, and you'll appreciate that beverage while you tinker with dependencies!); #; # When changing dependencies or versions in this file, check to see if the ""supportedPythonPackages"" DataProvider; # used by the testGATKPythonEnvironmentPackagePresent test in PythonEnvironmentIntegrationTest needs to be updated; # to reflect the changes.; #; name: gatk; channels:; # if channels other than conda-forge are added and the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely nec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:1300,depend,dependencies,1300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['depend'],['dependencies']
Integrability,"n a new `--segments` argument:. ```; gatk ModelSegments; --normal-allelic-counts normal.allelicCounts.tsv (equivalently, we could omit this and adjust minimum-total-allele-count-case, as is done in the WDL); --allelic-counts normal.allelicCounts.tsv; --denoised-copy-ratios normal.denoisedCR.tsv; --segments joint-segmentation.interval_list; -O .; --output-prefix normal. gatk ModelSegments; --normal-allelic-counts normal.allelicCounts.tsv; --allelic-counts tumor-1.allelicCounts.tsv; --denoised-copy-ratios tumor-1.denoisedCR.tsv; --segments joint-segmentation.interval_list; -O .; --output-prefix tumor-1. ...; ```. Each scatter of ModelSegments will run as before, aside from skipping the segmentation step in favor of using the joint segmentation. We will repeat the het-genotyping step, but this is cheap and it's probably better to repeat it to make sure filtering is applied consistently. It would also require more changes to the command line to specify where to output the hets for each sample during multisample segmentation and to skip genotyping in each scatter, if we were to go that route. There are many possible combinations of inputs that need to be tested, but the same is already true of the current ModelSegments. Furthermore, there are slight wrinkles when running in tumor-only mode (i.e., when `--normal-allelic-counts` are not available). Because each sample is genotyped indiviudally, each may yield a different set of hets (in contrast to genotyping in matched-normal mode, in which the normal determines the set of hets used in all samples). We will thus have to take the intersection of these hets before performing multisample segmentation. Unfortunately, we will not be able to re-perform this intersection in each scatter, since we will no longer have access to the hets from the other samples. However, we *will* ultimately intersect the hets from each sample with the joint segmentation before modeling, which may be a rough proxy for the intersection of hets from a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607313549:2490,rout,route,2490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607313549,1,['rout'],['route']
Integrability,"n chr1:10254; skipping that record. Set --max-indel-length >= 204; 12:55:32.502 INFO LeftAlignAndTrimVariants - Reference allele is too long (207) at position chr1:10276; skipping that record. Set --max-indel-length >= 207; 12:55:32.536 INFO ProgressMeter - unmapped 0.0 295 178787.9; 12:55:32.536 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 12:55:32.536 INFO LeftAlignAndTrimVariants - 133 variants trimmed; 12:55:32.536 INFO LeftAlignAndTrimVariants - 10 variants skipped because the reference allele was too long. The longest had a reference allele length of 245. To not skip these variants set --max-indel-length >= 245; 12:55:32.536 INFO LeftAlignAndTrimVariants - 0 variants left aligned; 12:55:32.542 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 6, 2018 12:55:32 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=249036800; ```; Multiple changes to messages in stdout. Includes # total records, number of records that were trimmed, # variant records skipped due to ref allele being too long and finally the max-indel-length value that needs to be set to include these in the leftalignandtrim. This is an improvement to previous stdout messaging. Upping max-indel-length; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLib",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:5770,message,messages,5770,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326,1,['message'],['messages']
Integrability,"n parsing unknown fields in Java.</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/850fcce9176e2c9070614dab53537760498c926b""><code>850fcce</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b7044987de77f1dc368fee558636d0b56d7e75e1""><code>b704498</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/e67347986eaf7d777a6ee34367fa99f4912423ab""><code>e673479</code></a> Fix cord handling in DynamicMessage and oneofs. (<a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/18375"">#18375</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/8a60b6527a976cfd0028153da3ad8e4ed280e0de""><code>8a60b65</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.23.4...v3.25.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot reba",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:2121,protocol,protocolbuffers,2121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,2,"['message', 'protocol']","['message', 'protocolbuffers']"
Integrability,"n't find the file, but the file is on the local file system. ```; ls -la /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; -rw-rw-r--. 1 test test 4668988887 Oct 4 11:27 /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; ```. Here is SPARK information. ```; A USER ERROR has occurred: Failed to read bam header from; /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; Caused by:File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Failed to read bam header from /hom",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:1288,protocol,protocolPB,1288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocolPB']
Integrability,n(EntryPoint.java:45); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54); at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35); at org.gradle.launcher.GradleMain.main(GradleMain.java:23); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:129); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: org.gradle.api.UncheckedIOException: java.io.IOException: Disk quota exceeded; at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:58); at org.gradle.cache.internal.btree.CachingBlockStore.close(CachingBlockStore.java:40); at org.gradle.cache.internal.btree.FreeListBlockStore.close(FreeListBlockStore.java:60); at org.gradle.cache.internal.btree.StateCheckBlockStore.close(StateCheckBlockStore.java:41); at org.gradle.cache.internal.btree.BTreePersistentIndexedCache.close(BTreePersistentIndexedCache.java:195); ... 60 more; Caused by: java.io.IOException: Disk quota exceeded; at java.io.RandomAccessFile.close0(Native Method); at java.io.RandomAccessFile.close(RandomAccessFile.java:645); at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:56); ... 64 more; Could not stop Service PluginResolutionServiceClient at BuildScopeServices.createPluginResolutionSer,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:14143,wrap,wrapper,14143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,1,['wrap'],['wrapper']
Integrability,n(EntryPoint.java:45); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54); at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35); at org.gradle.launcher.GradleMain.main(GradleMain.java:23); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:129); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: org.gradle.api.UncheckedIOException: java.io.IOException: Disk quota exceeded; at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:58); at org.gradle.cache.internal.btree.CachingBlockStore.close(CachingBlockStore.java:40); at org.gradle.cache.internal.btree.FreeListBlockStore.close(FreeListBlockStore.java:60); at org.gradle.cache.internal.btree.StateCheckBlockStore.close(StateCheckBlockStore.java:41); at org.gradle.cache.internal.btree.BTreePersistentIndexedCache.close(BTreePersistentIndexedCache.java:195); ... 60 more; Caused by: java.io.IOException: Disk quota exceeded; at java.io.RandomAccessFile.close0(Native Method); at java.io.RandomAccessFile.close(RandomAccessFile.java:645); at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:56); ... 64 more; Could not stop org.gradle.cache.internal.DefaultMultiProcessSafePersistentIndexedCache@4f4dc135.; or,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:7318,wrap,wrapper,7318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,1,['wrap'],['wrapper']
Integrability,n(EntryPoint.java:45); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54); at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35); at org.gradle.launcher.GradleMain.main(GradleMain.java:23); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:129); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: org.gradle.api.UncheckedIOException: java.io.IOException: Disk quota exceeded; at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:58); at org.gradle.cache.internal.btree.CachingBlockStore.close(CachingBlockStore.java:40); kStore.java:60); at org.gradle.cache.internal.btree.StateCheckBlockStore.close(StateCheckBlockStore.java:41); at org.gradle.cache.internal.btree.BTreePersistentIndexedCache.close(BTreePersistentIndexedCache.java:195); ... 64 more; Caused by: java.io.IOException: Disk quota exceeded; at java.io.RandomAccessFile.close0(Native Method); at java.io.RandomAccessFile.close(RandomAccessFile.java:645); at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:56); ... 68 more. FAILURE: Build failed with an exception.; - What went wrong:; org.gradle.api.UncheckedIOException: java.io.IOException: Disk quota exceeded; - Try:; Run with --stacktrace o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:21526,wrap,wrapper,21526,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,1,['wrap'],['wrapper']
Integrability,"n/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc:1:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h: In instantiation of 'static NUMBER ContextBase<NUMBER>::approximateLog10SumLog10(NUMBER, NUMBER) [with NUMBER = float]':; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:75:53: required from 'static void ContextBase<NUMBER>::initializeMatchToMatchProb() [with NUMBER = float]'; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:47:35: required from 'static void ContextBase<NUMBER>::initializeStaticMembers() [with NUMBER = float]'; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc:52:19: required from here; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:16: error: 'isinf' was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive]; if (isinf(small) == -1 || isinf(big) == -1); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:4,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/utils.h:4,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc:1:; /usr/local/Cellar/gcc/5.3.0/include/c++/5.3.0/cmath:853:5: note: 'template<class _Tp> typename __gnu_cxx::__enable_if<std::__is_arithmetic<_Tp>::__value, int>::__type std::isinf(_Tp)' declared here, later in the translation unit; isinf(_Tp __f); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/utils.h:4:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc:1:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:38: error: 'isinf' was not declared ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343:10277,depend,dependent,10277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343,1,['depend'],['dependent']
Integrability,"n/gatk-4.1.9.0/gatk --java-options -Xms24g VariantRecalibrator -V temp/vartiant_germline/sites.only.vcf.gz -O temp/vartiant_germline/recaliberation.indel.vcf --tranches-file temp/vartiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz --use-allele-specific-annotations`. #### Error Message; ```; Using GATK jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms24g -jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantRecalibrator -V temp/vatiant_germline/sites.only.vcf.gz -O temp/vatiant_germline/recaliberation.indel.vcf --tranches-file temp/vatiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_su",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6963:1690,Message,Message,1690,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963,1,['Message'],['Message']
Integrability,"n: chr3:117,527,190; INFO	2022-05-06 12:14:45	SortVcf	wrote 800,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:134,613,380; INFO	2022-05-06 12:14:45	SortVcf	wrote 825,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:153,780,108; INFO	2022-05-06 12:14:45	SortVcf	wrote 850,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:173,329,831; INFO	2022-05-06 12:14:46	SortVcf	wrote 875,000 records. Elapsed time: 00:00:03s. Time for last 25,000: 0s. Last read position: chr3:192,133,262; [Fri May 06 12:14:46 EDT 2022] picard.vcf.SortVcf done. Elapsed time: 0.36 minutes.; Runtime.totalMemory()=2855272448; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp. java.lang.ArrayIndexOutOfBoundsException: 16799; 	at htsjdk.samtools.BinningIndexBuilder.processFeature(BinningIndexBuilder.java:102); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.finalizeFeature(TabixIndexCreator.java:106); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.addFeature(TabixIndexCreator.java:92); 	at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:203); 	at htsjdk.variant.variantcontext.writer.VCFWriter.add(VCFWriter.java:242); 	at picard.vcf.SortVcf.writeSortedOutput(SortVcf.java:183); 	at picard.vcf.SortVcf.doWork(SortVcf.java:101); 	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); 	at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292); ```. #### Expected output. There's almost certainly some format issue with my VCF, but ideally GATK would have a better error message than ArrayIndexOutOfBoundsException.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7838:3169,message,message,3169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7838,1,['message'],['message']
Integrability,"nHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 5.0 failed 1 times, most recent failure: Lost task 1.0 in stage 5.0 (TID 12, localhost, executor driver): java.util.ConcurrentModificationException; 	at java.util.ArrayList.sort(ArrayList.java:1464); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.<init>(ReadThreadingAssembler.java:81); 	at org.bro",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:7261,Message,MessageHub,7261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['Message'],['MessageHub']
Integrability,"nHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:5570,Message,MessageHub,5570,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,1,['Message'],['MessageHub']
Integrability,nMapForVariant(FuncotatorEngine.java:162); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:924); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1095); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680:5016,wrap,wrapAndCopyInto,5016,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680,1,['wrap'],['wrapAndCopyInto']
Integrability,"nager: Starting task 1.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 1, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:55:54 INFO TaskSetManager: Lost task 0.0 in stage 2.0 (TID 3) on xx.xx.xx.25, executor 2: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 01:00 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:54 INFO TaskSetManager: Starting task 0.1 in stage 2.0 (TID 6, xx.xx.xx.16, executor 3, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:55:55 INFO TaskSetManager: Lost task 0.1 in stage 2.0 (TID 6) on xx.xx.xx.16, executor 3: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 2]; 01:00 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:55 INFO TaskSetManager: Starting task 0.2 in stage 2.0 (TID 7, xx.xx.xx.23, executor 5, partition 0, PROCESS_LOCAL, 6010 bytes); 18/04/24 17:55:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.23:42535 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:55:55 INFO TaskSetManager: Lost task 0.2 in stage 2.0 (TID 7) on xx.xx.xx.23, executor 5: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 3]; 01:00 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:55:55 INFO TaskSetManager: Starting task 0.3 in stage 2.0 (TID 8, xx.xx.xx.24, executor 4, partition 0, PROCESS_LOCAL, 601",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:28033,Wrap,WrappedArray,28033,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Wrap'],['WrappedArray']
Integrability,"nager:54 - Lost task 3.1 in stage 0.0 (TID 4) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 1]; 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 7, scc-q12.scc.bu.edu, executor 2, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 WARN TaskSetManager:66 - Lost task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 3, start 97885291, span 192458, expected MD5 ef90368731b6e0be845bc82cd92b0c6a; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:30299,Wrap,Wrappers,30299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"naging and querying Supplementary alignment; > information from read alignment records:; >; > Some of the things that I think smell:; >; > 1.; >; > Querying: implemented in htsjdk consists in forging artificial; > SAMRecords that contain only the alignment info in the SA tag element... It; > seems to me that it makes more sense to create class to hold this; > information alone (e.g. ReadAlignmentInfo or ReadAlignment); SATagBuilder; > already has defined a private inner class with that in mind ""SARead"" so why; > not flesh it out and make it public.; > 2.; >; > Writing: currently SATagBuilder gets attached to a read, parsing its; > current SA attribute content into SARead instances. It provides the; > possibility adding additional SAM record one by one or clearing the list.; > ... then it actually updates the SA attribute on the original read when a; > method (setTag) is explicitly called.; >; > I don't see the need to attach the SATag Builder to a read... it could; > perfectly be free standing; the same builder could be re-apply to several; > reads for that matter and I don't see any gain in hiding the read SA tag; > setting process,... even if typically this builder output would go to the; > ""SA"" tag, perhaps at some point we would like to also write SA coordinate; > list somewhere else, some other tag name or perhaps an error message... why; > impose this single purpose limitation?; >; > I suggest to drop the notion of a builder for a more general custom; > ReadAlignmentInfo (or whatever name) list. Such list could be making; > reference to a dictionary to validate its elements, prevent duplicates,; > keep the primary SA in the first position... etc.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3324>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AArTZft11VTCtCHT_xr89kPL7hMFYQyhks5sQNghgaJpZM4Ofpkb>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323:2115,message,message,2115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323,1,['message'],['message']
Integrability,"ncher.java:331); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:264); 	at htsjdk.samtools.metrics.MetricsFile.loadClass(MetricsFile.java:471); 	at htsjdk.samtools.metrics.MetricsFile.read(MetricsFile.java:353); 	... 8 more; ```. If it is replaced, the tool still errors but with a different error:; ```; java.lang.IllegalArgumentException: Features added out of order: previous (TabixFeature{referenceIndex=0, start=118314029, end=118314036, featureStartFilePosition=1403632633, featureEndFilePosition=-1}) > next (TabixFeature{referenceIndex=0, start=33414233, end=33414234, featureStartFilePosition=1403632876, featureEndFilePosition=-1}); 	at htsjdk.tribble.index.tabix.TabixIndexCreator.addFeature(TabixIndexCreator.java:89); 	at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:170); 	at htsjdk.variant.variantcontext.writer.VCFWriter.add(VCFWriter.java:219); 	at java.util.ArrayList.forEach(ArrayList.java:1249); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalSuccess(FilterByOrientationBias.java:171); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:781); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); 	at org.broadinstitute.hellbender.Main.main(Main.java:221); ```. It does not matter if I produce the pre-adapter metrics with the latest Picard jar v2.9.2. I get the same error. . I'm using a M2 callset from GATK3. Even so, I don't think I should get the above error?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030:3915,adapter,adapter,3915,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030,1,['adapter'],['adapter']
Integrability,ncodeFuncotationFactory.java:2465); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:953); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:812); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:796); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:473); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:474); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:529); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036:8139,wrap,wrapAndCopyInto,8139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036,1,['wrap'],['wrapAndCopyInto']
Integrability,ncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:529); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Ite,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036:9649,wrap,wrapAndCopyInto,9649,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036,1,['wrap'],['wrapAndCopyInto']
Integrability,ncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:152); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:924); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Ite,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653:4685,wrap,wrapAndCopyInto,4685,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653,1,['wrap'],['wrapAndCopyInto']
Integrability,ncurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.net.UnknownHostException: www.googleapis.com; 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:668); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.jav,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094:7136,protocol,protocol,7136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094,1,['protocol'],['protocol']
Integrability,"nd other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge::keras after 2.2.5; # undesirably set the environment variable KERAS_BACKEND = theano by default; - defaults::intel-openmp=2019.4; - conda-forge::scikit-learn=0.22.2; - conda-forge::matplotlib=3.2.1; - conda-forge::pandas=1.0.3. # core R dependencies; these should only be used for plotting and do not take precedence over core python dependencies!; - r-base=3.6.2; - r-data.table=1.12.8; - r-dplyr=0.8.5; - r-getopt=1.20.3; - r-ggplot2=3.3.0; - r-gplots=3.0.3; - r-gsalib=2.1; - r-optparse=1.6.4. # other python dependencies; these should be removed after functionality is moved into Java code; - biopython=1.76; - pyvcf=0.6.8; - bioconda::pysam=0.15.3 # using older conda-installed versions may result in libcrypto / openssl bugs. # pip installs should be avoided, as pip may not respect the dependencies found by the conda solver; - pip:; - gatkPythonPackageArchive.zip; ```. It seems to successfully create the environment. I'd still recommend updating the information on your README.md and the file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:3197,depend,dependencies,3197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,4,['depend'],['dependencies']
Integrability,"ndardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/resources/main'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/tmp/sparkJar/MANIFEST.MF'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; ```. ```; Deprecated Gradle features were used in this build, making it incompatible with Gradle 8.0. You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins. See https://docs.gradle.org/7.3.2/userguide/command_line_interface.html#sec:command_line_warnings. Execution optimizations have been disabled for 4 invalid unit(s) of work during this build to ensure correctness.; Please consult deprecation warnings for more details.; ```; The warnings show up in at least these tasks: gatkTabComplete, installDist, gatkDoc, shadowJar, sparkJar. Seems like it should be easy to fix, I'm not sure how we didn't see th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7625:1493,depend,dependency,1493,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7625,1,['depend'],['dependency']
Integrability,nder.tools.walkers.varianteval.VariantEval$PositionAggregator.addVariant(VariantEval.java:478) at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval$PositionAggregator.access$100(VariantEval.java:469) at org.broadinstitute.hellbender.tools.walkers.varianteval.VariantEval.apply(VariantEval.java:511) at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120) at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) at java.util.Iterator.forEachRemaining(Iterator.java:116) at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151) at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174) at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418) at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118) at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049) at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211) at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160) at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203) at org.broadinstitute.hellbender.M,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7304:5898,wrap,wrapAndCopyInto,5898,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7304,1,['wrap'],['wrapAndCopyInto']
Integrability,ndexedFeatureReader$WFIterator.readNextRecord(TribbleIndexedFeatureReader.java:365); at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:346); at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:307); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); ```. I ran `java -jar gatk-4.0.0.0/gatk-package-4.0.0.0-local.jar SelectVariants -V gnomADaccuracyTest.noMQinSNPVQSR.SynDip.vcf.gz -O testNoIndex.vcf.gz`. Data is at `/humgen/gsa-hpprojects/dev/gauthier/reblockGVCF` If I remember to pull down the index everything works swimmingly. I'd love for this to either work without an index or fail early with an appropriate message about the index being missing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224:2959,message,message,2959,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224,1,['message'],['message']
Integrability,"nds for identifying the copy-neutral state.; - [ ] @MartonKN is going to work on an improved caller for his next project. This caller should also make simple calls (not full allelic copy number, but just `0`, `+`, `-`), but should also take advantage of the copy-ratio and minor-allele fraction posteriors estimated by `ModelSegments` to generate quality scores. Plotting:; - Other than the allele-fraction model, the limiting factor was the original plotting code (some plotting runs originally took several hours for a single WGS sample...) We can now make plotting much faster with the ordering enforced by `TSVLocatableCollection` (see below).; - There are now two plotting tools, `PlotDenoisedCopyRatios` and `PlotModeledSegments`. This is in contrast to the old `PlotSegmentedCopyRatio` and `PlotACNVResults`.; - Because `ModelSegments` optionally takes denoised copy ratio and/or allelic counts, `PlotModeledSegments` outputs only the corresponding plots appropriately.; - I added a dependency on the R package `data.table` to slightly speed up the reading of input files.; - Setting `pch="".""` also sped up the generation of scatter plots.; - Plotting now takes a couple of minutes, most of which is I/O (#3554).; - AAF (rather than MAF) is now plotted for allele fraction (#2957). Other:; - I've introduced a `LocatableCollection` class to unify how allelic counts, copy ratios, and segments are stored and read/written from/to TSV (#2836). Intervals are always output in lexicographical order for now, to be consistent with the old coverage collection (#2951). Once @asmirnov239's `CollectReadCounts` is in, we can change everything over to ordering determined by the sequence dictionary.; - Column headers and log2 copy ratio output have been standardized throughout (#2886).; - [x] I've also introduced a `NamedSampleFile` abstract class to tag files that have `#SAMPLE_NAME=...` as the first comment line. For `CollectAllelicCounts`, this simply uses code borrowed from `GetSampleName`. W",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:9138,depend,dependency,9138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['depend'],['dependency']
Integrability,ne.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:518); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:192); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collect,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:3042,Wrap,WrappingSpliterator,3042,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,4,['Wrap'],['WrappingSpliterator']
Integrability,net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); 	at com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); 	at com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); 	at com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:100); 	at com.luz.push.utils.GcmUtils.init(GcmUtils.java:31); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:14064,protocol,protocol,14064,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,3,['protocol'],['protocol']
Integrability,"nevermind. this may be also fixed by excluding some dependencies. let's close for now, may reopen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1859#issuecomment-222182739:52,depend,dependencies,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1859#issuecomment-222182739,1,['depend'],['dependencies']
Integrability,ng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.doWork(DataflowCommandLineProgram.java:107); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:151); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:78); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:75); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:126); ... 33 more; Caused by: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.genomics.dataflow.readers.bam.Reader.process(Reader.java:93); at com.google.cloud.genomics.dataflow.readers.bam.ReadBAMTransform$ReadFn.processElement(ReadBAMTransform.java:68); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/866:3786,Integrat,IntegrationTestSpec,3786,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866,2,['Integrat'],['IntegrationTestSpec']
Integrability,"ng?. On Wed, Jan 24, 2018 at 4:39 PM droazen <notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> @yfarjoun; > <https://github.com/yfarjoun> We have an update on this! We've identified; > the bug:; >; > - When AbstractFeatureReader.getFeatureReader() tries to open a .vcf.gz; > that doesn't have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations of SeekableStream in htsjdk.; >; > —; > You",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:1004,contract,contract,1004,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725,1,['contract'],['contract']
Integrability,ngEngine.calculateGenotypes(GenotypingEngine.java:210); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.calculateGenotypes(GenotypeGVCFs.java:266); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.regenotypeVC(GenotypeGVCFs.java:222); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:201); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase$$Lambda$82/1457352442.accept(Unknown Source); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:159); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:201); 	at org.broadi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4467:5363,wrap,wrapAndCopyInto,5363,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4467,1,['wrap'],['wrapAndCopyInto']
Integrability,ngine.java:152); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:135); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:283); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:135); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); 	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:502); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1014180059:8973,wrap,wrapAndCopyInto,8973,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1014180059,2,['wrap'],['wrapAndCopyInto']
Integrability,nit>(ErrorProbabilities.java:25) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:138) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:154) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; ; at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1058) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211) ;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:9303,wrap,wrapAndCopyInto,9303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['wrap'],['wrapAndCopyInto']
Integrability,"nning jobs on our Spark cluster I start seeing error messages in the logs midway through the job, of the form:. ```; 16/02/16 11:45:10 ERROR TransportRequestHandler: Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=1974353486066, chunkIndex=0}, buffer=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=715964266 cap=715964266]}} to /69.173.65.228:49341; closing connection; ```. java.nio.channels.ClosedChannelException. These are often followed by stacktraces like this:. ```; java.io.IOException: Broken pipe; at sun.nio.ch.FileDispatcherImpl.write0(Native Method); at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47); at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93); at sun.nio.ch.IOUtil.write(IOUtil.java:65); at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:466); at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:105); at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:91); at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:254); at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237); at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:281); at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:761); at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:311); at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:729); at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1127); at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:663); at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:644); at io.netty.channel.ChannelOutboundHandlerAdapter.flush(ChannelOutboundHandlerAdapter.java:115); at io.netty.channel.AbstractChannelHandlerContext",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1491:1004,Message,MessageWithHeader,1004,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1491,1,['Message'],['MessageWithHeader']
Integrability,no reason to depend on spark when we depend on spark ML lib anyway. Simpler to update 1 dependency than two. @lbergelson wdyt?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2035:13,depend,depend,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2035,3,['depend'],"['depend', 'dependency']"
Integrability,"no, the problem is that the test spec does not include placeholders. This works:. ```; @Test; public void testReadFiltering_asIntegrationTestSpec() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + ""%s"",; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );; spec.executeTest(""testReadFiltering_asIntegrationTestSpec"", this);; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1164#issuecomment-170048255:280,Integrat,IntegrationTestSpec,280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164#issuecomment-170048255,2,['Integrat'],['IntegrationTestSpec']
Integrability,"no. I didn't have time to look at the integration tests :-(. On Tue, Jan 12, 2021 at 3:17 PM droazen <notifications@github.com> wrote:. > @yfarjoun <https://github.com/yfarjoun> What do you want to do with this; > one? Are the issues with the tests resolved?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/6453#issuecomment-758914892>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AAU6JUVKOVTKSAHQK3SROIDSZSU33ANCNFSM4KUTOOYA>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6453#issuecomment-758946298:38,integrat,integration,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6453#issuecomment-758946298,1,['integrat'],['integration']
Integrability,nonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1190); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). **This is the stack I get when the test completes but fails (note that the expected line count appears to not match the line count of the expected output file in the repo): **. java.lang.AssertionError: line counts expected [2629] but found [507]; 	at org.testng.Assert.fail(Assert.java:94); 	at org.testng.Assert.failNotEquals(Assert.java:496); 	at org.testng.Assert.assertEquals(Assert.java:125); 	at org.testng.Assert.assertEquals(Assert.java:372); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:211); 	at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.assertEqualTextFiles(IntegrationTestSpec.java:190); 	at org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.testExampleAssemblyRegionWalker(ExampleAssemblyRegionWalkerSparkIntegrationTest.java:29); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); 	at org.testng.internal.TestMethodWorker.invok,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:3460,Integrat,IntegrationTestSpec,3460,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,1,['Integrat'],['IntegrationTestSpec']
Integrability,"not documented within GATK); ##### ERROR VCF VariantContext (this is an external codec and is not documented within GATK); ##### ERROR VCF3 VariantContext (this is an external codec and is not documented within GATK); ##### ERROR ------------------------------------------------------------------------------------------. then I added a name like this:. --variant:VCF $NOW/w-91.raw.g.vcf \; --variant:VCF $NOW/w-92.raw.g.vcf \; --variant:VCF $NOW/w-93.raw.g.vcf \. also met a error like this:. ##### ERROR; ##### ERROR MESSAGE: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file; ##### ERROR ------------------------------------------------------------------------------------------. and I change the name like this:. --variant:VCF3 $NOW/w-91.raw.g.vcf \; --variant:VCF3 $NOW/w-92.raw.g.vcf \; --variant:VCF3 $NOW/w-93.raw.g.vcf \. also error:. ##### ERROR MESSAGE: Unable to parse header with error: Your input file has a malformed header: This codec is strictly for VCFv3 and does not support VCFv4.1, for input source: /gss1/home/hjb20181119/panyongpeng/NN1138-2/RIL_genotype/mapping/w-1.raw.g.vcf; ##### ERROR ------------------------------------------------------------------------------------------. I checked my GVCF file and the header is :. ##fileformat=VCFv4.1; ##ALT=<ID=NON_REF,Description=""Represents any possible alternative allele at this location"">; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FORMAT=<ID=AD,Number=.,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block"">; ##FORMAT=<ID=PGT,Number=1,Type",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7315:1884,MESSAGE,MESSAGE,1884,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7315,1,['MESSAGE'],['MESSAGE']
Integrability,not going to happen in this iteration. depends on https://github.com/broadinstitute/hellbender/pull/345 and https://github.com/broadinstitute/hellbender/pull/387,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/52#issuecomment-94112935:39,depend,depends,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/52#issuecomment-94112935,1,['depend'],['depends']
Integrability,note: this may remain unresolved for alpha-2 because it depends on some setting that may be difficult or impossible to fix,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1873#issuecomment-223060599:56,depend,depends,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1873#issuecomment-223060599,1,['depend'],['depends']
Integrability,now that htsjdk is java 8 we can push a bunch of functions into the interface itself.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1191:68,interface,interface,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1191,1,['interface'],['interface']
Integrability,now that we're on htsjdk 2.2.1 we should switch to asyncIO for bams (not tribble); - [x] switch to asyncIO for bams (build.gradle); - [x] switch tests to use asyncIO for bams (build.gradle); - [x] update readme to say that we're using async IO; - [x] update startup message to clarify which IO is sync/async. measure and report performance impact on (using JdkDeflater and IntelDeflater); - [x] PrintReads ; - [x] BaseRecalibrator,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1653:266,message,message,266,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1653,1,['message'],['message']
Integrability,nputStreamReader.read(InputStreamReader.java:177); at htsjdk.tribble.readers.LongLineBufferedReader.fill(LongLineBufferedReader.java:140); at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:300); at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:356); at htsjdk.tribble.readers.SynchronousLineReader.readLine(SynchronousLineReader.java:51); at htsjdk.tribble.TabixFeatureReader$FeatureIterator.readNextRecord(TabixFeatureReader.java:170); at htsjdk.tribble.TabixFeatureReader$FeatureIterator.next(TabixFeatureReader.java:205); at htsjdk.tribble.TabixFeatureReader$FeatureIterator.next(TabixFeatureReader.java:149); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1845); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:601); at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1098); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:166); at org.broadinstitute.hellbender.Main.m,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8969:5918,wrap,wrapAndCopyInto,5918,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8969,1,['wrap'],['wrapAndCopyInto']
Integrability,nsformer.java:20); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:118); at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:189); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1058); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203);,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7092:10535,wrap,wrapAndCopyInto,10535,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7092,1,['wrap'],['wrapAndCopyInto']
Integrability,nstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.WellformedReadFilter.test(WellformedReadFilter.java:77); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.lambda$getReads$e4b35a40$1(GATKSparkTool.java:213); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool$$Lambda$93/2063469002.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:2382,wrap,wrapAndCopyInto,2382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['wrap'],['wrapAndCopyInto']
Integrability,nt.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:77); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:361); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); 	at org.broadinstitute.hellbender.cmdline.Comman,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1850,protocol,protocol,1850,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,"ntException: Self-suppression not permitted; at java.lang.Throwable.addSuppressed(Throwable.java:1043); at org.broadinstitute.hellbender.tools.picard.sam.FastqToSam.doWork(FastqToSam.java:163); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:61); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); Caused by: java.lang.NoClassDefFoundError: org/xerial/snappy/LoadSnappy; at htsjdk.samtools.util.SnappyLoader.<init>(SnappyLoader.java:86); at htsjdk.samtools.util.SnappyLoader.<init>(SnappyLoader.java:52); at htsjdk.samtools.util.TempStreamFactory.getSnappyLoader(TempStreamFactory.java:42); at htsjdk.samtools.util.TempStreamFactory.wrapTempOutputStream(TempStreamFactory.java:74); at htsjdk.samtools.util.SortingCollection.spillToDisk(SortingCollection.java:223); at htsjdk.samtools.util.SortingCollection.add(SortingCollection.java:166); at htsjdk.samtools.SAMFileWriterImpl.addAlignment(SAMFileWriterImpl.java:192); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:36); at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:16); at htsjdk.samtools.util.AbstractAsyncWriter$WriterRunnable.run(AbstractAsyncWriter.java:117); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.ClassNotFoundException: org.xerial.snappy.LoadSnappy; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); ... 11 more. We can find snappy-java in <INST_DIR>/build/install/gatk/lib/snappy-java-1.1.1.7.jar, but it ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2868:1174,wrap,wrapTempOutputStream,1174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2868,1,['wrap'],['wrapTempOutputStream']
Integrability,"ntReads cannot subset based on a list of read names. Rather FilterSamReads can do so as long as the reads are queryname-sorted. So then it would be good to distinguish this tool from FilterSamReads by saying (assuming true) ""Unlike FilterSamReads, this tool can take any sort-order, e.g. unsorted, to subset target reads.""; 3. ReadDataProgramGroup.java. And `6. ` from above. ---; ## FilterLongReadAlignmentsSAMSpark. 1. In the one-line summary, I'm not clear on what is meant by ""Filters"". Based on the result file, seems like it collects metrics on each contig alignment.; 2. ; 3. If metrics, then DiagnosticsAndQCProgramGroup.java. And `6. ` from above. ---; ## FindBadGenomicKmersSpark. 1. The term ""copy number"" should be reserved in reference to CNV analyses. So instead, how about:; Identify sequence contexts that occur at high frequency in a reference; 2. Please define a kmer. If only a reference fasta is required (as listed under Inputs) great. But if the tool also depends on a FAI index and DICT dictionary, please do include them. Also, it would be good to provide an example of how such information is used in SV discovery, e.g. ""the resulting file can be given to FindBreakpointEvidenceSpark, which will then ignore such sequence contexts during analysis."" Also would be good to mention that the default kmer size (--k-size 51) is optimized for human if indeed this is the case.; 3. ReferenceProgramGroup.java. And `6. ` from above. ---; ## FindBreakpointEvidenceSpark. 1. Assembles and aligns contigs of genomic breakpoint regions associated with structural variants ; 2. Overview and Notes could use finessing but let's leave this for next year. One thing to include is a reference to FermiLite for those seeking more information. A publication would be best. And `6. ` from above. ---; ## StructuralVariationDiscoveryPipelineSpark. 1. Runs the structural variant discovery workflow on a single sample in Spark ; 2. Fyi we sanction a ""Caveats"" section, which is likely more appropri",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451:2945,depend,depends,2945,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451,1,['depend'],['depends']
Integrability,"nt_tsv/94.mkdup.sort.rg.tsv (45 / 323); 06:49:20.605 INFO GermlineCNVCaller - Shutting down engine; [August 13, 2021 6:49:20 AM GMT] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 2.27 minutes.; Runtime.totalMemory()=2076049408; java.lang.IllegalArgumentException: Prefix string too short; at java.io.File.createTempFile(File.java:2001); at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFileInDirectory(IOUtils.java:685); at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFile(IOUtils.java:666); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.lambda$writeIntervalSubsetReadCountFiles$1(GermlineCNVCaller.java:434); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.writeIntervalSubsetReadCountFiles(GermlineCNVCaller.java:433); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.doWork(GermlineCNVCaller.java:323); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192). `; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7410:2518,wrap,wrapAndCopyInto,2518,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7410,1,['wrap'],['wrapAndCopyInto']
Integrability,nternal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); [TileDB::FileSystem] Error: hdfs: Error getting hdfs connection; [TileDB::StorageManagerConfig] Error: Error getting hdfs connection: Connection refused.; Gradle suite > Gradle test > ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6522:6641,Message,MessageHubBackedObjectConnection,6641,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6522,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,"nts/Minute; 17:13:31.286 INFO FilterMutectCalls - Starting first pass through the variants; 17:13:31.570 INFO FilterMutectCalls - Shutting down engine; [February 17, 2019 5:13:31 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=845676544; java.lang.NumberFormatException: For input string: "".""; 	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65); 	at java.lang.Integer.parseInt(Integer.java:569); 	at java.lang.Integer.valueOf(Integer.java:766); 	at htsjdk.variant.variantcontext.CommonInfo.lambda$getAttributeAsIntList$1(CommonInfo.java:287); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Collections$2.tryAdvance(Collections.java:4717); 	at java.util.Collections$2.forEachRemaining(Collections.java:4725); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at htsjdk.variant.variantcontext.CommonInfo.getAttributeAsList(CommonInfo.java:273); 	at htsjdk.variant.variantcontext.CommonInfo.getAttributeAsIntList(CommonInfo.java:281); 	at htsjdk.variant.variantcontext.VariantContext.getAttributeAsIntList(VariantContext.java:738); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyReadPositionFilter(Mutect2FilteringEngine.java:223); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:529); 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:130); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5684:3669,wrap,wrapAndCopyInto,3669,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5684,1,['wrap'],['wrapAndCopyInto']
Integrability,"o allow custom picking of the correct dependencies. With gradle, a composite build can be done to assemble together every GATK4 sub-modules, and still being able to publish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and remove if required, without any major version bump.; * `testing`: this will contain the testing framework. It is related with #1481 and #3567. ; * `documentation`: this might be useful for code dependent on `com.sun.javadoc` to do not interact with other classes if code for document",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3900:1304,depend,dependency,1304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900,1,['depend'],['dependency']
Integrability,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3540:1252,adapter,adapter,1252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540,5,['adapter'],['adapter']
Integrability,oadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:306); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:243); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); 	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEnt,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1070784053:6499,wrap,wrapAndCopyInto,6499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1070784053,1,['wrap'],['wrapAndCopyInto']
Integrability,oadinstitute/gatk/jobs/498538899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.13/tests/test/index.html) |; | integration | openjdk11 | [33752.12](https://travis-ci.com/broadinstitute/gatk/jobs/498538898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.12/tests/test/index.html) |; | variantcalling | openjdk8 | [33752.4](https://travis-ci.com/broadinstitute/gatk/jobs/498538890) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.4/tests/test/index.html) |; | unit | openjdk8 | [33752.3](https://travis-ci.com/broadinstitute/gatk/jobs/498538889) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.3/tests/test/index.html) |; | conda | openjdk8 | [33752.5](https://travis-ci.com/broadinstitute/gatk/jobs/498538891) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.5/tests/test/index.html) |; | integration | openjdk8 | [33752.2](https://travis-ci.com/broadinstitute/gatk/jobs/498538888) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.2/tests/test/index.html) |; | cloud | openjdk11 | [33752.14](https://travis-ci.com/broadinstitute/gatk/jobs/498538900) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.14/tests/test/index.html) |; | cloud | openjdk8 | [33752.1](https://travis-ci.com/broadinstitute/gatk/jobs/498538887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.1/tests/test/index.html) |; | unit | openjdk11 | [33752.13](https://travis-ci.com/broadinstitute/gatk/jobs/498538899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.13/tests/test/index.html) |; | integration | openjdk11 | [33752.12](https://travis-ci.com/broadinstitute/gatk/jobs/498538898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_337,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234:1675,integrat,integration,1675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234,1,['integrat'],['integration']
Integrability,oadinstitute/hellbender/utils/recalibration/covariates/ContextCovariate.java line 191 -->. ```; while (bases[currentNPenalty] != 'N') {; final int baseIndex = BaseUtils.simpleBaseToBaseIndex(bases[currentNPenalty]);; currentKey |= (baseIndex << offset);; offset -= 2;; currentNPenalty--;; }; ```. The current while loop allows the array index to become negative and walk right off the edge of the read. So a proposed fix is as follows (assuming it does not break the covariate logic) -->. ```; while (currentNPenalty > 0 && bases[currentNPenalty] != 'N') {; final int baseIndex = BaseUtils.simpleBaseToBaseIndex(bases[currentNPenalty]);; currentKey |= (baseIndex << offset);; offset -= 2;; currentNPenalty--;; }; ```. Minimal Command (test.bam attached - added txt extension just so site would let me attach it) -->. ```; gatk-launch BaseRecalibrator -I test.bam -O test.table -R GATK_Bundle_Build38/Homo_sapiens_assembly38.fasta --knownSites GATK_Bundle_Build38/dbsnp_146.hg38.vcf.gz; ```. Error message --> . ```; java.lang.ArrayIndexOutOfBoundsException: -1; 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ContextCovariate.contextWith(ContextCovariate.java:191); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ContextCovariate.recordValues(ContextCovariate.java:68); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.StandardCovariateList.recordAllValuesInStorage(StandardCovariateList.java:133); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:546); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:527); 	at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:180); 	at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); 	at java.util.strea,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4005:1679,message,message,1679,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4005,1,['message'],['message']
Integrability,obReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 41 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 47 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727:5558,protocol,protocol,5558,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727,1,['protocol'],['protocol']
Integrability,obReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:9046,protocol,protocol,9046,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['protocol'],['protocol']
Integrability,"oblem using BaseRecalibratorSpark. The tool fails soon after starting. The same error appears with the same bam file on different machines. Additionally, vanilla BaseRecalibrator works just fine on these bams (so I don't think the issue is with the bam). They are all suffering from the same/similar stacktrace. We've had BaseRecalibratorSpark work fine on other bam files. Additionally, changing the number of threads still results in the same stacktrace. I've also tried running the BQSRPipelineSpark to see if that would suffer the same issue and it fails in the same manner. Additionally, I've run ValidateSamFile. There are some reads missing their mates, but this hasn't presented an issue in other tools (including vanilla BaseRecalibrator). Searching thru the forum, I found an old issue with a similar stacktrace, but that issue appears to occur in GATK 2.4: https://gatkforums.broadinstitute.org/gatk/discussion/3265/bqsrgatherer-exception. In the below stacktrace, I've bolded the error message that seems to occur in each of these samples. `Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854:1166,message,message,1166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854,1,['message'],['message']
Integrability,ocate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482:1123,wrap,wrapper,1123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482,1,['wrap'],['wrapper']
Integrability,"ocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:158); 	at com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:489); 	at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:206); 	... 31 more; ```; Followed by repetitions of the following stacktrace:; ```; Feb 07, 2018 12:41:59 PM com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; java.net.SocketTimeoutException: connect timed out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAdd",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369:4489,protocol,protocol,4489,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369,1,['protocol'],['protocol']
Integrability,ocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:158); 	at com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:489); 	at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:206); 	at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:70); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1825); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1012); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:975); 	at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369:6386,protocol,protocol,6386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369,1,['protocol'],['protocol']
Integrability,ocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:112); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:113); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(Google,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:1432,protocol,protocol,1432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235,2,['protocol'],['protocol']
Integrability,ocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(Googl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:2558,protocol,protocol,2558,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['protocol'],['protocol']
Integrability,od); 	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); 	at com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); 	at com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); 	at com.google.auth.oauth,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:13881,protocol,protocol,13881,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,3,['protocol'],['protocol']
Integrability,oder.java:178); 	at java.io.InputStreamReader.read(InputStreamReader.java:184); 	at htsjdk.tribble.readers.LongLineBufferedReader.fill(LongLineBufferedReader.java:140); 	at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:300); 	at htsjdk.tribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:356); 	at htsjdk.tribble.readers.SynchronousLineReader.readLine(SynchronousLineReader.java:51); 	at htsjdk.tribble.TabixFeatureReader$FeatureIterator.readNextRecord(TabixFeatureReader.java:170); 	at htsjdk.tribble.TabixFeatureReader$FeatureIterator.next(TabixFeatureReader.java:205); 	at htsjdk.tribble.TabixFeatureReader$FeatureIterator.next(TabixFeatureReader.java:149); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:490); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1058); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7614:3248,wrap,wrapAndCopyInto,3248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7614,2,['wrap'],['wrapAndCopyInto']
Integrability,"odule>; from theano.compile.mode import *; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/compile/mode.py"", line 11, in <module>; import theano.gof.vm; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/vm.py"", line 674, in <module>; from . import lazylinker_c; File ""${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 140, in <module>; preargs=args); File ${INSTALLDIRGATK}/lib/python3.6/site-packages/theano/gof/cmodule.py"", line 2396, in compile_str; (status, compile_stderr.replace('\n', '. '))); Exception: Compilation failed (return status=1): /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_deregisterTMCloneTable. /usr/bin/ld.gold: error: ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_registerTMCloneTable. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x1a): error: unsupported reloc 42. ${INSTALLDIRGCC}/bin/../lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x6b): error: unsupported reloc 42. collect2: error: ld returned 1 exit status. ```. Then I have installed theano with python 3.6.6 which is compiled with gcc 5.4.0, and it was giving me no errors. ```sh. $ theano-nose . ----------------------------------------------------------------------; Ran 0 tests in 0.012s. OK; ```. The Theano toolchain issue might be caused by theano not being actively developed anymore. Probably they never tested it with newer toolchains.; See this message that is also on the Theano github page.; https://groups.google.com/d/msg/theano-users/7Poq8BZutbY/rNCIfvAEAwAJ. #### Steps to reproduce; see description. #### Expected behavior; see description. #### Actual behavior; see description. ----. ## Feature request; - Switch from pymc3/Theano to another framework that offers the same functionality; - Modify the depedencies of gcnvkernel. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766:3925,message,message,3925,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766,1,['message'],['message']
Integrability,"of `HaplotypeCaller` will not include spanning deletion alleles when run in single sample VCF mode or in genotype given alleles mode, even when that genotype would be more appropriate. In the joint calling workflow `GenotypeGVCFs` adds genotypes for spanning deletions, although the input likelihoods will not be broken out to specifically account for spanning deletion alleles. Some implementation notes:. - I also fixed some behavior specific to GGA mode that I encountered while testing this bug. In particular, when GGA mode was run with multiple variants with the same start position or with spanning events, `HaplotypeCaller` used to emit the warning `""Multiple valid VCF records detected in the alleles input file at site "" + loc + "", only considering the first record""` for each such site. This was a bit of a misleading message, since the other variants were in fact taken into account UNLESS HC decided to emit an empty variant context, for example due to zero coverage.; - I rewrote the `createAlleleMapper` method in `AssemblyBasedCallerGenotypingEngine`. The old version had a very brittle mapping scheme that depended heavily on the ordering of alleles in the variant context created by `AssemblyBasedCallerUtils.makeMergedVariantContext` and `getEventsAtThisLoc`. This proved to be difficult to ensure when spanning deletions were added in, and there was an ominous TODO in the old method saying that the logic was not good enough, so I ended up re-writing it from scratch. The new version is longer but I hope it is easier to read and less fragile, but let me know if I've missed anything. Test currently fail on this branch and therefore it should not be merged. To make them pass we need a fix to https://github.com/broadinstitute/gatk/issues/4716 which is currently being worked on in https://github.com/broadinstitute/gatk/pull/4645. However, since that PR is taking a while to make it through code review, I thought it might be good to start the review process for these changes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4963:1274,depend,depended,1274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4963,1,['depend'],['depended']
Integrability,"of the expected files, since the transform is appended to the corresponding variable name. DetermineGermlineContigPloidy and PostprocessGermlineCNVCalls are missing exact-match tests and should probably have some, but I'll leave that to someone else.; - [x] Update other python integration tests.; - [x] Clean up some of the changes to the priors.; - [x] Clean up some TODO comments that I left to track code changes that might result in changed numerics. I'll try to go through and convert these to PR comments in an initial review pass.; - [x] Test over multiple shards on WGS and WES. Probably some scientific tests on ~100 samples in both cohort and case mode would do the trick. We should also double check runtime/memory performance (I noted ~1.5x speedups, but didn't measure carefully; I also want to make sure the changes to posterior sampling didn't introduce any memory issues). @mwalker174 will ping you when a Docker is ready! Might be good to loop in Isaac and/or Jack as well.; - [x] Perhaps add back the fix for 2-interval shards in https://github.com/broadinstitute/gatk/pull/8180, which I removed since the required functionality wasn't immediately available in Pytensor. Not sure if this actually broke things though---need to check. (However, I don't actually think this is a very important use case to support...); - [x] Delete/deprecate/etc. CNN tools/tests as appropriate. Note that this has to be done concurrently, since we remove Tensorflow. @droazen perhaps I can take a first stab at this in a subsequent commit to this PR once more of the gCNV dust settles and/or has undergone a preliminary review? EDIT: Disabled integration/WDL tests. We should add some deprecation messages to the tools---we can note that they should still work in previous environments but will be untested. I might set up a separate PR for deletion, to be done at the appropriate time (but I call dibs on this, can't have @davidbenjamin overtaking my all-time record for number of lines deleted 😛).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285:3800,integrat,integration,3800,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285,2,"['integrat', 'message']","['integration', 'messages']"
Integrability,"oft/gatk-4.4.0.0# ""$CONDA"" env create -n gatk -f ""$SOFT/gatk-${GATK_VERSION}/gatkcondaenv.yml""; ...; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Installing pip dependencies: | Ran pip subprocess with arguments:; ['/opt/miniconda/envs/gatk/bin/python', '-m', 'pip', 'install', '-U', '-r', '/soft/gatk-4.4.0.0/condaenv.i9brvcrk.requirements.txt', '--exists-action=b']; Pip subprocess output:. Pip subprocess error:; /opt/miniconda/envs/gatk/bin/python: No module named pip. failed. CondaEnvException: Pip failed. ```; ---; It can be fixed with setting classic colver:; ```; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda --version; conda 23.10.0; root@d12ac7710afc:/soft/gatk-4.4.0.0# conda config --set solver classic; root@d12ac7710afc:/soft/gatk-4.4.0.0# ""$CONDA"" env create -n gatk -f ""$SOFT/gatk-${GATK_VERSION}/gatkcondaenv.yml""; ...; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Installing pip dependencies: \ Ran pip subprocess with arguments:; ['/opt/miniconda/envs/gatk/bin/python', '-m', 'pip', 'install', '-U', '-r', '/soft/gatk-4.4.0.0/condaenv.rtsyg5rl.requirements.txt', '--exists-action=b']; Pip subprocess output:; Processing ./gatkPythonPackageArchive.zip; Building wheels for collected packages: gatkpythonpackages; Building wheel for gatkpythonpackages (setup.py): started; Building wheel for gatkpythonpackages (setup.py): finished with status 'done'; Created wheel for gatkpythonpackages: filename=gatkpythonpackages-0.1-py3-none-any.whl size=117686 sha256=f2165b43e412c95ff9a788022d355279e5434032fb8c9cf82fbd71779acd1a76; Stored in directory: /tmp/pip-ephem-wheel-cache-5a9zdytx/wheels/06/f7/e1/87cb7da6f705baa602256a58c9514b47dc313aade8809a01da; Successfully built gatkpythonpackages; Installing collected packages: gatkpythonpackages; Successfully installed gatkpythonpackages-0.1. done; #; # To activate this environment, use; #; # $ conda activate gatk; #; # To deactivate an active environmen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8618:2832,depend,dependencies,2832,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8618,1,['depend'],['dependencies']
Integrability,"ok, native repo is done https://github.com/broadinstitute/gatk-native-bindings; we're still hashing out the interfaces and it will be a bit before we have created the artifacts at maven central.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-216660840:108,interface,interfaces,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-216660840,1,['interface'],['interfaces']
Integrability,"ollapsed it into a single class for several reasons:; - Inheriting from a more generic traversal type caused usability issues and confusion with respect to the command-line arguments. The `ReadWindow` was the unit of processing for the superclass, but for `AssemblyRegionWalker` it was the unit of I/O and `AssemblyRegion` was the unit of processing, and I couldn't update the docs for `ReadWindowWalker` to clear up the confusion without mentioning `AssemblyRegion`-specific concepts.; - The `ReadShard` / `ReadWindow` was/is **only** there to prove that we can shard the data without introducing calling artifacts, and to provide a unit of parallelism for the upcoming Spark implementation. It's not something we really want to expose to users as a prominent knob, and we may hide it completely in the future once the shard size is tuned for performance.; - Inheriting from a more abstract walker type caused a number of other problems as well: methods that should have been final in the supertype could no longer be made final, with the result that tool implementations could inappropriately override engine initialization/shutdown routines. Also, there were issues with the progress meter, since both the supertype traversal and subtype traversal needed their own progress meter for their different units of processing. Ultimately it was just too awkward and forced, and the read shard is something that we eventually want to make an internal/encapsulated implementation detail anyway. GATK3 made the mistake, I think, of using long, confusing inheritance chains for its walker types, with the result that you got awkward and forced relationships like `RodWalker` inheriting from `LocusWalker`. It's better, I think, to make each traversal as standalone as possible, especially given the simplicity of writing a new walker type in GATK4. For all of these reasons we don't want `AssemblyRegionWalker` to inherit from a more abstract traversal type -- it's just going to be its own standalone thing",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513:1660,rout,routines,1660,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513,1,['rout'],['routines']
Integrability,ollowing jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6016742374.11](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16321393716) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.11/tests/test/index.html) |; | integration | 11 | [6016742374.12](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16321393852) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.12/tests/test/index.html) |; | cloud | 11 | [6016742374.11](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16347530908) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.11/tests/test/index.html) |; | unit | 11 | [6016742374.13](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16347531468) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.13/tests/test/index.html) |; | integration | 11 | [6016742374.12](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16347531169) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.12/tests/test/index.html) |; | unit | 11 | [6016742374.13](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16362542517) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.13/tests/test/index.html) |; | cloud | 11 | [6016742374.11](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16362542090) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.11/tests/test/index.html) |; | integration | 11 | [6016742374.12](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16362542310) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8459#issuecomment-1698045984:1202,integrat,integration,1202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8459#issuecomment-1698045984,2,['integrat'],['integration']
Integrability,"om.cloudera.dataflow.spark.TemplatedTextOutputFormat.getDefaultWorkFile(TemplatedTextOutputFormat.java:46); at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:995); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:979); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61); at org.apache.spark.scheduler.Task.run(Task.scala:64); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 15/07/14 13:14:53 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1, localhost): java.lang.IncompatibleClassChangeError: Found class org.apache.hadoop.mapreduce.TaskAttemptContext, but interface was expected; at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getOutputFile(TemplatedTextOutputFormat.java:50); at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getDefaultWorkFile(TemplatedTextOutputFormat.java:46); at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:995); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:979); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61); at org.apache.spark.scheduler.Task.run(Task.scala:64); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 15/07/14 13:14:53 ERROR scheduler.TaskSetManager: Task 0 in stage 1.0 fa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:30972,interface,interface,30972,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['interface'],['interface']
Integrability,omADaccuracyTest.noMQinSNPVQSR.SynDip.vcf.gz; at htsjdk.variant.vcf.AbstractVCFCodec.decodeLine(AbstractVCFCodec.java:281); at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:262); at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:64); at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:70); at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:37); at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.readNextRecord(TribbleIndexedFeatureReader.java:365); at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:346); at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:307); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224:1542,wrap,wrapAndCopyInto,1542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224,1,['wrap'],['wrapAndCopyInto']
Integrability,"ommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; GET https://storage.googleapis.com/storage/v1/b/fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/o?maxResults=1&prefix=5c2db926-3b1c-479c-9ed3-a99ce518de91/omics_mutect2/60955825-7723-4bc9-8202-bdd9975bb5c0/call-mutect2/Mutect2/7d737efc-c8be-4a6d-8803-4f786129521a/call-SplitIntervals/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list.idx/&projection=full&userProject; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""User project specified in the request is invalid."",; ""reason"" : ""invalid""; } ],; ""message"" : ""User project specified in the request is invalid.""; }; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:428); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1111); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:514); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeU",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716:4454,message,message,4454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716,1,['message'],['message']
Integrability,omputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Connection refused (Connection refused); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCred,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:2280,protocol,protocol,2280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['protocol'],['protocol']
Integrability,on channels to read the same file (across 1k threads) and got the error below. Yes I know a million parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:1066,protocol,protocol,1066,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156,1,['protocol'],['protocol']
Integrability,"on localhost (executor driver) (4/4); 17/05/05 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool ; 17/05/05 17:03:58 INFO DAGScheduler: ResultStage 2 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:202) finished in 10.370 s; 17/05/05 17:03:58 INFO DAGScheduler: Job 1 finished: saveAsNewAPIHadoopFile at ReadsSparkSink.java:202, took 16.702399 s; 17/05/05 17:03:58 INFO SparkUI: Stopped Spark web UI at http://172.30.0.122:46483; 17/05/05 17:03:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/05/05 17:03:59 INFO MemoryStore: MemoryStore cleared; 17/05/05 17:03:59 INFO BlockManager: BlockManager stopped; 17/05/05 17:03:59 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/05/05 17:03:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/05/05 17:03:59 INFO SparkContext: Successfully stopped SparkContext; [May 5, 2017 5:03:59 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=799080448; 17/05/05 17:03:59 INFO ApplicationMaster: Final app status: FAILED, exitCode: 16, (reason: Shutdown hook called before final status was reported.); 17/05/05 17:03:59 INFO ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: Shutdown hook called before final status was reported.); 17/05/05 17:03:59 INFO ApplicationMaster: Deleting staging directory hdfs://ip-172-30-0-86.ec2.internal:8020/user/hadoop/.sparkStaging/application_1493961816416_0010; 17/05/05 17:03:59 INFO ShutdownHookManager: Shutdown hook called; 17/05/05 17:03:59 INFO ShutdownHookManager: Deleting directory /mnt1/yarn/usercache/hadoop/appcache/application_1493961816416_0010/spark-223a9e8b-0fe9-41f0-8bed-f843978f1882; 17/05/05 17:03:59 INFO ShutdownHookManager: Deleting directory /mnt/yarn/usercache/hadoop/appcache/application_1493961816416_0010/spark-573a9c53-e268-4f3b-8907-1f35e5839788; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046:18568,message,message,18568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046,1,['message'],['message']
Integrability,"on went away and the program run successfully. ---. @eddiebroad commented on [Thu Dec 01 2016](https://github.com/broadinstitute/gatk-protected/issues/806#issuecomment-264264203). per @droazen : @achevali @LeeTL1220 . ---. @LeeTL1220 commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gatk-protected/issues/806#issuecomment-265342816). @eddiebroad Before this gets assigned, what version of gatk-protected are you using?; Assuming that this is a version we built (despite the name ""eddie.jar""): @achevali , can you figure out how you are reporting the error. @droazen are you sure this is not in the engine?. ---. @eddiebroad commented on [Wed Dec 07 2016](https://github.com/broadinstitute/gatk-protected/issues/806#issuecomment-265464665). @LeeTL1220 . The original JAVA JAR where I first observed the ""null"" message I presume was based off commit 3a2bb0d. At the time the project was initiated I think it was the latest commit. The original JAR where the ""null"" message was observed was gatk-protected-all-3a2bb0d-SNAPSHOT-spark_standalone.jar . Because of the ""3a2bb0d"" in the JAR file name is why I presume that it's based off commit 3a2bb0d. . From the gatk-protected repo code (and also ""gatk"" repo) I added some debug/print statements and saved to a differently named JAR ""eddie.jar"" to help me distinguish my hacking from the original JAR. . The JAVA file where I added the most helpful statements was in CommandLineProgram.java which is actually in ""gatk"" repo (not ""gatk-protected"" repo). If I look at a LOG, I can see ""EAS"" my initials and see c40e75b which appears to be a more recent commit compared to 3a2bb0d. ```; EAS in main!!!!; EAS to call instanceMain second....; EAS to call instanceMain first....; 17:28:40.295 INFO SparkGenomeReadCounts - EAS ABOUT TO CALL instanceMainPostParseArgs in instanceMain in clp.java ; 17:28:40.396 INFO IntelGKLUtils - Trying to load Intel GKL library from:; 	jar:file:/cromwell_root/fc-7ac504fc-7fe4-4bc1-89d3-7f16317b8ff4/eddie.jar!/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2922:3872,message,message,3872,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2922,1,['message'],['message']
Integrability,on: Cannot parse the funcotation attribute.  Num values: 31   Num keys: 53 ; ;     at org.broadinstitute.hellbender.tools.funcotator.FuncotationMap.createAsAllTableFuncotationsFromVcf(FuncotationMap.java:224) ; ;     at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.lambda$createAlleleToFuncotationMapFromFuncotationVcfAttribute$5(FuncotatorUtils.java:2256) ; ;     at java.base/java.util.stream.Collectors.lambda$uniqKeysMapAccumulator$1(Collectors.java:178) ; ;     at java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ; ;     at java.base/java.util.stream.IntPipeline$1$1.accept(IntPipeline.java:180) ; ;     at java.base/java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:104) ; ;     at java.base/java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:699) ; ;     at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; ;     at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; ;     at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; ;     at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ;     at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; ;     at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createAlleleToFuncotationMapFromFuncotationVcfAttribute(FuncotatorUtils.java:2255) ; ;     at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.ArHetvarFilter.buildArHetByGene(ArHetvarFilter.java:77) ; ;     at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.ArHetvarFilter.firstPassApply(ArHetvarFilter.java:50) ; ;     at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.firstPassApply(FilterFuncotations.java:161) ; ;     at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:17) ; ;     at org.broadinstitute.hellbender.engine,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7865:7935,wrap,wrapAndCopyInto,7935,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7865,1,['wrap'],['wrapAndCopyInto']
Integrability,on:No shortest ALT at 464564654 across alleles: [*]`. Complete error message:. ```; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chr4::464564654[VC /bug.g.vcf.gz @ ; ```; redacted; ```. ] filters=; at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:145); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:136); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7961:1285,wrap,wrapAndCopyInto,1285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7961,1,['wrap'],['wrapAndCopyInto']
Integrability,"onPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1169,wrap,wrapper,1169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,"onScriptExecutor.java:121); at; org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.executeDeterminePloidyAndDepthPythonScript(DetermineGermlineContigPloidy.java:411); at; org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.doWork(DetermineGermlineContigPloidy.java:288); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). Kindly give your inputs.. Thanks; Sridhar. On Thu, 17 Oct 2019 at 16:05, samuelklee <notifications@github.com> wrote:. > Thanks for trying out the tool, @ssri28 <https://github.com/ssri28>. The; > exception message states that “List of input read-count files cannot; > contain duplicates,” so that would be the first thing to check. Since we; > are either building a model or calling ploidy from the count files, it; > doesn’t make sense to allow duplicates.; >; > The support forums at https://gatkforums.broadinstitute.org/ are a better; > place for getting help with running the tools and diagnosing exceptions.; > GitHub issues should be reserved for bug reports and feature requests.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6217?email_source=notifications&email_token=AKXA3TRWNVROQOYIKTK4XITQPA5XDA5CNFSM4JBWKHV2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEBPUC7Q#issuecomment-543113598>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AKXA3TSNIGY7IC4Q2V4IVWLQPA5XDANCNFSM4JBWKHVQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6217#issuecomment-543122687:4916,message,message,4916,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6217#issuecomment-543122687,1,['message'],['message']
Integrability,ongoing effort to reduce dependency on dataflow packages. @lbergelson please have a look,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1765:25,depend,dependency,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1765,1,['depend'],['dependency']
Integrability,onnection refused); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); at sha,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:1685,protocol,protocol,1685,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843,1,['protocol'],['protocol']
Integrability,"onsolidated with---@jamesemery thoughts? Again, let me reiterate that it seems that many of these parameter values were chosen arbitrarily (or, if not, that the procedure for choosing them has been lost). As a start, you can see the results of some optimizations I did on the CHM mix on slide 15 at https://docs.google.com/presentation/d/1zGuquAZWSUQ-wNxp8D6HhGNjIaFcV0_X9WAS4LODbEo/edit?usp=sharing Here, I optimized over haplotype-to-reference + read-to-haplotype SW parameters on various metrics after variant normalization using vcfeval. These optimizations were done using the Bayesian optimization framework I prototyped long ago (see https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer and https://docs.google.com/presentation/d/1t5WOAEOMp0xAzJgpKbP68BUnclNYfIVRrDSL9wl1-3A/edit?usp=sharing); this entailed running parameter scans using a local Cromwell on my desktop. Probably this optimization work could be redone relatively easily using the Neptune framework put together by @dalessioluca, which was still in development at the time I did this work. Happy to share the resources and scripts I used if we go down this route; they are pretty lightweight. See more discussion starting here: https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566. Alternatively, we could merge this branch to expose the parameters now and punt on consolidating/optimizing them. I'm not completely convinced we should even do the former unless we are going to follow through on the latter, but happy to defer to others. Finally, note also there is one code optimization that I removed, since it makes assumptions on the SW parameter values that might not be valid for non-default values. I'll highlight this with a comment below. We can restore it if we add code to check whether the assumptions hold, but I'd be curious to see in which cases the optimization makes a big difference. See https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707870344.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471:2428,rout,route,2428,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471,1,['rout'],['route']
Integrability,oogle.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: No route to host (connect failed); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsPr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5220:1833,protocol,protocol,1833,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5220,1,['protocol'],['protocol']
Integrability,"ool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `AllelicCountCollector` per partition, instead of per locus. Assigning to @tomwhite by request of @droazen ...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3823:1165,integrat,integration,1165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823,2,['integrat'],['integration']
Integrability,"ools `CallVariantsFromAlignedContigsSpark` and `CallVariantsFromAlignedContigsSAMSpark` share a significant part of workflow. Conceptually, what happens is:; 1. turn `AlignmentRegion`'s (produced by another tool in difference formats that must be parsed) into `AssembledBreakpoint`'s;; 2. extract `BreakpointAllele` from a `AssembledBreakpoint`, and group the `AssembledBreakpoint`'s by each of their `BreakpointAllele`;; 3. filter `BreakpointAllele`'s;; 4. for each `BreakpointAllele` that survived the filter, filter its supporting `AssembledBreakpoint`'s then create an `VariantContext`;; 5. write VCF. In both of the tools, these steps are accomplished in almost the same way, involving the following functions. ``` java; public static Iterable<AssembledBreakpoint> assembledBreakpointsFromAlignmentRegions(final byte[] contigSequence,; final Iterable<AlignmentRegion> alignmentRegionsIterable,; final Integer minAlignLength);. public static Tuple2<BreakpointAllele, Tuple2<Tuple2<String,String>, AssembledBreakpoint>> keyByBreakpointAllele(final Tuple2<Tuple2<String,String>, AssembledBreakpoint> breakpointIdAndAssembledBreakpoint);. public static Boolean inversionBreakpointFilter(final Tuple2<BreakpointAllele, Tuple2<Tuple2<String,String>,AssembledBreakpoint>> breakpointAlleleTuple2Tuple2);. public static VariantContext filterBreakpointsAndProduceVariants(final Tuple2<BreakpointAllele, Iterable<Tuple2<Tuple2<String,String>, AssembledBreakpoint>>> assembledBreakpointsPerAllele,; final Broadcast<ReferenceMultiSource> broadcastReference);; ```. The concept is general enough that a separate class (potentially having its own shallow class hierarchy for different types of SV's) is extracted and provide a single interface like `callVariants()`.; And if the afore-mentioned functions could be moved from `ContigAligner` to here, all of them can be packed in the extracted class/interface.; Then different callers for different SV types could just override (or whatever technique) when fit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-240138574:1761,interface,interface,1761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-240138574,2,['interface'],['interface']
Integrability,ools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316:6127,wrap,wrapAndCopyInto,6127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316,1,['wrap'],['wrapAndCopyInto']
Integrability,ools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955:6269,wrap,wrapAndCopyInto,6269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955,5,['wrap'],['wrapAndCopyInto']
Integrability,ools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3481:6198,wrap,wrapAndCopyInto,6198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3481,2,['wrap'],['wrapAndCopyInto']
Integrability,optim.univariate.UnivariateOptimizer.computeObjectiveValue(UnivariateOptimizer.java:148); 	at org.apache.commons.math3.optim.univariate.BrentOptimizer.doOptimize(BrentOptimizer.java:225); 	at org.apache.commons.math3.optim.univariate.BrentOptimizer.doOptimize(BrentOptimizer.java:43); 	at org.apache.commons.math3.optim.BaseOptimizer.optimize(BaseOptimizer.java:153); 	at org.apache.commons.math3.optim.univariate.UnivariateOptimizer.optimize(UnivariateOptimizer.java:70); 	at org.broadinstitute.hellbender.utils.OptimizationUtils.max(OptimizationUtils.java:40); 	at org.broadinstitute.hellbender.tools.walkers.contamination.ContaminationModel.lambda$calculateContamination$13(ContaminationModel.java:214); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.contamination.ContaminationModel.calculateContamination(ContaminationModel.java:215); 	at org.broadinstitute.hellbender.tools.walkers.contamination.ContaminationModel.<init>(ContaminationModel.java:67); 	at org.broadinstitute.hellbender.tools.walkers.contamination.CalculateContamination.doWork(CalculateContamination.java:127); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCom,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6282:1504,wrap,wrapAndCopyInto,1504,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6282,1,['wrap'],['wrapAndCopyInto']
Integrability,opyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.AlleleFrequencyUtils.lambda$buildMaxMafRule$1(AlleleFrequencyUtils.java:30) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.lambda$checkFilter$0(FuncotationFilter.java:48) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:558) ; at org.broadinstitute.hellbender.tools.funcotator.filtrationRules.FuncotationFilter.checkFilter(FuncotationFilter.java:49) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$null$0(FilterFuncotations.java:194) ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:176) ; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:3491,wrap,wrapAndCopyInto,3491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['wrap'],['wrapAndCopyInto']
Integrability,or.next(SamReader.java:574); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:553); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:27); at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:13); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203);,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6865:6425,wrap,wrapAndCopyInto,6425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6865,1,['wrap'],['wrapAndCopyInto']
Integrability,"or: Low-level I/O; minor: Read failed; #010: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5FDint.c line 204 in H5FD_read(): ; driver read request failed; major: Virtual File Layer; minor: Read failed; #011: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5FDsec2.c line 725 in H5FD_sec2_re; ad(): file read failed: time = Wed Apr 14 11:52:33 2021; , filename = '/SCRATCH-BIRD/users/lindenbaum-p/work/NEXTFLOW/20210411.GRCh37.gatkcnv.brs/work/92/579e5a48aa9e52cd0; e1df603266809/B00HOTD.counts.hdf5', file descriptor = 250, errno = 121, error message = 'Remote I/O error', buf = ; 0x2b6ebddf38e8, total read size = 384, bytes this sub-read = 384, bytes actually read = 18446744073709551615, offs; et = 712120; major: Low-level I/O; minor: Read failed; HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5D.c line 826 in H5Dvlen_reclaim(); : invalid dataspace; major: Invalid arguments to routine; minor: Inappropriate type; 11:52:33.796 INFO GermlineCNVCaller - Shutting down engine; [April 14, 2021 11:52:33 AM CEST] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed t; ime: 0.90 minutes.; Runtime.totalMemory()=2374500352; Exception in thread ""main"" java.lang.InternalError: H5DreadVL_str: failed to read variable length strings; 	at ncsa.hdf.hdf5lib.H5.H5DreadVL(Native Method); 	at org.broadinstitute.hdf5.HDF5File.lambda$readStringArray$0(HDF5File.java:161); 	at org.broadinstitute.hdf5.HDF5File.readDataset(HDF5File.java:349); 	at org.broadinstitute.hdf5.HDF5File.readStringArray(HDF5File.java:150); 	at org.broadinstitute.hellbender.tools.copynumber.utils.HDF5Utils.readIntervals(HDF5Utils.java:62); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.HDF5SimpleCountCollection.lambda$new; $2(HDF5SimpleCountCollection.java:76); 	at htsjdk.samtools.util.Lazy.get(Lazy.java:25); 	at org.broadinstitute.hellbender.too",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7202:3457,rout,routine,3457,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7202,1,['rout'],['routine']
Integrability,"orcement of consistent GC-bias correction).; - [ ] That said, I'll carry over this TODO from above: Revisit standardization procedure by checking with simulated data. We should make sure that the centering of the data does not rescale the true copy ratio.; - The only major difference is we no longer make a QC PoN or check for large events. This was performed awkwardly in the old pipeline, so I'd rather not port it over. Eventually we will do all denoising with the gCNV coverage model anyway.; - Pre/tangent-normalization copy ratio are now referred to as standardized/denoised copy ratio.; - [x] Old code is still used for GC-bias correction in `CreateReadCountPanelOfNormals`, and we still use the `AnnotateTargets` tool. We should port this over (possibly as part of `PreprocessIntervals`) at some point (actually, I think we will be forced to, since `PreprocessIntervals` will output a Picard interval list, and `AnnotateTargets` outputs a target file).; - [x] Integration tests are still needed for `CreateReadCountPanelOfNormals`. These might not test for correctness, but we could possibly compare to old PoNs. Segmentation/modeling:; - Instead of separate tools for copy-ratio segmentation (`PerformSegmentation`) and allele-fraction segmentation/union/modeling (`AllelicCNV`), there is now just a single segmentation/modeling tool (`ModelSegments`).; - Input is denoised copy ratio and/or allelic counts. If only one input is provided, then we only model only the corresponding quantity.; - There is no separate allele-fraction workflow. Unlike the old approach, we do not perform any genotyping or modeling before doing kernel segmentation.; - [x] Old code and classes are used for segment union. We should port or possibly replace this with a simple method that uses kernel segmentation. EDIT: Actually, just tried running a WGS sample and this is still a major bottleneck. EDIT 2: Hmm...actually doesn't seem to be an issue on my desktop (compared to my laptop, on which the run hangs ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:2887,Integrat,Integration,2887,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['Integrat'],['Integration']
Integrability,org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: provided start is negative: -1; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:54768,Wrap,Wrappers,54768,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['Wrap'],['Wrappers']
Integrability,org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036:10908,wrap,wrapAndCopyInto,10908,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036,1,['wrap'],['wrapAndCopyInto']
Integrability,org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:23827,wrap,wrapAndCopyInto,23827,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['wrap'],['wrapAndCopyInto']
Integrability,org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:924); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653:5944,wrap,wrapAndCopyInto,5944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653,1,['wrap'],['wrapAndCopyInto']
Integrability,org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.regenotypeVC(GenotypeGVCFsEngine.java:185); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:135); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:283); at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:135); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:423); at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadins,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1135301848:5595,wrap,wrapAndCopyInto,5595,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1135301848,2,['wrap'],['wrapAndCopyInto']
Integrability,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2345,protocol,protocol,2345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,3,"['protocol', 'wrap']","['protocol', 'wrapper']"
Integrability,"ot sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage if there is no data for known indels. I will propose very soon two PRs with fully functional tools (without the n-way out feature for indel-realignment), and trying to add simple integration tests with the data already available on the repository and running with GATK3.8-1. If that is OK for you, I will proceed with this approach.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:2181,integrat,integration,2181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115,1,['integrat'],['integration']
Integrability,otationFactory.java:1086); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFac,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6774:3290,wrap,wrapAndCopyInto,3290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774,1,['wrap'],['wrapAndCopyInto']
Integrability,otationFactory.java:1086); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFac,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069:2468,wrap,wrapAndCopyInto,2468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069,1,['wrap'],['wrapAndCopyInto']
Integrability,other than manually testing this---is there a test I can write to include this? Maybe add it to the QS integration test?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7844#issuecomment-1125299078:103,integrat,integration,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7844#issuecomment-1125299078,1,['integrat'],['integration']
Integrability,"ots file '/researchers/sebastian.hollizeck/lowcWGS/IN-PM01004/Bam/AnalyzeCovariates.pdf'; 23:15:31.932 INFO AnalyzeCovariates - Shutting down engine; [January 19, 2020 11:15:31 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2161115136; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.2074992987327687075';source('/tmp/BQSR.6874121927957307421.R'); /tmp/AnalyzeCovariates6611620304443967041.csv /researchers/sebastian.hollizeck/lowcWGS/IN-PM01004/Bam/IN-PM01004_rmd.recal.bam.recalTable /researchers/sebastian.hollizeck/lowcWGS/IN-PM01004/Bam/AnalyzeCovariates.pdf; Stdout: WARNING: ignoring environment value of R_HOME. Stderr: During startup - Warning messages:; 1: Setting LC_CTYPE failed, using ""C"" ; 2: Setting LC_COLLATE failed, using ""C"" ; 3: Setting LC_TIME failed, using ""C"" ; 4: Setting LC_MESSAGES failed, using ""C"" ; 5: Setting LC_MONETARY failed, using ""C"" ; 6: Setting LC_PAPER failed, using ""C"" ; 7: Setting LC_MEASUREMENT failed, using ""C"" ; Error in readRDS(pfile) : ; cannot read workspace version 3 written by R 3.6.0; need R 3.5.0 or newer; Calls: source ... library -> find.package -> lapply -> FUN -> readRDS; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:80); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:19); 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.generatePlots(RecalUtils.java:360); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.generatePlots(AnalyzeCovariates.java:329); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.Analy",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6393:3741,message,messages,3741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6393,1,['message'],['messages']
Integrability,"ould like to address are similar to yours, with some inclussions. * Regarding NIO support, I would go to remove completely `File` support. If API users need to use the `File` abstraction, they should convert to a `java.nio.Path` using the `toPath` method.; * In addition, I would like that HTTP/S and FTP is handled also with NIO. For HTTP/S, I am working in a simple `FileSystemProvider` that should be good enough for using in combination with HTSJDK ([jsr203-http](https://github.com/magicDGS/jsr203-http)), and I can speed up the development there for needs in HTSJDK; for FTP, maybe [ftp-fs](https://github.com/robtimus/ftp-fs) can be used or a simple implementation can be derived from the HTTP/S implementation (without credentials). This will remove the special handling of HTTP/S and FTP paths in HTSJDK in favor of a consistent and pluggable manner.; * Interfaces for the data types are great, and maybe it will be good to have codec interfaces for both encoding and decoding. For example, I am missing encoders in tribble (an attempt in https://github.com/samtools/htsjdk/pull/822 for writing support).; * For VCF, I would like to have a less diploid-centric interface and design, or at least a way of configure the catching of genotype-related attributes. Currently there are methods for homozygotes/heterozygotes that aren't really useful for triploids or even VCFs without variation (for example, in Pool-Seq data).; * Modular design for artifacts: thus, a project with only SAM/BAM requirements will require only `htsjdk-sam`, and if they also want CRAM support, `htsjdk-cram`. See https://github.com/samtools/htsjdk/issues/896 for more info about it.; * Common license for all HTSJDK, or at least for each module. This will be good for taking into account legal concerns when including the library, because now there is a mixture depending on the files that are used. This is what is coming to my mind now. Maybe I added something else in https://github.com/samtools/htsjdk/issues/520",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940:1238,interface,interface,1238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940,2,"['depend', 'interface']","['depending', 'interface']"
Integrability,ounds for length 1; > 44 at java.base/jdk.internal.util.Preconditions.outOfBounds(Preconditions.java:64); > 45 at java.base/jdk.internal.util.Preconditions.outOfBoundsCheckIndex(Preconditions.java:70); > 46 at java.base/jdk.internal.util.Preconditions.checkIndex(Preconditions.java:266); > 47 at java.base/java.util.Objects.checkIndex(Objects.java:359); > 48 at java.base/java.util.ArrayList.get(ArrayList.java:427); > 49 at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.lambda$getGermlineAltAlleleFrequencies$27(SomaticGenotypingEngine.java:389); > 50 at java.base/java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:248); > 51 at java.base/java.util.stream.SliceOps$1$1.accept(SliceOps.java:200); > 52 at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625); > 53 at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509); > 54 at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499); > 55 at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:575); > 56 at java.base/java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); > 57 at java.base/java.util.stream.DoublePipeline.toArray(DoublePipeline.java:571); > 58 at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getGermlineAltAlleleFrequencies(SomaticGenotypingEngine.java:390); > 59 at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getNegativeLogPopulationAFAnnotation(SomaticGenotypingEngine.java:363); > 60 at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:166); > 61 at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:336); > 62 at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:304); > 63 at org.broadinstitute.hellbender.engine.AssemblyRegionWal,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7849#issuecomment-1597198632:5609,wrap,wrapAndCopyInto,5609,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7849#issuecomment-1597198632,1,['wrap'],['wrapAndCopyInto']
Integrability,ource); ```. then there are dumps like this. ```; org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markPairedEnds$66146993$1(MarkDuplicatesSparkUtils.java:182); org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils$$Lambda$51/84990817.call(Unknown Source); org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$1$1.apply(JavaRDDLike.scala:126); org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$1$1.apply(JavaRDDLike.scala:126); scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371); scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327); scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388); scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388); scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327); scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327); scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327); scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:29); org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.lambda$apply$26a6df3e$1(BaseRecalibratorSparkFn.java:27); org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn$$Lambda$65/1110390847.call(Unknown Source); ```. and . ```; org.broadinstitute.hellbender.engine.filters.ReadFilter.lambda$and$cbfb947b$1(ReadFilter.java:31); org.broadinstitute.hellbender.engine.filters.ReadFilter$$Lambda$33/1797796358.test(Unknown Source); org.broadinstitute.hellbender.engine.filters.ReadFilter.lambda$and$cbfb947b$1(ReadFilter.java:31); org.broadinstitute.hellbender.engine.filters.ReadFilter$$Lambda$33/1797796358.test(Unknown Source); org.broadinstitute.hellbender.engine.filters.ReadFilter.lambda$and$cbfb947b$1(ReadFilter.java:31); org.broadinstitute.hellbender.engine.filters.ReadFilter$$Lambda$33/1797796358.test(Unknown Source); org.broadinstitute.hellbender.engine.filters.ReadFilter.lambda$and$cbfb947b$1(ReadFilter.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1657#issuecomment-203742647:2153,Wrap,Wrappers,2153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1657#issuecomment-203742647,1,['Wrap'],['Wrappers']
Integrability,"out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:158); 	at com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:489); 	at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:206); 	... 31 more; ```; Followed by repetitions of the following stacktrace:; ```; Feb 07, 2018 12:41:59 PM com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; java.net.SocketTimeoutException: connect timed out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doC",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369:4398,protocol,protocol,4398,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369,1,['protocol'],['protocol']
Integrability,out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:158); 	at com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:489); 	at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:206); 	at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:70); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1825); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1012); 	at com.google.cloud.hado,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369:6295,protocol,protocol,6295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369,1,['protocol'],['protocol']
Integrability,outputting better error messages when command line parsing fails,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/173:24,message,messages,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/173,1,['message'],['messages']
Integrability,overall this looks reasonable to me. Adding an integration test is important - at least lock in the variants that are concordant with gatk3 so that we dont lose those while refactoring and fixing etc.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1567#issuecomment-196949010:47,integrat,integration,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1567#issuecomment-196949010,1,['integrat'],['integration']
Integrability,oy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: provided start is negative: -1; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkCont,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:54802,Wrap,Wrappers,54802,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['Wrap'],['Wrappers']
Integrability,"ozygous genotypes failing two-tailed binomial test (example below); q .. select genotypes using -i/-e options; and the new genotype can be one of:; . .. missing (""."" or ""./."", keeps ploidy); 0 .. reference allele (e.g. 0/0 or 0, keeps ploidy); c:GT .. custom genotype (e.g. 0/0, 0, 0/1, m/M, overrides ploidy); m .. minor (the second most common) allele (e.g. 1/1 or 1, keeps ploidy); M .. major allele (e.g. 1/1 or 1, keeps ploidy); p .. phase genotype (0/1 becomes 0|1); u .. unphase genotype and sort by allele (1|0 becomes 0/1); Usage: bcftools +setGT [General Options] -- [Plugin Options]; Options:; run ""bcftools plugin"" for a list of common options. Plugin options:; -e, --exclude <expr> Exclude a genotype if true (requires -t q); -i, --include <expr> include a genotype if true (requires -t q); -n, --new-gt <type> Genotypes to set, see above; -t, --target-gt <type> Genotypes to change, see above. Example:; # set missing genotypes (""./."") to phased ref genotypes (""0|0""); bcftools +setGT in.vcf -- -t . -n 0p. # set missing genotypes with DP>0 and GQ>20 to ref genotypes (""0/0""); bcftools +setGT in.vcf -- -t q -n 0 -i 'GT=""."" && FMT/DP>0 && GQ>20'. # set partially missing genotypes to completely missing; bcftools +setGT in.vcf -- -t ./x -n . # set heterozygous genotypes to 0/0 if binom.test(nAlt,nRef+nAlt,0.5)<1e-3; bcftools +setGT in.vcf -- -t ""b:AD<1e-3"" -n 0. # force unphased heterozygous genotype if binom.test(nAlt,nRef+nAlt,0.5)>0.1; bcftools +setGT in.vcf -- -t ./x -n c:'m/M'; ```; I was always wondering if GATK will have a plugin interface where people can code their own using groovy, kotlin, javascript or python plugins to extend some of the functionality where developers may not reach immediately. Personally I use htsjdk extensively (and sometimes pysam) to code a new personal tool each time I need something that I cannot find exactly what I look for. But a generic gatk plugin interface would be really useful and may provide means to extend the community support.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1556119501:1930,interface,interface,1930,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1556119501,2,['interface'],['interface']
Integrability,p.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482:2399,wrap,wrapper,2399,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482,5,"['Wrap', 'wrap']","['WrapperExecutor', 'wrapper']"
Integrability,p: |; | [...er/tools/picard/analysis/CollectGcBiasMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9waWNhcmQvYW5hbHlzaXMvQ29sbGVjdEdjQmlhc01ldHJpY3MuamF2YQ==) | `0.794% <0%> (+0.794%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `0.847% <0%> (+0.847%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `67.347% <0%> (+1.02%)` | `34% <0%> (+1%)` | :arrow_up: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `73.118% <0%> (+1.075%)` | `25% <0%> (ø)` | :arrow_down: |; | [...e/conversion/allelicbalancecaller/CNLOHCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9jb252ZXJzaW9uL2FsbGVsaWNiYWxhbmNlY2FsbGVyL0NOTE9IQ2FsbGVyLmphdmE=) | `96.283% <0%> (+1.115%)` | `95% <0%> (+3%)` | :arrow_up: |; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `92.737% <0%> (+1.117%)` | `61% <0%> (+2%)` | :arrow_up: |; | [...itute/hellbender/tools/picard/vcf/LiftOverVcf.java](h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320273200:2874,Integrat,IntegrationTestSpec,2874,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320273200,1,['Integrat'],['IntegrationTestSpec']
Integrability,pache.commons.math3.linear.Array2DRowRealMatrix.walkInRowOrder(Array2DRowRealMatrix.java:400); at org.apache.commons.math3.linear.AbstractRealMatrix.walkInOptimizedOrder(AbstractRealMatrix.java:879); at org.broadinstitute.hellbender.tools.walkers.annotator.AllelePseudoDepth.composeInputLikelihoodMatrix(AllelePseudoDepth.java:122); at org.broadinstitute.hellbender.tools.walkers.annotator.AllelePseudoDepth.annotate(AllelePseudoDepth.java:93); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.lambda$annotateGenotypes$6(VariantAnnotatorEngine.java:427); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateGenotypes(VariantAnnotatorEngine.java:427); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:360); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:334); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:243); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.base/java,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8800:4712,wrap,wrapAndCopyInto,4712,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8800,1,['wrap'],['wrapAndCopyInto']
Integrability,park.lambda$regionToVariants$2(HaplotypeCallerSpark.java:253); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark$$Lambda$312.00000000EC650830.apply(Unknown Source); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:278); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1823); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:305); at java.util.stream.StreamSpliterators$WrappingSpliterator$$Lambda$314.00000000EC651070.getAsBoolean(Unknown Source); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:217); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:180); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:311); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:692); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948); at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:888); at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:948); at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:694); at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334); at org.apache.spark.rdd.RDD.iterator(RDD.scala:285); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4265:2231,Wrap,Wrappers,2231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4265,1,['Wrap'],['Wrappers']
Integrability,"parkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:14:00 WARN scheduler.TaskSetManager: Lost task 16.0 in stage 0.0 (TID 2, scc-q15.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 146479558, span 42247, expected MD5 8e364a33b9a9350f9ebfac1db38af647; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.r",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:8147,Wrap,Wrappers,8147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['Wrap'],['Wrappers']
Integrability,"parkGenomeReadCounts"" tool is a non-helpful ""null"" error message. A non-helpful error ""null"" message was printed by gatk-protected with the command-line below; during the course of trying to use it on/in FireCloud:. ```; + java -Xmx48g -jar fc-7ac504fc-7fe4-4bc1-89d3-7f16317b8ff4/eddie.jar SparkGenomeReadCounts --outputFile this.entity_id.coverage.tsv --reference fc-e2421839-93d5-4ed5-8861-593f00364e54/Homo_sapiens_assembly19.fasta --input firecloud-tcga-open-access/tutorial/bams/C835.HCC1143_BL.4.bam --binsize 5000; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp; .....; ......; ......; proceeding with flushing remote transports.; ***********************************************************************. null. ***********************************************************************; ```. To try to make a more helpful error message appear I added a ""catch"" block after a call to runTool in instanceMainPostParseArgs in file CommandLineProgram.java and got a more helpful message about a missing dictionary file: . try {; return runTool();; } ; catch(Exception e) {; e.getStackTrace();; }. java.lang.RuntimeException: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:204); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:152); Caused by: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:409); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2922:1141,message,message,1141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2922,1,['message'],['message']
Integrability,patch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); ```. Unlikely to be related to this branch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6652#issuecomment-672024253:5016,Message,MessageHubBackedObjectConnection,5016,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6652#issuecomment-672024253,6,['Message'],"['MessageHub', 'MessageHubBackedObjectConnection']"
Integrability,"pe; if (isinf(small) == -1 || isinf(big) == -1); ^; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:16: note: suggested alternative:; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/template.h:4,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/avx_function_instantiations.cc:3:; /usr/local/Cellar/gcc/5.3.0/include/c++/5.3.0/cmath:853:5: note: 'std::isinf'; isinf(_Tp __f); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/template.h:86:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/avx_function_instantiations.cc:3:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:38: error: 'isinf' was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive]; if (isinf(small) == -1 || isinf(big) == -1); ^; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:16: note: 'isinf' declared here, later in the translation unit; if (isinf(small) == -1 || isinf(big) == -1); ^; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h: In instantiation of 'static NUMBER ContextBase<NUMBER>::approximateLog10SumLog10(NUMBER, NUMBER) [with NUMBER = float]':; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/pairhmm-template-kernel.cc:120:9: required from 'void initializeVectorsavxs(int, int, NUMBER*, NUMBER*, NUMBER*, Context<NUMBER>, testcase*, __m256*, __m256*, __m256*, __m256*, __m256*, __m256*, __m256*) [with NUMBER = float; __m256 = __vector(8) float]'; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/pairhmm-template-kernel.cc:268:69: required from 'NUMBER compute_full_prob_avxs(testcase*, NUMBER*) [with NUMBER = float]'; /Users/louisb/Worksp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187417081:3840,depend,dependent,3840,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187417081,2,['depend'],['dependent']
Integrability,peCallerGenotypingEngine.java:162); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:596); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1(HaplotypeCallerSpark.java:282); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1038); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:969); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:760); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrRe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230:1999,Wrap,Wrappers,1999,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230,1,['Wrap'],['Wrappers']
Integrability,"periment with the LL score discussed there (see https://www.aaai.org/Papers/ICML/2003/ICML03-060.pdf for the original paper---although note that despite the paper's high citation count, I'm not sure what the canonical name for this metric actually is, but it doesn't appear to be ""LL score""---perhaps someone else knows or has better Google-fu and can figure it out) before moving on to their methods for estimating F1. Doing a literature search for other discussions of optimizing F1 or other metrics in the context of positive-unlabeled learning might be worthwhile, but I think most methods will probably involve some sort of estimation of the base rate in unlabeled data. I think we may have to add some mechanism for holding out a validation set during training if we want to automatically tune thresholds in a rigorous fashion. Shouldn't be too bad---we can just have the training tool randomly mask out a set of the truth and pass the mask to the scoring tool (or maybe just determine the threshold in the training tool, if we are running in positive/negative mode and have access to unlabeled data)---but does add a couple of parameters to the tool interfaces. This also adds additional dependence on the quality of the truth resources. I think an implicit assumption in any use of the truth---even just thresholding/calibrating by sensitivity---is that it is a random sample; however, I'm not sure how true this is in actual use. For example, in malaria, it looks like we may have to resort to using a callset that has been very conservatively filtered as truth, which will bias us towards high scores and the peaks of the positive distribution. Perhaps we can also experiment with just treating training/truth on an equal footing (I think the distinction between the two is somewhat blurry in the original VQSR design, anyway). Perhaps @davidbenjamin has some thoughts? I see some related stuff going on in ThresholdCalculator, but I have to admit that I can't tell whether that's used in a ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241:1678,interface,interfaces,1678,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241,1,['interface'],['interfaces']
Integrability,pin every dependency in the gatkcondaenv to the last successful version,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7801:10,depend,dependency,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7801,1,['depend'],['dependency']
Integrability,pin hail version in the integration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8424:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8424,1,['integrat'],['integration']
Integrability,"please clean up the pull request - include only changes relevant to this integration test. Also, a test is failing on travis `Cannot read non-existent file: /home/travis/build/broadinstitute/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/picard/analysis/CollectBaseDistributionByCycle/first5000a.bam`. please fix those and reassign to me; back to @dekling",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/872#issuecomment-137495836:73,integrat,integration,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/872#issuecomment-137495836,1,['integrat'],['integration']
Integrability,"plied_ to the reference to generate the SV genome. Paired-end reads w/ equal lengths (100bp) and insert sizes (500bp) were _uniformly_ generated from the SV genome and was mapped to chr22 using BWA-MEM (default arguments). Coverage on 100bp uniform bins were collected using `CollectFragmentCounts` (default arguments: MQ > 30, both mates aligned, and only innies). The coverage was studied case-by-case on a few SVs. **Case-by-base study**:; ; _Balanced translocation:_; <img width=""1440"" alt=""baltr-1-igv"" src=""https://user-images.githubusercontent.com/15305869/37737056-0a811466-2d29-11e8-84ef-4f31f030d05b.png"">. Here, an event in shown where a ~ 3kb region of chr22 is translocated to another region. Ideally, there should be no coverage loss. The IGV inspection shows excess coverage on the left side and depletion on the right side. Upon inspecting the conjugate translocation site, a similar scenario is seen. This situation is hardly avoidable -- depending on the mappability of the two loci, one captures the chimeric fragment of the other with higher probability (right?). The situation is worse for `CollectFragmentCounts` because chimeras are ignored altogether:. ![baltr-1](https://user-images.githubusercontent.com/15305869/37738066-2bb27a5a-2d2c-11e8-905d-ea553b93741b.png). _Deletion:_; For deletions, both coverage collection strategies work well. The deletion region is not quite captured perfectly by either method. <img width=""1440"" alt=""del-1-igv"" src=""https://user-images.githubusercontent.com/15305869/37738404-48dec038-2d2d-11e8-9d7e-625ff8e453e7.png"">. ![del-1](https://user-images.githubusercontent.com/15305869/37739544-ceeb7376-2d30-11e8-9480-3fb2a408e48a.png). _Tandem Duplication_:; For tandem duplications, neglecting FF and RR fagments leads to an underestimation of the size of the duplicated region by `CollectFragmentCounts`. IGV does not seem to get it quite right either (@cwhelan does the IGV plot make sense to you? could it be there's a bug in SVGen in genera",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4551:1426,depend,depending,1426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551,1,['depend'],['depending']
Integrability,"plotypes in the sample contains the site-specific alternate allele at the site (ie. excluding `*` which represents variation that beings upstream of the current variant. NB that this results in cases where `PGT` is not the same as the phased `GT` field. For example, in the case of a spanned SNP site with REF allele `A` and alt alleles `C` and `*`, `GT` may be set to `1|2` to represent the spanned SNP, while PGT would be set to `1|0` to represent the fact that it is the first haplotype in the pair of phased haplotypes that contains the site-specific alt allele (in this case `C`). If reviewers agree with this interpretation, I think we should create a new ticket to clarify documentation around the PGT and PID tags to reflect it. . After discussions with @ldgauthier I believe that there may be downstream issues in preserving phasing after passing gVCFs through CombineGVCFs, GenomicsDBImport, and/or GenotypeGVCFs, especially if the gVCFs are emitted without GT fields. In that case, `GenotypeGVCFs` should probably have logic to reconstruct the phased genotype for each sample based on the PGT and PID tags when possible. I will create a new ticket describing the issue. There still may be cases where HaplotypeCaller does not emit phasing information for spanning deletions due to the presence of extra haplotypes that contradict diploid phasing, as in https://github.com/broadinstitute/gatk/issues/6845. A fix to that issue would likely reduce the number of those cases. The integration test result file `src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/withOxoGReadCounts.vcf` does not have any changes that have to do with this PR -- it was automatically updated by GenotypeGVCFsIntegrationTest, which included some new jitter in QUAL scores as described in https://github.com/broadinstitute/gatk/pull/6859, but never got checked in with that PR. I figure that it's best to update it now so that the results reflect the current expected behavior of the tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6937:1856,integrat,integration,1856,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6937,1,['integrat'],['integration']
Integrability,"pp/VectorLoglessPairHMM/LoadTimeInitializer.cc:1:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h: In instantiation of 'static NUMBER ContextBase<NUMBER>::approximateLog10SumLog10(NUMBER, NUMBER) [with NUMBER = double]':; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:75:53: required from 'static void ContextBase<NUMBER>::initializeMatchToMatchProb() [with NUMBER = double]'; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:47:35: required from 'static void ContextBase<NUMBER>::initializeStaticMembers() [with NUMBER = double]'; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc:53:20: required from here; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:16: error: 'isinf' was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive]; if (isinf(small) == -1 || isinf(big) == -1); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:4,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/utils.h:4,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc:1:; /usr/local/Cellar/gcc/5.3.0/include/c++/5.3.0/cmath:853:5: note: 'template<class _Tp> typename __gnu_cxx::__enable_if<std::__is_arithmetic<_Tp>::__value, int>::__type std::isinf(_Tp)' declared here, later in the translation unit; isinf(_Tp __f); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/utils.h:4:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc:1:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:38: error: 'isinf' was not declared ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343:13212,depend,dependent,13212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343,1,['depend'],['dependent']
Integrability,"ppear to be ""LL score""---perhaps someone else knows or has better Google-fu and can figure it out) before moving on to their methods for estimating F1. Doing a literature search for other discussions of optimizing F1 or other metrics in the context of positive-unlabeled learning might be worthwhile, but I think most methods will probably involve some sort of estimation of the base rate in unlabeled data. I think we may have to add some mechanism for holding out a validation set during training if we want to automatically tune thresholds in a rigorous fashion. Shouldn't be too bad---we can just have the training tool randomly mask out a set of the truth and pass the mask to the scoring tool (or maybe just determine the threshold in the training tool, if we are running in positive/negative mode and have access to unlabeled data)---but does add a couple of parameters to the tool interfaces. This also adds additional dependence on the quality of the truth resources. I think an implicit assumption in any use of the truth---even just thresholding/calibrating by sensitivity---is that it is a random sample; however, I'm not sure how true this is in actual use. For example, in malaria, it looks like we may have to resort to using a callset that has been very conservatively filtered as truth, which will bias us towards high scores and the peaks of the positive distribution. Perhaps we can also experiment with just treating training/truth on an equal footing (I think the distinction between the two is somewhat blurry in the original VQSR design, anyway). Perhaps @davidbenjamin has some thoughts? I see some related stuff going on in ThresholdCalculator, but I have to admit that I can't tell whether that's used in a similar PU context. Also note that depending on the model used, we might not have well calibrated posteriors---the IsolationForest simply outputs scores in a unit interval, and we simply report the difference between the positive and the negative scores, for example.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241:2557,depend,depending,2557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241,1,['depend'],['depending']
Integrability,"pply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:13:58 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0, scc-q16.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 9999, span 21707, expected MD5 059b07ed1e0589040ada9b236b88b509; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.r",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:6561,Wrap,Wrappers,6561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['Wrap'],['Wrappers']
Integrability,"practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already placing the correct argument name before the file name. What else you need!"". Proposal:. An annotation to tell what codes to try out, the first one that canDecode returns true is used otherwise a configurable error message saying what the problem could be:. <pre>; @Codecs(BEDCodec.class); FeatureInput&lt;BEDFeature&gt; features;; </pre>. <pre>; @Codecs(value = BEDCodec.class, failureMessage = ""The file provided must be a BED formatted file with extension .bed""); FeatureInput&lt;BEDFeature&gt; features;; </pre> . <pre>; @Codecs(BCFCodec.class, VCFCodec.class); FeatureInput&lt;VariantContext&gt; variants;; </pre>. <pre>; // force = true, means that canDecode won't be called and instead we try to read the content directly,; // the codec's code is responsible to throw an appropriate UserException.BadInput indicating formatting issues; this should be the case already anyway.; @Codecs(value = TargetCodec.class, force = true); FeatureInput&lt;Target&gt; target;; </pre>. If the annotation is not present it can default to the current behavior.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1184:2214,message,message,2214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184,1,['message'],['message']
Integrability,prevent log message from triggering incorrectly,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4147:12,message,message,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4147,1,['message'],['message']
Integrability,prevent log4j error messages in spark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2622:20,message,messages,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2622,1,['message'],['messages']
Integrability,previously system properties were set by the wrapper script but not by gatk-launch when running with a local jar; now both local jar and wrapper script get the same properties; more properties are now explicitely set for spark tools as well; fixes #2316,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2500:45,wrap,wrapper,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2500,2,['wrap'],['wrapper']
Integrability,"previously we dependend on com.github.fommil.netlib:netlib:all which is a pom only dependency that includes a number of jars containing native code. this caused problems when importing GATK using maven, see #3724. to fix this, I've added the exact versions of the transitive dependencies that we want; an added bonus is that it means we are no longer including native code for systems we don't support, like arm, 32 bit systems, and windows",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3742:14,depend,dependend,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3742,3,['depend'],"['dependencies', 'dependency', 'dependend']"
Integrability,profiling of GenotypeGVCFs showed a lot of wasted time in VariantContext.toString() which can be tracked to computing an error message we never display in `AFCalculator.getLog10PNonRef`; fixing it so we only compute the message when we the error occurs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3478:127,message,message,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3478,2,['message'],['message']
Integrability,"ption of the columns (each being of form; tract_name.column_name). There's nothing at all sophisticated about this; format, but it's pretty generalizable and easy to parse (and create). An; example; >; > # hgIntegrator: database=hg38 region=genome Wed Apr 18 11:15:34 2018; >; > #gap.chrom gap.chromStart gap.chromEnd gap.type; >; > chr1 0 10000 telomere; >; > chr1 207666 257666 contig; >; > chr1 297968 347968 contig; >; > chr1 535988 585988 contig; >; > chr1 2702781 2746290 scaffold; >; >; For what it's worth, your description of your approach sounds like a; sensible one to me.; I am concerned about the size of the data and how we'd access it. I've; chosen the tracts I have because they are small enough to jam into; resources. On Tue, May 1, 2018 at 8:06 AM samuelklee <notifications@github.com> wrote:. > @TedBrookings <https://github.com/TedBrookings> which formats are you; > using, in particular?; >; > In the CNV package, I've taken pains to unify how tabular data are; > represented in Java, depending on whether each record is Locatable or; > whether the collection of records can be associated with a sample name or; > sequence dictionary. This allows us to represent records that extend; > Locatable with multidimensional numerical or non-numerical annotations; > along with some metadata (sample name and sequence dictionary) with a; > minimum of boilerplate. There are also base methods for producing interval; > trees, etc.; >; > However, this unification effort was a quick push I made before release,; > so some polishing or redesigning may be warranted. We may also want to add; > more forms of metadata, etc. if other teams would require more features.; > Another downside is that this code lacks the indexing, NIO support, etc.; > that some of the other standardized/Tribble formats enjoy. For CNV data,; > this isn't a huge issue, but I think it would be nice to unify how we; > represent such data GATK-wide. As I said above, I don't think VCF is the; > correct answer, but",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385683551:1519,depend,depending,1519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385683551,1,['depend'],['depending']
Integrability,"ption: Job aborted due to stage failure: Task 12 in stage 0.0 failed 4 times, most recent failure: Lost task 12.3 in stage 0.0 (TID 14, scc-q09.scc.bu.edu, executor 1): java.lang.IllegalArgumentException: **Wrong FS: hdfs://scc:8020/user/farrell/adsp/bams/SRR990385.bai, expected: hdfs://scc**; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:105); at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302); at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298); at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766); at org.seqdoop.hadoop_bam.util.WrapSeekable.openPath(WrapSeekable.java:60); at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:142); at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:121); at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:178); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:177); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:134); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:69); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3909:1881,Wrap,WrapSeekable,1881,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3909,1,['Wrap'],['WrapSeekable']
Integrability,"quified samples. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-260475512). @ldgauthier Will this tool be ported to GATK4? . ---. @ldgauthier commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-260637796). ¯_(ツ)_/¯. I wasn't going to port it myself. It's not under active development, but GTEx used it a little in the past. ---. @vdauwera commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-260713724). Hmm. Who would be the right person to ask whether GTex would need this ported? . ---. @ldgauthier commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-260739166). Last I checked, Xiao Li was using the tool for the work he was doing with Ayellet Segre. ---. @vdauwera commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-260778577). Thanks, I emailed them to ask about their use of the tool. . ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-287823398). Response from Xiao Li:. > The “CombineSampleData” tool is initially developed by Laura to perform integrated variant calling when we have both WES and WGS data for same individuals. Use GTEx release v6 data, we have found that it helps generating better genotype calls and improves calls from older technologies (e.g.: HiSeq2000 vs. HiSeqX, Agilent vs. ICE). In GTEx, all samples will be genotyped with both WGS and WES, and because of this, in our final release next year, we want to use this tool to generate a call set that integrates WGS and WES. Prior to this, we plan to publish this method that we could cite it in the final release paper. I will expect this method very useful for other big consortiums where both WGS and WES are available for same samples. . > Hope you could keep it in GATK.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2485:4110,integrat,integrated,4110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2485,2,['integrat'],"['integrated', 'integrates']"
Integrability,"r gradle; build.gradle. 3. Significant changes to existing code to support/invoke new filter; - add arguments for XGBoostEvidenceFilter, changes for scaling density filter by coverage; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/StructuralVariationDiscoveryArgumentCollection.java; - replace calls to BreakpointDensityFilter with calls to BreakpointFilterFactory; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSpark.java; - input coverage-scaled thresholds, convert to absolute internally. Allow thresholds to be double instead of int; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointDensityFilter.java; - getter functions added to calculate properties for XGBoostEvidenceFilter. Also fromStringRep() and helper constructors added for testing; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointEvidence.java; - updates to tests reflecting changes to these interfaces; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointDensityFilterTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSparkUnitTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/integration/FindBreakpointEvidenceSparkIntegrationTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/integration/SVIntegrationTestDataProvider.java. 4. Added code; - factory to call appropriate BreakpointEvidence filter; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointFilterFactory.java; - simple helper class to hold feature vectors for classifier; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/EvidenceFeatures.java; - implement classifier-based BreakpointEvidence filter; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/XGBoostEvidenceFilter.java; - unit test for classifier filter; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389218477:1741,interface,interfaces,1741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389218477,1,['interface'],['interfaces']
Integrability,"r.java:102); at htsjdk.tribble.TribbleIndexedFeatureReader.&lt;init&gt;(TribbleIndexedFeatureReader.java:127); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:120); at org.broadinstitute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:350); ... 14 more; Caused by: java.lang.IllegalStateException: Duplicate key 0; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1254); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec.readActualHeader(XsvLocatableTableCodec.java:341); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec.readActualHeader(XsvLocatableTableCodec.java:64); at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:79); at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:37); at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:261); ... 18 more; ```. java version:; ```; java -version; openjdk version ""1.8.0_222""; OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1~deb9u1-b10); OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode); ```; I added th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223:3240,wrap,wrapAndCopyInto,3240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223,1,['wrap'],['wrapAndCopyInto']
Integrability,r.java:89); 	at htsjdk.variant.variantcontext.writer.IndexingVariantContextWriter.add(IndexingVariantContextWriter.java:203); 	at htsjdk.variant.variantcontext.writer.VCFWriter.add(VCFWriter.java:242); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants.apply(SelectVariants.java:620); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6443:2964,wrap,wrapAndCopyInto,2964,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6443,1,['wrap'],['wrapAndCopyInto']
Integrability,r/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(Nati,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482:1204,wrap,wrapper,1204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482,1,['wrap'],['wrapper']
Integrability,ractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:162); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:79); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:996); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:541); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:474); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:591); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:436); 	... 29 more; `; Thanks for your time!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:7771,protocol,protocol,7771,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['protocol'],['protocol']
Integrability,"raction model only models hets, we perform a `GetHetCoverage`-like binomial genotyping step (and output the results) before modeling. However, instead of assuming the null hypothesis of het (f = 0.5) and accepting a site when we cannot reject the null, we assume the null hypothesis of hom (f = error rate or 1 - error rate) and accept a site when we can reject the null. This entire process is very similar to what @davidbenjamin does in https://github.com/broadinstitute/gatk/pull/3638. We should consider combining this code (along with `AllelicCount`/`PileupSummary`) at some point.; - [x] Added option to use matched normal.; - [ ] Rather than port over the old modeling code, I would rather expand the allele-fraction model to allow for the modeling of hom sites. I wrote up such a model in some notes I sent around a few months back. This model allows for an allelic PoN that uses all sites to learn reference bias, not just hets. Depending on how our python development proceeds, I may try to implement this model using the old `GibbsSampler` code instead.; - [x] In the meantime, we can try to speed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed the mode and highest density credible interval (because of the below item).; - [x] Some residual bias remains i",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:5463,Depend,Depending,5463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['Depend'],['Depending']
Integrability,"rageImpl.get(StorageImpl.java:238); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:736); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:497); at htsjdk.samtools.util.IOUtil.assertPathsAreReadable(IOUtil.java:525); at picard.fingerprint.CrosscheckFingerprints.doWork(CrosscheckFingerprints.java:449); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Bucket is requester pays bucket but no user project provided."",; ""reason"" : ""required""; } ],; ""message"" : ""Bucket is requester pays bucket but no user project provided.""; }; at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:150); at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:451); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1089); at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7489:2046,message,message,2046,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7489,1,['message'],['message']
Integrability,"ralVariationDiscoveryArgumentCollection.java; - replace calls to BreakpointDensityFilter with calls to BreakpointFilterFactory; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSpark.java; - input coverage-scaled thresholds, convert to absolute internally. Allow thresholds to be double instead of int; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointDensityFilter.java; - getter functions added to calculate properties for XGBoostEvidenceFilter. Also fromStringRep() and helper constructors added for testing; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointEvidence.java; - updates to tests reflecting changes to these interfaces; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointDensityFilterTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSparkUnitTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/integration/FindBreakpointEvidenceSparkIntegrationTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/integration/SVIntegrationTestDataProvider.java. 4. Added code; - factory to call appropriate BreakpointEvidence filter; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointFilterFactory.java; - simple helper class to hold feature vectors for classifier; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/EvidenceFeatures.java; - implement classifier-based BreakpointEvidence filter; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/XGBoostEvidenceFilter.java; - unit test for classifier filter; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/XGBoostEvidenceFilterUnitTest.java. 5. Added resources; - Genome tracts; src/main/resources/large/hg38_centromeres.txt.gz; src/main/resources/large/hg38_gaps.txt.gz; src/main/resources/large/hg38_umap_s100.txt.gz; - Classifier binary file; src/main/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389218477:2024,integrat,integration,2024,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389218477,1,['integrat'],['integration']
Integrability,"raph; originally. Maybe the use case was variants from UG that we didn't; necessarily believe were aligned properly?. I don't have any objections, but I'd feel better if we had a better guess; at what the original method was trying to do. On Wed, Apr 3, 2019 at 9:56 PM David Benjamin <notifications@github.com>; wrote:. > In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them; > into the ref haplotype, then threading these constructed haplotypes into; > the assembly graph with a large edge weight. There are several drawbacks to; > this approach:; >; > - The strange edge weights interfere with the AdaptiveChainPruner.; > - The large edge weights may not be large enough to avoid pruning when; > depth is extremely high.; > - The alleles may be lost if assembly fails.; > - If the alleles actually exist but are in phase with another variant; > we end up putting an enormous amount of weight on a false haplotype.; >; > We can get around these issue with the following method:; >; > - assemble haplotypes without regard to the force-called alleles.; > - if an allele is present in these haplotypes, do nothing further.; > - otherwise, add a haplotype in which the allele is injected into the; > reference haplotype.; >; > @LeeTL1220 <https://github.com/LeeTL1220> I prototyped this and it seems; > to resolve the missed forced alleles that Ziao found.; >; > @ldgauthier <https://github.com/ldgauthier> Can you think of any; > objections to making this change in HaplotypeCaller?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMcaTJg47gnOkE-d_AeAqXpO8zpxks5vdVvfgaJpZM4cbxVV>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767:1438,inject,injected,1438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767,1,['inject'],['injected']
Integrability,"rc/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:4,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/utils.h:4,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc:1:; /usr/local/Cellar/gcc/5.3.0/include/c++/5.3.0/cmath:853:5: note: 'template<class _Tp> typename __gnu_cxx::__enable_if<std::__is_arithmetic<_Tp>::__value, int>::__type std::isinf(_Tp)' declared here, later in the translation unit; isinf(_Tp __f); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/utils.h:4:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc:1:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:38: error: 'isinf' was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive]; if (isinf(small) == -1 || isinf(big) == -1); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:4,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/utils.h:4,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc:1:; /usr/local/Cellar/gcc/5.3.0/include/c++/5.3.0/cmath:853:5: note: 'template<class _Tp> typename __gnu_cxx::__enable_if<std::__is_arithmetic<_Tp>::__value, int>::__type std::isinf(_Tp)' declared here, later in the translation unit; isinf(_Tp __f); ^. /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/utils.cc: In function 'void get_time(timespec*)':; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/utils.cc:214:17: error: 'CLOCK_REALTIME' was not declared in this scope; clock_gettime(CLOCK_REALTIME, store_struct);; ^; /Users/louisb/Workspa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343:14323,depend,dependent,14323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343,1,['depend'],['dependent']
Integrability,"rc/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:4,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/utils.h:4,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc:1:; /usr/local/Cellar/gcc/5.3.0/include/c++/5.3.0/cmath:853:5: note: 'template<class _Tp> typename __gnu_cxx::__enable_if<std::__is_arithmetic<_Tp>::__value, int>::__type std::isinf(_Tp)' declared here, later in the translation unit; isinf(_Tp __f); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/utils.h:4:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc:1:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:38: error: 'isinf' was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive]; if (isinf(small) == -1 || isinf(big) == -1); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:4,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/utils.h:4,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc:1:; /usr/local/Cellar/gcc/5.3.0/include/c++/5.3.0/cmath:853:5: note: 'template<class _Tp> typename __gnu_cxx::__enable_if<std::__is_arithmetic<_Tp>::__value, int>::__type std::isinf(_Tp)' declared here, later in the translation unit; isinf(_Tp __f); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/utils.h:4:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/LoadTimeInitializer.cc:1:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h: In instantiation of 'static NUMBER Con",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343:11388,depend,dependent,11388,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343,1,['depend'],['dependent']
Integrability,re are dumps like this. ```; org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markPairedEnds$66146993$1(MarkDuplicatesSparkUtils.java:182); org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils$$Lambda$51/84990817.call(Unknown Source); org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$1$1.apply(JavaRDDLike.scala:126); org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$1$1.apply(JavaRDDLike.scala:126); scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371); scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327); scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388); scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:388); scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327); scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327); scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327); scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:29); org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.lambda$apply$26a6df3e$1(BaseRecalibratorSparkFn.java:27); org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn$$Lambda$65/1110390847.call(Unknown Source); ```. and . ```; org.broadinstitute.hellbender.engine.filters.ReadFilter.lambda$and$cbfb947b$1(ReadFilter.java:31); org.broadinstitute.hellbender.engine.filters.ReadFilter$$Lambda$33/1797796358.test(Unknown Source); org.broadinstitute.hellbender.engine.filters.ReadFilter.lambda$and$cbfb947b$1(ReadFilter.java:31); org.broadinstitute.hellbender.engine.filters.ReadFilter$$Lambda$33/1797796358.test(Unknown Source); org.broadinstitute.hellbender.engine.filters.ReadFilter.lambda$and$cbfb947b$1(ReadFilter.java:31); org.broadinstitute.hellbender.engine.filters.ReadFilter$$Lambda$33/1797796358.test(Unknown Source); org.broadinstitute.hellbender.engine.filters.ReadFilter.lambda$and$cbfb947b$1(ReadFilter.java:31); org.broadinst,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1657#issuecomment-203742647:2186,Wrap,Wrappers,2186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1657#issuecomment-203742647,1,['Wrap'],['Wrappers']
Integrability,"re falling back on Java implementations (e.g., AVX PairHMM tests). We need to determine the dependencies for these tests and install them separately. Here is the list of packages that get pulled in by the R install: ```autoconf automake autotools-dev binutils bsdmainutils build-essential; bzip2-doc cdbs cpp cpp-5 debhelper dh-strip-nondeterminism dh-translations; dpkg-dev fakeroot g++ g++-5 gcc gcc-5 gettext gettext-base gfortran; gfortran-5 groff-base ifupdown intltool intltool-debian iproute2; isc-dhcp-client isc-dhcp-common libalgorithm-diff-perl; libalgorithm-diff-xs-perl libalgorithm-merge-perl libarchive-zip-perl; libasan2 libasprintf-dev libasprintf0v5 libatm1 libatomic1; libauthen-sasl-perl libblas-common libblas-dev libblas3 libbz2-dev; libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libcroco3 libcurl3; libdns-export162 libdpkg-perl libencode-locale-perl libfakeroot; libfile-basedir-perl libfile-desktopentry-perl libfile-fcntllock-perl; libfile-listing-perl libfile-mimeinfo-perl libfile-stripnondeterminism-perl; libfont-afm-perl libfontenc1 libgcc-5-dev libgdbm3 libgettextpo-dev; libgettextpo0 libgfortran-5-dev libgfortran3 libgomp1 libhtml-form-perl; libhtml-format-perl libhtml-parser-perl libhtml-tagset-perl; libhtml-tree-perl libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl; libhttp-message-perl libhttp-negotiate-perl libio-html-perl; libio-socket-ssl-perl libipc-system-simple-perl libisc-export160 libisl15; libitm1 libjpeg-dev libjpeg-turbo8-dev libjpeg8-dev liblapack-dev liblapack3; liblsan0 liblwp-mediatypes-perl liblwp-protocol-https-perl liblzma-dev; libmail-sendmail-perl libmailtools-perl libmnl0 libmpc3 libmpfr4 libmpx0; libncurses5-dev libnet-dbus-perl libnet-http-perl libnet-smtp-ssl-perl; libnet-ssleay-perl libpaper-utils libpaper1 libpcre16-3 libpcre3-dev; libpcre32-3 libpcrecpp0v5 libperl5.22 libpipeline1 libpng12-dev libquadmath0; libreadline-dev libreadline6-dev libsigsegv2 libstdc++-5-dev; libsys-hostname-long-perl libtcl8.6 libtext-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954:2308,message,message-perl,2308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954,3,"['mediat', 'message', 'protocol']","['mediatypes-perl', 'message-perl', 'protocol-https-perl']"
Integrability,"reInput, and FeatureManager.; > ; > FeatureContext: This is tool-facing interface (replaces; > RefMetaDataTracker).; > Allows particular sources of Features to be queried.; > ; > FeatureDataSource: Handles the low-level details of querying a source of; > Features.; > Uses a caching scheme optimized for the use case of queries over; > intervals with gradually increasing start/stop positions.; > ; > FeatureInput: This is used to declared Feature arguments in tools; > (replaces RodBinding).; > The engine discovers all FeatureInput arguments declared in the tool's; > class; > hierarchy, and initializes data sources for each one that was specified; > on the command line.; > ; > FeatureManager: Manages the pool of data sources, as well as codec and; > file format; > discovery and type checking.; > ; > -ReadWalker interface has changed: apply() now takes a FeatureContext; > argument; > (will be null if there are no sources of Features).; > ; > -Included an example tool PrintReadsWithVariants to demonstrate use of the; > new; > ReadWalker interface.; > ; > -Since Feature files must be indexed in order to query them, I have; > provided a; > tool IndexFeatureFile that can index any Feature-containing file.; > ; > -Made required changes to the argument-parsing system. Feature argument; > discovery; > is as de-coupled as possible from the main arg parser.; > ; > -Made required changes to BQSR, and eliminated the temporary; > HACKRefMetaDataTracker.; > ; > ## -Comprehensive tests; > ; > You can view, comment on, or merge this pull request online at:; > ; > https://github.com/broadinstitute/hellbender/pull/224; > Commit Summary; > - Feature support: stripped-down replacement for the old GATK ROD; > system; > ; > File Changes; > - _M_; > src/main/java/org/broadinstitute/hellbender/cmdline/ClassFinder.java; > https://github.com/broadinstitute/hellbender/pull/224/files#diff-0; > (18); > - _M_; > src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineParser.java; > https://gi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/224#issuecomment-75657392:1419,interface,interface,1419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/224#issuecomment-75657392,1,['interface'],['interface']
Integrability,read name mangling should use `replaceAll` instead of `replace`. Discovered in the process of creating test data for more comprehensive SV integration tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5107:139,integrat,integration,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5107,1,['integrat'],['integration']
Integrability,"rect.github.com/protocolbuffers/protobuf/issues/18375"">#18375</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/8a60b6527a976cfd0028153da3ad8e4ed280e0de""><code>8a60b65</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.23.4...v3.25.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:2743,depend,dependabot-security-updates,2743,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,1,['depend'],['dependabot-security-updates']
Integrability,"ree reads. For other; mutations, maybe there's less than 10 reads corresponding to less than 10; cells, and it can vary pretty dramatically. The total number of cells; represented in a single sample can be thousands to tens of thousands,; usually - but could be many more as the tech advances. My hack for it at the moment is to encode both the cell barcode and the UMI; information into the read name. Then, for each variant, I query the reads; that overlap that variant in the bam file and analyze each read for; supporting the variant or the REF allele - then I can count the reads; according to the specific cells and also deal with any UMI redundancy per; cell. This works pretty well except for the cases where the HC reassembly; provides evidence for the variant and I can't track it to the originally; aligned reads. Also, mostly I think the difficulty here relates to indels; around homopolymers with our pacbio long isoform reads in our rna-seq; variant pipeline that leverages the gatk rna-seq protocol with HC. On Thu, Feb 29, 2024 at 8:58 AM Gökalp Çelik ***@***.***>; wrote:. > Since each cell has a barcode wouldn't it be nice to use them as their; > Read Group ID and Sample Name within the BAM so that variant callers will; > distinguish each cell from their Sample Name and produce a multisample VCF; > for that variant site. Once IDs and Sample Names are split per cell you may; > be able to color them differently in IGV to even visually observe those; > events.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971203108>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABZRKX6LYHUXDUMGDU3AIFLYV4ZZLAVCNFSM6AAAAABD4OZKJ6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSNZRGIYDGMJQHA>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971223953:1982,Message,Message,1982,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971223953,1,['Message'],['Message']
Integrability,ree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...bender/tools/spark/pathseq/PathSeqFilterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFGaWx0ZXJTcGFyay5qYXZh) | `70.968% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/spark/pathseq/PSFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyLmphdmE=) | `92.617% <100%> (+0.531%)` | `33 <1> (+1)` | :arrow_up: |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <100%> (+1.429%)` | `2 <0> (ø)` | :arrow_down: |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <92.857%> (ø)` | `12 <12> (?)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <94.286%> (ø)` | `11 <11> (?)` | |; | [...nstitute/hellbender/utils/clipping/ClippingOp.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jbGlwcGluZy9DbGlwcGluZ09wLmphdmE=) | `84.365% <0%> (+1.629%)` | `91% <0%> (+2%)` | :arrow_up: |; | [...stitute/hellbender/utils/clipping/ReadClipper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310:1867,Adapter,AdapterTrimTransformer,1867,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310,1,['Adapter'],['AdapterTrimTransformer']
Integrability,"refactoring our SmithWaterman code to prepare us for using native code optimized aligners. * Adding new interfaces `SmithWatermanAligner` and `SmithWatermanAlignment`.; * Refactoring `SWPairwiseAlignment` to be a `SmithWatermanAligner`, renaming it to SmithWatermanJavaAligner to distinguish it from future native aligners.; * Refactoring and renaming`SWPairwiseAlignmentUnitTest` and abstracting a superclass `SmithWatermanAlignerAbstractUnitTest` ; * Creating `SWNativeAlignerWrapper` which can accept a `SWAlignerNativeBinding` and wrap it into a `SmithWatermanAligner` as well as a test for it; * adding an option to `AssemblyBasedCallerArgumentCollection` which allows the aligner to be specified, currently we only have 1 real option; * adding an aligner as a field to Mutect2 and HaplotypeCaller, updating all library calls that use alignment to accept an aligner as an argument",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3600:104,interface,interfaces,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3600,2,"['interface', 'wrap']","['interfaces', 'wrap']"
Integrability,refetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.net.UnknownHostException: www.googleapis.com; 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:668); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shade,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094:6864,protocol,protocol,6864,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094,1,['protocol'],['protocol']
Integrability,remove Dataflow dependency,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/954:16,depend,dependency,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/954,1,['depend'],['dependency']
Integrability,remove direct spark dependency and use ML lib,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2035:20,depend,dependency,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2035,1,['depend'],['dependency']
Integrability,remove fastutil as a direct dependency,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1120:28,depend,dependency,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1120,1,['depend'],['dependency']
Integrability,removing 'help wanted' because code is not visible outside and integration tests use internal data.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/246#issuecomment-94342121:63,integrat,integration,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/246#issuecomment-94342121,1,['integrat'],['integration']
Integrability,removing GenomicsDB dependencies from travis.yml,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2257:20,depend,dependencies,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2257,1,['depend'],['dependencies']
Integrability,removing all google genomics API dependencies,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4266:33,depend,dependencies,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4266,1,['depend'],['dependencies']
Integrability,removing an unused interface that was carried over from GATK3; removing check for file subtypes that is also no longer relevant,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4542:19,interface,interface,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4542,1,['interface'],['interface']
Integrability,removing coveralls dependency from buildscript,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3699:19,depend,dependency,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3699,1,['depend'],['dependency']
Integrability,removing hamcrest and junit test dependencies; these were necessary for dataflow tests but are no longer used,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4315:33,depend,dependencies,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4315,1,['depend'],['dependencies']
Integrability,"removing redundant builds:; we will now have:; openJDK builds for cloud, integration, and unit tests; docker builds for integration and unit tests; an oracleJDK build for integration tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2770:73,integrat,integration,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2770,3,['integrat'],['integration']
Integrability,removing spark dataflow dependency,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1023:24,depend,dependency,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1023,1,['depend'],['dependency']
Integrability,removing the non-docker unit and integration test matrix entries because; they were redundant with the docker ones,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2804:33,integrat,integration,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2804,1,['integrat'],['integration']
Integrability,removing the unused dependency 'com.github.wendykierp:JTransforms:3.1',MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4950:20,depend,dependency,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4950,1,['depend'],['dependency']
Integrability,removing unecessary test dependencies,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4315:25,depend,dependencies,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4315,1,['depend'],['dependencies']
Integrability,removing unimplemented interface FileExtension,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4542:23,interface,interface,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4542,1,['interface'],['interface']
Integrability,rename integration tests to use IntegrationTest in name,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/191:7,integrat,integration,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/191,2,"['Integrat', 'integrat']","['IntegrationTest', 'integration']"
Integrability,requirement: existing integration tests (CollectInsertSizeMetricsTest) need to produce identical results,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/391#issuecomment-94331760:22,integrat,integration,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/391#issuecomment-94331760,1,['integrat'],['integration']
Integrability,"res (#7735); - Add withdrawn and is_control columns [VS-70] [VS-213] (#7736); - Allow interval lists that require the SA to see (#7743); - allow for gatk to be overridden, update with known good jar (#7758); - VS-361 Add GvsWithdrawSamples wdl (#7765); - Extract Performance Improvements (#7686); - Don't put withdrawn sample data in alt_allele table [VS-369] (#7762); - remove PET code (#7768); - Adding AD for scale testing VS 225 add AD (#7713); - Deterministic Sample ID assignments [VS-371] (#7770); - remove R scripts from filtering (#7781); - Remove an old ""temp table"" dataset (#7780); - Clean up LocalizeFile [VS-314] (#7771); - Remove pet code from CreateVariantIngestFiles and friends [VS-375] (#7773); - 317 remove excess header values in VCF extract (#7786); - correct auth in split intervals (#7790); - Add code to (optionally) zero pad the vcf filename. (#7783); - LoadData `maxRetries` parameterized, default increased [VS-383] (#7791); - Update to latest version of ah_var_store gatk override jar (#7793); - GvsUnified WDL to wrap the 6 core GVS WDLs [VS-382] (#7789); - Pinned typing_extensions python package to 4.1.1 to fix conda environment. (#7802); - WeightedSplitInterval fixes [VS-384] [VS-332] (#7795); - Replace Travis with GithubActions (#7754); - Docker build only lfs pulls main/src/resources/large (#7727); - Clean up gatk jars -- looks like we are not passing them properly in the extract (#7788); - Fix typo that broke git lfs pull (#7806); - Document AoU SOP (up to the VAT) [VS-63] (#7807); - Incident VS 365 clinvar classification fix (#7769); - VS-390. Add precision and sensitivity wdl (#7813); - Quickstart based integration test [VS-357] (#7812); - 365 vat python testing additions (#7756); - VS 396 clinvar grabs too many values (#7823); - Added a test to validate WDLs in the scripts directory. (#7826) (#7829); - VAT Performance / Reliability Improvements (#7828); - VAT naming conventions [VS-410] (#7827); - Rc remove ad from vat (#7832); - bugfix, we were",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:23188,wrap,wrap,23188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['wrap'],['wrap']
Integrability,return more useful error messages from RScriptExecutor,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/223:25,message,messages,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/223,1,['message'],['messages']
Integrability,rg.broadinstitute.hellbender.utils.GenomeLocParser.createGenomeLoc(GenomeLocParser.java:185); at org.broadinstitute.hellbender.utils.GenomeLocParser.createGenomeLoc(GenomeLocParser.java:169); at org.broadinstitute.hellbender.utils.GenomeLocParser.createGenomeLoc(GenomeLocParser.java:150); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager$SplitRead.setRead(OverhangFixingManager.java:402); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager$SplitRead.<init>(OverhangFixingManager.java:396); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.getSplitRead(OverhangFixingManager.java:467); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Collections$2.tryAdvance(Collections.java:4717); at java.util.Collections$2.forEachRemaining(Collections.java:4725); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.addReadGroup(OverhangFixingManager.java:207); at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.splitNCigarRead(SplitNCigarReads.java:259); at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.firstPassApply(SplitNCigarReads.java:180); at org.broadinstitute.hellbender.engine.TwoPassReadWalker.lambda$traverseReads$0(TwoPassReadWalker.java:62); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(Refe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5293:3298,wrap,wrapAndCopyInto,3298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5293,1,['wrap'],['wrapAndCopyInto']
Integrability,"rg.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I understand that you never see this warning, could you confirm/deny that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/609:3618,depend,dependency,3618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609,1,['depend'],['dependency']
Integrability,riateList.recordAllValuesInStorage(StandardCovariateList.java:133); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:546); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:527); 	at org.broadinstitute.hellbender.transformers.BQSRReadTransformer.apply(BQSRReadTransformer.java:145); 	at org.broadinstitute.hellbender.transformers.BQSRReadTransformer.apply(BQSRReadTransformer.java:27); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellb,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6242#issuecomment-592005237:8987,wrap,wrapAndCopyInto,8987,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6242#issuecomment-592005237,1,['wrap'],['wrapAndCopyInto']
Integrability,ribble.readers.LongLineBufferedReader.readLine(LongLineBufferedReader.java:356); at htsjdk.tribble.readers.SynchronousLineReader.readLine(SynchronousLineReader.java:51); at htsjdk.tribble.readers.LineIteratorImpl.advance(LineIteratorImpl.java:24); at htsjdk.tribble.readers.LineIteratorImpl.advance(LineIteratorImpl.java:11); at htsjdk.samtools.util.AbstractIterator.next(AbstractIterator.java:57); at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:70); at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:37); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:181); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:49); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-575277936:2372,wrap,wrapAndCopyInto,2372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-575277936,1,['wrap'],['wrapAndCopyInto']
Integrability,"ributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterIn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1281,wrap,wrapper,1281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,"rimVariants - 0 variants left aligned; 12:55:32.542 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 6, 2018 12:55:32 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=249036800; ```; Multiple changes to messages in stdout. Includes # total records, number of records that were trimmed, # variant records skipped due to ref allele being too long and finally the max-indel-length value that needs to be set to include these in the leftalignandtrim. This is an improvement to previous stdout messaging. Upping max-indel-length; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 2:03:44 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/au",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:6335,wrap,wrapper,6335,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326,1,['wrap'],['wrapper']
Integrability,rk.SparkSharder$5.computeNext(SparkSharder.java:293); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder$5.computeNext(SparkSharder.java:281); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.TransformedIterator.hasNext(TransformedIterator.java:43); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$5.hasNext(Iterators.java:547); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$5.hasNext(Iterators.java:547); 	at org.broadinstitute.hellbender.utils.iterators.PushTo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994:1486,Wrap,WrappingSpliterator,1486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994,1,['Wrap'],['WrappingSpliterator']
Integrability,rk.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: org.broadinstitute.hellbender.exceptions.GATKException: Erred when inferring breakpoint location and event type from chimeric alignment:; asm010450:tig00000 1_189_chrUn_JTFH01000312v1_decoy:663-851_-_189M512H_60_8_149_O 153_701_chrUn_JTFH01000312v1_decoy:1-549_+_152S549M_60_0_549_O; at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:51); at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$null$0(DiscoverVariantsFromContigAlignmentsSAMSpark.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.sc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:12477,Wrap,WrappingSpliterator,12477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['Wrap'],['WrappingSpliterator']
Integrability,"rk.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.TaskSetManager: Task 284 in stage 25.0 failed 4 times; aborting job; 18/01/12 20:38:37 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@23007ed{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(50,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(52,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(34,WrappedArray()); 18/01/12 20:38:37 ERROR org.apache.spark.scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(60,WrappedArray()); 20:38:37.897 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [January 12, 2018 8:38:37 PM UTC] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 42.74 minutes.; Runtime.totalMemory()=16692805632; org.apache.spark.SparkException: Job aborted due to stage failure: Task 284 in stage 25.0 failed 4 times, most recent failure: Lost task 284.3 in stage 25.0 (TID 43224, cw-test-w-6.c.broad-dsde-methods.internal, executor 7): java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Uti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:5709,Wrap,WrappedArray,5709,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['Wrap'],['WrappedArray']
Integrability,"rk/bwa/BwaSpark.java#L47) launches `BwaSparkEngine` as follows:. ```; final BwaSparkEngine engine = new BwaSparkEngine(bwaArgs.numThreads, bwaArgs.fixedChunkSize, referenceFileName);; ```. and launches the alignment as follows:. ```; final JavaRDD<GATKRead> reads = engine.alignWithBWA(ctx, unalignedReads, readsHeader);; ```. That in turn calls the `align()` method within [BwaSparkEngine.java](https://github.com/broadinstitute/gatk/blob/9fb4d756afbbad58a7e709e2e9fd308983ad255b/src/main/java/org/broadinstitute/hellbender/tools/spark/bwa/BwaSparkEngine.java#L72):. ```; final JavaRDD<String> samLines = align(shortReadPairs);; ```. which then instantiates a new [BwaMem](https://github.com/broadinstitute/gatk/blob/9fb4d756afbbad58a7e709e2e9fd308983ad255b/src/main/java/org/broadinstitute/hellbender/tools/spark/bwa/BwaSparkEngine.java#L101) object:. ```; final BwaMem mem = new BwaMem(index);; ```. Since the BWA implementation at [lindenb/jbwa](https://github.com/lindenb/jbwa) is basically a direct call to Heng's BWA as a library, the BWA option for verbosity is set by the `-v` argument as noted [here](http://bio-bwa.sourceforge.net/bwa.shtml#3):. ```; -v INT Control the verbose level of the output. This option has not been fully supported ; throughout BWA. Ideally, a value 0 for disabling all the output to stderr; 1 for ; outputting errors only; 2 for warnings and errors; 3 for all normal messages; 4 or ; higher for debugging. When this option takes value 4, the output is not SAM. [3] ; ```. This is used in Heng's [bwamem.c](https://github.com/lh3/bwa/blob/5961611c358e480110793bbf241523a3cfac049b/bwamem.c#L1224-L1226) file - and several other places - which generates the printout you see, as follows:. ```; if (bwa_verbose >= 3); fprintf(stderr, ""[M::%s] Processed %d reads in %.3f CPU sec, %.3f real sec\n"", __func__, n, cputime() - ctime, realtime() - rtime);; }; ```. So I would just adjust the verbosity via the arguments to the level that is preferable. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2054#issuecomment-235675398:1628,message,messages,1628,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2054#issuecomment-235675398,1,['message'],['messages']
Integrability,"rnal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results for any of the other affected classes listed above. . #### Expected behavior; I expect unit tests to pass or fail whether or not they are run as a group or individually. . #### Actual behavior; Unit test results are different depending on if the test classes are run as a large group or individually.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:7487,depend,depending,7487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,1,['depend'],['depending']
Integrability,roadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:266); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.makeAnnotatedCall(HaplotypeCallerGenotypingEngine.java:298); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:148); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:566); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:253); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark$$Lambda$312.00000000EC650830.apply(Unknown Source); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:278); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1823); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:305); at java.util.stream.StreamSpliterators$WrappingSpliterator$$Lambda$314.00000000EC651070.getAsBoolean(Unknown Source); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:217); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:180); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:311); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:692); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948); at org.apache.spark.storage.BlockManager.doPut(Bl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4265:1618,Wrap,WrappingSpliterator,1618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4265,1,['Wrap'],['WrappingSpliterator']
Integrability,roadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.makeAnnotatedCall(HaplotypeCallerGenotypingEngine.java:298); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:148); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:566); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:253); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark$$Lambda$312.00000000EC650830.apply(Unknown Source); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:278); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1823); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:305); at java.util.stream.StreamSpliterators$WrappingSpliterator$$Lambda$314.00000000EC651070.getAsBoolean(Unknown Source); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:217); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:180); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:311); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:692); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948); at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:888); at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:948); at org.apache.spark.storage,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4265:1742,Wrap,WrappingSpliterator,1742,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4265,1,['Wrap'],['WrappingSpliterator']
Integrability,"roadinstitute.hellbender.tools.walkers.variantutils...; 2022-08-16T22:45:53.6079174Z Constructing Javadoc information...; 2022-08-16T22:45:53.6079564Z [search path for source files: src/main/java]; 2022-08-16T22:45:53.6082788Z [search path for class files: /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/classes,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/zipfs.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/dnsns.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/sunjce_provider.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/icedtea-sound.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/nashorn.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/java-atk-wrapper.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/sunec.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/sunpkcs11.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/cldrdata.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/jaccess.jar,/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext/localedata.jar,/gatk/gatk-package-unspecified-SNAPSHOT-local.jar,/jars/gatk-package-4.2.6.1-50-g40182c7-SNAPSHOT-testDependencies.jar,/jars/gatk-package-4.2.6.1-50-g40182c7-SNAPSHOT-test.jar]; 2022-08-16T22:45:53.6382333Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.6383952Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:4: error: package com.google.common.base does not exist; 2022-08-16T22:45:53.6523417Z src/main/java/org/broadinstitute/hellbender/engine/FeatureInput.java:3: error: package com.google.common.annotations does not exist",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:1531,wrap,wrapper,1531,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['wrap'],['wrapper']
Integrability,roxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); [TileDB::FileSystem] Error: hdfs: Error getting hdfs connection; [TileDB::StorageManagerConfig] Error: Error getting hdfs connection: Connection refused.; Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest > testWriteToAndQueryFromGCS FAILED; java.io.IOException: GenomicsDB JNI Error: VCFAdapterException : Could not copy contents of VCF header filename gs:/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6522:6875,Message,MessageHub,6875,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6522,1,['Message'],['MessageHub']
Integrability,"roxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 5.0 failed 1 times, most recent failure: Lost task 1.0 in stage 5.0 (TID 12, localhost, executor driver): java.util.ConcurrentModificationException; 	at java.util.ArrayList.sort(ArrayList.java:1464); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.<init>(ReadThreadingAssembler.java:81); 	at org.broadinstitute.hellb",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:7284,Message,MessageHub,7284,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['Message'],['MessageHub']
Integrability,"roxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an I",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:5593,Message,MessageHub,5593,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,1,['Message'],['MessageHub']
Integrability,"rror: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scratch space available for temporary directory and around 500GB of storage space available to hold outputs of GenomicsDBImport outputs. #### Actual behavior; Above error message indicating that disk quota has exceeded. I'm not exactly sure what's going on here as I am directing the outputs of the GenomicsDBImport runs to directories with more than enough storage space and yet it seems to fail. Any help will be greatly appreciated. Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6950:2831,message,message,2831,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950,1,['message'],['message']
Integrability,rrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:68); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:66); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:984); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:2979,wrap,wrapAndCopyInto,2979,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887,1,['wrap'],['wrapAndCopyInto']
Integrability,rrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098:7425,wrap,wrapAndCopyInto,7425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098,2,['wrap'],['wrapAndCopyInto']
Integrability,rs.rnaseq.OverhangFixingManager.addReadGroup(OverhangFixingManager.java:207); at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.splitNCigarRead(SplitNCigarReads.java:259); at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.firstPassApply(SplitNCigarReads.java:180); at org.broadinstitute.hellbender.engine.TwoPassReadWalker.lambda$traverseReads$0(TwoPassReadWalker.java:62); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.TwoPassReadWalker.traverseReads(TwoPassReadWalker.java:60); at org.broadinstitute.hellbender.engine.TwoPassReadWalker.traverse(TwoPassReadWalker.java:42); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5293:4598,wrap,wrapAndCopyInto,4598,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5293,1,['wrap'],['wrapAndCopyInto']
Integrability,rtingAction.execute(ExceptionReportingAction.java:22); at org.gradle.launcher.Main.doAction(Main.java:33); at org.gradle.launcher.bootstrap.EntryPoint.run(EntryPoint.java:45); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54); at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35); at org.gradle.launcher.GradleMain.main(GradleMain.java:23); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:129); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: org.gradle.api.UncheckedIOException: java.io.IOException: Disk quota exceeded; at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:58); at org.gradle.cache.internal.btree.CachingBlockStore.close(CachingBlockStore.java:40); at org.gradle.cache.internal.btree.FreeListBlockStore.close(FreeListBlockStore.java:60); at org.gradle.cache.internal.btree.StateCheckBlockStore.close(StateCheckBlockStore.java:41); at org.gradle.cache.internal.btree.BTreePersistentIndexedCache.close(BTreePersistentIndexedCache.java:195); ... 60 more; Caused by: java.io.IOException: Disk quota exceeded; at java.io.RandomAccessFile.close0(Native Method); at java.io.RandomAccessFile.close(RandomAccessFile.java:645); at org.gradle.cache.internal.btree.FileBackedBlockSto,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:7165,wrap,wrapper,7165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,2,['wrap'],['wrapper']
Integrability,rtingAction.execute(ExceptionReportingAction.java:22); at org.gradle.launcher.Main.doAction(Main.java:33); at org.gradle.launcher.bootstrap.EntryPoint.run(EntryPoint.java:45); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54); at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35); at org.gradle.launcher.GradleMain.main(GradleMain.java:23); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:129); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: org.gradle.api.UncheckedIOException: java.io.IOException: Disk quota exceeded; at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:58); at org.gradle.cache.internal.btree.CachingBlockStore.close(CachingBlockStore.java:40); kStore.java:60); at org.gradle.cache.internal.btree.StateCheckBlockStore.close(StateCheckBlockStore.java:41); at org.gradle.cache.internal.btree.BTreePersistentIndexedCache.close(BTreePersistentIndexedCache.java:195); ... 64 more; Caused by: java.io.IOException: Disk quota exceeded; at java.io.RandomAccessFile.close0(Native Method); at java.io.RandomAccessFile.close(RandomAccessFile.java:645); at org.gradle.cache.internal.btree.FileBackedBlockStore.close(FileBackedBlockStore.java:56); ... 68 more. FAILURE: Build fail,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1364:21373,wrap,wrapper,21373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1364,1,['wrap'],['wrapper']
Integrability,"rtitions$1(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858); 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:56); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:56); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:56); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:331); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93); 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166); 	at org.apache.spark.scheduler.Task.run(Task.scala:141); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620); 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64); 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:93); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635); 	at java.base/java.lang.Thread.run(Thread.java:833); ``` . #### Steps to reproduce; Run HaplotypeCallerSpark multiple times, it had a chance to fail.; Looks like the method ensureCapacity of GenotypesCache is not synchronized. So when multiple task threads run into this method, the new added cache is not fully initialized. #### Expected behavior; spark tasks success. #### Actual behavior; spark tasks failed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8961:4874,synchroniz,synchronized,4874,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8961,1,['synchroniz'],['synchronized']
Integrability,"run `SelectVariants -select 'dbSNPBuildID=119'`. this blows up . ```; Invalid JEXL expression detected for select-0 with message ![0,18]: 'dbSNPBuildID = 119;' context is readonly; ```. which is a suboptimal message - it should point to a doc to JEXL. (btw the fix seems to be to use `==` not `=`)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1313:121,message,message,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1313,2,['message'],['message']
Integrability,running RevertBaseQualityScores from Version:4.alpha-70-g10d9ec1-SNAPSHOT on /seq/picard_aggregation/G77386/NA12878/v1/NA12878.bam. ```; java.lang.IllegalArgumentException: end must be >= start. start:13984870 end:13984869; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$18(ReadWalker.java:79); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$45/1492875057.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:78); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:448); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1473:1093,wrap,wrapAndCopyInto,1093,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1473,1,['wrap'],['wrapAndCopyInto']
Integrability,ryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:240); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:232); 	... 22 more; Caused by: java.net.SocketTimeoutException: connect timed out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:162); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:79); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:996); 	at shaded.cloud_nio.com.google.api.client.googlea,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:7196,protocol,protocol,7196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['protocol'],['protocol']
Integrability,"s - Starting pass 0 through the variants ; ; 11:03:51.014 INFO FilterMutectCalls - Shutting down engine ; ; \[June 4, 2021 11:03:51 AM CST\] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.19 minutes. ; ; Runtime.totalMemory()=625999872 ; ; java.lang.NumberFormatException: **For input string: ""167|35|14""** ; ; at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) ; ; at java.lang.Integer.parseInt(Integer.java:580) ; ; at java.lang.Integer.valueOf(Integer.java:766) ; ; at htsjdk.variant.variantcontext.CommonInfo.lambda$getAttributeAsIntList$1(CommonInfo.java:288) ; ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; ; at java.util.Collections$2.tryAdvance(Collections.java:4717) ; ; at java.util.Collections$2.forEachRemaining(Collections.java:4725) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; ; at htsjdk.variant.variantcontext.CommonInfo.getAttributeAsList(CommonInfo.java:274) ; ; at htsjdk.variant.variantcontext.CommonInfo.getAttributeAsIntList(CommonInfo.java:282) ; ; at htsjdk.variant.variantcontext.VariantContext.getAttributeAsIntList(VariantContext.java:827) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.DuplicatedAltReadFilter.areAllelesArtifacts(DuplicatedAltReadFilter.java:26) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.HardAlleleFilter.calculateErrorProbabilityForAlleles(HardAlleleFilter.java:16) ; ; at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2AlleleFilter.errorProbabilities(Mutect2AlleleFilter.java:86) ; ; at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7298:6484,wrap,wrapAndCopyInto,6484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7298,1,['wrap'],['wrapAndCopyInto']
Integrability,"s case with HaplotypeCallerSpark). Any idea on how to extend the size?. The errors are:. `org.broadinstitute.hellbender.exceptions.UserException: Max size of locatable exceeded. Max size is 5000, but locatable size is 8638. Try increasing shard size and/or padding. Locatable: Contig1:65711-74348; 	at org.broadinstitute.hellbender.engine.spark.SparkSharder$5.computeNext(SparkSharder.java:293); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder$5.computeNext(SparkSharder.java:281); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.TransformedIterator.hasNext(TransformedIterator.java:43); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$5.hasNext(Iterators.java:547); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994:1144,Wrap,WrappingSpliterator,1144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994,1,['Wrap'],['WrappingSpliterator']
Integrability,s in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3092731818.10](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004333411) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.10/tests/test/index.html) |; | cloud | 11 | [3092731818.11](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004333541) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.11/tests/test/index.html) |; | unit | 11 | [3092731818.13](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004333748) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.13/tests/test/index.html) |; | integration | 11 | [3092731818.12](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004333644) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.12/tests/test/index.html) |; | conda | 8 | [3092731818.3](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004627834) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.3/tests/test/index.html) |; | unit | 8 | [3092731818.1](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004627636) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.1/tests/test/index.html) |; | integration | 8 | [3092731818.0](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004627523) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.0/tests/test/index.html) |; | variantcalling | 8 | [3092731818.2](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004627749) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1252803679:1668,integrat,integration,1668,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1252803679,1,['integrat'],['integration']
Integrability,s in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3092905417.10](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004691605) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.10/tests/test/index.html) |; | cloud | 11 | [3092905417.11](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004691712) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.11/tests/test/index.html) |; | unit | 11 | [3092905417.13](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004691976) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.13/tests/test/index.html) |; | integration | 11 | [3092905417.12](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004691810) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.12/tests/test/index.html) |; | unit | 8 | [3092905417.1](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004926160) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.1/tests/test/index.html) |; | conda | 8 | [3092905417.3](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004926443) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.3/tests/test/index.html) |; | variantcalling | 8 | [3092905417.2](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004926310) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.2/tests/test/index.html) |; | integration | 8 | [3092905417.0](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004926053) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1252832367:1911,integrat,integration,1911,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1252832367,1,['integrat'],['integration']
Integrability,s in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3291375153.10](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425447220) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.10/tests/test/index.html) |; | cloud | 11 | [3291375153.11](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425447314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.11/tests/test/index.html) |; | unit | 11 | [3291375153.13](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425447526) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.13/tests/test/index.html) |; | integration | 11 | [3291375153.12](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425447422) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.12/tests/test/index.html) |; | unit | 8 | [3291375153.1](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425749385) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.1/tests/test/index.html) |; | conda | 8 | [3291375153.3](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425749598) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.3/tests/test/index.html) |; | variantcalling | 8 | [3291375153.2](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425749495) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.2/tests/test/index.html) |; | integration | 8 | [3291375153.0](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425749244) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1285871268:1911,integrat,integration,1911,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1285871268,1,['integrat'],['integration']
Integrability,s in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3300297321.10](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444638536) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.10/tests/test/index.html) |; | unit | 11 | [3300297321.13](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444638791) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.13/tests/test/index.html) |; | cloud | 11 | [3300297321.11](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444638641) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.11/tests/test/index.html) |; | conda | 8 | [3300297321.3](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444856356) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.3/tests/test/index.html) |; | integration | 11 | [3300297321.12](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444638712) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.12/tests/test/index.html) |; | unit | 8 | [3300297321.1](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444856205) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.1/tests/test/index.html) |; | variantcalling | 8 | [3300297321.2](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444856277) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.2/tests/test/index.html) |; | integration | 8 | [3300297321.0](https://github.com/broadinstitute/gatk/actions/runs/3300297321/jobs/5444856114) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300297321.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1287425480:1192,integrat,integration,1192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1287425480,2,['integrat'],['integration']
Integrability,s in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3300316784.10](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444679663) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.10/tests/test/index.html) |; | cloud | 11 | [3300316784.11](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444679780) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.11/tests/test/index.html) |; | unit | 11 | [3300316784.13](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444679952) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.13/tests/test/index.html) |; | integration | 11 | [3300316784.12](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444679868) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.12/tests/test/index.html) |; | conda | 8 | [3300316784.3](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444871971) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.3/tests/test/index.html) |; | unit | 8 | [3300316784.1](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444871800) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.1/tests/test/index.html) |; | variantcalling | 8 | [3300316784.2](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444871887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.2/tests/test/index.html) |; | integration | 8 | [3300316784.0](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444871682) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1287429116:1911,integrat,integration,1911,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1287429116,1,['integrat'],['integration']
Integrability,s specifically from the GCS access in `CloudStorageReadChannel.fetchSize()`:. ```; com.google.cloud.storage.StorageException: 503 Service Unavailable; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:202); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:234); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.<init>(CloudStorageReadChannel.java:78); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.create(CloudStorageReadChannel.java:68); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newReadChannel(CloudStorageFileSystemProvider.java:304); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newByteChannel(CloudStorageFileSystemProvider.java:265); at java.nio.file.Files.newByteChannel(Files.java:361); at java.nio.file.Files.newByteChannel(Files.java:407); at htsjdk.samtools.seekablestream.SeekablePathStream.<init>(SeekablePathStream.java:41); at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamFactory.getStreamFor(SeekableStreamFactory.java:101); at htsjdk.tribble.readers.TabixReader.readIndex(TabixReader.java:270). [2:58] ; From stdout:. [2:58] ; 15:55:58.059 INFO GenomicsDBImport - Done importing batch 19/444; 15:56:21.780 INFO GenomicsDBImport - Shutting down engine; code: 503; message: 503 Service Unavailable; reason: null; location: null; retryable: false; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253:2212,message,message,2212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253,1,['message'],['message']
Integrability,"s where results changed:. - For the snpeff test, since the behavior on this branch seems more correct to me than master, I tried running the GATK4 test case inputs with GATK3, and it produces exactly the same results as this branch does. So I think that issue was introduced by the original GATK4 port, and is fixed in this branch.; - The rest of the tests with changed results don't seem to hit your breakpoint, though. So I think we need to figure out why they changed, and maybe also compare them with GATK3 (which can be a pain because the output format is slightly different).; - As you mentioned, you changed the reference for testEvalTrackWithoutGenotypesWithSampleFields, which seems to have only affected the number of loci processed. So I'm unclear why that change was necessary. If the test truly should have been failing without this change, will it still fail if the change is reverted ? If not, can we fix it, and either way there should be a negative test for that case. A few other general comments:. - I changed this PR to `draft` mode for now, which just better categorizes it for our internal workflow purposes. When its ready for a detailed code review we can remove the `draft` status.; - The `HashMap<FeatureInput<VariantContext>, HashMap<String, Collection<VariantContext>>>` can be wrapped in a class with just a couple of methods, so we don't have to manifest that long type all over the place.; - I know this PR still in an interim state, but passing the VariantWalker in as an argument to the comp methods doesn't seem like a step forward to me. If we can't solve that problem completely in this PR (which is fine, I'm all for trying to contain this), are those changes necessary ? Perhaps that part should just wait for the next round.; - Any new classes/methods should use `final` for variables and parameters wherever applicable, and public classes and methods should have javadoc.; - Finally, I'm curious if you've tried any perf testing on this branch ? Is it better ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-744689987:1380,wrap,wrapped,1380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-744689987,1,['wrap'],['wrapped']
Integrability,"s.java:278); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:83); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:31); at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:78); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:382); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:183); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289). Nov 24, 2018 6:05:09 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.NoRouteToHostException: No route to host (Host unreachable); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.ww",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417:3773,rout,route,3773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417,2,['rout'],['route']
Integrability,s/498538890) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.4/tests/test/index.html) |; | unit | openjdk8 | [33752.3](https://travis-ci.com/broadinstitute/gatk/jobs/498538889) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.3/tests/test/index.html) |; | conda | openjdk8 | [33752.5](https://travis-ci.com/broadinstitute/gatk/jobs/498538891) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.5/tests/test/index.html) |; | integration | openjdk8 | [33752.2](https://travis-ci.com/broadinstitute/gatk/jobs/498538888) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.2/tests/test/index.html) |; | cloud | openjdk11 | [33752.14](https://travis-ci.com/broadinstitute/gatk/jobs/498538900) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.14/tests/test/index.html) |; | cloud | openjdk8 | [33752.1](https://travis-ci.com/broadinstitute/gatk/jobs/498538887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.1/tests/test/index.html) |; | unit | openjdk11 | [33752.13](https://travis-ci.com/broadinstitute/gatk/jobs/498538899) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.13/tests/test/index.html) |; | integration | openjdk11 | [33752.12](https://travis-ci.com/broadinstitute/gatk/jobs/498538898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.12/tests/test/index.html) |; | variantcalling | openjdk8 | [33752.4](https://travis-ci.com/broadinstitute/gatk/jobs/498538890) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.4/tests/test/index.html) |; | conda | openjdk8 | [33752.5](https://travis-ci.com/broadinstitute/gatk/jobs/498538891) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_33752.5/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234:2506,integrat,integration,2506,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-819750234,1,['integrat'],['integration']
Integrability,s/coveragemodel/learning_sample_bias_latent.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_read_depth.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/learning_sample_sex_genotypes.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_contig_anots.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_HMM_priors_table.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/mean_bias_covariates_matrix.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_mean_log_bias.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_model/target_specific_unexplained_variance.tsv; src/test/resources/org/broadinstitute/hellbender/tools/coveragemodel/sim_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/acnv-segments-from-allelic-integration.seg; src/test/resources/org/broadinstitute/hellbender/tools/exome/af-params-from-allelic-integration.af.param; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-1.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-2.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-3.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/allelic-pon-test-pulldown-4.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/dupReadsMini.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12778.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12872.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/exome/calculatetargetcoverage/exome-read-counts-NA12878.bam,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:29037,integrat,integration,29037,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['integrat'],['integration']
Integrability,"sDBImport: ; `java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms2G -Xmx20G -XX:+UseParallelGC -XX:ParallelGCThreads=2 -jar MySoftwares/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenomicsDBImport --genomicsdb-workspace-path 007_Database_DBImport_VCFref/database_interval_9 --sample-name-map sample_name_map --intervals 006_IntervalsSplit_DBImport_VCFref/interval_9.list --reader-threads 5 --batch-size 60 --tmp-dir TMPDIR --max-num-intervals-to-import-in-parallel 3 --merge-input-intervals`. GenotypeGVCFs:; `java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms4G -Xmx16G -XX:+UseParallelGC -XX:ParallelGCThreads=2 -jar MySoftwares/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenotypeGVCFs -R PigeonBatch5/000_DataLinks/000_RefSeq/Cliv2.1_genomic.fasta --intervals 006_IntervalsSplit_DBImport_VCFref/interval_9.list --force-output-intervals PigeonBatch4/008_RawVcfGz/MergeVcf/pigeonBatch1234_filtered.vcf.gz -V gendb://007_Database_DBImport_VCFref/database_interval_9 -O 008_RawVcfGz_DBImport_VCFref/001_DividedIntervals/interval_9.vcf.gz --tmp-dir TMPDIR --allow-old-rms-mapping-quality-annotation-data --only-output-calls-starting-in-intervals --verbosity ERROR`. #### **User Description of the Issue:**; ""I'm using the GenotypeGVCFs function based on GenomicsDBImport database. I've divided the reference into 50 intervals. Some intervals seems ok, but some reports error as following. I used a VCF file in ""--force-output-intervals"" for down stream analysis. I've never seen this error without ""--force-output-intervals"". I've searched for the error message and changed my GATK version to 4.2.6.1 since similar error has been solved as a bug in recent update, but it still not works on my dataset..."". @droazen and @samuelklee , any insight on this?. Thank you,. Anthony",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7938:5348,message,message,5348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7938,1,['message'],['message']
Integrability,"se reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:51); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:77); at org.broadinstitute.hellbender.Main.main(Main.java:92); ```. Same command on original picard passes validation (though claims the bam is different from itself: https://github.com/broadinstitute/picard/issues/160). Note to whoever fixes this: once this is fixed, re-enable code in BaseRecalibratorIntegrationTest.java. ```; //IntegrationTestSpec.compareBamFiles(actualHiSeqBam_recalibrated, expectedHiSeqBam_recalibrated);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/419:2419,Integrat,IntegrationTestSpec,2419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419,1,['Integrat'],['IntegrationTestSpec']
Integrability,sed by: java.net.UnknownHostException: www.googleapis.com; 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:668); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:6133); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:505); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094:7439,protocol,protocol,7439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094,1,['protocol'],['protocol']
Integrability,"seq.bam""). samples = pd.DataFrame.from_dict({""patient"": [""ATCC25586"", ""SL1344"", ""LT2"", ""ATCC25586"", ""SL1344"", ""LT2""], ""sample"": [""1"", ""1"", ""1"", ""2"", ""2"", ""2""]}). localrules: simulate_RNAseq_reads, download_ATCC25586_cds_from_genomic, download_LT2_cds_from_genomic, download_SL1344_cds_from_genomic. rule all:; input:; expand(output/{patient}-{sample}/unaligned_simulated_bam.bam, zip, sample=samples[""sample""], patient=samples[""patient""]); # run this bam file through PathSeq. rule convert_FASTA_to_BAM:; input:; fq1=FQ1,; output:; output/{patient}-{sample}/unaligned_simulated_bam.bam; shell:; ""module load picard && ""; ""java -Xmx8g -XX:ParallelGCThreads=5 -jar $PICARDJARPATH/picard.jar ""; ""FastqToSam F1={input.fq1} O={output} ""; ""SM={wildcards.sample} RG={wildcards.sample} ""; ""TMP_DIR=/lscratch/$SLURM_JOBID"". rule simulate_RNAseq_reads:; conda:; ""../envs/rsubread-env.yaml""; params:; FQ1_PREFIX; input:; CDS_FA; output:; FQ1; script:; ""R/simulate_RNAseq.R"". # download the cds_from_genomic fasta file; rule download_SL1344_cds_from_genomic:; params:; url=SL1344_CDS_URL; output:; SL1344_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}"". rule download_LT2_cds_from_genomic:; params:; url=LT2_CDS_URL; output:; LT2_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}"". rule download_ATCC25586_cds_from_genomic:; params:; url=ATCC25586_CDS_URL; output:; ATCC25586_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}""; ```; rsubread-env.yaml; ```; name: rsubread; channels:; - conda-forge; - bioconda; - defaults; dependencies:; - bioconductor-rsubread; - bioconductor-biostrings; ```; simulate_RNAseq.R; ```; library(Rsubread); library(Biostrings); set.seed(strtoi(snakemake@wildcards[[""sample""]])). fasta = readDNAStringSet(snakemake@input[[1]]). expr = matrix(1, ncol=1, nrow=length(fasta)). simReads(transcript.file=snakemake@input[[1]], expression.levels=expr,; output.prefix=snakemake@params[[1]], library.size=100000, simulate.sequencing.error=TRUE); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6705:4341,depend,dependencies,4341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705,1,['depend'],['dependencies']
Integrability,"serialization/spec/class.html#a4100):. _If not specified by the class, the value returned is a hash computed from the class's name, interfaces, methods, and fields using the Secure Hash Algorithm (SHA) as defined by the National Institute of Standards._. Now when I look at the `java.io.ObjectStreamClass.java` file for 64-bit JDK7 and JDK8 - from src.zip - both have the same code for the following parts after performing a `diff` - I didn't list all of the lines of code since they are quite long:. ```; public long getSerialVersionUID() {; // REMIND: synchronize instead of relying on volatile?; if (suid == null) {; suid = AccessController.doPrivileged(; new PrivilegedAction<Long>() {; public Long run() {; return computeDefaultSUID(cl);; }; }; );; }; return suid.longValue();; }; ... private static long computeDefaultSUID(Class<?> cl) {; ...very long code which can be inspected via the src.zip file...; }; ```. So looking at the code portions of `computeDefaultSUID()` and I notice in our instance `ReadFilter` is a interface, which gets defined later via [ReadFilterLibrary.java](https://github.com/broadinstitute/hellbender/blob/62ef76ba60951c562a0d4c39189aa3f01f27f8d3/src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilterLibrary.java) or via `new ReadsFilter(readFilter, header)`, in either of these instances the fields would be different, based on this portion of `computeDefaultSUID` when looking at declared fields:. ```; Field[] fields = cl.getDeclaredFields();; MemberSignature[] fieldSigs = new MemberSignature[fields.length];; for (int i = 0; i < fields.length; i++) {; fieldSigs[i] = new MemberSignature(fields[i]);; }; ```. Therefore the `SUID` would be different based on the fields it would have. Please let me know if I misinterpreted something. @jean-philippe-martin I would be happy to help out, but even when I try a small test like this I get an error - I probably am performing something incorrectly. Below are the steps I performed using the codebase fro",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107730499:1333,interface,interface,1333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107730499,1,['interface'],['interface']
Integrability,"ses where applicable; 15:24:12.735 INFO ReadsSparkSink - Finished sorting the bam file and dumping read shards to disk, proceeding to merge the shards into a single file using the master thread; 15:41:27.766 INFO ReadsSparkSink - Finished merging shards into a single output bam; 15:41:34.351 INFO MarkDuplicatesSpark - Shutting down engine; [May 7, 2018 3:41:34 PM EDT] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 61.21 minutes.; Runtime.totalMemory()=13635682304; ```. With native libraries (note the lack of the usual warning):. ```; $ ${GATK_DIR}/gatk MarkDuplicatesSpark --java-options ""-Djava.library.path=${HADOOP_DIR}/hadoop-2.6.5-src/hadoop-common-project/hadoop-common/target/hadoop-common-2.6.5/lib/native"" -I CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -O CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.dupmarked_native.bam -- --spark-runner LOCAL --spark-master local[8]; Using GATK wrapper script ${GATK_DIR}/gatk/build/install/gatk/bin/gatk; Running:; ${GATK_DIR}/gatk/build/install/gatk/bin/gatk MarkDuplicatesSpark -I CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -O CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.dupmarked_native.bam --spark-master local[8]; 21:47:47.494 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 21:47:47.827 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:${GATK_DIR}/gatk/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.so; 21:47:48.268 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 21:47:48.268 INFO MarkDuplicatesSpark - The Genome Analysis Toolkit (GATK) v4.0.4.0-7-g46a8661-SNAPSHOT; 21:47:48.268 INFO MarkDuplicatesSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:47:48.270 INFO MarkDuplicatesSpark - Executing as cwh",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4746:4912,wrap,wrapper,4912,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4746,1,['wrap'],['wrapper']
Integrability,setting RScriptExecutor to output useful messages on failure,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/237:41,message,messages,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/237,1,['message'],['messages']
Integrability,setup_gcnvkernel.py: Add missing pyvcf dependency,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8341:39,depend,dependency,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8341,1,['depend'],['dependency']
Integrability,"similar same error message with ; `gatk HaplotypeCallerSpark -R ref.fa -I input.GatherBamFiles.bam -O output.g2.vcf.gz`. OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); gatk 4.1.8.1 . ```; 07:16:06.169 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 20/08/15 07:16:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.5 MB, free 57.3 GB); 20/08/15 07:16:06 INFO SparkUI: Stopped Spark web UI at http://e1c-050:4041; 20/08/15 07:16:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/08/15 07:16:06 INFO MemoryStore: MemoryStore cleared; 20/08/15 07:16:06 INFO BlockManager: BlockManager stopped; 20/08/15 07:16:06 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/08/15 07:16:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/08/15 07:16:06 INFO SparkContext: Successfully stopped SparkContext; 07:16:06.412 INFO HaplotypeCallerSpark - Shutting down engine; [August 15, 2020 7:16:06 AM EDT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.11 minutes.; Runtime.totalMemory()=102900432896; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:67); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617:19,message,message,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617,1,['message'],['message']
Integrability,sjdk.samtools.AsyncSAMFileWriter.<init>(AsyncSAMFileWriter.java:32); at htsjdk.samtools.SAMFileWriterFactory.makeBAMWriter(SAMFileWriterFactory.java:216); at htsjdk.samtools.SAMFileWriterFactory.makeBAMWriter(SAMFileWriterFactory.java:188); at htsjdk.samtools.SAMFileWriterFactory.makeSAMOrBAMWriter(SAMFileWriterFactory.java:324); at htsjdk.samtools.SAMFileWriterFactory.makeWriter(SAMFileWriterFactory.java:343); at org.broadinstitute.hellbender.utils.read.ReadUtils.createCommonSAMWriterFromFactory(ReadUtils.java:949); at org.broadinstitute.hellbender.utils.read.ReadUtils.createCommonSAMWriter(ReadUtils.java:921); at org.broadinstitute.hellbender.engine.GATKTool.createSAMWriter(GATKTool.java:405); at org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSR.onTraversalStart(ApplyBQSR.java:54); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:515); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:74); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:65); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:69); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:148); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:126); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:101); at org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSRIntegrationTest.testPRFailWithLowMaxCycle(ApplyBQSRIntegrationTest.java:134); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1741#issuecomment-212508559:1774,Integrat,IntegrationTestSpec,1774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1741#issuecomment-212508559,6,['Integrat'],['IntegrationTestSpec']
Integrability,sjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:208); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at org.seqdoop.hadoop_bam.BAMRecordReader.nextKeyValue(BAMRecordReader.java:225); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:182); 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.rdd,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:7151,Wrap,Wrappers,7151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['Wrap'],['Wrappers']
Integrability,sks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2349:6925,Message,MessageHub,6925,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2349,2,['Message'],['MessageHub']
Integrability,so non-Docker users have a way to get the required dependencies.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5888:51,depend,dependencies,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5888,1,['depend'],['dependencies']
Integrability,"so, whether we can change the way such a pseudo likelihood is calculated in order to make a better selection for this case and in general. ---. @vruano commented on [Wed Dec 07 2016](https://github.com/broadinstitute/gsa-unstable/issues/1530#issuecomment-265535122). Also increase the kmer size to 35 does the job (-kmerSize 35) I guess that that prevents non-ref paths merge back into the reference between events thus resulting in less complex graphs. ---. @vruano commented on [Wed Dec 07 2016](https://github.com/broadinstitute/gsa-unstable/issues/1530#issuecomment-265535498). The user can be inform of using these work arounds (change the max number of haplotypes or kmersize) but those are not good solutions in general as he would pay a CPU and sensitivity penalty in other places. . ---. @vruano commented on [Wed Dec 07 2016](https://github.com/broadinstitute/gsa-unstable/issues/1530#issuecomment-265551340). I can see how the current best-path selection algorithm may fail to produce a good coverage of events across the active region depending on the weights on edges .... for some configurations the algorithm may dedicate too much time in exploring alternatives in one section of the graph because these are nearly equaly likely disregarding other possibilities other section just because they can only result in a relatively larger drop in the likelihood of the path. . I quick but elegant solution would be to simulate passes across the graph... first iterations would produce a quickly growing set of haplotypes but eventually repeated sampling would not produce new haplotypes. if after 100 subsequent simulations there is no new discovery or we have reached a limit (128?) we would stop there. This simulation approach could be implemented only in situations the graphs are too complex for an analytical solution. We can determine the maximum number of paths in a graph with a quick deep first traversal to decide whether to use the analytical-exact or the simulation-proximate app",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2954:4625,depend,depending,4625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2954,1,['depend'],['depending']
Integrability,"sorry, this is duplicate of #5336 ; I posted twice due to confusion related to [recent github issues](https://status.github.com/messages)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5337#issuecomment-431858746:128,message,messages,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5337#issuecomment-431858746,1,['message'],['messages']
Integrability,spatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); [TileDB::FileSystem] Error: hdfs: Error getting hdfs connection; [TileDB::StorageManagerConfig] Error: Error getting hdfs connection: Connection refused.; Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest > testWriteToAndQueryFromGCS FAILED; java.io.IOException: GenomicsD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6522:6787,Message,MessageHubBackedObjectConnection,6787,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6522,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,"specific requirement for now:; - create a dataflow tool that replicates the functionality of CollectMultipleMetrics on dataflow and run CollectAlignmentSummaryMetrics, CollectInsertSizeMetrics, QualityScoreDistribution, MeanQualityByCycle, CollectBaseDistributionByCycle. depends on #389 , #391 , #393 , #392 , #397",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/398#issuecomment-94332044:272,depend,depends,272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/398#issuecomment-94332044,1,['depend'],['depends']
Integrability,specifying com.github.fommil native dependencies explicitly,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3742:36,depend,dependencies,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3742,1,['depend'],['dependencies']
Integrability,"specops issue #269 https://github.com/broadinstitute/dsp-spec-ops/issues/269. - user can provide either [snps-truth-sensitivity-filter-level, indels-truth-sensitivity-filter-level] or [snps-lod-score-cutoff, indels-lod-score-cutoff], or neither, in which case default values of snps-truth-sensitivity-filter=99.7 and indels-truth-sensitivity-fitler=99.0 are used.; - regardless of lod score cutoffs or truth sensitivity cutoffs, the filtering string is either ""low_VQSLOD_SNP"" or ""low_VQSLOD_INDEL""; - if lod score cutoffs are provided, those are used for filtering. the header filter message looks like ""Site failed INDEL model VQSLOD cutoff of 0.0""; - if truth sensitivity cutoffs are provided, the corresponding lod scores are looked up from the tranche table in BigQuery. the header filter message in this case looks like ""Site failed INDEL model sensitivity cutoff (90.0), corresponding with VQSLOD cutoff of 0.0""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7194:585,message,message,585,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7194,2,['message'],['message']
Integrability,ssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:91); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:246); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:493); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1326(HaplotypeCallerSpark.java:223); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:213); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866); at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670); at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149:2598,Wrap,WrappingSpliterator,2598,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149,1,['Wrap'],['WrappingSpliterator']
Integrability,ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protoco,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1443,Wrap,WrapperExecutor,1443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['Wrap'],['WrapperExecutor']
Integrability,"ssorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:42166,Wrap,Wrappers,42166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['Wrap'],['Wrappers']
Integrability,st be at least 3 ; ; at java.base/java.io.File.createTempFile(File.java:2104) ; ; at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFileInDirectory(IOUtils.java:685) ; ; at org.broadinstitute.hellbender.utils.io.IOUtils.createTempFile(IOUtils.java:666) ; ; at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.lambda$writeIntervalSubsetReadCountFiles$1(GermlineCNVCaller.java:430) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.stream.IntPipeline$1$1.accept(IntPipeline.java:180) ; ; at java.base/java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:104) ; ; at java.base/java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:699) ; ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ; ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497) ; ; at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.writeIntervalSubsetReadCountFiles(GermlineCNVCaller.java:429) ; ; at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.doWork(GermlineCNVCaller.java:319) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211) ; ; at org.broadinstitute.hellbender,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7591:3356,wrap,wrapAndCopyInto,3356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7591,1,['wrap'],['wrapAndCopyInto']
Integrability,sting.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); ````,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4024:3777,Message,MessageHub,3777,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4024,2,['Message'],['MessageHub']
Integrability,stitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857) ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151) ; at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174) ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418) ; at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102) ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048) ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139) ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191) ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210) ; at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163) ; at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206) ; at org.broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651:6894,wrap,wrapAndCopyInto,6894,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651,1,['wrap'],['wrapAndCopyInto']
Integrability,stitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7090:13556,wrap,wrapAndCopyInto,13556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7090,1,['wrap'],['wrapAndCopyInto']
Integrability,stitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6774:6088,wrap,wrapAndCopyInto,6088,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774,1,['wrap'],['wrapAndCopyInto']
Integrability,stitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:907); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:861); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069:5266,wrap,wrapAndCopyInto,5266,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069,1,['wrap'],['wrapAndCopyInto']
Integrability,stitute.hellbender.tools.walkers.GenotypeGVCFsEngine.regenotypeVC(GenotypeGVCFsEngine.java:185); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:135); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:283); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:135); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:490); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1159695894:6408,wrap,wrapAndCopyInto,6408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7866#issuecomment-1159695894,1,['wrap'],['wrapAndCopyInto']
Integrability,stractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	- locked <0x0000000584a63348> (a java.net.SocksSocketImpl); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.go,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1285,protocol,protocol,1285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,successful integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/802f9314-2b8b-4007-9c8d-6832a5687f22),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8770:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8770,1,['integrat'],['integration']
Integrability,t (connect failed); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); at sha,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5220:2018,protocol,protocol,2018,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5220,1,['protocol'],['protocol']
Integrability,"t (engine, CNV, different tools, etc.). For example, the gCNV code from #3838, will include a full python framework to be use in conjunction with the GATK CNV code. In gatk3, different artifacts were generated to allow custom picking of the correct dependencies. With gradle, a composite build can be done to assemble together every GATK4 sub-modules, and still being able to publish different components in different artifacts. At least I would like to have a different artifact for pure-java components separate from the rest, to be sure that python (for example) is not required. Does some of this makes sense for you? A proposed scheme will be the following:. * `common`/`engine`: this should include the engine, utils, and everything that it can be useful by itself. This should be a dependency for every other module. Components in other sub-modules might be proposed to be moved to this one if they might be useful out of their own. If the package names does not change, the interface and usage will be unmodified, and then there is no change in the API.; * `spark`: I think that this is a nice separation from other components. In this case, this can include all code related with Spark classes for removal of the huge Spark dependency in sub-projects that does not require them.; * `tools` and `spark-tools`: this can be even split in more fine grained sub-modules depending on the pipeline (e.g. CNV, Mutect, etc., if it makes sense). In addition, the separation between normal tools and spark-tools will make easier for downstream projects to support or not spark in their code.; * `experimental`: this might contain prototype code that might change in the future, and that will be nice in terms of documentation purposes (always annotated with `@BetaFeature` or `@Experimental`, etc.). In addition, code shouldn't rely on the code in this package for anything, allowing to have experimental code for play around and remove if required, without any major version bump.; * `testing`: this w",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3900:1053,interface,interface,1053,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3900,1,['interface'],['interface']
Integrability,"t annoying things that I repeatedly encountered during the Java 17 port that we should look into. . **Log Spam Issues:** (these result in lots of error log spam that make the logs super hard to scan when there is a failure):. - The WDL test logs are riddled with “localization by hard link failed” and ""Docker not found"" failures, which makes it hard to scan them for real failures. Can we eliminate/fix these ?; - The logs have a few gradle task dependency warnings - we should hunt down the cause. ; - We routinely pull ~800 branches every time we run git clone for a CI job. Can we do shallow git clones?; - We're using deprecated gradle features that result in warnings in the logs, these should be updated.; - The test runner seems to serialize (via toString) every argument to every test method. Many of these have *huge* ""toString"" representations (i.e., `org.broadinstitute.hellbender.tools.spark.sv.integration.ExtractOriginalAlignmentRecordsByNameSparkIntegrationTest`) that fill the logs with reams of huge test values. We should codify/unify the test case wrapper class that we use in htsjdk for these cases. . **Other Issues:**. - We should review the shadowJar contents - it includes some surprising stuff (i.e., the publish-picard.sh script we use to publish picard).; - Do we still need the unpacktestjar task in `dockertest.gradle`, to work around testNG inability to find tests in a jar ?; - The test matrix job names all look the same in the github UI because only the first N characters are displayed, and they all have the same prefix. We should rename them so they start with unique prefixes.; - The library it.unimi.dsi:fastutil:7.0.61 appears to not be used [Fix] (reported in IntelliJ/Project Structure/Problems).; - It's non-intuitive that the *Dockerfile* builds the `run_unit_tests.sh` script. Is that necessary - can this not be built on demand ? Also, it should be named to run_tests.sh, since it doesn't run unit tests, but rather whatever test group it is told to run.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8087:1107,wrap,wrapper,1107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8087,1,['wrap'],['wrapper']
Integrability,t java.util.stream.IntPipeline.toArray(IntPipeline.java:502); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:207); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:436); 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:120); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverseVariants(TwoPassVariantWalker.java:74); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverse(TwoPassVariantWalker.java:27); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.ru,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085:4801,wrap,wrapAndCopyInto,4801,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085,1,['wrap'],['wrapAndCopyInto']
Integrability,t org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:546); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:527); 	at org.broadinstitute.hellbender.transformers.BQSRReadTransformer.apply(BQSRReadTransformer.java:145); 	at org.broadinstitute.hellbender.transformers.BQSRReadTransformer.apply(BQSRReadTransformer.java:27); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); 	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7549:4931,wrap,wrapAndCopyInto,4931,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7549,1,['wrap'],['wrapAndCopyInto']
Integrability,"t org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:47); at org.gradle.internal.execution.impl.DefaultWorkExecutor.execute(DefaultWorkExecutor.java:33); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:140); ... 34 more; Caused by: org.gradle.process.internal.ExecException: A problem occurred starting process 'command 'javadoc''; at org.gradle.process.internal.DefaultExecHandle.execExceptionFor(DefaultExecHandle.java:237); at org.gradle.process.internal.DefaultExecHandle.setEndStateInfo(DefaultExecHandle.java:214); at org.gradle.process.internal.DefaultExecHandle.failed(DefaultExecHandle.java:364); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:87); at org.gradle.internal.operations.CurrentBuildOperationPreservingRunnable.run(CurrentBuildOperationPreservingRunnable.java:42); ... 3 more; Caused by: net.rubygrapefruit.platform.NativeException: Could not start 'javadoc'; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:27); at net.rubygrapefruit.platform.internal.WrapperProcessLauncher.start(WrapperProcessLauncher.java:36); at org.gradle.process.internal.ExecHandleRunner.startProcess(ExecHandleRunner.java:98); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:71); ... 4 more; Caused by: java.io.IOException: Cannot run program ""javadoc"" (in directory ""/home/cb2/gatk""): error=2, No such file or directory; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:25); ... 7 more; Caused by: java.io.IOException: error=2, No such file or directory; ... 8 more. * Get more help at https://help.gradle.org. BUILD FAILED in 1s; 5 actionable tasks: 1 executed, 4 up-to-date; `; ```; I'm open to it being a lot of things. For context, I'm just setting up GATK on a new Linux virtual machine, so some dependencies may not exist.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:13242,Wrap,WrapperProcessLauncher,13242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716,3,"['Wrap', 'depend']","['WrapperProcessLauncher', 'dependencies']"
Integrability,"t were evidently memory failures when running HaplotypeCaller on some standard test WGS data when using the exact task used in the warp pipeline here: https://github.com/broadinstitute/warp/blob/develop/pipelines/broad/dna_seq/germline/variant_calling/VariantCalling.wdl. I found that running that wdl with otherwise default inputs except for `haplotype_scatter_count` being set to 10 (so each node doing approximately 5x as much work as when the default, 50, is set) I would get repeated HaplotypeCaller job failures after a few hours that had the pattern of memory failures. The errors tend to involve HaplotypeCaller abruptly ending without any sort of error message or exception at all (which could indicate the vm is dying):; ```; 03:22:15.993 INFO ProgressMeter - chr13:18173014 378.6 1419490 3749.0; 03:22:26.338 INFO ProgressMeter - chr13:18177988 378.8 1419530 3747.4; 03:22:36.801 INFO ProgressMeter - chr13:18203610 379.0 1419700 3746.1; (END); ```; Or alternatively it seems to end without the end-of-run messages being output:; ```; 23:05:30.662 INFO ProgressMeter - chr2:47207099 428.8 1372310 3200.4; 23:05:40.859 INFO ProgressMeter - chr2:47323745 429.0 1372960 3200.7; 23:05:50.896 INFO ProgressMeter - chr2:47476709 429.1 1373720 3201.2; Using GATK jar /gatk/gatk-package-4.2.2.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx6933m -Xms6933m -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -jar /gatk/gatk-package-4.2.2.0-local.jar HaplotypeCaller [INPUTS]; 2022/02/10 23:06:52 Starting delocalization.; 2022/02/10 23:06:53 Delocalization script execution started...; ```. These failures appear to be reproducible and happen at about the same point in every run. The fact that increasing the memory or decreasing the interval per shard seems to remove the issue it makes me suspect there might be an issue where HaplotypeCaller is using more memory a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7693:1051,message,messages,1051,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7693,1,['message'],['messages']
Integrability,t.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.net.UnknownHostException: www.googleapis.com; 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:668); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094:7228,protocol,protocol,7228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094,1,['protocol'],['protocol']
Integrability,t.VariantContext.getAttributeAsIntList(VariantContext.java:738); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyReadPositionFilter(Mutect2FilteringEngine.java:223); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:529); 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:130); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverseVariants(TwoPassVariantWalker.java:74); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverse(TwoPassVariantWalker.java:27); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.ru,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5684:5135,wrap,wrapAndCopyInto,5135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5684,1,['wrap'],['wrapAndCopyInto']
Integrability,t.VariantContext.getMaxPloidy(VariantContext.java:785); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeRefConfidenceGenotypes(ReferenceConfidenceVariantContextMerger.java:405); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:92); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:212); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3412:1855,wrap,wrapAndCopyInto,1855,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3412,1,['wrap'],['wrapAndCopyInto']
Integrability,t.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePip,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:10969,wrap,wrapAndCopyInto,10969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,1,['wrap'],['wrapAndCopyInto']
Integrability,tFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:333); 	... 24 more; Caused by: java.net.UnknownHostException: metadata; 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:104); 	... 34 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-411503423:8104,protocol,protocol,8104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-411503423,4,['protocol'],['protocol']
Integrability,"tFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 18/04/24 17:40:52 INFO TaskSetManager: Lost task 0.0 in stage 2.0 (TID 3) on xx.xx.xx.25, executor 2: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 01:33 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:40:52 INFO TaskSetManager: Starting task 0.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 4, partition 0, PROCESS_LOCAL, 6010 bytes); 01:33 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:40:52 INFO TaskSetManager: Starting task 1.1 in stage 2.0 (TID 6, xx.xx.xx.24, executor 1, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:41:19 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.24:49115 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:41:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.24:49115 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:41:31 WARN TaskSetManager: Lost task 0.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 4): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilt",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:27045,Wrap,WrappedArray,27045,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Wrap'],['WrappedArray']
Integrability,tHandler.java:208); at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:113); at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340); at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340); at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340); at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340); at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandler,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:44412,Message,MessageToMessageDecoder,44412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['Message'],['MessageToMessageDecoder']
Integrability,tHostByAddr; 0.0% 3 + 0 org.apache.spark.util.collection.ExternalSorter.insertAll; 0.0% 0 + 2 htsjdk.samtools.util.zip.IntelDeflater.deflateBytes; 0.0% 2 + 0 sun.misc.Unsafe.defineClass; 0.0% 2 + 0 sun.reflect.MethodAccessorGenerator.emitInvoke; 0.0% 2 + 0 org.apache.spark.deploy.SparkHadoopUtil$$anonfun$2$$anonfun$apply$mcJ$sp$2.apply; 0.0% 2 + 0 java.util.IdentityHashMap.resize; 0.0% 0 + 1 java.lang.Runtime.availableProcessors; 0.0% 0 + 1 java.io.FileInputStream.available; 0.0% 0 + 1 sun.management.GarbageCollectorImpl.getCollectionTime; 0.0% 0 + 1 java.lang.Thread.setPriority0; 0.0% 0 + 1 sun.nio.ch.FileDispatcherImpl.read0; 0.0% 0 + 1 sun.nio.ch.Net.socket0; 0.0% 1 + 0 org.seqdoop.hadoop_bam.SAMRecordWritable.set; 0.0% 1 + 0 org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.org$apache$spark$util$collection$SizeTracker$$numUpdates; 0.0% 1 + 0 java.util.IdentityHashMap$Values.toArray; 0.0% 1 + 0 io.netty.buffer.AbstractByteBufAllocator.heapBuffer; 0.0% 1 + 0 sun.net.www.protocol.http.Handler.openConnection; 1.0% 106 + 55 Total interpreted (including elided). Compiled + native Method ; 13.7% 2116 + 2 com.ning.compress.lzf.impl.UnsafeChunkEncoderLE.tryCompress; 2.7% 409 + 0 htsjdk.samtools.util.BlockCompressedOutputStream.write; 2.4% 373 + 2 com.ning.compress.lzf.impl.UnsafeChunkDecoder.decodeChunk; 1.4% 214 + 0 htsjdk.samtools.SAMUtils.bytesToCompressedBases; 1.4% 211 + 0 htsjdk.samtools.BinaryTagCodec.readTags; 1.0% 147 + 3 htsjdk.samtools.BAMRecordCodec.encode; 0.7% 108 + 0 org.broadinstitute.hellbender.relocated.com.google.common.collect.ImmutableMultimap$Builder.build; 0.6% 99 + 0 java.util.Iterator.forEachRemaining; 0.6% 84 + 2 org.apache.spark.util.collection.TimSort$SortState.mergeLo; 0.5% 82 + 0 org.broadinstitute.hellbender.relocated.com.google.common.collect.AbstractMapBasedMultimap.put; 0.5% 73 + 2 scala.collection.Iterator$$anon$13.hasNext; 0.4% 68 + 0 htsjdk.samtools.BinaryTagCodec.readSingleValue; 0.4% 66 + 0 org.broadinstitute.hellbender.util,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1702#issuecomment-210127581:7095,protocol,protocol,7095,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1702#issuecomment-210127581,1,['protocol'],['protocol']
Integrability,"tOutputFormat.getDefaultWorkFile(TemplatedTextOutputFormat.java:46); at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:995); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:979); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61); at org.apache.spark.scheduler.Task.run(Task.scala:64); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 15/07/14 13:14:53 ERROR util.SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-0,5,main]; java.lang.IncompatibleClassChangeError: Found class org.apache.hadoop.mapreduce.TaskAttemptContext, but interface was expected; at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getOutputFile(TemplatedTextOutputFormat.java:50); at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getDefaultWorkFile(TemplatedTextOutputFormat.java:46); at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:995); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:979); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61); at org.apache.spark.scheduler.Task.run(Task.scala:64); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 15/07/14 13:14:53 WARN scheduler.TaskSetManager: Lost task 0.0 in stage ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:29840,interface,interface,29840,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['interface'],['interface']
Integrability,"tPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); Caused by: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-890235307]; 	at shaded.cloud_nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:179); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:487); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	... 50 more; ```. I'll rerun without using NIO for the dbsnp vcf and I'll try to look through the other 7 error messages to see if anything is different from those above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:15796,message,messages,15796,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963,1,['message'],['messages']
Integrability,"table code path: scanning neighbor chimeric alignment pairs of a contig iteratively and outputs inversion breakpoints as symbolic variant `<INV>`, annotated with `INV55` and `INV33` for signaling if it is the left or right breakpoint of the assumed inversion.; * the experimental code path that separates the alignment pre-processing step from the inference step, and studying the alignments in whole; this code path, in addition to outputting insertion, deletion and small duplication calls as does the stable path, outputs ; * BND records representing assembled breakpoints for which type could not be completely determined using only the contig alignments; this includes supposedly inversion breakpoints; * complex (`<CPX>`) variants from assembly contigs with more than 2 alignments; ; The tool proposed in this PR is based on [manual review](https://github.com/broadinstitute/dsde-methods-sv/tree/sh_inv_filter_init/docs/knowledgeBase/variantReview/inversion/chm) of a callset generated a long time ago (but still useful for studying filtering inversion breakpoints), and is designed to be integrated with the experimental code path. ### proposed algo. #### input:; * the ""INV55/INV33""-annotated `BND` records output by the upstream experimental code path; * BND's have related concepts of `MATE` and `PARTNER` (see figure below, left); * `MATE`: novel adjacency, i.e. contiguity on sample that is absent on reference (e.g. mobile element insertions, deletions); * `PARTNER`: novel disruption, i.e. contiguity on reference disrupted on sample (e.g. insertions, deletions). ![inversion_demo](https://user-images.githubusercontent.com/16310888/40271739-6d999b30-5b6f-11e8-86db-78fa11db4305.png). * complex variants detected by the upstream experimental code path; the reason is that sometimes inversion calls are incorporated as part of a larger, more complex event and the logic implemented in the upstream code, theoretically, allows for arbitrarily complex rearrangement; shown above on the rig",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4789:1434,integrat,integrated,1434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4789,1,['integrat'],['integrated']
Integrability,"tage 5.0 failed 4 times, most recent failure: Lost task 181.3 in stage 5.0 (TID 1139, scc-q02.scc.bu.edu, executor 24): java.lang.IllegalArgumentException: provided start is negative: -1; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$andThen$0(SVInterval.java:61); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:86); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval.<init>(SVInterval.java:51); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:48); at org.broadinstitute.hellbender.tools.spark.sv.evidence.QNameFinder.apply(QNameFinder.java:16); at org.broadinstitute.hellbender.tools.spark.utils.FlatMapGluer.hasNext(FlatMapGluer.java:44); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939); at org.apache.spark.SparkCont",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:40376,Wrap,Wrappers,40376,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,2,['Wrap'],['Wrappers']
Integrability,"tarted to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:1511,wrap,wrapper,1511,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646,1,['wrap'],['wrapper']
Integrability,"tash@broadinstitute.org>; Date: Thu Dec 7 02:50:19 2017 -0500. update WDL scripts. commit 12bcfa192ee6fa6da21239ebf5b513633efe974f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:47:33 2017 -0500. significant updates to GermlineCNVCaller; integration tests for GermlineCNVCaller w/ sim data in both run modes. commit 151416a4af735ca721bd75e4b54a780c17ac9397; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 01:42:05 2017 -0500. hybrid ADVI abstract argument collection w/ flexible default values; hybrid ADVI argument collection for contig ploidy model; hybrid ADVI argument collection for germline denoising and calling model. commit 56e21bf955d3dc0c52aceb384f28cf6173959de0; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 23:18:39 2017 -0500. rewritten python-side coverage metadata table reader using pandas to fix the issues with comment line; change criterion for cohort/case based on whether a contig-ploidy model is provided or not; simulated test files for ploidy determination tool; proper integration test for ploidy determination tool and all edge cases; updated docs for ploidy determination tool. commit 7fa104b2e9170770cfc5b338835e41215d7fd39c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 18:43:17 2017 -0500. kabab case for gCNV-related tools; removed short args (this also partially affected PlotDenoisedCopyRatios and PlotModeledSegments and their integration tests). commit f02cb024331a986213cfd9fae2da706bbc5ddbd9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 18:02:40 2017 -0500. synced with mb_gcnv_python_kernel. commit 2963bbf8c90418d9b88545c93771ae51cf542db9; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 11:38:05 2017 -0500. Fixing typo in travis.yml. commit 6cf589999c716ec66404eb0a2ae4310dd130a772; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 6 11:13:58 2017 -0500. editable, full path. commit d998f2d5c2b33dd41e291b",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:7729,integrat,integration,7729,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,1,['integrat'],['integration']
Integrability,"te(ResolveCachingStateStep.java:90); at org.gradle.internal.execution.steps.ResolveCachingStateStep.execute(ResolveCachingStateStep.java:48); at org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:69); at org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:47); at org.gradle.internal.execution.impl.DefaultWorkExecutor.execute(DefaultWorkExecutor.java:33); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:140); ... 34 more; Caused by: org.gradle.process.internal.ExecException: A problem occurred starting process 'command 'javadoc''; at org.gradle.process.internal.DefaultExecHandle.execExceptionFor(DefaultExecHandle.java:237); at org.gradle.process.internal.DefaultExecHandle.setEndStateInfo(DefaultExecHandle.java:214); at org.gradle.process.internal.DefaultExecHandle.failed(DefaultExecHandle.java:364); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:87); at org.gradle.internal.operations.CurrentBuildOperationPreservingRunnable.run(CurrentBuildOperationPreservingRunnable.java:42); ... 3 more; Caused by: net.rubygrapefruit.platform.NativeException: Could not start 'javadoc'; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:27); at net.rubygrapefruit.platform.internal.WrapperProcessLauncher.start(WrapperProcessLauncher.java:36); at org.gradle.process.internal.ExecHandleRunner.startProcess(ExecHandleRunner.java:98); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:71); ... 4 more; Caused by: java.io.IOException: Cannot run program ""javadoc"" (in directory ""/usr/bin/gatk""): error=2, No such file or directory; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:25); ... 7 more; Caused by: java.io.IOException: error=2, No such file or directory; ... 8 more",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-590387973:12115,Wrap,WrapperProcessLauncher,12115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-590387973,2,['Wrap'],['WrapperProcessLauncher']
Integrability,te.hellbender.utils.Utils.validateArg(Utils.java:724); 	at org.broadinstitute.hellbender.utils.MathUtils.log10BinomialProbability(MathUtils.java:934); 	at org.broadinstitute.hellbender.utils.MathUtils.binomialProbability(MathUtils.java:927); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:56); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePip,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098:6100,wrap,wrapAndCopyInto,6100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098,1,['wrap'],['wrapAndCopyInto']
Integrability,"te@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi."",; ""reason"" : ""forbidden""; } ],; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi.""; }; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:333); 	... 21 more; ```; The latter is more verbose than I need, but having that message from the 403 was key (since I needed the service account name to give it access.)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4592:5646,message,message,5646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4592,1,['message'],['message']
Integrability,"tecanada ; enum34 1.1.10+computecanada ; gatkpythonpackages 0.1 ; gcnvkernel 0.8 ; h5py 3.1.0+computecanada ; intel-openmp 2021.1.1+computecanada; joblib 0.14.1+computecanada ; kiwisolver 1.3.1+computecanada ; matplotlib 3.3.4+computecanada ; mkl 2021.1.1+computecanada; numpy 1.17.3+computecanada ; pandas 1.0.3+computecanada ; patsy 0.5.3+computecanada ; Pillow 8.1.2+computecanada ; pip 20.0.2 ; pymc3 3.1 ; pyparsing 3.1.0 ; python-dateutil 2.8.2+computecanada ; pytz 2023.3+computecanada ; scipy 1.1.0+computecanada ; setuptools 46.1.3 ; six 1.16.0+computecanada ; tbb 2021.1.1+computecanada; Theano 1.0.4 ; tqdm 4.19.5+computecanada ; wheel 0.34.2 ; ----. I used python 3.6.10 as suggested in gatkcondaenv.yml.template and respecting these dependencies found here setup_gcnvkernel.py:. ""theano == 1.0.4"",; ""pymc3 == 3.1"",; ""numpy >= 1.13.1"",; ""scipy >= 0.19.1"",; ""tqdm >= 4.15.0"" . ----. mkl is installed in my environment.; When I do : python -c ""import numpy ; numpy.show_config()"". I get this message:. blas_mkl_info:; libraries = ['mkl_rt', 'pthread']; library_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib/intel64']; define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]; include_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/include', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib']; blas_opt_info:; libraries = ['mkl_rt', 'pthread']; library_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib/intel64']; define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]; include_dirs = ['/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/include', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/Core/imkl/2020.1.217/mkl/lib'",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8387:6230,message,message,6230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8387,1,['message'],['message']
Integrability,"template<class _Tp> typename __gnu_cxx::__enable_if<std::__is_arithmetic<_Tp>::__value, int>::__type std::isinf(_Tp)' declared here, later in the translation unit; isinf(_Tp __f); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:2:0:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h: In instantiation of 'static NUMBER ContextBase<NUMBER>::approximateLog10SumLog10(NUMBER, NUMBER) [with NUMBER = float]':; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:57:5: required from 'NUMBER compute_full_prob(testcase*, NUMBER*) [with NUMBER = float]'; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:116:69: required from here; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:16: error: 'isinf' was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive]; if (isinf(small) == -1 || isinf(big) == -1); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:1:; /usr/local/Cellar/gcc/5.3.0/include/c++/5.3.0/cmath:853:5: note: 'template<class _Tp> typename __gnu_cxx::__enable_if<std::__is_arithmetic<_Tp>::__value, int>::__type std::isinf(_Tp)' declared here, later in the translation unit; isinf(_Tp __f); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/baseline.cc:2:0:; /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/common_data_structure.h:94:38: error: 'isinf' was not declared in this scope, and no declarations were found by argument-dependent lookup at the point of instantiation [-fpermissive]; if (isinf(small) == -1 || isinf(big) == -1); ^; In file included from /Users/louisb/Workspace/gatk/src/main/cpp/VectorLoglessPairHMM/headers.h:27:0,; from /U",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343:7810,depend,dependent,7810,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187727343,1,['depend'],['dependent']
Integrability,"tent, but I was finding that when I would apply these filters to the output of other tools like samtools view, I'd get different number of reported reads compared to what seemed to be being discovered within HaplotypeCaller (via adding debug messages). For example, using this SRA sample: https://www.ncbi.nlm.nih.gov/sra/SRR12324251 and mapping the reads against these references using minimap2: https://s3.amazonaws.com/zymo-files/BioPool/ZymoBIOMICS.STD.refseq.v2.zip, and then observing the alignments that appear at position 97201 on the main E. Coli Chromosome we can see that there are 873 alignments overlapping that position:; `samtools view gatk_bams/Escherichia_coli_complete_genome.fasta.SRR12324251_1.fastq.bam.bam Escherichia_coli_chromosome:97201-97201 | less -S`. Applying the above filters to these alignments reports 871 alignments. However, GATK HaplotypeCaller reports only 743 valid alignments (before variant calling). Below is some code where I added debug messages to retrieve the read names that HaplotypeCaller determines to be valid:. *~line 476 of `HaplotypeCallerEngine.java`*; ```; public ActivityProfileState isActive( final AlignmentContext context, final ReferenceContext ref, final FeatureContext features ) {; if ( forceCallingAllelesPresent && features.getValues(hcArgs.alleles, ref).stream().anyMatch(vc -> hcArgs.forceCallFiltered || vc.isNotFiltered())) {; return new ActivityProfileState(ref.getInterval(), 1.0);; }. if( context == null || context.getBasePileup().isEmpty() ) {; // if we don't have any data, just abort early; return new ActivityProfileState(ref.getInterval(), 0.0);; }. final boolean debug = (context.getPosition() - 1) % 100000 == 0 || (context.getPosition() >= 97200 && context.getPosition() <= 97350) || (context.getPosition() >= 641000 && context.getPosition() <= 650000);; if (debug) {; System.out.println(""Position "" + context.getPosition() + "" Reads at position "" + context.size());; if (context.getPosition() == 97201 && context.getCon",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7873:2613,message,messages,2613,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7873,1,['message'],['messages']
Integrability,terGencodeFuncotationsByTranscript(GencodeFuncotationFactory.java:281); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:338); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:138); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:113); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.lambda$enqueueAndHandleVariant$0(Funcotator.java:502); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:504); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:399); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:109); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(Abst,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886:1189,wrap,wrapAndCopyInto,1189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886,1,['wrap'],['wrapAndCopyInto']
Integrability,"terMutectCalls - Starting first pass through the variants; 22:58:28.484 INFO FilterMutectCalls - Shutting down engine; [January 6, 2019 10:58:28 PM SGT] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=2141192192; java.lang.IllegalArgumentException: errorRateLog10 must be good probability but got NaN; 	at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleLog10ErrorRate(QualityUtils.java:321); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.lambda$applyGermlineVariantFilter$10(Mutect2FilteringEngine.java:207); 	at java.util.stream.DoublePipeline$3$1.accept(DoublePipeline.java:231); 	at java.util.Spliterators$DoubleArraySpliterator.forEachRemaining(Spliterators.java:1198); 	at java.util.Spliterator$OfDouble.forEachRemaining(Spliterator.java:822); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 	at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:207); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:436); 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:120); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$I",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085:3610,wrap,wrapAndCopyInto,3610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085,1,['wrap'],['wrapAndCopyInto']
Integrability,terator.hasNext(AbstractIterator.java:138); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.TransformedIterator.hasNext(TransformedIterator.java:43); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$5.hasNext(Iterators.java:547); 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1811); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$5.hasNext(Iterators.java:547); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.fillCache(PushToPullIterator.java:71); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.advanceToNextElement(PushToPullIterator.java:58); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.<init>(PushToPullIterator.java:37); 	at org.broadinstitute.hellbender.utils.variant.writers.GVCFBlockCombiningIterator.<ini,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994:1849,Wrap,WrappingSpliterator,1849,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994,1,['Wrap'],['WrappingSpliterator']
Integrability,teringEngine.getIntArrayTumorField(Mutect2FilteringEngine.java:235); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyMedianFragmentLengthDifferenceFilter(Mutect2FilteringEngine.java:106); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:228); 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.apply(FilterMutectCalls.java:113); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:159); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); 	at org.broadi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787:5301,wrap,wrapAndCopyInto,5301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787,1,['wrap'],['wrapAndCopyInto']
Integrability,teringEngine.getIntArrayTumorField(Mutect2FilteringEngine.java:235); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyMedianFragmentLengthDifferenceFilter(Mutect2FilteringEngine.java:106); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:228); 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.apply(FilterMutectCalls.java:121); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4363:6227,wrap,wrapAndCopyInto,6227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363,1,['wrap'],['wrapAndCopyInto']
Integrability,terval.java:60); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:147); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3874:1347,Wrap,WrappingSpliterator,1347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874,1,['Wrap'],['WrappingSpliterator']
Integrability,"tests will now run as cloud, integration, and unit on travis; this reduces our wallclock time from 30ish -> 20ish minutes. cleaned up some wierdness in the way things were specified as well",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2399:29,integrat,integration,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2399,1,['integrat'],['integration']
Integrability,th.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.NoRouteToHostException: No route to host (Host unreachable); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsPr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417:1349,protocol,protocol,1349,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417,3,['protocol'],['protocol']
Integrability,"thanks @yhcheng - I think you should work with the developer of jbwa to create a packaged, pre-compiled binary (on all platforms supported) and put it on maven central so that gatk (and others) will be able to reference it. We will not be able to build it on all the platforms (we made 1 snapshot on linux+mac to unblock ourselves but the real solution is for jbwa to be hosted on maven central and have pre-build binaries. It would greatly help also if jbwa depended on https://github.com/broadinstitute/gatk-native-bindings and implemented the NativeLibrary interface). . @droazen wdyt?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1914#issuecomment-227447420:459,depend,depended,459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1914#issuecomment-227447420,2,"['depend', 'interface']","['depended', 'interface']"
Integrability,"that would depend on another annotation. if the walker is also annotated; @ByLocus then you can do both sample and locus, but if only @bySample, then; each of workers would have to process each sample in it's entirety. for; your latter example, the walker would have to be annotated; @BySample and @ByInterval. if multiple annotations are not possible then we need to figure out how to; allow for all the combinations. On Fri, Mar 20, 2015 at 12:09 PM, droazen notifications@github.com wrote:. > Clarify what is meant by ""scatter by sample"" -- do you mean that each; > worker on the farm/cloud would handle all of the data for a single sample?; > Or do you mean partition the data by sample, and then within each sample; > partition it by interval?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/hellbender/issues/320#issuecomment-84057467; > .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/320#issuecomment-84086924:11,depend,depend,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/320#issuecomment-84086924,1,['depend'],['depend']
Integrability,the SplitNCigarReadsIntegrationTest are just bogus. The fix is to port the actual integration tests for SplitNCigarReads,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1209#issuecomment-165816312:82,integrat,integration,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1209#issuecomment-165816312,1,['integrat'],['integration']
Integrability,"the google genomics API has deprecated all the features we were using,; this includes the reference lookup api, and the google Read data types. removing all google genomics related dependencies; * replacing com.google.cloud.genomics:gatk-tools-java:1.1 with gov.nist.math.jama:gov.nist.math.jama:1.1.1; 	we rely on this transitive dependency, making it a direct dependency instead; * remove com.google.apis:google-api-services-genomics:v1-rev527-1.22.0; * remove com.google.cloud.genomics:google-genomics-utils:v1-0.10. * delete ReferenceAPISource and tests; * delete GoogleGenomicsReadToGATKReadAdapter and tests; * delete CigarConversionUtils and tests. * update other classes to remove references to these types; * improve an error message",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4266:181,depend,dependencies,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4266,4,"['depend', 'message']","['dependencies', 'dependency', 'message']"
Integrability,"the htsget protocol ; > ; > This year, the GA4GH team introduced the htsget protocol to allow users to download read data for subsections of the genome in which they are interested. This is a richer and more flexible approach to working with reads data. It allows you to keep your genomics data in a common BAM file format on Google Cloud Storage and work with it efficiently from your computation pipelines, using standard bioinformatics tools. We have already launched our own open source implementation of this protocol, which you can use to access your reads data. Many popular tools such as samtools and htslib have been updated by the community to support htsget. Documentation is provided here. The Reads API is now deprecated, and will be decommissioned after one year, or after there has been no API activity for one month by those receiving this notice, whichever comes first. ; > ; > Variants API is now replaced by htsget and Variant Transforms ; > ; > The GA4GH team also plans to extend the htsget protocol to cover variant data, and we will extend our implementation of htsget to cover this use case. ; > ; > After analyzing usage of the Variants API, we found that users primarily used it to import variant data and then export it to BigQuery. To save time and effort, we created Variant Transforms, an open source tool for directly importing VCF data into BigQuery. Variant Transforms and its documentation are published here. Variant Transforms is more scalable than the legacy Variants API, and it has a robust roadmap with a dedicated team. We also welcome collaborators on this project as it advances. ; > ; > The Variants API is now deprecated, and will be decommissioned after one year, or after there has been no API activity for one month, whichever comes first. ; > ; > We are excited to move in step with the global genomics community and provide you with the latest technology for managing your genomic data. We have lots of other projects on the way, and look forward to s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4166:1168,protocol,protocol,1168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166,1,['protocol'],['protocol']
Integrability,the integration test (testBasic) must check the contents of the created file,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/897:4,integrat,integration,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/897,1,['integrat'],['integration']
Integrability,"the most issue , gatk doesn't support aarch64, is there a plan to support?; and another issue, ""The gatk environment, requires hardware with AVX support for tools that depend on TensorFlow (e.g. CNNScoreVariant). "", the word means gatk requires AVX ?or TensorFlow depend AVX? I confused.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6118:168,depend,depend,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6118,2,['depend'],['depend']
Integrability,the requirement is to make MD fully work in a tested way (all Picard integration tests must work - perhaps by comparing the sets of reads that got marked as 'duplicate'). Note: we'll migrate this code from genomics-pipeline and adapt it to our needs and style.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/488:69,integrat,integration,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/488,1,['integrat'],['integration']
Integrability,the requirement is to port DepthOfCoverage or write a new tool that collects coverage information per base (primarily for WGS) and stats as DoC does. Integration tests also need to be ported or created. Current test data is broad-internal but we should move to using public data.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/617:150,Integrat,Integration,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/617,1,['Integrat'],['Integration']
Integrability,the requirement is to port the code and change the interface from a readwalker and implement tests.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/45#issuecomment-94352324:51,interface,interface,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/45#issuecomment-94352324,1,['interface'],['interface']
Integrability,the requirement is to port the tool and all integration tests (all are public),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/53#issuecomment-94351463:44,integrat,integration,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/53#issuecomment-94351463,1,['integrat'],['integration']
Integrability,the requirement is to port the tool and the integration tests. Removing 'help wanted' because it requires broad-only data. The data must be checked to make sure it's publicly avaialbable.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/51#issuecomment-94351840:44,integrat,integration,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/51#issuecomment-94351840,1,['integrat'],['integration']
Integrability,the tests written by David A a while back have not been run or updated and they fail (we now compare more stringently so maybe that's why). The ticket is to figure out why and fix if possible. Depends on code changes in https://github.com/broadinstitute/gatk/pull/1921,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1922:193,Depend,Depends,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1922,1,['Depend'],['Depends']
Integrability,the usecase is depth of coverage per exon (for CNV); depend on #98,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/109:53,depend,depend,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/109,1,['depend'],['depend']
Integrability,there was a code path that didn't get exercised in integration tests or quickstart data (writeMissingIntervals) that wasn't made aware of the storeCompressedReferences flag. Updated to operate correctly in its presence,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8556:51,integrat,integration,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8556,1,['integrat'],['integration']
Integrability,this allows us to also remove the cloudera artifactory repo which will fix #610. removing some traces of gradle 2.2.1 from our build script and rerunning gradle wrapper to generate an updated wrapper,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1023:161,wrap,wrapper,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1023,2,['wrap'],['wrapper']
Integrability,"this allows us to remove the compile time dependencies minicluster and testng and convert them to dependencies of this new artifact; moving utils.test package to testutils and a new source root. the new dependency structure looks like. main <- testUtils; ^ ^; test. one side effect was that commons.math is no longer imported, we were accidentally using this in some places instead of commons.math3 which is what we wanted.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5112:42,depend,dependencies,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5112,3,['depend'],"['dependencies', 'dependency']"
Integrability,"this for a first workflow to target?. 1) Run ExtractVariantAnnotations on a training set of chromosomes. You can keep training/truth labels as in Best Practices, for now.; 2) Run TrainVariantAnnotationsModel on that. We'll use the truth scores generated here for any sensitivity conversions---i.e., we'll be calibrating scores only to the truth sites that are contained in the training set of chromosomes.; 3) Use the trained model to run a single shard of ScoreVariantAnnotations on a validation set of chromosomes.; 4) Run some variation of the above script on the resulting outputs to determine SNP and INDEL score thresholds for optimizing the corresponding LL scores. We can also add some code to the script to use the truth scores from step 2 to convert these score thresholds into truth-sensitivity thresholds.; 5) Provide these truth-sensitivity thresholds to ScoreVariantAnnotations and use them to hard filter. Evaluate on a test set of chromosomes. If all looks good, we can later move steps 3-4 into the train tool and automate the passing of sensitivities in 5 via outputs in the model directory. This will let us keep the basic interface of ScoreVariantAnnotations the same, but we'll have to add a few basic parameters to TrainVariantAnnotationsModel to control the train/validation split. So I think all this branch is missing is step 5---we'll simply need to add command-line parameters for the SNP/INDEL sensitivity thresholds and then do the hard filtering in the VCF writing method highlighted above. Do you think you can handle implementing that in this branch, and then the rest at the WDL level? I can help with the python script for the LL stuff (or anything else), if needed. Not sure if you got a chance to check out what your collaborators are doing in the methods you're looking to compare against, but it would be good to understand if this basic scheme for train/validation/test splitting can be replicated over there. You'll want to compare apples to apples, after all!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1068345084:1221,interface,interface,1221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1068345084,1,['interface'],['interface']
Integrability,this happens on the branch for https://github.com/broadinstitute/gatk/pull/1630 (which uses async IO for tests to mimic non-test usage). This bug is either due to or exposed by asynchronous tribble reading. more logs https://travis-ci.org/broadinstitute/gatk/jobs/118507152. test results; https://storage.googleapis.com/hellbender/test/build_reports/5109.2/tests/classes/org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltrationIntegrationTest.html#testClusteredSnps. ```; java.lang.RuntimeException: htsjdk.tribble.TribbleException: Exception encountered in worker thread.; at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:153); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:126); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:108); at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltrationIntegrationTest.testClusteredSnps(VariantFiltrationIntegrationTest.java:36); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentiall,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:631,Integrat,IntegrationTestSpec,631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,6,['Integrat'],['IntegrationTestSpec']
Integrability,"this is confirmed, the resulting tables are the same. Here's what i ran:. ```; BAM=""./src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam""; REF=""./src/test/resources/human_g1k_v37.chr17_1Mb.fasta""; VCF=""./src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf"". java -jar ~/bin/GenomeAnalysisTK-3.3-0/GenomeAnalysisTK.jar -T BaseRecalibrator -R $REF --knownSites $VCF -I $BAM -o gatk3.pre.cols.table --sort_by_all_columns; java -jar ~/bin/GenomeAnalysisTK-3.3-0/GenomeAnalysisTK.jar -T BaseRecalibrator -R $REF --knownSites $VCF -I $BAM -BQSR gatk3.pre.cols.table -o gatk3.post.cols.table --sort_by_a\; ll_columns. bamOut=gatk4.recalibrated.bam; build/install/hellbender/bin/hellbender BaseRecalibrator -R $REF --knownSites $VCF -I $BAM -RECAL_TABLE_FILE gatk4.pre.cols.table --sort_by_all_columns true; build/install/hellbender/bin/hellbender ApplyBQSR -I $BAM --bqsr_recal_file gatk4.pre.cols.table -O $bamOut; build/install/hellbender/bin/hellbender BaseRecalibrator -R $REF --knownSites $VCF -I $bamOut -RECAL_TABLE_FILE gatk4.post.cols.table --sort_by_all_columns true. diff gatk3.post.cols.table gatk4.post.cols.table; ```. The result is . ```; 18c18; < recalibration_report /Users/akiezun/IdeaProjects/hellbender/gatk3.pre.cols.table; ---; > recalibration_report null; ```. Which is expected because GATK4 does not know that a pre table was used. Integration test coming shortly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/322#issuecomment-94605868:1459,Integrat,Integration,1459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/322#issuecomment-94605868,1,['Integrat'],['Integration']
Integrability,this is pretty scary looking code and it's not tied with the dataflow 'walker' interface and so i'm assuming it's just a temporary step to putting all of this in and start refactoring. fine to live in the dev package for now. It will show up on the commandline though - maybe we need a way to hide those dev tools. ; @droazen your turn,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/523#issuecomment-103708285:79,interface,interface,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/523#issuecomment-103708285,1,['interface'],['interface']
Integrability,"this is the initial port of the Allele Specific annotation for HaplotypeCaller. It mostly focuses on the GVCF mode (ie outputs the 'raw' data). I have a branch in protected https://github.com/broadinstitute/gatk-protected/tree/ak_haplotypecaller_allele_specific_annotations that uses those and I verified that the annotations are correctly output and their values are much closer that before to those from GATK3.5. I did not port any code related to combining the annotations in GenotypeGVCFs or CombinedGVCFs etc. Also, no code for VariantAnnotator or UnifiedGenotyper was ported - gatk4 does not have those tools right now. @droazen can you review? Sorry, this is a whole bunch of code and it's not the final version yet (in particular, little effort was put into redesigning the framework - that will wait until we have integration tests so we can keep the results stable while improving design and code). We also need to add tickets to:; - turn dithering off/on in RankSum tests (it's always off for now to simplify testing); - use AlleleSpecific annotations in the VCF mode; - (later) port code for combining annotations",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1825:823,integrat,integration,823,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1825,1,['integrat'],['integration']
Integrability,"this should fix #3724, I've tested it locally by building a maven project with the following pom; ```; <project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""; xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"">; <modelVersion>4.0.0</modelVersion>; <groupId>org.broadinstitute</groupId>; <artifactId>gatk-downstream-test</artifactId>; <packaging>jar</packaging>; <version>1.0-SNAPSHOT</version>; <name>gatk-downstream-test</name>; <url>http://maven.apache.org</url>; <repositories>; <repository>; <snapshots />; <id>snapshots</id>; <name>libs-snapshot</name>; <url>https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot</url>; </repository>; </repositories>; <dependencies>; <dependency>; <groupId>org.broadinstitute</groupId>; <artifactId>gatk</artifactId>; <version>4.beta.6-15-g62e339f-SNAPSHOT</version>; </dependency>; <dependency>; <groupId>junit</groupId>; <artifactId>junit</artifactId>; <version>3.8.1</version>; <scope>test</scope>; </dependency>; </dependencies>; </project>; ```. This didn't build correctly with the current gatk, but builds with this patch, (note that the snapshot version will be different if you download and build this yourself). @Vzzarr Is it possible for you to build this locally and test it with your project?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3742#issuecomment-339059340:760,depend,dependencies,760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3742#issuecomment-339059340,6,['depend'],"['dependencies', 'dependency']"
Integrability,this solves a nasty precision issue in the HaplotypeCaller integration tests where tests would pass or fail depending on the order in which they ran!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1764:59,integrat,integration,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1764,2,"['depend', 'integrat']","['depending', 'integration']"
Integrability,this ticket is done. https://github.com/broadinstitute/gatk-native-bindings is the set of interfaces and IntelGKL is the library that contains the Intel native code. Our build scripts are updated. GKL will move to maven central but that's not a gatk work item.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-224288335:90,interface,interfaces,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-224288335,1,['interface'],['interfaces']
Integrability,ticks): Executor task launch worker-4. Interpreted + native Method ; 0.1% 0 + 8 java.io.UnixFileSystem.delete0; 0.0% 7 + 0 org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1$$anonfun$12$$anonfun$apply$4.apply$mcV$sp; 0.0% 0 + 6 java.net.Inet6AddressImpl.lookupAllHostAddr; 0.0% 0 + 6 java.util.zip.Deflater.deflateBytes; 0.0% 6 + 0 org.apache.spark.util.collection.TimSort.sort; 0.0% 5 + 0 org.apache.spark.util.collection.TimSort$SortState.mergeHi; 0.0% 0 + 4 java.net.SocketInputStream.socketRead0; 0.0% 4 + 0 org.apache.spark.util.collection.ExternalSorter.insertAll; 0.0% 4 + 0 org.apache.spark.util.collection.TimSort$SortState.mergeLo; 0.0% 2 + 0 com.twitter.chill.ScalaCollectionsRegistrar.apply; 0.0% 0 + 1 java.net.PlainSocketImpl.socketAvailable; 0.0% 0 + 1 java.lang.Class.getDeclaredMethods0; 0.0% 0 + 1 java.io.FileOutputStream.writeBytes; 0.0% 1 + 0 java.nio.HeapCharBuffer.<init>; 0.0% 1 + 0 java.nio.HeapIntBuffer.<init>; 0.0% 1 + 0 org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto.newBuilder; 0.0% 1 + 0 java.util.IdentityHashMap$Values.size; 0.0% 1 + 0 org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.<clinit>; 0.0% 1 + 0 org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto.<clinit>; 0.0% 1 + 0 org.bdgenomics.adam.models.SingleReadBucketSerializer.<init>; 0.0% 1 + 0 java.util.regex.Pattern$Branch.<init>; 0.0% 1 + 0 hbparquet.hadoop.util.ContextUtil.getConfiguration; 0.0% 1 + 0 sun.reflect.generics.visitor.Reifier.reifyTypeArguments; 0.0% 1 + 0 scala.collection.immutable.Map$Map3.<init>; 0.0% 1 + 0 sun.reflect.ByteVectorImpl.trim; 0.6% 62 + 27 Total interpreted (including elided). Compiled + native Method ; 9.5% 1441 + 0 com.ning.compress.lzf.impl.UnsafeChunkEncoderLE.tryCompress; 2.0% 304 + 0 htsjdk.samtools.util.BlockCompressedOutputStream.write; 1.8% 275 + 0 com.ning.compress.lzf.impl.UnsafeChunkDecoder.decodeChunk; 1.2% 176 + 2 htsjdk.samtools.BinaryTag,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1702#issuecomment-210127581:1524,protocol,protocol,1524,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1702#issuecomment-210127581,1,['protocol'],['protocol']
Integrability,"tionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 5.0 failed 1 times, most recent failure: Lost task 1.0 in stage 5.0 (TID 12, localhost, executor driver): java.util.Conc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:7027,Message,MessageHubBackedObjectConnection,7027,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,"tionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that severa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:5336,Message,MessageHubBackedObjectConnection,5336,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,titute.hellbender.engine.FeatureDataSource.getTribbleFeatureReader(FeatureDataSource.java:383); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:335); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:222); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6578:3893,wrap,wrapAndCopyInto,3893,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6578,1,['wrap'],['wrapAndCopyInto']
Integrability,titute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.WellformedReadFilter.test(WellformedReadFilter.java:77); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.lambda$getReads$e4b35a40$1(GATKSparkTool.java:213); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool$$Lambda$93/2063469002.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.rdd,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:2100,Wrap,Wrappers,2100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['Wrap'],['Wrappers']
Integrability,titute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:137); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:113); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:496); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:387); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:918); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-391421032:6741,wrap,wrapAndCopyInto,6741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-391421032,1,['wrap'],['wrapAndCopyInto']
Integrability,titute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:566); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$2(HaplotypeCallerSpark.java:253); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark$$Lambda$312.00000000EC650830.apply(Unknown Source); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:278); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1823); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:305); at java.util.stream.StreamSpliterators$WrappingSpliterator$$Lambda$314.00000000EC651070.getAsBoolean(Unknown Source); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:217); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:180); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:311); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:692); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:957); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:948); at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:888); at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:948); at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:694); at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334); at org.apache.spark.rdd.RDD.iterator(RDD.scala:285); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4265:2075,Wrap,WrappingSpliterator,2075,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4265,1,['Wrap'],['WrappingSpliterator']
Integrability,"tiveCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/12/21 13:13:16 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 18/12/21 13:13:19 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; [Stage 0:> (0 + 2) / 155]18/12/21 13:13:57 WARN scheduler.TaskSetManager: Lost task 10.0 in stage 0.0 (TID 1, scc-q15.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 2485550, span 40026, expected MD5 106b97c463c8a19ce0f92bbd488ac81d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.r",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:4981,Wrap,Wrappers,4981,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['Wrap'],['Wrappers']
Integrability,"to validate inputs. (#7845); - Compute filter scatter [VS-392] (#7852); - remove withdrawn req (#7844); - Improve import error message [VS-437] (#7855); - Fix Input Validation python notebook (#7853); - Add VAT Validation check that aa_change and exon_number are consistently set. (#7850); - Ingest 10K [VS-344] (#7860); - X/Y chromosome reweighting for better extract shard runtime balance [VS-389] (#7868); - VET Ingest Validation / Allow Ingest of non-VQSR'ed data (#7870); - Fix AoU workflow bugs (#7874); - Curate input arrays to skip already ingested sample data [VS-246] (#7862); - KM upload GVS product sheet (#7883); - Default extract scatter width [VS-415] (#7878); - Volatile tasks review [VS-447] (#7880); - Update Quickstart Integration for X/Y scaling changes [VS-464] (#7881); - clean up dockstore; - Rc vs 63 vat sop documentation (#7879); - Fix up FQ and race condition issues with volatile tasks work [VS-478] (#7888); - Use gvs-internal project in integration test (#7901); - Add cost observability BQ table [VS-441] (#7891); - Add preliminary labels to queries [VS-381] (#7902); - Workflow compute costs [VS-472] (#7905); - Fix bug and update images (#7912); - VS 483 Beta user wdl (#7894); - Core storage model cost [VS-473] (#7913); - Update Quickstart & Integration to use re-blocked v2 gVCFs [VS-491] (#7924); - KM GVS documentation (#7903); - Track BigQuery costs of GVS python VS-480 (#7915); - Read cost observability table [VS-475] (#7923); - Fix Race Condition, Add Support for Extract by Array of Sample Names (ie from a Sample Set) (#7917); - Rightsize import batches [VS-486] (#7925); - [AoU DRC] Support uppercase site_ids for reblocking (#7929); - Populate cost metadata for GATK tasks. (#7919); - remove accidentally added input (#7931); - VS_492 - Beta User Jar release (#7934); - Cost WDL should throw on FISS API errors [VS-518] (#7942); - Fix bad check for missing workflow name [VS-520] (#7943); - Remove usage of service account from GvsValidateVAT.wdl (#7937",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:25190,Integrat,Integration,25190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,6,"['Integrat', 'integrat']","['Integration', 'integration']"
Integrability,to(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:504); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:399); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:109); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:107); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:994); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886:2186,wrap,wrapAndCopyInto,2186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886,1,['wrap'],['wrapAndCopyInto']
Integrability,"too long (225) at position chr1:10178; skipping that record. Set --reference_window_stop >= 225 ; INFO 10:49:23,200 LeftAlignAndTrimVariants - Reference allele is too long (221) at position chr1:10213; skipping that record. Set --reference_window_stop >= 221 ; INFO 10:49:23,201 LeftAlignAndTrimVariants - Reference allele is too long (223) at position chr1:10218; skipping that record. Set --reference_window_stop >= 223 ; INFO 10:49:23,203 LeftAlignAndTrimVariants - Reference allele is too long (212) at position chr1:10229; skipping that record. Set --reference_window_stop >= 212 ; INFO 10:49:23,203 LeftAlignAndTrimVariants - Reference allele is too long (216) at position chr1:10231; skipping that record. Set --reference_window_stop >= 216 ; INFO 10:49:23,205 LeftAlignAndTrimVariants - Reference allele is too long (204) at position chr1:10237; skipping that record. Set --reference_window_stop >= 204 ; INFO 10:49:23,205 LeftAlignAndTrimVariants - Reference allele is too long (209) at position chr1:10238; skipping that record. Set --reference_window_stop >= 209 ; INFO 10:49:23,208 LeftAlignAndTrimVariants - Reference allele is too long (204) at position chr1:10254; skipping that record. Set --reference_window_stop >= 204 ; INFO 10:49:23,214 LeftAlignAndTrimVariants - Reference allele is too long (207) at position chr1:10276; skipping that record. Set --reference_window_stop >= 207 ; 0 variants were aligned; INFO 10:49:23,402 ProgressMeter - done 638.0 0.0 s 10.6 m 0.0% 0.0 s 0.0 s ; INFO 10:49:23,402 ProgressMeter - Total runtime 0.41 secs, 0.01 min, 0.00 hours ; ------------------------------------------------------------------------------------------; Done. There were 1 WARN messages, the first 1 are repeated below.; WARN 10:49:22,065 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091:4464,message,messages,4464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091,1,['message'],['messages']
Integrability,tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotations(GencodeFuncotationFactory.java:487); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotations(GencodeFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:387); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:316); at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hel,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385021157:9110,wrap,wrapAndCopyInto,9110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385021157,1,['wrap'],['wrapAndCopyInto']
Integrability,"tps://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-252258477). I don't have special privileges on the cloud...requests like this need to; go through pipeline-help...sorry. Y. On Fri, Oct 7, 2016 at 9:08 AM, ldgauthier notifications@github.com wrote:. > I don't know what intermediates we save on the cloud but maybe @yfarjoun; > https://github.com/yfarjoun is willing to help.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-252247496,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0lAsJd9NECpPP0JYVp2ziDhga0B9ks5qxkRUgaJpZM4KQT_3; > . ---. @vdauwera commented on [Wed Oct 26 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-256499771). Writing pipeline-help now and cc'ing everyone involved in this thread. Will try to get some kind of protocol set up for debugging things that happen in the cloud pipeline, because I expect this will happen again. But if it gets too complicated we could also mock up some fake records that would reproduce this. It seems to me that shouldn't be too hard. . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-260498705). I need to ping Daniel on getting access to the files. ---. @ronlevine commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275576931). @vdauwera Can you get the data? I can take a look a this issue. ---. @vdauwera commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275578721). Oh, they gave me access to the files but I never took the next step of figuring out which files are relevant. There are twenty thousand samples... I'm not sure what is the best way to approach this. ---. @ldgauthier commented on [Wed Mar 01 2017](https://github.com/broadinsti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2959:2563,protocol,protocol,2563,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2959,1,['protocol'],['protocol']
Integrability,"tps://github.com/protocolbuffers/protobuf/commit/4728531c162f2f9e8c2ca1add713cfee2db6be3b""><code>4728531</code></a> Add recursion check when parsing unknown fields in Java.</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/850fcce9176e2c9070614dab53537760498c926b""><code>850fcce</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b7044987de77f1dc368fee558636d0b56d7e75e1""><code>b704498</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/e67347986eaf7d777a6ee34367fa99f4912423ab""><code>e673479</code></a> Fix cord handling in DynamicMessage and oneofs. (<a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/18375"">#18375</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/8a60b6527a976cfd0028153da3ad8e4ed280e0de""><code>8a60b65</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.23.4...v3.25.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <su",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:2004,protocol,protocolbuffers,2004,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,2,['protocol'],['protocolbuffers']
Integrability,tractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:94); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:517); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:151); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:170); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:74); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:65); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:69); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:148); ... 49 more; Caused by: java.nio.channels.ClosedChannelException; at sun.nio.ch.FileChannelImpl.ensureOpen(FileChannelImpl.java:109); at sun.nio.ch.FileChannelImpl.position(FileChannelImpl.java:252); at htsjdk.samtools.seekablestream.SeekableFileStream.position(SeekableFileStream.java:64); at htsjdk.tribble.TribbleIndexedFeatureReader$BlockStreamWrapper.read(TribbleIndexedFeatureReader.java:534); at java.io.InputStream.read(InputStream.java:101); at htsjdk.tribble.readers.PositionalBufferedStream.fill(PositionalBufferedStream.java:127); at htsjdk.tribble.readers.PositionalBufferedStream.read(PositionalBufferedStream.java:79); at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284); at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326); at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178); at java.io.InputStreamReader.read(InputStreamReader.java:184); at htsjdk.tribble.readers.LongLineBufferedReader.fill(LongLineBuffe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:8196,Integrat,IntegrationTestSpec,8196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,1,['Integrat'],['IntegrationTestSpec']
Integrability,tractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:94); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:517); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:151); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:170); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:74); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:65); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:69); at org.broadinstitute.hellbender.utils.test.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:148); ... 49 more; Caused by: java.nio.channels.ClosedChannelException; at sun.nio.ch.FileChannelImpl.ensureOpen(FileChannelImpl.java:109); at sun.nio.ch.FileChannelImpl.position(FileChannelImpl.java:252); at htsjdk.samtools.seekablestream.SeekableFileStream.position(SeekableFileStream.java:64); at htsjdk.tribble.TribbleIndexedFeatureReader$BlockStreamWrapper.read(TribbleIndexedFeatureReader.java:534); at java.io.InputStream.read(InputStream.java:101); at htsjdk.tribble.readers.PositionalBufferedStream.fill(PositionalBufferedStream.java:127); at htsjdk.tribble.readers.PositionalBufferedStream.read(PositionalBufferedStream.java:79); at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284); at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326); at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178); at java.io.InputStreamReader.read(InputStreamReader.java:184); at htsjdk.tribble.readers.LongLineBufferedReader.fill(LongLineBufferedReader.java:140); at ht,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:8228,Integrat,IntegrationTestSpec,8228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,1,['Integrat'],['IntegrationTestSpec']
Integrability,tractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$null$1(FilterFuncotations.java:196) ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$getMatchingFilters$2(FilterFuncotations.java:192) ; at java.base/java.util.HashMap$Values.forEach(HashMap.java:976) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.getMatchingFilters(FilterFuncotations.java:191) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.secondPassApply(FilterFuncotations.java:174) ; at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:19) ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:5261,wrap,wrapAndCopyInto,5261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['wrap'],['wrapAndCopyInto']
Integrability,"travis is now using the gradlew wrapper, which handles this download for us",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/547:32,wrap,wrapper,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/547,1,['wrap'],['wrapper']
Integrability,"true; 13:15:05.204 INFO FuncotatorDataSourceDownloader - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Deflater: IntelDeflater; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Inflater: IntelInflater; 13:15:05.204 INFO FuncotatorDataSourceDownloader - GCS max retries/reopens: 20; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Requester pays: disabled; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Initializing engine; 13:15:05.205 INFO FuncotatorDataSourceDownloader - Done initializing engine; 13:15:05.205 INFO FuncotatorDataSourceDownloader - Germline data sources selected.; 13:15:05.207 INFO FuncotatorDataSourceDownloader - Collecting expected checksum...; 13:19:33.264 INFO FuncotatorDataSourceDownloader - Shutting down engine; [November 18, 2023 1:19:33 PM CST] org.broadinstitute.hellbender.tools.funcotator.FuncotatorDataSourceDownloader done. Elapsed time: 4.48 minutes.; Runtime.totalMemory()=1967128576; code: 0; message: All 3 retries failed. Waited a total of 14000 ms between attempts; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: All 3 retries failed. Waited a total of 14000 ms between attempts; 	at com.google.cloud.storage.contrib.nio.CloudStorageRetryHandler.handleRetryForStorageException(CloudStorageRetryHandler.java:135); 	at com.google.cloud.storage.contrib.nio.CloudStorageRetryHandler.handleStorageException(CloudStorageRetryHandler.java:115); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:253); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.<init>(CloudStorageReadChannel.java:110); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.create(CloudStorageReadChannel.java:90); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newReadChannel(CloudStorageFileSystemProvider.java:390); 	at com.google.cloud.storage.contrib.nio.CloudStorageF",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:2877,message,message,2877,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['message'],['message']
Integrability,"ts and custom serializers (gCNV Spark tests are currently disabled). **Discussion about gCNV ICG unit tests (May 1st, 2017):**; It is possible to automate the test for ComputableNodeFunctions. One initializes the parents to random values, calls the function, and checks whether it has had any side effects on the parents. One must make a random-data-provider-of-some-sort for each parent node because the parent INDArrays have different shapes. For other functions in CoverageModelEMComputeBlock and CoverageModelEMWorkspace that query ICG nodes -- one needs to create a firewall. One can elevate all such functions to classes that essentially behave functionally, (ICGNodeProvider, List<NodeKey>, extra arguments) -> output, as opposed to writing vanilla member functions such as CoverageModelEMComputeBlock.getBiasLatentPosteriorDataUnregularized, etc. Then we can write automated unit tests for these classes. Another approach is to write a thin ImmutableNDArray interface that blocks access to all mutators and returns instances of ImmutableNDArray when a matrix view is extracted (e.g. via INDArray.get(...)). This is also quite non-trivial and requires intimate familiarity with Nd4j codebase. Perhaps one could write an immutable DataBuffer for Nd4j. Finally, there might be a brute-force approach: substitute all in-plane operations such as muli and addi with mul and add, and in-place transformations such as Transforms.log(INDArray, boolean duplicate) with Transforms.log(INDArray, true), run gCNV, and require identical results. This is the easiest approach. This was my approach during the development. First, I wrote every function without in-place operations, ran the code, optimized the function with in-place ops, ran the code again, assert. If we can automate this sort of thing, it is the easiest way out. For the time being, I annotate all functions that can potentially mutate the ICG with @QueriesICG to finally decide how we'd like to proceed. I also made a TODO for writing suc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2929:1991,interface,interface,1991,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2929,1,['interface'],['interface']
Integrability,tsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:569); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:27); at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:13); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:89); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.ma,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631:3417,wrap,wrapAndCopyInto,3417,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631,1,['wrap'],['wrapAndCopyInto']
Integrability,"tually tried it, before putting in the above comment, and quickly ran into the problem of mixing Java serialization and Kryo serialization, so a larger re-structuring might be needed, and not just a inheritance structure). ------------; ### On the problem of having a confusing TODO for ; `boolean SimpleChimera.isCandidateInvertedDuplication()`. The todo message. > TODO: 5/5/18 Note that the use of the following predicate is currently obsoleted by; {@link AssemblyContigWithFineTunedAlignments#hasIncompletePictureFromTwoAlignments()}; because the contigs with this alignment signature is classified as ""incomplete"",; hence will NOT sent here for constructing SimpleChimera's.; But we may want to keep the code (and related code in BreakpointComplications) for future use. Comment by @cwhelan ; > I'm a bit confused by this comment: this method is still being called in several places, so how is it obsolete?. Reply by @SHUANG-Broad (also copied to update the ""TODO"" message; > this predicate is currently used in two places (excluding appearance in comments): `BreakpointComplications.IntraChrStrandSwitchBreakpointComplications`, where it is use to test if the input simple chimera indicates an inverse tandem duplication and trigger the logic for inferring duplicated region; and `BreakpointsInference.IntraChrStrandSwitchBreakpointInference`, where it is used for breakpoint inference. The problem is, the contig will not even be sent here, because `AssemblyContigWithFineTunedAlignments.hasIncompletePictureFromTwoAlignments()` defines a simple chimera that has strand switch and the two alignments overlaps on reference as ""incomplete"", so in practice the two uses are not going to be triggered. But when we come back later and see what can be extracted from such ""incomplete"" contigs, these code could be useful again. So it is kept. ------------; ### On the problem of writing out SAM records of ""Unknown"" contigs efficiently. First round comment by @cwhelan ; > This seems like a very inef",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030:2748,message,message,2748,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030,1,['message'],['message']
Integrability,tute.hellbender.Main.main(Main.java:233); ```; and ; ```; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Host is down (connect failed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCrede,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:4327,protocol,protocol,4327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235,1,['protocol'],['protocol']
Integrability,tute.hellbender.engine.FeatureDataSource.getCodecForFea; tureInput(FeatureDataSource.java:324); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:304); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:256); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:230); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:214); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855:2937,wrap,wrapAndCopyInto,2937,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855,1,['wrap'],['wrapAndCopyInto']
Integrability,tute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:131); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:106); at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:163); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:21,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6340:5099,wrap,wrapAndCopyInto,5099,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6340,1,['wrap'],['wrapAndCopyInto']
Integrability,tute.hellbender.tools.walkers.annotator.VariantAnnotator.makeLikelihoods(VariantAnnotator.java:244) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:234) ; ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133) ; ; at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ; ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497) ; ; at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211) ; ; at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160) ; ; at org.broadinstitute.h,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6915:1974,wrap,wrapAndCopyInto,1974,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6915,1,['wrap'],['wrapAndCopyInto']
Integrability,tute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:263); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:979); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$assemblyFunction$0(HaplotypeCallerSpark.java:179); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197); 	at java.base/java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1856); 	at java.base/java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:292); 	at java.base/java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.base/java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.base/java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:298); 	at java.base/java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$ConcatenatedIterator.getTopMetaIterator(Iterators.java:1379); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$ConcatenatedIterator.hasNext(Iterators.java:1395); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.fillCache(PushToPullIterator.java:71); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.advanceToNextElement(PushToPullIterator.java:58); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.(PushToPullIterator.java:37); 	at org.broadinstitute.hellbender.utils.variant.writers.GVCFBlockCombiningIterator.(GVCFBlockCombiningIterator.java:14); 	at org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSink.lambda$writeVariantsSingle$516343c4$1(VariantsSparkSink.java:127),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8961:2012,Wrap,WrappingSpliterator,2012,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8961,1,['Wrap'],['WrappingSpliterator']
Integrability,tute.hellbender.tools.walkers.vqsr.CNNScoreVariants.sendBatchIfReady(CNNScoreVariants.java:416); 	at org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants.firstPassApply(CNNScoreVariants.java:336); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:17); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147:2227,wrap,wrapAndCopyInto,2227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147,1,['wrap'],['wrapAndCopyInto']
Integrability,tute.hellbender.utils.QualityUtils.errorProbToQual(QualityUtils.java:211); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyContaminationFilter(Mutect2FilteringEngine.java:79); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:518); at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:130); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverseVariants(TwoPassVariantWalker.java:74); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverse(TwoPassVariantWalker.java:27); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821:1923,wrap,wrapAndCopyInto,1923,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821,1,['wrap'],['wrapAndCopyInto']
Integrability,tute/gatk/actions/runs/5906500357); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [5906500357.10](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16022649132) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.10/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [5906500357.12](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16022649351) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5906500357.11](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16022649238) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.11/tests/testOnPackagedReleaseJar/index.html) |; | conda | 17.0.6+10 | [5906500357.3](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16023343655) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.3/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [5906500357.1](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16023343343) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.1/tests/testOnPackagedReleaseJar/index.html) |; | variantcalling | 17.0.6+10 | [5906500357.2](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16023343497) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.2/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5906500357.0](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16023343147) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684393146:1840,integrat,integration,1840,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684393146,1,['integrat'],['integration']
Integrability,tute/gatk/actions/runs/5906807871); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [5906807871.10](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16023558278) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.10/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [5906807871.12](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16023558558) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5906807871.11](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16023558444) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [5906807871.1](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16024178952) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.1/tests/testOnPackagedReleaseJar/index.html) |; | conda | 17.0.6+10 | [5906807871.3](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16024179175) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.3/tests/testOnPackagedReleaseJar/index.html) |; | variantcalling | 17.0.6+10 | [5906807871.2](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16024179060) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.2/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5906807871.0](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16024178803) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684420305:1840,integrat,integration,1840,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684420305,1,['integrat'],['integration']
Integrability,twork is unreachable: connect; 	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method); 	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); 	at com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); 	at com.google.auth.oauth2,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:13786,protocol,protocol,13786,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,3,['protocol'],['protocol']
Integrability,"ty to actually address this issue is to dynamically reduce the number of alt alleles loosing the less likely ones base on a maximum number of possible genotypes. So the user does not indicate the maximum number of alternative but the maximum number of genotypes. Which alt. alleles make it could be decided by taking a look in the corresponding hom. alt genotype likelihood dropping those alternatives with the worst hom. PLs. ---. @vdauwera commented on [Tue Mar 10 2015](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-78122186). @vruano What you propose sounds great. How much work would it take to implement this? . ---. @vruano commented on [Mon Mar 23 2015](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-85066881). Looking into that particular use case... the problem seem to be in position:. 45SrDNA_Jacobsen 9283. That seems to be very polymorphic or noisy even within individual samples, to the point that many lack PLs so perhaps merging would not work or at least the exact model depending annotations (QUAL column and MLEAC/F format field) cannot be updated based on them... I think that best way to move forward here is:; 1. Lift up that maximum number of Genotypes to output PLs based on the ploidy parameter (I think the limit was quite modest perhaps as low as 20).; 2. Implement the alt. allele `culling` or `collapsing` that I mention above in HaplotypeCaller already. ; 3. Implement the alt. allele `re-culling` or `re-collapsing` in GVCF (VCF as well?) merging tools such as CombineGVCFs/GenotypeGVCFs.; 4. Regenotyping and QUAL recalculating tools would need to make sure that PLs less input are handled appropriately, not sure what would happen now if some of the inputs lack PLs... (an Exception?) ; - For example QUAL could be approximated as the max of the input Quals, and QD as the average? ; - Or simple lift them blank?. So it would a bit of work I would say... 3 of the old PTs worth. ---. @vdauwera commented on [Thu May 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2955:2334,depend,depending,2334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2955,1,['depend'],['depending']
Integrability,typerEngine.finalizeGenotype(GnarlyGenotyperEngine.java:147); 	at org.broadinstitute.hellbender.tools.walkers.gnarlyGenotyper.GnarlyGenotyperEngine.finalizeGenotype(GnarlyGenotyperEngine.java:78); 	at org.broadinstitute.hellbender.tools.walkers.gnarlyGenotyper.GnarlyGenotyper.apply(GnarlyGenotyper.java:298); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7483:3502,wrap,wrapAndCopyInto,3502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7483,1,['wrap'],['wrapAndCopyInto']
Integrability,typingEngine.java:296); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:210); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:565); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1(HaplotypeCallerSpark.java:271); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); [2018-04-15T03:55Z] ip-10-0-0-57: 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); [2018-04-15T03:55Z] ip-10-0-0-57: 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); [2018-04-15T03:55Z] ip-10-0-0-57: 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1038); [2018-04-15T03:55Z,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661:3441,Wrap,WrappingSpliterator,3441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661,1,['Wrap'],['WrappingSpliterator']
Integrability,uVGVzdC5qYXZh) | `90.909% <0%> (-0.758%)` | `5% <0%> (ø)` | |; | [...ellbender/tools/walkers/vqsr/CNNScoreVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/6017/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50cy5qYXZh) | `79.736% <0%> (-0.709%)` | `45% <0%> (ø)` | |; | [...ls/walkers/varianteval/util/EvaluationContext.java](https://codecov.io/gh/broadinstitute/gatk/pull/6017/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnRldmFsL3V0aWwvRXZhbHVhdGlvbkNvbnRleHQuamF2YQ==) | `75.676% <0%> (-0.64%)` | `12% <0%> (ø)` | |; | [...te/hellbender/utils/runtime/ProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/6017/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `56.338% <0%> (-0.606%)` | `8% <0%> (ø)` | |; | [...der/utils/solver/SynchronizedUnivariateSolver.java](https://codecov.io/gh/broadinstitute/gatk/pull/6017/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvU3luY2hyb25pemVkVW5pdmFyaWF0ZVNvbHZlci5qYXZh) | `81.609% <0%> (-0.413%)` | `11% <0%> (ø)` | |; | [...ools/walkers/haplotypecaller/graphs/TestGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/6017/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvVGVzdEdyYXBoLmphdmE=) | `89.286% <0%> (-0.369%)` | `6% <0%> (ø)` | |; | [...spark/sv/utils/SingleSequenceReferenceAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/6017/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TaW5nbGVTZXF1ZW5jZVJlZmVyZW5jZUFsaWduZXIuamF2YQ==) | `80.556% <0%> (-0.266%)` | `16% <0%> (ø)` | |; | [...gine/spark/datasources/ReadsSparkSinkUnitTest.java](https://codecov.io/gh/broadins,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-506021220:2740,Synchroniz,SynchronizedUnivariateSolver,2740,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-506021220,1,['Synchroniz'],['SynchronizedUnivariateSolver']
Integrability,ual_AS-167622_Sample_AS-167622.merged.vcf.gz; at htsjdk.variant.vcf.AbstractVCFCodec.decodeLine(AbstractVCFCodec.java:281); at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:262); at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:64); at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:70); at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:37); at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.readNextRecord(TribbleIndexedFeatureReader.java:365); at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:346); at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:307); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4255:1842,wrap,wrapAndCopyInto,1842,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4255,1,['wrap'],['wrapAndCopyInto']
Integrability,"uent; at least 10 samples must have called genotypes; 13:41:00.528 INFO ProgressMeter - unmapped 0.0 37 4277.5; 13:41:00.528 INFO ProgressMeter - Traversal complete. Processed 37 total variants in 0.0 minutes.; 13:41:00.580 INFO GenotypeGVCFs - Shutting down engine; [October 26, 2023 at 1:41:00 PM CEST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=285212672; ```; ```; ##source=HaplotypeCaller; ##bcftools_viewVersion=1.16+htslib-1.16; ##bcftools_viewCommand=view -c1 output.vcf; Date=Thu Oct 26 13:41:08 2023; ##bcftools_annotateVersion=1.16+htslib-1.16; ##bcftools_annotateCommand=annotate -x INFO,FORMAT/SB,FORMAT/PL; Date=Thu Oct 26 13:41:08 2023; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT CGAAGAGGTAGGTGCGAG-1; chr19 55910646 . AC A 352.6 . . GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9:15:99:0|1:55910646_AC_A:55910646; chr19 55910648 . AAATCCCCC A 352.6 . . GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9:15:99:0|1:55910646_AC_A:55910646; chr19 55910653 . CCCCAT *,C 227.84 . . GT:AD:DP:GQ:PGT:PID:PS 1|2:0,9,6:15:99:1|0:55910646_AC_A:55910646; chr19 55910675 . T C 30.64 . . GT:AD:DP:GQ 0/1:13,2:15:38; ```. The relevant parts of the output. HaplotypeCaller:; ```; chr19 55910648 AAATCCCCC A,<NON_REF> GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9,0 :15:99:0|1:55910646_AC_A:55910646; chr19 55910653 CCCCAT *,C,<NON_REF> GT:AD:DP:GQ:PGT:PID:PS 2|1:0,9,6,0:15:99:1|0:55910646_AC_A:55910646; ```; GenotypeGVCFs:; ```; chr19 55910648 AAATCCCCC A GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9 :15:99:0|1:55910646_AC_A:55910646; chr19 55910653 CCCCAT *,C GT:AD:DP:GQ:PGT:PID:PS 1|2:0,9,6 :15:99:1|0:55910646_AC_A:55910646; ```. I understand that; - PID/PGT can only encode phasing for biallelic variants, ; - so PID/PGT + unphased GT can not be used to infer the correctly phased GT in general; - but only (and only maybe) in this case PID/PGT + wrongly phased GT can be used to infer the correctly phased GT (because the mangeling of the GT might depend on PGT). is this correct?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195:21567,depend,depend,21567,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195,1,['depend'],['depend']
Integrability,"uest <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/18387"">#18387</a> from protocolbuffers/cp-lp-25</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b5a7cf7cf4b7e39f6b02205e45afe2104a7faf81""><code>b5a7cf7</code></a> Remove RecursiveGroup test case which doesn't exist in 25.x pre-Editions</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/f000b7e18fd6921ca02ea4b87608e8cadcb7b64f""><code>f000b7e</code></a> Fix merge conflict by adding optional label to proto2 unittest_lite.proto</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/4728531c162f2f9e8c2ca1add713cfee2db6be3b""><code>4728531</code></a> Add recursion check when parsing unknown fields in Java.</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/850fcce9176e2c9070614dab53537760498c926b""><code>850fcce</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b7044987de77f1dc368fee558636d0b56d7e75e1""><code>b704498</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/e67347986eaf7d777a6ee34367fa99f4912423ab""><code>e673479</code></a> Fix cord handling in DynamicMessage and oneofs. (<a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/18375"">#18375</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/8a60b6527a976cfd0028153da3ad8e4ed280e0de""><code>8a60b65</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.23.4...v3.25.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dep",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:1422,protocol,protocolbuffers,1422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,1,['protocol'],['protocolbuffers']
Integrability,"ufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 719847424 bytes for committing reserved memory.; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid11513.log; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f27ebfe7d9a, pid=11455, tid=0x00007f27e87e5700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libfml.6198146539708364717.jnilib+0xed9a] rld_itr_init+0x4a; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fd2680a350c, pid=11685, tid=0x00007fd2b02bf700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libbwa.5694772191018335324.jnilib+0x850c] bwa_mem2idx+0xcc; ```. The underlying issue in these cases is likely either ""out of memory"" or, perhaps in the case of the seg faults, ""file not found"" or ""malformed file"", but we could greatly improve our ability to interpret Travis failures if we were more careful about checking return values from system calls. Eg., in the function below from the BWA bindings we could check the return values of the `mmap()` and `calloc()` calls, and die with an appropriate error message if they fail:. ```; bwaidx_t* jnibwa_openIndex( int fd ) {; struct stat statBuf;; if ( fstat(fd, &statBuf) == -1 ) return 0;; uint8_t* mem = mmap(0, statBuf.st_size, PROT_READ, MAP_SHARED, fd, 0);; close(fd);; bwaidx_t* pIdx = calloc(1, sizeof(bwaidx_t));; bwa_mem2idx(statBuf.st_size, mem, pIdx);; pIdx->is_shm = 1;; mem_fmt_fnc = &fmt_BAMish;; bwa_verbose = 0;; return pIdx;; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3209:2317,message,message,2317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209,1,['message'],['message']
Integrability,ug Report. ### Affected tool(s) or class(es); ReadsPipelineSpark. ### Affected version(s); - [x] Latest public release version 4.1.0.0; - [ ] Latest master branch as of [date of test?]. ### Description . ```; java.lang.IllegalArgumentException: Interval NC_007605:1-171823 not within the bounds of a contig in the provided dictionary; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.engine.Shard.divideIntervalIntoShards(Shard.java:87); 	at org.broadinstitute.hellbender.engine.Shard.divideIntervalIntoShards(Shard.java:66); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.lambda$runTool$0(ReadsPipelineSpark.java:221); 	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.runTool(ReadsPipelineSpark.java:222); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:528); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5644:988,wrap,wrapAndCopyInto,988,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5644,1,['wrap'],['wrapAndCopyInto']
Integrability,ugly message on missing input file,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1297:5,message,message,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1297,1,['message'],['message']
Integrability,update error message when sample name in VCF cannot be looked up in sampleMap.tsv,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7074:13,message,message,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7074,1,['message'],['message']
Integrability,"updated shadowJar to 1.2.3 since version 1.2.2 of the shadowJar plugin had some issues with gradle ; 2.11 which just released. some `build.gradle` cleanup; - removed dependency on `lib/tools.java` since it doesn't seem to be used and should be provided by the system anyway; - removed individual excludes of `guava-jdk5` since we exclude them globally; - changed our plugin application to use the newer style; - updated jacoco, coverals, and versions plugin versions; - added group and description to sparkJar task so it shows up in `gradle tasks`; - updated gradle wrapper version to 2.11; - readme now states 2.11 as minimum version",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1478:166,depend,dependency,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1478,2,"['depend', 'wrap']","['dependency', 'wrapper']"
Integrability,updating GenomicsDB integration to match the changes in the importer,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2626:20,integrat,integration,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2626,1,['integrat'],['integration']
Integrability,updating Intel-GKL dependency to 8.6,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5463:19,depend,dependency,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5463,1,['depend'],['dependency']
Integrability,"updating bams, sams, and cram to sam spec version 1.5 (some invalid bams were not updated); updated interval list headers for bed tests from v 1.4 - 1.5; updating several tests to give a better error message if an index IS present when it's expected to not be",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/763:200,message,message,200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/763,1,['message'],['message']
Integrability,updating dataflow and htsjdk to newest versions; adding gradle versions plugin to help with identifying dependencies that need updates. This broke one of our spark related tests so I've excluded it for now. See #581. It should be reeneabled when https://github.com/cloudera/spark-dataflow/issues/49 is complete.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/582:104,depend,dependencies,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/582,1,['depend'],['dependencies']
Integrability,updating dependencies,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/219:9,depend,dependencies,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/219,2,['depend'],['dependencies']
Integrability,updating dependencies to current version,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/495:9,depend,dependencies,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/495,1,['depend'],['dependencies']
Integrability,"updating gradlew wrapper to newer gradle, 2.7",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/941:17,wrap,wrapper,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/941,1,['wrap'],['wrapper']
Integrability,updating htsjdk and picard dependencies; htsjdk 2.13.1 -> 2.13.2; picard 2.14.0 -> 2.16.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3962:27,depend,dependencies,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3962,1,['depend'],['dependencies']
Integrability,updating wrapper from 2.13 -> 3.0. disable daemon on travis since it's now enabled by default and gradle recommends disabling it on CI servers; remove jacoco version specification since 3.0 specifies a reasonable version by default; update the test result html path on travis since it changed in 3.0,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2097:9,wrap,wrapper,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2097,1,['wrap'],['wrapper']
Integrability,upgrade Picard dependency from 2.18.13 -> 2.18.15,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5344:15,depend,dependency,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5344,1,['depend'],['dependency']
Integrability,"upgraded from 1.127 to 1.128; removed the local repo entirely, we now have no non-maven dependencies!. there was a small API change so I updated all those files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/172:88,depend,dependencies,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/172,1,['depend'],['dependencies']
Integrability,upgrading picard dependency from 2.18.1 -> 2.18.2. this way we'll be on the latest release when we start doing MarkDuplicates tieout,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4676:17,depend,dependency,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4676,1,['depend'],['dependency']
Integrability,"ur input file. If I am wrong and this is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (general-use/engine) dependency of ``FilterByOrientationBias`` will try to instantiate a class that does not exist. The ``sed`` was supposed to be temporary until picard was wrapped properly in GATK. But until then, it does mean that all GATK-based downstream dependencies of ``CollectSequencingArtifactMetrics`` will fail without the sed. Again, the fix is not in ``FilterByOrientationBias``. > Also, FilterByOrientationBias does not output bgzipped VCFs. So this is not in line with how GATK tools should work. . ``FilterByOrientationBias`` just farms it out to a VCF Writer. That dependency (VCF Writer) should handle that. Can you confirm, @lbergelson ? Is there an additional step to make this work that I did not know about?. > Again, FilterByOrientationBias is not production worthy and I think at this point it should get an experimental or BETA label. Only because of the ``sed`` nonsense, as near as I can tell. Definitely, BETA -- not experimental. All I'm saying is that I don't believe any code change needs to go into ``FilterByOrientationBias`` (with the possible exception of the bgzip VCF). These issues are all in its dependencies, which a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:2170,wrap,wrapped,2170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143,1,['wrap'],['wrapped']
Integrability,"ureInput;. public CodecWrapper(FeatureCodec<FEATURE_TYPE, SOURCE> childCodec, FeatureInput<FEATURE_TYPE> featureInput); {; this.childCodec = childCodec;; this.featureInput = featureInput;; }. @Override; public Feature decodeLoc(SOURCE source) throws IOException {; return childCodec.decodeLoc(source);; }. @Override; public FEATURE_TYPE decode(SOURCE source) throws IOException {; FEATURE_TYPE feature = childCodec.decode(source);. //Either look for marker class or otherwise poke in FeatureInput here:; if (feature instanceof VariantContext); {; feature = new FeatureInputAwareVariantContext(feature, featureInput);; }. return feature;; }. @Override; public FeatureCodecHeader readHeader(SOURCE source) throws IOException {; return childCodec.readHeader(source);; }. @Override; public Class<FEATURE_TYPE> getFeatureType() {; return childCodec.getFeatureType();; }. @Override; public SOURCE makeSourceFromStream(InputStream bufferedInputStream) {; return childCodec.makeSourceFromStream(bufferedInputStream);; }. @Override; public LocationAware makeIndexableSourceFromStream(InputStream inputStream) {; return childCodec.makeIndexableSourceFromStream(inputStream);; }. @Override; public boolean isDone(SOURCE source) {; return childCodec.isDone(source);; }. @Override; public void close(SOURCE source) {; childCodec.close(source);; }. @Override; public boolean canDecode(String path) {; return childCodec.canDecode(path);; }; }. public static interface FeatureInputAware<FEATURE_TYPE extends Feature>; {; public FeatureInput<FEATURE_TYPE> getFeatureInput();; }. public static class FeatureInputAwareVariantContext extends VariantContext implements FeatureInputAware<VariantContext>; {; private FeatureInput<VariantContext> featureInput;. public FeatureInputAwareVariantContext(VariantContext parent, FeatureInput<VariantContext> featureInput); {; super(parent);; this.featureInput = featureInput;; }. @Override; public FeatureInput<VariantContext> getFeatureInput() {; return featureInput;; }; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823546766:2178,interface,interface,2178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823546766,1,['interface'],['interface']
Integrability,using --version results in a bizarre error message,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1293:43,message,message,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1293,1,['message'],['message']
Integrability,using linked or sorted data structures to reduce our dependency on the arbitrary changes in iterator orders (happens everytime you move from a jvm to another jvm),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1844:53,depend,dependency,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1844,1,['depend'],['dependency']
Integrability,ute.hellbender.tools.funcotator.FilterFuncotations.firstPassApply(FilterFuncotations.java:161) ; ;     at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:17) ; ;     at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; ;     at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77) ; ;     at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ;     at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ; ;     at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133) ; ;     at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ;     at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; ;     at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; ;     at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; ;     at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ; ;     at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ;     at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497) ; ;     at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75) ; ;     at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40) ; ;     at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085) ; ;     at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) ; ;     at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ;     at org.broadinstitute.h,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7865:9682,wrap,wrapAndCopyInto,9682,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7865,1,['wrap'],['wrapAndCopyInto']
Integrability,"utput from chr1. The output shows the Maximum resident set size (kbytes): **2630440**. Using GATK jar /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar defined in environment variable GATK_LOCAL_JAR; ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx200g -Xms16g -jar /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenomicsDBImport --sample-name-map sample_map.chr1 --genomicsdb-workspace-path genomicsDB.rb.bypass.time.chr1 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --bypass-feature-reader --L chr1 --batch-size 50 --reader-threads 4 --overwrite-existing-genomicsdb-workspace; Command being timed: ""gatk --java-options -Xmx200g -Xms16g GenomicsDBImport --sample-name-map sample_map.chr1 --genomicsdb-workspace-path genomicsDB.rb.bypass.time.chr1 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --bypass-feature-reader --L chr1 --batch-size 50 --reader-threads 4 --overwrite-existing-genomicsdb-workspace""; User time (seconds): 270716.45; System time (seconds): 1723.34; Percent of CPU this job got: 99%; Elapsed (wall clock) time (h:mm:ss or m:ss): 76:08:24; Average shared text size (kbytes): 0; Average unshared data size (kbytes): 0; Average stack size (kbytes): 0; Average total size (kbytes): 0; Maximum resident set size (kbytes): 2630440; Average resident set size (kbytes): 0; Major (requiring I/O) page faults: 5; Minor (reclaiming a frame) page faults: 206030721; Voluntary context switches: 11129822; Involuntary context switches: 176522; Swaps: 0; File system inputs: 627981312; File system outputs: 466730160; Socket messages sent: 0; Socket messages received: 0; Signals delivered: 0; Page size (bytes): 4096; Exit status: 0. ```. So using the import on reblocked gvcfs using --bypass-feature-reader was the fastest way to import our 3500 gVCFs and minimize memory.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252598687:3022,message,messages,3022,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252598687,2,['message'],['messages']
Integrability,"utputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:37305,Wrap,Wrappers,37305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"utputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:37057,Wrap,Wrappers,37057,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,va heap space; 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:208); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at org.seqdoop.hadoop_bam.BAMRecordReader.nextKeyValue(BAMRecordReader.java:225); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:182); 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:7118,Wrap,Wrappers,7118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['Wrap'],['Wrappers']
Integrability,va.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1467,Wrap,WrapperExecutor,1467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['Wrap'],['WrapperExecutor']
Integrability,va:260); at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:207); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:436); at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:120); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverseVariants(TwoPassVariantWalker.java:74); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverse(TwoPassVariantWalker.java:27); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5553:2109,wrap,wrapAndCopyInto,2109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553,1,['wrap'],['wrapAndCopyInto']
Integrability,va:260); at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:286); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:519); at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:130); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverseVariants(TwoPassVariantWalker.java:74); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverse(TwoPassVariantWalker.java:27); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLin,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452818901:2485,wrap,wrapAndCopyInto,2485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452818901,1,['wrap'],['wrapAndCopyInto']
Integrability,"vaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-45f7a9f3-b94f-4040-bf32-0dbfe44f8f68; 2019-05-14 17:07:05 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-70db8953-5dec-4eb8-910d-f0abd7e1c42b. real 41m12.118s; user 83m41.069s; sys 10m15.403s. #### Steps to reproduce; atk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineSpark \; -R $REF \; --aligner-index-image GRCh38_full_analysis_set_plus_decoy_hla.fa.img \; --kmers-to-ignore GRCh38_ignored_kmers.txt \; --contig-sam-file hdfs:///project/casa/gcad/$CENTER/sv/$SAMPLE.contig-sam-file.sam\; -I $CRAM_DIR/$SAMPLE.cram \; -O hdfs:///project/casa/gcad/$CENTER/sv/$SAMPLE.sv.vcf.gz \; -- \; --spark-runner SPARK --spark-master yarn --deploy-mode client \; --executor-memory 85G\; --driver-memory 30g\; --num-executors 40\; --executor-cores 4\; --conf spark.yarn.submit.waitAppCompletion=false\; --name ""$SAMPLE"" \; --files $REF.img,$KMER \; --conf spark.yarn.executor.memoryOverhead=5000 \; --conf spark.network.timeout=600 \; --conf spark.executor.heartbeatInterval=120; #### Expected behavior. Should complete and write output files. . #### Actual behavior; Job aborts after running 45 min and no output files are written. The error message refers to filename that is not actually passed as a parameter to the tool: hdfs://scc:-1/. Not sure where the -1 is coming from. . ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942:6288,message,message,6288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942,1,['message'],['message']
Integrability,variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); at picard.util.LiftoverUtils.liftVariant(LiftoverUtils.java:92); at picard.vcf.LiftoverVcf.doWork(LiftoverVcf.java:426); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```. #### Steps to reproduce. Download vcf from here:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/HG002_SVs_Tier1_v0.6.vcf.gz. gatk LiftoverVcf \; -I b37/HG002_SVs_Tier1_v0.6.vcf.gz \; -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz \; -CHAIN grch37_to_grch38.over.chain.gz \; --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz \; -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa. #### Expected behavior; The original b37 vcf has a deletion here:. 1 532077 ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT A; SVLEN=-100;;SVTYPE=DEL;END=532177;sizecat=100to299;. The liftover to hg38 should look like this:; chr1 596697 REF=ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT; ALT=A; INFO Fields; SVLEN=-100; SVTYPE=DEL;END=596797;sizecat=100to299;. The error message suggests LiftoverVcf is not updating the INFO/END field from 532177 to 596797 and an error is being triggered since the END is before the start. An incorrect INFO/END will cause problems with tabix and other programs. #### Actual behavior; It generates an error when the INFO/END is before the start and aborts.. ----. ## Feature request; Liftover INFO/END . ### Description; ; The INFO/END position also needs to be updated-not just the site position.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6725:4916,message,message,4916,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725,1,['message'],['message']
Integrability,vel=2 -jar /gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar MarkDuplicatesSpark --spark-master local[28] --conf spark.local.dir=/datatmp/ -I ./A.sort.bam -O ./A.sort.bam.Mdup.bam -M ./A.sort.bam.Md.metrics.txt --tmp-dir /datatmp/ --conf spark.network.timeout=200h --conf spark.executor.heartbeatInterval=100h --read-name-regex null`; It reports the error below.; `20/12/15 11:43:00 ERROR Executor: Exception in task 15.0 in stage 7.0 (TID 12538); java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$handleFragments$12(MarkDuplicatesSparkUtils.java:395); at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(It,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7001:1229,wrap,wrapAndCopyInto,1229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001,1,['wrap'],['wrapAndCopyInto']
Integrability,"ver VM v1.8.0_181-b13; 14:35:47.080 INFO SelectVariants - Start Date/Time: September 24, 2018 2:35:45 PM EET; 14:35:47.080 INFO SelectVariants - ------------------------------------------------------------; 14:35:47.081 INFO SelectVariants - ------------------------------------------------------------; 14:35:47.082 INFO SelectVariants - HTSJDK Version: 2.16.1; 14:35:47.082 INFO SelectVariants - Picard Version: 2.18.13; 14:35:47.082 INFO SelectVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:35:47.082 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:35:47.082 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:35:47.082 INFO SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:35:47.082 INFO SelectVariants - Deflater: IntelDeflater; 14:35:47.082 INFO SelectVariants - Inflater: IntelInflater; ```. From @jean-philippe-martin . > This error message is related to GATK's ability to load files on Google buckets (""gcs://bucket/file.bam""). This ability is enabled even when running locally (this aspect is intentional, because it's useful to be able to run a local GATK instance to process remote data without having to fire up a VM).; > ; > As the bucket-reading code (""NIO"") initializes, it looks for credentials to use. Those can be set via an environment variable or via gcloud auth, as described in GATK's README. If neither of these are set, it checks whether it's currently running in a Google virtual machine (so it can figure out who owns the virtual machine that it's running on, and use those credentials). Apparently this code throws an exception if it runs out of ways to find credentials, and our code prints it out and moves on.; > ; > The message is useful, for if we were running in a google VM and the credential-finding failed, we'd certainly like to know. Whether we need the full stack trace, now, that's a choice we have to make.; > . We should tone down the error message if possible.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5220:6251,message,message,6251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5220,2,['message'],['message']
Integrability,verhangFixingManager.addReadGroup(OverhangFixingManager.java:209); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.splitNCigarRead(SplitNCigarReads.java:270); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.firstPassApply(SplitNCigarReads.java:180); 	at org.broadinstitute.hellbender.engine.TwoPassReadWalker.lambda$traverseReads$0(TwoPassReadWalker.java:62); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.TwoPassReadWalker.traverseReads(TwoPassReadWalker.java:60); 	at org.broadinstitute.hellbender.engine.TwoPassReadWalker.traverse(TwoPassReadWalker.java:42); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:979); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:182); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:201); 	at org.broadinstitute.hellbender.Main.runCommandLinePro,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5230:1765,wrap,wrapAndCopyInto,1765,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5230,1,['wrap'],['wrapAndCopyInto']
Integrability,"version 4.1.9.0. ### Description ; Headers with another `@` character fail to create a valid bam using MarkDuplicatesSpark. The bam file is empty. But the header will work when using samtools markdup instead. The following example was found in one of many samples we found in ICGC datasets. Example header:; `@HWI-ST700660_163:1:1101:1243:1870#1@0/1`. Log:<br> (removed some content since it was too long); ```; 00:05 DEBUG: [kryo] Read: Object[]; 00:05 DEBUG: [kryo] Read: Object[]; 00:05 DEBUG: [kryo] Read: Object[]; 00:05 DEBUG: [kryo] Read: Object[]; 00:05 DEBUG: [kryo] Write: Object[]; 00:05 DEBUG: [kryo] Write: Object[]; 00:05 DEBUG: [kryo] Write: Object[]; ...; 01:22 DEBUG: [kryo] Read: CompressedMapStatus; 01:22 DEBUG: [kryo] Write: CompressedMapStatus; ...; 02:25 DEBUG: [kryo] Read: WrappedArray([]); 02:25 DEBUG: [kryo] Write: WrappedArray([]); 02:25 DEBUG: [kryo] Read: scala.Tuple3[]; 02:25 DEBUG: [kryo] Read: scala.Tuple3[]; 02:25 DEBUG: [kryo] Read: WrappedArray([]); 02:25 DEBUG: [kryo] Read: WrappedArray([]); 02:25 DEBUG: [kryo] Write: scala.Tuple3[]; ...; 02:42 DEBUG: [kryo] Write object reference 1941: HLA-A*24:152; 02:42 DEBUG: [kryo] Write object reference 1945: chrUn_JTFH01001224v1_decoy; 02:42 DEBUG: [kryo] Write object reference 1949: HLA-B*14:01:01; 02:42 DEBUG: [kryo] Write object reference 1953: chr5_GL949742v1_alt; ...; 02:42 DEBUG: [kryo] Write object reference 1942: SAMSequenceRecord(name=HLA-A*24:152,length=3176,dict_index=2919,assembly=null,alternate_names=[]); 02:42 DEBUG: [kryo] Write object reference 1946: SAMSequenceRecord(name=chrUn_JTFH01001224v1_decoy,length=1051,dict_index=2066,assembly=null,alternate_names=[]); 02:42 DEBUG: [kryo] Write object reference 1950: SAMSequenceRecord(name=HLA-B*14:01:01,length=3312,dict_index=2999,assembly=null,alternate_names=[]); 02:42 DEBUG: [kryo] Write object reference 1954: SAMSequenceRecord(name=chr5_GL949742v1_alt,length=226852,dict_index=241,assembly=null,alternate_names=[]); ...; 02:42 DEBUG: [kryo]",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8134:1080,Wrap,WrappedArray,1080,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8134,2,['Wrap'],['WrappedArray']
Integrability,"very little GATK experience. The problem is that you've got AMD libraries on a PowerPC machine. I don't; know if GATK makes PowerPC libraries available natively, but you should be; able to get the source code and compile it yourself. Note that this will not fix the problem of your machine architecture; lacking the AVX instruction set. That's a hardware issue. But it should; (okay, *might*) get rid of the warnings about missing .so files. As an aside, I'm curious whether PowerPC architecture has an instruction; set similar to AVX. This is something I might actually be able to; contribute to the project so I'm excited by the prospect!. -Dan. On Fri, Sep 4, 2020, 11:53 AM R-obert <notifications@github.com> wrote:. > Hello,; >; > I'm trying to use GATK4 (4.1.8.1) on an Ubuntu (16.04) machine. The; > machine is a ""PowerLinux"" machine and I'm guessing that the most relevant; > info for the following problem is that it is a ppc64le system. When I use; > HaplotypeCaller, I see the following messages on the screen:; >; > Running:; > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -jar /home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCaller -R ref.fa -I mybam.bam -O mycalls.vcf.gz -L snps.vcf -ip 100; >; > 16:17:04.377 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; >; > 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600:1032,message,messages,1032,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600,1,['message'],['messages']
Integrability,"very possible codec hoping to find one and only one that answers yes to the canDecode(FileName) method call. If none does execution fails saying that there is no code available to deal with the input file; if more than one codec returns true then is supposed to throw another error indicating the ambiguity. The former is likely an user cased error whereas the later is rather a bug as Codec developers seems to be responsible to make sure that such a collision never happens... This has a few draw backs:; - Seems to quasi-force to establish a 1-to-1 assignation of Codecs and file extension names; canDecode documentation encourages use the file name as the way to determine whether the codec can decode or not the file. What if the file is a simple tab separated value file (with some column count and format constrains) and general extensions such as .tab or .tsv seem acceptable names in practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already placing the correct argument name before the file name. What else you need!"". Proposal:. An annotation to tell what codes to try out, the first one that canDe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1184:1072,message,message,1072,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184,1,['message'],['message']
Integrability,"via htsjdk's new wrapper feature.; Also provide a command-line switch to tune or disable it if necessary. A test with CountReads on a ~900MB input shows a 40MB buffer; gives over 5x speedup. DO NOT SUBMIT until htsjsk's new version is released; that incorporates the [wrapper feature](https://github.com/samtools/htsjdk/pull/775).; Then, update the build file before submitting. Sample run:. $ ./gatk-launch CountReads -I ""gs://${INPUTFOLDER}/CEUTrio.HiSeq.WGS.b37.ch20.4m-12m.NA12878.bam"" --cloudPrefetchBuffer=0; (...); org.broadinstitute.hellbender.tools.CountReads done. Elapsed time: 2.82 minutes.; $ ./gatk-launch CountReads -I ""gs://${INPUTFOLDER}/CEUTrio.HiSeq.WGS.b37.ch20.4m-12m.NA12878.bam"" --cloudPrefetchBuffer=40; (...); org.broadinstitute.hellbender.tools.CountReads done. Elapsed time: 0.49 minutes. cc: @lbergelson @droazen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2331:17,wrap,wrapper,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2331,2,['wrap'],['wrapper']
Integrability,"ware/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar VariantRecalibrator -R Gmax_275_v2.0.fa --variant Ztem.gatk.vcf.gz --resource:hapmap,known=false,training=true,truth=true,prior=10.0 final.intersected.snp.vcf.gz -an QD -an MQ -an MQRankSum -an ReadPosRankSum -an FS -an SOR -an DP -mode SNP -O Ztem.gatk.snp.recal --tranches-file Ztem.gatk.snp.tranches --rscript-file Ztem.gatk.snp.plots.R -tranche 90.0 -tranche 92.0 -tranche 94.0 -tranche 96.0 -tranche 97.0 -tranche 98.0 -tranche 99.0 -tranche 99.9; java -Xmx3990m -Djava.io.tmpdir=/gss1/home/ldl20190322/a_haoxiaoshuai/JavaTmpDir -jar /gss1/home/ldl20190322/a_haoxiaoshuai/z_software/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar ApplyVQSR -R Gmax_275_v2.0.fa -V Ztem.gatk.vcf.gz --truth-sensitivity-filter-level 99.0 --tranches-file Ztem.gatk.snp.tranches --recal-file Ztem.gatk.snp.recal -mode SNP -O Ztem.gatk.snp.vcf.gz. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; Below is the message of the mistakes and i just omitted some no use information in the log file:; .; .; .; 15:51:14.040 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.156 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.373 INFO VariantRecalibrator - Building FS x ReadPosRankSum plot...; 15:51:15.374 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:16.493 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:16.722 INFO VariantRecalibrator - Building MQRankSum x ReadPosRankSum plot...; 15:51:16.722 INFO VariantRecalibratorEngine - Evaluating full set of 3600 variants...; 15:51:17.819 INFO VariantRecalibratorEngine - Evaluating full set of 3600 variants...; 15:51:18.045 INFO VariantRecalibrator - Executing: Rscript /gss1/home/ldl20190322/a_haoxiaoshuai/a_project/WGS_Z/e_vqsr_plot/Ztem.gatk.snp.plots.R; 15:51:38.589 INFO VariantRecalibrator - Executing: Rscript (resource)org/broadinstitute/hellbender",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6948:1552,message,message,1552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6948,1,['message'],['message']
Integrability,"we need to be able to create repositories dependent on hellbender and the best way is to make a jar and pot in on maven central. @lbergelson can you look into it? It's pretty high priority because it blocks work on those new repositories. (if there's a solution without maven central, i'm open to it too)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/384:42,depend,dependent,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/384,1,['depend'],['dependent']
Integrability,weird message for CountVariants -L unmapped,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1309:6,message,message,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1309,1,['message'],['message']
Integrability,what do do about things like `SparkCommandLineProgram` that has a dependency on `com.google.cloud.dataflow.sdk.options.PipelineOptionsFactory`?. Or `ReadFilter` that implements `SerializableFunction` from `com.google.cloud.dataflow.sdk.transforms.SerializableFunction`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/954#issuecomment-146225913:66,depend,dependency,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/954#issuecomment-146225913,1,['depend'],['dependency']
Integrability,"when this is fixed, IntegrationTestSpec::compareBamFiles needs to be updated",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/177#issuecomment-75000083:20,Integrat,IntegrationTestSpec,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/177#issuecomment-75000083,1,['Integrat'],['IntegrationTestSpec']
Integrability,"when trying to build GATK fully I get this error:; ```; > Task :gatkDoc FAILED; Execution optimizations have been disabled for task ':gatkDoc' to ensure correctness due to the following reasons:; - Gradle detected a problem with the following location: '/home/jeremie/GATK/build/classes/java/main'. Reason: Task ':gatkDoc' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/home/jeremie/GATK/build/resources/main'. Reason: Task ':gatkDoc' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/jeremie/GATK/build/tmp/gatkDoc/javadoc.options'. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. Deprecated Gradle features were used in this build, making it incompatible with Gradle 8.0. You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins. See https://docs.gradle.org/7.3.2/userguide/command_line_interface.html#sec:command_line_warnings. Execution optimizations have been disabled for 1 invalid unit",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7936#issuecomment-1202544500:428,depend,dependency,428,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7936#issuecomment-1202544500,4,['depend'],"['dependency', 'depending']"
Integrability,"will still provide the background default (or the built-in ploidy of 2 for humans), but the user input value will supersede these in overlapping regions. Note that the overlap is checked against the active region, meaning variants near the boundary of the `--ploidy-regions` file may end up with GT fields having ploidy slightly differently than expected, for example if your custom region overlaps a given active region but the variant ends up being written to a location outside that interval. In this case the ploidy from the user input would be used rather than any other default. # Implementation Details. The key idea is to allow `HaplotypeCallerEngine` to initialize multiple genotyping engines based on the `--ploidy-regions` input. The intervals are first parsed to check for positive integer ploidy values, and then used to create hashmaps of ploidy -> genotyper. The engine uses two types of genotypers: one for active region determination and one for doing the actual genotyping. Both admit a ploidy paramter passed via `hcArgs`. This PR modifies the `HaplotypeCallerArgumentCollection` class to include a method for creating copies of this object with differing ploidy amounts. These then get fed to the constructors of the appropriate genotyper classes, which are organized into two hashmaps. In every situation where one of these genotypers is used, we instead begin the scope by calling a ""get local genotyper"" method that performs the logic of checking whether the region of interest overlaps any of the user-provided regions, and then selects the appropriate `localEngine` genotyper for the task, ensuring the user-provided ploidy supersedes any other defaults. # A Note on Dependency. The flexibility of using either .bed or .interval_list files to specify this information depends on [this](https://github.com/samtools/htsjdk/pull/1680) PR in htsjdk being made into a full release, and then bumping the dependency of GATK. The code in this PR would not compile until this happens.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8464:2223,Depend,Dependency,2223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8464,3,"['Depend', 'depend']","['Dependency', 'dependency', 'depends']"
Integrability,wrapping ReadCovariate.keyCache in a ThreadLocal to prevent multithreading issues; changing worker type for dataflow to 4-core,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/915:0,wrap,wrapping,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/915,1,['wrap'],['wrapping']
Integrability,wrapping TribbleException in GenomicsDBImport,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4546:0,wrap,wrapping,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4546,1,['wrap'],['wrapping']
Integrability,"x Race Condition, Add Support for Extract by Array of Sample Names (ie from a Sample Set) (#7917); - Rightsize import batches [VS-486] (#7925); - [AoU DRC] Support uppercase site_ids for reblocking (#7929); - Populate cost metadata for GATK tasks. (#7919); - remove accidentally added input (#7931); - VS_492 - Beta User Jar release (#7934); - Cost WDL should throw on FISS API errors [VS-518] (#7942); - Fix bad check for missing workflow name [VS-520] (#7943); - Remove usage of service account from GvsValidateVAT.wdl (#7937); - refactoring for testablity (#7946); - More import retries [VS-532] (#7953); - A few last doc changes (#7927); - WDL to extract a single callset cost (BQ only, not Terra) (#7940); - Temporarily swap in Corretto for Temurin as we can't download Temurin. (#7969); - GL-548 - Update CreateVat code to handle samples that do not contain all population groups. (#7965); - Restore Temurin 11 [VS-570] (#7972); - Add table size check to quickstart integration test [VS-501] (#7970); - Consolidate various docs for AoU callset generation into one to rule them all [VS-553] (#7971); - VS-567. Removing usage of ServiceAccount from CreateVat related WDLs (#7974); - WDL to extract Avro files for Hail import [VS-579] (#7981); - Removed usage of service account from WDLs (#7985); - Document steps for GVS cleanup for base use case [VS-586] (#7989); - Change backticks to single quotes in several error messages - causing shell to attempt to execute. (#7995); - VS-598 - Minor update to AoU Documentation. (#7994); - Allow for incremental addition of data to alt_allele [VS-52] (#7993); - Minor AoU Documentation Update (#7999); - Batch population of alt_allele table from vet_ tables [VS-265] (#7998); - Change drop_state to NONE for Ingest/Extract [VS-607] (#8000); - python -> python3 (#8001); - Generate Hail import/export script [VS-605] (#8002); - clearer error when values are missing (#7939); - Ah [VS-565] output intervals and sample list (#8010); - make CreateAltAlleleT",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:26897,integrat,integration,26897,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['integrat'],['integration']
Integrability,xception: connect timed out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:162); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:79); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:996); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:541); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:474); 	at shaded.cloud_nio.com.googl,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:7468,protocol,protocol,7468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['protocol'],['protocol']
Integrability,"xecutor.Executor: Running task 0.0 in stage 1.0 (TID 1); 15/07/14 13:14:53 INFO storage.BlockManager: Removing broadcast 0; 15/07/14 13:14:53 INFO storage.BlockManager: Removing block broadcast_0; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_0 of size 6656 dropped from memory (free 277996857); 15/07/14 13:14:53 INFO storage.BlockManager: Removing block broadcast_0_piece0; 15/07/14 13:14:53 INFO storage.MemoryStore: Block broadcast_0_piece0 of size 3753 dropped from memory (free 278000610); 15/07/14 13:14:53 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on localhost:65240 in memory (size: 3.7 KB, free: 265.1 MB); 15/07/14 13:14:53 INFO storage.BlockManagerMaster: Updated info of block broadcast_0_piece0; 15/07/14 13:14:53 INFO spark.ContextCleaner: Cleaned broadcast 0; 15/07/14 13:14:53 ERROR executor.Executor: Exception in task 0.0 in stage 1.0 (TID 1); java.lang.IncompatibleClassChangeError: Found class org.apache.hadoop.mapreduce.TaskAttemptContext, but interface was expected; at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getOutputFile(TemplatedTextOutputFormat.java:50); at com.cloudera.dataflow.spark.TemplatedTextOutputFormat.getDefaultWorkFile(TemplatedTextOutputFormat.java:46); at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:995); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:979); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61); at org.apache.spark.scheduler.Task.run(Task.scala:64); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 15/07/14 13:14:53 ERROR util.SparkUncaughtExceptionHandler: Uncaught exc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:28669,interface,interface,28669,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['interface'],['interface']
Integrability,"xist in 25.x pre-Editions</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/f000b7e18fd6921ca02ea4b87608e8cadcb7b64f""><code>f000b7e</code></a> Fix merge conflict by adding optional label to proto2 unittest_lite.proto</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/4728531c162f2f9e8c2ca1add713cfee2db6be3b""><code>4728531</code></a> Add recursion check when parsing unknown fields in Java.</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/850fcce9176e2c9070614dab53537760498c926b""><code>850fcce</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b7044987de77f1dc368fee558636d0b56d7e75e1""><code>b704498</code></a> Internal change</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/e67347986eaf7d777a6ee34367fa99f4912423ab""><code>e673479</code></a> Fix cord handling in DynamicMessage and oneofs. (<a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/18375"">#18375</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/8a60b6527a976cfd0028153da3ad8e4ed280e0de""><code>8a60b65</code></a> Merge pull request <a href=""https://redirect.github.com/protocolbuffers/protobuf/issues/17704"">#17704</a> from protocolbuffers/cp-segv</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/94a26630e362a4771b5ec80eac49f494988ca408""><code>94a2663</code></a> Fixed a SEGV when deep copying a non-reified sub-message.</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.23.4...v3.25.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). D",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:1760,protocol,protocolbuffers,1760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,1,['protocol'],['protocolbuffers']
Integrability,xt.JEXLMap.get(JEXLMap.java:15); 	at htsjdk.variant.variantcontext.VariantContextUtils.match(VariantContextUtils.java:338); 	at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.matchesFilter(VariantFiltration.java:380); 	at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.filter(VariantFiltration.java:339); 	at org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration.apply(VariantFiltration.java:299); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:109); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:107); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:994); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4921:6345,wrap,wrapAndCopyInto,6345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4921,1,['wrap'],['wrapAndCopyInto']
Integrability,"xt: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:105; 16/08/24 14:06:10 INFO FileInputFormat: Total input paths to process : 1; 16/08/24 14:06:21 INFO SparkUI: Stopped Spark web UI at http://10.200.98.30:4040; 16/08/24 14:06:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 16/08/24 14:06:21 INFO MemoryStore: MemoryStore cleared; 16/08/24 14:06:21 INFO BlockManager: BlockManager stopped; 16/08/24 14:06:21 INFO BlockManagerMaster: BlockManagerMaster stopped; 16/08/24 14:06:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 16/08/24 14:06:21 INFO SparkContext: Successfully stopped SparkContext; 14:06:21.109 INFO SparkGenomeReadCounts - Shutting down engine; [August 24, 2016 2:06:21 PM EDT] org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts done. Elapsed time: 0.36 minutes.; Runtime.totalMemory()=3192389632; java.lang.IndexOutOfBoundsException; at java.nio.ByteBuffer.wrap(ByteBuffer.java:375); at htsjdk.samtools.BAMRecord.getCigar(BAMRecord.java:246); at org.seqdoop.hadoop_bam.BAMSplitGuesser.guessNextBAMRecordStart(BAMSplitGuesser.java:189); at org.seqdoop.hadoop_bam.BAMInputFormat.addProbabilisticSplits(BAMInputFormat.java:244); at org.seqdoop.hadoop_bam.BAMInputFormat.getSplits(BAMInputFormat.java:159); at org.seqdoop.hadoop_bam.AnySAMInputFormat.getSplits(AnySAMInputFormat.java:253); at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:120); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.rdd.RDD.partitions(RDD.scala:237); at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239); at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237); at scala.Option.getOrElse(Option",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2113:1983,wrap,wrap,1983,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2113,1,['wrap'],['wrap']
Integrability,"y COHORT/CASE modes, GermlineCNVCaller COHORT/CASE modes, and PostprocessGermlineCNVCalls. Numerical results are also relatively close to those from 4.4.0.0 for all identifiable call and model quantities (albeit far outside any reasonable exact-match thresholds, most likely due to differences in RNG, sampling, and the aforementioned priors). Some remaining TODOs:. - [x] Rebuild and push the base Docker. EDIT: Mostly covered by #8610, but this also includes an addition of `libblas-dev`.; - [x] Update expected results for integration tests, perhaps add any that might be missing. EDIT: These were generated on WSL Ubuntu 20.04.2, we'll see if things pass on 22.04. Note that changing the ARD priors does change the *names* of the expected files, since the transform is appended to the corresponding variable name. DetermineGermlineContigPloidy and PostprocessGermlineCNVCalls are missing exact-match tests and should probably have some, but I'll leave that to someone else.; - [x] Update other python integration tests.; - [x] Clean up some of the changes to the priors.; - [x] Clean up some TODO comments that I left to track code changes that might result in changed numerics. I'll try to go through and convert these to PR comments in an initial review pass.; - [x] Test over multiple shards on WGS and WES. Probably some scientific tests on ~100 samples in both cohort and case mode would do the trick. We should also double check runtime/memory performance (I noted ~1.5x speedups, but didn't measure carefully; I also want to make sure the changes to posterior sampling didn't introduce any memory issues). @mwalker174 will ping you when a Docker is ready! Might be good to loop in Isaac and/or Jack as well.; - [x] Perhaps add back the fix for 2-interval shards in https://github.com/broadinstitute/gatk/pull/8180, which I removed since the required functionality wasn't immediately available in Pytensor. Not sure if this actually broke things though---need to check. (However, I don't ac",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285:2434,integrat,integration,2434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1847549285,1,['integrat'],['integration']
Integrability,"y(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 18/12/21 13:14:03 WARN scheduler.TaskSetManager: Lost task 23.0 in stage 0.0 (TID 6, scc-q15.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 2, start 93470412, span 157, expected MD5 56b7844faa4e0c4f61fd6774df454b09; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1760); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1157); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.r",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547:11314,Wrap,Wrappers,11314,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547,1,['Wrap'],['Wrappers']
Integrability,y.queryFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:314); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:229); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:207); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Ite,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:22568,wrap,wrapAndCopyInto,22568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['wrap'],['wrapAndCopyInto']
Integrability,"yay!. On Mon, Feb 23, 2015 at 6:02 PM, droazen notifications@github.com wrote:. > Replicates most of the functionality of the old ROD system in ~5% of the; > code. The incomprehensible tangle of nested iterators, bindings, views,; > states,; > tracks, trackers, builders etc., etc., is gone, replaced by about 4 core; > classes:; > FeatureContext, FeatureDataSource, FeatureInput, and FeatureManager.; > ; > FeatureContext: This is tool-facing interface (replaces; > RefMetaDataTracker).; > Allows particular sources of Features to be queried.; > ; > FeatureDataSource: Handles the low-level details of querying a source of; > Features.; > Uses a caching scheme optimized for the use case of queries over; > intervals with gradually increasing start/stop positions.; > ; > FeatureInput: This is used to declared Feature arguments in tools; > (replaces RodBinding).; > The engine discovers all FeatureInput arguments declared in the tool's; > class; > hierarchy, and initializes data sources for each one that was specified; > on the command line.; > ; > FeatureManager: Manages the pool of data sources, as well as codec and; > file format; > discovery and type checking.; > ; > -ReadWalker interface has changed: apply() now takes a FeatureContext; > argument; > (will be null if there are no sources of Features).; > ; > -Included an example tool PrintReadsWithVariants to demonstrate use of the; > new; > ReadWalker interface.; > ; > -Since Feature files must be indexed in order to query them, I have; > provided a; > tool IndexFeatureFile that can index any Feature-containing file.; > ; > -Made required changes to the argument-parsing system. Feature argument; > discovery; > is as de-coupled as possible from the main arg parser.; > ; > -Made required changes to BQSR, and eliminated the temporary; > HACKRefMetaDataTracker.; > ; > ## -Comprehensive tests; > ; > You can view, comment on, or merge this pull request online at:; > ; > https://github.com/broadinstitute/hellbender/pull/224; > Co",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/224#issuecomment-75657392:444,interface,interface,444,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/224#issuecomment-75657392,1,['interface'],['interface']
Integrability,yep! I should have that wrapped up soon. testing the updated WDL now,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-848993767:24,wrap,wrapped,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-848993767,1,['wrap'],['wrapped']
Integrability,"yes, please try wrapping. We can't push that down to htsjdk because it would be too disruptive for all clients of that library",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/917#issuecomment-149741251:16,wrap,wrapping,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/917#issuecomment-149741251,1,['wrap'],['wrapping']
Integrability,"yes, that's what this ticket is for - to make the new interfaces. OK to close if this is a dup of issue #82 in your mind",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/20#issuecomment-69375418:54,interface,interfaces,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/20#issuecomment-69375418,1,['interface'],['interfaces']
Integrability,yet another message to support reverting to good old ./. for missing genotypes and 0/0 for homozygous reference.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1935719294:12,message,message,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1935719294,1,['message'],['message']
Integrability,"yground/programs/gatk-protected/build/libs/gatk-protected-package-b4390fb-SNAPSHOT-local.jar; 102-b14; Version: 4.alpha.2-1136-gc18e780-SNAPSHOT; 16:55:21.931 INFO GermlineCNVCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:55:21.932 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:55:21.932 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:55:21.932 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:21.932 INFO GermlineCNVCaller - Deflater: IntelDeflater; 16:55:21.932 INFO GermlineCNVCaller - Inflater: IntelInflater; 16:55:21.932 INFO GermlineCNVCaller - Initializing engine; 16:55:21.932 INFO GermlineCNVCaller - Done initializing engine; 16:55:21.933 INFO GermlineCNVCaller - Spark disabled. sparkMaster option (local[*]) ignored.; 16:55:23.448 INFO GermlineCNVCaller - Parsing the read counts table...; 16:55:24.876 INFO GermlineCNVCaller - Parsing the sample sex genotypes table...; 16:55:24.896 INFO GermlineCNVCaller - Parsing the germline contig ploidy annotation table...; 16:55:24.906 INFO ContigGermlinePloidyAnnotationTableReader - Ploidy tags: SEX_XX, SEX_XY; 16:55:25.056 INFO GermlineCNVCaller - Parsing the copy number transition prior table and initializing the caches...; 16:55:28.634 INFO GermlineCNVCaller - Initializing the EM algorithm workspace...; 16:55:32.861 INFO GermlineCNVCaller - Shutting down engine; [June 12, 2017 4:55:32 PM ACST] org.broadinstitute.hellbender.tools.coveragemodel.germline.GermlineCNVCaller done. Elapsed time: 0.18 minutes.; Runtime.totalMemory()=1364721664; org.broadinstitute.hellbender.exceptions.GATKException: Nd4j data type must be set to double for coverage modeller routines to function properly. This can be done by setting JVM system property ""dtype"" to ""double"". Can not continue. Thanks. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/gatk/discussion/comment/39376#Comment_39376",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3098:2726,rout,routines,2726,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3098,1,['rout'],['routines']
Integrability,"ypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 01:12 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:56:07 INFO TaskSetManager: Starting task 1.2 in stage 2.0 (TID 9, xx.xx.xx.27, executor 0, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:56:37 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.27:46181 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:56:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.27:46181 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:56:39 WARN TaskSetManager: Lost task 1.2 in stage 2.0 (TID 9, xx.xx.xx.27, executor 0): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadins",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:31451,Wrap,WrappedArray,31451,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Wrap'],['WrappedArray']
Integrability,"ypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 01:44 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:56:39 INFO TaskSetManager: Starting task 1.3 in stage 2.0 (TID 10, xx.xx.xx.16, executor 3, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:56:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.24:35903 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:56:39 INFO TaskSetManager: Lost task 1.3 in stage 2.0 (TID 10) on xx.xx.xx.16, executor 3: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 18/04/24 17:56:39 ERROR TaskSetManager: Task 1 in stage 2.0 failed 4 times; aborting job; 18/04/24 17:56:39 INFO TaskSchedulerImpl: Cancelling stage 2; 18/04/24 17:56:39 INFO TaskSchedulerImpl: Stage 2 was cancelled; 18/04/24 17:56:39 INFO DAGScheduler: ShuffleMapStage 2 (mapToPair at PSFilter.java:125) failed in 45.219 s due to Job aborted due to stage failure: Task 1 in stage 2.0 failed 4 times, most recent failure: Lost task ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:34048,Wrap,WrappedArray,34048,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Wrap'],['WrappedArray']
Integrability,"~Draft PR for mobbing discussion~ Ready for review, integration tested [here](https://app.terra.bio/#workspaces/broad-firecloud-dsde/VS-415%20GVS%20Quickstart%20Default%20Extract%20Scatter/job_history/7ef604ff-46e8-45d9-be39-e88276db993b).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7880:52,integrat,integration,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7880,1,['integrat'],['integration']
Integrability,"… as well as excluding log4j 1.x. GKL 0.5.6 now uses the log4j 1.x API for logging, and we use the log4j-1.2-api bridge JAR to redirect to log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#which_jars) for details. This change was made because GATK 3.x uses log4j 1.x, and users were reporting errors in the output. This release fixes those errors. GATK 4 uses log4j2 and, in order to make the API compatible with the GKL, we need to add a dependency on the log4j-1.2-api bridge. Unfortunately, the log4j 1.X JAR is also brought in due to some transitive dependency from another package, which causes conflicts with the log4j-1.2-api bridge package. To solve that, we need to exclude log4j 1.X from the dependencies, and let log4j-1.2-api take care of any calls to the log4j 1.X API, redirecting them to the log4j2 implementation. See [here](https://logging.apache.org/log4j/2.0/faq.html#exclusions) for details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3416:113,bridg,bridge,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416,6,"['bridg', 'depend']","['bridge', 'dependencies', 'dependency']"
Integrability,…ceContentsAsFile(....). This gets rid of Hierarchical URI error message.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4723:65,message,message,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4723,1,['message'],['message']
Integrability,"…es #1572. This commit also addresses #3069, by virtue of building against GKL 0.5.3, which pushes INFO and WARN messages to the Java logger.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3177:113,message,messages,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177,1,['message'],['messages']
Integrability,"…joint-genotyping from the resulting GVCFs. @ldgauthier & @davidbenjamin this PR is a follow up from our short conversation in #4650 a couple of months ago, where I was wanting to generate GVCFs with MNP support. My goal here is that I really want to be able to generate a single VCF that a) gives me reference confidence and b) gives me MNPs for close by variants. This is for a clinical pipeline where all calling is done one sample at a time, so the problem of joint-genotyping from different MNP representations doesn't come up. I did briefly look at using `--emit-ref-confidence BP_RESOLUTION` but that has two issues that make me prefer this route:. 1) The generated files are really very large because they have a row for every single BP; 2) More problematic, is that when there is a MNP of say `ACG/GCT` two things happen that are less than ideal from my perspective. The first is that rows are emitted into the VCF for all three positions (the variant at A's position, and two `<NON_REF>` lines at the positions for the C and T respectively). Secondly, when one or more bases is the same in both MNP alleles (the C in this case) that base is output with a very high hom-ref GQ, which feels wrong!. I'm more than happy to modify this PR to address any concerns you have (e.g. adding a `--force-mnps-with-gvcfs` parameter that has to be specified, or requiring `--unsafe` to enable this). I'm also open to other solutions, but this seemed expedient and reasonable for folks running single-sample pipelines like you see in clinical settings.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5182:648,rout,route,648,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5182,1,['rout'],['route']
Integrability,…ration tests. The fix for the original bug (CompareSAMs not obeying stringency) is a one line fix in CompareSAMs. The two BQSR integration tests referenced in the issue use a different code path and required a different fix (assuming that relaxing the stringency is the right thing to do in those cases). I also added a new CompareSAMs integration test and changed the CompareSAMs tool to return result of the comparison.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/604:128,integrat,integration,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/604,2,['integrat'],['integration']
Integrability,👍 Thanks Tom! Should we patch hadoop bam to throw a more informative message here as well?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1951#issuecomment-229978199:69,message,message,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1951#issuecomment-229978199,1,['message'],['message']
Integrability,👍 to this with the understanding that we may be removing `IntegrationTestSpec` in the future.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-245958527:58,Integrat,IntegrationTestSpec,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-245958527,1,['Integrat'],['IntegrationTestSpec']
Modifiability," (PathSeqBuildKmers) and filtering reads that are low-quality, low-complexity, or come from the host (PathSeqFilterSpark). Sorry for the especially large size on this PR. **PathSeqBuildKmers tool**. Note this has been renamed from PathSeqKmerSpark. Input:; 1) Host reference FASTA; 2) False positive probability (0 create a hash set, >0 to create a Bloom filter); 3) Kmer length (1-31); 4) Kmer base indices to mask (optional). Output:; 1) Serialized kmer Hopscotch set (.hss) or Bloom filter (.bfi) file. For each reference record, the tool generates a list of long's containing the canonicalized/masked kmers. The result is a Collection<long[]> variable, which is then converted to either a PSKmerSet (Hopscotch set) or PSKmerBloomFilter, depending on the desired false positive probability. . The PSKmerSet/BloomFilter classes are basically wrappers for LargeLongHopscotchSet and LongBloomFilter, respectively. They both inherit PSKmerCollection, which provides a contains() function for querying new kmers for set membership and makes loading the kmers for filtering more convenient. These classes also store the kmer size, mask, and false positive probability. They also handle canonicalization/masking on queried kmers. **PathSeqFilterSpark tool**. Input:; 1) Input BAM; 2) Host kmer set file (optional); 3) Host reference bwa image (optional). Output:; 1) BAM containing paired reads that still have mates; 2) BAM containing unpaired reads / reads whose mates were filtered out; 3) Metrics file containing read counts and elapsed wall time at each step (optional). Filtering steps performed on each read:; - If the user sets the --isHostAligned, the read will first be filtered if it is aligned sufficiently well ; - Alignment info is stripped; - A series of quality filters (same as in the previous version of this tool); - Kmerized and filtered out if at least a threshold number of kmers are in the host set (default 1); - Aligned to the host reference and filtered if it maps sufficiently ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3115:983,inherit,inherit,983,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3115,1,['inherit'],['inherit']
Modifiability, (ø)` | `0 <0> (?)` | |; | [...dinstitute/hellbender/engine/GATKToolUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2xVbml0VGVzdC5qYXZh) | `91.017% <100%> (+0.473%)` | `71 <0> (ø)` | :arrow_down: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `83.846% <100%> (+0.252%)` | `49 <2> (ø)` | :arrow_down: |; | [...GATKPlugin/GATKReadFilterPluginDescriptorTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yVGVzdC5qYXZh) | `88.62% <50%> (-1.76%)` | `48 <1> (+1)` | |; | [...Plugin/GATKAnnotationPluginDescriptorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yVW5pdFRlc3QuamF2YQ==) | `88.235% <63.158%> (-1.43%)` | `58 <1> (+1)` | |; | [...rg/broadinstitute/hellbender/utils/ClassUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9DbGFzc1V0aWxzLmphdmE=) | `86.842% <75%> (+1.128%)` | `21 <2> (+2)` | :arrow_up: |; | [...ine/GATKPlugin/GATKAnnotationPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `76.875% <83.333%> (+0.293%)` | `57 <3> (ø)` | :arrow_down: |; | [.../tools/walkers/haplotypecaller/RefVsAnyResult.java](https://codecov.io/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5573#issuecomment-455708523:2809,Plugin,Plugin,2809,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5573#issuecomment-455708523,1,['Plugin'],['Plugin']
Modifiability," - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 23:43:52.471 INFO GermlineCNVCaller - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.REFERENCE_FASTA : null; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 23:43:52.472 DEBUG ConfigFactory - Configuration file values: ; 23:43:52.474 DEBUG ConfigFactory - 	gcsMaxRetries = 20; 23:43:52.474 DEBUG ConfigFactory - 	gcsProjectForRequesterPays = ; 23:43:52.474 DEBUG ConfigFactory - 	gatk_stacktrace_on_user_exception = false; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.use_async_io_read_samtools = false; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.use_async_io_write_samtools = true; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.use_async_io_write_tribble = false; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.compression_level = 2; 23:43:52.474 DEBUG ConfigFactory - 	spark.kryoserializer.buffer.max = 512m; 23:43:52.474 DEBUG ConfigFactory - 	spark.driver.maxResultSize = 0; 23:43:52.474 DEBUG ConfigFactory - 	spark.driver.userClassPathFirst = true; 23:43:52.474 DEBUG ConfigFactory - 	spark.io.compression.codec = lzf; 23:43:52.474 DEBUG ConfigFactory - 	spark.executor.memoryOverhead = 600; 23:43:52.475 DEBUG ConfigFactory - 	spark.driver.extraJavaOptions = ; 23:43:52.475 DEBUG ConfigFactory - 	spark.executor.extraJavaOptions = ; 23:43:52.475 DEBUG ConfigFactory - 	codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 23:43:52.475 DEBUG ConfigFactory - 	read_filter_packages = [org.broadinstitute.hellbend",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:3076,Config,ConfigFactory,3076,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['Config'],['ConfigFactory']
Modifiability," - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIn",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:4860,Config,ConfigFactory,4860,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['Config'],['ConfigFactory']
Modifiability," - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:39:19.226 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:39:19.226 DEBUG ConfigFactory - Configuration file values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:39:19.246 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:39:19.246 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:39:19.246 INFO PathSeqPipelineSpark - Initializing engine; 17:39:19.246 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:5880,Config,ConfigFactory,5880,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability," - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:54:55.302 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:54:55.302 DEBUG ConfigFactory - Configuration file values:; 17:54:55.320 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:54:55.320 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:54:55.320 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:54:55.320 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:54:55.320 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:54:55.320 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:54:55.320 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:54:55.320 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:54:55.320 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:54:55.320 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:54:55.321 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:54:55.321 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:54:55.321 DEBUG ConfigFactory - createOutputBamIndex = true; 17:54:55.321 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:54:55.321 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:54:55.321 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:54:55.321 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:54:55.321 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:54:55.321 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:54:55.321 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:54:55.321 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:54:55.321 INFO PathSeqPipelineSpark - Initializing engine; 17:54:55.321 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:6519,Config,ConfigFactory,6519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Config'],['ConfigFactory']
Modifiability," - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 23:37:00.976 DEBUG ConfigFactory - Configuration file values: ; 23:37:00.982 DEBUG ConfigFactory - gcsMaxRetries = 20; 23:37:00.982 DEBUG ConfigFactory - gcsProjectForRequesterPays = ; 23:37:00.982 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 23:37:00.982 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 23:37:00.982 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 23:37:00.982 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 23:37:00.983 DEBUG ConfigFactory - samjdk.compression_level = 2; 23:37:00.983 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 23:37:00.983 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 23:37:00.983 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 23:37:00.983 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 23:37:00.983 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 23:37:00.983 DEBUG ConfigFactory - spark.driver.extraJavaOptions = ; 23:37:00.983 DEBUG ConfigFactory - spark.executor.extraJavaOptions = ; 23:37:00.983 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 23:37:00.983 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 23:37:00.983 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 23:37:00.983 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 23:37:00.983 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 23:37:00.983 DEBUG ConfigFactory - createOutputBamIndex = true; 23:37:00.984 INFO GermlineCNVCaller - Deflater: IntelDeflater; 23:37:00.984 INFO GermlineCNVCaller - Inflater: IntelInflater; 23:37:00.984 INFO GermlineCNVCaller - GCS max retries/reopens: 20; 23:37:00.984 INFO GermlineCNVCaller - Requester pays: disabled; 23:37:00.984 INFO GermlineCNVCaller - Initializing engine; 23:37:00.990 DEBUG ScriptExe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:4673,Config,ConfigFactory,4673,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,1,['Config'],['ConfigFactory']
Modifiability, - cache miss 17632 > 11908 expanding to 23818; 11:36:41.254 DEBUG IntToDoubleFunctionCache - cache miss 29537 > 23818 expanding to 47638; 11:36:42.578 DEBUG Mutect2 - Processing assembly region at chrM:5744-6043 isActive: false numReads: 0; 11:36:47.533 DEBUG Mutect2 - Processing assembly region at chrM:6044-6343 isActive: false numReads: 30078; 11:36:47.979 DEBUG Mutect2 - Processing assembly region at chrM:6344-6353 isActive: false numReads: 30081; 11:36:48.322 DEBUG Mutect2 - Processing assembly region at chrM:6354-6629 isActive: true numReads: 60135; 11:36:55.630 DEBUG ReadThreadingGraph - Recovered 8 of 11 dangling tails; 11:36:55.645 DEBUG ReadThreadingGraph - Recovered 7 of 16 dangling heads; 11:36:55.737 DEBUG IntToDoubleFunctionCache - cache miss 26606 > 4800 expanding to 26616; 11:36:55.741 DEBUG IntToDoubleFunctionCache - cache miss 26873 > 26616 expanding to 53234; 11:36:56.119 DEBUG Mutect2Engine - Active Region chrM:6354-6629; 11:36:56.119 DEBUG Mutect2Engine - Extended Act Region chrM:6254-6729; 11:36:56.119 DEBUG Mutect2Engine - Ref haplotype coords chrM:6254-6729; 11:36:56.119 DEBUG Mutect2Engine - Haplotype count 128; 11:36:56.119 DEBUG Mutect2Engine - Kmer sizes count 0; 11:36:56.120 DEBUG Mutect2Engine - Kmer sizes values []; 11:39:06.762 DEBUG Mutect2 - Processing assembly region at chrM:6630-6929 isActive: false numReads: 30053; 11:39:07.547 DEBUG Mutect2 - Processing assembly region at chrM:6930-7229 isActive: false numReads: 0; 11:39:07.574 DEBUG Mutect2 - Processing assembly region at chrM:7230-7493 isActive: false numReads: 359; 11:39:07.584 DEBUG Mutect2 - Processing assembly region at chrM:7494-7771 isActive: true numReads: 718; 11:39:07.668 DEBUG ReadThreadingGraph - Recovered 32 of 33 dangling tails; 11:39:07.713 DEBUG ReadThreadingGraph - Recovered 31 of 50 dangling heads; 11:39:07.996 DEBUG Mutect2Engine - Active Region chrM:7494-7771; 11:39:07.998 DEBUG Mutect2Engine - Extended Act Region chrM:7394-7871; 11:39:07.999 DEBUG Mutect2Eng,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:13432,Extend,Extended,13432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Extend'],['Extended']
Modifiability," --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:48:31.261 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:48:31.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:48:31.693 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.693 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.3.0; 13:48:31.693 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:48:31.694 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:48:31.694 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:48:31.694 INFO CountReadsSpark - Start Date/Time: December 21, 2018 1:48:31 PM EST; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.694 INFO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:1691,variab,variables,1691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725,2,"['config', 'variab']","['configured', 'variables']"
Modifiability," 17 apis, it's more difficult to retrieve the actual values. And even then, because the gatkdoc process only consumes a subset of the classes consumed by the javadoc process (it only sees `@DocumentedFeature`s), it's quite easy to reference something in the javadoc comment that can be resolved by javdoc, but not by gatkdoc. But it appears that even the javadoc process isn't rendering these tags correctly. Here is the raw javadoc comment:; ```; * Input VCF file. Site-level annotations will be extracted from the contained variants (or alleles,; * if the {@value USE_ALLELE_SPECIFIC_ANNOTATIONS_LONG_NAME} argument is specified).; ```; The rendering in javadoc (the argument name is missing entirely, but it should be interpolated):; <img width=""780"" alt=""Screen Shot 2023-01-05 at 12 17 43 PM"" src=""https://user-images.githubusercontent.com/10062863/210841121-15a4d357-dbfa-47e2-808b-08cdeb6d42be.png"">. The rendering in gatkdoc (the variable name appears in the text, but it should be interpolated):; <img width=""1055"" alt=""Screen Shot 2023-01-05 at 12 12 46 PM"" src=""https://user-images.githubusercontent.com/10062863/210840538-9a42bf02-b968-4ac9-9591-90512e87ab50.png"">. Note that QuickDocumentation within IntelliJ seems to render them correctly. Additionally, I noticed that some {@link} targets are not rendering correctly in gatkdoc, i.e., these links in `ScoreVariantAnnotations`:; ```; * {@link VariantRecalibrator} workflow. Using a previously trained model produced by {@link TrainVariantAnnotationsModel},; ```; work in javadoc, but not gatkDoc, even though the target in this case IS included in the set of objects available to the gatkDoc process. The gatkdoc process is not translating these (and apparently its replacing them with the text). But generating the anchor tags will require translation because the javadoc output files are organized hierarchically whereas the gatkdoc files are flat. The links in html file generated by javadoc have anchor tags with proper hrefs, wher",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8146:2128,variab,variable,2128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8146,1,['variab'],['variable']
Modifiability," 2018; >; > #gap.chrom gap.chromStart gap.chromEnd gap.type; >; > chr1 0 10000 telomere; >; > chr1 207666 257666 contig; >; > chr1 297968 347968 contig; >; > chr1 535988 585988 contig; >; > chr1 2702781 2746290 scaffold; >; >; For what it's worth, your description of your approach sounds like a; sensible one to me.; I am concerned about the size of the data and how we'd access it. I've; chosen the tracts I have because they are small enough to jam into; resources. On Tue, May 1, 2018 at 8:06 AM samuelklee <notifications@github.com> wrote:. > @TedBrookings <https://github.com/TedBrookings> which formats are you; > using, in particular?; >; > In the CNV package, I've taken pains to unify how tabular data are; > represented in Java, depending on whether each record is Locatable or; > whether the collection of records can be associated with a sample name or; > sequence dictionary. This allows us to represent records that extend; > Locatable with multidimensional numerical or non-numerical annotations; > along with some metadata (sample name and sequence dictionary) with a; > minimum of boilerplate. There are also base methods for producing interval; > trees, etc.; >; > However, this unification effort was a quick push I made before release,; > so some polishing or redesigning may be warranted. We may also want to add; > more forms of metadata, etc. if other teams would require more features.; > Another downside is that this code lacks the indexing, NIO support, etc.; > that some of the other standardized/Tribble formats enjoy. For CNV data,; > this isn't a huge issue, but I think it would be nice to unify how we; > represent such data GATK-wide. As I said above, I don't think VCF is the; > correct answer, but certainly it could fit into whatever framework we come; > up with.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385656468>,; > or",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385683551:1710,extend,extend,1710,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385683551,1,['extend'],['extend']
Modifiability," 2021. ### Description ; The Mutect2 WDL's Funcotate task has an unintuitive setup with regard to setting memory for the Funcotate task. Funcotate task memory is defined [here](https://github.com/broadinstitute/gatk/blob/4.1.8.1/scripts/mutect2_wdl/mutect2.wdl#L1108); ![image](https://user-images.githubusercontent.com/45641912/139333822-aa0b3adc-b92e-4317-a75e-da322f96822f.png). This is using the dictionary defined earlier called **standard_runtime**. ![image](https://user-images.githubusercontent.com/45641912/139333917-0d97ef00-88e6-4340-8cee-e3295127eab8.png). This dictionary uses a variable called **machine_mem** which is calculated using the workflow's **small_task_mem** input, which is configurable. ![image](https://user-images.githubusercontent.com/45641912/139333959-4465b06d-b2ce-4ab2-bae9-285e25168c1d.png); ![image](https://user-images.githubusercontent.com/45641912/139333973-c8e2c1f6-0efd-4f45-9d1e-10f6c4a2baac.png). To allocate more memory for the Funcotate task, one has to define this **small_task_mem** variable at the workflow level. This effectively changes the amount of memory for all tasks that make use of this dictionary, rather than just the Funcotate task. Funcotate has two input variables **default_ram_mb** and **default_disk_space_gb** which have no bearing on the memory and disk space configuration for the task.; ![image](https://user-images.githubusercontent.com/45641912/139334343-8e614e17-27ef-4fef-815d-fe6e8c39ffef.png). This leads to user confusion when they see these variables in the method configuration page, put values in, and don't see their Funcotate task use the specified values.; ![image](https://user-images.githubusercontent.com/45641912/139334535-4b9a0353-910e-4764-a6d2-a454f4d344aa.png). #### Steps to reproduce; Define the input variables **default_ram_mb** and **default_disk_space_gb** for a run of the Mutect2 workflow to be different from the amounts defined by [*small_task_mem*](https://github.com/broadinstitute/gatk/blob/4.1.8.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7532:1218,variab,variable,1218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7532,1,['variab'],['variable']
Modifiability, 28; 11:35:42.758 DEBUG IntToDoubleFunctionCache - cache miss 2649 > 28 expanding to 2659; 11:35:42.766 DEBUG IntToDoubleFunctionCache - cache miss 2666 > 11 expanding to 2676; 11:35:42.789 DEBUG IntToDoubleFunctionCache - cache miss 2667 > 2659 expanding to 5320; 11:35:42.790 DEBUG IntToDoubleFunctionCache - cache miss 2679 > 2676 expanding to 5354; 11:35:43.244 DEBUG Mutect2 - Processing assembly region at chrM:601-900 isActive: false numReads: 0; 11:35:43.823 DEBUG Mutect2 - Processing assembly region at chrM:901-1153 isActive: false numReads: 2725; 11:35:44.025 DEBUG Mutect2 - Processing assembly region at chrM:1154-1397 isActive: true numReads: 5446; 11:35:45.183 DEBUG ReadThreadingGraph - Recovered 0 of 0 dangling tails; 11:35:45.190 DEBUG ReadThreadingGraph - Recovered 0 of 1 dangling heads; 11:35:45.409 DEBUG IntToDoubleFunctionCache - cache miss 0 > -1 expanding to 10; 11:35:45.413 DEBUG Mutect2Engine - Active Region chrM:1154-1397; 11:35:45.413 DEBUG Mutect2Engine - Extended Act Region chrM:1054-1497; 11:35:45.413 DEBUG Mutect2Engine - Ref haplotype coords chrM:1054-1497; 11:35:45.413 DEBUG Mutect2Engine - Haplotype count 1; 11:35:45.413 DEBUG Mutect2Engine - Kmer sizes count 0; 11:35:45.414 DEBUG Mutect2Engine - Kmer sizes values []; 11:35:45.737 DEBUG Mutect2 - Processing assembly region at chrM:1398-1697 isActive: false numReads: 2722; 11:35:45.837 DEBUG Mutect2 - Processing assembly region at chrM:1698-1997 isActive: false numReads: 0; 11:35:45.999 DEBUG Mutect2 - Processing assembly region at chrM:1998-2297 isActive: false numReads: 0; 11:35:46.219 DEBUG Mutect2 - Processing assembly region at chrM:2298-2543 isActive: false numReads: 2555; 11:35:46.674 DEBUG Mutect2 - Processing assembly region at chrM:2544-2841 isActive: true numReads: 5108; 11:35:48.094 DEBUG ReadThreadingGraph - Recovered 17 of 20 dangling tails; 11:35:48.198 DEBUG ReadThreadingGraph - Recovered 16 of 50 dangling heads; 11:35:48.511 DEBUG IntToDoubleFunctionCache - cache miss 2389 >,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:8355,Extend,Extended,8355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Extend'],['Extended']
Modifiability," 676191.6; 13:54:20.447 INFO ProgressMeter - chrX:39799780 9.4 6342000 676514.9; 13:54:30.520 INFO ProgressMeter - chrX:91818371 9.5 6453000 676246.2; 13:54:40.591 INFO ProgressMeter - chrX:143619069 9.7 6568000 676399.8; 13:54:50.640 INFO ProgressMeter - chrUn_KI270743v1:125398 9.9 6674000 675662.2; 13:55:00.673 INFO ProgressMeter - chr20_KI270869v1_alt:62679 10.0 6792000 676161.8; 13:55:10.679 INFO ProgressMeter - chr19_GL949752v1_alt:485077 10.2 6910000 676673.7; 13:55:26.149 INFO ProgressMeter - HLA-DRB1*11:01:02:3272 10.5 6938356 662718.7; 13:55:26.149 INFO ProgressMeter - Traversal complete. Processed 6938356 total records in 10.5 minutes.; 13:55:26.149 INFO ComposeSTRTableFile - Shutting down engine; [April 4, 2021 1:55:26 PM EDT] org.broadinstitute.hellbender.tools.dragstr.ComposeSTRTableFile done. Elapsed time: 10.52 minutes.; Runtime.totalMemory()=1128792064; Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16G -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar CalibrateDragstrModel -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --str-table-path gvcf.STR/ADNI_002_S_0413.hg38.realign.bqsr/ADNI_002_S_0413.hg38.realign.bqsr.STR.table -O gvcf.STR/ADNI_002_S_0413.hg38.realign.bqsr/ADNI_002_S_0413.hg38.realign.bqsr.Dragstr.model -I /restricted/projectnb/casa/wgs.hg38/adni/cram/ADNI_002_S_0413.hg38.realign.bqsr.cram; 13:55:30.890 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Apr 04, 2021 1:55:31 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182:11278,variab,variable,11278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182,1,['variab'],['variable']
Modifiability," : 131072; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.REFERENCE_FASTA : null; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; > 21:13:04.224 DEBUG ConfigFactory - Configuration file values:; > 21:13:04.230 DEBUG ConfigFactory - gcsMaxRetries = 20; > 21:13:04.230 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; > 21:13:04.230 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; > 21:13:04.230 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; > 21:13:04.230 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; > 21:13:04.230 DEBUG ConfigFactory - samjdk.compression_level = 1; > 21:13:04.230 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; > 21:13:04.230 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; > 21:13:04.230 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; > 21:13:04.230 DEBUG ConfigFactory - spark.io.compression.codec = lzf; > 21:13:04.230 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; > 21:13:04.230 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; > 21:13:04.230 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; > 21:13:04.230 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; > 21:13:04.230 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; > 21:13:04.231 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; > 21:13:04.231 DEBUG ConfigFactory - createOutputBamIndex = true; > 21:13:04.231 INFO GenotypeGVCFs - Deflater: IntelDeflater; > 21:13:04.231 INFO GenotypeGVCFs - Inflater: IntelInfla",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4161:3777,Config,ConfigFactory,3777,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4161,1,['Config'],['ConfigFactory']
Modifiability," : true; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 20:41:37.620 DEBUG ConfigFactory - Configuration file values:; 20:41:37.626 DEBUG ConfigFactory - gcsMaxRetries = 20; 20:41:37.626 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 20:41:37.626 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 20:41:37.626 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 20:41:37.626 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 20:41:37.626 DEBUG ConfigFactory - samjdk.compression_level = 2; 20:41:37.626 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 20:41:37.626 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 20:41:37.626 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 20:41:37.626 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 20:41:37.626 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 20:41:37.626 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 20:41:37.627 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 20:41:37.627 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 20:41:37.627 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 20:41:37.627 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 20:41:37.627 DEBUG ConfigFactory - createOutputBamIndex = true; 20:41:37.627 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 20:41:37.627 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 20:41:37.627 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 20:41:37.627 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 20:41:37.627 INFO PathSeqPipelineSpark - Initializing engine; 20:41:37.627 INFO PathSeqPipelineSpark -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:5566,Config,ConfigFactory,5566,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['Config'],['ConfigFactory']
Modifiability, <0> (?)` | |; | [...ils/optimization/PersistenceOptimizerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL29wdGltaXphdGlvbi9QZXJzaXN0ZW5jZU9wdGltaXplclVuaXRUZXN0LmphdmE=) | `2% <0%> (ø)` | `1 <0> (?)` | |; | [...utils/downsampling/DownsamplingMethodUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRG93bnNhbXBsaW5nTWV0aG9kVW5pdFRlc3QuamF2YQ==) | `3.448% <0%> (ø)` | `1 <0> (?)` | |; | [...yper/StandardCallerArgumentCollectionUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9TdGFuZGFyZENhbGxlckFyZ3VtZW50Q29sbGVjdGlvblVuaXRUZXN0LmphdmE=) | `4.098% <0%> (ø)` | `2 <0> (?)` | |; | [...lbender/utils/mcmc/ParameterizedStateUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9tY21jL1BhcmFtZXRlcml6ZWRTdGF0ZVVuaXRUZXN0LmphdmE=) | `14.286% <0%> (ø)` | `2 <0> (?)` | |; | [...itute/hellbender/engine/ProgressMeterUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlclVuaXRUZXN0LmphdmE=) | `1.282% <0%> (ø)` | `1 <0> (?)` | |; | [...broadinstitute/hellbender/utils/UtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9VdGlsc1VuaXRUZXN0LmphdmE=) | `0.206% <0%> (ø)` | `1 <0> (?)` | |; | [...eVcfWithExpectedAlleleFractionIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlb,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750:2068,Parameteriz,ParameterizedStateUnitTest,2068,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750,1,['Parameteriz'],['ParameterizedStateUnitTest']
Modifiability," Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.REFERENCE_FASTA : null; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 11:35:40.190 DEBUG ConfigFactory - Configuration file values: ; 11:35:40.196 DEBUG ConfigFactory - 	gcsMaxRetries = 20; 11:35:40.196 DEBUG ConfigFactory - 	gcsProjectForRequesterPays = ; 11:35:40.196 DEBUG ConfigFactory - 	gatk_stacktrace_on_user_exception = false; 11:35:40.196 DEBUG ConfigFactory - 	samjdk.use_async_io_read_samtools = false; 11:35:40.196 DEBUG ConfigFactory - 	samjdk.use_async_io_write_samtools = true; 11:35:40.197 DEBUG ConfigFactory - 	samjdk.use_async_io_write_tribble = false; 11:35:40.197 DEBUG ConfigFactory - 	samjdk.compression_level = 2; 11:35:40.197 DEBUG ConfigFactory - 	spark.kryoserializer.buffer.max = 512m; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.maxResultSize = 0; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.userClassPathFirst = true; 11:35:40.197 DEBUG ConfigFactory - 	spark.io.compression.codec = lzf; 11:35:40.197 DEBUG ConfigFactory - 	spark.executor.memoryOverhead = 600; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.extraJavaOptions = ; 11:35:40.198 DEBUG ConfigFactory - 	spark.executor.extraJavaOptions = ; 11:35:40.198 DEBUG ConfigFactory - 	codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 11:35:40.198 DEBUG ConfigFactory - 	read_filter_packages = [org.broadinstitute.hellbend",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:3552,Config,ConfigFactory,3552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Config'],['ConfigFactory']
Modifiability," Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 08:48:45.921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 08:48:45.921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.REFERENCE_FASTA : null; 08:48:45.921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 08:48:45.921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 08:48:45.921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 08:48:45.922 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 08:48:45.922 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 08:48:45.922 DEBUG ConfigFactory - Configuration file values:; 08:48:45.927 DEBUG ConfigFactory - gcsMaxRetries = 20; 08:48:45.927 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 08:48:45.927 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 08:48:45.927 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 08:48:45.927 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 08:48:45.927 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 08:48:45.927 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 08:48:45.927 DEBUG ConfigFactory - samjdk.compression_level = 2; 08:48:45.927 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 08:48:45.927 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 08:48:45.927 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 08:48:45.927 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 08:48:45.927 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 08:48:45.927 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 08:48:45.928 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 08:48:45.928 DEBUG ConfigFactory",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6217:4197,Config,ConfigFactory,4197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6217,1,['Config'],['ConfigFactory']
Modifiability," Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.REFERENCE_FASTA : null; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 11:35:40.190 DEBUG ConfigFactory - Configuration file values: ; 11:35:40.196 DEBUG ConfigFactory - 	gcsMaxRetries = 20; 11:35:40.196 DEBUG ConfigFactory - 	gcsProjectForRequesterPays = ; 11:35:40.196 DEBUG ConfigFactory - 	gatk_stacktrace_on_user_exception = false; 11:35:40.196 DEBUG ConfigFactory - 	samjdk.use_async_io_read_samtools = false; 11:35:40.196 DEBUG ConfigFactory - 	samjdk.use_async_io_write_samtools = true; 11:35:40.197 DEBUG ConfigFactory - 	samjdk.use_async_io_write_tribble = false; 11:35:40.197 DEBUG ConfigFactory - 	samjdk.compression_level = 2; 11:35:40.197 DEBUG ConfigFactory - 	spark.kryoserializer.buffer.max = 512m; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.maxResultSize = 0; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.userClassPathFirst = true; 11:35:40.197 DEBUG ConfigFactory - 	spark.io.compression.codec = lzf; 11:35:40.197 DEBUG ConfigFactory - 	spark.executor.memoryOverhead = 600; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.extraJavaOptions = ; 11:35:40.198 DEBUG ConfigFactory - 	spark.executor.extraJavaOptions = ; 11:35:40.198 DEBUG ConfigFactory - 	codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 11:35:40.198 DEBUG ConfigFactory - 	read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 11:35:40.198 DEBUG ConfigFactory - 	annotation_packages = [",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:3631,Config,ConfigFactory,3631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Config'],['ConfigFactory']
Modifiability," HTSJDK Defaults.CUSTOM_READER_FACTORY :; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.REFERENCE_FASTA : null; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 20:41:37.620 INFO PathSeqPipelineSpark - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 20:41:37.620 DEBUG ConfigFactory - Configuration file values:; 20:41:37.626 DEBUG ConfigFactory - gcsMaxRetries = 20; 20:41:37.626 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 20:41:37.626 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 20:41:37.626 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 20:41:37.626 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 20:41:37.626 DEBUG ConfigFactory - samjdk.compression_level = 2; 20:41:37.626 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 20:41:37.626 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 20:41:37.626 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 20:41:37.626 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 20:41:37.626 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 20:41:37.626 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 20:41:37.627 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 20:41:37.627 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:4848,Config,ConfigFactory,4848,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['Config'],['ConfigFactory']
Modifiability," HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 23:43:52.472 DEBUG ConfigFactory - Configuration file values: ; 23:43:52.474 DEBUG ConfigFactory - 	gcsMaxRetries = 20; 23:43:52.474 DEBUG ConfigFactory - 	gcsProjectForRequesterPays = ; 23:43:52.474 DEBUG ConfigFactory - 	gatk_stacktrace_on_user_exception = false; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.use_async_io_read_samtools = false; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.use_async_io_write_samtools = true; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.use_async_io_write_tribble = false; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.compression_level = 2; 23:43:52.474 DEBUG ConfigFactory - 	spark.kryoserializer.buffer.max = 512m; 23:43:52.474 DEBUG ConfigFactory - 	spark.driver.maxResultSize = 0; 23:43:52.474 DEBUG ConfigFactory - 	spark.driver.userClassPathFirst = true; 23:43:52.474 DEBUG ConfigFactory - 	spark.io.compression.codec = lzf; 23:43:52.474 DEBUG ConfigFactory - 	spark.executor.memoryOverhead = 600; 23:43:52.475 DEBUG ConfigFactory - 	spark.driver.extraJavaOptions = ; 23:43:52.475 DEBUG ConfigFactory - 	spark.executor.extraJavaOptions = ; 23:43:52.475 DEBUG ConfigFactory - 	codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 23:43:52.475 DEBUG ConfigFactory - 	read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 23:43:52.475 DEBUG ConfigFactory - 	annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 23:43:52.477 DEBUG ConfigFactory - 	cloudPrefetchBuffer = 40; 23:43:52.477 DEBUG ConfigFactory - 	cloudIndexPrefetchBuffer = -1; 23:43:52.477 DEBUG ConfigFactory - 	createOutputBamIndex = true; 23:43:52.477 INFO GermlineCNVCaller - Deflater: In",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:3455,Config,ConfigFactory,3455,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['Config'],['ConfigFactory']
Modifiability, Haplotype count 1; 11:35:45.413 DEBUG Mutect2Engine - Kmer sizes count 0; 11:35:45.414 DEBUG Mutect2Engine - Kmer sizes values []; 11:35:45.737 DEBUG Mutect2 - Processing assembly region at chrM:1398-1697 isActive: false numReads: 2722; 11:35:45.837 DEBUG Mutect2 - Processing assembly region at chrM:1698-1997 isActive: false numReads: 0; 11:35:45.999 DEBUG Mutect2 - Processing assembly region at chrM:1998-2297 isActive: false numReads: 0; 11:35:46.219 DEBUG Mutect2 - Processing assembly region at chrM:2298-2543 isActive: false numReads: 2555; 11:35:46.674 DEBUG Mutect2 - Processing assembly region at chrM:2544-2841 isActive: true numReads: 5108; 11:35:48.094 DEBUG ReadThreadingGraph - Recovered 17 of 20 dangling tails; 11:35:48.198 DEBUG ReadThreadingGraph - Recovered 16 of 50 dangling heads; 11:35:48.511 DEBUG IntToDoubleFunctionCache - cache miss 2389 > 10 expanding to 2399; 11:35:48.874 DEBUG Mutect2Engine - Active Region chrM:2544-2841; 11:35:48.874 DEBUG Mutect2Engine - Extended Act Region chrM:2444-2941; 11:35:48.875 DEBUG Mutect2Engine - Ref haplotype coords chrM:2444-2941; 11:35:48.875 DEBUG Mutect2Engine - Haplotype count 128; 11:35:48.875 DEBUG Mutect2Engine - Kmer sizes count 0; 11:35:48.875 DEBUG Mutect2Engine - Kmer sizes values []; 11:36:08.907 INFO ProgressMeter - chrM:2544 0.4 10 22.3; 11:36:08.954 DEBUG Mutect2 - Processing assembly region at chrM:2842-2920 isActive: false numReads: 4726; 11:36:09.094 DEBUG Mutect2 - Processing assembly region at chrM:2921-3202 isActive: true numReads: 4600; 11:36:09.663 DEBUG ReadThreadingGraph - Recovered 1 of 2 dangling tails; 11:36:09.671 DEBUG ReadThreadingGraph - Recovered 4 of 7 dangling heads; 11:36:09.750 DEBUG Mutect2Engine - Active Region chrM:2921-3202; 11:36:09.750 DEBUG Mutect2Engine - Extended Act Region chrM:2821-3302; 11:36:09.750 DEBUG Mutect2Engine - Ref haplotype coords chrM:2821-3302; 11:36:09.751 DEBUG Mutect2Engine - Haplotype count 32; 11:36:09.751 DEBUG Mutect2Engine - Kmer sizes count 0; 11,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:9488,Extend,Extended,9488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Extend'],['Extended']
Modifiability," INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 3, 2017 5:27:51 AM UTC] Executing as centos@master.novalocal on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11; Version: 4.beta.5; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 05:27:52.642 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 05:27:52.642 INFO PrintReadsSpark - Deflater: IntelDeflater; 05:27:52.642 INFO PrintReadsSpark - Inflater: IntelInflater; 05:27:52.643 INFO PrintReadsSpark - GCS max retries/reopens: 20; 05:27:52.643 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 05:27:52.643 INFO PrintReadsSpark - Initializing engine; 05:27:52.643 INFO PrintReadsSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@dcf3e99] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@61df66b6].; log4j:ERROR Could not instantiate appender named ""console"".; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; log4j:WARN No appenders could be found for logger (org.apache.spark.SparkContext).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; ```; I can run command using the spark-shell but somehow GATK4 fails. Any idea?. thank you very much",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3651:3536,variab,variable,3536,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3651,1,['variab'],['variable']
Modifiability, INFO GermlineCNVCaller - HTSJDK Defaults.CUSTOM_READER_FACTORY : ; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.REFERENCE_FASTA : null; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:37:00.975 INFO GermlineCNVCaller - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 23:37:00.976 DEBUG ConfigFactory - Configuration file values: ; 23:37:00.982 DEBUG ConfigFactory - gcsMaxRetries = 20; 23:37:00.982 DEBUG ConfigFactory - gcsProjectForRequesterPays = ; 23:37:00.982 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 23:37:00.982 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 23:37:00.982 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 23:37:00.982 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 23:37:00.983 DEBUG ConfigFactory - samjdk.compression_level = 2; 23:37:00.983 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 23:37:00.983 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 23:37:00.983 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 23:37:00.983 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 23:37:00.983 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 23:37:00.983 DEBUG ConfigFactory - spark.driver.extraJavaOptions = ; 23:37:00.983 DEBUG ConfigFactory - spark.executor.extraJavaOptions = ; 23:37:00.983 DEBUG ConfigFactory - c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:3812,Config,ConfigFactory,3812,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,1,['Config'],['ConfigFactory']
Modifiability," Instructions. The github issue tracker is for bug reports, feature requests, and API documentation requests. General questions about how to use the GATK, how to interpret the output, etc. should be asked on the [official support forum](http://gatkforums.broadinstitute.org/gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Feature request. ### Tool(s) or class(es) involved. VariantRecalibrator. ### Description. VariantRecalibrator automatically runs the generated Rscript to produce recalibration plots. This is usually good and convenient, but it requires that all *R* dependencies must be installed in the same environment in the current running GATK environment. This is not necessarily the case for sandbox-based package managers e.g. docker or conda. A viable fix on the user's side is to include R dependencies with GATK in e.g. docker or conda. But I think I would prefer if my packages were as independent of each other as possible. It would be great if **VariantRecalibrator had an option to write but not run the Rscript for recalibration plots.** Then, the user can call the Rscript in an appropriate e.g. R conda environment or docker image.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7697:1553,sandbox,sandbox-based,1553,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7697,1,['sandbox'],['sandbox-based']
Modifiability, Server VM warning: Insufficient space for shared memory file:; 30934; Try using the -Djava.io.tmpdir= option to select an alternate temp location. FAILURE: Build failed with an exception. * What went wrong:; Gradle could not start your build.; > Cannot create service of type DependencyLockingHandler using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyLockingHandler() as there is a problem with parameter #2 of type ConfigurationContainerInternal.; > Cannot create service of type ConfigurationContainerInternal using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createConfigurationContainer() as there is a problem with parameter #13 of type DefaultConfigurationFactory.; > Cannot create service of type DefaultConfigurationFactory using DefaultConfigurationFactory constructor as there is a problem with parameter #2 of type ConfigurationResolver.; > Cannot create service of type ConfigurationResolver using method DefaultDependencyManagementServices$DependencyResolutionScopeServices.createDependencyResolver() as there is a problem with parameter #1 of type ArtifactDependencyResolver.; > Cannot create service of type ArtifactDependencyResolver using method DependencyManagementBuildScopeServices.createArtifactDependencyResolver() as there is a problem with parameter #4 of type List<ResolverProviderFactory>.; > Could not create service of type VersionControlRepositoryConnectionFactory using VersionControlBuildSessionServices.createVersionControlSystemFactory().; > Failed to create parent directory '/home/jdjdj0202/gatk/.gradle' when creating directory '/home/jdjdj0202/gatk/.gradle/vcs-1'. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. BUILD FAILED in 754ms. FAILURE: Build failed with an exception. * What went wrong:; Could not update /home/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8346:1500,Config,ConfigurationResolver,1500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8346,1,['Config'],['ConfigurationResolver']
Modifiability," Since GC bias is a; > property of the fragments that are pulled by the baits, a reasonable; > measure of ""GC content"" of each bait has to be calculated from the expected; > value of the GC content of the fragments that the bait pulls (not the GC; > content of the baits or targets), and this can be easily calculated from; > the previously obtained empirical distributions.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk-protected/issues/914>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0qEpyk5wss6qvl653UQo-BAiQWfIks5rdjPNgaJpZM4ME4kq>; > .; >. ---. @mbabadi commented on [Sat Feb 18 2017](https://github.com/broadinstitute/gatk-protected/issues/914#issuecomment-280820307). @yfarjoun, thanks for your comments. On the first two points, I agree. Let me clarify: I was going to use the bait-length and insert-length as _hyperparameters_ of the pdf, where the pdf itself gives the probability of having an insert in a certain configuration relative to the bait. I think the parametrization you proposed, i.e. the distance between nearest ends of insert and bait, is very reasonable since the PDF is going to be reflection-symmetric once averaged over all baits; and you're right, the bait length is constant (77bp for ICE) so we can drop it from the analysis. If the fragment capture efficiency is insensitive to the relative position of the bait sequence in the fragment, we expect the pdf to be approximately uniform (save for boundary effects at the scale of bait length), with the 0.5 x (insert length - bait length) setting the upper bound of the distribution. However, some dependency on the position of the bait is expected: e.g. if the bait sequence is on the dangling end of a fragment, it is less likely to stay bound than if it is in the middle of the fragment. I'm curious to see what comes out (who knows -- maybe another 6-bp periodicity!).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2947:6394,config,configuration,6394,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2947,1,['config'],['configuration']
Modifiability," [VS-472] (#7905); - Fix bug and update images (#7912); - VS 483 Beta user wdl (#7894); - Core storage model cost [VS-473] (#7913); - Update Quickstart & Integration to use re-blocked v2 gVCFs [VS-491] (#7924); - KM GVS documentation (#7903); - Track BigQuery costs of GVS python VS-480 (#7915); - Read cost observability table [VS-475] (#7923); - Fix Race Condition, Add Support for Extract by Array of Sample Names (ie from a Sample Set) (#7917); - Rightsize import batches [VS-486] (#7925); - [AoU DRC] Support uppercase site_ids for reblocking (#7929); - Populate cost metadata for GATK tasks. (#7919); - remove accidentally added input (#7931); - VS_492 - Beta User Jar release (#7934); - Cost WDL should throw on FISS API errors [VS-518] (#7942); - Fix bad check for missing workflow name [VS-520] (#7943); - Remove usage of service account from GvsValidateVAT.wdl (#7937); - refactoring for testablity (#7946); - More import retries [VS-532] (#7953); - A few last doc changes (#7927); - WDL to extract a single callset cost (BQ only, not Terra) (#7940); - Temporarily swap in Corretto for Temurin as we can't download Temurin. (#7969); - GL-548 - Update CreateVat code to handle samples that do not contain all population groups. (#7965); - Restore Temurin 11 [VS-570] (#7972); - Add table size check to quickstart integration test [VS-501] (#7970); - Consolidate various docs for AoU callset generation into one to rule them all [VS-553] (#7971); - VS-567. Removing usage of ServiceAccount from CreateVat related WDLs (#7974); - WDL to extract Avro files for Hail import [VS-579] (#7981); - Removed usage of service account from WDLs (#7985); - Document steps for GVS cleanup for base use case [VS-586] (#7989); - Change backticks to single quotes in several error messages - causing shell to attempt to execute. (#7995); - VS-598 - Minor update to AoU Documentation. (#7994); - Allow for incremental addition of data to alt_allele [VS-52] (#7993); - Minor AoU Documentation Update (#7999); -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:26457,refactor,refactoring,26457,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['refactor'],['refactoring']
Modifiability," burden. The parties interested in working on a specific architecture will contribute code directly to the respective architecture-specific repo and gatk will take occasional updates of those repos. The gatk repo will depend on the other two. The PPC repo will depend on the AVX repo (and any other native repos will depend on the AVX one). The avx and ppc repos will have their own build systems and unit tests against the new interface. The AVX repo will expose something like the following Java API (to be worked out in detail). ```; //Used to copy references to byteArrays to JNI from reads; public final class JNIReadDataHolderClass {; public byte[] readBases = null;; public byte[] readQuals = null;; public byte[] insertionGOP = null;; public byte[] deletionGOP = null;; public byte[] overallGCP = null;; }. //Used to copy references to byteArrays to JNI from haplotypes; public final class JNIHaplotypeDataHolderClass {; public byte[] haplotypeBases = null;; }. public interface NativePairHMMKernel extends AutoCloseable { . /**; * Function to initialize the fields of JNIReadDataHolderClass and JNIHaplotypeDataHolderClass from JVM.; * C++ code gets FieldIDs for these classes once and re-uses these IDs for the remainder of the program. Field IDs do not; * change per JVM session; *; * @param readDataHolderClass class type of JNIReadDataHolderClass; * @param haplotypeDataHolderClass class type of JNIHaplotypeDataHolderClass; */; void jniInitializeClassFields(Class<JNIReadDataHolderClass> readDataHolderClass, Class<JNIHaplotypeDataHolderClass> haplotypeDataHolderClass);. /**; * Real compute kernel; */; void jniComputeLikelihoods(int numReads, int numHaplotypes, JNIReadDataHolderClass[] readDataArray,; JNIHaplotypeDataHolderClass[] haplotypeDataArray, double[] likelihoodArray, int maxNumThreadsToUse);. /**; * Print final profiling information from native code. ; */; default void close() { jniClose(); }. void jniClose();; }; ```. and a class that implements those as native methods",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864:1680,extend,extends,1680,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864,1,['extend'],['extends']
Modifiability," changes relevant to gatk -; * Allow changes for allele specific and other annotations to vid file via GenomicsDBImporter without hardcoding them in genomicsdb. See [GenomicsDB Fix 39](https://github.com/GenomicsDB/GenomicsDB/pull/39). Thanks @mlathara.; * [Fix](https://github.com/GenomicsDB/GenomicsDB/pull/54) for ; BUGreportGATK-07-19-19 reported by @bshifaw where a large ploidy + number of genotypes was leading to math overflow. The overflow is now caught and GenomicsDB stops enumerating genotypes for this case. Thanks @kgururaj.; * [Fix](https://github.com/GenomicsDB/GenomicsDB/pull/66) for missing libcurl in the native GenomicsDB library - Issue #6122 ; * [Fix](https://github.com/GenomicsDB/GenomicsDB/pull/67) to avoid crashing when vcfbufferstream from htslib happens to be invalid. This check was put in response to the [Forum Issue 59667](https://gatkforums.broadinstitute.org/gatk/discussion/comment/59667#Comment_59667). Note that the test vcfs [sample2](https://github.com/broadinstitute/gatk/tree/master/src/test/resources/org/broadinstitute/hellbender/tools/mutect/createpon/sample2.vcf), [sample3](https://github.com/broadinstitute/gatk/tree/master/src/test/resources/org/broadinstitute/hellbender/tools/mutect/createpon/sample3.vcf) and [sample4](https://github.com/broadinstitute/gatk/tree/master/src/test/resources/org/broadinstitute/hellbender/tools/mutect/createpon/sample4.vcf) had to be changed to be htslib compliant for importing and to run `org.broadinstitute.hellbender.tools.walkers.mutect.CreateSomaticPanelOfNormalsIntegrationTest` successfully.; * Allow for native GenomicsDBExceptions to be propagated as java IOExceptions to allow gatk to gracefully handle the exception by printing out relevant information. See [GenomicsDB Fix 68](https://github.com/GenomicsDB/GenomicsDB/pull/68).; * [Fix](https://github.com/GenomicsDB/GenomicsDB/pull/70) for issues using vid protobuf interface to pass vid information and there is more than one config. Thanks @mlathara.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6188:1988,config,config,1988,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6188,1,['config'],['config']
Modifiability," code, though I don't know how much you cleaned up the GATK4 version. We would also want to make sure that we only implement this optimization if that SNP is the only SNP on the haplotype. In cases where the haplotype has multiple SNPs and the phasing is poor, this could artificially inflate the likelihoods. Although we've seen that the graph traversal frequently breaks phasing then generating haplotypes anyway, so maybe I overestimate our current likelihood accuracy. Anyway, take my advice with a grain of salt. It's just some musings from a bored and somewhat sleep-deprived mom with a sleeping baby on her lap. ---. @davidbenjamin commented on [Fri Mar 03 2017](https://github.com/broadinstitute/gatk-protected/issues/909#issuecomment-284024760). > I think the main blocker in implementing it would be the complexity of the existing code, though I don't know how much you cleaned up the GATK4 version. We refactored all the engine stuff shared with `HaplotypeCaller` to be very distinct from the somatic genotyping logic, so the only complexity would be in local assembly and PairHMM. Which could be significant, of course. > We would also want to make sure that we only implement this optimization if that SNP is the only SNP on the haplotype. . .Although we've seen that the graph traversal frequently breaks phasing. The specific case I had in mind is when you have a bubble or something more complex in the graph, followed by a stretch of reference (i.e. all haplotypes have nothing going on here), followed (or not) by more activity. It seems reasonable in that case to chop each active area into its own haplotype(s), which is equivalent to pinning the ref-only area to be ref-only in PairHMM. I believe but could be wrong that in a case like this our assembly would not respect phasing between the two active areas anyway, so we lose nothing. By the way, I should clarify that the idea is not to truncate the `ActiveRegion`, but rather to break it into a few small haplotypes semi-intel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2945:1539,refactor,refactored,1539,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2945,1,['refactor'],['refactored']
Modifiability," correct places, which often manifests as simply re-clipping the soft-clipped bases where necessary. This might seem expensive but low quality ends are fairly rare and consequently this has a negligible effect on runtime. ; (NOTE: this might cause unintended consequences for annotations, which have not been extensively tested thus far); - The `DRAGENGenotypeLikelihoodCalculator` object is actually an instantiation of the regular `GenotypeLikelihoodCalculator` object that is called normally for the standard variant model calculation and then has its computed tables/values reused for the subsequent calculations. This means there is a risk if not careful of using the table values for the wrong reads/sties if we are not strict about the state of the cache.; - Currently in order to lower the mapping quality threshold for HaplotypeCaller two separate arguments must be called. This is because the mapping-quality threshold is checked twice, once for the read filter plugin `getToolDefaultArgumentCollections()` which gets instantiated before the HaplotypeCaller arguments are populated, and again before assembly. While the functionality to be stricter about mapping quality for assembly compared to active region discovery might be important it is unclear if this matters and perhaps the latter check can be done away with? ; - I have added a genotype debugging stream that closely matches the debug output stream from DRAGEN (which itself was a reflection of the GATK3 debug out stream). This involved a lot of threading output writers through the codebase and perhaps this is better handled by the ""--debug"" argument like it used to? Thoughts? . Notes: ; - It should be noted that by design all of the added changes to HaplotypeCaller are opt-in, barring errors in implementation.; - This code is measurably slower than vanilla HaplotypeCaller. In particular FRD is a very expensive step that corresponds to ~5-7% of the runtime. This is in part because it has to duplicate many of the steps ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6634:3117,plugin,plugin,3117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6634,1,['plugin'],['plugin']
Modifiability," counts file(s)...; 10:20:12.545 INFO gcnvkernel.io.io_metadata - Loading germline contig ploidy and global read depth metadata...; 10:20:12.554 INFO root - Loading denoising model configuration from the provided model...; 10:20:12.555 INFO root - - bias factors enabled: True; 10:20:12.555 INFO root - - explicit GC bias modeling enabled: True; 10:20:12.555 INFO root - - bias factors in active classes disabled: False; 10:20:12.555 INFO root - - maximum number of bias factors: 5; 10:20:12.555 INFO root - - number of GC curve knobs: 20; 10:20:12.555 INFO root - - GC curve prior standard deviation: 1.0; 10:20:12.954 INFO gcnvkernel.tasks.task_case_denoising_calling - Instantiating the denoising model...; 10:20:15.806 INFO gcnvkernel.tasks.task_case_denoising_calling - Instantiating the sampler...; 10:20:15.807 INFO gcnvkernel.tasks.task_case_denoising_calling - Instantiating the copy number caller...; 10:20:18.549 INFO gcnvkernel.models.fancy_model - Global model variables: {'log_mean_bias_t', 'psi_t_log__', 'W_tu', 'ard_u_log__'}; 10:20:18.549 INFO gcnvkernel.models.fancy_model - Sample-specific model variables: {'read_depth_s_log__', 'psi_s_log__', 'z_sg', 'z_su'}; 10:20:18.549 INFO gcnvkernel.tasks.inference_task_base - Instantiating the convergence tracker...; 10:20:18.549 INFO gcnvkernel.tasks.inference_task_base - Setting up DA-ADVI...; 10:20:24.995 INFO gcnvkernel.tasks.task_case_denoising_calling - Loading the model and updating the instantiated model and workspace...; 10:20:25.005 INFO gcnvkernel.io.io_commons - Reading model parameter values for ""log_mean_bias_t""... Stderr: Traceback (most recent call last):; File ""/media/Data/tmp/case_denoising_calling.3564509013495540802.py"", line 201, in <module>; shared_workspace, initial_params_supplier, args.input_model_path); File ""/usr/BioinfSoftware/Anaconda/3-2020.11/envs/gatk4.3.0.0/lib/python3.6/site-packages/gcnvkernel/tasks/task_case_denoising_calling.py"", line 128, in __init__; self.continuous_model_approx, inpu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8740:7306,variab,variables,7306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8740,1,['variab'],['variables']
Modifiability," false; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; > 21:13:04.224 DEBUG ConfigFactory - Configuration file values:; > 21:13:04.230 DEBUG ConfigFactory - gcsMaxRetries = 20; > 21:13:04.230 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; > 21:13:04.230 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; > 21:13:04.230 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; > 21:13:04.230 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; > 21:13:04.230 DEBUG ConfigFactory - samjdk.compression_level = 1; > 21:13:04.230 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; > 21:13:04.230 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; > 21:13:04.230 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; > 21:13:04.230 DEBUG ConfigFactory - spark.io.compression.codec = lzf; > 21:13:04.230 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; > 21:13:04.230 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; > 21:13:04.230 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; > 21:13:04.230 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; > 21:13:04.230 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; > 21:13:04.231 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; > 21:13:04.231 DEBUG ConfigFactory - createOutputBamIndex = true; > 21:13:04.231 INFO GenotypeGVCFs - Deflater: IntelDeflater; > 21:13:04.231 INFO GenotypeGVCFs - Inflater: IntelInflater; > 21:13:04.231 INFO GenotypeGVCFs - GCS max retries/reopens: 20; > 21:13:04.231 INFO GenotypeGVCFs - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; > 21:13:04.231 INFO GenotypeGVCFs - Initializing engine; > 21:13:11.834 INFO GenotypeGVCFs - Done initializing engine; > 21:13:11.950 DEBUG MathUtils$Log10Cache - cache miss 2 > 0 expanding",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4161:4217,Config,ConfigFactory,4217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4161,1,['Config'],['ConfigFactory']
Modifiability," for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!?[0m. 16:58:10.116 INFO PrintVariantsSpark - Initializing engine; 16:58:10.116 INFO PrintVariantsSpark - Done initializing engine; 19/02/18 16:58:10 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19/02/18 16:58:10 INFO org.spark_project.jetty.util.log: Logging initialized @8431ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: Started @8536ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 19/02/18 16:58:11 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 19/02/18 16:58:12 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:8032; 19/02/18 16:58:13 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:10200; 19/02/18 16:58:15 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1550508751046_0004; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalB",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:4692,config,configuration,4692,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['config'],['configuration']
Modifiability," if true, annotate the M2 VCFs using oncotator (to produce a TCGA MAF); ##; ## ** Primary inputs **; ## ref_fasta, ref_fasta_index, ref_dict: reference genome, index, and dictionary; ## tumor_bam, tumor_bam_index, and tumor_sample_name: BAM, index and sample name for the tumor sample (sample name used for output naming); ## normal_bam, normal_bam_index, and normal_sample_name: BAM, index and sample name for the normal sample (optional if running tumor-only); ##; ## ** Primary resources ** (optional but strongly recommended); ## pon, pon_index: optional panel of normals in VCF format containing probable technical artifacts (false positves); ## gnomad, gnomad_index: optional database of known germline variants (see http://gnomad.broadinstitute.org/downloads); ## variants_for_contamination, variants_for_contamination_index: VCF of common variants with allele frequencies fo calculating contamination; ##; ## ** Secondary resources ** (for optional tasks); ## onco_ds_tar_gz, default_config_file: Oncotator datasources and config file; ## sequencing_center, sequence_source: metadata for Oncotator; ##; ## Outputs :; ## - One VCF file and its index with primary filtering applied; secondary filtering and functional annotation if requested.; ##; ## Cromwell version support ; ## - Successfully tested on v27; ##; ## LICENSING : ; ## This script is released under the WDL source code license (BSD-3) (see LICENSE in ; ## https://github.com/broadinstitute/wdl). Note however that the programs it calls may ; ## be subject to different licenses. Users are responsible for checking that they are; ## authorized to run all programs before running this script. Please see the docker ; ## pages at https://hub.docker.com/r/broadinstitute/* for detailed licensing information ; ## pertaining to the included programs. workflow Mutect2 {; # Runtime; String gatk4_jar; File picard_jar; String m2_docker; String oncotator_docker; Int preemptible_attempts; # Workflow options; Int scatter_count; File? in",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3341:2528,config,config,2528,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3341,1,['config'],['config']
Modifiability, is of type [org.slf4j.impl.Log4jLoggerFactory]; java.lang.NoClassDefFoundError: org/apache/logging/log4j/core/appender/AbstractAppender; at java.lang.ClassLoader.defineClass1(Native Method); at java.lang.ClassLoader.defineClass(ClassLoader.java:763); at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); at java.net.URLClassLoader.defineClass(URLClassLoader.java:467); at java.net.URLClassLoader.access$100(URLClassLoader.java:73); at java.net.URLClassLoader$1.run(URLClassLoader.java:368); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349); at java.lang.ClassLoader.loadClass(ClassLoader.java:411); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.decodeCacheFiles(PluginRegistry.java:181); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.loadFromMainClassLoader(PluginRegistry.java:119); at org.apache.logging.log4j.core.config.plugins.util.PluginManager.collectPlugins(PluginManager.java:132); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternParser.java:131); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternParser.java:112); at org.apache.logging.log4j.core.layout.PatternLayout.createPatternParser(PatternLayout.java:220); at org.apache.logging.log4j.core.layout.PatternLayout.<init>(PatternLayout.java:138); at org.apache.logging.log4j.core.layout.PatternLayout.<init>(PatternLayout.java:57); at org.apache.logging.log4j.core.layout.PatternLayout$Builder.build(PatternLayout.java:446); at org.apache.logging.log4j.core.config.AbstractConfiguration.setToDefault(AbstractConfiguration.java:518); at org.apache.logging.log4j.core.config.DefaultConfiguration.<init>(DefaultConfi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:3314,Plugin,PluginRegistry,3314,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,1,['Plugin'],['PluginRegistry']
Modifiability," log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.L",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5397,variab,variable,5397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['variab'],['variable']
Modifiability," might have something to do with the incorrect prior -- if the prior is skewing toward homozygosity, then double-counting your variant data might counteract this and rescue some variant genotypes, which will be mainly hets. The EM model that people implicitly seem to have in mind is alternating E steps on each sample to get genotype posteriors with M steps to learn the allele frequencies. So let's work out what happens if you do just one iterations:. 0) Initialize allele frequencies to the mean of the Dirichlet heterozygosity prior; i.e. ~1 for ref, ~1/1000 for each alt, plus any allele counts from the resources. Genotype priors come from the multinomial distribution (one genotype is a draw of 2 alleles) of these allele frequencies.; 1) (E step) genotype posteriors are the product of genotype likelihoods with the priors from step 0). Pseudocounts are the sum of expected posterior allele counts.; 2) (M step) MLE allele frequencies are the mode of the Dirichlet parameterized by the sum of the original step 0) prior+resources pseudocounts with the E step pseudocounts from step 1). Hmmm that does sound a lot like what the code is doing now. I suppose it's defensible after all. ---. @ldgauthier commented on [Thu May 19 2016](https://github.com/broadinstitute/gsa-unstable/issues/1185#issuecomment-220347447). So it sounds to me like the action item here is to fix the Dirichlet heterozygosity prior. I like the idea of adding one count for the ref and 1/1000 for each alt (rather than, for example, 1000 for ref and one for alt) so the heterozygosity prior does something in the absence of external resource counts, but doesn't overwhelms them if they are present. @davidbenjamin Can you think of a more rigorous justification for the scaling of counts between sample genotype allele counts and the heterozygosity?. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1185#issuecomment-260474993). Is this still alive? To be continued in ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2918:5252,parameteriz,parameterized,5252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2918,1,['parameteriz'],['parameterized']
Modifiability," on the [forum](https://gatkforums.broadinstitute.org/gatk/discussion/13680/variants-with-ad-0-0-and-dp-0#latest)... Aparently some variants with non-zero quals have 0 AD and DPs. Other annotations are also missing from the INFO columns. . After some debugging it turns out that the criteria to determine whether a read should be considered for a variant in terms of alignment overlap are different for taking part of PL calculation and AD/DP calculation. . Where is not totally clear what is the best way to go in practice. It seems to me that we should be consistent here and both PL and AD/DP should use the same criterion. The offending code lines:. **HaplotypeCallerGenotypingEngine.java ln171**:. ```java; ReadLikelihoods<Allele> readAlleleLikelihoods = readLikelihoods.marginalize(alleleMapper, ; new SimpleInterval(mergedVC).expandWithinContig(ALLELE_EXTENSION, header.getSequenceDictionary()));; if (configuration.isSampleContaminationPresent()) {; readAlleleLikelihoods.contaminationDownsampling(configuration.getSampleContamination());; }. ```; The code above decides the involvement in PL calculations. Notice that ```ALLELE_EXTENSION``` is set to ```2```. . For the AD/DP and so on the code responsible is in **AssemblyBasedCallerGenotypingEngine.java ln366**:. ```; // Otherwise (else part) we need to do it again.; if (configuration.useFilteredReadMapForAnnotations || !configuration.isSampleContaminationPresent()) {; readAlleleLikelihoodsForAnnotations = readAlleleLikelihoodsForGenotyping;; readAlleleLikelihoodsForAnnotations.filterToOnlyOverlappingReads(loc);; } else {; readAlleleLikelihoodsForAnnotations = readHaplotypeLikelihoods.marginalize(alleleMapper, loc);; if (emitReferenceConfidence) {; readAlleleLikelihoodsForAnnotations.addNonReferenceAllele(Allele.NON_REF_ALLELE);; }; }. ```. The ```filterToOnlyOverlappingReads(loc)``` is called then the overlap criterion is strict. (e.g. 0bp padding). This is also the case for the ```marginalize``` call if the conditional is ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5434:1052,config,configuration,1052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5434,1,['config'],['configuration']
Modifiability," pet (#7098); - added support for loading QUALapprox into VET (#7101); - Add -m flag to gsutil step; add dockstore branch filters to facilitate development (#7104); - updates to ImportGenomes and LoadBigQueryData (#7112); - Add ngs to cohort extract Dockerfile; remove exception catching in extract python script (#7113); - remove problematic storage_location imports (#7119); - Reduce memory and CPU for CreateImportTsvs task, check for files before attempting load (#7121); - add -m flag to gsutil mv step (#7129); - ah_var_store : Add sample file argument to cohort extract (#7117); - wip; - initial cohort extract; - minor changes; - wip; - get genotypes working; - clarify sample -> sample_id; - add mode; - mode is mandatory, uses location instead of position; - add query mode; - fix contig name; - forgot this file; - fix location bug; - Ingest wip to be added to other var db code (#6582); - ingest arrays refactored; - add filter, change sample to sample_id; - fix bugs; - wip; - major refactor splitting ingest for arrays from exomes/genomes; - create output files for actual raw array tables; - change site_name to rsid; - change GT encoding, change output file names and remove dir structure, get probe metadata; - fix prefix; - update GT encoding; - remove filter, rename columns, allow sample id as input; - array cohort extract (#6666); - new bit-compression (#6691); - refactored to common ProbeInfo, support compressed data on ingest, support local CSV probe info; - update exome ingest; - minor mods; - change structure, add compressed option to ingest; - add imputed tsv creator and refactor; - add fields for uncompressed imputed data; - Adding a test and small features to var store branch (#6761); - upgraded to new google bigquery libraries and storage api v1; used storage api for probe info; synced encoded gt definitions; - added support for probe_id ranges (#6806); - ah - use new GT encoding (#6822); - Tool for arrays QC metrics calculations (#6812); - ah update array ex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:6382,refactor,refactor,6382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['refactor'],['refactor']
Modifiability," really know what's happening. We wouldn't expect gatk4 haplotype caller to be that much slower. . It looks like they're running beta2 which is kind of old as well. Can you ask them what exact version they're using?. Can you ask if they have the log (stdout + stderr) for the gatk4 non-spark run? I can't tell what pairhmm they're actually running with and the logs would help with that. . Can you also find out what sort of hardware they're running on? Specifically, is it an intel machine with support for AVX?. A good setting for` --nativePairHmmThreads` is probably 4-8, you won't see any improvement after that. I also noticed that they're setting -XX:+UseParallelGC -XX:ParallelGCThreads=32 for the gatk3. They would be better off setting it to 2-4 threads. Performance gets worse beyond that typically from what I've seen. They can set the same thing for gatk4 using`--javaOptions ' -XX:+UseParallelGC -XX:ParallelGCThreads=4'`. Their spark configuration looks wrong in a number of ways which is probably a big part of why they're not seeing any improvement. In general you want executors with ~4-8 cores and at least 4g of memory per core. I don't know how much memory their nodes have, and I don't know if they're running with autoscaling turned on, but I suspect they're only allocating 1 executor on 1 node and then it's thrashing memory because it's trying to run 32 threads at once. Spark tuning for haplotype caller is going to be complicated though and I don't know how to do it will yet, we will be revisiting it in the next quarter probably. They're also running withs spark 2.1.0, we currently require spark 2.0.2 which is an unfortunately specific version, we're planning on upgrading to spark 2.2.+ in the next quarter. . You should make it clear to them that the results will not be the same between 3, 4, and 4-spark yet and that 4 is in rapid state of flux and has known performance issues that we're planning on working soon. Even so though, that slowdown they're seeing is bi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3631#issuecomment-332879964:971,config,configuration,971,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631#issuecomment-332879964,1,['config'],['configuration']
Modifiability," should definitely provide defaults for typical data types in *documentation*.) And in the end, I think it is beneficial for users that wish to tweak knobs to do some work to understand what those knobs actually do (even if just at a basic level). The other downside of option 2 is that it might not be immediately obvious from the command line what parameters are being used. For example, if a user chooses a set of defaults but then overrides some of them, we should make it so they don't have to go digging through the logs to see what parameters are actually used in the end. Nor should they have to go back and check what the defaults were for whatever version of the jar they were using at the time. Option 2 might also make it easier to inadvertently override parameters, etc. via command-line typos or copy-and-paste errors---it's much more straightforward to require and check that every parameter is specified once and fallback to a default if not, as we do now. Not to say that we couldn't get around any of these issues in Barclay, but I think it'll require some thought and careful design. Would be interested to hear Engine team's opinions. Finally, one point that I think will become more relevant as our tools and pipelines become more flexible and parameterized: I think we should start thinking of ""Best Practices Recommendations"" less as ""here is the best set of parameters to use with your data"" and more as ""here is *how to find* the best set of parameters to use with your data (for a given truth set, sensitivity requirement, etc.)"". After all, if we are putting together pipelines to do hyperparameter optimization, there is no reason not to share them with the community. This would also relax the requirement that the defaults in the WDL (which have to be kept in sync with those in the GATK jar) represent some sort of Best Practices Recommendation, which is awkward in exactly scenarios like the one you highlight. @vdauwera @LeeTL1220 @sooheelee might have some thoughts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385584289:1603,flexible,flexible,1603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385584289,2,"['flexible', 'parameteriz']","['flexible', 'parameterized']"
Modifiability," table creation and data loading in LoadData (#7056); - WIP; - tieout scripts; - notes files; - updated diff scripts; - fixed bug...; - add wdl and inputs file for warp pipeline; - reverting logging; - included top level WDL; - use gnarly with BQ extract cohort; - remove unused file; - cleaning up; - tidy; - tidy up before PR; - tidy up before PR; - PR comments; - merge conflict misfires; - added example SQL to create alt allele table from VET; - option to remove PLs; - fixed and enhanced unit test; - removing unused config, causing travis to fail; - add CreateVariantIngestFiles integration test (#7071); - add sampleName (instead of NULL) to error message (#7074); - Update To handle if no data error (#7084); - Memory improvement when writing missing positions to pet (#7098); - added support for loading QUALapprox into VET (#7101); - Add -m flag to gsutil step; add dockstore branch filters to facilitate development (#7104); - updates to ImportGenomes and LoadBigQueryData (#7112); - Add ngs to cohort extract Dockerfile; remove exception catching in extract python script (#7113); - remove problematic storage_location imports (#7119); - Reduce memory and CPU for CreateImportTsvs task, check for files before attempting load (#7121); - add -m flag to gsutil mv step (#7129); - ah_var_store : Add sample file argument to cohort extract (#7117); - Perform full WGS cohort extract scientific tieout for 35 ACMG59 samples (#7106); - Enable Read/Execution Project for BQ Queries (#7136); - ah - optional service account (#7140); - Add load lock file to prevent accidental re-loading of data to BQ (#7138); - #251 Address gvcf no-calls missing QUALapprox and other features (#7146); - Job Add labels to BQ operations from GATK (Issues-199) (#7115); - parse map to list to avoid brackets and spaces in vcf output (#7168); - #259 Inline schema for importgenomes.wdl (#7171); - Created AvroFileReader and unittest, Update ExtractCohort and ExtractCohortEngine (#7174); - #224 Import WDL: handle ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:11071,enhance,enhanced,11071,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,"['config', 'enhance']","['config', 'enhanced']"
Modifiability," the user class path in order to get around the fact that our classes aren't in the system class loader. Here's an example program I wrote that can do it on the driver. . ``` java; package org.broadinstitute.hellbender.tools;. import org.apache.spark.api.java.JavaSparkContext;; import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;; import org.broadinstitute.hellbender.cmdline.programgroups.SparkProgramGroup;; import org.broadinstitute.hellbender.engine.spark.GATKSparkTool;. import java.io.IOException;; import java.lang.reflect.Field;; import java.net.URI;; import java.net.URISyntaxException;; import java.nio.file.Files;; import java.nio.file.Path;; import java.nio.file.Paths;; import java.nio.file.spi.FileSystemProvider;; import java.util.ArrayList;; import java.util.List;; import java.util.ServiceLoader;. @CommandLineProgramProperties(summary = ""test"", oneLineSummary = ""testthing"", programGroup = SparkProgramGroup.class); public class TestGCS extends GATKSparkTool {; private static final long serialVersionUID = 1L;. @Override; protected void runTool(JavaSparkContext ctx) {; try {; modifyProviders();; } catch (IllegalAccessException | NoSuchFieldException e) {; throw new RuntimeException(""Couldn't reset FilesystemProviders"");; }; try {; final Path index = Paths.get(new URI(""gs://hellbender/test/build_reports/1626.1/tests/index.html""));; System.out.println(""Count:"" + Files.lines(index).count());; } catch (URISyntaxException | IOException e) {; throw new RuntimeException(""Couldn't read file"");; }; }; }. private void modifyProviders() throws IllegalAccessException, NoSuchFieldException {; final Field installedProviders = FileSystemProvider.class.getDeclaredField(""installedProviders"");; installedProviders.setAccessible(true);; installedProviders.set(null, loadInstalledProviders());; installedProviders.setAccessible(false);; }. //copied from FileSystemProvider, modified to use TestGCS.classLoader() instead of systemClassloader; private static List<File",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2312:1146,extend,extends,1146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2312,1,['extend'],['extends']
Modifiability," tool, MosaicHunter. The option you suggest looks great. Do you mean that I should establish the GATK 4 developing environment and develop the MosaicHunterFilter tool? I may do that when I have some time. I found the document of GATK 4 at https://github.com/broadinstitute/gatk. Do you have any further advices?. Best regards,; Adam Yongxin Ye; Center for Bioinformatics; Peking University. At 2018-07-07 01:43:05, ""Geraldine Van der Auwera"" <notifications@github.com> wrote:. Hi @Yyx2626, I'm Geraldine, you may remember me from the Beijing training. It was great visiting your team! I'm sorry it took me so long to follow up on this discussion, and I want to thank you again for reaching out to us about integrating the tool that you developed into GATK. We are certainly very interested in providing this enhancement to the research community, and we are now ready to talk about the next steps. After examining your paper and the source code in Github, we think that the most efficient way to integrate the functionality you developed would be to adapt the filtering parts of your tool to run on the output of Mutect2. So this would be a standalone tool that you would run after Mutect2, much like the current FilterMutectCalls tool. If the results are comparable to your current tool, then we would take that into the official distribution of GATK. If somehow that integration does not yield satisfactory results, then we would look at integrating the entire tool, though we're hoping it won't be necessary, so we can avoid maintaining duplicate functionality for some of the boilerplate data transformations. David @davidbenjamin can provide some advice on how to implement this in GATK4; in brief you would need to write some code that applies the filters you developed to a variant context. Let us know if this is an option you'd like to explore; we'd be happy to help. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404104349:1275,adapt,adapt,1275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404104349,1,['adapt'],['adapt']
Modifiability," true; 08:48:45.922 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 08:48:45.922 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 08:48:45.922 DEBUG ConfigFactory - Configuration file values:; 08:48:45.927 DEBUG ConfigFactory - gcsMaxRetries = 20; 08:48:45.927 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 08:48:45.927 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 08:48:45.927 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 08:48:45.927 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 08:48:45.927 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 08:48:45.927 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 08:48:45.927 DEBUG ConfigFactory - samjdk.compression_level = 2; 08:48:45.927 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 08:48:45.927 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 08:48:45.927 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 08:48:45.927 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 08:48:45.927 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 08:48:45.927 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 08:48:45.928 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 08:48:45.928 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 08:48:45.928 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 08:48:45.928 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 08:48:45.928 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 08:48:45.928 DEBUG ConfigFactory - createOutputBamIndex = true; 08:48:45.928 INFO DetermineGermlineContigPloidy - Deflater: IntelDeflater; 08:48:45.928 INFO DetermineGermlineContigPloidy - Inflater: IntelInflater; 08:48:45.928 INFO DetermineGermlineContigPl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6217:4779,Config,ConfigFactory,4779,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6217,1,['Config'],['ConfigFactory']
Modifiability," true; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 23:43:52.472 DEBUG ConfigFactory - Configuration file values: ; 23:43:52.474 DEBUG ConfigFactory - 	gcsMaxRetries = 20; 23:43:52.474 DEBUG ConfigFactory - 	gcsProjectForRequesterPays = ; 23:43:52.474 DEBUG ConfigFactory - 	gatk_stacktrace_on_user_exception = false; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.use_async_io_read_samtools = false; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.use_async_io_write_samtools = true; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.use_async_io_write_tribble = false; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.compression_level = 2; 23:43:52.474 DEBUG ConfigFactory - 	spark.kryoserializer.buffer.max = 512m; 23:43:52.474 DEBUG ConfigFactory - 	spark.driver.maxResultSize = 0; 23:43:52.474 DEBUG ConfigFactory - 	spark.driver.userClassPathFirst = true; 23:43:52.474 DEBUG ConfigFactory - 	spark.io.compression.codec = lzf; 23:43:52.474 DEBUG ConfigFactory - 	spark.executor.memoryOverhead = 600; 23:43:52.475 DEBUG ConfigFactory - 	spark.driver.extraJavaOptions = ; 23:43:52.475 DEBUG ConfigFactory - 	spark.executor.extraJavaOptions = ; 23:43:52.475 DEBUG ConfigFactory - 	codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 23:43:52.475 DEBUG ConfigFactory - 	read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 23:43:52.475 DEBUG ConfigFactory - 	annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 23:43:52.477 DEBUG ConfigFactory - 	cloudPrefetchBuffer = 40; 23:43:52.477 DEBUG ConfigFactory - 	cloudIndexPrefetchBuffer = -1; 23:43:52.477 DEBUG ConfigFactory - 	createOutputBamIndex = true; 23:43:52.477 INFO GermlineCNVCaller - Deflater: IntelDeflater; 23:43:52.477 INFO GermlineCNVCaller - Inflater: IntelInflater; 23:43:52.477 INFO GermlineCNVCaller - GCS max retries/reopens: 20; 2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:3599,Config,ConfigFactory,3599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['Config'],['ConfigFactory']
Modifiability," unnecessary copies of the data (now fixed: https://github.com/cloudera/spark-dataflow/pull/60), which caused OOM errors when trying to broadcast the 3GB reference data. With this fixed, I ran a [pipeline called JoinReferencesDataflow](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/tools/dataflow/pipelines/JoinReferencesDataflow.java) on a small cluster that broadcasts the reference as a dataflow view. The code is a modified version of CountReadsDataflow that simply sends the view, and then doesn't use it, so we can see the cost of doing a broadcast (See the rest of the code in this branch: https://github.com/tomwhite/hellbender/tree/hadoop-references). JoinReferencesDataflow took 2 min 25s to run, of which 18s were for reading the reference from the local filesystem in the driver. For comparison, CountReadsDataflow took 17s on the same cluster. So broadcasting the reference takes less than 2 minutes. Note that this was just for one task, but Spark has [an efficient protocol for sending broadcast variables](http://www.cs.berkeley.edu/~agearh/cs267.sp10/files/mosharaf-spark-bc-report-spring10.pdf), which scales well with the number of nodes, so the approach looks feasible. Having said all that, we might still want to use the sharding approach, in order to share more code between the Google and Spark dataflow implementations. One way this could work would be to generalize `RefAPISource` and `RefAPIMetadata` to support reading reference data from a [ReferenceHadoopSource](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/engine/dataflow/datasources/ReferenceHadoopSource.java), which is in line with @droazen's last comment. Am I right in thinking that the read pipeline work is being completed in https://github.com/broadinstitute/hellbender/tree/da_read_pipeline? Is that at a point where I could try with pipeline on Spark, or should I wait until it's merged?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353:1189,variab,variables,1189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353,1,['variab'],['variables']
Modifiability," values:; 17:39:19.244 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:39:19.244 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:39:19.245 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:39:19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:39:19.246 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:39:19.246 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:39:19.246 INFO PathSeqPipelineSpark - Initializing engine; 17:39:19.246 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/24 17:39:19 INFO SparkContext: Running Spark version 2.2.0; 18/04/24 17:39:19 WARN NativeCodeLoader: Unable to load native-hadoop lib",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:6071,Config,ConfigFactory,6071,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability," values:; 17:54:55.320 DEBUG ConfigFactory - gcsMaxRetries = 20; 17:54:55.320 DEBUG ConfigFactory - samjdk.compression_level = 2; 17:54:55.320 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 17:54:55.320 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:54:55.320 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:54:55.320 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:54:55.320 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:54:55.320 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:54:55.320 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:54:55.320 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:54:55.321 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:54:55.321 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:54:55.321 DEBUG ConfigFactory - createOutputBamIndex = true; 17:54:55.321 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:54:55.321 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:54:55.321 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:54:55.321 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:54:55.321 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:54:55.321 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:54:55.321 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:54:55.321 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:54:55.321 INFO PathSeqPipelineSpark - Initializing engine; 17:54:55.321 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/24 17:54:55 INFO SparkContext: Running Spark version 2.2.0; 18/04/24 17:54:55 WARN NativeCodeLoader: Unable to load native-hadoop lib",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:6710,Config,ConfigFactory,6710,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['Config'],['ConfigFactory']
Modifiability," we'd just want to let the user be able to specify the theano directory (rather than dump things in `~/.theano` unexpectedly). We should think about whether this should be opt-in, i.e., should we preserve the original behavior of using `~/.theano` by default?; > ; > @mwalker174 opinions? @droazen or engine team, thoughts on what the policy should be for python/R scripts doing this sort of thing? Is it generally true that the GATK leaves no trace, other than producing the expected output?. Dear samuelklee,. Thank you very much for you reply. I also found this problem last night. It seems that the problem is originally from Theano and Pymc3, rather than GATK 4.0. Some similar problems have been reported just like (1) https://github.com/pymc-devs/pymc3/issues/1463 (2) https://stackoverflow.com/questions/52270853/how-to-get-rid-of-theano-gof-compilelock and (3) https://groups.google.com/forum/#!topic/theano-users/eJ2vl2PUTk4. Last night, I have already tried to reset base_compiledir for theano, through two ways: (1) creating a ~/.theanorc file just like you suggested (2) modifying the file ~/.bashrc for my login node, by adding a line: export THEANO_FLAGS=""base_compiledir=/scratch/gatk-user1/z-Temp/z-Temp-Theano-$chr"". However, the truth is that, in our cluster, when I submit the 25 jobs (for each chromosomes), they are assigned to different computer nodes randomly. It means that I have to set THEANO environment variable for each corresponding random computer nodes respectively, which is quite difficult for me, as the nodes are random assigned. So, now I'm going to add lines like below to the ~/.theanorc in my login node, to see what will happen. Maybe It will work.; #######; [global]; config.compile.timeout = 100000 ; ######. However, I'm really appreciate it if some one in your team can help to add a function to specify a temporary directory for the theano directory, which can be bound to the corresponding node shared by other GATK threads. Thank you and Best regards.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-548557073:2522,variab,variable,2522,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6235#issuecomment-548557073,2,"['config', 'variab']","['config', 'variable']"
Modifiability," what intervals were used for the jobs. I tried using running GenomicsDBImport with -L over a small region, or I ran SelectVariants on the gVCF first (which behaves a little differently), and then used that subset gVCF as input to GenomicsDBImport, where GenomicsDBImport is given the entire contig as the interval. The resulting workspaces will be slightly different, with the latter containing information over a wider region (GenomicsDBIport truncates start/end of the input records to just the target interval). . So if either of these workspaces is passed to GenotypeGVCFs, using --only-output-calls-starting-in-intervals and -L 1:1050-1150:. I think any upstream padding doesnt matter. If you have a multi-nucleotide polymorphism that starts upstream of 1050 but spans 1050, this job wouldnt be responsible for calling that. The prior job, which has an interval set upstream of this one should call it. I think GenomicsDbImport's behavior is fine here. If you have a multi-NT variant that starts within 1050-1150, but extends outside (i.e. deletion or insertion starting at 1148), this could be a problem. The GenomicsDB workspace created with the interval 1:1050-1150 lacks the information to score that, right? The workspace created using the more permissive SelectVariants->GenomicsDBImport contains that downstream information and presumably would make the same call as if GenotypeGVCFs was given the intact chromosome as input, right?. However, it seems that if I simply create the workspace with a reasonably padded interval (adding 1kb should be more than enough for Illumina, right?), and then run GenotypeGVCFs with the original, unpassed interval, then the resulting workspace should contain all available information and GenotypeGVCFs should be able to make the same call as if it was given a whole-chromosome workspace as input. . Does that logic seem right? . ```; # The Input gVCF; 1	1040	.	A	<NON_REF>	.	.	END=1046	GT:DP:GQ:MIN_DP:PL	0/0:15:24:14:0,24,360; 1	1047	.	T	<NON_REF>	.	",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1221558244:1618,extend,extends,1618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1221558244,1,['extend'],['extends']
Modifiability," yes, I know is still in beta but I’ve found these problems when I compared the outputs from Haplotypecaller in spark and in not Spark versions. For comparing these results I've used this tool [https://drive.google.com/file/d/1r2WHyiz5WqOIyY_EZ1VZt92wGlL19SE4/view?usp=sharing](url) and I've obtained these plots for sensitivity and specificity( The sensitivity is defined as the number of sites inwhich both sequencing and microarrays detected a deviation from the reference sequencedivided by the number of sites where a variant was detected by using the microarrays). **Spark**; Sensitivity; ![spark_sensitivity_hg19](https://user-images.githubusercontent.com/10074137/47148261-86b77280-d2d0-11e8-8b5a-9ecfef16d889.png); Specificity; ![sparkspecificityhg19](https://user-images.githubusercontent.com/10074137/47148277-933bcb00-d2d0-11e8-97eb-1adceb4e5ee2.png). **Local non Spark tool with GATK 2.7**; ![hg19local](https://user-images.githubusercontent.com/10074137/47148427-fcbbd980-d2d0-11e8-87d8-04ec20c1005d.png); furthermore I've executed the pipeline until BQSR in Spark version and after, I am focused just on Haplotypecaller because I've used this ""backwards"" approach and I've discovered that the pipeline is deterministic from the phase Variant Discovery, but don't in the phase of Preprocessing because when I've executed this phase more times, I've obtained results completely, this is the test with one single sample:; ![comparisons_pfc32](https://user-images.githubusercontent.com/10074137/47148552-49071980-d2d1-11e8-8b1c-aec468285699.png); furthermore when I've used the output from BQSR (executed in Spark) for execute of Haplotypecaller in local(not in Spark) and adapting this output for Haplotypecaller, I had to use the tool Samtools for sort the outputs and after this step the outputs are passed from average of 19 gigabytes to 13 gigabytes average for the all samples. I've opened this Issue because I would to help you with my experiments to improvement your tool.; thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5323:1923,adapt,adapting,1923,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5323,1,['adapt'],['adapting']
Modifiability,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 21:02:08.892 INFO PrintReadsSpark - Initializing engine; 21:02:08.892 INFO PrintReadsSpark - Done initializing engine; 18/07/24 21:02:08 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 18/07/24 21:02:09 INFO org.spark_project.jetty.util.log: Logging initialized @6492ms; 18/07/24 21:02:09 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT; 18/07/24 21:02:09 INFO org.spark_project.jetty.server.Server: Started @6584ms; 18/07/24 21:02:09 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@42ecc554{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/07/24 21:02:09 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 18/07/24 21:02:09 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.9.0-hadoop2; 18/07/24 21:02:10 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at shuang-small-m/10.128.5.217:8032; 18/07/24 21:02:10 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at shuang-small-m/10.128.5.217:10200; 18/07/24 21:02:12 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1532457503538_0038; 21:02:16.702 INFO FeatureManager - Using codec BEDCodec to read file hdfs://shuang-small-m:8020/data/intervals.bed; 21:02:16.863 INFO IntervalArgumentCollection - Processing 1219 bp from intervals; 18/07/24 21:02:17 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1; 18/07/24 21:02:25 WARN org.apache.spark.scheduler.TaskSetMan",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5051:7022,config,configure,7022,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5051,1,['config'],['configure']
Modifiability,"!?[0m. 16:58:10.116 INFO PrintVariantsSpark - Initializing engine; 16:58:10.116 INFO PrintVariantsSpark - Done initializing engine; 19/02/18 16:58:10 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19/02/18 16:58:10 INFO org.spark_project.jetty.util.log: Logging initialized @8431ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: Started @8536ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 19/02/18 16:58:11 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 19/02/18 16:58:12 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:8032; 19/02/18 16:58:13 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:10200; 19/02/18 16:58:15 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1550508751046_0004; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; 19/02/18 16:58:25 INFO org.apache.h",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:4786,config,configure,4786,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['config'],['configure']
Modifiability,"![IMG_9960](https://user-images.githubusercontent.com/11076296/95899038-ee88e280-0d5d-11eb-86bf-272687eb9ac0.jpg). Decided to just sit down and go through the exercise of threading all of the parameter sets by hand after biffing it once. Reproducing above; might be helpful for the reviewer if this goes in, but they may want to independently check it. (Is there a way I could've gotten IntelliJ to do this for me?). I would hope that we could do some refactoring to simplify this a bit, if not model ablation or consolidation of parameters, but I won't attempt it for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707919816:452,refactor,refactoring,452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707919816,1,['refactor'],['refactoring']
Modifiability,"![weighted](https://user-images.githubusercontent.com/11076296/97032266-8ab9a300-152f-11eb-8d73-148ff99963be.png). Here is the result of optimizing for sensitivity in the high-confidence, low-compexity region of chr22 in CHM, allowing haplotype-to-reference and read-to-haplotype (match, mismatch, gap open) to range over ([1, 20], [-20, -1], [-20, -1]) and fixing gap extend penalties to -1. The optimal (match, mismatch, gap open) parameters found in this run appear to be:. haplotype-to-reference: 2, -8, -19; read-to-haplotype: 1, -4, -3. I wouldn't put much stock in interpreting these parameters or their exact values for now, but it does appear that the match values and the haplotype-to-reference gap-open penalty might be saturating the bounds of the search. Plots of the type suggested by @dalessioluca might be more illuminating. Compare with default performance:. ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------------------------------; 9.000 4003 4019 494 1036 0.8905 0.7944 0.8397; None 4009 4025 511 1030 0.8873 0.7956 0.8390; ````. That the corresponding curve with a precision/sensitivity endpoint of (0.8873, 0.7956) above isn't at the top of the pack means that we could squeeze out some extra calls by varying the SW parameters. Of course, this doesn't account for negative impact elsewhere. One could imagine writing a loss where this sensitivity is optimized while putting minimum constraints on precision, sensitivity, and/or F1 in the high-confidence, high-complexity regions (the assumption being the truth set is complete in those regions), or some weightings/variations thereof. EDIT: Actually, looks like overall performance in the high-confidence region improves:. ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715465692:369,extend,extend,369,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715465692,1,['extend'],['extend']
Modifiability,"""fs.gs.project.id"", value);; }; }. if (working_dir.empty()) {; hdfsBuilderConfSetStr(builder, ""fs.gs.working.dir"", ""/"");; } else {; hdfsBuilderConfSetStr(builder, ""fs.gs.working.dir"", working_dir.c_str());; }. // Default buffer sizes are huge in the GCS connector. GenomicsDB reads/writes in smaller chunks,; // so the buffer size can be made a little smaller.; hdfsBuilderConfSetStr(builder, ""fs.gs.io.buffersize.write"", ""262144"");. hdfsFS hdfs_handle = hdfsBuilderConnect(builder);; free(value);; return hdfs_handle;; }; ```. This is the error from Travis logs-; ```; Running Test: Test method testWriteToAndQueryFromGCS(org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest); hdfsBuilderConnect(forceNewInstance=1, nn=gs://hellbender-test-logs, port=0, kerbTicketCachePath=(NULL), userName=(NULL)) error:; java.io.IOException: Error getting access token from metadata server at: http://metadata/computeMetadata/v1/instance/service-accounts/default/token; at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:210); at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:75); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1826); Caused by: com.google.api.client.http.HttpResponseException: 404 Not Found; {""error"":""invalid_request"",""error_description"":""Service account not enabled on this instance""}; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1072); at com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:159); at com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:493); at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:208); ... 77 more; [GenomicsDB::StorageManagerConfig] Error: Error getting hdfs connection: Connection refused.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422915888:2017,config,configure,2017,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422915888,1,['config'],['configure']
Modifiability,"# Bug Report. ## Affected tool(s) or class(es); gatk `GenomicsDBImport ` `GenotypeGVCFs`; ## Affected version(s); The Genome Analysis Toolkit (GATK) v4.5.0.0; ## Description; Hi,; Here is my situation, I'm testing the feasibility of incremental GenomicsDB，I have total 400 samples to joint calling, I have no problem directly using `GenomicsDBImport `and `GenotypeGVCFs `for joint calling of all 400 samples. The configuration used is 4c32g for `GenomicsDBImport `and 2c16g for `GenotypeGVCFs`. But when I first built a GenomicsDB of 200 samples using `GenomicsDBImport `successfully, and then use GenomicsDB `--genomicsdb-update-workspace-path` increment 200 samples into the GenomicsDB , use this incremental imported GenomicsDB to `GenotypeGVCFs`. The error happend and report GENOMICSDB_TIMER,Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; Here are my code; ```; gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenomicsDBImport \; --tmp-dir $PWD \; --genomicsdb-workspace-path ~{workspace_dir_name}~{prefix}.~{index} \; --batch-size 50 \; -L ~{intervals} \; --reader-threads 5 \; --merge-input-intervals \; --consolidate \; -V ~{sep = "" -V "" single_sample_gvcfs}. gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenomicsDBImport \; --tmp-dir $PWD \; --genomicsdb-update-workspace-path ~{workspace_dir_name} \; --batch-size 50 \; --reader-threads 5 \; --merge-input-intervals \; --consolidate \; -V ~{sep = "" -V "" single_sample_gvcfs}. gatk --java-options ""-Xms8000m -Xmx~{max_mem}m"" \; GenotypeGVCFs \; --tmp-dir $PWD \; -R ~{ref} \; -O ~{workspace_dir_name}.vcf.gz \; -G StandardAnnotation \; --only-output-calls-starting-in-intervals \; -V gendb://~{workspace_dir_name} \; -L ~{intervals} \; --merge-input-intervals \; -all-sites; ```; And I found that before report error the number of threads used by GATK increased, but the memory usage did not exceed the maximum limit of the server.; I also cheched `--max-alternate-alleles` and `--genomicsdb-max-alternate-al",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8777:413,config,configuration,413,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8777,1,['config'],['configuration']
Modifiability,"# Feature request; ### Tool(s) or class(es) involved; Funcotator. ### Description; Currently, the GencodeFuncotationFactory is doing a lot. A suggested refactoring would be to have an AbstractGencodeFuncotationFactory that encapsulates the shared functionality b/w segment and small mutation annotation. Then two concrete classes for annotating segments and small mutations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5932:152,refactor,refactoring,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5932,1,['refactor'],['refactoring']
Modifiability,"# Summary. This PR adds a new flag to `HaplotypeCaller` called `--ploidy-regions` which allows the user to input a .bed or .interval_list with ""name"" column equal to a positive integer for the ploidy to use when calling variants in that region. The main use case is for calling haploid variants outside the PAR for XY individuals as required by the VCF spec, but this provides a much more flexible interface for other similar niche applications, like genotyping individuals with other known aneuploidies. The global `-ploidy` flag will still provide the background default (or the built-in ploidy of 2 for humans), but the user input value will supersede these in overlapping regions. Note that the overlap is checked against the active region, meaning variants near the boundary of the `--ploidy-regions` file may end up with GT fields having ploidy slightly differently than expected, for example if your custom region overlaps a given active region but the variant ends up being written to a location outside that interval. In this case the ploidy from the user input would be used rather than any other default. # Implementation Details. The key idea is to allow `HaplotypeCallerEngine` to initialize multiple genotyping engines based on the `--ploidy-regions` input. The intervals are first parsed to check for positive integer ploidy values, and then used to create hashmaps of ploidy -> genotyper. The engine uses two types of genotypers: one for active region determination and one for doing the actual genotyping. Both admit a ploidy paramter passed via `hcArgs`. This PR modifies the `HaplotypeCallerArgumentCollection` class to include a method for creating copies of this object with differing ploidy amounts. These then get fed to the constructors of the appropriate genotyper classes, which are organized into two hashmaps. In every situation where one of these genotypers is used, we instead begin the scope by calling a ""get local genotyper"" method that performs the logic of checking ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8464:389,flexible,flexible,389,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8464,1,['flexible'],['flexible']
Modifiability,"## Bug Report. ### Affected class; AssemblyBasedCallerUtils. ### Affected version(s); - [x] Latest public release version 4.1.9.0; - [x] Latest master branch as of 10/10/2020. ### Description ; When adjusting the base quality of overlapping read pairs, the modifications are made in place. If the modified reads are later used in another active region, the results from the later active region will be changed by the earlier modification. We had previously fixed this issue in #4926. But it looks like the refactoring in https://github.com/broadinstitute/gatk/commit/1353e3201bb11e29039efd89359b0a4cfc11e5c0 reverted to the earlier behavior. `AssemblyBasedCallerUtilsUnitTest.testfinalizeRegion()` will fail due to this behavior if [line 67](https://github.com/broadinstitute/gatk/blob/master/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtilsUnitTest.java#L67) is changed from:; ```; AssemblyBasedCallerUtils.finalizeRegion(activeRegion, false, false, minbq, header, sampleList, false);; ```; to:; ```; AssemblyBasedCallerUtils.finalizeRegion(activeRegion, false, false, minbq, header, sampleList, true);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6882:506,refactor,refactoring,506,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6882,1,['refactor'],['refactoring']
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); Build. ### Affected version(s); - [X] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; ```; =======================<phase: build >============================; ===> Building for gatk-4.2.6.1_1. Welcome to Gradle 7.5.1!. Here are the highlights of this release:; - Support for Java 18; - Support for building with Groovy 4; - Much more responsive continuous builds; - Improved diagnostics for dependency resolution. For more details see https://docs.gradle.org/7.5.1/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). FAILURE: Build failed with an exception. * Where:; Build file '/wrkdirs/usr/ports/biology/gatk/work/gatk-4.2.6.1/build.gradle' line: 15. * What went wrong:; Plugin [id: 'de.undercouch.download', version: '4.1.2'] was not found in any of the following sources:. - Gradle Core Plugins (plugin is not in 'org.gradle' namespace); - Plugin Repositories (could not resolve plugin artifact 'de.undercouch.download:de.undercouch.download.gradle.plugin:4.1.2'); Searched in the following repositories:; Gradle Central Plugin Repository; ```. #### Steps to reproduce; regular build. Version: 4.2.6.1; Java-17; FreeBSD 13.1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7984:815,Plugin,Plugin,815,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7984,7,"['Plugin', 'plugin']","['Plugin', 'Plugins', 'plugin']"
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); CreateReadCountPanelOfNormals. ### Affected version(s); - [ ] Latest public release version [4.1.0.0]. ### Description ; When you run it on a single machine, it trys to use _hadoop_ and failed. ```; $ java -jar ../gatk-package-4.1.0.0-local.jar CreateReadCountPanelOfNormals --input in.counts.hdf5 --output out.pon.hdf5; 12:33:52.103 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 12:33:52.162 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 12:33:53.793 INFO CreateReadCountPanelOfNormals - ------------------------------------------------------------; 12:33:53.794 INFO CreateReadCountPanelOfNormals - The Genome Analysis Toolkit (GATK) v4.1.0.0; 12:33:53.794 INFO CreateReadCountPanelOfNormals - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Initializing engine; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 19/02/18 12:33:53 INFO SparkContext: Running Spark version 2.2.0; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar) to method sun.security.krb5.Config.getInstance(); WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 12:33:54.187 WARN NativeCo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5686:423,variab,variables,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686,2,"['config', 'variab']","['configured', 'variables']"
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); All. ### Description ; Since we expect users to write config files manually, we need to have some enforcement of naming rules. At the least, to disallow spaces in the name and version fields. There are many places throughout the code where we assume that there will be no spaces. Additionally, I hear from users that they want any Funcotator tsv outputs to never have spaces (or tabs or other special characters -- ""_"", ""-"" are obviously okay). . We can solicit users about which special characters are okay, but definitely disallow spaces and tabs. #### Steps to reproduce; Add a space to the Gencode datasource config (name or version field) and try to funcotate a segment file. #### Expected behavior; No errors and no spaces in the field names. #### Actual behavior; Exception in gene list output renderer.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5937:141,config,config,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5937,2,['config'],['config']
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); GATK 4.1.0.0. ### Description ; Funcotator does not perform any annotation on a minimal VCF with canonical cancer variants and returns the following error:. ```; 23:28:30.519 INFO Funcotator - Initializing Funcotator Engine...; 23:28:30.523 INFO Funcotator - Creating a VCF file for output: file:xxx/sandbox/idh.funcotated.vcf; 23:28:30.541 INFO ProgressMeter - Starting traversal; 23:28:30.541 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 23:28:30.652 INFO ProgressMeter - unmapped 0.0 15 8108.1; 23:28:30.652 INFO ProgressMeter - Traversal complete. Processed 15 total variants in 0.0 minutes.; 23:28:30.652 WARN Funcotator - ================================================================================; 23:28:30.652 WARN Funcotator - _ _ _ __ __ _ _ _ _; 23:28:30.652 WARN Funcotator - | || || | \ \ / /_ _ _ __ _ __ (_)_ __ __ _ | || || |; 23:28:30.652 WARN Funcotator - | || || | \ \ /\ / / _` | '__| '_ \| | '_ \ / _` | | || || |; 23:28:30.653 WARN Funcotator - |_||_||_| \ \V V / (_| | | | | | | | | | | (_| | |_||_||_|; 23:28:30.653 WARN Funcotator - (_)(_)(_) \_/\_/ \__,_|_| |_| |_|_|_| |_|\__, | (_)(_)(_); 23:28:30.653 WARN Funcotator - |___/; 23:28:30.653 WARN Funcotator - --------------------------------------------------------------------------------; 23:28:30.653 WARN Funcotator - Only IGRs were produced for this dataset. This STRONGLY indicates that this; 23:28:30.653 WARN Funcotator - run was misconfigured.; 23:28:30.653 WARN Funcotator - You MUST check your data sources to make sure they are correct for these data.; 23:28:30.653 WARN Funcotator - ================================================================================; ```. There is no reason to assume that there is any issue with the data sources or run parameters. They have worked fine using a different VCF that had completed INFO tags. #### Steps to reproduce; Run Funcotator",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5777:387,sandbox,sandbox,387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5777,1,['sandbox'],['sandbox']
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); GermlineCNVCaller . ### Affected version(s); v4.0.4.0 and v4.0.11.0 tested with same result. ### Description ; ![screenshot 2018-11-02 14 50 17](https://user-images.githubusercontent.com/11543866/47934764-a8a71c80-deae-11e8-9f8f-c8a8b563d77a.png). ```; java.lang.IllegalArgumentException: Intervals for read-count file /home/shlee/gcnv/cvg/HG00096_chr20XY.hdf5 do not contain all specified intervals.; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.writeIntervalSubsetReadCountFiles(GermlineCNVCaller.java:390); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.doWork(GermlineCNVCaller.java:285); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Command runs fine sans `-XL` parameter. The contents of `-XL` are simply:. ![screenshot 2018-11-02 14 51 58](https://user-images.githubusercontent.com/11543866/47934827-e0ae5f80-deae-11e8-891e-473ec8420433.png). #### Expected behavior; It would be great to be able to iterate GermlineCNVCaller on coverage data while excluding various regions, e.g. centromeric regions, to test the impact of such regions on the denoising. Currently, the hypothetical workaround would be to collect coverage while excluding regions or to manually remove such intervals from the coverage data. Having to collect coverage once over all of the data is preferable to collecting coverage again and again over slightly variable regions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5388:1978,variab,variable,1978,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5388,1,['variab'],['variable']
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller 4.1.1.0. ### Affected version(s); - [x] Latest public release version; - [x] Latest master branch as of 3/31/2019. ### Description ; It looks like PR #5840 did a lot of refactoring to the way F1R2/F2R1 annotations are computed. Along the way it looks like `OxoGReadCounts` was renamed to `OrientationBiasReadCounts`. This is, unfortunately for some, a non-backwards compatible change as any pipeline that uses `-A OxoGReadCounts` will now fail. I'm not sure if there's a deprecation mechanism for annotations that would inform users of this, and I'm not sure there's a whole lot to be done at this point. I'm logging this issue mainly so anyone else who runs into this will find the answer quickly. Might be nice to add a line to the 4.1.1.0 release notes though noting this change.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5848:235,refactor,refactoring,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5848,1,['refactor'],['refactoring']
Modifiability,## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [x] Latest public release version [4.2.0.0]. ### Description ; HaplotypeCaller fails with the following java error:. ```*** Error in `java': munmap_chunk(): invalid pointer: 0x00007f1da5980f00 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x7f3e4)[0x7f1daaec73e4]; /var/tmp/rwilton/libgkl_smithwaterman14257239252565866950.so(_Z21runSWOnePairBT_avx512iiiiPhS_iiaPcPs+0x338)[0x7f05b3b50f48]; /var/tmp/rwilton/libgkl_smithwaterman14257239252565866950.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)```. #### Steps to reproduce; Using properly-aligned paired-end reads from GIAB reference sample HG002 (NA24385) with GRCh38.p12. Please see the attached log file for parameterization and stderr log:; [vcall.swbug.log](https://github.com/broadinstitute/gatk/files/6275740/vcall.swbug.log). #### Expected behavior; No error. #### Actual behavior; See above and attached log file. Thank you in advance for having a look at this!. Richard Wilton; Johns Hopkins University,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7187:789,parameteriz,parameterization,789,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7187,1,['parameteriz'],['parameterization']
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2, HaplotypeCaller; ./gatk Mutect2 -I scripts/microbial/mtb/samples/D1CLVACXX.1.Solexa-125092.aligned.bam -R scripts/microbial/mtb/Mycobacterium_tuberculosis_H37Rv.fasta -O test.vcf --num-matching-bases-in-dangling-end-to-recover 1 --max-reads-per-alignment-start 75. ### Affected version(s); Latest master branch as of 2/18/21. ### Description ; java.lang.ArrayIndexOutOfBoundsException: Index 25 out of bounds for length 25; 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.extendDanglingPathAgainstReference(AbstractReadThreadingGraph.java:913); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.mergeDanglingHead(AbstractReadThreadingGraph.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.recoverDanglingHead(AbstractReadThreadingGraph.java:542); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.AbstractReadThreadingGraph.recoverDanglingHeads(AbstractReadThreadingGraph.java:447); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.getAssemblyResult(ReadThreadingAssembler.java:685); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.createGraph(ReadThreadingAssembler.java:664); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.assemble(ReadThreadingAssembler.java:549); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.assembleKmerGraphsAndHaplotypeCall(ReadThreadingAssembler.java:195); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.runLocalAssembly(ReadThreadingAssembler.java:160); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7085:588,extend,extendDanglingPathAgainstReference,588,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7085,1,['extend'],['extendDanglingPathAgainstReference']
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); GATK version 4.2.5.0, run from the `us.gcr.io/broad-gatk/gatk:4.2.5.0` docker image. ### Description ; Rarely (~0.1%) within exomes that were sequenced at Broad (by GP), we encounter the error message whose stack trace is shown below. This occurs during batch processing, but it is specific to the .CRAM files: running Mutect2 on the same file produces the same error, and running Mutect2 on other files with the same arguments works fine. The files that trigger this error have contents that match the Broad GP-produced .md5 checksum, and they also pass `samtools quickcheck`. #### Steps to reproduce; (The variables are filled in as one might reasonably expect.); ```sh; /gatk/gatk --java-options ""-Xmx${RAM}G"" \; Mutect2 \; --input ${cram} \; --reference ${REFERENCE_FASTA} \; --panel-of-normals ${PON} \; --germline-resource ${GNOMAD} \; --intervals ${INTERVALS} \; --output ${unfiltered}; ```. #### Expected behavior; In all other cases, somatic variant calling proceeds successfully. #### Actual behavior; ```; 00:17:31.944 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 00:17:32.225 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.226 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.2.5.0; 00:17:32.226 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 00:17:32.227 INFO Mutect2 - Executing as root@8d398eecd56e on Linux v5.10.90+ amd64; 00:17:32.227 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 00:17:32.228 INFO Mutect2 - Start Date/Time: April 5, 2022 12:17:31 AM GMT; 00:17:32.228 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.228 INFO Mutect2 - ------------------------------------------------------------; 00:17:32.229 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7755:692,variab,variables,692,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7755,1,['variab'],['variables']
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); N/A. ### Affected version(s); - [ x] Latest public release version [4.5.0.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; Dockerfile does not create unprivileged user account. #### Steps to reproduce; * git clone https://github.com/broadinstitute/gatk.git; * cd gatk; * git checkout 4.5.0.0; * docker build -t gatk .; * docker run ... #### Expected behavior; I'd expect the user to be in an unprivileged account in `/home/gatk` when the container is started. If there is a use case for enabling root (say for allowing system installs) this should be an option (config or a separate Dockerfile). #### Actual behavior; On `docker run` the user is root under `/gatk`. A container should not put the user in a root account upon startup. This is especially so in shared computing environments. I attempted to create a ""gatk"" account with `RUN useradd -d /home/gatk -ms /bin/bash gatk` (etc) in the Dockerfile but I get `Permission denied: '/root/.config/conda/.condarc'.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8856:635,config,config,635,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8856,2,['config'],['config']
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); The docker image: `broadinstitute/gatk`. ### Affected version(s); `latest`. ### Description ; - The current GATK image has 44 layers; - In [the Azure Container Registry standard service tier](https://learn.microsoft.com/en-us/azure/container-registry/container-registry-skus#registry-throughput-and-throttling), ""ReadOps per minute"" is limited to 3000; - ""A `docker pull` translates to multiple read operations based on the number of layers in the image, plus the manifest retrieval.""; - 3000 / 45 = 66. That means that the image can only be pulled 66 times per minute. This is problematic for running many concurrent workflows that also have many shards. Once that limit is exceeded, the task can fail, which can cause the entire workflow to fail. ; - Layers can be viewed here: `docker history --no-trunc broadinstitute/gatk > gatk-image-layers.txt`; [gatk-image-layers.txt](https://github.com/broadinstitute/gatk/files/14212774/gatk-image-layers.txt). #### Steps to reproduce; `docker history --no-trunc broadinstitute/gatk > gatk-image-layers.txt`. #### Expected behavior; `--squash` shall be added to `build_docker_base_cloud.sh`, like has been added to `build_docker_base_locally.sh` already: https://github.com/broadinstitute/gatk/blob/a353e49f218e675f331abf629f0bb46df1d5151d/scripts/docker/gatkbase/build_docker_base_locally.sh#L24. #### Workaround; Users can pull the existing image, and [use `docker-squash` to squash the image to a single layer](https://github.com/goldmann/docker-squash), then push it into their private ACR, then update their WDLs to reference the new image.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684:176,layers,layers,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684,7,"['Layers', 'layers']","['Layers', 'layers']"
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; ; ### Affected version(s); -All versions after 4.1.4.1, including 4.1.9.0. ### Description ; A user on the forum reported an error message that does not give position information when reporting an allele problem in the reference. A similar issue in FilterVariantTranches was previously discussed at #6701 however the fix only changed FilterVariantTranches. We discussed adding a change with VariantRecalibrator that would also fix other GATK tools when this issue comes up. ; Forum Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360074618292-New-version-of-GATK-leads-to-VariantRecalibrator-error-. #### Command; `~/bin/gatk-4.1.9.0/gatk --java-options -Xms24g VariantRecalibrator -V temp/vartiant_germline/sites.only.vcf.gz -O temp/vartiant_germline/recaliberation.indel.vcf --tranches-file temp/vartiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz --use-allele-specific-annotations`. #### Error Message; ```; Using GATK jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms24g -jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.ja",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6963:933,polymorphi,polymorphic,933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963,1,['polymorphi'],['polymorphic']
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; Resource Bundle. ### Affected version(s); Resource Bundle downloaded 21. July 2020 (ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/ OR https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0;tab=objects?prefix=). ### Description ; The available dataset lack information for FS, SOR etc. but this parameter are necessary for the best practice workflow of the VariantRecalibrator and cannot be added with the VariantAnnotator as the individual information is not included. #### Steps to reproduce; Run VariantRecalibrator with the publicly available reference files. And the recommended parameter settings. gatk --java-options ""-Xmx24g -Xms24g"" VariantRecalibrator \; -V ${inputfile} \; --trust-all-polymorphic \; -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 \; -an FS -an ReadPosRankSum -an MQRankSum -an QD -an SOR \; -mode INDEL \; --max-gaussians 4 \; -resource:mills,known=false,training=true,truth=true,prior=12 ${gatk_ref}Mills_and_1000G_gold_standard.indels.hg38.vcf.gz \; -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ${gatk_ref}Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz \; -resource:dbsnp,known=true,training=false,truth=false,prior=2 ${gatk_ref}/Homo_sapiens_assembly38.dbsnp138.vcf \; -O ${fileprefix}_indels.recal \; --tranches-file ${fileprefix}_indels.tranches. #### Expected behavior; Calculation of VQSLOD tranches. #### Actual behavior; A USER ERROR has occurred: Bad input: Values for FS annotation not detected for ANY training variant in the input callset. VariantAnnotator may be used to add these annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6715:815,polymorphi,polymorphic,815,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6715,1,['polymorphi'],['polymorphic']
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); VcfFuncotationFactoryUnitTest; SimpleKeyXsvFuncotationFactoryUnitTest; SimpleTsvOutputRendererUnitTest; VcfOutputRendererUnitTest; VariantOverlapAnnotaterUnitTest. ### Affected version(s). - [x] Latest master branch as of August 12, 2020. ### Description ; When running the entire unit test suite using; ```; ./gradlew test; ```; where the environment variable TEST_TYPE=unit. The same 371 tests will fail. The following stack trace gives an example of one of the failing tests:; ```; org.broadinstitute.hellbender.exceptions.GATKException: Unable to automatically instantiate codec org.broadinstitute.hellbender.utils.codecs.AnnotatedIntervalCodec; 	at org.broadinstitute.hellbender.engine.FeatureManager.getCandidateCodecsForFile(FeatureManager.java:508); 	at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:455); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:354); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:334); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorIm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6748:402,variab,variable,402,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748,1,['variab'],['variable']
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); _Funcotator_. ### Affected version(s); - [x] Latest public release version [version v4.1.4.1]; - [ ] Latest master branch as of [date of test?]. ### Description . Hi @jonn-smith , I saw you often address Funcotator related issues, so I thought this might be of interest to you. I ran funcotator on a vcf created by mutect2 from RNA-seq data. The vcf includes a large deletion in the GABARAP gene, and when Funcotator processes this annotation, it dies with an error about a query that extends past the end of a contig:. > htsjdk.samtools.SAMException: Query asks for data past end of contig. Query contig ENST00000571253.1|ENS; G00000170296.9|OTTHUMG00000102156.3|OTTHUMT00000440082.2|AC120057.8-003|GABARAP|837|UTR5:1-753|CDS:754-8; 37| start:1 stop:895 contigLength:837; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(Ca; chingIndexedFastaSequenceFile.java:316); at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource; .java:78); at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource; .java:64); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.; getFivePrimeUtrSequenceFromTranscriptFasta(GencodeFuncotationFactory.java:744); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createUtrFuncotation(GencodeFuncotationFactory.java:1568); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:983); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:805); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:78",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345:535,extend,extends,535,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345,1,['extend'],['extends']
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - any version with basename(basename()) function call. (e.g. latest version on master). ### Description ; ```; ""Failed to evaluate 'output_basename' (reason 1 of 1): Evaluating basename(basename(tumor_reads, "".bam""), "".cram"") failed: Failed to interpret 'CDS-00rz9N.hg38' as a file path input for basename (reason 1 of 1): java.lang.IllegalArgumentException: Could not build the path ""CDS-00rz9N.hg38"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, Google Cloud Storage, DRS. Failures: ; HTTP: CDS-00rz9N.hg38 does not have an http or https scheme (IllegalArgumentException); Google Cloud Storage: Path ""CDS-00rz9N.hg38"" does not have a gcs scheme (IllegalArgumentException); DRS: CDS-00rz9N.hg38 does not have a drs scheme. (IllegalArgumentException); Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems""; ```; #### Steps to reproduce; Just run the mutect2.wdl on terra it seems create the issue (maybe using a bam filepath with a name in ""gs://[path]/[NAME].hg38.bam"". #### Expected behavior; I think using basename(basename( is not working with the new version of terra, I would expect another solution with an if on the name end or something.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7485:996,config,configure,996,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7485,1,['config'],['configure']
Modifiability,"## Bug Report. ### Affected tool(s) or class(es); `SAMRecord` from `GATKRead`. ### Affected version(s); - [x] Latest master branch as of January 30, 2024. ### Description ; When I run a tool with a bam file as input, the following code will give me a null:; ```java; @Override; public void apply(GATKRead read, ReferenceContext referenceContext, FeatureContext featureContext) {. // Build sets of read IDs for each file.; final SAMRecord samRecord = read.convertToSAMRecord(getHeaderForReads());; final SAMFileSource fileSource = samRecord.getFileSource();; System.out.println(fileSource);; ```. Output:; (a long list of `null`). #### Steps to reproduce; Create a ReadWalker that takes in a bam file. Here is an integration test that will replicate the issue:. ```java; public class ReadConcordanceIntegrationTest extends CommandLineProgramTest {. @Test; public void testTwoCrams() throws IOException {; final File output = createTempFile(""testReadConcordanceOutputFile"", "".txt"");; final File input = new File(GATKBaseTest.largeFileTestDir, ""expected.K-562.splitNCigarReads.chr20.bam"");. final ArgumentsBuilder args = new ArgumentsBuilder();. args.addInput(input);; this.runCommandLine(args.getArgsArray());; }; }; ```. #### Expected behavior; Output should be the file used in the read data source (bam file) for each read. #### Actual behavior; I get nulls instead",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8671:814,extend,extends,814,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8671,1,['extend'],['extends']
Modifiability,"## Bug Report. ### Affected version(s); - Latest master branch as of 1/12/2022. ### Description ; When I tried to build from the github repo, I received the following error:. FAILURE: Build failed with an exception. * Where:; Build file '/gatk/build.gradle' line: 688. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Could not resolve all files for configuration ':runtimeClasspath'.; > Could not find biz.k11i:xgboost-predictor:0.3.0.; Searched in the following locations:; - https://repo.maven.apache.org/maven2/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; - https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; - https://oss.sonatype.org/content/repositories/snapshots/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; - file:/root/.m2/repository/biz/k11i/xgboost-predictor/0.3.0/xgboost-predictor-0.3.0.pom; Required by:; project :. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. #### Steps to reproduce; `git clone https://github.com/broadinstitute/gatk.git`; `cd gatk/`; `./gradlew bundle`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7636:375,config,configuration,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7636,1,['config'],['configuration']
Modifiability,"## Bug Report. - OS: Arch Linux; - Java: 17. ### Affected version(s); - [x] Latest public release version [version?]. ### Description . Firstly, I run `./gradle localJar`. ```; Downloading https://services.gradle.org/distributions/gradle-7.5.1-bin.zip; ...........10%............20%...........30%............40%...........50%............60%...........70%............80%...........90%............100%. Welcome to Gradle 7.5.1!. Here are the highlights of this release:; - Support for Java 18; - Support for building with Groovy 4; - Much more responsive continuous builds; - Improved diagnostics for dependency resolution. For more details see https://docs.gradle.org/7.5.1/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; Executing: git lfs pull --include src/main/resources/large. FAILURE: Build failed with an exception. * Where:; Build file '/build/gatk/src/gatk/build.gradle' line: 104. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Execution of ""git lfs pull --include src/main/resources/large"" failed with exit code: 2. git-lfs is required to build GATK but may not be installed. See https://github.com/broadinstitute/gatk#building for information on how to build GATK. * Try:; > Run with --stacktrace option to get the stack trace.; > Run with --info or --debug option to get more log output.; > Run with --scan to get full insights. * Get more help at https://help.gradle.org. BUILD FAILED in 17s; ```; However, I already install git-lfs; ```; git-lfs usr/; git-lfs usr/bin/; git-lfs usr/bin/git-lfs; git-lfs usr/share/; git-lfs usr/share/licenses/; git-lfs usr/share/licenses/git-lfs/; git-lfs usr/share/licenses/git-lfs/LICENSE; git-lfs usr/share/man/; git-lfs usr/share/man/man1/; git-lfs usr/share/man/man1/git-lfs-checkout.1.gz; git-lfs usr/share/man/man1/git-lfs-clean.1.gz; git-lfs usr/share/man/man1/git-lfs-clone.1.gz; git-lfs usr/share/man/man1/git-lfs-dedup.1.gz; git-lfs usr/share/man/man1/git-lfs-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8320:756,Config,Configure,756,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8320,1,['Config'],['Configure']
Modifiability,"## Bug Report. java.lang.OutOfMemoryError when 'java -jar /usr/hpc-bio/gatk/gatk-package-4.1.2.0-local.jar' sometimes, but there is a lot of memeory yet. And then all features can not be used. This is the call stack.; ```; java -jar gatk/gatk-package-4.1.2.0-local.jar; Exception in thread ""main"" java.lang.OutOfMemoryError: Requested array size exceeds VM limit; at java.util.Properties$LineReader.readLine(Properties.java:485); at java.util.Properties.load0(Properties.java:353); at java.util.Properties.load(Properties.java:317); at org.aeonbits.owner.loaders.PropertiesLoader.load(PropertiesLoader.java:50); at org.aeonbits.owner.loaders.PropertiesLoader.load(PropertiesLoader.java:43); at org.aeonbits.owner.LoadersManager.load(LoadersManager.java:46); at org.aeonbits.owner.Config$LoadType$2.load(Config.java:129); at org.aeonbits.owner.PropertiesManager.doLoad(PropertiesManager.java:290); at org.aeonbits.owner.PropertiesManager.load(PropertiesManager.java:163); at org.aeonbits.owner.PropertiesManager.load(PropertiesManager.java:153); at org.aeonbits.owner.PropertiesInvocationHandler.<init>(PropertiesInvocationHandler.java:54); at org.aeonbits.owner.DefaultFactory.create(DefaultFactory.java:46); at org.aeonbits.owner.ConfigCache.getOrCreate(ConfigCache.java:87); at org.aeonbits.owner.ConfigCache.getOrCreate(ConfigCache.java:40); at org.broadinstitute.hellbender.utils.config.ConfigFactory.getOrCreate(ConfigFactory.java:268); at org.broadinstitute.hellbender.utils.config.ConfigFactory.getOrCreateConfigFromFile(ConfigFactory.java:454); at org.broadinstitute.hellbender.utils.config.ConfigFactory.initializeConfigurationsFromCommandLineArgs(ConfigFactory.java:439); at org.broadinstitute.hellbender.utils.config.ConfigFactory.initializeConfigurationsFromCommandLineArgs(ConfigFactory.java:414); at org.broadinstitute.hellbender.Main.parseArgsForConfigSetup(Main.java:121); at org.broadinstitute.hellbender.Main.setupConfigAndExtractProgram(Main.java:179); at org.broadinstitute.hellben",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6050:780,Config,Config,780,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6050,2,['Config'],['Config']
Modifiability,"## Bug Report; HaplotypeCaller. ### Affected version(s); 4.3.0. ### Description ; A plot of the frequency distribution of GQ values associated with variants reported by HaplotypeCaller demonstrates ""periodicity"". The following counts GQ values for TP variant calls (data from HG002, aligned to GRCh38 with three different read aligners, chr14 only):. ![GQdist HC](https://user-images.githubusercontent.com/8249753/215591505-06b76118-cdbf-4b04-ae70-55acaaf8fce9.png). Most of the distribution is periodic on GQ values that are even multiples of 3. This is seen in the data for this plot: [GCdist.xlsx](https://github.com/broadinstitute/gatk/files/10540627/GCdist.xlsx). In addition, about 80% of the reported variants were associated with GQ=99 (not plotted here). This kind of thing might be an artifact of the algorithm used to compute GQ. For example, underlying data such as MAPQ might be manifesting the same periodicity, which is then ""passed through"" to GQ. It might also be an implementation error. For example, premature rounding or the use of an integer variable instead of a floating point variable might lead to inadvertent quantization of a result. But this is just speculation, given only that the distribution would be expected to be smooth, not periodic. #### Steps to reproduce; A little bit of awk should suffice to pull GQ values from a plain-text VCF file. #### Expected behavior; No periodicity in the frequency distribution of GQ values. For example, here is the distribution of GQ values for the same three sets of read mappings but with variants called with DeepVariant:. ![GQdist DV](https://user-images.githubusercontent.com/8249753/215611788-9372cec8-7841-4d90-b137-b3f950902fba.png). In addition, about 15% of the reported variants were associated with GQ=99 (not plotted here). #### Actual behavior; (As above.). Thanks for any insight you can provide on this!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8179:1063,variab,variable,1063,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8179,2,['variab'],['variable']
Modifiability,"## Bug/Usability Report. ### Affected tool(s) or class(es); Mutect2 WDL. ### Affected version(s); - [x] Latest public release version [4.1.81]; - [x] Latest master branch as of October 28, 2021. ### Description ; The Mutect2 WDL's Funcotate task has an unintuitive setup with regard to setting memory for the Funcotate task. Funcotate task memory is defined [here](https://github.com/broadinstitute/gatk/blob/4.1.8.1/scripts/mutect2_wdl/mutect2.wdl#L1108); ![image](https://user-images.githubusercontent.com/45641912/139333822-aa0b3adc-b92e-4317-a75e-da322f96822f.png). This is using the dictionary defined earlier called **standard_runtime**. ![image](https://user-images.githubusercontent.com/45641912/139333917-0d97ef00-88e6-4340-8cee-e3295127eab8.png). This dictionary uses a variable called **machine_mem** which is calculated using the workflow's **small_task_mem** input, which is configurable. ![image](https://user-images.githubusercontent.com/45641912/139333959-4465b06d-b2ce-4ab2-bae9-285e25168c1d.png); ![image](https://user-images.githubusercontent.com/45641912/139333973-c8e2c1f6-0efd-4f45-9d1e-10f6c4a2baac.png). To allocate more memory for the Funcotate task, one has to define this **small_task_mem** variable at the workflow level. This effectively changes the amount of memory for all tasks that make use of this dictionary, rather than just the Funcotate task. Funcotate has two input variables **default_ram_mb** and **default_disk_space_gb** which have no bearing on the memory and disk space configuration for the task.; ![image](https://user-images.githubusercontent.com/45641912/139334343-8e614e17-27ef-4fef-815d-fe6e8c39ffef.png). This leads to user confusion when they see these variables in the method configuration page, put values in, and don't see their Funcotate task use the specified values.; ![image](https://user-images.githubusercontent.com/45641912/139334535-4b9a0353-910e-4764-a6d2-a454f4d344aa.png). #### Steps to reproduce; Define the input variables **default",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7532:780,variab,variable,780,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7532,2,"['config', 'variab']","['configurable', 'variable']"
Modifiability,"## Documentation request. ### Description ; This involves the Tool Docs pages. When sharing the link to a tool docs page, the link description shows the PHP code from the old website. . For example, ; **SelectVariants**; _include '../../../../common/include/common.php'; include_once '../../../config.php'; $module = modules::GATK; $name = docSN::toolDocs; printHeader($module, $name, topSN::guide); ..._. This PHP code does not appear in the actual Tool Docs, so there is no visible problem on the website.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7024:294,config,config,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7024,1,['config'],['config']
Modifiability,"## Documentation request. ### Tool(s) or class(es) involved; Mutect2 and FilterMutectCalls. ### Description ; Because both `M2ArgumentCollection` and `M2FiltersArgumentCollection` extend `AssemblyBasedCallerArgumentCollection`, both `Mutect2` and `FilterMutectCalls` display all assembly and caller arguments in the documentation/help even if those arguments don't actually do anything. For example both tools have the argument `--contamination-fraction-to-filter` which has the description:. ```; Fraction of contamination in sequencing data (for all samples) to aggressively remove. If this fraction is greater is than zero, the caller will aggressively attempt to remove contamination ; through biased down-sampling of reads. Basically, it will ignore the contamination fraction of reads for ; each alternate allele. So if the pileup contains N total bases, then we will try to remove ; (N * contamination fraction) bases for each alternate allele.; ```. This argument definitely doesn't do anything in `FilteMutectCalls` but I also don't think it's hooked up to do anything in `Mutect2` either (at least when I tried giving it a high value I still got the same calls). This is by design because Mutect has other ways of handling contamination, but the argument is still displayed in both tools' documentation which is confusing. There are other arguments that have the same issue where it's unclear if they do anything in Mutect or not.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5352:180,extend,extend,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5352,1,['extend'],['extend']
Modifiability,"## Documentation system request. Currently, the tooldoc generation system does not separate arguments that relate to deployment decisions like compute platform (eg `--gcs-project-for-requester-pays`) from the ones that modify the analytical or processing behavior of the tools. This adds to the cognitive burden involved in sorting through all the options available for a given tool. We'd like to have a separate category for these arguments so that they would be isolated from the rest. . In addition, there are a bunch of convenience arguments in the common args section that have more to do with how we're running the tool than its analysis behavior, and could also be consolidated into this separate category (or their own category but that might be too granular). Examples below are from the popular tool [SelectVariants](https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_hellbender_tools_walkers_variantutils_SelectVariants.php):. #### Arguments that would be stratified as platform args. `--cloud-index-prefetch-buffer`; `--cloud-prefetch-buffer`; `--disable-bam-index-caching`; `--gcs-max-retries`; `--gcs-project-for-requester-pays`. #### Arguments that would be stratified as convenience args. `--arguments_file` ; `--help` ; `--version` ; `--create-output-bam-index` ; `--create-output-bam-md5`; `--create-output-variant-index`; `--create-output-variant-md5`; `--gatk-config-file`; `--QUIET`; `--seconds-between-progress-updates`; `--tmp-dir`; `--use-jdk-deflater`; `--use-jdk-inflater`; `--verbosity`; `--showHidden` -> I thought we had got rid of hidden args??. These could also be stratified as convenience but one could argue they affect tool behavior qualitatively:. `--disable-sequence-dictionary-validation`; `--lenient`; `--read-validation-stringency`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5234:1420,config,config-file,1420,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5234,1,['config'],['config-file']
Modifiability,"## Feature request. ### Tool(s) or class(es) involved. Engine level argument. ### Description. This is a new capability. Presently tools like Mutect2 and HaplotypeCaller ignore; soft-clipping by default. In some sequencing products that use long reads relative; to the insert size, the reads often contain some amount of adapter. These reads; are typically soft-clipped by upstream tools like MergeBamAlignments. The result is an increase in false positive rates in somatic samples that have long read lengths compared to insert size. These false positives can be eliminated using the `-no-soft-clips` option, but this ignores all soft clips regardless of why the read was soft-clipped. The proposal here is to add a new engine level argument that will allow GATK tools to ignore soft-clips that occur at the start position of the reads mate. This will allow tools to utilize soft-clips that may contain evidence of indels without providing support for artifactual variants due to adapter sequence.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6346:321,adapt,adapter,321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6346,2,['adapt'],['adapter']
Modifiability,## Feature request. ### Tool(s) or class(es) involved. `GATKSparkTool`. ### Description. `GATKTool` currently has them (and unfortunately takes `File` as input). It would great if some refactoring can happen so that methods provide common utilities (such as these) can be merged in a single base class.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5083:185,refactor,refactoring,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5083,1,['refactor'],['refactoring']
Modifiability,"## Feature request. ### Tool(s) or class(es) involved; Funcotator. ### Description. Currently, there is a Caching mechanism in VcfFuncotationFactory. This could be refactored into a separate component and shared with other funcotation factories. Not all funcotation factories would benefit from this cache, but certainly LocatableXsvFuncotationFactory would. If the refactoring is to put the cache into DataSourceFuncotationFactory, then there needs to be a mechanism for subclasses to disable it. Additionally, the cache should be made into a separate class that can be used from DataSourceFuncotationFactory. Just to encapsulate the cache functionality.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4974:164,refactor,refactored,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4974,2,['refactor'],"['refactored', 'refactoring']"
Modifiability,"## Feature request. ### Tool(s) or class(es) involved; Funcotator. ### Description; Currently, the location of config files that specify the formats for SEG file output are hardcoded in the FuncotatorEngine. These should be available to to override via parameters to the FuncotatorEngine during initialization.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5962:111,config,config,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5962,1,['config'],['config']
Modifiability,"## Feature request. ### Tool(s) or class(es) involved; GenomicsDBImport. ### Description; Users get confused by this error message: `A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader`; `Caused by: java.io.IOException: GenomicsDB JNI Error: VariantQueryProcessorException : Could not open array 1$1$249250621 at workspace: ...; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed`. In one of our [docs](https://gatk.broadinstitute.org/hc/en-us/articles/360035889971--How-to-Consolidate-GVCFs-for-joint-calling-with-GenotypeGVCFs), we offer this advice, but this is not a proper argument in the GATK tool docs yet:; _If you’re working on a POSIX filesystem (e.g. Lustre, NFS, xfs, ext4 etc), you must set the environment variable TILEDB_DISABLE_FILE_LOCKING=1 before running any GenomicsDB tool. If you don’t, you will likely see an error like Could not open array genomicsdb_array at workspace:[...]_. **This request is to add a proper argument to deal with this scenario in GenomicsDBImport and to document it in the tool docs.**",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6519:790,variab,variable,790,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6519,1,['variab'],['variable']
Modifiability,"## Feature request. ### Tool(s) or class(es) involved; M2 PoN Creation. ### Description; There is no progress meter when running `CreateSomaticPanelOfNormals`. This makes debugging harder and the tool could be accidentally identified as frozen. ### Proposed solution; `final Consumer<Locatable> progressUpdater,` as a parameter to the backend class.; The CLI ( `CreateSomaticPanelOfNormals`) can just pass in `l -> progressMeter.update(l)` as long as the CLI extends GATKTool.; When you want to disable the progress meter, you can simply pass in: `l -> {}`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5629:459,extend,extends,459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5629,1,['extend'],['extends']
Modifiability,## Feature request. ### Tool(s) or class(es) involved; Mitochondria WDL. ### Description; User request from the forum:. If the mitochondria WDL had string inputs for all of the tool paths it would be more portable for those running with a local backend without docker.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6258:205,portab,portable,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6258,1,['portab'],['portable']
Modifiability,"## Feature request. ### Tool(s) or class(es) involved; SelectVariants/GenotypeGVCFs/GnarlyGenotyper. ### Description; GenomicsDBExportConfiguration allows for the following to be configured - currently they are mostly hardcoded - `produceGTField`, `produceGTWithMinPLValueForSpanningDeletions`, `setSitesOnlyQuery`, `maxDiploidAltAllelesThatCanBeGenotyped` and `maxGenotypeCount`. Most of this functionality was implemented to support various use cases at some point. Look at the current arguments for subsetting/downsampling/filtering/joint genotyping in the tools and hook existing tool arguments with GenomicsDBExportConfiguration as needed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6456:179,config,configured,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6456,1,['config'],['configured']
Modifiability,"## Feature request. ### Tool(s) or class(es) involved; _FindBreakpointEvidenceSpark_, _StructuralVariationDiscoveryPipelineSpark_, when using _XGBoostEvidenceFilter.java_. ### Description; The SV pipeline filters BreakpointEvidence based on BreakpointDensityFilter, or optionally XGBoostEvidenceFilter. The XGBoostEvidenceFilter uses a saved classifier model trained with Python code external to the GATK. This poses two main problems:; 1) The external Python code was designed for proof-of-principle and method development, not maintainability or ease of use. Additionally, GATK users and developers are assumed to be familiar with Java, not necessarily Python.; 2) The external Python code must share heterogeneous data with Java for unit/integration tests (supplying test BreakpointEvidence, expected classifier features, and expected classifier probabilities). Currently this is done via JSON files organized to (invertibly) store Pandas or Numpy objects. The resulting code to load these JSON files in on the Java side is complex.; These problems can be resolved by; 1) Replacing external python code by porting to an **experimental** tool in the GATK.; 2) Replacing JSON files with a serialization strategy currently supported by the GATK (e.g. Kryo). Additional benefits can be obtained by ensuring that the classifier-training subroutines are sufficiently general to speed development for other projects that may want to use boosted decision trees for classification.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4922:529,maintainab,maintainability,529,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4922,1,['maintainab'],['maintainability']
Modifiability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator scripts_. ### Description; The scripts for Funcotator (`src/scripts/funcotator`) should all be refactored, if necessary, to allow for command-line arguments rather than internal configurations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5346:162,refactor,refactored,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5346,2,"['config', 'refactor']","['configurations', 'refactored']"
Modifiability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator tests_. ### Description; Now that the test data sources have been refactored, we need to go through and remove any extraneous data sources that are no longer necessary.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5350:133,refactor,refactored,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5350,1,['refactor'],['refactored']
Modifiability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator_, _MafOutputRenderer_, _VcfOutputRenderer_. ### Description; For VCFs, we render each funcotation separately, then concatenate strings. This approach has the drawback of being less flexible in terms of ordering the fields (and setting up aliases), but that has not mattered yet. Regardless, it means that all string operations (e.g. excluding fields and sanitizing values) must be in the same method (in this case renderSanitizedFuncotationForVcf) and that method must work on a funcotation. For MAFs, we flatten out the funcotations and put the fields into a giant map. Then we do the changes to field names and values on that map. But by the time I want to exclude fields and sanitize, the map is already made, so we do not render individual funcotations. Therefore no need for a renderSantiziedFuncotationForMaf. We should investigate how easy it would be to generalize an output renderer to use the `map` convention like in `MafOutputRenderer` so we can bubble up that functionality. Since there are only 2 output types now, it might be best to do it before we get more of them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5240:248,flexible,flexible,248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5240,1,['flexible'],['flexible']
Modifiability,## Feature request. ### Tool(s) or class(es) involved; _Funcotator_. ### Description; Currently Funcotator fuzzy-matches between `b37` and `hg19` to enable reuse of data sources compatible with `hg19`. This was a mistake. We need to refactor the data sources to have a separate set for `b37` and `hg19` and remove the fuzzy matching. Bugs and confusion surrounding this fuzzy matching continue to bite and scratch us and are causing time to be lost.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5347:233,refactor,refactor,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5347,1,['refactor'],['refactor']
Modifiability,"## Feature request. ### Tool(s) or class(es) involved; _Funcotator_. ### Description; When running Funcotator on a large VCF, it can take several hours to complete, but each variant row is handled separately, row 1 and row 5 million are equally likely to have problems. Currently, a sufficiently malformed variant row causes it to crash and leave partial output. . It would be much friendlier if the true crash problems (e.g. something like ""invalid interval"") were saved and the crash-causing variant lines reported in bulk at completion, sending an OS exit code/error then. . It might even be a configurable option to exit immediately or save until end. . I do think it is appropriate to crash if a problem is encountered while parsing the header lines.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7097:597,config,configurable,597,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7097,1,['config'],['configurable']
Modifiability,"## Feature request. Since CombineVariants will not be ported, we need equivalent functionality to its ability to annotate ""set"", ie which callset(s) a site is present in. Here is an excerpt from a tutorial that describes this functionality in action:. ----. To find out which set each variant belongs to, we can use CombineVariants. CombineVariants has a way to annotate each site with which set the site belongs to. For example, if a site is in GIAB and failed hard filtering but passed VQSR, CombineVariants will annotate the site with set=G-filterInH-V. The ""filterIn"" flag before the filtering method tells us the site failed the filtering method, hence it was ""filtered"" in the set. java -jar GenomeAnalysisTK.jar \; 	-T CombineVariants \; 	-R ref/human_g1k_b37_20.fasta \; 	-V:G truth_dataset/NA12878.GIAB.vcf \; 	-V:H vcfs/NA12878.hard.filtered.vcf \; 	-V:V vcfs/NA12878.VQSR.filtered.vcf \; 	-o sandbox/NA12878.Combined.vcf . The set-annotated VCF looks like this:. ````; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT INTEGRATION NA12878; 20 61795 rs4814683 G T 2034.16 PASS AC=2;AF=0.500;AN=4;(...);set=Intersection​ ​ GT:AD:ADALL:DP :GQ:PL 0/1:218,205:172,169:769:99 0/1:30,30:.:60:99:1003,0,1027; ````. In this record, ""set=Intersection​"" indicates this record was present and unfiltered in all callsets considered. Here is a key of all the possible combinations for this 3-way venn:. | Meaning | Annotation |; |:-|:-|; | In GIAB only | G |; | In GIAB and failed VQSR only | G-H-filterInV |; | In GIAB and failed both hard filtering and VQSR | G-filterInH-filterInV |; | In GIAB and failed hard filtering only | G-filterInH-V |; | In GIAB and passed both hard filtering and VQSR | Intersection |; | Not in GIAB and failed VQSR only | H-filterInV |; | Not in GIAB and failed both hard filtering and VQSR | FilteredInAll |; | Not in GIAB and failed hard filtering only | filterInH-V |; | Not in GIAB and passed both hard filtering and VQSR | H-V |",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2489:903,sandbox,sandbox,903,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2489,1,['sandbox'],['sandbox']
Modifiability,"## First, add variables to HelpConstants.java ; at <https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/utils/help/HelpConstants.java>. These need to be under _group definitions_ as well as under _supercategory_. E.g.:; ```; public final static String DOC_CAT_READFILTERS = ""Read Filters"";; public final static String DOC_CAT_READFILTERS_SUMMARY = ""Read Filters used by the engine to select reads to be included for analysis"";; ...; // supercat Utilities; groupToSuperCategory.put(DOC_CAT_READFILTERS, DOC_SUPERCAT_UTILITIES);; ```. - group name variable and descriptor: DOC_CAT_ANNOTATORS = ""Annotation Modules""; - group summary variable and descriptor: DOC_CAT_ANNOTATORS_SUMMARY = ""Annotations available to HaplotypeCaller, Mutect2 and VariantAnnotator""; - super category: Utilities (same group as read filters). This is now in <https://github.com/broadinstitute/gatk/pull/3835/commits/320b64a0391b751f4a738100fe854d243b02f2b4>. ---; ## SOP ; https://github.com/broadinstitute/gatk/pull/3835. [1] Add feature tag and define elements to all annotation modules in <https://github.com/broadinstitute/gatk/tree/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator>. E.g. the tag looks thus:; ```; @DocumentedFeature(groupName=HelpConstants.DOC_CAT_READFILTERS, groupSummary=HelpConstants.DOC_CAT_READFILTERS_SUMMARY, summary = ""Keep only reads that are first of pair""); ```; - group name variable: DOC_CAT_ANNOTATORS; - group summary variable: DOC_CAT_ANNOTATORS_SUMMARY; - summary specific to the annotation module. ### For copy-pasting:; ```; @DocumentedFeature(groupName=HelpConstants.DOC_CAT_ANNOTATORS, groupSummary=HelpConstants.DOC_CAT_ANNOTATORS_SUMMARY, summary = """"); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344383546:14,variab,variables,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344383546,5,['variab'],"['variable', 'variables']"
Modifiability,"## Investigation. ### Tool(s) or class(es) involved; Funcotator. ### Description; We should determine whether we can refactor the datasources for both segment and small mutations. Perhaps separate the two into distinct class hierarchies. This will make initialization more complicated, since we may have to initialize more than one FuncotationFactory per datasource directory. We should also eventually support mixed inputs (since a VCF can have both)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5961:117,refactor,refactor,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5961,1,['refactor'],['refactor']
Modifiability,"## Question. Why we use MIN_DP over DP for synthetic Ref allele depth for genotypes derived from hom-ref blocks? ; Would it make more sense to keep and use the average or median?. ```java. ## GenotypeGVCFsEngine.java:176 (about); ...; if (result.isPolymorphicInSamples()) {; // For polymorphic sites we need to make sure e.g. the SB tag is sent to the annotation engine and then removed later.; final VariantContext reannotated = annotationEngine.annotateContext(result, features, ref, null, a -> true);; return new VariantContextBuilder(reannotated).genotypes(; ==!==> cleanupGenotypeAnnotations(reannotated, false)).make();; } else if (includeNonVariants) {; ... ## Same file ln 436, method cleanupGenotypeAnnotations:; ...; // move the MIN_DP to DP; if ( oldGT.hasExtendedAttribute(GATKVCFConstants.MIN_DP_FORMAT_KEY) ) {; depth = parseInt(oldGT.getAnyAttribute(GATKVCFConstants.MIN_DP_FORMAT_KEY));; builder.DP(depth);; attrs.remove(GATKVCFConstants.MIN_DP_FORMAT_KEY);; }; ... ```. ### Tool(s) or class(es) involved; GenotypeGVCFs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7185:282,polymorphi,polymorphic,282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7185,1,['polymorphi'],['polymorphic']
Modifiability,"### Affected class(es); All test classes in GATK (and downstream projects) extending `BaseTest`. ### Affected version(s); - [x] Latest public release version; - [x] Latest master branch. ### Description ; The GATK toolkit assumes `US` locale (set in a `Main` static method), which in turn produces all the test files using the `US` locale; if the test suite is run in a different locale, it might fail unexpectedly. For example, if the locale has a comma-separated decimals instead of dot-separated, comparing the expected file output with `US` locale against the generated by the tests fail. . #### Expected behavior; `BaseTest` should set the locale in a `@BeforeSuite` method (or static method) to set the assumptions of the toolkit to all tests (also for downstream toolkits). #### Actual behavior; `BaseTest` picks default locale.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5012:75,extend,extending,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5012,1,['extend'],['extending']
Modifiability,"### Affected tool(s) or class(es); Funcotator, but could be future tools as well. ### Affected version(s); - [ ] Latest master branch as of [June 14, 2018]. ### Description ; Currently, if you want to read a MAF the GATK will use AnnotatedIntervalCodec. This is fine in the majority of cases. However, under the hood, it is using a configuration setup that has an aliasing scheme. This alias scheme is fairly permissive and can lead to conflicts. For example, if a MAF has a column named ""END"", the MAF will not parse, since the default configuration will attempt to use the ""END"" column instead of ""End_Position"". This can be fixed if we have a MAF codec, but some decisions need to be made. For example, should it produce AnnotatedIntervals? Variant may be too difficult.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4897:332,config,configuration,332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4897,2,['config'],['configuration']
Modifiability,"### Affected tool(s) or class(es); docker version GATK:4.1.1.0. ### Affected version(s); ; latest release. ### Description ; Funcotator shuts down part way through job. A configuration problem @ google?; [funcotator_crash.txt](https://github.com/broadinstitute/gatk/files/3652568/funcotator_crash.txt). RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: www.googleapis.com; ; ### Description . 04:13:19.667 INFO ProgressMeter - 15:85753672 1834.2 199000 108.5; 04:17:42.593 INFO VcfFuncotationFactory - dbSNP 9606_b150 cache hits/total: 0/0; 04:17:42.593 INFO VcfFuncotationFactory - gnomAD_exome 2.1 cache hits/total: 0/1402; 04:17:42.593 INFO VcfFuncotationFactory - gnomAD_genome 2.1 cache hits/total: 0/162233; 04:17:42.665 INFO Funcotator - Shutting down engine; [September 25, 2019 4:17:42 AM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 1,845.78 minutes.; Runtime.totalMemory()=4523032576; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: www.googleapis.com; at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:318); at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182:171,config,configuration,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182,1,['config'],['configuration']
Modifiability,"### Instructions. ## Bug Report; ### Affected tool(s) or class(es); - tools: HaplotypeCaller perhaps Mutec. ; - classes: AlleleLikelihoods. ### Affected version(s); - [ X] Latest public release version [version?]; - [ X] Latest master branch as of [date of test?]. ### Description ; Right before calling annotators HC engine adds filtered reads as additional evidence in the AlleleLikelihoods instance that is passed down to the annotators. The code requests the new evidence to have 0.0 likelihoods so label them as uninformative. However due to an error in how the lk arrays are ""extended"" inside the AlleleLikelihoods these reads inherit past reads (removed) zombie likelihoods instead. Fix is easy. as simple as remove this enclosing ```if``` in AlleleLikelihoods, and simply executed its body; always:. ```; line 793:; if (initialLikelihood != 0.0) // the default array new value.; {; for (int a = 0; a < alleleCount; a++) {; Arrays.fill(sampleValues[a], sampleEvidenceCount, newSampleEvidenceCount, initialLikelihood);; }; }; ```. #### Steps to reproduce. Debug and active region with filtered reads. . #### Expected behavior. Those reads won't contribute to AD or DP. #### Actual behavior. They do contribute, at random, to those count annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7153:582,extend,extended,582,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7153,2,"['extend', 'inherit']","['extended', 'inherit']"
Modifiability,"### Instructions. Initially reported by a user on the [forum](https://gatkforums.broadinstitute.org/gatk/discussion/13680/variants-with-ad-0-0-and-dp-0#latest)... Aparently some variants with non-zero quals have 0 AD and DPs. Other annotations are also missing from the INFO columns. . After some debugging it turns out that the criteria to determine whether a read should be considered for a variant in terms of alignment overlap are different for taking part of PL calculation and AD/DP calculation. . Where is not totally clear what is the best way to go in practice. It seems to me that we should be consistent here and both PL and AD/DP should use the same criterion. The offending code lines:. **HaplotypeCallerGenotypingEngine.java ln171**:. ```java; ReadLikelihoods<Allele> readAlleleLikelihoods = readLikelihoods.marginalize(alleleMapper, ; new SimpleInterval(mergedVC).expandWithinContig(ALLELE_EXTENSION, header.getSequenceDictionary()));; if (configuration.isSampleContaminationPresent()) {; readAlleleLikelihoods.contaminationDownsampling(configuration.getSampleContamination());; }. ```; The code above decides the involvement in PL calculations. Notice that ```ALLELE_EXTENSION``` is set to ```2```. . For the AD/DP and so on the code responsible is in **AssemblyBasedCallerGenotypingEngine.java ln366**:. ```; // Otherwise (else part) we need to do it again.; if (configuration.useFilteredReadMapForAnnotations || !configuration.isSampleContaminationPresent()) {; readAlleleLikelihoodsForAnnotations = readAlleleLikelihoodsForGenotyping;; readAlleleLikelihoodsForAnnotations.filterToOnlyOverlappingReads(loc);; } else {; readAlleleLikelihoodsForAnnotations = readHaplotypeLikelihoods.marginalize(alleleMapper, loc);; if (emitReferenceConfidence) {; readAlleleLikelihoodsForAnnotations.addNonReferenceAllele(Allele.NON_REF_ALLELE);; }; }. ```. The ```filterToOnlyOverlappingReads(loc)``` is called then the overlap criterion is strict. (e.g. 0bp padding). This is also the case for the ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5434:955,config,configuration,955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5434,1,['config'],['configuration']
Modifiability,"#$ -pe smp 2; #$ -t 1-128. shopt -s expand_aliases. cd $TMPDIR. #Load dependencies on Myriad. module load java/temurin-8/8u322-b06; module load gatk/4.2.5.0. #Parse parameter files for inputs. number=$SGE_TASK_ID. paramfile=/home/regmvcr/Scratch/jobscripts/JSBF/file_names.txt. SAMPLE=""`sed -n ${number}p $paramfile | awk '{print $1}'`"". #run SplitNCigarReads. gatk SplitNCigarReads \; -R /home/regmvcr/Scratch/reference/sarek/resources_broad_hg38_v0_Homo_sapiens_assembly38.fasta \; -I ""/home/regmvcr/Scratch/workspace/JSBF/star_salmon/""$SAMPLE"".markdup.sorted.bam"" \; -O ""/home/regmvcr/Scratch/workspace/JSBF/SplitNCigarReads/""$SAMPLE""_split.bam"". I get the following output:. GATK: Some GATK tools require conda and associated libraries.; To use them run:; module load python/miniconda3/4.10.3; source $UCL_CONDA_PATH/etc/profile.d/conda.sh; conda activate $GATK_CONDA; Using GATK jar /shared/ucl/apps/gatk-bsd/4.2.5.0/gatk-4.2.5.0/gatk-package-4.2.5.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /shar; ed/ucl/apps/gatk-bsd/4.2.5.0/gatk-4.2.5.0/gatk-package-4.2.5.0-local.jar SplitNCigarReads -R /home/regmvcr/Scratch/reference/sarek/resources_broad_hg38_v0_Homo_sapiens_assemb; ly38.fasta -I /home/regmvcr/Scratch/workspace/JSBF/star_salmon/I3O-MC-JSBF-100-1003.markdup.sorted.bam -O /home/regmvcr/Scratch/workspace/JSBF/SplitNCigarReads/I3O-MC-JSBF-10; 0-1003_split.bam; 19:40:24.551 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/lustre/shared/ucl/apps/gatk-bsd/4.2.5.0/gatk-4.2.5.0/gatk-package-4.2.5.0-local.jar!/com; /intel/gkl/native/libgkl_compression.so; Sep 14, 2023 7:40:24 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:40:24.716 INFO SplitNCigarRea",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8522:1352,variab,variable,1352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8522,1,['variab'],['variable']
Modifiability,"#253 - Added ""final"" keyword to classes that are not inherited, added…",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/512:53,inherit,inherited,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/512,1,['inherit'],['inherited']
Modifiability,"$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:151); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /opt/conda/share/gatk4-4.0.11.0-0/gatk-package-4.0.11.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=8 -Xms4G -Xmx6G -Djava.io.tmpdir=. -jar /opt/conda/share/gatk4-4.0.11.0-0/gatk-package-4.0.11.0-local.jar VariantFiltration -V indels.vcf.gz -O indels.flt.vcf.gz --filter-expression QD < 2.0 --filter-name lowQD --filter-expression MQ < 20.0 --filter-name lowMQ --filter-expression FS > 200.0 --filter-name highFS --filter-expression SOR > 10.0 --filter-name highSOR --filter-expression ReadPosRankSum < -20.0 --filter-name lowReadPosRankSum --filter-expression InbreedingCoeff < -0.8 --filter-name lowInbreedingCoeff; ```; In an upstream stage I have passed my VCF through bcftools. Some digging led me to find that bcftools (view, norm, etc) will apparently convert fields such as ""MQ=NaN"" to ""MQ=nan"" when writing VCF. This issue has been reported to the bcftools team but has been closed as ""wontfix"", [see here](ht",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5582:3406,variab,variable,3406,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582,1,['variab'],['variable']
Modifiability,"' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/resources/main'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; - Gradle detected a problem with the following location: '/Users/louisb/Workspace/gatk/build/tmp/sparkJar/MANIFEST.MF'. Reason: Task ':sparkJar' uses this output of task ':condaStandardEnvironmentDefinition' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed. Please refer to https://docs.gradle.org/7.3.2/userguide/validation_problems.html#implicit_dependency for more details about this problem.; ```. ```; Deprecated Gradle features were used in this build, making it incompatible with Gradle 8.0. You can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins. See https://docs.gradle.org/7.3.2/userguide/command_line_interface.html#sec:command_line_warnings. Execution optimizations have been disabled for 4 invalid unit(s) of work during this build to ensure correctness.; Please consult deprecation warnings for more details.; ```; The warnings show up in at least these tasks: gatkTabComplete, installDist, gatkDoc, shadowJar, sparkJar. Seems like it should be easy to fix, I'm not sure how we didn't see them when doing the upgrade.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7625:1974,plugin,plugins,1974,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7625,1,['plugin'],['plugins']
Modifiability,"'t know the exact reason for it:. ```; [2019-10-01 02:52:52,49] [info] Running with database db.url = jdbc:hsqldb:mem:e98d186c-96db-46ae-92e5-c326e7aa05d9;shutdown=false;hsqldb.tx=mvcc; [2019-10-01 02:53:01,19] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2019-10-01 02:53:01,20] [info] [RenameWorkflowOptionsInMetadata] 100%; [2019-10-01 02:53:01,31] [info] Running with database db.url = jdbc:hsqldb:mem:c4b3296a-4b73-4053-b6bf-d4eeb71c8956;shutdown=false;hsqldb.tx=mvcc; [2019-10-01 02:53:01,85] [info] Slf4jLogger started; [2019-10-01 02:53:02,22] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-876ccf5"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-10-01 02:53:02,28] [info] Metadata summary refreshing every 1 second.; [2019-10-01 02:53:02,31] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-10-01 02:53:02,31] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-10-01 02:53:02,32] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-10-01 02:53:02,32] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2019-10-01 02:53:02,40] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-10-01 02:53:02,43] [info] SingleWorkflowRunnerActor: Version 46.1; [2019-10-01 02:53:02,44] [info] SingleWorkflowRunnerActor: Submitting workflow; [2019-10-01 02:53:02,49] [info] Unspecified type (Unspecified version) workflow c55a06f3-abc1-4db1-8e0f-ea0303caab2c submitted; [2019-10-01 02:53:02,51] [info] SingleWorkflowRunnerActor: Workflow submitted c55a06f3-abc1-4db1-8e0f-ea0303caab2c; [2019-10-01 02:53:02,51] [info",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6189:1233,config,configured,1233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6189,1,['config'],['configured']
Modifiability,"(1) Sounds good.; (2) Ah, makes sense. I thought I saw the creation of the bunny outside of the scope of the worker (which it isn't); (3) Yes and no. Suppose you switched/refactored from log4j to something else, you'd want to know that the timing still makes sense (or if log4j messed up their timing in a new release). It's not really an issue as log4j isn't going to mess up big and whatever you'd change to would also likely be as already tested as log4j. ; I'll leave it up to you if you want to add timing tests or not.; (4) Great! ; I think this work is something that we should keep the Dataflow team abreast of. There is no reason why great profiling tools couldn't eventually make their way into the SDK code and Google Console. LTGM. Feel free to merge once my whitespace comment is addressed (with or without any more tests).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/628#issuecomment-120189286:171,refactor,refactored,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/628#issuecomment-120189286,1,['refactor'],['refactored']
Modifiability,"(As part of your final review @cmnbroad, you should open a ticket to eventually refactor the `MendelianViolation` class)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-404576289:80,refactor,refactor,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-404576289,1,['refactor'],['refactor']
Modifiability,"(Linked to #7988); Feature additions (and integration tests) for CompareReferences tool, including:; * ability to run base-level comparison modes on specified sequences (not just detected mismatching sequences) using ""sequences-to-align"" option ; * changed wording for missing MD5 compatibility status ('COMPATIBLE' to 'MAYBE_COMPATIBLE,' or something similar) in compatibility tool ; * option to ignore case level differences in base level comparison modes . NOTE: integration test on using an equivalent sequences input file with more than one line (ie. specifying more than one sequences) not yet tested, and can probably do some refactoring to clean up the code for the equivalent sequence comparisons",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8163:633,refactor,refactoring,633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8163,1,['refactor'],['refactoring']
Modifiability,(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more; ```. Thank you. Full log:; ````; 17:54:54.447 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 17:54:54.891 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/scratch/home/int/eva/userx/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 17:54:54.924 DEBUG NativeLibraryLoader - Extracting libgkl_compression.so to /tmp/userx/libgkl_compression2910983555987484852.so; 17:54:55.293 INFO PathSeqPipelineSpark - ------------------------------------------------------------; 17:54:55.294 INFO PathSeqPipelineSpark - The Genome Analysis Toolkit (GATK) v4.0.3.0; 17:54:55.294 INFO PathSeqPipelineSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:54:55.295 INFO PathSeqPipelineSpark - Executing as userx@node016 on Linux v2.6.32-220.4.1.el6.x86_64 amd64; 17:54:55.295 INFO PathSeqPipelineSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_131-b11; 17:54:55.295 INFO PathSeqPipelineSpark - Start Dat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:2996,variab,variables,2996,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,2,"['config', 'variab']","['configured', 'variables']"
Modifiability,(The variable was renamed to GATK_STACKTRACE_ON_USER_EXCEPTION). There are no mentions left of STACK_TRACE_ON_USEREXCEPTION. Thanks to David who reported this bug on gatk-dev-public.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3116:5,variab,variable,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3116,1,['variab'],['variable']
Modifiability,"* *:100`. where the first asterisk stands for ""any contig"", the second stands for ""whole contig"" and the 100 means into 100bp adjacent intervals. from 7ch to 900M??? A few more example as to how such a language could look like:. ```; chr1 # the entire chr1; chr1 * # same; chr1,chr2 # both chr1 and chr2, in full.; * # all contigs in full.; * * # same.; chr1 100-200 # sigle interval from 100-200 on chr1.; chr1 { 100-200 } # same; chr1 { # same; 100-200; }; * 100-200 # 100-200 at every contig.; chr1,chr2 100-200 # only on chr1 and chr2; chr1 *200 # from 1-200 i.e. start to 200.; chr1 4000* # from 4000 to the end of chr1.; chr1 4000 # only position 4000; chr1 4M # only position 4 million. M=10^6, k/K=10^3 ; chr1 10000-99 # from 10000 to 10099... ; # perhaps is best not to accept this as it might silence user input errors.; # but what about instead?; chr1 100[00-99]; chr1 10000+100 # 100 bps starting at 10000 so 10000-10099; chr1 4k # only poistion 4000.; chr20 1M+32K # from position 1 million extending to the following 32Kbps.; chr20 1M1+32K # from position 1 million and 1 instead. (avoiding all those 0s). chr1 *:200 # consecutive 200bp intervals for the entire chromosome; chr1 *:200(100) # 200bp intervals with 100 gaps; chr1 *:200/20 # 200bp intervals with an overlap of 20bp.; chr1 *:20/200 # 200bp starting every 20 positions (so 180bp overlap); chr1 *:200~20 # 200bp intervals truncating down to 20bp if necessary. ; chr1 { # we can combine interval specs in blocks if they apply to the same contig(s).; 1M-2M:150(20) # from 1 to 2Mbp 150 intervals with 20bp gap; 20M-25M # a big interval from 20 to 25M.; 40012451-40023451 # another standalone interval ; } . ```; ## Interval exclusion; We could specify the exclused interval in the same file:; ```; chr20 *:200 exclude *10000 11000000+10000 32510000* # 200bp intervals except telomere and centromere regions. chr20 { # another way using blocks.; *:200; } excl {; *10000 ; 11000000+10000 ; 32510000*; }. ```. ## Arbitrary interval",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5702:1601,extend,extending,1601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5702,1,['extend'],['extending']
Modifiability,"* Added support for annotating 5'/3' flanks via new FIVE_PRIME_FLANK and THREE_PRIME_FLANK funcotations. * Added --five-prime-flank-size and --three-prime-flank-size arguments to control the size of each flanking region. * Refactored datasource classes to allow for padded/custom queries to make this feature possible. * We now emit IGR funcotations in more cases (in particular, when a gene has no basic transcripts, and when the basic transcripts do not fully span a gene and the flank size is small). * Added comprehensive unit tests, and updated integration test data. Resolves #4771",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5403:223,Refactor,Refactored,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5403,1,['Refactor'],['Refactored']
Modifiability,"* Adding a new GATKTool level argument `--variant-output-interval-filtering-mode` which allows filtering output variants according to the input interval list. This replaces `--only-output-calls-starting-in-intervals` which was available in GenotypeGvcfs and GnarlyGenotyper. It works by adding a filtering decorator to the vcf writers created through `GATKTool.createVCFWriter`. ; There are several different filtering modes:; `STARTS_IN`, `ENDS_IN`, `OVERLAPS`, `CONTAINED`, and `ANYWHERE`. The default for tools is not to apply the decorator, but they may optionally change that behavior by overriding the new `getDefaultVariantOutputFilterMode`. `--variant-output-interval-filtering-mode STARTS_IN` is equivalent to the previous behavior of `--only-output-calls-starting-in-intervals true`. MockVcfWriter is now a testUtils class. The naming is a bit awkward so improvements would be helpful. This doesn't fix the weird behavior in HaplotypeCaller but does allow subsetting unique shards with SelectVariants and other variant outputting tools. We could adapt this to apply to bam outputs as well if that seems useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6388:1056,adapt,adapt,1056,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6388,1,['adapt'],['adapt']
Modifiability,"* Currently things are in a weird state, picard style interval lists are handled either as tribble files if they are named correctly as .interval_list; If they are named .intervals, .picard, or .list they are loaded with a different code path.; This unifies it so that picard files are only loaded as .interval_list and .intervals is always considered a Gatk style list. * This removes the work around for broken 0 length intervals that was put in place a long time ago. However, the workaround was effectively removed; for all .interval_list files in 4.1.3.0 when we started reading those through the tribble plugin. Either the broken files no longer are used or they; are misnamed as .intervals. * fix tests to deal correctly with .inverval_list vs .intervals",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6465:610,plugin,plugin,610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6465,1,['plugin'],['plugin']
Modifiability,"* No change in the actual behaviour of GATK; * Several protected methods for customize some parameters of the toolkit:; - `String getCommandLineName()`: returns the name from the command line toolkit; - `void handleResult(Object)`: handle the output of the tool; * `main(String[] args)` code moved to a non-static final method (`mainEntry(String[])`) called inside the static one. This allow that the changes from override the customization methods could be apply with custom instances. With this changes a custom main could be simplify a lot. As an example:. ```java; public class Main extends org.broadinstitute.hellbender.Main {. @Override; protected String getCommandLineName() { return ""MyCustomName""; }. @Override; protected List<String> getPackageList() {; return Arrays.asList(""org.custom.tools"");; }. @Override; protected List<Class<? extends CommandLineProgram>> getClassList() {; return Arrays.asList(CreateSequenceDictionary.class, IndexFeatureFile.class);; }. public static void main(final String[] args) {; new Main().mainEntry(args);; }. }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2246:587,extend,extends,587,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2246,2,['extend'],['extends']
Modifiability,"* Shows the flags needed for sites only query and for producing GT fields; * https://github.com/broadinstitute/gatk/issues/3688; * https://github.com/Intel-HLS/GenomicsDB/issues/161; * Currently, hard coded - need to discuss how these flags will be passed in.; * FYI after https://github.com/Intel-HLS/GenomicsDB/pull/165 is merged in, we will not need to have long argument lists for GenomicsDB. A Protobuf object will be the input parameter and can be configured as needed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4496:454,config,configured,454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4496,1,['config'],['configured']
Modifiability,* SparkContextFactory no longer always emits a warning about the GCS connector environment variables.; This should now only occur when running tests and missing the necessary environment variables. I should have fixed this one a long time ago...,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5987:91,variab,variables,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5987,2,['variab'],['variables']
Modifiability,* creating utils to spin up a Dataproc cluster which will shut itself down after a brief interval of inactivity (10 minutes idle or 30 minutes total); * adding tests which spin up a cluster and run PrintReadsSpark on them; * updating gatk-launch to be aware of new GCLOUD_HOME environment variable. first round of #2298,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3767:289,variab,variable,289,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3767,1,['variab'],['variable']
Modifiability,* fix partitioning bug by moving edge fixing from coordinateSortReads -> querynameSortReads; * refactor methods to reduce code duplication; * renaming and moving some methods; * disallow duplicate sort order on spark because it doesn't work with headerless reads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4765:95,refactor,refactor,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4765,1,['refactor'],['refactor']
Modifiability,* fixing two issues that prevented us from publishing to maven central; - fixing sourceJar typo -> sourcesJar; - configure the pom for all artifact filters; * partial fix for https://github.com/broadinstitute/gatk/issues/5212,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5224:113,config,configure,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5224,1,['config'],['configure']
Modifiability,* update gradle wrapper 8.2.1 -> 8.10.2; * remove 'versions' plugin because we don't use it; * update gradle plugins to new versions; * shadow plugin changed maintainers and coordinates com.github.johnrengelman.shadow:8.1.1 -> com.gradleup.shadow:8.3.3; * git-version 0.5.1 -> 3.1.0; * sonatype scan 2.6.1 -> 2.8.3; * download 5.4.0 -> 5.6.0; * use tasks.register() which is the newer style,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8998:61,plugin,plugin,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8998,3,['plugin'],"['plugin', 'plugins']"
Modifiability,"**After** we've ported reduce support for allele-specific annotations in https://github.com/broadinstitute/gatk/issues/1893 (and not as we're porting!), we should refactor the relevant interfaces to clean them up a bit.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3293:163,refactor,refactor,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3293,1,['refactor'],['refactor']
Modifiability,"**Brief issue description:** ; When following the tutorial https://gatk.broadinstitute.org/hc/en-us/articles/360035531092--How-to-part-I-Sensitively-detect-copy-ratio-alterations-and-allelic-segments, the #4 Plot standardized and denoised copy ratios with PlotDenoisedCopyRatios have different results than the tutorial. Through the control vectors test, it seems that the samples that are used in step #2 to generate CNV PON used in the tutorial are different from the files stored in the tutorial.; **Results:**; Following steps 1 to 4, the resulting plots; ![hcc1143_T_clean denoised](https://github.com/broadinstitute/gatk/assets/89409924/3bce4382-5109-4c6e-b34d-1c6e365dcf62); ![hcc1143_T_clean denoisedLimit4](https://github.com/broadinstitute/gatk/assets/89409924/9d23987c-2747-43af-b72c-4e3754015531); The results have values However, the values in the tutorial are 0.134 and 0.125.; **Tests**; Using the files provided in the tutorial and script generated `cnvponC.pon.hdf5`, which seems to lead to this inconsistency result.; Using:; gatk --java-options ""-Xmx6500m"" CreateReadCountPanelOfNormals \; -I HG00133.alt_bwamem_GRCh38DH.20150826.GBR.exome.counts.hdf5 \; -I HG00733.alt_bwamem_GRCh38DH.20150826.PUR.exome.counts.hdf5 \; -I NA19654.alt_bwamem_GRCh38DH.20150826.MXL.exome.counts.hdf5 \; --minimum-interval-median-percentile 5.0 \; -O sandbox/cnvponC.pon.hdf5; **Files**; The script used to generate this result are attached. ; [gatk_tutorial11682_issue.zip](https://github.com/user-attachments/files/15930567/gatk_tutorial11682_issue.zip). Please help me understand this difference in reproducing the tutorial result. It will be extremely helpful for me to use the pipelines on our lab-generated data. Thank you very much!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8884:1351,sandbox,sandbox,1351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8884,1,['sandbox'],['sandbox']
Modifiability,"**Initial integration of GKL**; - Removed native build related items from `build.gradle`; - Removed native code from src tree; - Refactored `PairHMM.java` and `VectorLoglessPairHMM.java` to use GKL; - Updated `VectorPairHMMUnitTest.java` to use GKL; - Added integration tests to `IntelDeflaterIntegrationTest.java`. **Notes**; - PairHMM has been tested in HaplotypeCaller and GVCF output is md5sum equivalent to the PairHMM currently in GATK; - PairHMM in GKL is still single threaded, but about **_1.4x faster**_ than existing PairHMM, due to fixing a performance issue in the native code; - Next steps are captured in #1903 #1946",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1935:129,Refactor,Refactored,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1935,1,['Refactor'],['Refactored']
Modifiability,"**Problem:**; Looking at the runtime block for the funcotator task in the Mutect2 WDL workflow, it doesn't look like `default_disk_space_gb` or `default_ram_mb` has any role in changing the VM resource settings. I don’t see them being used at all in the rest of the task block. The correct parameters to change to adjust the memory and disk space for this task are `small_task_mem` and `small_task_disk`. **Suggestion**; Remove `default_disk_space_gb` or `default_ram_mb` variables since they are not being used in the task. This makes it less confusing when users need to adjust the resources being used, they can simply use the `small_task_mem` and `small_task_disk` variables; or ; Have the `default_disk_space_gb` and `default_ram_mb` variables be used in the runtime block with the `select_first` function that way users have the option to adjust the resources being used, and if not the task can use the default runtime_params dictionary values. This allows funcotator its own separate variables for adjusting resources. Workflow Link: ; https://github.com/broadinstitute/gatk/blob/79a4cda5e045a7f62cc7ed61d102fabc3637fafb/scripts/mutect2_wdl/mutect2.wdl#L1101. User Question Link:; https://gatk.broadinstitute.org/hc/en-us/community/posts/360068111052-Mutect2-Funcotator-error-?page=1#community_comment_360011181392",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6680:472,variab,variables,472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6680,4,['variab'],['variables']
Modifiability,"**The following work has been done:**; - We performed a round of evaluations against XHMM and cn.MOPS on a cohort of 160 samples from SFARI project (which is described in our ASHG poster). For ground truth we used a callset generated from Talkowski lab SV pipeline on matched whole genome samples. Unfortunately, SFARI cohort is not public and cannot be used for public facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:649,variab,variable,649,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502,1,['variab'],['variable']
Modifiability,**UPDATE**; Add proposed heuristic alignment filtering/picking of long reads for later cpx SV resolving.; Solves #3221 . . Changed `AlignedContig` by adding a boolean field to signal if several equally good alignment configurations exist for downstream analysis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3432:217,config,configurations,217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3432,1,['config'],['configurations']
Modifiability,"**changes in this PR:**; - resolves specops issue #247 - ImportGenomes.wdl takes Array[File] from data table as vcf input; - refactor LoadBigQueryData.wdl back into ImportGenomes; - returns an error if the `bq load` step fails (workflow was silently succeeding when this step failed); - checks existence of tables using `bq show` rather than the csv file - this should still be safe against a race condition because of @ericsong 's refactoring to prevent the `CreateTables` step from being scattered; - run CreateTables at the start (don't wait for CreateImportTsvs); - does NOT use a preemptible VM for the LoadTables step, to minimize (though not eliminate) the possibility of loading a duplicate set of data (see specops issue #248 for further discussion). **testing:**; - these changes were tested in Terra, BQ outputs checked and verified",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7112:125,refactor,refactor,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7112,2,['refactor'],"['refactor', 'refactoring']"
Modifiability,"- Add a CLI flag `--exclude-field-name` which can be specified multiple times.; For example `... --exclude-field-name Clinvar_bar --exclude-field-name Clinvar_foo ...`. We will specify the column names with the full field name: `<datasourcename>_<fieldname>`. For now, we specify via an `exclude`. If nothing is specified, then show everything. - Make sure that this new parameter is integrated into the config file framework as implemented by #4581",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943:404,config,config,404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943,1,['config'],['config']
Modifiability,"- Adds size similarity criterion to SVConcordance and SVCluster tools. This is particularly useful for accurately matching smaller SVs that have a high degree of breakpoint uncertainty, in which case reciprocal overlap does not work well. PESR/mixed variant types must have size similarity, reciprocal overlap, and breakend window criteria met. Depth-only variants may have either size similarity + reciprocal overlap OR breakend window criteria met (or both).; - Rewrites some of the linkage logic to be simpler to read.; - Fixes a rare bug with `SortedMultiset` in `SVClusterEngine` that sometimes caused records with identical start positions to get lost.; - Removes null record attributes to avoid `.` INFO/FORMAT fields, which cause a parsing error with Integer types.; - Add check that the vcf header contigs are sorted in the same order.; - Retain FILTER and QUAL fields in output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8257:464,Rewrite,Rewrites,464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8257,1,['Rewrite'],['Rewrites']
Modifiability,- ApplyBQSR adapted to fit into the Skeleton pipeline; - command-line version still works and passes tests (including cloud); - BaseRecalibrator's testPlottingWorkflow now passes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/815:12,adapt,adapted,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/815,1,['adapt'],['adapted']
Modifiability,"- Created FuncotationFactory as new base class for DataSourceFuncotationFactory; - Created ComputedFuncotationFactory class, inheriting from FuncotationFactory and acting as a base class for GCContentFuncotationFactory and ReferenceContextFuncotationFactory; - Extracted GC content calculation and reference context annotations from previous classes; - Created two new arguments for reference window size and gc content window size; - Created unit tests for GCContent- and ReferenceContextFuncotationFactories; - Regenerated validation files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6033:125,inherit,inheriting,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6033,1,['inherit'],['inheriting']
Modifiability,"- HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 20:41:37.620 DEBUG ConfigFactory - Configuration file values:; 20:41:37.626 DEBUG ConfigFactory - gcsMaxRetries = 20; 20:41:37.626 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 20:41:37.626 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 20:41:37.626 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 20:41:37.626 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 20:41:37.626 DEBUG ConfigFactory - samjdk.compression_level = 2; 20:41:37.626 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 20:41:37.626 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 20:41:37.626 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 20:41:37.626 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 20:41:37.626 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 20:41:37.626 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 20:41:37.627 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 20:41:37.627 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 20:41:37.627 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 20:41:37.627 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 20:41:37.627 DEBUG ConfigFactory - createOutputBamIndex = true; 20:41:37.627 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 20:41:37.627 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 20:41:37.627 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 20:41:37.627 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 20:41:37.627 INFO PathSeqPipelineSpark - Initializing engine; 20:41:37.627 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/23 20:41:38 INFO SparkContext: ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:5711,Config,ConfigFactory,5711,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['Config'],['ConfigFactory']
Modifiability,"- I sneaked in another change where I pass in a single file containing a list of input_vcfs instead of an array of input_vcfs. I made this because Terra couldn't save my inputs when I passed in 700 samples.; - Most of the logic was moved into `CreateTables`, including the determination for what files to load. It would have been cleaner to move all of the file loading logic into `LoadTable` but the current approach cuts down the on the number of `gsutil ls` calls made and more importantly, only spins up a shard if there are files to load.; - I pushed the logic into a separate workflow because I wanted to refactor it as two tasks and I couldn't find a way to get a Task to call another Task without wrapping it in a workflow.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7056:611,refactor,refactor,611,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7056,1,['refactor'],['refactor']
Modifiability,"- Moved tools to ""Metagenomics"" program group; - Updated tool docs; - Changed tool arguments to kebab-case; - Defined argument strings as static variables that are cross-referenced in integration tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3918:145,variab,variables,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3918,1,['variab'],['variables']
Modifiability,- Picard Version: 2.18.16; 11:33:26.275 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:33:26.275 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:33:26.275 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 11:33:26.276 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:33:26.276 INFO CountReadsSpark - Deflater: IntelDeflater; 11:33:26.276 INFO CountReadsSpark - Inflater: IntelInflater; 11:33:26.276 INFO CountReadsSpark - GCS max retries/reopens: 20; 11:33:26.276 INFO CountReadsSpark - Requester pays: disabled; 11:33:26.277 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 11:33:26.277 INFO CountReadsSpark - Initializing engine; 11:33:26.277 INFO CountReadsSpark - Done initializing engine; 2019-01-07 11:33:26 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:26 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-07 11:33:26 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:27 INFO Utils:54 -,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:4625,config,configuration,4625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['config'],['configuration']
Modifiability,- Picard Version: 2.18.16; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:35:11.511 INFO CountReadsSpark - Deflater: IntelDeflater; 13:35:11.511 INFO CountReadsSpark - Inflater: IntelInflater; 13:35:11.512 INFO CountReadsSpark - GCS max retries/reopens: 20; 13:35:11.512 INFO CountReadsSpark - Requester pays: disabled; 13:35:11.512 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:35:11.512 INFO CountReadsSpark - Initializing engine; 13:35:11.512 INFO CountReadsSpark - Done initializing engine; 2019-01-09 13:35:11 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:11 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-09 13:35:11 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:12 INFO Utils:54 -,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:4364,config,configuration,4364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['config'],['configuration']
Modifiability,"- Refactored GencodeGtfCodec to enable parsing of ENSEMBL GTF files.; - Created AbstractGtfCodec and EnsemblGtfCodec.; - Updated Funcotator and Funcotation Factories to allow ENSEMBL-based; GTF files.; - Added an e. coli data sources folder, reference, VCF, and expected; data for testing.; - Added tests for ENSEMBL GTF files. Fixes #6180",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6477:2,Refactor,Refactored,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6477,1,['Refactor'],['Refactored']
Modifiability,- Refactors both the base and root `dockerfile` to reduce the total # of layers. Addresses: https://github.com/broadinstitute/gatk/issues/8684,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8686:2,Refactor,Refactors,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8686,2,"['Refactor', 'layers']","['Refactors', 'layers']"
Modifiability,"- added custom classes `ExtractCohortRecord` and `ExtractCohortFilterRecord` that implement `Locatable`; - refactored attribute building from these records; - now that the records are `Locatable`s, can use `OverlapDetector` to filter locations down to only desired intervals (including excluded sites); - removed queryMode `QUERY` and associated querying from options",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7181:107,refactor,refactored,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7181,1,['refactor'],['refactored']
Modifiability,"- error messages will now include all the missing arguments when applicable; - error messages should be more readable; old style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument output was missing: Argument 'output' is required. ***********************************************************************; ```. new style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred:. Invalid command line:; required argument --input was not specified; required argument --output was not specified. Rerun with --help to see more information on available options. ***********************************************************************; ```; - fixed a bug in CommandLineParser; - collection arguments that had a mutual exclusion field would be reported as missing even if one of the mutex arguments was present; - adding tests for this case; - some refactoring on CommandLineParser. fixes #418. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1144). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1144:1027,refactor,refactoring,1027,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1144,1,['refactor'],['refactoring']
Modifiability,- fixup for problem with fully specified `file:///` names that I introduced in #1450 ; - adding test for fully specified `file:///` url; - adding additional tests to `ReadSparkSink` for HDFS; - tests for writing to HDFS using `MiniDFSCluster`; - tests for overwriting existing HDFS paths; - fixed instance of Wrong FileSystem exception in `ReadSparkSink`; - refactored `ReadSparkSink` to remove duplication; - adding `MiniClusterUtils`; - revising existing code using `MiniDFSCluster` to go through `MiniClusterUtils`; - had to make the minicluster dependency a compile time instead of test dependency so downstream projects can make use of MiniClusterUtils.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1461:358,refactor,refactored,358,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1461,1,['refactor'],['refactored']
Modifiability,"- samjdk.use_async_io_read_samtools = false; 20:41:37.626 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 20:41:37.626 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 20:41:37.626 DEBUG ConfigFactory - samjdk.compression_level = 2; 20:41:37.626 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 20:41:37.626 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 20:41:37.626 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 20:41:37.626 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 20:41:37.626 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 20:41:37.626 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 20:41:37.627 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 20:41:37.627 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 20:41:37.627 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 20:41:37.627 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 20:41:37.627 DEBUG ConfigFactory - createOutputBamIndex = true; 20:41:37.627 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 20:41:37.627 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 20:41:37.627 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 20:41:37.627 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 20:41:37.627 INFO PathSeqPipelineSpark - Initializing engine; 20:41:37.627 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/23 20:41:38 INFO SparkContext: Running Spark version 2.2.0; 18/04/23 20:41:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/04/23 20:41:38 INFO SparkContext: Submitted application: PathSeqPipelineSpark; 18/04/23 20:41:39 INFO ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:5972,Config,ConfigFactory,5972,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['Config'],['ConfigFactory']
Modifiability,"------------------------------------------------------------------------------------; // arguments for debugging / developing the haplotype caller; @@ -634,12 +635,11 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if ( emitReferenceConfidence() ) {; ; if (SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES); - throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and Genotyping Giving Alleles at the same time"");; + throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and GENOTYPE_GIVEN_ALLELES at the same time"");; ; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FOR_EMITTING = -0.0;; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FOR_CALLING = -0.0;; ; -; // also, we don't need to output several of the annotations; annotationsToExclude.add(""ChromosomeCounts"");; annotationsToExclude.add(""FisherStrand"");; @@ -651,6 +651,9 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if (!SCAC.annotateAllSitesWithPLs); logger.info(""All sites annotated with PLs forced to true for reference-model confidence output"");; SCAC.annotateAllSitesWithPLs = true;; + } else if ( ! doNotRunPhysicalPhasing ) {; + doNotRunPhysicalPhasing = true;; + logger.info(""Disabling physical phasing, which is supported only for reference-model confidence output"");; }; ; if ( SCAC.AFmodel == AFCalcFactory.Calculation.EXACT_GENERAL_PLOIDY ); @@ -678,7 +681,7 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if( SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES && consensusMode ); throw new UserException(""HaplotypeCaller cannot be run in both GENOTYPE_GIVEN_ALLELES mode and in consensus mode. Please choose one or the other."");; ; - genotypingEngine = new HaplotypeCallerGenotypingEngine( getToolkit(), SCAC, tryPhysicalPhasing);; + genotypingEngine = new HaplotypeCallerGenotypingEngi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237:3039,extend,extends,3039,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237,1,['extend'],['extends']
Modifiability,"----. ## Bug Report. ### Affected tool(s) or class(es); ReblockGVCF . ### Affected version(s); 4.2.0.0. ### Description ; When running ReblockGVCF the following exception occurs:. `java.lang.IllegalArgumentException: cannot add a genotype with GQ=-1 because it's not within bounds [0,20); `. #### Steps to reproduce. Using a gVCF created with 4.2.0.0 HaplotypeCaller... `gatk ReblockGVCF -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -V gvcf.gather/GARDWGSN00001.autosome.g.vcf.gz -drop-low-quals -rgq-threshold 20 -do-qual-approx -O gvcf.reblock_gq20/GARDWGSN00001.autosome.g.vcf.gz`. #### Expected behavior; Should run to completion and create reblocked GVCF. #### Actual behavior; ```; Reblocking gvcf.gather/GARDWGSN00001.autosome.g.vcf.gz to gvcf.reblock_gq20/GARDWGSN00001.autosome.g.vcf.gz; Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar ReblockGVCF -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -V gvcf.gather/GARDWGSN00001.autosome.g.vcf.gz -drop-low-quals -rgq-threshold 20 -do-qual-approx -O gvcf.reblock_gq20/GARDWGSN00001.autosome.g.vcf.gz; 11:25:55.531 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jun 30, 2021 11:25:55 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 11:25:55.708 INFO ReblockGVCF - ------------------------------------------------------------; 11:25:55.709 INFO ReblockGVCF - The Genome Analysis Toolkit (GATK) v4.2.0.0; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7334:936,variab,variable,936,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7334,1,['variab'],['variable']
Modifiability,"-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30,55] [info] Unspecified type (Unspecified version) workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,68] [info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:2605,config,configured,2605,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['config'],['configured']
Modifiability,"-40) PCR free whole genome samples sequenced to ~45X depth. I'm running into problems figuring out how wide to scatter the analysis, and how to allocate resources. It would be incredibly helpful to have some very clear guidelines about how number of samples and the number of intervals within each scatter affect both runtime and memory usage. Here's what I've been able to infer from the WDL pipelines, tool docs and experimentation (though I suspect some of it is wrong):. 1. Memory usage is approximately proportional to number of samples, number of intervals, number of bias covariates and max copy number. What the docs don't say is what the default is for the number of bias covariates _and_ how to take these numbers and project an approximate memory usage. 2. It would appear that GermlineCNVCaller will, by default, attempt to use all CPU cores available on the machine. From the WDL I see that setting environment variables `MKL_NUM_THREADS` and `OMP_NUM_THREADS` seems to control the parallelism? It would be nice if `GermlineCNVCaller` took a `--threads` and then set these before spawning the python process. 3. Runtime? This would be really nice to have some guidelines around as I get wildly varying results depending on how I'm running. My experimentation is with a) 20 45X WGS samples, b) bin size = 500bp, c) running on a 96-core general purpose machine at AWS with 384GB of memory. My first attempt a) scattered the genome into 48 shards of approximately 115k bins each, representing ~50mb of genome and b) ran 24 jobs concurrently but failed to set the environment variables to control parallelism. In that attempt the first wave of jobs were still running after 24 hours and getting close to finishing up the initial de-noising epoch, with 3/24 having failed due to memory allocation failures. My second attempt, now running, scattered the genome into 150 shards, and is running 12 jobs at a time with 8 cores each and the environment variables set. On the second attempt it look",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6166:1101,variab,variables,1101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6166,1,['variab'],['variables']
Modifiability,"-CompareSAMs not ported because ReadWalker traversal is not suited; for it. -SplitNCigarReads not ported because of the way it uses the reference; (could be ported to ReadWalker with some refactoring, however). There were a few engine changes as well to accomodate the new ReadWalker tools:. -Method to allow walkers to access the SAM header from the reads data source. -No longer require an index for BAM/SAM files when no intervals are; provided and no queries are performed. -onTraversalDone() now allows tools to return a value, which is printed; out by the engine. Resolves #113",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/122:188,refactor,refactoring,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/122,1,['refactor'],['refactoring']
Modifiability,"-Created a new base class for Spark tools, GATKSparkTool, that centrally manages; and validates standard tool inputs (reads, reference, and intervals). This allows; us to enforce consistency across tools, delete duplicated boilerplate code from tools; to load inputs, and perform standard kinds of validation (eg., sequence dictionary; validation) in one place. -Tools that don't fit into the pattern established by GATKSparkTool can still extend; SparkCommandLineProgram directly. -This is just a first step -- there is still much work to be done to unify our data source; classes and transparently handle inputs from different sources (GCS, hdfs, files), but; having inputs centrally managed should make the remaining tasks much easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/955:440,extend,extend,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/955,1,['extend'],['extend']
Modifiability,-Fixes broken input in somatic funcotator test; -Removes some unused resource variable defaults; -Adds `set -u` in some tasks,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6506:78,variab,variable,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6506,1,['variab'],['variable']
Modifiability,"-Ported BQSR and ApplyBQSR to spark. -Refactored the BQSR engine so that all versions of BQSR (walker, dataflow,; and spark) call into a common engine, and removed duplicated versions; of the engine from the codebase.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/911:38,Refactor,Refactored,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/911,1,['Refactor'],['Refactored']
Modifiability,"-Require that the reference dictionary be a superset of the reads dictionary; only when there is at least one CRAM input. -When determining whether a superset relationship exists, do not take extended; attributes (like the sequence MD5) into account; only consider the contig names; and lengths. -Do not require common contigs to occur at the same absolute indices across; dictionaries (but do require that they occur in the same relative order).; Contig indices were an issue for GATK3, but since hellbender relies on contig; names for queries we can afford to disable this annoying check. If we later find; that we need to turn it back on, we can easily do so. -Updated tests appropriately:; -Added test cases showing that extended attributes are ignored when checking; for a superset. ```; -Added test cases for various combinations of the new boolean options; requireSuperset and checkContigIndices. -The existing integration test CRAMSupportIntegrationTest.testWrongRef(); shows that we throw when a CRAM is provided as input with a reference; that does not contain all of its contigs.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/877:192,extend,extended,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877,2,['extend'],['extended']
Modifiability,"-Will now look for both shadow and spark jars in the same directory; as the gatk-launch script, and use them if found. Also checks; BIN_PATH for jars. -Environment variable overrides GATK_SHADOW_JAR and GATK_SPARK_JAR; take precedence over everything. -Wrapper script is used if found and GATK_SHADOW_JAR is not set. Resolves #1693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2090:164,variab,variable,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2090,1,['variab'],['variable']
Modifiability,"-Within a tool, Feature headers can now be obtained from a FeatureContext within apply(),; or from the inherited method getHeaderForFeatures() outside of apply() (eg., in onTraversalStart()). -VariantWalkers have the additional inherited convenience method getHeaderForVariants(); that returns the header for the driving source of variants typed as a VCFHeader. -Engine-facing classes FeatureManager and FeatureDataSource now also expose headers. Requested by Adam",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/308:103,inherit,inherited,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/308,2,['inherit'],['inherited']
Modifiability,".6/configparser.py"", line 1138, in _unify_values; sectiondict = self._sections[section]; KeyError: 'blas'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/configparser.py"", line 168, in fetch_val_for_key; return theano_cfg.get(section, option); File ""/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.6.10/lib/python3.6/configparser.py"", line 781, in get; d = self._unify_values(section, vars); File ""/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.6.10/lib/python3.6/configparser.py"", line 1141, in _unify_values; raise NoSectionError(section); configparser.NoSectionError: No section: 'blas'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/configparser.py"", line 328, in __get__; delete_key=delete_key); File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/configparser.py"", line 172, in fetch_val_for_key; raise KeyError(key); KeyError: 'blas.ldflags'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/configdefaults.py"", line 1256, in check_mkl_openmp; import mkl; ModuleNotFoundError: No module named 'mkl'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/py",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8387:1630,config,configparser,1630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8387,1,['config'],['configparser']
Modifiability,".6/site-packages/theano/compile/__init__.py"", line 10, in <module>; from theano.compile.function_module import *; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/compile/function_module.py"", line 21, in <module>; import theano.compile.mode; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/compile/mode.py"", line 10, in <module>; import theano.gof.vm; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/vm.py"", line 662, in <module>; from . import lazylinker_c; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/gof/lazylinker_c.py"", line 42, in <module>; location = os.path.join(config.compiledir, 'lazylinker_ext'); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/confith.join(config.compiledir, 'lazylinker_ext'); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configparser.py"", line 333, in __get__; self.__set__(cls, val_str); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configparser.py"", line 344, in __set__; self.val = self.filter(val); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configdefaults.py"", line 1745, in filter_compiledir; "" '%s'. Check the permissions."" % path); ValueError: Unable to create the compiledir directory '/root/.theano/compiledir_Linux-4.10--generic-x86_64-with-debian-stretch-sid-x86_64-3.6.2-64'. Check the permissions. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeCommand(PythonScriptExecutor.java:79); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.checkPythonEnvironmentForPackage(PythonScriptExecutor.java:192); at org.broadinstit",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782:6361,config,configparser,6361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782,1,['config'],['configparser']
Modifiability,".921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 08:48:45.921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 08:48:45.921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 08:48:45.922 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 08:48:45.922 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 08:48:45.922 DEBUG ConfigFactory - Configuration file values:; 08:48:45.927 DEBUG ConfigFactory - gcsMaxRetries = 20; 08:48:45.927 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 08:48:45.927 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 08:48:45.927 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 08:48:45.927 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 08:48:45.927 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 08:48:45.927 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 08:48:45.927 DEBUG ConfigFactory - samjdk.compression_level = 2; 08:48:45.927 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 08:48:45.927 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 08:48:45.927 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 08:48:45.927 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 08:48:45.927 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 08:48:45.927 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 08:48:45.928 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 08:48:45.928 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 08:48:45.928 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 08:48:45.928 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 08:48:45.928 DEBUG ConfigFac",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6217:4483,Config,ConfigFactory,4483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6217,1,['Config'],['ConfigFactory']
Modifiability,.; SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]; java.lang.NoClassDefFoundError: org/apache/logging/log4j/core/appender/AbstractAppender; at java.lang.ClassLoader.defineClass1(Native Method); at java.lang.ClassLoader.defineClass(ClassLoader.java:763); at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); at java.net.URLClassLoader.defineClass(URLClassLoader.java:467); at java.net.URLClassLoader.access$100(URLClassLoader.java:73); at java.net.URLClassLoader$1.run(URLClassLoader.java:368); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349); at java.lang.ClassLoader.loadClass(ClassLoader.java:411); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.decodeCacheFiles(PluginRegistry.java:181); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.loadFromMainClassLoader(PluginRegistry.java:119); at org.apache.logging.log4j.core.config.plugins.util.PluginManager.collectPlugins(PluginManager.java:132); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternParser.java:131); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternParser.java:112); at org.apache.logging.log4j.core.layout.PatternLayout.createPatternParser(PatternLayout.java:220); at org.apache.logging.log4j.core.layout.PatternLayout.<init>(PatternLayout.java:138); at org.apache.logging.log4j.core.layout.PatternLayout.<init>(PatternLayout.java:57); at org.apache.logging.log4j.core.layout.PatternLayout$Builder.build(PatternLayout.java:446); at org.apache.logging.log4j.core.config.AbstractConfiguration.setToDefault(AbstractConfiguration.java:518); at org.apache.logging.log4j.core.config.DefaultConfigura,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:3294,config,config,3294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,1,['config'],['config']
Modifiability,".AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec.readActualHeader(XsvLocatableTableCodec.java:341); at org.broadinstitute.hellbender.utils.codecs.xsvLocatableTable.XsvLocatableTableCodec.readActualHeader(XsvLocatableTableCodec.java:64); at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:79); at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:37); at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:261); ... 18 more; ```. java version:; ```; java -version; openjdk version ""1.8.0_222""; OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1~deb9u1-b10); OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode); ```; I added the cadd folder into data source folder like the structure mentioned in document:; ```; cadd; |- hg19; | |- cadd.config; | |- InDels_inclAnno.tsv; | |- InDels_inclAnno.tsv.gz.tbi; |; |- hg38; | |- cadd.config; | |- InDels_inclAnno.tsv; | |- InDels_inclAnno.tsv.gz.tbi; ```; The config file (cadd.config); ```; name = CADD; version = v1.4; src_file = InDels_inclAnno.tsv; origin_location =; preprocessing_script = UNKNOWN. Whether this data source is for the b37 reference.; Required and defaults to false.; isB37DataSource = false. Supported types:; simpleXSV -- Arbitrary separated value table (e.g. CSV), keyed off Gene Name OR Transcript IDlocatableXSV -- Arbitrary separated value table (e.g. CSV), keyed off a genome locationgencode -- Custom datasource class for GENCODEcosmic -- Custom datasource class for COSMIC vcf -- Custom datasource class for Variant Call Format (VCF) files; type = locatableXSV; Required field for GENCODE files.Path to the FASTA file from which to load the sequences for GENCODE transcripts:; gencode_fasta_path =. Required field for GENCODE files.; NCBI build version (either hg19 or hg38):; ncb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223:4368,config,config,4368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223,1,['config'],['config']
Modifiability,.CREATE_INDEX : false; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.CREATE_MD5 : false; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.CUSTOM_READER_FACTORY : ; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.REFERENCE_FASTA : null; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 11:35:40.190 DEBUG ConfigFactory - Configuration file values: ; 11:35:40.196 DEBUG ConfigFactory - 	gcsMaxRetries = 20; 11:35:40.196 DEBUG ConfigFactory - 	gcsProjectForRequesterPays = ; 11:35:40.196 DEBUG ConfigFactory - 	gatk_stacktrace_on_user_exception = false; 11:35:40.196 DEBUG ConfigFactory - 	samjdk.use_async_io_read_samtools = false; 11:35:40.196 DEBUG ConfigFactory - 	samjdk.use_async_io_write_samtools = true; 11:35:40.197 DEBUG ConfigFactory - 	samjdk.use_async_io_write_tribble = false; 11:35:40.197 DEBUG ConfigFactory - 	samjdk.compression_level = 2; 11:35:40.197 DEBUG ConfigFactory - 	spark.kryoserializer.buffer.max = 512m; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.maxResultSize = 0; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.userClassPathFirst = true; 11:35:40.197 DEBUG ConfigFactory - 	spark.io.compression.codec = lzf; 11:35:40.197 DEBUG ConfigFactory - 	spark.executor.memoryOverhead = 600; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.extraJavaOptions = ; 11:35:40.198 DEBUG ConfigFactory - 	spark.executor.extraJavaOptions = ; 11:35:40.198 DEBUG ConfigFa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:3350,Config,ConfigFactory,3350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Config'],['ConfigFactory']
Modifiability,".NON_ZERO_BUFFER_SIZE : 131072; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.REFERENCE_FASTA : null; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:4717,Config,ConfigFactory,4717,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['Config'],['ConfigFactory']
Modifiability,".USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 08:48:45.921 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 08:48:45.922 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 08:48:45.922 INFO DetermineGermlineContigPloidy - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 08:48:45.922 DEBUG ConfigFactory - Configuration file values:; 08:48:45.927 DEBUG ConfigFactory - gcsMaxRetries = 20; 08:48:45.927 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 08:48:45.927 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 08:48:45.927 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 08:48:45.927 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 08:48:45.927 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 08:48:45.927 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 08:48:45.927 DEBUG ConfigFactory - samjdk.compression_level = 2; 08:48:45.927 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 08:48:45.927 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 08:48:45.927 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 08:48:45.927 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 08:48:45.927 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 08:48:45.927 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 08:48:45.928 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 08:48:45.928 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 08:48:45.928 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 08:48:45.928 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 08:48:45.928 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 08:48:45.928 DEBUG ConfigFactory - createOutputBamIndex = true; 08:48:45.928 INFO DetermineGermlineContigPloidy - Defl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6217:4639,Config,ConfigFactory,4639,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6217,1,['Config'],['ConfigFactory']
Modifiability,".USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 11:35:40.190 DEBUG ConfigFactory - Configuration file values: ; 11:35:40.196 DEBUG ConfigFactory - 	gcsMaxRetries = 20; 11:35:40.196 DEBUG ConfigFactory - 	gcsProjectForRequesterPays = ; 11:35:40.196 DEBUG ConfigFactory - 	gatk_stacktrace_on_user_exception = false; 11:35:40.196 DEBUG ConfigFactory - 	samjdk.use_async_io_read_samtools = false; 11:35:40.196 DEBUG ConfigFactory - 	samjdk.use_async_io_write_samtools = true; 11:35:40.197 DEBUG ConfigFactory - 	samjdk.use_async_io_write_tribble = false; 11:35:40.197 DEBUG ConfigFactory - 	samjdk.compression_level = 2; 11:35:40.197 DEBUG ConfigFactory - 	spark.kryoserializer.buffer.max = 512m; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.maxResultSize = 0; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.userClassPathFirst = true; 11:35:40.197 DEBUG ConfigFactory - 	spark.io.compression.codec = lzf; 11:35:40.197 DEBUG ConfigFactory - 	spark.executor.memoryOverhead = 600; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.extraJavaOptions = ; 11:35:40.198 DEBUG ConfigFactory - 	spark.executor.extraJavaOptions = ; 11:35:40.198 DEBUG ConfigFactory - 	codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 11:35:40.198 DEBUG ConfigFactory - 	read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 11:35:40.198 DEBUG ConfigFactory - 	annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 11:35:40.198 DEBUG ConfigFactory - 	cloudPrefetchBuffer = 40; 11:35:40.198 DEBUG ConfigFactory - 	cloudIndexPrefetchBuffer = -1; 11:35:40.198 DEBUG ConfigFactory - 	createOutputBamIndex = true; 11:35:40.200 INFO Mutect2 - Deflater: JdkDeflater; 11:35:40.201 INFO Mutect2 - Inflater: JdkInflater; 11:35:40.202 INFO Mutect2 - GCS max retries/reopens: 20; 11:35:40.202 INFO Mutect2 - Requester pays: disabled; 11:35:40.202 INFO Mutect2 - Initializing engine; 11",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:4145,Config,ConfigFactory,4145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Config'],['ConfigFactory']
Modifiability,.buildevents.BuildExceptionReporter] 	at org.gradle.groovy.scripts.internal.DefaultScriptRunnerFactory$ScriptRunnerImpl.run(DefaultScriptRunnerFactory.java:92); 22:05:55.969 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl$2.run(DefaultScriptPluginFactory.java:176); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.ProjectScriptTarget.addConfiguration(ProjectScriptTarget.java:77); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:181); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:55); 22:05:55.970 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:573); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.project.DefaultProject.evaluate(DefaultProject.java:125); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.execution.TaskPathProjectEvaluator.configureHierarchy(TaskPathProjectEvaluator.java:42); 22:05:55.971 [ERROR] [org.gra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:3012,config,configuration,3012,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['config'],['configuration']
Modifiability,".codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar PrintReadsSpark -I /gatk4/output.bam -O /gatk4/output_3.bam --sparkMaster yarn-client; Warning: Master yarn-client is deprecated since 2.0. Please use master ""yarn"" with specified deploy mode instead.; 18:11:33.604 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 18:11:33.737 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [October 13, 2017 6:11:33 PM CST] PrintReadsSpark --output /gatk4/output_3.bam --input /gatk4/output.bam --sparkMaster yarn-client --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false; [October 13, 2017 6:11:33 PM CST] Executing as hdfs@mg on Linux 3.10.0-514.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_91",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:1672,variab,variables,1672,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,"['config', 'variab']","['configured', 'variables']"
Modifiability,.executeScript(PythonScriptExecutor.java:151); at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.executeGermlineCNVCallerPythonScript(GermlineCNVCaller.java:441); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.doWork(GermlineCNVCaller.java:288); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); Using GATK jar /gatk/gatk-package-4.1.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx10G -jar /gatk/gatk-package-4.1.0.0-local.jar GermlineCNVCaller --run-mode COHORT -L /gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/inputs/-25145621/SureSelect_Human_All_Exon_V6_UTR.1based.preprocessed.filtered.scattered.8543.interval_list --input /gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/inputs/371827342/P0000335.b37.counts.hdf5 --input /gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/inputs/-1425124017/P0000480.b37.counts.hdf5 --input /gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:27539,variab,variable,27539,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,1,['variab'],['variable']
Modifiability,.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490); at java.base/java.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:600); at java.base/java.util.concurrent.ForkJoinTask.reportException(ForkJoinTask.java:678); at java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:737); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateParallel(ReduceOps.java:919); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233); at java.base/java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:558); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.lambda$collectCaseStatsParallel$14(CalibrateDragstrModel.java:568); at java.base/java.util.concurrent.ForkJoinTask$AdaptedCallable.exec(ForkJoinTask.java:1448); at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290); at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020); at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656); at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594); at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183); Caused by: java.lang.IllegalArgumentException: Requested start 8613 is beyond the sequence length HLA-DRB1*04:03:01; at htsjdk.samtools.cram.ref.ReferenceSource.getReferenceBasesByRegion(ReferenceSource.java:207); at htsjdk.samtools.cram.build.CRAMReferenceRegion.fetchReferenceBasesByRegion(CRAMReferenceRegion.java:169); at htsjdk.samtools.cram.structure.Slice.normalizeCRAMRecords(Slice.java:502); at htsjdk.samtools.cram.structure.Container.getSAMRecords(Container.java:322); at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIte,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8139:8394,Adapt,AdaptedCallable,8394,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8139,1,['Adapt'],['AdaptedCallable']
Modifiability,".java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646204>:; >; > > + IntervalList intervalList = new IntervalList(sequenceDictionary);; > + intervals.stream().map(si -> new Interval(si.getContig(), si.getStart(), si.getEnd())).forEach(intervalList::add);; > +; > + // sort intervals according to their coordinates and unique them (i.e. delete duplicates); > + intervalList.uniqued();; > +; > + // pad all elements of intervalList; > + intervalList = intervalList.padded(padding,padding);; > +; > + // merge those that intersect after padding; > + intervalList = IntervalList.intersection(intervalList, intervalList);; > +; > + // break the intervals up to bins -- the last bin in each interval can be shorter than the others; > + IntervalList bins = new IntervalList(sequenceDictionary);; > + int bin_start, bin_end;; > + Interval new_bin;; >; > Agreed, but *if* you didn't inline it, you would want to declare it; > inside the loop. In Java you pretty much always try to give variables the; > most local scope possible.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646252>:; >; > > +; > + // merge those that intersect after padding; > + intervalList = IntervalList.intersection(intervalList, intervalList);; > +; > + // break the intervals up to bins -- the last bin in each interval can be shorter than the others; > + IntervalList bins = new IntervalList(sequenceDictionary);; > + int bin_start, bin_end;; > + Interval new_bin;; > + for(Interval in : intervalList) {; > + bin_start = in.getStart();; > + bin_end = Math.min(bin_start + widthOfBins - 1, in.getEnd());; > + while(bin_start < in.getEnd()) {; > + new_bin = new Interval(in.getContig(), bin_start, bin_end);; > + bins.add(new_bin);; > + bin_start += widthOfBins;; > + bin_end = Math.min(bin_start + widthOfBins - 1, in.getEnd());; >; > If you move bin_e",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:9676,variab,variables,9676,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211,1,['variab'],['variables']
Modifiability,".makeMeansTable(VariantRecalibrator.java:986); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.writeModelReport(VariantRecalibrator.java:887); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.onTraversalSuccess(VariantRecalibrator.java:680); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1062); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms100g -jar /share/pkg.7/gatk/4.2.0.0/install/bin/gatk-package-4.2.0.0-local.jar VariantRecalibrator -V /rprojectnb2/kageproj/gatk/pVCF/chr1/chr1.raw.excessHet.sites.vcf.gz -O snps.recal --tranches-file snps.tranches --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.8 -tranche 99.6 -tranche 99.5 -tranche 99.4 -tranche 99.3 -tranche 99.0 -tranche 98.0 -tranche 97.0 -tranche 90.0 -an AS_QD -an AS_ReadPosRankSum -an AS_MQRankSum -an AS_FS -an AS_MQ -an AS_SOR -an AS_MQ --use-allele-specific-annotations -mode SNP --output-model snps.model --max-gaussians 6 -resource:hapmap,known=false,training=true,truth=true,prior=15 /rprojectnb2/kageproj/gatk/bundle/hapmap_3.3.hg38.vcf.gz -resource:omni,known=false,training=true,truth=true,prior=12 /rprojectnb2/kageproj/gatk/bundle/1000G_omni",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7380:10091,variab,variable,10091,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7380,1,['variab'],['variable']
Modifiability,.txt; > 12:28:19.227 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/Cosmic.db -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/cosmic/hg38/Cosmic.db; > 12:28:19.401 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_tissue.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/cosmic_tissue/hg38/cosmic_tissue.tsv; > 12:28:19.487 INFO DataSourceUtils - Setting lookahead cache for data source: chr1_a_bed : 100000; > 12:28:19.495 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/chr1_a_bed.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/chr1_a_bed/hg38/chr1_a_bed.tsv; > 12:28:19.500 INFO FeatureManager - Using codec XsvLocatableTableCodec to read file file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/chr1_a_bed/hg38/chr1_a_bed.config; > 12:28:19.505 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/chr1_a_bed.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/chr1_a_bed/hg38/chr1_a_bed.tsv; > 12:28:19.507 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/chr1_a_bed.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/chr1_a_bed/hg38/chr1_a_bed.tsv; > WARNING 2020-07-21 12:28:19 AsciiLineReader Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; > 12:28:19.512 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_fusion.tsv -> file:///home/pkus/resources/gatk/funcotator/funcotator_dataSources.v1.6.20190124s/cosmic_fusion/hg38/cosmic_fusion.tsv; > 12:28:19.522 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/genco,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975:13476,config,config,13476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661776975,1,['config'],['config']
Modifiability,/commit/2bb2f50996e5e826268145d426e8edd697f9a46f?src=pr&el=desc) will **increase** coverage by `0.319%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #4445 +/- ##; ===============================================; + Coverage 79.156% 79.475% +0.319% ; - Complexity 16583 17182 +599 ; ===============================================; Files 1049 1050 +1 ; Lines 59510 60950 +1440 ; Branches 9747 10190 +443 ; ===============================================; + Hits 47106 48440 +1334 ; - Misses 8620 8690 +70 ; - Partials 3784 3820 +36; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4445?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `77.703% <ø> (+5.764%)` | `62 <0> (+17)` | :arrow_up: |; | [...stitute/hellbender/utils/config/ConfigFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb25maWcvQ29uZmlnRmFjdG9yeS5qYXZh) | `76.398% <100%> (-0.036%)` | `45 <3> (ø)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-40%)` | `1% <0%> (-2%)` | |; | [...nder/cmdline/PicardCommandLineProgramExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1BpY2FyZENvbW1hbmRMaW5lUHJvZ3JhbUV4ZWN1dG9yLmphdmE=) | `60% <0%> (-10%)` | `4% <0%> (+1%)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4445#issuecomment-368063117:1229,config,config,1229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4445#issuecomment-368063117,2,"['Config', 'config']","['ConfigFactory', 'config']"
Modifiability,/cosmic_fusion.tsv -> file:///gatk/./my_data/funcotator_dataSources.v1.7.20200521s/cosmic_fusion/hg19/cosmic_fusion.tsv; 12:11:28.932 INFO DataSourceUtils - Resolved data source file path: file:///gatk/gencode_xhgnc_v75_37.hg19.tsv -> file:///gatk/./my_data/funcotator_dataSources.v1.7.20200521s/gencode_xhgnc/hg19/gencode_xhgnc_v75_37.hg19.tsv; 12:11:29.933 INFO DataSourceUtils - Resolved data source file path: file:///gatk/Cosmic.db -> file:///gatk/./my_data/funcotator_dataSources.v1.7.20200521s/cosmic/hg19/Cosmic.db; 12:11:30.002 INFO DataSourceUtils - Setting lookahead cache for data source: ClinVar : 100000; 12:11:30.004 INFO DataSourceUtils - Resolved data source file path: file:///gatk/clinvar_hgmd.tsv -> file:///gatk/./my_data/funcotator_dataSources.v1.7.20200521s/clinvar_hgmd/hg19/clinvar_hgmd.tsv; 12:11:30.005 INFO FeatureManager - Using codec XsvLocatableTableCodec to read file file:///gatk/./my_data/funcotator_dataSources.v1.7.20200521s/clinvar_hgmd/hg19/clinvar_hgmd.config; 12:11:30.052 INFO DataSourceUtils - Resolved data source file path: file:///gatk/clinvar_hgmd.tsv -> file:///gatk/./my_data/funcotator_dataSources.v1.7.20200521s/clinvar_hgmd/hg19/clinvar_hgmd.tsv; 12:11:30.053 INFO DataSourceUtils - Resolved data source file path: file:///gatk/clinvar_hgmd.tsv -> file:///gatk/./my_data/funcotator_dataSources.v1.7.20200521s/clinvar_hgmd/hg19/clinvar_hgmd.tsv; WARNING 2021-03-24 12:11:30 AsciiLineReader Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; 12:11:30.054 INFO DataSourceUtils - Resolved data source file path: file:///gatk/dnaRepairGenes.20180524T145835.csv -> file:///gatk/./my_data/funcotator_dataSources.v1.7.20200521s/dna_repair_genes/hg19/dnaRepairGenes.20180524T145835.csv; 12:11:30.055 INFO DataSourceUtils - Resolved data source file path: file:///gatk/simple_uniprot_Dec012014.tsv -> file:///gatk/./my_data/funcotator_dataSources.v1.7.20200521s/sim,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7158:13759,config,config,13759,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7158,1,['config'],['config']
Modifiability,"/gatk-package-4.1.2.0-local.jar; Exception in thread ""main"" java.lang.OutOfMemoryError: Requested array size exceeds VM limit; at java.util.Properties$LineReader.readLine(Properties.java:485); at java.util.Properties.load0(Properties.java:353); at java.util.Properties.load(Properties.java:317); at org.aeonbits.owner.loaders.PropertiesLoader.load(PropertiesLoader.java:50); at org.aeonbits.owner.loaders.PropertiesLoader.load(PropertiesLoader.java:43); at org.aeonbits.owner.LoadersManager.load(LoadersManager.java:46); at org.aeonbits.owner.Config$LoadType$2.load(Config.java:129); at org.aeonbits.owner.PropertiesManager.doLoad(PropertiesManager.java:290); at org.aeonbits.owner.PropertiesManager.load(PropertiesManager.java:163); at org.aeonbits.owner.PropertiesManager.load(PropertiesManager.java:153); at org.aeonbits.owner.PropertiesInvocationHandler.<init>(PropertiesInvocationHandler.java:54); at org.aeonbits.owner.DefaultFactory.create(DefaultFactory.java:46); at org.aeonbits.owner.ConfigCache.getOrCreate(ConfigCache.java:87); at org.aeonbits.owner.ConfigCache.getOrCreate(ConfigCache.java:40); at org.broadinstitute.hellbender.utils.config.ConfigFactory.getOrCreate(ConfigFactory.java:268); at org.broadinstitute.hellbender.utils.config.ConfigFactory.getOrCreateConfigFromFile(ConfigFactory.java:454); at org.broadinstitute.hellbender.utils.config.ConfigFactory.initializeConfigurationsFromCommandLineArgs(ConfigFactory.java:439); at org.broadinstitute.hellbender.utils.config.ConfigFactory.initializeConfigurationsFromCommandLineArgs(ConfigFactory.java:414); at org.broadinstitute.hellbender.Main.parseArgsForConfigSetup(Main.java:121); at org.broadinstitute.hellbender.Main.setupConfigAndExtractProgram(Main.java:179); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:204); at org.broadinstitute.hellbender.Main.main(Main.java:291); ```. ### Affected version(s); - [x] Latest public release version [version?]; Yes. 4.1.2.0. - [ ] Latest master branch as of [date of test?]; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6050:1231,Config,ConfigCache,1231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6050,1,['Config'],['ConfigCache']
Modifiability,"/man1/git-lfs-ls-files.1.gz; git-lfs usr/share/man/man1/git-lfs-merge-driver.1.gz; git-lfs usr/share/man/man1/git-lfs-migrate.1.gz; git-lfs usr/share/man/man1/git-lfs-pointer.1.gz; git-lfs usr/share/man/man1/git-lfs-post-checkout.1.gz; git-lfs usr/share/man/man1/git-lfs-post-commit.1.gz; git-lfs usr/share/man/man1/git-lfs-post-merge.1.gz; git-lfs usr/share/man/man1/git-lfs-pre-push.1.gz; git-lfs usr/share/man/man1/git-lfs-prune.1.gz; git-lfs usr/share/man/man1/git-lfs-pull.1.gz; git-lfs usr/share/man/man1/git-lfs-push.1.gz; git-lfs usr/share/man/man1/git-lfs-smudge.1.gz; git-lfs usr/share/man/man1/git-lfs-standalone-file.1.gz; git-lfs usr/share/man/man1/git-lfs-status.1.gz; git-lfs usr/share/man/man1/git-lfs-track.1.gz; git-lfs usr/share/man/man1/git-lfs-uninstall.1.gz; git-lfs usr/share/man/man1/git-lfs-unlock.1.gz; git-lfs usr/share/man/man1/git-lfs-untrack.1.gz; git-lfs usr/share/man/man1/git-lfs-update.1.gz; git-lfs usr/share/man/man1/git-lfs.1.gz; git-lfs usr/share/man/man5/; git-lfs usr/share/man/man5/git-lfs-config.5.gz; ```. Then I run ; ```; git lfs pull --include src/main/resources/large; ./gradle localJar; ```; then; ```; error transferring ""1d70940bd9d7c6c862304c66d64233726dc30342ae7032a4636939e8249cbf46"": [0] remote missing object 1d70940bd9d7c6c862304c66d64233726dc30342ae7032a4636939e8249cbf46; error transferring ""bd17c3a98f7651b4e7ee54d875c47ec12e18b75daf79b3744a2590ddb0d6b44d"": [0] remote missing object bd17c3a98f7651b4e7ee54d875c47ec12e18b75daf79b3744a2590ddb0d6b44d; error transferring ""6f663a2fdbcde0addc5cb755f7af5d4c19bed92dccfd20e25b2acf2bc8c2ca7c"": [0] remote missing object 6f663a2fdbcde0addc5cb755f7af5d4c19bed92dccfd20e25b2acf2bc8c2ca7c; error transferring ""e38e09cfe7b7ffbc80dce4972bc9c382148520147d46738a3f6f3235b2d876c6"": [0] remote missing object e38e09cfe7b7ffbc80dce4972bc9c382148520147d46738a3f6f3235b2d876c6; error transferring ""4ed7feb0343e9ac03135b1456b2c8d2edab1b359c4950908c4d44152c0634a89"": [0] remote missing object 4ed7feb0343e9ac03135b",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8320:3445,config,config,3445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8320,1,['config'],['config']
Modifiability,"0 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIndex = true; 16:16:36.298 INFO GenomicsDBImport - Deflater: IntelDeflater; 16:16:36.298 INFO GenomicsDBImport - Inflater: IntelInflater; 16:16:36.298 INFO GenomicsDBImport - GCS max retries/reopens: 20; 16:16:36.298 INFO GenomicsDBImport - Requester pays: disabled; 16:16:36.298 INFO GenomicsDBImport - Initializing engine; 16:16:36.523 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified in",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:5286,Config,ConfigFactory,5286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['Config'],['ConfigFactory']
Modifiability,"000); eden space 946688K, 10% used [0x000000066ab00000,0x0000000670bff978,0x00000006a4780000); from space 56832K, 99% used [0x00000006a5900000,0x00000006a9076d70,0x00000006a9080000); to space 85504K, 0% used [0x00000006a9b80000,0x00000006a9b80000,0x00000006aef00000); ParOldGen total 1497088K, used 20019K [0x00000003c0000000, 0x000000041b600000, 0x000000066ab00000); object space 1497088K, 1% used [0x00000003c0000000,0x00000003c138ceb0,0x000000041b600000); Metaspace used 36791K, capacity 37258K, committed 37504K, reserved 1081344K; class space used 5023K, capacity 5176K, committed 5248K, reserved 1048576K. Card table byte_map: [0x00002b5f67df9000,0x00002b5f69dfa000] byte_map_base: 0x00002b5f65ff9000. Marking Bits: (ParMarkBitMap*) 0x00002b5f57e71fa0; Begin Bits: [0x00002b5f6b656000, 0x00002b5f7b656000); End Bits: [0x00002b5f7b656000, 0x00002b5f8b656000). Polling page: 0x00002b5f56e61000. CodeCache: size=245760Kb used=5233Kb max_used=5233Kb free=240526Kb; bounds [0x00002b5f58a39000, 0x00002b5f58f59000, 0x00002b5f67a39000]; total_blobs=2060 nmethods=1583 adapters=391; compilation: enabled. Compilation events (10 events):; Event: 4.330 Thread 0x000056487672d800 1579 1 java.lang.ThreadLocal::getMap (5 bytes); Event: 4.330 Thread 0x000056487672d800 nmethod 1579 0x00002b5f58f55ed0 code [0x00002b5f58f56020, 0x00002b5f58f56130]; Event: 4.333 Thread 0x000056487672d800 1580 3 java.io.FileOutputStream::write (12 bytes); Event: 4.333 Thread 0x000056487672d800 nmethod 1580 0x00002b5f58f56550 code [0x00002b5f58f566c0, 0x00002b5f58f56848]; Event: 4.333 Thread 0x000056487672d800 1582 3 java.io.FilterInputStream::read (9 bytes); Event: 4.333 Thread 0x000056487672d800 nmethod 1582 0x00002b5f58f56910 code [0x00002b5f58f56a80, 0x00002b5f58f56ca8]; Event: 4.344 Thread 0x000056487672d800 1583 3 java.util.Formatter$Flags::<init> (10 bytes); Event: 4.344 Thread 0x000056487672d800 nmethod 1583 0x00002b5f58f56d50 code [0x00002b5f58f56ec0, 0x00002b5f58f57070]; Event: 4.344 Thread 0x000056487672",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4158:15516,adapt,adapters,15516,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158,1,['adapt'],['adapters']
Modifiability,"00000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30,55] [info] Unspecified type (Unspecified version) workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,68] [info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bd",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:2485,config,configured,2485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['config'],['configured']
Modifiability,"015f-0a1b-f1bd-00002ce33928 ; on database directory /tmp/spark-98953d35-8594-4907-b4a5-0870f1d17b3e/metastore with class loader sun.misc.Launcher$AppClassLoader@5c647e05 ; Loaded from file:/opt/cloudera/parcels/CDH-5.12.1-1.cdh5.12.1.p0.3/jars/derby-10.11.1.1.jar; java.vendor=Oracle Corporation; java.runtime.version=1.8.0_91-b14; user.dir=/opt/Software/gatk; os.name=Linux; os.arch=amd64; os.version=3.10.0-514.el7.x86_64; derby.system.home=null; Database Class Loader started - derby.database.classpath=''; 17/10/11 14:25:33 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.1.0-cdh5.12.1; 17/10/11 14:25:33 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException; SQL context available as sqlContext. **./gradlew bundle**; **[root@com1 gatk]# ./gradlew bundle; when I executed the command ”./gradlew bundle”， it appeared the error in the last ，did this matter？**. .......; [loading ZipFileIndexFileObject[/root/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.6.5/d50be1723a09be903887099ff2014ea9020333/jackson-databind-2.6.5.jar(com/fasterxml/jackson/databind/annotation/JsonSerialize$Inclusion.class)]]; [loading ZipFileIndexFileObject[/root/.gradle/caches/modules-2/files-2.1/org.apache.logging.log4j/log4j-core/2.5/7ed845de1dfe070d43511fab1784e6c4118398/log4j-core-2.5.jar(org/apache/logging/log4j/core/config/plugins/PluginVisitorStrategy.class)]]; [done in 5759 ms]; 1 error; :gatkTabComplete FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkTabComplete'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/opt/Software/gatk/build/tmp/gatkTabComplete/jadoc.options'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 7.431 secs",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240:3362,config,config,3362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240,3,"['Plugin', 'config', 'plugin']","['PluginVisitorStrategy', 'config', 'plugins']"
Modifiability,05:51.489 DEBUG Mutect2 - Processing assembly region at chrM:11085-11384 isActive: false numReads: 0; 12:05:51.501 DEBUG Mutect2 - Processing assembly region at chrM:11385-11684 isActive: false numReads: 0; 12:05:51.513 DEBUG Mutect2 - Processing assembly region at chrM:11685-11984 isActive: false numReads: 0; 12:05:51.526 DEBUG Mutect2 - Processing assembly region at chrM:11985-12284 isActive: false numReads: 0; 12:06:02.022 DEBUG Mutect2 - Processing assembly region at chrM:12285-12584 isActive: false numReads: 0; 12:06:03.941 DEBUG Mutect2 - Processing assembly region at chrM:12585-12729 isActive: false numReads: 44205; 12:06:04.330 DEBUG Mutect2 - Processing assembly region at chrM:12730-13020 isActive: true numReads: 88386; 12:06:10.995 DEBUG ReadThreadingGraph - Recovered 11 of 15 dangling tails; 12:06:11.087 DEBUG ReadThreadingGraph - Recovered 7 of 36 dangling heads; 12:06:11.465 DEBUG Mutect2Engine - Active Region chrM:12730-13020; 12:06:11.470 DEBUG Mutect2Engine - Extended Act Region chrM:12630-13120; 12:06:11.474 DEBUG Mutect2Engine - Ref haplotype coords chrM:12630-13120; 12:06:11.478 DEBUG Mutect2Engine - Haplotype count 128; 12:06:11.481 DEBUG Mutect2Engine - Kmer sizes count 0; 12:06:11.485 DEBUG Mutect2Engine - Kmer sizes values []; 12:08:48.420 DEBUG Mutect2 - Processing assembly region at chrM:13021-13320 isActive: false numReads: 44155; 12:08:49.628 INFO ProgressMeter - chrM:13021 33.1 50 1.5; 12:09:01.241 DEBUG Mutect2 - Processing assembly region at chrM:13321-13620 isActive: false numReads: 55070; 12:09:01.757 DEBUG Mutect2 - Processing assembly region at chrM:13621-13636 isActive: false numReads: 55240; 12:09:02.341 DEBUG Mutect2 - Processing assembly region at chrM:13637-13936 isActive: true numReads: 110273; 12:09:09.957 DEBUG ReadThreadingGraph - Recovered 24 of 26 dangling tails; 12:09:10.041 DEBUG ReadThreadingGraph - Recovered 6 of 14 dangling heads; 12:09:10.602 DEBUG Mutect2Engine - Active Region chrM:13637-13936; 12:09:10.608 DEBUG Mu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:19314,Extend,Extended,19314,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Extend'],['Extended']
Modifiability,0; 12:06:11.474 DEBUG Mutect2Engine - Ref haplotype coords chrM:12630-13120; 12:06:11.478 DEBUG Mutect2Engine - Haplotype count 128; 12:06:11.481 DEBUG Mutect2Engine - Kmer sizes count 0; 12:06:11.485 DEBUG Mutect2Engine - Kmer sizes values []; 12:08:48.420 DEBUG Mutect2 - Processing assembly region at chrM:13021-13320 isActive: false numReads: 44155; 12:08:49.628 INFO ProgressMeter - chrM:13021 33.1 50 1.5; 12:09:01.241 DEBUG Mutect2 - Processing assembly region at chrM:13321-13620 isActive: false numReads: 55070; 12:09:01.757 DEBUG Mutect2 - Processing assembly region at chrM:13621-13636 isActive: false numReads: 55240; 12:09:02.341 DEBUG Mutect2 - Processing assembly region at chrM:13637-13936 isActive: true numReads: 110273; 12:09:09.957 DEBUG ReadThreadingGraph - Recovered 24 of 26 dangling tails; 12:09:10.041 DEBUG ReadThreadingGraph - Recovered 6 of 14 dangling heads; 12:09:10.602 DEBUG Mutect2Engine - Active Region chrM:13637-13936; 12:09:10.608 DEBUG Mutect2Engine - Extended Act Region chrM:13537-14036; 12:09:10.613 DEBUG Mutect2Engine - Ref haplotype coords chrM:13537-14036; 12:09:10.617 DEBUG Mutect2Engine - Haplotype count 128; 12:09:10.621 DEBUG Mutect2Engine - Kmer sizes count 0; 12:09:10.625 DEBUG Mutect2Engine - Kmer sizes values []; 12:13:51.290 DEBUG Mutect2 - Processing assembly region at chrM:13937-13944 isActive: true numReads: 54773; 12:13:53.989 DEBUG ReadThreadingGraph - Recovered 29 of 59 dangling tails; 12:13:54.004 DEBUG ReadThreadingGraph - Recovered 0 of 35 dangling heads; 12:13:54.432 DEBUG Mutect2Engine - Active Region chrM:13937-13944; 12:13:54.440 DEBUG Mutect2Engine - Extended Act Region chrM:13837-14044; 12:13:54.447 DEBUG Mutect2Engine - Ref haplotype coords chrM:13837-14044; 12:13:54.452 DEBUG Mutect2Engine - Haplotype count 128; 12:13:54.456 DEBUG Mutect2Engine - Kmer sizes count 0; 12:13:54.462 DEBUG Mutect2Engine - Kmer sizes values []; 12:13:55.715 DEBUG Mutect2 - Processing assembly region at chrM:13945-14244 isActive: false ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:20339,Extend,Extended,20339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Extend'],['Extended']
Modifiability,"1) Runtime Block. Generally diskpace, memory, and docker image would be the main cloud runtime attributes to have for a task. Maybe give them default values, so that users can change them in the json if they would like. ; 2) Variable declaration placement. Not absolutely necessary but thought it might help reduce the number of lines in the wdl. Here is an example where the task declares a variable that is not in the call or workflow block: [here](https://github.com/gatk-workflows/seq-format-conversion/blob/0f4abf107950769ffd891770db18c9691e720314/cram-to-bam.wdl#L79). Here is a wdl doc about it [(link)](https://support.terra.bio/hc/en-us/articles/360037485511-Add-Variables) though its old. Hard to find a direct statement about it in the wdl 1.0 spec but this section hints at it [link](https://github.com/openwdl/wdl/blob/master/versions/1.0/SPEC.md#declared-inputs-defaults-and-overrides).; 3. Input naming. Ahh. that makes sense. I often see `input_file` being used in wdls so that could work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6504#issuecomment-615216274:225,Variab,Variable,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6504#issuecomment-615216274,3,"['Variab', 'variab']","['Variable', 'Variables', 'variable']"
Modifiability,1. Allow for using separate threads for reading / processing / writing (max 3); 2. Use NM SAM tag instead of edit distance; 3. Perform likelihood scoring on trimmed read. Additional changes include:; 1. CachingIndexedFastaSequenceFile is enhanced to be thread safe and allow for adjusting its cache size. The change involved synchronizing the main query method (getSubsequenceAt) and deriving the cache size from a settable variable rather than from a constant.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8982:238,enhance,enhanced,238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8982,2,"['enhance', 'variab']","['enhanced', 'variable']"
Modifiability,"1. User can define the number of Spark cores in gradle test by environmental variable GATK_TEST_SPARK_CORES. If the variable is not defined, or the value is bogus, will fall back to default of ""local[*]""; 2. Skip intelDeflator test on PPC platforms.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1776:77,variab,variable,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1776,2,['variab'],['variable']
Modifiability,"1. line coverage is 89% for this class. Uncovered code is for a) read without bases, b) IO exception when writing the report, c) plotting code. So i'm not too worried about this.; 2. agreed in principle. To make this doable though we need a testing framework that would make it easy to manufacture reads en bulk. Right now we'd need to make them one by one - integration test has a nice property of being portable across picard/gatk and it's easy to plug in because it has an input with many reads. I'm assuming that 'looks fine' is equivalent to 'LGTM' and will merge when tests pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1013#issuecomment-149761535:405,portab,portable,405,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1013#issuecomment-149761535,1,['portab'],['portable']
Modifiability,"10 --max_calling_iters=10 --caller_update_convergence_threshold=1.000000e-03 --caller_internal_admixing_rate=7.500000e-01 --caller_external_admixing_rate=1.000000e+00 --disable_caller=false --disable_sampler=false --disable_annealing=false; Stdout: 10:20:12.111 INFO case_denoising_calling - THEANO_FLAGS environment variable has been set to: device=cpu,floatX=float64,optimizer=fast_run,compute_test_value=ignore,openmp=true,blas.ldflags=-lmkl_rt,openmp_elemwise_minsize=10; 10:20:12.273 INFO root - Loading modeling interval list from the provided model...; 10:20:12.475 INFO gcnvkernel.io.io_intervals_and_counts - The given interval list provides the following interval annotations: {'GC_CONTENT'}; 10:20:12.491 INFO root - The model contains 11901 intervals and 23 contig(s); 10:20:12.491 INFO root - Loading 1 read counts file(s)...; 10:20:12.545 INFO gcnvkernel.io.io_metadata - Loading germline contig ploidy and global read depth metadata...; 10:20:12.554 INFO root - Loading denoising model configuration from the provided model...; 10:20:12.555 INFO root - - bias factors enabled: True; 10:20:12.555 INFO root - - explicit GC bias modeling enabled: True; 10:20:12.555 INFO root - - bias factors in active classes disabled: False; 10:20:12.555 INFO root - - maximum number of bias factors: 5; 10:20:12.555 INFO root - - number of GC curve knobs: 20; 10:20:12.555 INFO root - - GC curve prior standard deviation: 1.0; 10:20:12.954 INFO gcnvkernel.tasks.task_case_denoising_calling - Instantiating the denoising model...; 10:20:15.806 INFO gcnvkernel.tasks.task_case_denoising_calling - Instantiating the sampler...; 10:20:15.807 INFO gcnvkernel.tasks.task_case_denoising_calling - Instantiating the copy number caller...; 10:20:18.549 INFO gcnvkernel.models.fancy_model - Global model variables: {'log_mean_bias_t', 'psi_t_log__', 'W_tu', 'ard_u_log__'}; 10:20:18.549 INFO gcnvkernel.models.fancy_model - Sample-specific model variables: {'read_depth_s_log__', 'psi_s_log__', 'z_sg', 'z_su'}",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8740:6513,config,configuration,6513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8740,1,['config'],['configuration']
Modifiability,"13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; > 21:13:04.223 INFO GenotypeGVCFs - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; > 21:13:04.224 DEBUG ConfigFactory - Configuration file values:; > 21:13:04.230 DEBUG ConfigFactory - gcsMaxRetries = 20; > 21:13:04.230 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; > 21:13:04.230 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; > 21:13:04.230 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; > 21:13:04.230 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; > 21:13:04.230 DEBUG ConfigFactory - samjdk.compression_level = 1; > 21:13:04.230 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; > 21:13:04.230 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; > 21:13:04.230 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; > 21:13:04.230 DEBUG ConfigFactory - spark.io.compression.codec = lzf; > 21:13:04.230 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; > 21:13:04.230 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; > 21:13:04.230 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; > 21:13:04.230 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; > 21:13:04.230 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; > 21:13:04.231 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; > 21:13:04.231 DEBUG ConfigFactory - createOutputBamIndex = true; > 21:13:04.231 INFO GenotypeGVCFs - Deflater: IntelDeflater; > 21:13:04.231 INFO GenotypeGVCFs - Inflater: IntelInflater; > 21:13:04.231 INFO GenotypeGVCFs - GCS max retries/reopens: 20; > 21:13:04.231 INFO GenotypeGVCFs - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; > 21:13:04.231 INFO GenotypeGVCFs - Initializing engine; > 21:13:11.834 INFO GenotypeGVCFs - Done initializing",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4161:4138,Config,ConfigFactory,4138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4161,1,['Config'],['ConfigFactory']
Modifiability,16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.CUSTOM_READER_FACTORY :; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.REFERENCE_FASTA : null; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_pac,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793:4363,Config,ConfigFactory,4363,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793,1,['Config'],['ConfigFactory']
Modifiability,"16T00:09:07.4038957Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4039323Z location: class CountingReadFilter; 2022-08-16T00:09:07.4039849Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T00:09:07.4040311Z @VisibleForTesting; 2022-08-16T00:09:07.4040921Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4041294Z location: class CountingVariantFilter; 2022-08-16T00:09:07.4054361Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4060164Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:75: error: cannot find symbol; 2022-08-16T00:09:07.4060614Z @VisibleForTesting; 2022-08-16T00:09:07.4061233Z symbol: class VisibleForTesting; 2022-08-16T00:09:07.4061591Z location: class ReadFilter; 2022-08-16T00:09:07.4083439Z src/main/java/org/broadinstitute/hellbender/utils/config/ConfigFactory.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4092135Z src/main/java/org/broadinstitute/hellbender/utils/config/GATKConfig.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4107682Z src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4116317Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4117746Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4124264Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:32: error: cannot find symbol; 2022-08-16T00:09:07.4124816Z private static BiMap<Log.LogLevel, Level> loggingLevelNamespaceMap;; 2022-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:12207,config,config,12207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,2,"['Config', 'config']","['ConfigFactory', 'config']"
Modifiability,"16T22:45:53.8024147Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8024320Z location: class CountingReadFilter; 2022-08-16T22:45:53.8024635Z src/main/java/org/broadinstitute/hellbender/engine/filters/CountingVariantFilter.java:197: error: cannot find symbol; 2022-08-16T22:45:53.8024772Z @VisibleForTesting; 2022-08-16T22:45:53.8025036Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8025212Z location: class CountingVariantFilter; 2022-08-16T22:45:53.8032154Z src/main/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptor.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8035089Z src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilter.java:75: error: cannot find symbol; 2022-08-16T22:45:53.8035234Z @VisibleForTesting; 2022-08-16T22:45:53.8035505Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8035658Z location: class ReadFilter; 2022-08-16T22:45:53.8087327Z src/main/java/org/broadinstitute/hellbender/utils/config/ConfigFactory.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8103864Z src/main/java/org/broadinstitute/hellbender/utils/config/GATKConfig.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8113680Z src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8117654Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:3: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8118430Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8124030Z src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java:32: error: cannot find symbol; 2022-08-16T22:45:53.8124383Z private static BiMap<Log.LogLevel, Level> loggingLevelNamespaceMap;; 2022-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:14245,config,config,14245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,2,"['Config', 'config']","['ConfigFactory', 'config']"
Modifiability,"19.245 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 17:39:19.245 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 17:39:19.245 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 17:39:19.245 DEBUG ConfigFactory - spark.yarn.executor.memoryOverhead = 600; 17:39:19.245 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 17:39:19.245 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 17:39:19.245 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 17:39:19.245 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 17:39:19.245 DEBUG ConfigFactory - createOutputBamIndex = true; 17:39:19.245 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 17:39:19.245 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 17:39:19.245 INFO PathSeqPipelineSpark - Deflater: IntelDeflater; 17:39:19.246 INFO PathSeqPipelineSpark - Inflater: IntelInflater; 17:39:19.246 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:39:19.246 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:39:19.246 INFO PathSeqPipelineSpark - Initializing engine; 17:39:19.246 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/24 17:39:19 INFO SparkContext: Running Spark version 2.2.0; 18/04/24 17:39:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/04/24 17:39:19 INFO SparkContext: Submitted application: PathSeqPipelineSpark; 18/04/24 17:39:20 INFO SecurityManager: Changing view acls ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:6305,Config,ConfigFactory,6305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Config'],['ConfigFactory']
Modifiability,"1:35:40.189 INFO Mutect2 - HTSJDK Defaults.REFERENCE_FASTA : null; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 11:35:40.189 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:35:40.190 INFO Mutect2 - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 11:35:40.190 DEBUG ConfigFactory - Configuration file values: ; 11:35:40.196 DEBUG ConfigFactory - 	gcsMaxRetries = 20; 11:35:40.196 DEBUG ConfigFactory - 	gcsProjectForRequesterPays = ; 11:35:40.196 DEBUG ConfigFactory - 	gatk_stacktrace_on_user_exception = false; 11:35:40.196 DEBUG ConfigFactory - 	samjdk.use_async_io_read_samtools = false; 11:35:40.196 DEBUG ConfigFactory - 	samjdk.use_async_io_write_samtools = true; 11:35:40.197 DEBUG ConfigFactory - 	samjdk.use_async_io_write_tribble = false; 11:35:40.197 DEBUG ConfigFactory - 	samjdk.compression_level = 2; 11:35:40.197 DEBUG ConfigFactory - 	spark.kryoserializer.buffer.max = 512m; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.maxResultSize = 0; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.userClassPathFirst = true; 11:35:40.197 DEBUG ConfigFactory - 	spark.io.compression.codec = lzf; 11:35:40.197 DEBUG ConfigFactory - 	spark.executor.memoryOverhead = 600; 11:35:40.197 DEBUG ConfigFactory - 	spark.driver.extraJavaOptions = ; 11:35:40.198 DEBUG ConfigFactory - 	spark.executor.extraJavaOptions = ; 11:35:40.198 DEBUG ConfigFactory - 	codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 11:35:40.198 DEBUG ConfigFactory - 	read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 11:35:40.198 DEBUG ConfigFactory - 	annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 11:35:40.198 DEBUG ConfigFactory - 	cloudPrefetchBuffer = 40; 11:35:40.198 DEBUG ConfigFactory - 	clou",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7281:3789,Config,ConfigFactory,3789,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7281,1,['Config'],['ConfigFactory']
Modifiability,"2 DEBUG ConfigFactory - Configuration file values:; 21:05:38.395 DEBUG ConfigFactory - gcsMaxRetries = 20; 21:05:38.395 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 21:05:38.395 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 21:05:38.395 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 21:05:38.395 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 21:05:38.395 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 21:05:38.395 DEBUG ConfigFactory - samjdk.compression_level = 2; 21:05:38.395 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 21:05:38.395 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 21:05:38.395 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 21:05:38.395 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 21:05:38.395 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 21:05:38.395 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 21:05:38.395 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 21:05:38.395 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 21:05:38.395 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 21:05:38.395 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 21:05:38.395 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 21:05:38.395 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 21:05:38.395 DEBUG ConfigFactory - createOutputBamIndex = true; 21:05:38.396 INFO GermlineCNVCaller - Deflater: IntelDeflater; 21:05:38.396 INFO GermlineCNVCaller - Inflater: IntelInflater; 21:05:38.396 INFO GermlineCNVCaller - GCS max retries/reopens: 20; 21:05:38.396 INFO GermlineCNVCaller - Requester pays: disabled; 21:05:38.396 INFO GermlineCNVCaller - Initializing engine; 21:05:38.399 DEBUG ScriptExecutor - Executing:; 21:05:38.399 DEBUG ScriptExecutor - python; 21:05:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8952:4183,Config,ConfigFactory,4183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8952,1,['Config'],['ConfigFactory']
Modifiability,"2 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:43:52.472 INFO GermlineCNVCaller - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 23:43:52.472 DEBUG ConfigFactory - Configuration file values: ; 23:43:52.474 DEBUG ConfigFactory - 	gcsMaxRetries = 20; 23:43:52.474 DEBUG ConfigFactory - 	gcsProjectForRequesterPays = ; 23:43:52.474 DEBUG ConfigFactory - 	gatk_stacktrace_on_user_exception = false; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.use_async_io_read_samtools = false; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.use_async_io_write_samtools = true; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.use_async_io_write_tribble = false; 23:43:52.474 DEBUG ConfigFactory - 	samjdk.compression_level = 2; 23:43:52.474 DEBUG ConfigFactory - 	spark.kryoserializer.buffer.max = 512m; 23:43:52.474 DEBUG ConfigFactory - 	spark.driver.maxResultSize = 0; 23:43:52.474 DEBUG ConfigFactory - 	spark.driver.userClassPathFirst = true; 23:43:52.474 DEBUG ConfigFactory - 	spark.io.compression.codec = lzf; 23:43:52.474 DEBUG ConfigFactory - 	spark.executor.memoryOverhead = 600; 23:43:52.475 DEBUG ConfigFactory - 	spark.driver.extraJavaOptions = ; 23:43:52.475 DEBUG ConfigFactory - 	spark.executor.extraJavaOptions = ; 23:43:52.475 DEBUG ConfigFactory - 	codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 23:43:52.475 DEBUG ConfigFactory - 	read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 23:43:52.475 DEBUG ConfigFactory - 	annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 23:43:52.477 DEBUG ConfigFactory - 	cloudPrefetchBuffer = 40; 23:43:52.477 DEBUG ConfigFactory - 	cloudIndexPrefetchBuffer = -1; 23:43:52.477 DEBUG ConfigFactory - 	createOutputBamIndex = true; 23:43:52.477 INFO GermlineCNVCaller - Deflater: IntelDeflater; 23:43:52.477 INFO GermlineCNVCaller - Inflater: IntelIn",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:3523,Config,ConfigFactory,3523,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['Config'],['ConfigFactory']
Modifiability,"2.0-local.jar; Exception in thread ""main"" java.lang.OutOfMemoryError: Requested array size exceeds VM limit; at java.util.Properties$LineReader.readLine(Properties.java:485); at java.util.Properties.load0(Properties.java:353); at java.util.Properties.load(Properties.java:317); at org.aeonbits.owner.loaders.PropertiesLoader.load(PropertiesLoader.java:50); at org.aeonbits.owner.loaders.PropertiesLoader.load(PropertiesLoader.java:43); at org.aeonbits.owner.LoadersManager.load(LoadersManager.java:46); at org.aeonbits.owner.Config$LoadType$2.load(Config.java:129); at org.aeonbits.owner.PropertiesManager.doLoad(PropertiesManager.java:290); at org.aeonbits.owner.PropertiesManager.load(PropertiesManager.java:163); at org.aeonbits.owner.PropertiesManager.load(PropertiesManager.java:153); at org.aeonbits.owner.PropertiesInvocationHandler.<init>(PropertiesInvocationHandler.java:54); at org.aeonbits.owner.DefaultFactory.create(DefaultFactory.java:46); at org.aeonbits.owner.ConfigCache.getOrCreate(ConfigCache.java:87); at org.aeonbits.owner.ConfigCache.getOrCreate(ConfigCache.java:40); at org.broadinstitute.hellbender.utils.config.ConfigFactory.getOrCreate(ConfigFactory.java:268); at org.broadinstitute.hellbender.utils.config.ConfigFactory.getOrCreateConfigFromFile(ConfigFactory.java:454); at org.broadinstitute.hellbender.utils.config.ConfigFactory.initializeConfigurationsFromCommandLineArgs(ConfigFactory.java:439); at org.broadinstitute.hellbender.utils.config.ConfigFactory.initializeConfigurationsFromCommandLineArgs(ConfigFactory.java:414); at org.broadinstitute.hellbender.Main.parseArgsForConfigSetup(Main.java:121); at org.broadinstitute.hellbender.Main.setupConfigAndExtractProgram(Main.java:179); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:204); at org.broadinstitute.hellbender.Main.main(Main.java:291); ```. ### Affected version(s); - [x] Latest public release version [version?]; Yes. 4.1.2.0. - [ ] Latest master branch as of [date of test?]; Not tested. #### S",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6050:1255,Config,ConfigCache,1255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6050,1,['Config'],['ConfigCache']
Modifiability,"2/Core/python/3.6.10/lib/python3.6/configparser.py"", line 781, in get; d = self._unify_values(section, vars); File ""/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx512/Core/python/3.6.10/lib/python3.6/configparser.py"", line 1141, in _unify_values; raise NoSectionError(section); configparser.NoSectionError: No section: 'blas'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/configparser.py"", line 328, in __get__; delete_key=delete_key); File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/configparser.py"", line 172, in fetch_val_for_key; raise KeyError(key); KeyError: 'blas.ldflags'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/theano/configdefaults.py"", line 1256, in check_mkl_openmp; import mkl; ModuleNotFoundError: No module named 'mkl'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/pymc3/__init__.py"", line 5, in <module>; from .distributions import *; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/pymc3/distributions/__init__.py"", line 1, in <module>; from . import timeseries; File ""/lustre04/scratch/helene/Ticket/0196857/ENV_python_3.6.10/lib/python3.6/site-packages/pymc3/distributions/timeseries.py"", line 1, in <module>; import theano.tensor as tt; File ""/lustre04/scratch/helene/Ticket/0196857/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8387:2094,config,configdefaults,2094,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8387,1,['config'],['configdefaults']
